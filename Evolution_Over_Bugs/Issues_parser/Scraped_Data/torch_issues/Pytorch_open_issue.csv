Issue Number,Issue Title,Time created,Time closed,Number of Assignees,Number of Comments,Tags
114968,Missing `.so` files when installing PyTorch 1.11.0 for PyTorch3D with Python 3.8 ,2023-12-01 18:20:37+00:00,,0,0,"[Label(name=""oncall: pt2"")]"
114967,Inplace update to buffers doesn't work with `aot_compile`,2023-12-01 18:10:19+00:00,,0,0,[]
114966,[dynamo] dynamo does not support dataclasses with `frozen=True`,2023-12-01 18:04:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
114964,"[dynamo] missing support for function `object.__setattr__(obj, name, value)`",2023-12-01 18:00:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
114963,"[dynamo] missing support for builtin function `dict.fromkeys(iterable, value=None, /)`",2023-12-01 17:58:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
114962,`CUDAExtension` no longer works with `ccache`,2023-12-01 17:48:02+00:00,,0,0,[]
114954,Add dynamic shape tests for important models to guard against regression,2023-12-01 16:18:29+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
114951,Unexpected poor performance of C++ extension / wish for a fast `operator[]`,2023-12-01 14:08:18+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
114949,"Nvidia P100, where to disable upcasting? Plus kernel image missing.",2023-12-01 12:18:13+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
114948,conda package _openmp_mutex  makes pytorch dataloader slower when set num_workers > 0,2023-12-01 12:08:53+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
114945,torch.multinomial - Unexpected (incorrect) results when replacement=True in version 2.1.1+cpu,2023-12-01 10:50:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random"")]"
114943,torch.einsum may choose a strategy for which there is not enough memory,2023-12-01 10:24:55+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
114942,[MPS only] failed assertion `New volume: xxx should match old volume: xxx [reshapeWithCommandBuffer] MPSNDArrayIdentity.',2023-12-01 10:10:57+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: mps"")]"
114938,torch.compile is not working with torchaudio.functional.lfilter,2023-12-01 08:42:07+00:00,,0,0,"[Label(name=""oncall: pt2"")]"
114936,[PT2.1][torch.compile] empty shape in tracing,2023-12-01 07:04:13+00:00,,0,0,"[Label(name=""oncall: pt2"")]"
114935,print statements used in torch/utils/cpp_extension.py,2023-12-01 06:51:51+00:00,,0,1,"[Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
114934,get an approximate value to the memory usage for both inferance and training  ,2023-12-01 06:38:20+00:00,,0,1,"[Label(name=""module: memory usage""), Label(name=""oncall: pt2"")]"
114933,duplicate code in python_arg_parser.cpp ,2023-12-01 06:27:09+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged"")]"
114928,`torch.nn.utils.rnn.pack_padded_sequence` heap-buffer-overflow,2023-12-01 03:45:39+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
114925,DISABLED test_make_fx_symbolic_exhaustive_out_special_entr_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-12-01 00:57:10+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
114913,[CI] Lintrunner takes 60+ min,2023-12-01 00:16:29+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
114911,single-batch `torch.bmm` is significantly slower with cuBLAS>12.1.0 ,2023-11-30 23:56:42+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: cuda""), Label(name=""module: third_party""), Label(name=""topic: performance"")]"
114904,Validations for 2.1.2 release,2023-11-30 22:05:53+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
114903,[inductor] `torch.var` unexpectedly returns NaN values on A16 and A2 ,2023-11-30 21:57:41+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
114899,aot_export_module doesn't work with torch.cond,2023-11-30 20:57:30+00:00,,1,2,"[Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
114892,ExportedProgram.run_decompistion errors when specifying dim=-1 in torch.ops.aten.scatter_add,2023-11-30 19:44:48+00:00,,0,0,"[Label(name=""oncall: export"")]"
114888,"PyTorch is super bloated, even the data loader has too many lines of code.",2023-11-30 18:50:05+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
114884,Undefined reference to ncclCommSplit,2023-11-30 17:31:37+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
114879,[inductor][cpu]basic_gnn_gin and basic_gnn_sage AMP performance regression,2023-11-30 16:09:17+00:00,,1,2,"[Label(name=""module: cpu""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
114877,Sparse CSC | CSR | Tensor Serialization Load Issue,2023-11-30 15:23:35+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: serialization""), Label(name=""triaged"")]"
114876,Add support for torch.cat on nested_tensor,2023-11-30 15:23:18+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
114875,[inductor][cpu] few models show performance regression on CPP Wrapper,2023-11-30 14:54:06+00:00,,0,3,"[Label(name=""module: cpu""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
114874,nn.LSTM tolerates wrong input shape when hidden state isn't provided.,2023-11-30 14:44:17+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
114873,[inductor][cpu] hf_T5_generate and doctr_det_predictor failed on CPP Wrapper Dynamic Shape,2023-11-30 14:42:05+00:00,,1,3,"[Label(name=""module: cpu""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
114871,Sparse block tensors (`torch.sparse`),2023-11-30 14:14:19+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
114869,[inductor][cpu] llama and pytorch_stargan failed on CPP Wrapper,2023-11-30 13:59:42+00:00,,1,3,"[Label(name=""module: cpu""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
114868,test_vmapvjpvjp_linalg_tensorsolve_cpu_float32 fails with precision issue,2023-11-30 12:59:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
114864,`torch.Tensor.index_add` segfault by negative-size-param,2023-11-30 11:34:57+00:00,,1,1,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: python frontend""), Label(name=""module: edge cases"")]"
114861,Torchrun threads with different computing speed.,2023-11-30 10:05:50+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
114859,PT2 QAT flow fails to get reasonable accuracy with  mobilenet_v3_large,2023-11-30 09:11:12+00:00,,0,0,"[Label(name=""oncall: quantization""), Label(name=""oncall: pt2"")]"
114857,recursive search for DDP ignored parameters,2023-11-30 08:34:56+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
114856,[RFC] Intel GPU Inductor backend upstreaming,2023-11-30 08:25:11+00:00,,3,0,"[Label(name=""module: intel""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
114855,SparseTensor index select uses more CUDA memory than Torch index select,2023-11-30 08:19:42+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
114850,[RFC] Add Intel GPU support into PyTorch CI/CD ,2023-11-30 07:15:58+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""module: intel"")]"
114848,[RFC]Intel GPU oneDNN Upstreaming,2023-11-30 06:47:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: intel"")]"
114844,CUDA graph doesn't update tensor on replay,2023-11-30 05:33:46+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
114842,[RFC] Intel GPU Runtime Upstreaming,2023-11-30 05:05:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: intel"")]"
114840,MacOS tests randomly fail after https://github.com/pytorch/pytorch/commit/165f4f6ccf7522d75df99c30821d583dfc58ad62,2023-11-30 05:01:36+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: ci""), Label(name=""module: macos"")]"
114835,[RFC] Building system for SYCL and limited number of SYCL kernels for ATen fallbacks of TorchInductor,2023-11-30 03:44:16+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: intel""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
114834,DISABLED test_grad_nn_functional_conv3d_cuda_float32 (__main__.TestOperatorsCUDA),2023-11-30 03:40:18+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
114833,DISABLED test_fn_gradgrad_linalg_lu_cuda_complex128 (__main__.TestBwdGradientsCUDA),2023-11-30 03:40:16+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: linear algebra""), Label(name=""skipped"")]"
114832,DISABLED test_fn_gradgrad_linalg_lu_factor_ex_cuda_float64 (__main__.TestBwdGradientsCUDA),2023-11-30 03:40:12+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: linear algebra""), Label(name=""skipped"")]"
114831,DISABLED test_torch_name_rule_map_updated (__main__.TraceRuleTests),2023-11-30 03:40:12+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
114808,Efficient Cholesky and QR updates,2023-11-29 23:26:11+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
114807,Addition of Sparse and Dense Tensors Triggers Internal Assertion Failure,2023-11-29 23:19:28+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
114805,Unsupported: call_method UserDefinedObjectVariable(_profiler_enabled) __call__ [] {},2023-11-29 22:51:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: graph breaks"")]"
114801,torch.onnx.export to support opset 20. ,2023-11-29 22:09:51+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
114796,Add head_mask for transformers,2023-11-29 21:09:10+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
114786,[ONNX] Refactor op level_debug to catch mismatches between ONNX models and ExportedProgram and nn.Module,2023-11-29 20:00:15+00:00,,2,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
114783,[ONNX] Extend `test_fx_op_conistency.py` to take `ExportedProgram` converter,2023-11-29 19:55:21+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
114777,torch.compile x autograd.Function x enum inputs graph breaks,2023-11-29 19:20:04+00:00,,0,1,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: graph breaks"")]"
114765,DistributedDataParallel _verify_param_shape_across_processes causes reserved memory on GPU,2023-11-29 17:59:33+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
114760,[AOTAutograd] nit `assert_functional_graph` is misnamed,2023-11-29 15:41:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: aotdispatch"")]"
114752,Issues when trying to compile nn.functional.interpolate() layer with dynamic input and output size,2023-11-29 12:40:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
114750,"[aarch64] `nn.Linear(20, 1)` inference fails",2023-11-29 12:27:31+00:00,,0,12,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""module: nn""), Label(name=""module: mkldnn""), Label(name=""module: regression""), Label(name=""module: arm"")]"
114743,aot_module fails to trace modules whose parameters are tied (models with shared params),2023-11-29 08:18:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
114742,[Add][compile] Tensor with dtype torch.int64 is not the expected dtype of torch.int32!,2023-11-29 07:33:27+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
114740,torch.cuda.amp.common.amp_definitely_not_available() failed and needs to raise RuntimeError,2023-11-29 06:27:51+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
114723,[RFC] Intel GPU Upstreaming ,2023-11-29 01:48:29+00:00,,4,1,"[Label(name=""triage review""), Label(name=""module: intel""), Label(name=""module: inductor"")]"
114721,AppleSilicon binaries are build without OpenMP support,2023-11-29 01:32:16+00:00,,1,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: releng"")]"
114719,DISABLED test_make_fx_symbolic_exhaustive_out_special_log_ndtr_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-29 00:56:53+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
114691,`torch.from_numpy` does not support `set_default_device`,2023-11-28 19:29:02+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: tensor creation"")]"
114681,DISABLED test_sync_batch_norm_empty_input (__main__.DistributedDataParallelTest),2023-11-28 15:39:39+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
114680,pytorch cpuinfo submodule to be updated to the latest,2023-11-28 14:07:46+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
114679,Unexpected Results in PyTorch Tensor Operations with Python Scalars,2023-11-28 13:59:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
114677,"Upgrading from 1.8.1 to 1.13.0 causes exported ONNX file enlarged greatly, printable graph changed, and crashed when converting to TensorRT",2023-11-28 09:22:00+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
114676,'SymFloat' object has no attribute 'is_integer',2023-11-28 09:19:34+00:00,,1,0,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
114674,Dynamo guards key error for `guarded_backend_cache.cached_backends`,2023-11-28 08:57:21+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
114672,torch.fft.ifft crashes for empty input,2023-11-28 07:52:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fft"")]"
114670,DISABLED test_backward_nn_functional_conv3d_cuda_float32 (__main__.TestCompositeComplianceCUDA),2023-11-28 06:40:17+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
114665,DISABLED test_cuda_stream_method_dynamic_shapes (__main__.DynamicShapesCtxManagerTests),2023-11-28 05:00:25+00:00,,0,1,"[Label(name=""triaged""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
114656,DISABLED test_conj_view_nn_functional_conv3d_cuda_complex64 (__main__.TestMathBitsCUDA),2023-11-28 00:57:42+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
114655,DISABLED test_noncontiguous_samples_nn_functional_conv3d_cuda_float32 (__main__.TestCommonCUDA),2023-11-28 00:57:12+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
114654,DISABLED test_jvpvjp_nn_functional_conv3d_cuda_float32 (__main__.TestOperatorsCUDA),2023-11-28 00:57:09+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: functorch"")]"
114652,__torch_dispatch__ fails on functionalization when lazy device and `out=` arg is used,2023-11-28 00:55:28+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""module: lazy""), Label(name=""module: functionalization"")]"
114650,Error when calculating the Jacobian of torch.conj using forward-mode differentiation,2023-11-28 00:35:47+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""has workaround""), Label(name=""needs design"")]"
114635,[export] AssertionError: expected FunctionType found method <bound method QuantLinearConvBase.quantized_forward of <class '__main__.QuantConv2d'>>,2023-11-27 22:32:00+00:00,,0,0,"[Label(name=""oncall: export"")]"
114632,[DeviceMesh] back DeviceMesh initialization by custom_pg,2023-11-27 22:02:09+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
114631,DISABLED test_vjpvmap_nn_functional_conv3d_cuda_float32 (__main__.TestOperatorsCUDA),2023-11-27 21:42:45+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
114629,[DeviceMesh] `init_device_mesh` does not support CPU-only,2023-11-27 21:16:45+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
114628,`run_decompositions` in `ExportedProgram` doesn't keep the same model state_dict,2023-11-27 21:14:06+00:00,,0,2,"[Label(name=""oncall: export"")]"
114617,RNN argument order,2023-11-27 18:53:24+00:00,,1,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
114602,[RFC] macOS x86 builds / test deprecation,2023-11-27 17:19:21+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: macos"")]"
114592,DISABLED test_variant_consistency_eager_nn_functional_conv3d_cuda_complex64 (__main__.TestCommonCUDA),2023-11-27 09:39:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
114591,Missing packaging dependency in torch 2.1.x,2023-11-27 09:20:17+00:00,,0,3,"[Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""module: tensorboard"")]"
114590,`torch.compiler.disable` causes a guard failure,2023-11-27 09:12:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
114581,Flawed testing of onesidedness in istft,2023-11-27 05:12:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fft"")]"
114577,torch.norm_except_dim() operator: Cannot call sizes() on tensor with symbolic sizes/strides ,2023-11-27 04:03:15+00:00,,0,1,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: norms and normalization""), Label(name=""oncall: pt2"")]"
114574,DISABLED test_schema_correctness_nn_functional_conv3d_cuda_complex64 (__main__.TestSchemaCheckModeOpInfoCUDA),2023-11-27 03:39:27+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
114573,DISABLED test_schema_correctness_nn_functional_conv3d_cuda_complex128 (__main__.TestSchemaCheckModeOpInfoCUDA),2023-11-27 03:39:23+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
114572,"In version 2.1, libtorch needs to be woken up every time it is called after the model is initialized, which means that every time the model is called, it is very slow to predict the first picture.",2023-11-27 02:58:12+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: cpp""), Label(name=""triaged"")]"
114571,inconsistency between nan cast to int32 on CPU and GPU,2023-11-27 02:29:03+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
114569,inconsistency on torch.clamp,2023-11-27 02:04:29+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
114567,Internal CI for libTorch,2023-11-27 01:01:48+00:00,,1,3,"[Label(name=""module: windows""), Label(name=""triaged"")]"
114566,Build LibTorch for Windows ARM64,2023-11-27 00:56:51+00:00,,1,2,"[Label(name=""module: windows""), Label(name=""triaged"")]"
114565,Create a reproducible build for LibTorch x64 on VS2022,2023-11-27 00:50:02+00:00,,1,2,"[Label(name=""module: windows""), Label(name=""triaged"")]"
114548,[BE / AOTAutograd] AOTAutograd should be refactored into smaller files with clear responsibilities,2023-11-26 10:41:58+00:00,,0,8,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114543,[torch.jit.script] Torchscript produces incorrect result when argmax result is used in indexing,2023-11-26 08:12:49+00:00,,0,1,"[Label(name=""oncall: jit"")]"
114542,size error when using bits-level ops + broadcasting + view,2023-11-26 03:29:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
114535,[profiling] CUDA memory viz does not compose with `torch.compile`,2023-11-25 14:02:07+00:00,,0,1,"[Label(name=""oncall: profiler"")]"
114534,`PYTORCH_NO_CUDA_MEMORY_CACHING=1` with `torch.multiprocessing` shared tensors seems to perform use-after-free,2023-11-25 13:47:37+00:00,,0,0,"[Label(name=""triage review""), Label(name=""module: multiprocessing""), Label(name=""module: cuda"")]"
114533,Tensor copied over to multiple GPUs on its own,2023-11-25 08:45:32+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
114529,Bug in element-wise multiplication of `torch.sparse_csr_tensor`s on GPU - 0's in result considered significant - PyTorch 2.1.1,2023-11-25 05:43:02+00:00,,0,7,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: regression"")]"
114527,"[debugging] Given a flag, `FakeTensor`s should store metadata about their creation stacktrace ",2023-11-25 04:10:08+00:00,,0,0,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: pt2-dispatcher"")]"
114525,[Inductor] StableDiffusion unet with `cudagraphs` backend raises fake tensor mismatch error,2023-11-25 03:13:36+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: cuda graphs""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
114517,Update error message on cache size exceeded to mention whether it's from `cache_size_limit` or `accumulated_cache_size_limit`,2023-11-24 19:18:18+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
114516,Change `automatic_dynamic_shapes` to trigger on `cache_size_limit` recompiles but not `accumulated_cache_size_limit` recompiles.,2023-11-24 19:16:13+00:00,,0,1,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
114511,"Raise `torch._dynamo.config.accumulated_cache_size_limit` higher, or potentially just remove it altogether.",2023-11-24 17:18:04+00:00,,0,3,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
114502,_foreach_supported_types is a list type while it is used for `in` check of _default_to_fused_or_foreach method in optimizer.py,2023-11-24 09:15:16+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
114495,[inductor][cpu]basic_gnn_edgecnn performance regression,2023-11-24 03:54:46+00:00,,1,6,"[Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
114494,[inductor][cpu]llama fp32 dynamic single thread performance regression,2023-11-24 03:22:59+00:00,,1,3,"[Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
114491,[inductor][cpu]pyhpc_isoneutral_mixing performance regression,2023-11-24 02:40:15+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
114489,[inductor][cpu]pyhpc_equation_of_state performance regression,2023-11-24 01:56:29+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
114488,[inductor][cpu]swin_base_patch4_window7_224 AMP single thread performance regression,2023-11-24 01:30:08+00:00,,2,2,"[Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
114485,Parameters between models don't copy in the C++ Pytroch Frontend under windows,2023-11-23 22:51:15+00:00,,0,0,"[Label(name=""module: windows""), Label(name=""module: cpp""), Label(name=""triaged"")]"
114483,dynamo supports Tensor.tolist but not Tensor.item,2023-11-23 20:55:35+00:00,,0,0,"[Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
114473,[inductor][cpu]cspdarknet53 and tf_mixnet_l AMP single thread performance regression,2023-11-23 18:24:43+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
114468,[inductor][cpu]phi_1_5 accuracy failure and AMP single thread performance regression,2023-11-23 16:10:38+00:00,,1,10,"[Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
114466,[inductor][cpu]detectron2_fcos_r_50_fpn accuracy and performance failure,2023-11-23 15:41:38+00:00,,1,3,"[Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
114465,Installation error: 'CMake Error at third_party/benchmark/CMakeLists.txt:304 (message):   Failed to determine the source files for the regular expression backend',2023-11-23 15:16:10+00:00,,0,11,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
114464,inductor silently ignores clone followed by a reshape,2023-11-23 14:08:17+00:00,,0,4,"[Label(name=""oncall: pt2"")]"
114462,Transformer with convolutional position wise feed forward network ,2023-11-23 13:14:53+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
114461,DISABLED test_make_fx_symbolic_exhaustive_special_laguerre_polynomial_l_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-23 12:45:46+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
114458,The behavior of Using different device in Autocast context ,2023-11-23 11:28:34+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
114455,Torch Cpu Memory Leak with FastApi uvicorn.,2023-11-23 09:36:16+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
114450,[AOTInductor] Need support to export freezing model,2023-11-23 07:38:23+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""feature""), Label(name=""oncall: pt2"")]"
114440,There seems to be redundant calling of findOp in findSchemaOrThrow method of Dispatcher.cpp,2023-11-23 04:09:16+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
114439,DISABLED test_variant_consistency_eager_linalg_lu_factor_cuda_float32 (__main__.TestCommonCUDA),2023-11-23 03:39:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
114415,AOTAutograd should detect aliasing of inputs that happens *below* subclasses,2023-11-22 22:36:03+00:00,,0,0,"[Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114414,[BE] remove SmallVector optimization in PyInterpreter.cpp when storing custom sizes,2023-11-22 22:28:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""module: dynamic shapes"")]"
114413,Support sending __torch_dispatch__ subclasses in torch.compile that do not desugar,2023-11-22 22:22:49+00:00,,0,2,"[Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
114412,torch.compile <> __torch_dispatch__ support tracker issue,2023-11-22 22:18:44+00:00,,0,1,"[Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114411,higher order ops + torch.compile + __torch_dispatch__ subclasses,2023-11-22 22:18:17+00:00,,0,0,"[Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: higher order operators""), Label(name=""module: pt2-dispatcher"")]"
114410,__torch_dispatch__ + compile: backward guards,2023-11-22 22:08:43+00:00,,0,3,"[Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114408,DISABLED test_make_fx_symbolic_exhaustive_special_i1_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-22 21:39:21+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
114406,torch.onnx.dynamo_export functionalization does not support aten.add_.Tensor,2023-11-22 21:36:22+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""release notes: onnx"")]"
114405,__torch_dispatch__ + compile: extra guards,2023-11-22 21:34:37+00:00,,0,4,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
114403,refactor TracingContext to take a more limited subset of ViewAndMutationMeta,2023-11-22 21:23:34+00:00,,0,5,"[Label(name=""good first issue""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114401,torch.compile + subclasses: input is duplicate of another input,2023-11-22 21:18:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
114400,torch.compile + subclasses: input aliases another input,2023-11-22 21:17:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
114399,"[BE] AOTAutograd, refactor `run_functionalized_fw_and_collect_metadata` to not take in `is_training` flag.",2023-11-22 21:15:47+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114398,[BE] better testing for subclasses + compile,2023-11-22 21:10:29+00:00,,0,2,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
114397,__torch_dispatch__ + compile: run functionalization before the subclass,2023-11-22 21:01:50+00:00,,0,2,"[Label(name=""module: __torch_dispatch__""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
114396,is PGNCCL abortCommsFromMap working correctly?,2023-11-22 20:56:02+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
114392,[BUG][pytree] equal `dict`s do not imply equal leaves and equal treespecs,2023-11-22 19:53:50+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: pytree"")]"
114389,__torch_dispatch__ + torch.compile: support custom methods/constructor calls,2023-11-22 18:58:36+00:00,,0,1,"[Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
114388,Respect user-specified USE_ROCM/USE_CUDA,2023-11-22 18:53:35+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""enhancement"")]"
114374,dynamic shapes support for __torch_dispatch__ subclasses + torch.compile,2023-11-22 17:49:56+00:00,,0,7,"[Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: pt2-dispatcher"")]"
114373,torch.compile support for SeamlessExpressivity/SeamlessM4T in fairseq2,2023-11-22 17:37:51+00:00,,0,0,"[Label(name=""oncall: pt2"")]"
114369,__torch_function_ subclasses do not work with dynamic shapes,2023-11-22 16:51:02+00:00,,1,1,"[Label(name=""module: __torch_function__""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
114366,TypeError: unhashable type: non-singleton SymInt in AOTAutograd merge_view_inputs,2023-11-22 16:17:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114364,Improve usability of CUDA package by adding description of CUDA,2023-11-22 15:54:13+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
114363,Register Meta func for aten::_cslt_sparse_mm,2023-11-22 15:53:35+00:00,,1,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
114361,Custom Process Group for Each Module in FSDP,2023-11-22 15:12:38+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
114357,Pytorch DDP across nodes: self._store = TCPStore( # type: ignore[call-arg] RuntimeError: Stop_waiting response is expected,2023-11-22 14:01:39+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
114356,"[WARNING] could not load None, generating random data instead is too spammy",2023-11-22 13:58:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: minifier"")]"
114353,add support for linalg lstsq in dynamo,2023-11-22 13:02:49+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""release notes: dynamo"")]"
114352,DISABLED test_make_fx_symbolic_exhaustive_out_special_laguerre_polynomial_l_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-22 12:46:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
114350,The 'out'-parameter in torch.matmul() works for 'cuda' device but not for 'cpu',2023-11-22 10:58:34+00:00,,0,14,"[Label(name=""module: cpu""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: intel"")]"
114346,[PT2] Compile Cold Start - Async JIT compile with Eager fallback,2023-11-22 09:30:58+00:00,,0,7,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
114345,Incorrect line in description of torch.frombuffer() method,2023-11-22 09:12:20+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: python frontend"")]"
114344,[AOTAutograd] Incorrect CSE aliasing while `requires_grad` meta differs,2023-11-22 08:19:37+00:00,,0,2,"[Label(name=""oncall: pt2"")]"
114340,DISABLED test_use_orig_params (__main__.TestFSDPOptimState),2023-11-22 06:40:27+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
114339,DISABLED test_make_fx_symbolic_exhaustive_out_special_i1_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-22 06:40:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
114338,[AOTAutograd] torch.compile under ambient `no_grad` is broken,2023-11-22 05:00:24+00:00,,1,10,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114334,`AdaptiveLogSoftmaxWithLoss` division by zero,2023-11-22 04:27:06+00:00,,1,1,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""actionable"")]"
114332,DISABLED test_make_fx_symbolic_exhaustive_special_hermite_polynomial_h_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-22 03:40:37+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
114320,"When cuda graph captures multi-stream function, allocations are not serviced from the correct pool",2023-11-22 00:01:36+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
114310,Support builtin round in torch.compile with dynamic shapes,2023-11-21 22:58:56+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
114306,Support calling torch.vmap from inside torch.compile,2023-11-21 22:06:22+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
114302,Mutation after `tensor.expand` returns wrong result.,2023-11-21 20:25:11+00:00,,1,10,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114301,Timeout of the coalesced operation cannot be detected,2023-11-21 20:14:11+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
114299,Per-Parameter-Sharding FSDP Tracker,2023-11-21 20:01:48+00:00,,2,9,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
114298,Compile pytorch for ppc64 redhat8,2023-11-21 19:51:55+00:00,,0,13,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER"")]"
114296,Minifier doesn't work with dynamic shapes,2023-11-21 19:47:58+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: minifier"")]"
114293,Recompilation triggered at each step of the loop involving array indexing,2023-11-21 19:08:11+00:00,,0,12,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
114292,"Tracing per-param sharding FSDP: User Defined Objects as inputs to HOPs (autograd.Function, specifically) ",2023-11-21 18:49:02+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: higher order operators""), Label(name=""module: distributed""), Label(name=""module: compiled autograd""), Label(name=""module: pt2-dispatcher"")]"
114291,"Tracing per-param sharding FSDP: Tensor keys in dicts over-rely on `specialized_value`, potentially soundness bug",2023-11-21 18:46:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
114290,Tracing per-param sharding FSDP: RemovableHandle -> RemovableHandleVariable ,2023-11-21 18:43:58+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
114289,"Tracing per-param sharding FSDP: Streams, Stream reconstruction ",2023-11-21 18:38:51+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
114288,Tracing per-param sharding FSDP: Dynamo tracing weakrefs,2023-11-21 18:36:19+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
114287,Align on the minimum supported Linux version (CentOS 7 is EOL in july 2024),2023-11-21 18:36:02+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
114286,Tracing per-param sharding FSDP,2023-11-21 18:35:58+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
114285,torch.linalg.matrix_rank fails on mps,2023-11-21 18:04:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
114283,CppException in Android Studio with faster_rcnn_fbnetv3g_fpn.yaml Configuration,2023-11-21 17:09:12+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
114232,manylinux_2_28 support,2023-11-21 13:09:43+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement"")]"
114231,inductor with dynamic shapes fails on float tensor creation from a tuple of ints,2023-11-21 13:02:08+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
114230,DISABLED test_make_fx_symbolic_exhaustive_special_chebyshev_polynomial_u_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-21 12:46:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
114226,[Inductor][gpu][miscompile] Outputs of torch.interpolate abnormally change when swapping output sequence,2023-11-21 12:28:02+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""topic: fuzzer"")]"
114220,boolean masking creates a graph break due to aten.nonzero,2023-11-21 10:42:47+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
114216,torch.nn.functional.max_pool2d outputs inf,2023-11-21 08:11:06+00:00,,1,1,"[Label(name=""module: nn""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
114215,Outputs of torch.mul abnormally change when swapping the input args of torch.mul,2023-11-21 08:08:08+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""topic: fuzzer"")]"
114212,DISABLED test_make_fx_symbolic_exhaustive_special_hermite_polynomial_he_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-21 06:40:18+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
114211,DISABLED test_make_fx_symbolic_exhaustive_special_chebyshev_polynomial_t_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-21 06:40:18+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
114207,`torch.gradient` heap buffer overflow,2023-11-21 06:06:25+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: python frontend"")]"
114206,[PT2] Compile Cold Start (Persistent Cacheing) - AOTAutograd may be bottleneck when `TORCHINDUCTOR_FX_GRAPH_CACHE=1`,2023-11-21 06:00:24+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""topic: performance""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: dynamo""), Label(name=""module: startup-tracing-compile time""), Label(name=""module: pt2-dispatcher"")]"
114203,[inductor] huggingface diffusers randn not replaced,2023-11-21 04:13:59+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: decompositions""), Label(name=""module: inductor"")]"
114202,torch._dynamo.exc.Unsupported: call_method UserDefinedObjectVariable(FrozenDict) __contains__ [ConstantVariable(str)] {},2023-11-21 04:00:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
114195,Remove temp variable to improve efficiency in `get_data_ptrs` for `TensorIterator`,2023-11-21 01:41:24+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: TensorIterator"")]"
114191,DISABLED test_closure_out_of_scope_cell_with_cond (__main__.MiscTests),2023-11-21 00:57:08+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
114189,Custom backend not called for compiling backward graph,2023-11-20 23:58:25+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: backend""), Label(name=""oncall: pt2"")]"
114188,Unsupported operator error: `aten::to_mkldnn` export to ONNX not supported,2023-11-20 23:38:35+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""onnx-triaged""), Label(name=""onnx-needs-info"")]"
114179,funccol collectives rewrite in dynamo does not work w/ kwargs,2023-11-20 22:26:27+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
114175,Unable to build on CUDA 11.8 due to cutlass incompatibility,2023-11-20 21:51:58+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
114171,"Indexing into torch.nn.Modulelist with indices >= 2 returns ""torch._dynamo.exc.InternalTorchDynamoError: SymNodeVariable() is not a constant""",2023-11-20 21:28:24+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
114165,Consider adding y/x -> y * 1/x optimization for `_foreach_div_.ScalarList` and other div Scalar overloads,2023-11-20 20:12:01+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: mta"")]"
114155,Lintrunner on all files fails locally even though it passes in CI,2023-11-20 19:13:03+00:00,,0,1,"[Label(name=""module: lint""), Label(name=""triaged"")]"
114153,[Tracker] Inconsistencies between CPU and GPU computation,2023-11-20 19:01:37+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged"")]"
114142,Mutating graph inputs on torch.export fails,2023-11-20 17:43:54+00:00,,0,19,"[Label(name=""triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
114139,test_arange_dynamic doesn't work with capture scalar outputs,2023-11-20 17:18:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor"")]"
114136,torch.vmap doesn't compose with torch.cond,2023-11-20 17:14:14+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: higher order operators""), Label(name=""module: pt2-dispatcher"")]"
114131,Inconsistency of state_dict loading across devices,2023-11-20 15:54:02+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
114123,Cannot fullgraph differentiate through boolean masking,2023-11-20 14:38:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: boolean tensor""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
114119,Performance of `torch.compile` is significantly slowed down under `torch.inference_mode`,2023-11-20 13:33:35+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""ezyang's list""), Label(name=""inference mode""), Label(name=""oncall: pt2"")]"
114114,Why there is no nn.LPPool3d?,2023-11-20 11:38:34+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable"")]"
114113,Typo in example of torch.linalg.solve_triangular,2023-11-20 11:23:52+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""actionable"")]"
114112,[JIT] - torch.script - 'Optional[Tensor]' object has no attribute or method 'size',2023-11-20 10:15:43+00:00,,0,0,"[Label(name=""oncall: jit"")]"
114109,`torch.compile()` makes loss `nan`,2023-11-20 09:15:40+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: pt2 accuracy"")]"
114107,Add the possibility to pass a `Generator` to `gumbel_softmax`,2023-11-20 08:45:17+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random"")]"
114105,Unexpected `None` value for stream with dynamo,2023-11-20 07:52:40+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
114102,"""aten::prelu"" can not be used in the metal backend",2023-11-20 07:25:32+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
114097,[RFC] Support for Redundant Hosts in TorchElastic,2023-11-20 06:40:11+00:00,,4,1,"[Label(name=""oncall: distributed""), Label(name=""module: elastic"")]"
114093,Found nn.LazyBatchNorm1d(0) has inconsistency bug between GPU and CPU testing,2023-11-20 02:35:26+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
114090,Nested tensors fail on Conv2D,2023-11-20 02:26:16+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
114086,exit code -1073740791 (0xC0000409) when torch.package.PackageExporter,2023-11-20 01:11:43+00:00,,0,0,"[Label(name=""module: windows""), Label(name=""oncall: package/deploy"")]"
114085,inconsistency in torch.Tensor.scatter on GPU and CPU,2023-11-20 01:05:07+00:00,,1,4,"[Label(name=""module: numerical-stability""), Label(name=""triaged"")]"
114080, torch.matrix_exp(x) get inf and nan,2023-11-20 00:23:04+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: cpu""), Label(name=""triaged"")]"
114072,Dynamic shapes not properly supported for nested tensor / tensor subclasses,2023-11-19 21:09:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""tensor subclass""), Label(name=""module: dynamic shapes"")]"
114070,[inductor] Assert that Inductor preserves output strides if `TORCHINDUCTOR_LAYOUT_OPTIMIZATION=0`,2023-11-19 20:39:00+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
114064,New Optimizer ,2023-11-19 16:08:50+00:00,,0,4,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
114048,Undocumented CUDA graphs requirement that kernels must use stream,2023-11-19 03:21:20+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: custom-operators""), Label(name=""module: cuda graphs"")]"
114044,Nan on torch.corrcoef(x.t()),2023-11-19 02:48:24+00:00,,0,1,"[Label(name=""triaged"")]"
114042,Poetry Torch 2.1.1+cu121 problem on Windows,2023-11-19 01:58:07+00:00,,1,12,"[Label(name=""module: binaries""), Label(name=""module: windows""), Label(name=""triaged"")]"
114040,IndexError: map::at with MPI CUDA collectives,2023-11-19 00:50:05+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
114035,Load model from jit script format. Repeating inference several times can lead to errors.,2023-11-19 00:13:39+00:00,,0,2,"[Label(name=""oncall: jit"")]"
114005,[pt2] Make error message clearer for torch.compile when running on windows,2023-11-17 23:49:18+00:00,,0,4,"[Label(name=""module: windows""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113985,[export] Helper function for specifying dynamic batch size,2023-11-17 21:09:29+00:00,,0,2,"[Label(name=""triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
113962,[v2.1.2] Release Tracker,2023-11-17 17:46:03+00:00,,0,15,"[Label(name=""triaged"")]"
113956,iSTFT gives wrong results for some batched input,2023-11-17 16:20:30+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: fft"")]"
113953,DISABLED test_lazy_clone_cuda_bfloat16 (__main__.TestTorchDeviceTypeCUDA),2023-11-17 15:41:17+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
113952,AOTAutograd silently drops required runtime assertions,2023-11-17 15:12:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
113948,Unknown CUDA Architecture Name 9.0a in CUDA_SELECT_NVCC_ARCH_FLAGS (compiling from source),2023-11-17 12:57:22+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
113946,DISABLED test_dynamic_kwarg (__main__.SubGraphTests),2023-11-17 12:46:18+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
113945,torch.jit.trace has incorrect execution for += operation during compilation,2023-11-17 12:25:52+00:00,,0,9,"[Label(name=""oncall: jit"")]"
113942,Tensorboard list of tensors as input,2023-11-17 10:26:02+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
113941,"libtorch_cpu.so: Undefined symbol ""__assert_fail""",2023-11-17 10:02:42+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
113938,deep copy 'HigherOrderOperator' bug,2023-11-17 09:44:18+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: higher order operators"")]"
113937,DISABLED test_distributed_checkpoint_state_dict_type0 (__main__.TestDistributedCheckpoint),2023-11-17 09:39:56+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
113936,DISABLED test_distributed_checkpoint_state_dict_type1 (__main__.TestDistributedCheckpoint),2023-11-17 09:39:53+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
113933,How to  re-use torch.compile results in different python processes?,2023-11-17 08:22:11+00:00,,1,11,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
113914,Register a torch op for `functorch.experimental.control_flow.map` to lower,2023-11-17 02:37:50+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: xla""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
113909,DISABLED test_cuda_stream_method (__main__.CtxManagerTests),2023-11-17 00:57:16+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
113908,DISABLED test_fn_fwgrad_bwgrad_linalg_lu_factor_ex_cuda_complex128 (__main__.TestFwdGradientsCUDA),2023-11-17 00:57:08+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
113905,Sympy reasoning with true division is broken,2023-11-17 00:26:07+00:00,,0,6,"[Label(name=""module: dependency bug""), Label(name=""triaged"")]"
113899,Tensor.requires_grad_() does not trace with make_fx,2023-11-16 22:28:20+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: ProxyTensor""), Label(name=""pre_dispatch tracing""), Label(name=""module: pt2-dispatcher"")]"
113895,Native c10d_functional collectives on inductor + CUDAGraphTrees generate wrong results,2023-11-16 21:24:14+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
113879,Tracking: Improve SymNode/Dynamic Shapes Logging,2023-11-16 17:00:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
113876,Fine grained SymNode logging,2023-11-16 16:39:10+00:00,,0,1,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
113868,Torchrun distribute training on Windows WSL,2023-11-16 14:49:12+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
113860,torch.fx export graph error ,2023-11-16 12:00:31+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
113858,Why the cuda peak memory usage increase after dist.reuduce_scatter operation ? ,2023-11-16 09:41:28+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
113857,DISABLED test_make_fx_symbolic_exhaustive_out_special_chebyshev_polynomial_u_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-16 09:39:47+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
113854,Timer: Add Standard Deviation for Single Measurement,2023-11-16 08:51:20+00:00,,0,0,"[Label(name=""oncall: profiler""), Label(name=""module: benchmark""), Label(name=""topic: new features"")]"
113850,DISABLED test_vmapvjpvjp_linalg_lu_factor_cuda_float32 (__main__.TestOperatorsCUDA),2023-11-16 06:40:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: functorch"")]"
113847,RuntimeError in use torch 2.1.0 cuda 11.8 ,2023-11-16 06:20:20+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
113840,torch.einsum is stuck in mp.Process,2023-11-16 04:06:21+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
113836,Can reducer provide a copy_hook?,2023-11-16 03:39:05+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
113833,cannot backprop a cnn when intermediate output has size larger than 2**31,2023-11-16 03:11:58+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: 64-bit""), Label(name=""actionable""), Label(name=""module: edge cases"")]"
113831,Update _scaled_mm to support addmm with bias.size == out.size,2023-11-16 02:31:52+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: float8"")]"
113824,DISABLED test_vjpvmap_nn_functional_conv_transpose3d_cuda_float32 (__main__.TestOperatorsCUDA),2023-11-16 00:57:38+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: functorch"")]"
113817,[ONNX] ONNX export of simple quantized model fails,2023-11-15 23:05:50+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""low priority""), Label(name=""triaged"")]"
113809,"Error during DDP, torch.compile, and cudagraph_trees",2023-11-15 22:07:42+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
113808,[ONNX][dynamo_export] ONNX::Celu Half unsupported but export passed w/ invalid model when opmath disabled,2023-11-15 21:53:39+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
113806,DISABLED test_make_fx_symbolic_exhaustive_out_special_chebyshev_polynomial_t_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-15 21:39:53+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
113800,InternalTorchDynamoError rewrapping loses exception chaining,2023-11-15 20:51:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
113798,consistency checks for across minor version builds,2023-11-15 20:04:39+00:00,,0,7,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
113794,[FSDP] Raise error when applying FSDP to `nn.ModuleList` or `nn.ModuleDict`,2023-11-15 19:26:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
113793,`torch.compile` fails when applied to tensor views that have been modified by in-place operators,2023-11-15 19:13:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113792,[export] Export warnings as no-ops,2023-11-15 19:12:14+00:00,,1,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
113788,torch.compile CUBLAS_STATUS_EXECUTION_FAILED,2023-11-15 19:03:14+00:00,,1,3,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: distributed"")]"
113786,torch.compile CUDNN_STATUS_MAPPING_ERROR,2023-11-15 19:00:43+00:00,,1,3,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: distributed"")]"
113778,Unsupported builtin operators for torch.export.export,2023-11-15 17:46:44+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""export-triaged""), Label(name=""oncall: export"")]"
113776,[cusparseLt] CUDA error: internal error when calling `cusparseLtStructuredDescriptorInit`,2023-11-15 17:44:50+00:00,,1,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
113773,RoCm support loop unrolling for `at::native::gpu_kernel_multiple_outputs`,2023-11-15 16:44:20+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""ciflow/rocm"")]"
113761,[DTensor][TP] 1-way TP raises index out of range,2023-11-15 13:55:46+00:00,,1,1,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: dtensor"")]"
113760,torch.profiler Trace view in Tensorboard is displayed as empty on RoCm version of PyTorch,2023-11-15 13:55:16+00:00,,0,8,"[Label(name=""module: rocm""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: tensorboard""), Label(name=""oncall: profiler"")]"
113755,Upsample trilinear onnx ,2023-11-15 12:35:57+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
113752,device_mesh documentation in FSDP ctor,2023-11-15 11:53:18+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
113751,"Cannot cast tensor to numpy array inside vmap due to ""Access data pointer of tensor that doesn't have storage""",2023-11-15 10:55:05+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: vmap"")]"
113750,[docs] Add reference/decomp impl snippets to functions in online docs for hackability and educational purposes / compensate for some unclear language in existing docs,2023-11-15 10:15:08+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: norms and normalization"")]"
113748,New feature: Balanced Sampler,2023-11-15 09:32:32+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
113744,Regression: `capture_pre_autograd_graph` does not support empty args and kwargs only anymore,2023-11-15 08:49:07+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
113743,The cuda batched GEMM has a poor performance for bigger batch size with smaller matrix size,2023-11-15 07:05:49+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""matrix multiplication"")]"
113741,Plan for transformer module based ROCm,2023-11-15 06:14:54+00:00,,0,0,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""ciflow/rocm"")]"
113737,torch.compile + SAC: mutations in backward are not preserved,2023-11-15 04:29:45+00:00,,2,7,"[Label(name=""module: checkpoint""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: distributed""), Label(name=""module: pt2-dispatcher"")]"
113736,DISABLED test_make_fx_symbolic_exhaustive_out_special_airy_ai_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-15 03:39:39+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
114604,"lax.cond, lax.switch alternatives",2023-11-15 02:22:41+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
113730,Can the official provide cpu offload method for large model inference?,2023-11-15 01:40:39+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs design"")]"
113724,[ONNX] Refactor xfail API to handle conditional failure scenarios,2023-11-15 00:28:33+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
113717,`preserve_rng_state=True` in torch.utils.checkpoint causes error when used with torch.compile + selective checkpointing + CUDA,2023-11-15 00:13:36+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113713,[cuDNN][cuDNN V8 API] cuDNN Flash-Attention Upstreaming RFC/tracking issue,2023-11-14 23:21:24+00:00,,1,2,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""oncall: transformer/mha"")]"
113708,`log_softmax` could be `2**124` to `2**1021` times more accurate on small outputs,2023-11-14 22:48:19+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
113707,torch.compile doesnt respect use_determistic_algorithms during the backward(),2023-11-14 22:47:14+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
113705,[ONNX] Track dynamic shapes integration for torch.onnx.dynamo_export,2023-11-14 22:38:57+00:00,,2,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""release notes: onnx"")]"
113700,C++ backtrace logging for dynamic shapes specialization,2023-11-14 22:29:56+00:00,,0,2,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""module: dynamic shapes"")]"
113698,verify ROCM profiler behavior listed in https://github.com/pytorch/tutorials/issues/2014,2023-11-14 22:24:27+00:00,,1,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""ciflow/rocm"")]"
113692,Removing index_put fallback results in bad C++ code,2023-11-14 21:41:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
113691,inductor/test_aot_inductor.py gets segfault but test ultimately passes,2023-11-14 21:19:21+00:00,,1,3,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113687,[ONNX] Execute ONNX Runtime with IOBindings through ONNXProgram.__call__,2023-11-14 20:52:16+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""release notes: onnx"")]"
113682,[export] Support capturing of non-tensor inputs,2023-11-14 20:35:49+00:00,,1,3,"[Label(name=""triaged""), Label(name=""export-triaged""), Label(name=""oncall: export"")]"
113673,Failure to resume from a normal (non-FSDP) checkpoint due to the optimizer state dict rekey,2023-11-14 19:14:44+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
113670,Implement Variable Tracker for Dataclasses,2023-11-14 18:49:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""topic: new features""), Label(name=""module: dynamo"")]"
113669,document functional_collectives,2023-11-14 18:40:14+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113663,FP8 types should not participate in type promotion and should have no math ops defined on them,2023-11-14 18:03:48+00:00,,0,6,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: float8"")]"
113652,[ONNX] ONNX export fails when combining tracing and scripting in the presence of symbolic functions,2023-11-14 16:47:42+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: regression"")]"
113646,Error in torch.set_default_tensor_type() documentation online (depreciated),2023-11-14 14:54:59+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable"")]"
113643,Distinguish immutable/mutable fake tensor mode,2023-11-14 13:51:14+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fakeTensor""), Label(name=""module: dynamo"")]"
113642,interpolate::trilinear returns wrong gradients on CUDA,2023-11-14 13:08:05+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""triaged"")]"
113637,Output mismatch of torch.Tensor.to with gpu inductor compiled when swapping output sequence,2023-11-14 10:07:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""topic: fuzzer"")]"
113623,torch.compile crash on sdxl unet compile with AMD 7900XTX,2023-11-14 06:17:15+00:00,,1,1,"[Label(name=""needs reproduction""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113621,App crashes when I attempt to run it with an iOS xcframework that relies on the LibTorch-Lite CocoaPod,2023-11-14 05:10:25+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: ios"")]"
113612,Graph breaks in APEX `FusedRMSNorm` causes bad interaction between NCCL allreduce and cudagraph tree,2023-11-14 01:49:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""module: cuda graphs""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
113606,`torch._dynamo.config.suppress_errors` may not be properly reset,2023-11-14 01:02:42+00:00,,1,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
113600,Segmentation fault in RPC worker when DataLoader has num_workers > 0,2023-11-14 00:43:20+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: distributed"")]"
113590,Implement FlashFFTConv algorithm,2023-11-13 22:31:39+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: multi-headed-attention"")]"
113589,Fake tensor produces incorrect values w/ is_coalesced and sparse_coo,2023-11-13 22:27:17+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
113587,bsr_dense_mm may produce incorrect results depending on triton kernel num_stages parameter,2023-11-13 21:37:00+00:00,,1,3,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""bug"")]"
113586,mps bug: failed assertion `[MPSNDArrayDescriptor sliceDimension:withSubrange:] error: subRange.start (8192) is not less than length of dimension[1] (512)',2023-11-13 21:23:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
113583,"OSS Test Failures surfaced internally, but not detected externally",2023-11-13 20:25:35+00:00,,1,4,"[Label(name=""module: ci""), Label(name=""triaged"")]"
113579,Creating Gaussian Mixture Models with MultivariateNormal,2023-11-13 19:46:03+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""module: nn""), Label(name=""triaged"")]"
113572,Deepcopying an exported model changes numerics for MobileNetV2,2023-11-13 18:24:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
113560,t.contiguous() ~10 slower in eager mode compared to torch.compile,2023-11-13 15:03:00+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
113552,2.1.0 export module：Why can't export() capture reverse graphs?,2023-11-13 08:52:38+00:00,,0,1,"[Label(name=""triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
113550,CUDA extension error message doesn't look correct,2023-11-13 07:55:52+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""module: cuda""), Label(name=""triaged"")]"
113546,"P0: Improve failure trace back when crashed to identify the cause of a crash and the ranks that the crash, output the real traceback at last.",2023-11-13 04:32:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""module: elastic"")]"
113545,P0: Logging Granularity checks fixes across torch.distributed + torchelastic launcher,2023-11-13 04:32:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: c10d"")]"
113544,"P0: Integrate distributed logger with TORCH_LOGS, make sure upper level library can't override distributed LOG level.",2023-11-13 04:29:51+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""module: distributed"")]"
113543,[PTD] Logging Improvements Main Task,2023-11-13 04:29:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""module: distributed"")]"
113541,Enhanced RNG State Management with Index-Based Control for Graph-Safe Tensor Parallelism,2023-11-13 04:04:55+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
113537,torch.compile error,2023-11-12 16:33:22+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113530,"Make ""torch.load"" multi threaded process",2023-11-12 11:44:42+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""needs research"")]"
113525,[Feature request] `stft` doesn't have `pad_value` argument,2023-11-11 21:14:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fft"")]"
113524,_fused_sdp_choice returns wrong backend in pt2,2023-11-11 20:37:35+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: multi-headed-attention"")]"
113522,SDPA Tutorial - fails for CPU runs on Google Colab,2023-11-11 17:11:10+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""docathon-h2-2023"")]"
113521,SDPA Tutorial - libcuda.so not found error for torch compile on Google Colab,2023-11-11 16:55:00+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""upstream triton"")]"
113515,torchrun discarding --rdzv-endpoint when it should not,2023-11-11 11:51:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: elastic"")]"
113507,Revisit test_edge_op_registration on PyTorch CI,2023-11-11 01:51:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: export"")]"
113506,DISABLED test_vit_aten_export (__main__.TestQuantizePT2EModels),2023-11-11 01:39:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""skipped"")]"
113504,[ONNX] STFT ExportProgram error,2023-11-11 00:58:16+00:00,,1,4,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
113496,"FSDP.forward() fails ""_is_root should not have been set"" error after saving a distributed checkpoint",2023-11-10 23:17:35+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""module: distributed"")]"
113490,/nodefaultlib:vcomp doesn't seem to be set when compiling with Intel OpenMP on Windows,2023-11-10 21:59:22+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged"")]"
113489,DISABLED test_make_fx_symbolic_exhaustive_round_decimals_3_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-10 21:39:45+00:00,,0,16,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
113486,Tensors Can't be  Overwritten in Visual Studio Windows,2023-11-10 20:31:45+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: windows""), Label(name=""module: cpp""), Label(name=""triaged"")]"
113483,Should `_native_batch_norm_legit_functional` be in native_functions.yaml?,2023-11-10 19:26:21+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
113479,DISABLED test_make_fx_symbolic_exhaustive_round_decimals_neg_3_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-10 18:40:35+00:00,,0,16,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
113478,DISABLED test_make_fx_symbolic_exhaustive_round_decimals_0_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-11-10 18:39:34+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
113456,Expose FakeTensor and FakeTensorMode as public APIs,2023-11-10 17:18:00+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
113453,Remove approvals when reverting a pr,2023-11-10 16:36:39+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: devx"")]"
113449,cuDNN error: CUDNN_STATUS_MAPPING_ERROR on gtx_1080/A10 when conv1d is called,2023-11-10 15:50:39+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
113444,ONNX Export - miscompilation for complex-valued operators,2023-11-10 13:53:18+00:00,,1,15,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
113443,`CompileProfiler` reports graph breaks while `dynamo.explain` reports no graph breaks,2023-11-10 12:32:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
113440,[inductor][cpu] freezing caused a lot of CV model crashed,2023-11-10 09:48:59+00:00,,1,17,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
113422,Implement pass-through `state_dict` and `load_state_dict` for dynamo `OptimizedModule`,2023-11-10 03:36:49+00:00,,0,5,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113419,code crashes on CI when using keep-going flag on PR,2023-11-10 02:56:59+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: devx"")]"
113415,Torch compile with DDP errors on parameterized modules,2023-11-10 02:05:54+00:00,,0,7,"[Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""module: nn.utils.parametrize""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
113414,Potential Precision Issue in SumKernel CPU Implementation Due to acc_type Selection,2023-11-10 02:04:39+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
113408,Early testing stop logic for CUDA error looks wrong for instantiated_test with pytest,2023-11-10 01:59:44+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: testing"")]"
113382,TorchXLA - owner @JackCaoG,2023-11-09 19:48:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: xla"")]"
113379,Print sources for free variables in dynamic shape logs,2023-11-09 18:43:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo""), Label(name=""module: guards"")]"
113378,[pytree] implement key path API,2023-11-09 18:40:34+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: pytree"")]"
113376,Add validation for send/recv sizes,2023-11-09 18:24:12+00:00,,0,6,"[Label(name=""oncall: distributed"")]"
113370,Incorrect stride when permuting shapes where a zero dimension is present.,2023-11-09 17:16:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases""), Label(name=""module: empty tensor"")]"
113368,Gradient of image rotation,2023-11-09 16:40:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: forward ad"")]"
113342,Torch2.1 returned  by calling new_group() or _get_default_group() is incorrect,2023-11-09 10:52:49+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
113329,Mark aten.normal as a core aten op,2023-11-09 05:10:39+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113326,`torch._C._cuda_getDeviceCount` inflates system memory usage,2023-11-09 02:32:21+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
113291,[aot_autograd] Handle `requires_grad` mutation in AOTAutograd,2023-11-08 19:41:34+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
113290,[dynamo / aot_autograd] AOTAutograd does not guard on input `requires_grad` setting changing for backwards,2023-11-08 19:33:40+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
113287,Provide a way to AOT torch.compile and serialize a model,2023-11-08 18:55:37+00:00,,0,14,"[Label(name=""triage review""), Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: startup-tracing-compile time""), Label(name=""module: distributed"")]"
113281,NCCL p2p ops hung after communicator aborts,2023-11-08 18:04:13+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
113271,[dynamo] Assigning result of Tensor in-place op destroys mutation tracking,2023-11-08 16:37:35+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
113263,PT2 improperly executes ambient saved_tensors_hooks,2023-11-08 14:59:13+00:00,,0,7,"[Label(name=""triage review""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
113252,DISABLED test_function_returns_input_inner_requires_grad_True_save_for_jvp_save_tensors_neither_mark_dirty_True_cpu (__main__.TestAutogradFunctionCPU),2023-11-08 08:00:26+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
113249,DISABLED test_reorder_compute_for_overlap (__main__.TestComputeCommReorderingMultiProc),2023-11-08 07:44:02+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
113245,NCCL error of PyTorch 2.1.0 when using multiple gpus,2023-11-08 06:28:03+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
113235,[dynamo] Remove usage of copy_graphstate/restore_graphstate in higher_order_ops.py,2023-11-08 03:25:39+00:00,,1,8,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
113232,[Torch Inductor] Torch Inductor Better Support for GNN workload and Inductor Sparse Compiler,2023-11-08 03:02:06+00:00,,0,1,"[Label(name=""triage review""), Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor"")]"
113228,dataloader use lmdb stuck,2023-11-08 01:51:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""release notes: dataloader"")]"
113222,EPOCH_DEPRECATION_WARNING in ChainedScheduler.step,2023-11-08 01:30:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: LrScheduler""), Label(name=""topic: deprecation"")]"
113221,DISABLED test_disable_fwd_grad_mixed_cpu (__main__.TestJvpCPU),2023-11-08 01:00:40+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
113220,DISABLED test_disable_fwd_grad_inside_cpu (__main__.TestJvpCPU),2023-11-08 00:56:55+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
113203,`inference_mode` before training results in FSDP AssertionError,2023-11-07 21:00:23+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
113192,"Fix docstring errors in checkpoint_example.py, basic_strategy.py, op_schema.py, contract.py, redistribute.py, __init__.py, api.py, device_mesh.py, _utils.py, sharding_prop.py, random.py, checkpoint_activation.py, placement_types.py, fully_shard.py, parallel_mode.py, replicate.py",2023-11-07 19:46:45+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
113190,"Fix docstring errors in _state_dict_utils.py, _runtime_utils.py, _shard_utils.py",2023-11-07 19:46:41+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
113188,"Fix docstring errors in _common_utils.py, _optim_utils.py, _wrap_utils.py, _unshard_param_utils.py, _fsdp_extensions.py, api.py, _debug_utils.py, _utils.py, wrap.py, sharded_grad_scaler.py",2023-11-07 19:46:37+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
113187,"Fix docstring errors in embedding.py, _limiter_utils.py, _dynamo_utils.py, embedding_bag.py, tensor_ops.py, api.py, _internals.py, _common.py, init.py, _exec_order_utils.py, _traversal_utils.py, chunk_sharding_spec.py, _trace_utils.py",2023-11-07 19:46:35+00:00,,1,6,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
113186,"Fix docstring errors in shard.py, op_registry_utils.py, local_timer.py, file_based_local_timer.py, api.py, distributed.py, cycling_iterator.py, __init__.py, _utils.py, reshard.py, common_op_utils.py, elastic_distributed_sampler.py, utils.py, log_level.py, store.py, logging.py, sharder.py, metadata.py",2023-11-07 19:46:33+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
113180,Higher train loss and worse evaluation metrics when using `torch.compile()`,2023-11-07 18:35:47+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: pt2 accuracy"")]"
113161,[Distributed][DTENSOR] Some operators registered under compositeimplicitautograd key can not work if I registered them under privateuse1,2023-11-07 15:25:17+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: dispatch""), Label(name=""module: dtensor"")]"
113160,"[dynamo] self-assigning operation causes `TensorVariable` to lose `mutable_local`, thus causing its attribute mutations to be untracked",2023-11-07 15:18:45+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
113156,torch._foreach_mul_ segmentation fault,2023-11-07 13:11:31+00:00,,1,5,"[Label(name=""module: crash""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: edge cases"")]"
113151,different outputs on `torch.asinh` between eager mode and torch.compile,2023-11-07 10:57:36+00:00,,0,4,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
113150,"Aborted (core dumped) after Run Pytorch2.0.0, which I compiled by myself",2023-11-07 10:44:24+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
113149,Compilation error on loongarch64,2023-11-07 10:17:00+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
113148,DISABLED test_lgamma_cpu (__main__.CpuTests),2023-11-07 09:44:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113146,DISABLED test_large_strided_reduction_dynamic_shapes_cpu (__main__.DynamicShapesCodegenCpuTests),2023-11-07 09:43:51+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113141,Output mismatch of torch.sum with torch.compile when swapping the input parameters of torch.mul on CPU,2023-11-07 08:06:22+00:00,,1,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
113140,DISABLED test_large_block_sizes_cuda (__main__.CudaTests),2023-11-07 06:40:54+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113139,DISABLED test_large_block_sizes_cpu (__main__.CpuTests),2023-11-07 06:40:01+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113137,DISABLED test_large_offset_pointwise_dynamic_shapes_cpu (__main__.DynamicShapesCodegenCpuTests),2023-11-07 06:39:55+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113136,DISABLED test_large_block_sizes_dynamic_shapes_cuda (__main__.DynamicShapesCodegenCudaTests),2023-11-07 06:39:52+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113135,DISABLED test_large_block_sizes_dynamic_shapes_cpu (__main__.DynamicShapesCodegenCpuTests),2023-11-07 06:39:49+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113134,DISABLED test_large_offset_pointwise_dynamic_shapes_cpu (__main__.DynamicShapesCpuTests),2023-11-07 06:39:46+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113133,DISABLED test_large_block_sizes_dynamic_shapes_cpu (__main__.DynamicShapesCpuTests),2023-11-07 06:39:43+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113132,DISABLED test_large_block_sizes_dynamic_shapes_cuda (__main__.DynamicShapesCudaTests),2023-11-07 06:39:40+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
113130,get_unbacked_symbol_defs in inductor uses a set and iterates over it,2023-11-07 05:59:20+00:00,,0,1,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""internal ramp-up task"")]"
113129,[torch.compile] Dynamic shape behavior is different between using torch.compile with and without compiled_autograd.enable,2023-11-07 05:45:59+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: compiled autograd""), Label(name=""module: pt2-dispatcher"")]"
113128,NCCL watchdog thread terminated with exception ,2023-11-07 05:37:43+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
113124,Request to add system requirements to doc,2023-11-07 03:48:26+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""docathon-h2-2023"")]"
113122,Request to create a tutorial for loading a model dumped by `torch.export`,2023-11-07 03:45:53+00:00,,1,3,"[Label(name=""triaged""), Label(name=""docathon-h2-2023""), Label(name=""oncall: export"")]"
113118,RuntimeError on `torch.unqiue_consecutive` with torch.compile( fullgraph = true),2023-11-07 02:51:41+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
113114,Allow to construct distributed Work object from Future,2023-11-07 01:30:27+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
113113,FSDP does not move modules without parameters to device,2023-11-07 01:22:43+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
113112,Add tests for ProcessGroupGloo::reduce_scatter_base and allgather_base,2023-11-07 01:19:26+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
113089,Add docs for __tensor_flatten__ / __tensor_unflatten__,2023-11-06 22:37:32+00:00,,0,3,"[Label(name=""triage review""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""tensor subclass""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
113079,"Automatically run ""lintrunner -a"" when needed and create review comments with autofixes",2023-11-06 22:16:21+00:00,,0,3,"[Label(name=""triaged"")]"
113067,[ONNX] stft export fails with dynamo_export,2023-11-06 20:50:10+00:00,,1,22,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
113063,Rework Dynamic Benchmarks To Actually Vary Shapes,2023-11-06 20:25:06+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
113062,MPS device: Sample from MultivariateNormal distribution,2023-11-06 20:22:30+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: mps"")]"
113053,[CUDA-12.2] cuSPARSE deprecated support for sparse BSR,2023-11-06 19:09:00+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
113045,[Feature][DTensor] Manage additional `_padded_local_tensor` attribute,2023-11-06 18:25:42+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: dtensor"")]"
113040,[PT2] [Hardening] Track recompiles alongside graph breaks in our actual/expected comparison CI runs,2023-11-06 17:50:09+00:00,,0,0,"[Label(name=""triage review""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
113037,`torch.div` on empty tensors causes segmentation fault,2023-11-06 17:40:49+00:00,,1,4,"[Label(name=""high priority""), Label(name=""module: crash""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: regression"")]"
113035,Training a network SUPER slow with Pytorch 2.1,2023-11-06 17:32:43+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
113034,make_fx produces incorrect graph when used under FunctionalTensorMode,2023-11-06 17:28:59+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""oncall: fx"")]"
113030,"Mismatching behaviour of tensor assignment ""a.data = b"" between torch.compile and eager execution",2023-11-06 16:40:39+00:00,,0,5,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
113024,Upsample bilinear 2d decomposition does not match native implementation for uint8,2023-11-06 13:49:39+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: decompositions"")]"
113022,Operator with only `Tensor[][]` args unsupported by dispatcher,2023-11-06 11:56:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
113020,Output mismatch of torch.to with torch.compile when swapping the input parameters of torch.mul on CPU,2023-11-06 10:00:35+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: cpu inductor"")]"
113017,Output mismatch of torch.max with torch.compile when swapping output sequence on CPU,2023-11-06 09:38:14+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: cpu inductor"")]"
113015,Output mismatch of torch.sum with torch.compile when swapping output sequence on CPU,2023-11-06 09:23:05+00:00,,0,11,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: cpu inductor"")]"
113007,`make_fx` failing for `_scaled_dot_product_flash_attention` decomposition,2023-11-06 05:22:43+00:00,,1,8,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: decompositions"")]"
113002,AOTInductor data dependents error when using max().item(),2023-11-06 02:51:05+00:00,,0,3,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""oncall: export"")]"
113001,the format of exported json from profiler is wrong!,2023-11-06 02:25:41+00:00,,1,1,"[Label(name=""oncall: profiler"")]"
112997,Add support for Flash Attention for AMD/ROCm,2023-11-05 21:07:53+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""ciflow/rocm"")]"
112956,Optim.step() is significantly SLOW on MPS,2023-11-04 15:52:50+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: mps"")]"
112955," Error loading ""AppData\\Local\\Temp\\_MEI136882\\torch\\lib\\cufft64_10.dll"" or one of its dependencies.",2023-11-04 15:34:49+00:00,,0,2,"[Label(name=""module: windows""), Label(name=""triaged""), Label(name=""module: third_party"")]"
112944,Getting an Error when loading a checkpoint :  AttributeError: Can't get attribute 'base_args_dict' on <module '__main__'>,2023-11-04 06:36:42+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: windows""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
112942,Can't build PyTorch 2.1 from source by GCC 13.2 on M1 MacOS,2023-11-04 03:47:16+00:00,,0,2,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: macos"")]"
112919,Export + assume_constant_result does not work for top-level annotated function,2023-11-03 22:01:44+00:00,,0,1,"[Label(name=""triage review""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
112903,Support for Bazel workspace function or Bazel module,2023-11-03 21:01:24+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: bazel"")]"
112901,Tracking: Dynamo Tracing Improvements,2023-11-03 20:36:56+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112887,DISABLED test_do_not_skip_side_effects (__main__.SkipNonTensorTests),2023-11-03 18:39:59+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
112883,Torchbench inference failures,2023-11-03 17:59:25+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112881,Torchbench Training Failing Models Tracker,2023-11-03 17:58:39+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112876,How to handle CVE vulnerabilities in underlying operating system?,2023-11-03 17:32:14+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: docker""), Label(name=""security"")]"
112872,libtorch exports miniz symbols,2023-11-03 16:53:26+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: cpp""), Label(name=""triaged"")]"
112865,[dynamo] Unable to continue tracing graph after try/except graph break,2023-11-03 16:28:36+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112857,Vendored FindCUDAToolkit.cmake deviates from upstream in splayed installation support,2023-11-03 15:31:48+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
112853,Vmap: There is a performance drop because we have not yet implemented the batching rule for aten::max_pool3d.,2023-11-03 15:07:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
112849,CSR matrix on MPS,2023-11-03 13:41:15+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: mps"")]"
112848,[dynamo] nit - add `@torch.autocast` function decoration to the testing path,2023-11-03 13:37:36+00:00,,0,2,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112847,High dimensional grid sample,2023-11-03 13:05:23+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
112844,torch.export does not support torchaudio.transforms.Spectrogram,2023-11-03 11:06:39+00:00,,0,7,"[Label(name=""module: onnx""), Label(name=""module: dynamo""), Label(name=""oncall: export""), Label(name=""module: export"")]"
112834,[MPS]Apple MPS produce different Loss value vs. NVIDIA CUDA after couple of digits,2023-11-03 08:04:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
112833,Failed to remove output annotation in Quantizer for PT2 QAT quantization,2023-11-03 07:47:58+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
112831,dynamo_export successfully export model but fails at onnx.checker.check_model,2023-11-03 07:31:45+00:00,,0,15,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
112827,Multi Scale Deformable Attention Support,2023-11-03 05:53:07+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: multi-headed-attention"")]"
112826,sparse allreduce not support  CSR format,2023-11-03 04:39:56+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: sparse"")]"
112824,[dynamo] Skipping the entire frame when graph breaking in for/while loop is excessive,2023-11-03 04:27:51+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112815,DISABLED test_trace_while_active (__main__.NCCLTraceTest),2023-11-03 00:57:51+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
112814,DISABLED test_get_parent_mesh_dim_not_exist (__main__.TestDeviceMeshGetItem),2023-11-03 00:56:56+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
112794,[dynamo] Implement enumerate fallback as polyfill,2023-11-02 22:05:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112791,DISABLED test_cuda_event_method_dynamic_shapes (__main__.DynamicShapesCtxManagerTests),2023-11-02 21:39:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
112789,[export] Make serialized pytree type name required ,2023-11-02 21:18:43+00:00,,1,0,"[Label(name=""triaged""), Label(name=""export-triaged""), Label(name=""oncall: export"")]"
112788,async_compile.triton is unable to cache generated triton kernels due to meta containing kernel names,2023-11-02 21:18:13+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
112775,Multi-Threaded GraphModule / torch.fx inference raises an exception,2023-11-02 19:35:40+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: fx"")]"
112771,PT2: don't always require inputs to be aligned,2023-11-02 19:25:46+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112749,Tracing mode for unbacked SymInts using real data,2023-11-02 15:56:36+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
112745,torch._dynamo.export raises Unexpected type in sourceless builder <class 'nemo.core.neural_types.elements.VoidType'> for torchaudio model,2023-11-02 15:24:15+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: dynamo"")]"
112744,"When torch.compile is used, some APIs are decomposed even if decomposition is empty.",2023-11-02 15:24:00+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112731,"[dynamo + optim] complex, sparse are not on tracing testing path",2023-11-02 14:13:51+00:00,,1,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112727,[dynamo] Implement iter fallback (and possibly all iters/generators) as polyfill,2023-11-02 13:34:59+00:00,,1,6,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112719,DISABLED test_meta_outplace_nn_functional_margin_ranking_loss_cpu_uint8 (__main__.TestMetaCPU),2023-11-02 12:45:37+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112718,'aten::unique_consecutive' to ONNX opset version 14 is not supported,2023-11-02 12:31:39+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
112716,Quantized model's size gets doubled on optimizing and saving it for mobile,2023-11-02 10:53:52+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""triaged""), Label(name=""oncall: mobile"")]"
112715,Wrong with code_coverage/readme.md,2023-11-02 10:50:37+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
112714,log_softmax() on CPU and GPU has expected numerical error when used with low-precision bfloat16,2023-11-02 09:43:06+00:00,,0,2,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""module: cpu""), Label(name=""triaged"")]"
112713,Discrepancy in Behavior of torch.diag_embed Between Eager Execution and 'torch.compiled' Optimized Mode,2023-11-02 09:39:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: decompositions"")]"
112702,DISABLED test_meta_outplace_std_mean_cpu_float64 (__main__.TestMetaCPU),2023-11-02 06:39:37+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112694,DISABLED test_cuda_stream_context_manager1_dynamic_shapes (__main__.DynamicShapesCtxManagerTests),2023-11-02 03:40:38+00:00,,0,20,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
112691,when huawei NPU,2023-11-02 03:02:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: backend"")]"
113369,When will Huawei Shengteng atlas be supported,2023-11-02 02:56:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: backend"")]"
112681,DISABLED test_meta_outplace_std_mean_cpu_float32 (__main__.TestMetaCPU),2023-11-02 00:57:40+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112678,Catalogue of flaky tests under `test/dynamo`,2023-11-02 00:10:56+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112670,[dynamo] direct invocation of bound method introduces graph break,2023-11-01 22:52:46+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: graph breaks"")]"
112666,dispatcher cannot determine dispatch key on tuple input,2023-11-01 22:05:26+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
112658,FSDP requires global device context,2023-11-01 21:11:34+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
112646,"Fix docstring errors in stream.py, pipe.py, blockpartition.py, microbatch.py, namespace.py, profile.py, tracker.py, portal.py, layout.py, __init__.py",2023-11-01 19:43:13+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112644,"Fix docstring errors in default_hooks.py, post_localSGD_hook.py, debugging_hooks.py, utils.py, hierarchical_model_averager.py, optimizer_overlap_hooks.py, mixed_precision_hooks.py, quantization_hooks.py, ddp_zero_hook.py, __init__.py, powerSGD_hook.py, averagers.py",2023-11-01 19:43:10+00:00,,1,6,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112641,"Fix docstring errors in post_localSGD_optimizer.py, functional_sgd.py, _functional_collectives.py, optimizer.py, utils.py, api.py, server_process_global_profiler.py, functions.py, backend_registry.py, __init__.py, options.py, internal.py, functional_adam.py",2023-11-01 19:43:05+00:00,,1,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112638,"Fix docstring errors in spectral_ops_fuzz_test.py, simple_timeit.py, timer_interface.py, op_benchmark.py, _stubs.py, fuzzer.py, compare.py, compile.py, interp.py, hipify_python.py, common.py, end_to_end.py, timer.py, __init__.py, sparse_fuzzer.py, blas_compare_setup.py",2023-11-01 19:43:00+00:00,,1,5,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112622,[ONNX] Assertion in models is not supported by fx exporter ,2023-11-01 18:53:44+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
112615,DISABLED test_resnet18_cpu (__main__.BenchmarkFusionCpuTest),2023-11-01 17:42:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""skipped""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
112608,`grad_fn` is not defined in `__torch_dispatch__` arguments when lazy device is used,2023-11-01 16:48:41+00:00,,0,8,"[Label(name=""triaged""), Label(name=""lazy"")]"
112602,"Fix docstring errors in batchnorm.py, activation.py",2023-11-01 15:29:41+00:00,,1,7,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112600,Fix docstring errors in loss.py,2023-11-01 15:29:38+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112593,"Fix docstring errors in nadam.py, radam.py, sgd.py, anomaly_mode.py, rprop.py, __init__.py, swa_utils.py, rmsprop.py, optimizer.py, lr_scheduler.py",2023-11-01 15:29:26+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112588,"Fix docstring errors in _torch_docs.py, serialization.py, overrides.py, _utils.py",2023-11-01 15:29:18+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112587,"Fix docstring errors in __init__.py, _tensor_docs.py, _meta_registrations.py, _tensor.py",2023-11-01 15:29:17+00:00,,1,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112586,"Fix docstring errors in _guards.py, _ops.py, _jit_internal.py, functional.py, _tensor_str.py, library.py",2023-11-01 15:29:15+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""topic: not user facing""), Label(name=""docathon-h2-2023"")]"
112585,"Fix docstring errors in _VF.py, _appdirs.py, hub.py, _classes.py, _storage_docs.py, _linalg_utils.py, torch_version.py, quasirandom.py, random.py, __future__.py, _lowrank.py, _vmap_internals.py, _sources.py, __config__.py, _lobpcg.py, _namedtensor_internals.py",2023-11-01 15:29:14+00:00,,1,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""medium""), Label(name=""docathon-h2-2023"")]"
112583,Nesting no_grad in autocast causes backwards graph to be (partially) lost outside of no_grad,2023-11-01 15:12:57+00:00,,0,9,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: amp (automated mixed precision)"")]"
112580,USE_SYSTEM_ONNX: undefined references,2023-11-01 14:20:36+00:00,,0,10,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
112579,Bugs in `torch.ao.quantization.fuse_modules`  cause operator fusion failure (`Conv2d` and `BatchNorm2d`),2023-11-01 11:48:32+00:00,,1,7,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
112577,[Breaking change 2.1] Passing non-contiguous inputs to SDPA on CUDA device with the mem-efficient attention backend returns garbage,2023-11-01 11:00:42+00:00,,1,9,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: correctness (silent)""), Label(name=""module: multi-headed-attention"")]"
112575,"RuntimeError: ""grid_sampler_2d_cuda"" not implemented for 'BFloat16'",2023-11-01 09:51:57+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: bfloat16"")]"
112574,DISABLED test_meta_outplace_std_mean_cpu_float16 (__main__.TestMetaCPU),2023-11-01 09:44:21+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112569,"RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at ""/opt/conda/conda-bld/pytorch_1695392035891/work/c10/cuda/CUDACachingAllocator.cpp"":1154, please report a bug to PyTorch",2023-11-01 06:51:05+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
112567,DISABLED test_numpy_non_writeable_cpu (__main__.TestNumPyInteropCPU),2023-11-01 06:40:02+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: numpy""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
112566,[inductor][cpu] detectron2 fasterrcnn accuracy failure,2023-11-01 06:02:59+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
112558,DISABLED test_meta_outplace_pinverse_cpu_complex64 (__main__.TestMetaCPU),2023-11-01 03:39:32+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112556,"when convert to onnx ,the jit will merge th outputs, it results to we can't distinguish  what the outputs represents",2023-11-01 03:25:33+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
112552,Inductor cpp wrapper: clean up the hard-coded schema for fusion OPs,2023-11-01 02:21:49+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112548,Show warning when compiling the optimizer and grads are going to be copied to cudagraph-owned memory,2023-11-01 01:25:26+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
112532,[Tracking] Follow ups for itertools infinite iterators,2023-10-31 21:11:07+00:00,,0,5,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112515,[Bug Report]FSDP: An error raises when loading FSDP distributed checkpoint with ignoring modules.,2023-10-31 17:00:49+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
112512,Constant output from exported ONNX,2023-10-31 16:32:01+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
112509,Add a function to torch.nested to create nested tensors from a buffer and sizes,2023-10-31 16:15:59+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
112495,Compilation Failure of torch.special.exp2 in torch.compile Optimized Mode,2023-10-31 12:22:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: cuda graphs""), Label(name=""oncall: pt2"")]"
112492,Compilation Failure of torch.cumsum in torch.compile Optimized Mode,2023-10-31 11:21:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: cuda graphs""), Label(name=""oncall: pt2""), Label(name=""module: decompositions"")]"
112491,[ONNX] Result from export_onnx in pytorch returns different result from pytorch,2023-10-31 11:16:34+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
112487,[ONNX] Exporting the operator 'aten::sparse_coo_tensor' to ONNX opset version 17 is not supported,2023-10-31 08:09:31+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
112479,DISABLED test_meta_outplace_pinverse_cpu_complex128 (__main__.TestMetaCPU),2023-10-31 06:39:49+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112463,DISABLED test_meta_outplace_nn_functional_margin_ranking_loss_cpu_int16 (__main__.TestMetaCPU),2023-10-31 00:56:57+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112462,DISABLED test_cuda_event_method (__main__.CtxManagerTests),2023-10-31 00:56:55+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
112459,GRUCell batching rule for vmap,2023-10-31 00:43:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
112443,torch.export emits node outside of Core ATen IR,2023-10-30 21:21:38+00:00,,1,4,"[Label(name=""triaged""), Label(name=""export-triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
112425,torch.jit.trace output changes when I add comments to the file,2023-10-30 18:44:12+00:00,,0,0,"[Label(name=""oncall: jit"")]"
112424,[torch.compile] Unit test failures after we always trace all module.forward method,2023-10-30 18:40:02+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
112422,DISABLED test_meta_outplace_nn_functional_margin_ranking_loss_cpu_float32 (__main__.TestMetaCPU),2023-10-30 18:39:21+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112402,[torch.jit.script] Expected a value of type 'Tensor' for argument 'b' but instead found type 'bool'.,2023-10-30 16:29:51+00:00,,0,2,"[Label(name=""oncall: jit"")]"
112398,[Tracker] Move nested tensors to beta,2023-10-30 15:45:07+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
112395,"KeyError during model export while using ""newer"" data types",2023-10-30 13:51:06+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
112389,KINETO_USE_DAEMON not work,2023-10-30 13:08:41+00:00,,0,1,"[Label(name=""oncall: profiler"")]"
112386,DISABLED test_meta_outplace_nn_functional_hinge_embedding_loss_cpu_float32 (__main__.TestMetaCPU),2023-10-30 12:45:57+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112383,Possible use-after-free of Tensor in JIT generated code,2023-10-30 11:33:03+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
112380,Need support CPU flash attention with mask,2023-10-30 09:40:13+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
112377,"RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at ""/opt/conda/conda-bld/pytorch_1695392020201/work/c10/cuda/CUDACachingAllocator.cpp"":1154, please report a bug to PyTorch.",2023-10-30 08:47:11+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
112376,Contradictory Error Message for stride Argument in torch.conv_transpose3d(),2023-10-30 08:43:46+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""module: convolution""), Label(name=""triaged"")]"
112372,[Tracer] RuntimeError: _Map_base::at when tracing using autograd.Function,2023-10-30 07:00:30+00:00,,0,0,"[Label(name=""oncall: jit"")]"
112371,Why is flake8 F821 disabled,2023-10-30 06:59:07+00:00,,1,3,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""better-engineering"")]"
112369,"In the func Tensor.to, how can I make privateuse lazy init",2023-10-30 06:39:18+00:00,,0,3,"[Label(name=""module: internals""), Label(name=""triaged"")]"
112354,DISABLED test_torch_name_rule_map (__main__.TraceRuleTests),2023-10-30 00:57:43+00:00,,0,47,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
112353,DISABLED test_meta_outplace_nn_functional_alpha_dropout_cpu_float16 (__main__.TestMetaCPU),2023-10-30 00:56:53+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112352,RFC: [pytree] node registration namespaces,2023-10-29 21:53:22+00:00,,0,6,"[Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: pytree"")]"
112347,"[dynamo] `.view([..., -1, ...])` fails on Tensors with unbacked SymInts in the shape",2023-10-29 17:45:28+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
112344,[test/dynamo] BE: cleanup `test_misc.py`,2023-10-29 14:43:59+00:00,,0,2,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112342,[pytree] Pytree node registration hygeine: deprecate global _register_pytree_node; only allow enabling registered pytree extensions locally,2023-10-29 14:06:09+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: pytree"")]"
112340,Unexpected behaviour with shared modules in multiprocessing on WSL2,2023-10-29 12:42:20+00:00,,0,3,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: wsl"")]"
112339,Requesting to add a section to the Installing C++ Distributions of PyTorch documentation for Apple M1/M2 Processors,2023-10-29 11:22:10+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
112338,`set` of enums produces a graph break (no repro),2023-10-29 11:11:52+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: graph breaks"")]"
112330,Library is included twice QNNPACK,2023-10-28 23:56:20+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""actionable"")]"
112318,IBM AfroHacks at AfroTech Participation,2023-10-28 13:02:11+00:00,,0,4,"[Label(name=""triaged"")]"
112303,"[dynamo]RFC/Feature request - cache, guard, and reuse InliningInstructionTranslator inline_call",2023-10-27 23:24:58+00:00,,0,10,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112285,PyTorch is shipped with different versions on NCCL,2023-10-27 20:15:02+00:00,,0,2,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""module: nccl"")]"
112277,test_DistributedDataParallel fails with static_graph=True,2023-10-27 18:54:46+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
112273,DISABLED test_meta_outplace_nn_functional_alpha_dropout_cpu_bfloat16 (__main__.TestMetaCPU),2023-10-27 18:39:28+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112264,Can't access attribute of wrapper tensor subclass under torch.compile,2023-10-27 17:36:38+00:00,,0,3,"[Label(name=""triaged""), Label(name=""tensor subclass""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
112260,[dynamo] we do not instantiate guards for ambient autocast mode,2023-10-27 16:49:08+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: guards"")]"
112256,[ONNX] In-place additon not being functionalized by torch.onnx.dynamo_export,2023-10-27 16:21:01+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""release notes: onnx"")]"
112251,Optest is unable to xfail on parametrized tests,2023-10-27 13:57:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: opcheck"")]"
112247,DISABLED test_meta_outplace_masked_var_cpu_complex64 (__main__.TestMetaCPU),2023-10-27 12:44:46+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112236,DISABLED test_meta_outplace_linalg_pinv_cpu_complex128 (__main__.TestMetaCPU),2023-10-27 06:39:46+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112220,DISABLED test_meta_outplace_linalg_lu_solve_cpu_complex64 (__main__.TestMetaCPU),2023-10-27 00:58:41+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
112218,[ONNX] Expose the graph module in torch.onnx ExportOutput,2023-10-27 00:42:15+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
112186,"Using the ""mps"" device on x86 Mac with AMD gpu, torch.argmax returns incorrect results.",2023-10-26 19:20:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
112182,DISABLED test_meta_outplace_fft_ihfftn_cpu_uint8 (__main__.TestMetaCPU),2023-10-26 18:39:23+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112180,Validations for 2.1.1 release,2023-10-26 18:37:30+00:00,,2,6,"[Label(name=""triaged"")]"
112176,~ Docathon H2 2023 ~,2023-10-26 17:35:23+00:00,,1,5,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""docathon-h2-2023"")]"
112171,Implement clip grad value on FSDP,2023-10-26 16:56:19+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
112164,[Tracking] torch.compile + torch.distributed + set_grad_enabled/autocast,2023-10-26 16:06:42+00:00,,1,1,"[Label(name=""oncall: distributed"")]"
112152,DDP backpropagated gradients not the same across all gpus when forward inference not using all declared modules,2023-10-26 14:13:20+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
112148,Export List/Tuple type inputs with dynamic size,2023-10-26 10:42:13+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
112142,DISABLED test_out_warning__refs_clamp_cpu (__main__.TestCommonCPU),2023-10-26 09:39:31+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown""), Label(name=""oncall: pt2"")]"
112139,[inductor][cpu] performance regression,2023-10-26 08:32:16+00:00,,1,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
112137,FSDP load sharded state dict + multi-backend init + bf16 + gloo (?) crashes,2023-10-26 07:24:26+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
112136,pyTorch 2.1 3x slower than 2.0,2023-10-26 07:16:55+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: windows""), Label(name=""module: cuda""), Label(name=""triaged"")]"
112133,DISABLED test_meta_outplace_fft_ihfftn_cpu_int64 (__main__.TestMetaCPU),2023-10-26 06:39:41+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112117,DISABLED test_cuda_stream_context_manager1 (__main__.CtxManagerTests),2023-10-26 03:39:37+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
112104,DISABLED test_meta_outplace_fft_ihfftn_cpu_int32 (__main__.TestMetaCPU),2023-10-26 00:56:32+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112095,torch.export fails on a model with optional parameter,2023-10-25 23:17:57+00:00,,0,3,"[Label(name=""triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
112090,Memory leak in torch.compile after aborting backward,2023-10-25 22:37:36+00:00,,1,7,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112089,"Failed to compile: null in call to `__builtin_memmove(__result, __first, sizeof(_Tp) * _Num);` Debian 12, ppc64le, gcc 12.2",2023-10-25 22:37:26+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
112079,The error type `UserError` in dynamo is confusing.,2023-10-25 20:47:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
112054,torch.distributed.distributed_c10d._get_default_group() is not Dynamo traceable,2023-10-25 20:02:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112044,pack_padded_sequence/pad_packed_sequence support in dynamo,2023-10-25 17:43:00+00:00,,0,7,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: fx""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
112043,"AssertionError: graph-captured input #1, of type <class 'torch.Tensor'>, is not among original inputs of types…",2023-10-25 17:42:58+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
112029,DDPWrapper,2023-10-25 16:07:54+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
112028,"dynamo rewrite for allreduce, default group",2023-10-25 16:07:08+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""module: dynamo"")]"
112024,torch.inference_mode and tensor subclass: RuntimeError: Cannot set version_counter for inference tensor,2023-10-25 15:12:20+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""tensor subclass"")]"
112015,op scaled_dot_product_attention case different results,2023-10-25 10:23:04+00:00,,0,3,"[Label(name=""oncall: transformer/mha"")]"
112013,RuntimeError for hessian vector product with jvp,2023-10-25 09:06:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
112009,_functional_collectives.all_gather_into_tensor cannot compile in aot_module_simplified,2023-10-25 08:00:10+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
112006,Strided tensor in backward cause uninitialized output,2023-10-25 06:43:04+00:00,,1,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
112004,DISABLED test_meta_outplace_fft_ihfftn_cpu_bool (__main__.TestMetaCPU),2023-10-25 06:39:31+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112003,DISABLED test_meta_outplace_fft_ihfft_cpu_uint8 (__main__.TestMetaCPU),2023-10-25 06:39:29+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
112002,[v2.1.0 torch.compile] ,2023-10-25 06:30:48+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
111987,DISABLED test_meta_outplace_fft_ihfft_cpu_int8 (__main__.TestMetaCPU),2023-10-25 00:56:57+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111986,DISABLED test_meta_outplace_fft_ifft_cpu_int16 (__main__.TestMetaCPU),2023-10-25 00:56:57+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111968,DISABLED test_meta_outplace_fft_ihfft_cpu_int32 (__main__.TestMetaCPU),2023-10-24 21:39:55+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111967,DISABLED test_meta_outplace_addmm_cpu_complex64 (__main__.TestMetaCPU),2023-10-24 21:39:28+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111966,[PT2] Graph break in forward pre-hook skips compiling forward for `nn.Transformer`,2023-10-24 21:39:06+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111962,[pytree] `pytree.tree_map` does not respect type of `torch.Size`,2023-10-24 20:45:31+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: pytree""), Label(name=""bug"")]"
111958,torch 2.1 FSDP only some layers might not be working with training only a couple of layers,2023-10-24 20:13:41+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
111953,Missing a vectorized version of TORCH_CHECK,2023-10-24 19:35:51+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
111952,Inductor with cpu lowering fails to raise exception on invalid getitem,2023-10-24 19:18:36+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
111950,Operators that return dynamic-shape outputs that require_grad choke in AOTAutograd,2023-10-24 18:48:07+00:00,,0,9,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
111943,Implement scatter and broadcast in functional collectives,2023-10-24 17:58:02+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
111931,[opcheck] Faster gradcheck execution,2023-10-24 15:45:30+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: opcheck"")]"
111930,[opcheck] Way to reduce Hypothesis sampling when running opcheck,2023-10-24 15:43:16+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: opcheck"")]"
111928,DISABLED test_meta_inplace_addmm_cpu_complex64 (__main__.TestMetaCPU),2023-10-24 15:39:43+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111925,Resize warning in two argument torch.logical_* with broadcasting,2023-10-24 15:37:51+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: boolean tensor""), Label(name=""module: safe resize"")]"
111924,[opcheck] Cannot share failures_dict between multiple tests with differing sets of tests they run ,2023-10-24 15:37:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: opcheck"")]"
111918,Graph break doesn't result in continuation function when break happens in if-statement expression without inline function call,2023-10-24 14:47:52+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""release notes: dynamo"")]"
111909,DISABLED test_meta_outplace_fft_ihfft_cpu_float64 (__main__.TestMetaCPU),2023-10-24 12:46:00+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
111908,Inconsistent Keyword Arguments behaviors in torch.triangular_solve(),2023-10-24 11:42:42+00:00,,0,2,"[Label(name=""triaged""), Label(name=""topic: deprecation""), Label(name=""topic: docs""), Label(name=""module: python frontend"")]"
111907,Migration from c10::variant to std::variant causes undefined symbols when linking against older pytorch,2023-10-24 11:01:25+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged"")]"
111905,Cannot build static windows libraries ,2023-10-24 10:10:25+00:00,,0,6,"[Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged""), Label(name=""module: static linking""), Label(name=""topic: binaries"")]"
111903,DISABLED test_meta_inplace_addmm_cpu_complex128 (__main__.TestMetaCPU),2023-10-24 09:39:42+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111902,torchscript file can not be loaded if its saved form the export model produced by torch.export.export,2023-10-24 09:00:32+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
111901,Multiprocess. DataLoader worker  is killed by signal: Segmentation fault.,2023-10-24 08:11:27+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
111900,"OOM when saving model(lora adapter), seems the clause ""FullyShardedDataParallel(model,...)"" will directly cause the OOM.",2023-10-24 07:47:04+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
111897,DISABLED test_meta_outplace_fft_ihfft2_cpu_int8 (__main__.TestMetaCPU),2023-10-24 06:39:45+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111896,ImportError: cannot import name 'external_utils' from partially initialized module 'torch._dynamo',2023-10-24 06:28:07+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: docker""), Label(name=""topic: binaries"")]"
111890,DISABLED test_cuda_stream_context_manager2 (__main__.CtxManagerTests),2023-10-24 03:41:35+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
111884,Custom FFT implementation returns unexpected results when using torch.compile,2023-10-24 01:35:25+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: correctness (silent)""), Label(name=""oncall: pt2"")]"
111874,Coalescing manager does not work w/device from torch.cuda.current_device(),2023-10-24 00:37:27+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
111863,Jit scripting support for `|` and mixing `typing`.,2023-10-23 23:47:20+00:00,,0,0,"[Label(name=""oncall: jit"")]"
111850,DISABLED test_cond_side_effects (__main__.MiscTests),2023-10-23 21:39:55+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
111849,DISABLED test_meta_outplace_fft_ihfft2_cpu_int64 (__main__.TestMetaCPU),2023-10-23 21:39:52+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111848,DISABLED test_cuda_stream_context_manager2_dynamic_shapes (__main__.DynamicShapesCtxManagerTests),2023-10-23 21:39:49+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
111837,[dynamo] UnspecializedNNModuleVariable does not implement object identity,2023-10-23 20:01:35+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111834,"Numerical inaccuracies in ""ddp_apply_optim_in_backward"" unit tests for gloo backend",2023-10-23 19:34:58+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
111830,[aotinductor]14k models: AttributeError: 'int' object has no attribute 'device',2023-10-23 19:11:28+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111825,DISABLED test_meta_outplace_fft_ihfft2_cpu_int16 (__main__.TestMetaCPU),2023-10-23 18:42:45+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
111824,GroupNorm & InstanceNorm does not handle channels_last correctly,2023-10-23 18:22:50+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""actionable"")]"
111819,__slots__ + inheriting from torch.Tensor,2023-10-23 18:05:17+00:00,,0,1,"[Label(name=""triaged""), Label(name=""tensor subclass""), Label(name=""module: python frontend"")]"
111818,[aotinductor] 14k models: Function input to foward(),2023-10-23 17:59:47+00:00,,1,5,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111813,[aot_inductor]14k models: RuntimeError: t == DeviceType::CUDA INTERNAL,2023-10-23 17:52:00+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111806,Revisit security implications of #31875,2023-10-23 16:35:27+00:00,,0,4,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""topic: security""), Label(name=""security"")]"
111804,Dynamo - more closely tracker class type in UserDefinedObjectVariable,2023-10-23 15:36:43+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111799,DISABLED test_meta_outplace_fft_ihfft2_cpu_float64 (__main__.TestMetaCPU),2023-10-23 12:46:09+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
111792,torch.jit.trace is not able to trace torch extension,2023-10-23 09:44:12+00:00,,0,2,"[Label(name=""oncall: jit"")]"
111789,Precisely monitor the collective communication tasks,2023-10-23 09:25:44+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: profiler"")]"
111786,pytorch support for cuda 12.2 ?,2023-10-23 06:55:02+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""needs design"")]"
111785,torch.compile precision bug when the attr object changes,2023-10-23 06:40:09+00:00,,1,6,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111784,DISABLED test_meta_outplace_fft_ihfft2_cpu_float32 (__main__.TestMetaCPU),2023-10-23 06:40:02+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111768,DISABLED test_meta_outplace_fft_ihfft2_cpu_bool (__main__.TestMetaCPU),2023-10-23 00:57:00+00:00,,1,7,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
111754,[dynamo] Better determinism of `ConfigModule` by walking using pytree,2023-10-22 01:43:09+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111753,[dynamo] AutogradFunctionMethodHigherOrderVariable check for new guards is broken,2023-10-22 01:28:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
111752,Is it a good time to switch to CXX11_ABI?,2023-10-22 01:23:38+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
111739,grad is inf/nan when using torch.amp,2023-10-21 08:04:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
111733,Bug: torch.compile fails to compile torch.func.vmap with reduction functions and raw python numbers,2023-10-21 05:56:06+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
111713,[dynamo] generic `is_` type shortcut is not appropriately guarded,2023-10-20 22:31:04+00:00,,1,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111709,lintrunner job time keeps growing,2023-10-20 22:09:40+00:00,,0,6,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: devx"")]"
111706,DISABLED test_meta_outplace_fft_ifft_cpu_uint8 (__main__.TestMetaCPU),2023-10-20 21:39:22+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111704,Add more flexibility on print / output console,2023-10-20 21:00:57+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement"")]"
111693,"[export] 14k models: AssertionError: graph-captured input # 2, of type <class 'torch.nn.parameter.Parameter'>, is not among original inputs of types",2023-10-20 19:37:57+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
111678,AOT Inductor Does not Work with minifier,2023-10-20 18:14:06+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
111676,[export] self.buffer += 1 raises error,2023-10-20 17:57:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
111674,Dynamo Compile samples should record file/line that raised exception,2023-10-20 17:54:50+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111669,Buffer overflow not prevented on MPS devices,2023-10-20 17:05:00+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""module: mps"")]"
111666,torch.onnx.errors.UnsupportedOperatorError: Exporting the operator 'aten::binary_cross_entropy' to ONNX opset version 14 is not supported.,2023-10-20 16:35:56+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
111663,[dynamo] Tracking: object identity,2023-10-20 16:11:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111654,"Static Linking C++, Op not available at runtime",2023-10-20 14:36:53+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: vision""), Label(name=""has workaround"")]"
111651,DISABLED test_meta_outplace_fft_ifft_cpu_int64 (__main__.TestMetaCPU),2023-10-20 12:45:30+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111646,torchrun: elastic training not restarted on missing keep-alive heartbeat/scale-down event,2023-10-20 10:33:28+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
111641,Can't export a pth model to onnx (RuntimeError: Couldn't lower all tuples),2023-10-20 09:16:15+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
111640,[RFC] Enable Int8-Mixed-BF16 PT2E PTQ Quantization with Inductor,2023-10-20 07:44:11+00:00,,1,17,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
111638,DISABLED test_meta_outplace_fft_ifft_cpu_float64 (__main__.TestMetaCPU),2023-10-20 06:39:44+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111636,torch2.1.0 DDP+compile+dynamic_shape cause error,2023-10-20 05:44:12+00:00,,0,7,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
111634,Batched matmul gives incorrect result on MPS devices,2023-10-20 05:21:17+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
111632,"[dynamo][profiler] console spew of ...""torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored"" for pages...",2023-10-20 04:51:51+00:00,,1,1,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111626,DISABLED test_meta_outplace_fft_hfft_cpu_uint8 (__main__.TestMetaCPU),2023-10-20 00:56:46+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111623,Missing `ignored_param` when calling wrapper_cls (FSDP) recursively,2023-10-20 00:17:23+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
111621,maximum Python version supported is not indicated,2023-10-19 23:46:22+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
111619,DISABLED test_cat_nhwc (__main__.TestQuantizedOps),2023-10-19 23:17:29+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""skipped"")]"
111583,DISABLED test_vmapjvpall_linalg_det_singular_cpu_float32 (__main__.TestOperatorsCPU),2023-10-19 17:21:09+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""skipped"")]"
111580,Dynamic shapes doesn't work for torch.diff / resize__symint in some cases,2023-10-19 16:52:33+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
111577,Prolonged network hiccup preventing retrieval of workflow job id,2023-10-19 16:33:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: devx"")]"
111570,Tensor `.cuda()` very slow with specific array sizes ,2023-10-19 15:24:58+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
111569,"[dynamo] so-called global state guard is installed on global, when in fact values are thread-local",2023-10-19 13:30:28+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111566,build: failure when building pytorch with TBB,2023-10-19 12:42:25+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: tbb"")]"
111564,misusing percision value in test_cuda function in torch/testing/_internal/common_nn.py.,2023-10-19 11:56:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: testing"")]"
111563,"Higher-order derivatives extremely slow, increasing exponentially",2023-10-19 11:46:56+00:00,,0,33,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs research"")]"
111562,[dynamo] `not aliased -> aliased` Guard only implemented for Tensors,2023-10-19 11:40:44+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111560,Building docs fails,2023-10-19 09:05:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: export"")]"
111559,[RFC] Add GradScaler on CPU,2023-10-19 09:03:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: half"")]"
111552,[Bug]: some parameters' grad is None when using FSDP with torch2.1.0,2023-10-19 07:02:00+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
111551,Custom `ModuleDict.__getitem__(key: tuple)` produces a graph break,2023-10-19 06:55:18+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111550,[dynamo] Implement full `is_` checking,2023-10-19 06:46:47+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111547,Bug with as_strided_tensorimpl for MPS devices,2023-10-19 06:20:02+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
111538,Propose to add constant padding mode to the `torch.nn.functional.grid_sample` function,2023-10-19 03:51:38+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""needs design"")]"
111525,Functorch FCD breaks with tensor subclasses,2023-10-19 01:19:27+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: functorch""), Label(name=""module: first class dims"")]"
111522,Insufficient hasattr guards on user defined objects,2023-10-18 23:55:44+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111519,"[pt2+profiler] attach aot_id to CompiledFunction, _compiled_fn number without aot_autograd",2023-10-18 22:56:00+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111517,MPS Performance regressions on Sonoma 14.0 ,2023-10-18 22:13:03+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: mps"")]"
111509,Sparse Tensor Sum Still Does Not Work for PyTorch Geometric,2023-10-18 21:16:16+00:00,,0,14,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
111508,LBFGS accuracy difference between CPU and GPU,2023-10-18 21:13:04+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
111495,[ONNX][dynamo] Parameter to export flat graphs,2023-10-18 19:02:21+00:00,,3,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
111482,"When keep_inference_input_mutations=True is set, one dynamic shape test fails",2023-10-18 16:40:43+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
111480,torch.jit.script persistently changes default from utf-8 to ascii,2023-10-18 16:11:12+00:00,,0,0,"[Label(name=""oncall: jit"")]"
111479,multi_head_attention_forward generates different values on MPS compared to CPU,2023-10-18 14:34:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
111473,"Rephrase sentence in ""Why and when to use sparsity"" for better understanding.",2023-10-18 12:21:27+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
111471,test_learnable_forward_per_channel fails due to integer overflow,2023-10-18 11:41:30+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
111466,yolov5_train,2023-10-18 09:00:11+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
111462,DISABLED test_meta_inplace_addmm_decomposed_cpu_complex128 (__main__.TestMetaCPU),2023-10-18 06:39:47+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch""), Label(name=""oncall: pt2"")]"
111456,torch.autocast() hangs on CPUs,2023-10-18 03:46:51+00:00,,1,10,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
111454,[ONNX][dynamo] Failed to export cumsum with dtype=float16,2023-10-18 02:47:20+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: half"")]"
111450,[FX Quant] operator.matmul (@ operator ) is not converted to torch.ops.quantized.matmul,2023-10-18 01:46:56+00:00,,1,4,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
111448,DISABLED test_compile_dtensor_redistribute_backward (__main__.TestDTensorCompileE2E),2023-10-18 01:22:14+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""skipped"")]"
111441,torch.compile of simple loop takes 34 seconds,2023-10-17 23:51:30+00:00,,1,8,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: startup-tracing-compile time""), Label(name=""module: higher order operators""), Label(name=""module: pt2-dispatcher"")]"
111424,Multi-node torchrun  training job does not use IB Network,2023-10-17 16:54:31+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
111423,torch.compile x autograd.Function: Make the backward strict mode less srict,2023-10-17 16:26:56+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
111419,nonnull error,2023-10-17 12:34:54+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
111417,AOTAutograd generates wrong strides for view+inplace op,2023-10-17 08:30:40+00:00,,0,3,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
111416,The results of masked.log_softmax on MPS are inconsistent with those on CPU,2023-10-17 04:45:58+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
111414,Minifier doesn't transfer execution states like @torch.no_grad to repro,2023-10-17 03:11:57+00:00,,2,6,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111410,"Use of -Wl,--as-needed in cmake config files can leak into third-party users' code and modify their own private libraries",2023-10-17 01:39:07+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""topic: build"")]"
111385,Torch Compile Dynamic fails on sample on diffusers VAE,2023-10-16 20:00:41+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
111384,[quant][pt2] Default batchnorm aten op has poor numerics during QAT,2023-10-16 19:51:20+00:00,,1,0,"[Label(name=""high priority""), Label(name=""oncall: quantization""), Label(name=""triaged"")]"
111374,Tensor.lerp inconsistent when using -Infinity between MPS and CPU,2023-10-16 15:28:51+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
111370,Tracker for torch._numpy errors under dynamo,2023-10-16 12:01:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: dynamo"")]"
111368,Implement device parameter in Dropout2d,2023-10-16 11:50:49+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
111366,RuntimeError: CUDAPluggableAllocator does not yet support cacheInfo,2023-10-16 11:01:17+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
111365,Failed to import transformer.,2023-10-16 10:59:59+00:00,,0,2,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""module: windows""), Label(name=""triaged"")]"
111363,Simulating lower memory on GPU does not indicate simulated memory in error message,2023-10-16 09:41:01+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
111359,I have a trouble with to_symmetric,2023-10-16 07:40:09+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: sparse""), Label(name=""triaged"")]"
111357,Couldn't export yolov7 quantized model to onnx,2023-10-16 07:37:15+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
111351,_foreach_copy_ supports fast copy between cpu and cuda devices.,2023-10-16 03:58:57+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: mta"")]"
111349,CUDA version 12.2 has differential accuracy when executing CPU and GPU,2023-10-16 02:47:22+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
111348,Custom Tensor Instances Do Not Work With DDP,2023-10-16 02:34:21+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
111331,[dynamo] Proposal: `@init_values_once` API for initializing tensors and constants - without tracing the function in Dynamo,2023-10-15 17:11:19+00:00,,0,9,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: dynamo"")]"
111320,test_max_pool1d reliably OOMs after https://github.com/pytorch/pytorch/pull/111216/,2023-10-15 02:58:38+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111317,Torch 2.1 compile + FSDP (mixed precision) + LlamaForCausalLM: `RuntimeError: attempting to assign a gradient with dtype 'c10::BFloat16' to a tensor with dtype 'float'.`,2023-10-15 02:20:28+00:00,,1,10,"[Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
111279,Cannot use compiled model together with the ddp strategy,2023-10-14 04:22:34+00:00,,0,5,"[Label(name=""oncall: distributed"")]"
111255,[AOTInductor] 14k models: AssertionError: Dynamo attempts to add additional input during export,2023-10-13 22:20:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111254,[AOTInductor] 14k models: AssertionError: Failed to produce a graph during tracing. Tracing through 'f' must produce a single graph.,2023-10-13 22:16:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111252,[AOTInductor] 14k models: UserError: Tried to use data-dependent value in the subsequent computation,2023-10-13 22:10:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111250,"[AOTInductor] 14k models: AssertionError: original output #2 is None, but only the following types are supported",2023-10-13 21:58:37+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111247,pytorch index_select is too slow,2023-10-13 21:53:59+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
111235,[dynamo] `ConfigModule`: Implement mechanism to hash non-`compile_ignored` configs quickly,2023-10-13 20:36:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111227,"nanogpt_generate: C++ compile times out, because the generated .cpp file is too large.",2023-10-13 19:31:33+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111224,[AOTInductor] 14K models: TypeError: make_boxed_func..g() missing 1 required positional argument: 'args',2023-10-13 19:17:44+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111223,[dynamo] Investigate interop issues with torch_scatter/torch_sparse/pyg_lib,2023-10-13 18:53:33+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
111220,[dynamo] Tracking: improve `ConfigModule`,2023-10-13 18:30:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111210,"RuntimeError: Expected is_sm80 || is_sm90 to be true, but got false. (Using Google Colab)",2023-10-13 16:42:11+00:00,,0,5,"[Label(name=""triaged"")]"
111209,[dynamo] annotate `allow_in_graph` with soft constraints,2023-10-13 15:18:15+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111206,`torch.utils.checkpoint` drops custom Tensor attributes,2023-10-13 14:05:58+00:00,,0,0,"[Label(name=""module: checkpoint""), Label(name=""triaged"")]"
111312,Trace dynamic batch size with make_fx,2023-10-13 10:00:30+00:00,,1,4,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: fx""), Label(name=""oncall: pt2""), Label(name=""oncall: fx""), Label(name=""module: functorch""), Label(name=""module: dynamic shapes""), Label(name=""module: pt2-dispatcher"")]"
111194,Guards elimination for unused variables,2023-10-13 09:06:07+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111190,[inductor][dynamic] fused_attention pattern could not be matched due to sym_size,2023-10-13 06:42:33+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor""), Label(name=""module: multi-headed-attention""), Label(name=""inductor_pattern_match"")]"
111187,"torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1331, unhandled cuda error (run with NCCL_DEBUG=INFO for details)",2023-10-13 05:23:31+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: wsl"")]"
111186,[ONNX][Exporter] Maintain support for exporter arguments export_params and keep_initializers_as_inputs,2023-10-13 04:59:16+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
111182,Training iresnet with torch.compile is slower than eager mode for torch 2.1.0,2023-10-13 03:24:50+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111173,unique(return_counts=True) fails on MPS for unsorted tensors with 1M+ elements,2023-10-13 00:30:15+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
111169,Result of adding noise is very different in mps vs cuda or cpu,2023-10-12 23:18:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
111168,Regression on CUDA 12.1 for vanilla transformer layer,2023-10-12 23:07:56+00:00,,0,10,"[Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
111159,Wrong onnx model from `torch.onnx.export` when using `index_add_` function with duplicate `index` values.,2023-10-12 20:41:19+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
111158,RuntimeError in run_streaming_llama.py When Using Accelerate with Streaming LLMa Model on A4500 GPU,2023-10-12 20:18:05+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: error checking""), Label(name=""triaged"")]"
111157,overloads can perhaps be more performant?,2023-10-12 19:55:46+00:00,,0,7,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: codegen"")]"
111150,[dynamo] `ConfigModule` and `config.patch` are not thread safe,2023-10-12 18:00:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111142,'torch._C.Node' object has no attribute 'cs',2023-10-12 16:30:09+00:00,,0,0,"[Label(name=""oncall: jit"")]"
111138,Module states cannot be fully synchronized due to the DDP broadcast_buffers breaking change,2023-10-12 14:55:22+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
111135,"No op for aten::where with argument types: Tensor, Tensor, bool.",2023-10-12 13:22:34+00:00,,0,0,"[Label(name=""oncall: jit"")]"
111133,Mismatch results of index_add_ between torch.compile Inductor backend and eager mode,2023-10-12 12:06:53+00:00,,1,7,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""module: functionalization""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
111131,"""Invalid Scalar type"" when using bf16 allreduce with Gloo backend",2023-10-12 10:52:36+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
111126,type promotion test for torch.div variants is broken,2023-10-12 08:42:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: testing"")]"
111121,torch::serialize::OutputArchive::save_to crash if save on C:\\,2023-10-12 06:16:31+00:00,,0,2,"[Label(name=""module: windows""), Label(name=""module: serialization""), Label(name=""triaged"")]"
111086,Build failure with Xcode 15 linker,2023-10-11 22:13:19+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
111085,"Getting ""master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified"" warning when using rdzv.",2023-10-11 22:08:40+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""oncall: r2p"")]"
111082,There is a performance drop because we have not yet implemented the batching rule for aten::mkldnn_rnn_layer_backward.,2023-10-11 20:35:15+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""module: functorch"")]"
111311,There is a performance drop because we have not yet implemented the batching rule for aten::mkldnn_rnn_layer_backward.,2023-10-11 20:33:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
111081,AOTAutograd perf: avoid as_strided() calls when we have intermediate bases,2023-10-11 20:23:00+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
111077,dump_operator_names.cc uses std::cout but dose not include iostream,2023-10-11 20:02:09+00:00,,0,1,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
111075,Export swallows exception,2023-10-11 19:20:14+00:00,,1,3,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""export-triaged""), Label(name=""oncall: export"")]"
111070,Option to disable fastpath in MHA,2023-10-11 18:59:14+00:00,,0,0,"[Label(name=""needs design""), Label(name=""oncall: transformer/mha"")]"
111050,DISABLED test__int_mm (__main__.TestSelectAlgorithm),2023-10-11 18:06:22+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
111047,[HigherOrderOp] cond  should accept pytree inputs,2023-10-11 17:32:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
111033,`CapabilityBasedPartitioner` returns invalid partitions.,2023-10-11 14:34:15+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: xla""), Label(name=""oncall: pt2"")]"
111029,"[JIT] Error when scripting wrapper of `matrix_norm` using `p: Union[str, int]` ",2023-10-11 13:13:54+00:00,,0,0,"[Label(name=""oncall: jit"")]"
111027,[PT2.1] SIGSEGV seen with view + sgn operator inside torch.compile,2023-10-11 10:09:20+00:00,,1,7,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""ZeroTensor""), Label(name=""oncall: pt2"")]"
111025,Unprompted UserWarning,2023-10-11 08:36:50+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
111024,ncu python conv2d.py runs indefinitely after activating cudnn.benchmark,2023-10-11 07:19:17+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
111020,[Dynamo] Error in speculate_subgraph doesn't report inner user stack trace,2023-10-11 03:59:58+00:00,,1,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
111019,[Dynamo] Support more argument types for autograd Function speculate: HigherOrderOperator with body that accepts non-Tensors as input,2023-10-11 03:57:54+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
111003,Dynamo inlining should compile partial subgraphs,2023-10-10 23:18:13+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
110980,DISABLED test_jvp_linalg_det_singular_cpu_float32 (__main__.TestOperatorsCPU),2023-10-10 20:19:17+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: regression""), Label(name=""skipped""), Label(name=""module: functorch"")]"
110971,`pip install deepspeed` fails if number of GPUs greater than a certain small number?,2023-10-10 18:57:38+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: third_party"")]"
110966,`torch.is_autocast_enabled()` always False on CPU,2023-10-10 18:35:06+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
110959,`model.named_buffers()` fails if module not hashable.,2023-10-10 17:37:02+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged"")]"
110957,kBackendDefaultTimeout is causing a timeout exception when rank 0 process exceeds 30 minutes preparing a dataset.,2023-10-10 17:07:15+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
110950,Enable more flake8-pyi ruff checks,2023-10-10 14:57:36+00:00,,0,2,"[Label(name=""good first issue""), Label(name=""module: lint""), Label(name=""triaged""), Label(name=""actionable"")]"
110946,RuntimeError: out_ptr == out_accessor[thread_count_nonzero[tid + 1]].data() INTERNAL ASSERT FAILED,2023-10-10 12:55:19+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
110944,gdb core dump when enable DEBUG mode to compile cpu torch in centos!!!,2023-10-10 12:18:29+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
110937,Issue with torch.distributed.launch,2023-10-10 09:37:58+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""oncall: r2p"")]"
110936,[inductor][cpu] [dynamic shapes][cppwrapper] performance regression,2023-10-10 09:01:27+00:00,,1,1,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
110921,The NCCL kernel did not start as expected,2023-10-10 04:03:18+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
110905,"RuntimeError: !needs_dynamic_casting<func_t>::check(iter) INTERNAL ASSERT FAILED at ""../aten/src/ATen/native/cpu/Loops.h"":349, ... please report a bug to PyTorch.",2023-10-09 22:52:38+00:00,,1,3,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
110904,[Inductor] `ConstantFolder` Utility Breaking in Recent Nightly,2023-10-09 22:44:38+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: inductor"")]"
110885,Depthwise conv3d slower than normal conv3d,2023-10-09 19:29:22+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
110883,MAX_JOBS ignored when compiling pytorch from source,2023-10-09 19:28:11+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
110871,[dynamo] Add asserts to prevent user defined objects/classes from going into ConstantVariable,2023-10-09 16:40:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
110866,Gradients (Jacobian) in inference,2023-10-09 14:58:33+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
110865,BCEWithLogitsLoss: Check if labels / targets are within zero and one,2023-10-09 14:48:49+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
110858,Broadcasting matmul is much slower than corresponding einsum,2023-10-09 10:03:41+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
110855,Matmul failure after dtype change on mixed AMD setup,2023-10-09 08:48:24+00:00,,0,4,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
110843,"AOTAutograd: set_ under no_grad still triggers ""a view of a leaf Variable that requires grad is being used in an in-place operation""",2023-10-09 03:54:39+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
110842,AOTAutograd: set_ on input that ultimately no-ops fails in runtime_wrapper copy_,2023-10-09 03:37:10+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
110841,[Inductor] [cpu][amp]  Eager model failed to run for some torchbench models,2023-10-09 02:48:39+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: cpu inductor"")]"
110819,Segmentation fault on aarch64 (Rpi4) using Pytorch 2.1.0 & torchaudio ,2023-10-08 15:04:07+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
110815,The derivation of swish activation function is wrong.,2023-10-08 07:54:03+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
110810,M2 Failing to build example-app in c++,2023-10-08 05:08:13+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: macos"")]"
110803,Toggling model.train() causes guard failures every time,2023-10-08 02:14:41+00:00,,0,7,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
110801,ONNX converter does not properly trace dynamic axis through graph,2023-10-07 22:47:30+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
110795,Build process failure with torch_shm_manager,2023-10-07 16:31:56+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
110786,.lldbinit formatters only work when building with clang,2023-10-07 05:54:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""release notes: devx""), Label(name=""topic: devs"")]"
110780,backward and grad behave inconsistently w.r.t. set_ on leaf variable,2023-10-07 03:30:06+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""has workaround"")]"
110779,"Repro for non-deterministic ""operation not permitted when stream is capturing"" crash",2023-10-07 01:27:45+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
110775,torch.distributed.pipeline skip module throws assert error that portal.grad is not None,2023-10-07 00:04:43+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
110761,Using ChainedScheduler with ReduceLROnPlateau leads to unexpected keyword argument error,2023-10-06 20:43:25+00:00,,0,7,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: LrScheduler"")]"
110758,"Fused Adamw RuntimeError: params, grads, exp_avgs, and exp_avg_sqs must have same dtype, device, and layout",2023-10-06 20:22:03+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
110738,Support using SymBool in arithmetics,2023-10-06 18:31:54+00:00,,1,7,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
110737,pytorch consuming all cpu cores 100% on ARM,2023-10-06 18:30:47+00:00,,0,6,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: openmp""), Label(name=""module: arm"")]"
110730,[dynamo]: `assert counter.frame_count == 1` is a bad practice when checking for no graph breaks,2023-10-06 18:05:42+00:00,,0,8,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
110702,sliding_window attention in scaled_dot_product,2023-10-06 13:18:48+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
110701,Error with monai SwinUNETR and checkpointing,2023-10-06 12:32:03+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
110700,More informative variable names in AOTAutograd,2023-10-06 12:19:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
110698,max_pool3d_with_indices_backward_cuda and avg_pool3d_backward_cuda does not have a deterministic implementation,2023-10-06 11:30:11+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: determinism"")]"
110693,"onnx export jit.script ShapeInferenceError Unexpected axis value: 1. Expected range [-1, 1)",2023-10-06 10:16:40+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
110681,[RFC] Scaled Dot Product Attention  API Changes,2023-10-06 02:38:07+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: python frontend""), Label(name=""module: multi-headed-attention"")]"
110669,Backward pass for Nested Tensors using flash attention in sdpa fails,2023-10-06 00:32:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""oncall: transformer/mha""), Label(name=""module: multi-headed-attention"")]"
110649,opinfo split is confusing,2023-10-05 21:10:15+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: testing"")]"
110641,`pytest test/dynamo -v ` fails locally,2023-10-05 20:45:23+00:00,,1,6,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
110636,[discussion] Have PyTorch functions support python scalars (like NumPy) + introduce convenience constants like `torch.pi` and `torch.e` and maybe analogue of `scipy.constants` namespace,2023-10-05 18:58:21+00:00,,0,14,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: python frontend"")]"
110630,Memory efficient attention for tensors where the last dimension is not divisible by 8,2023-10-05 18:23:58+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: multi-headed-attention"")]"
110611,torch.compile CPU backend is slower than eager for several transcendental functions,2023-10-05 16:13:33+00:00,,2,3,"[Label(name=""triaged""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
110610,DISABLED test_type_promotion__foreach_sub (__main__.ForeachTests),2023-10-05 15:39:56+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
110605,ValueError issued instead of TypeError when tensor is cast to a scalar,2023-10-05 14:41:21+00:00,,1,4,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: numpy"")]"
110602,AOTAutograd logging: log autograd graphs,2023-10-05 14:29:22+00:00,,1,3,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
110599,[torch.compile] Multiple set operations don't work,2023-10-05 13:54:42+00:00,,1,4,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""release notes: dynamo"")]"
110595,Incorrect docstring / documentation for torch.nn.functional.scaled_dot_product_attention in 2.1,2023-10-05 12:03:26+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
110594,Multiprocessing takes forever after on .get()  with mp.Queue() (Possible Deadlock),2023-10-05 09:43:28+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
110588,libtorch.so: error adding symbols: file in wrong format,2023-10-05 06:54:49+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
110543,Clean way to distinguish python subclass NT vs. C++ NT,2023-10-04 19:13:10+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
110541,On the correctness of torch.signal.windows.cosine,2023-10-04 18:55:16+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""topic: bc breaking""), Label(name=""topic: docs"")]"
110525,performance drop because batching rule for aten::_scaled_dot_product_attention_math is not yet implemented,2023-10-04 15:27:09+00:00,,0,5,"[Label(name=""module: vmap""), Label(name=""oncall: transformer/mha""), Label(name=""module: functorch"")]"
110516,Torch Nested Issue With Backward Pass In Transpose,2023-10-04 14:38:10+00:00,,0,2,"[Label(name=""triaged""), Label(name=""has workaround""), Label(name=""module: nestedtensor"")]"
110515,DynamicQuantizedLinear shows incorrect qscheme after applying eager mode dynamic quantization,2023-10-04 14:35:59+00:00,,1,6,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
110507,doc modification of torch.nn.softshrink api,2023-10-04 12:30:47+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
110506,[dynamo] Slow compile times for optimizers due to for loops,2023-10-04 12:16:09+00:00,,0,11,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: dynamo"")]"
110505,scaled_dot_product returns NaN arrays with eval(),2023-10-04 07:43:21+00:00,,0,2,"[Label(name=""oncall: transformer/mha"")]"
110485,[export] `torch.tensor(0)` should not get burned in as a constant,2023-10-03 23:21:10+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: dynamo""), Label(name=""oncall: export""), Label(name=""module: pt2-dispatcher"")]"
110479,[FSDP] [Checkpointing] Loading optimizer state dict with use_orig_params True causes OOM,2023-10-03 22:11:55+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
110476,[ONNX] Figure out aot inline strategy for Dort / onnxrt backend,2023-10-03 21:45:33+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
110461,Custom tensor attributes not preserved with registered functions,2023-10-03 19:32:02+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: custom-operators""), Label(name=""module: library"")]"
110455,Local build breakage on AWS cluster,2023-10-03 18:01:02+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged"")]"
110450,`test_pytorch_onnx_onnxruntime_cuda.py` is not run in CI,2023-10-03 15:42:01+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged"")]"
110448,Explore Hybrid (CPU+GPU) Graphs in Scalar parameters,2023-10-03 14:51:14+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
110447,Using `torch.onnx.export` from file named `onnx.py` results in cryptic error message,2023-10-03 13:41:09+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
110439,Torch.onnx.export of module used positional and keyword arguments,2023-10-03 08:43:17+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
110436,Pytorch for Python 3.12 not available,2023-10-03 05:22:03+00:00,,0,15,"[Label(name=""high priority""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
110422,jacrev Issue when Using Cuda,2023-10-02 23:53:57+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
110387,Different results for forward pass of two equal tensors through Conv2d,2023-10-02 13:34:23+00:00,,0,13,"[Label(name=""triaged""), Label(name=""module: numerical-reproducibility""), Label(name=""module: memory format"")]"
110379,Pytorch LoadNativeLibrary issue,2023-10-02 09:12:51+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
110366,Categorical Simplex constraint throws error for valid values,2023-10-01 20:44:04+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
110363,"nn.BatchNorm2d (track_running_stats = True) causes ""modified by an in-place operation"" error when in torch.nn.parallel.DistributedDataParallel",2023-10-01 19:28:47+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
110356,"Dropout signature inconsistent between `torch.dropout`, `torch.nn.Dropout` and `torch.nn.functional.dropout`",2023-10-01 13:37:59+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
110347,ONNX export: TransformerEncoder is exported with fixed input dims,2023-10-01 04:05:35+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
110342,[inductor]: Not handling `ConcatKernel/NopKernel` fusions leads to suboptimal fusions,2023-09-30 23:50:00+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
110334,Perf-Drop (factor=2) Ubuntu-vs-Windows on same PC (dual-boot),2023-09-30 11:16:01+00:00,,0,7,"[Label(name=""module: windows""), Label(name=""module: cuda""), Label(name=""triaged"")]"
110332,`torch.jit.load()` might unresponsive in IBM s390x when loading some certain torchscript saved by x86 machine.,2023-09-30 08:29:43+00:00,,0,0,"[Label(name=""oncall: jit"")]"
110331,"torch.Tensor.__repr__ causes torch.compile to error: ""got an unexpected keyword argument 'tensor_contents'""",2023-09-30 07:53:42+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
110315,"torch._dynamo.exc.Unsupported: unexpected sourceless type bases: (<class 'torchrec.streamable.Pipelineable'>,)",2023-09-29 21:08:35+00:00,,1,4,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""oncall: export"")]"
110304,"pytorch_stargan: ""_inductor/fx_passes/joint_graph.py"", line 166, in constant_fold_uniform_value KeyError ""val""",2023-09-29 19:30:39+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
110295,Tests modify global state cause later tests to fail,2023-09-29 18:24:09+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: devx"")]"
110291,AOT Autograd Neg View Support,2023-09-29 17:34:59+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
110285,TypeError: Got unsupported ScalarType BFloat16,2023-09-29 15:52:26+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
110281,feat(Pipeline Parallelism): use mincut optimization for local communication optimization,2023-09-29 13:21:35+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
114605,vmap: Transform single-element tensor to integer,2023-09-29 10:28:46+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
110259,Cannot avoid kineto_LIBRARY-NOTFOUND error when using pre-built pytorch,2023-09-29 00:31:26+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""oncall: profiler"")]"
110255,ONNX export of torch.nn.Transformer still fails,2023-09-28 23:38:03+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
110252,cuda/tf32 docs are outdated,2023-09-28 22:49:27+00:00,,1,4,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: tf32"")]"
110250,Accessing Particular Nightly Builds Don't Work,2023-09-28 21:54:06+00:00,,0,14,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
110249,`torch.func.functional_call` does not work with `__torch_function__ ` Tensor-like objects,2023-09-28 21:49:11+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: __torch_function__""), Label(name=""module: functorch"")]"
110238,PyTorch with non-shared build (building a single shared lib) is unsupported,2023-09-28 18:40:26+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: static linking"")]"
110210,DISABLED test_noncontiguous_samples__native_batch_norm_legit_cuda_float32 (__main__.TestCommonCUDA),2023-09-28 09:40:03+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
110205,RuntimeError: Expected packed scalar Tensor to be of dimension 1. Got 0 instead.,2023-09-28 08:02:20+00:00,,0,4,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""actionable"")]"
110198,DISABLED test_activations_abs__cpu (__main__.TestNestedTensorDeviceTypeCPU),2023-09-28 03:40:01+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
110194,cudaMallocAsync cause too much fragmentation.,2023-09-28 02:32:05+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
110175,Module-level bufferization for torch dynamo module spanning multiple `fx.GraphModule`,2023-09-27 18:04:36+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
110156,Add _worker_end_fn_t to the DataLoader,2023-09-27 13:13:56+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
110154,"ValueError: args contained 2 None's after flattening. When exporting a ScriptModule or ScriptFunction, no args may be None because that breaks type propagation.",2023-09-27 12:54:55+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
110148,Torch.onnx.dynamo_export stuck at reshape,2023-09-27 09:33:35+00:00,,0,9,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: dynamo""), Label(name=""oncall: export"")]"
110137," custom_ops._destroy(""test::foo"") doesn't remove abstract_impl",2023-09-27 03:58:05+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
110136,Unbacked SymInts get reallocated whenever you repropagate fake tensors,2023-09-27 03:55:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: dynamic shapes""), Label(name=""module: pt2-dispatcher"")]"
110135,logging stack_info doesn't do anything,2023-09-27 03:53:10+00:00,,0,0,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: ProxyTensor""), Label(name=""module: pt2-dispatcher"")]"
110131,Some ONNX tests have been disabled because of new tensor.split signature,2023-09-27 02:02:00+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
110130,Create a new heuristic TD rule for failures coming from base commit of the pull requests,2023-09-27 01:35:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: devx"")]"
110116,Skip cuda kernel launch with torch.sum when dimension length is 0,2023-09-26 21:38:24+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
110098,Dynamo tests in CI seem to not run at times,2023-09-26 19:43:26+00:00,,1,8,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
110096,"GPT2ForSequenceClassification, LayoutLMForSequenceClassification: ""torch._dynamo.exc.Unsupported: call_function BuiltinVariable(setattr) [HFPretrainedConfigVariable(), ConstantVariable(str), ConstantVariable(str)] {}""",2023-09-26 19:28:41+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
110089,"sam: AssertionError at torch/_inductor/graph.py `assert isinstance(value, (TensorBox, sympy.Expr))`",2023-09-26 17:32:38+00:00,,1,9,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: export"")]"
110084,scatter_add: Mixing 0-dim and 1-dim tensors,2023-09-26 16:24:02+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: python frontend""), Label(name=""module: edge cases"")]"
110080,Devices API,2023-09-26 15:31:55+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""topic: new features""), Label(name=""module: python frontend"")]"
110074,ImportError: libc10_cuda.so: cannot open shared object file: No such file or directory,2023-09-26 12:23:52+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
110065,[BUG] Elastic cannot kill all subprocesses after sending sigterm.,2023-09-26 08:32:41+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: elastic"")]"
110056,torch.onnx.export causes floating point exception with core dump for empty slice assignment,2023-09-26 04:47:26+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
110032,Race condition on shutdown involving PThreadPool and autograd,2023-09-25 20:46:41+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""module: sanitizers"")]"
110029,Dataloader resetting with num_workers=1 and persistent_workers=True,2023-09-25 20:23:34+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
110026,DISABLED test_raises_mesh_dim_less_than_2 (__main__.TestDeviceMeshGetItem),2023-09-25 18:39:53+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
110014,tan/tanh discrepancies with complex due to jiterator,2023-09-25 15:52:03+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: jiterator"")]"
110004,Please offer packages with local version `torch==2.1.0+cpu` for macOS,2023-09-25 09:52:02+00:00,,0,0,"[Label(name=""module: build""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
110000,RuntimeError: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED,2023-09-25 07:48:46+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
109991,Implmenet kthvalue for bfloat16 on CUDA,2023-09-25 04:32:57+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: bfloat16"")]"
109987,Static quantization for Transformer block : AttributeError 'function' object has no attribute 'is_cuda',2023-09-25 03:08:08+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
109982,DISABLED test_cat_addmm (__main__.TestMaxAutotune),2023-09-25 00:57:00+00:00,,0,3,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
109970,torch-<version>.dist-info WHEEL file contains incorrect metadata for M1/M2 macOS platform,2023-09-24 10:46:36+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""module: m1"")]"
109968,Dtype hard-coded in DataLoader (for python floats).,2023-09-24 10:33:55+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: data"")]"
109963,WelfordReduction seems to have invalid/dead code when reduction_numel <= 1,2023-09-24 05:27:26+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: inductor"")]"
109958,How to compile torch 2.0.1 version from source?,2023-09-24 00:53:04+00:00,,0,1,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
109948,Simple script segfaulting when grad is enabled,2023-09-23 20:37:43+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: edge cases"")]"
109946,Indexed batch matrix multiplication to support MoEs and FFFs,2023-09-23 18:18:05+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
109943,Problems when loading PT files und Linux - Duda which are created under Mac Apple Silicon MPS,2023-09-23 15:49:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
109942,pytorch XLA document error,2023-09-23 15:24:49+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: xla"")]"
109941,Need latest NCCL support to reduce GPU HBM consumption,2023-09-23 09:27:54+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
109938,Batching for is_in,2023-09-23 05:22:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
109934,test test_2d_fsdp_integration_fsdp_nested_param_groups failed,2023-09-23 01:15:45+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
109929,Memory access fault with AMD Rocm,2023-09-22 23:48:40+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: rocm""), Label(name=""triaged"")]"
109926,cm3leon_generate failing compilation,2023-09-22 23:12:42+00:00,,1,8,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
109923,Import order issue with torch and pybind11 Library Statically Linked to libstdc++,2023-09-22 22:35:25+00:00,,0,0,"[Label(name=""module: abi""), Label(name=""triaged""), Label(name=""module: static linking"")]"
109909,Large Discrepancies between PyTorch and ONNXRuntime Inference ,2023-09-22 20:12:16+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
109895,moco: torch._dynamo.exc.Unsupported: hasattr: TensorVariable(),2023-09-22 17:47:20+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
109885,"DALLE2_pytorch: ""torch._dynamo.exc.Unsupported: call_method NNModuleVariable() eval [] {}""",2023-09-22 14:44:30+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
109884,basic_gnn_gcn: ERROR:common:TypeError: object of type 'GreaterThan' has no len(),2023-09-22 14:32:00+00:00,,1,4,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor"")]"
109880,[FSDP ]How to convert sharded_state_dict files into full_state_dict offline without distributed process,2023-09-22 13:44:11+00:00,,2,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""module: distributed_checkpoint"")]"
109874,[inductor][cpu] performance regression,2023-09-22 09:53:50+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
109873,Allow try except check for numpy bfloat16 representation,2023-09-22 09:49:47+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
109870,Wrongly returns nan for vectorized complex numbers division on PPC/ZArch,2023-09-22 09:03:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: POWER"")]"
109863,[BUG?] Why Allocator use stream to manage Block?,2023-09-22 04:21:18+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
109861,Cannot use constrain_as_size from fake tensor implementations: RuntimeError: tried to get Int out of SymInt,2023-09-22 03:36:52+00:00,,2,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""oncall: export"")]"
109856,Severe performance regression on deterministic algorithm in torch 2.0,2023-09-22 03:23:53+00:00,,0,11,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: cublas""), Label(name=""module: determinism"")]"
109854,"Directly support assert on Scalar, instead of forcing Tensor",2023-09-22 03:10:54+00:00,,2,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
109850,torch._export has no logging,2023-09-22 02:56:55+00:00,,1,0,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""export-triaged""), Label(name=""oncall: export"")]"
109848,[dynamo][stream] Stream runtime operation in FX graph is ignored by remaining compiler,2023-09-22 02:52:14+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
109833,Implement Copy-on-write (COW) tensors,2023-09-21 23:23:09+00:00,,1,3,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
109827,PIN disabled tests for the release,2023-09-21 21:19:34+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""topic: binaries"")]"
109819,ValueError: only one element tensors can be converted to Python scalars,2023-09-21 19:39:51+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: regression"")]"
109806,Incompatible dimensions error for FusedMatMul,2023-09-21 17:39:40+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
109802,Bits types cannot be used under deterministic mode,2023-09-21 17:22:51+00:00,,1,18,"[Label(name=""triaged""), Label(name=""module: determinism"")]"
109791,Heap-buffer-overflow during tensor unpickling,2023-09-21 15:14:34+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
109781,"`torch.embedding`, `weight[indices]`, `torch.index_select` returns random data with indices on meta device",2023-09-21 10:42:12+00:00,,0,1,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: embedding""), Label(name=""ezyang's list""), Label(name=""module: meta tensors""), Label(name=""topic: bc breaking"")]"
109777,Wrong vector shift results on PowerPC,2023-09-21 08:19:13+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: vectorization""), Label(name=""module: POWER"")]"
109774,[DDP + Dynamo] Tracing DDP AllReduce,2023-09-21 07:19:33+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
109770,Slow performance when running torch.jit traced model with Flash Attention using libtorch on Windows,2023-09-21 04:47:05+00:00,,0,1,"[Label(name=""module: windows""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
109768,LLaMA-2 70b model convert from PyTorch to ONNX format ,2023-09-21 03:50:22+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
109762,DTensor: summon full tensor API?,2023-09-21 01:23:07+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
109753,fp16 parity issue with traced code on GPU,2023-09-20 23:55:15+00:00,,0,10,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""oncall: export"")]"
109747,[RFC][TorchElastic] topology info in training apps/ranks,2023-09-20 22:37:30+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: elastic"")]"
109725,Profiler should implicitly synchronize gpu devices ,2023-09-20 17:25:25+00:00,,0,6,"[Label(name=""oncall: profiler"")]"
109724,assert_is_valid_input_type is too weak,2023-09-20 17:22:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
109719,Make torch.cuda.graphs.is_current_stream_capturing() available in TorchScript,2023-09-20 14:39:07+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: cuda graphs"")]"
109706,Make standard container classes satisfy container Protocols.,2023-09-20 09:58:12+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
109700,[inductor][cpu] performance regression,2023-09-20 09:24:16+00:00,,3,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
109699,[TorchScript] Support ScriptFunction arguments in torch.jit.script calls.,2023-09-20 09:15:45+00:00,,0,0,"[Label(name=""oncall: jit"")]"
109697,[DDP + Dynamo] Traceable DDP hooks,2023-09-20 07:15:33+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
109691,Extends the functionality of  `nn.BatchNorm1d`.,2023-09-20 06:22:41+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
109687,[RFC]: Moving most torch.compile backends out of core,2023-09-20 04:43:18+00:00,,0,19,"[Label(name=""triaged""), Label(name=""topic: bc breaking""), Label(name=""dependency issue""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
109675,[FSDP] UnpicklingError when calling save_state_dict in distributed run,2023-09-20 01:51:40+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
109666,FSDP: ShardedStateDict support for world_size = 1,2023-09-20 00:39:21+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
109652,InstanceNorm does not catch dim mismatch,2023-09-19 21:49:44+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
109610,AsyncCompile loses useful exception backtrace in __get_result,2023-09-19 15:31:58+00:00,,0,9,"[Label(name=""good first issue""), Label(name=""module: logging""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
109592,test_memory_timeline fails on PPC due to extra temopraries,2023-09-19 12:23:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: POWER""), Label(name=""oncall: profiler"")]"
109586,Max pool with negative integer inputs and channels_last memory layout gives the wrong values,2023-09-19 08:21:03+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
109585,[Torch-Onnx] Exporting the operator 'quantized::conv_transpose2d' to ONNX opset version 13 is not supported.,2023-09-19 07:48:04+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
109583,[dynamo][jagged tensor] Slow compilation time for a helper function of jagged tensor,2023-09-19 05:54:54+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
109582,Make Dropout take a dim=... argument,2023-09-19 05:23:50+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""has workaround"")]"
109581,torch.optim.Adafactor,2023-09-19 05:20:14+00:00,,1,3,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
109579,[Android: React Native] couldn't find DSO to load: libtorch-code-gen.so when loading model ,2023-09-19 03:50:57+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
109577,ONNX Export error,2023-09-19 03:40:57+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
109552,[fake/meta] Bad meta kernel for conv1d,2023-09-18 22:49:15+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: pt2-dispatcher"")]"
109539,Torch FX SubgraphMatcher Any / Oneof Patterns,2023-09-18 20:54:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: fx.passes"")]"
109528,attn_output_weights sometimes rerurn `None`,2023-09-18 18:11:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
109514,_assert_bound_is_rational can fail,2023-09-18 15:49:19+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
109504,[dynamo] torch._dynamo.exc.Unsupported: comparison SymNodeVariable() <built-in function is_> ListVariable(),2023-09-18 15:25:02+00:00,,0,5,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
109497,Very big differences in output of `torch.lobpcg` (values and run-time) compared to SciPy on a very ill-conditioned Laplacian matrix,2023-09-18 13:41:02+00:00,,0,17,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
109494,Performance degradation on AMD + A800 when computation is small,2023-09-18 12:37:01+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
109489,Investigate Strictness of torch.compile `is_big_gpu`,2023-09-18 10:44:49+00:00,,0,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
109488,[bug] FALLBACK path has been taken inside: runCudaFusionGroup,2023-09-18 09:24:28+00:00,,0,1,"[Label(name=""oncall: jit"")]"
109484,[dynamo][symbolic shapes] Long compilation time for KJT helper function,2023-09-18 08:32:47+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
109478,ProcessGroup is not automatically destroyed when the process exits,2023-09-18 06:29:44+00:00,,0,4,"[Label(name=""oncall: distributed"")]"
109477,[DTensor] optimizer step performance is still too bad,2023-09-18 05:39:51+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: dtensor"")]"
109462,Inconsistent behavior for in-place operations on coalesced sparse tensors,2023-09-17 16:45:33+00:00,,0,9,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
109460,[BUG][pytree] treespec serialization for locally defined classes and namedtuple types,2023-09-17 13:48:15+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: pytree"")]"
109457,Training results from using MPS backend are poor compared to CPU and CUDA,2023-09-17 11:34:28+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: mps"")]"
109453,Inconsistent Behavior of `ConvTranspose2d` on CPU and CUDA,2023-09-17 06:11:15+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""triaged"")]"
109446,torch pollutes libgomp symbols when import _C,2023-09-16 21:22:06+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: openmp""), Label(name=""module: third_party"")]"
109445,Memory usage steadily increasing when using back propagation with sparse CSR parameter matrices on CPU,2023-09-16 20:47:59+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
109443,RNN Documentation is Confusing / Wrong,2023-09-16 18:31:53+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""actionable"")]"
109442,CPU memory cannot get released after `torch.compile` (caused by importing `AsyncCompile`),2023-09-16 18:13:09+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
109440,[FSDP] supports QLora finetuning,2023-09-16 17:15:17+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
109425,Cannot export a quantized model that permutes a quantized tensor to ONNX,2023-09-16 04:08:35+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
109420,Supporting Block_Ptrs in inductor code gen,2023-09-16 01:38:12+00:00,,0,10,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
109401,Interleaved isend and irecv causes hang,2023-09-15 21:39:55+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
109392,[FSDP] Implement additional check for turn on 2D TP + FSDP extension,2023-09-15 17:50:34+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
109386,Make Fx Generating Incorrect Graph For GPTQ model,2023-09-15 16:48:43+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: ProxyTensor"")]"
109385,FSDP crashes when submodule calls method that isn't `forward()`,2023-09-15 16:31:52+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
109383,cuda rng state for 2.0.1 cannot be used for 2.1.0,2023-09-15 16:06:26+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: random"")]"
109379,DISABLED test_compute_local_shape_and_global_offset_1D (__main__.UtilTest),2023-09-15 15:39:50+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
109362,DISABLED test_nondeterministic_alert_median_cuda_float64 (__main__.TestTorchDeviceTypeCUDA),2023-09-15 06:39:32+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
109341,DISABLED test_nondeterministic_alert_kthvalue_cuda_float64 (__main__.TestTorchDeviceTypeCUDA),2023-09-15 00:56:47+00:00,,0,3,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
109321,DISABLED test_backend_match_guard_multi_threads (__main__.MiscTests),2023-09-14 21:39:25+00:00,,0,27,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
109310,DISABLED test_nondeterministic_alert_histc_cuda (__main__.TestTorchDeviceTypeCUDA),2023-09-14 18:39:23+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
109309,Support the `ExitStack` context manager (or a simplified version),2023-09-14 18:36:01+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
109303,Create static analysis tool to improve ONNX export success,2023-09-14 17:42:45+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""release notes: onnx"")]"
109294,Attribute 'kernel_shape' is expected to have field 'ints' when exporting a module with `List[Tensor]` inputs/outputs,2023-09-14 13:46:53+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
109292,aten::squeeze exported to ONNX as an `If` node,2023-09-14 12:56:02+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
109290,DISABLED test_nondeterministic_alert_bincount_cuda (__main__.TestTorchDeviceTypeCUDA),2023-09-14 12:45:31+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
109289,PyTorch 2.1 smoke test requirements ,2023-09-14 12:38:13+00:00,,3,2,"[Label(name=""triaged"")]"
109285,[inductor][cpu] perf regression,2023-09-14 11:08:06+00:00,,2,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
109276,DISABLED test_nondeterministic_alert_MaxUnpool3d_cuda_float64 (__main__.TestTorchDeviceTypeCUDA),2023-09-14 06:39:42+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
109268,DISABLED test_nondeterministic_alert_MaxUnpool3d_cuda_float32 (__main__.TestTorchDeviceTypeCUDA),2023-09-14 00:56:32+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
109266,Add a unittest for ModuleWrapPolicy callable,2023-09-14 00:35:19+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""pt_distributed_rampup"")]"
109263,[profiler] Show shapes for lists of tensors in chrome traces,2023-09-14 00:11:45+00:00,,1,0,"[Label(name=""oncall: profiler"")]"
109261,[dynamo] Disable DDPOptimizer or error out if DDPOptimizer + static_graph is detected,2023-09-13 23:37:29+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
109260,[FSDP] Simplify `_fully_sharded_module_to_handle`,2023-09-13 23:23:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
109240,AOTAutograd should put keep mutations in the graph during training,2023-09-13 19:17:32+00:00,,0,21,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
109237,"AOTAutograd should track view chains so it can replay them, instead of using as_strided.",2023-09-13 19:11:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
109236,Report name of defining class along side function name in Dynamo logs,2023-09-13 19:07:05+00:00,,1,0,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
109235,ONNX exporter issue: fails to add conversions exporting T5 Transformer model,2023-09-13 19:06:32+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
109224,DISABLED test_nondeterministic_alert_MaxUnpool3d_cuda_float16 (__main__.TestTorchDeviceTypeCUDA),2023-09-13 18:39:32+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
109213,inductor/test_max_autotune having timeout issues,2023-09-13 17:22:44+00:00,,1,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
109204,Pytorch ROCM windows builds,2023-09-13 16:07:55+00:00,,0,0,"[Label(name=""module: windows""), Label(name=""module: rocm""), Label(name=""triaged"")]"
109195,DISABLED test_nondeterministic_alert_MaxUnpool2d_cuda_float64 (__main__.TestTorchDeviceTypeCUDA),2023-09-13 12:45:54+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
109194,"`torch.mean` not supported for `torch.sparse_coo_tensor`, but `torch.sum` is supported (`scipy.sparse.coo_matrix` does support both `mean` and `sum`)",2023-09-13 11:14:17+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""enhancement"")]"
109193,"F.conv2d(input, weight, bias, self.stride, RuntimeError: cuDNN error: CUDNN_STATUS_MAPPING_ERROR",2023-09-13 11:10:21+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cudnn""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
109191,Gradients across different ranks are not synchronized when using DDP,2023-09-13 10:27:51+00:00,,1,8,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
109181,DISABLED test_nondeterministic_alert_MaxUnpool2d_cuda_float32 (__main__.TestTorchDeviceTypeCUDA),2023-09-13 06:39:39+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
109180,FSDP vs. MiCS,2023-09-13 06:14:27+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
109175,SparseSemiStructuredTensors are constructed differently from the original dense ones,2023-09-13 05:04:13+00:00,,1,9,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
109166,NAN appears in the backward results of masked.cumprod on macos,2023-09-13 03:06:49+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: half""), Label(name=""module: mps"")]"
109162,DISABLED test_nondeterministic_alert_MaxUnpool2d_cuda_float16 (__main__.TestTorchDeviceTypeCUDA),2023-09-13 00:56:52+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
109137,[ONNX] Provide an option to not generate `report_dynamo_export.sarif`,2023-09-12 19:29:01+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
109134,FSDP should have tests for partial state_dict and optim state_dict loading,2023-09-12 18:56:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""module: distributed_checkpoint"")]"
109131,Introduce 'backend' concept to torch.export.export API,2023-09-12 18:41:58+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""feature""), Label(name=""triaged""), Label(name=""topic: new features""), Label(name=""oncall: export"")]"
109130,DISABLED test_nondeterministic_alert_MaxUnpool1d_cuda_float64 (__main__.TestTorchDeviceTypeCUDA),2023-09-12 18:39:22+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
109113,"The API ""torch::jit::_load_for_mobile"" is limited to create an object living on the stack.",2023-09-12 14:52:30+00:00,,0,0,"[Label(name=""oncall: jit"")]"
109112,Unable to install the latest version of PyTorch using mamba.,2023-09-12 14:39:21+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
109108,Cannot construct `torch.sparse_coo_tensor` (but `scipy.sparse.coo_matrix` works fine): `TypeError: only integer tensors of a single element can be converted to an index`,2023-09-12 13:27:01+00:00,,0,10,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: scipy compatibility"")]"
109103,"DDP - ""No backend type associated with device type cpu"" with new Model Phi 1.5 despite everything loaded on GPUs",2023-09-12 12:14:58+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
109100,FSDP do not support `ignored_parameters` when `auto_wrap_policy` is specified,2023-09-12 07:29:16+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
109098,Can't initializa NVML,2023-09-12 06:28:46+00:00,,0,2,"[Label(name=""triaged"")]"
109094,Parameters of cuda module zero out when used in multiprocessing,2023-09-12 02:56:24+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
109074,torch.compile/triton holding GIL during compilation and CompiledKernel call results in deadlocks during distributed training,2023-09-11 22:32:08+00:00,,1,13,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""upstream triton"")]"
109067,torch.argmax fails for device='mps:0',2023-09-11 21:33:55+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: mps"")]"
109062,CollectiveFunctionRewriteVariable for all_to_all_single,2023-09-11 20:35:22+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
109052,Allow reductions to write into pinned memory,2023-09-11 19:25:44+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: reductions"")]"
109017,torch.sparse_coo_tensor argname quirks + [feature request] `.numpy()`/`from_numpy` method for sparse_coo_tensor/sparse_csr_tensor (or maybe name them as `.scipy()`/`.from_scipy()` or at least under some `torch.utils.*` namespace,2023-09-11 10:22:50+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: scipy compatibility"")]"
109016,pr build failures in inductor dynamic shape test for operation tests with simple tensors. Side effect of current test framework,2023-09-11 09:42:43+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: cpu inductor"")]"
109014,Cannot install torchmetrics - ERROR 403,2023-09-11 09:09:25+00:00,,0,20,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""triaged"")]"
109010,The following will always fail on NixOS,2023-09-11 08:46:40+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""topic: build"")]"
109009,TypeError: mask must have dtype bool,2023-09-11 08:13:31+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: masked operators"")]"
109002,[FSDP] How can I wrap a model that has both nn.Parameter and nn.Module,2023-09-11 04:13:14+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
109001,"Incorrect strides and accuracy when combining `torch.compile` with `op(out=out)` having complex number outputs, `test_ops::test_out` is bugged",2023-09-11 03:44:45+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
108999,[inductor][cpu] perf regression,2023-09-11 01:55:23+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
108993,DISABLED test_complex_half_reference_testing_pow_cuda_complex32 (__main__.TestCommonCUDA),2023-09-11 00:56:36+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: nvfuser""), Label(name=""oncall: pt2"")]"
108990,"`PYTORCH_TEST_WITH_INDUCTOR=1 python test/test_ops.py -k test_out_{warnings_, *}{_refs_, *}randn_cuda_float32` fails on main",2023-09-10 23:43:26+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
108984,PPC64le: GCC 11.2.1 Linker Error in bin/torch_shm_manager,2023-09-10 19:39:25+00:00,,0,8,"[Label(name=""triaged""), Label(name=""topic: build""), Label(name=""bug"")]"
108983,ZeroTensor (and probably neg/conj) doesn't play well with wrapper tensor subclasses,2023-09-10 16:54:24+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""ZeroTensor"")]"
108977,[feature request] Provide some sparse eigen solver(s) for PyTorch (maybe via `ARPACK` as in scipy) + SPD sparse / laplace linear system solver - maybe NVidia AMGx library?,2023-09-10 12:14:34+00:00,,0,10,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
108976,About FSDP,2023-09-10 10:04:24+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
108975, Exporting the operator 'aten::_convolution_mode' to ONNX opset version 14 is not supported.,2023-09-10 09:54:24+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""onnx-needs-info""), Label(name=""release notes: onnx"")]"
108971,Really slow compilation times for torch.compile causing distributed training errors,2023-09-10 06:45:33+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: startup-tracing-compile time""), Label(name=""module: distributed"")]"
108968,Unnecessary cuda synchronizations that we should remove in PyTorch,2023-09-10 04:51:03+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
108966,torch.compile graph breaks should be independent of DDP buckets,2023-09-10 03:34:32+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
108948,Add Lambert W function as torch.special.lambertw,2023-09-09 15:26:22+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: special""), Label(name=""topic: new features"")]"
108942,Dynamo's eval_frame.c is not thread/subinterpreter safe,2023-09-09 10:09:48+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
108934,PPC64le: vsx_helpers.h errors,2023-09-09 03:36:25+00:00,,0,27,"[Label(name=""module: build""), Label(name=""triaged"")]"
108926,Support ONNX export for aten::select_backward and aten::slice_backward,2023-09-08 23:10:42+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
108909,DISABLED test_nondeterministic_alert_MaxUnpool1d_cuda_float32 (__main__.TestTorchDeviceTypeCUDA),2023-09-08 21:40:51+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
108900,[c10d] fix functional collective reduce op naming convention,2023-09-08 20:44:18+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
108898,[dynamo] Missing guard on global function,2023-09-08 20:36:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: guards"")]"
108888,RuntimeError: Unrecognized tensor type ID: ZeroTensor,2023-09-08 19:02:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""ZeroTensor"")]"
108882,Inconsistent any( ) between cuda and cpu - Incorrect complex to bool conversion,2023-09-08 18:02:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: correctness (silent)"")]"
108877,[optimize_ddp] moco - NameError: name 's2' is not defined ,2023-09-08 17:30:15+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: distributed"")]"
108870,"Inconsistent, platform-dependent torch.ones_like behavior on metatensors",2023-09-08 15:29:22+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: meta tensors"")]"
108862,"A100 runners down: apt-get install nvidia-docker2, Could not get lock /var/lib/dpkg/lock-frontend",2023-09-08 12:57:26+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: infra"")]"
108861,RuntimeError: DataLoader worker (pid 11011) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit,2023-09-08 11:07:31+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
108859,Certain torch functions are not handled by torch func wrapper,2023-09-08 10:36:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
108858,Ubuntu vs Windows: torch.cuda.OutOfMemoryError only happens on Ubuntu,2023-09-08 09:54:41+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
108857,DISABLED test_nondeterministic_alert_MaxUnpool1d_cuda_float16 (__main__.TestTorchDeviceTypeCUDA),2023-09-08 09:39:40+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
108851,about nccl not work,2023-09-08 07:30:57+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: nccl"")]"
108840,Tensor Parallel doesn't work with torch.compile,2023-09-08 05:00:14+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dtensor""), Label(name=""module: distributed"")]"
108835,CompileId in Dynamo log messages should include restart analysis count,2023-09-08 03:44:33+00:00,,0,0,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
108833,Export should never unspec NN module,2023-09-08 03:41:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
108830,torch._export.pass_base.ExportPassBaseError: Unsupported target type: <function sym_min at 0x7ff25dd10670>,2023-09-08 03:25:12+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""export-triage-review""), Label(name=""oncall: export"")]"
108829,torch._dynamo.export produces object that is not pickleable,2023-09-08 03:23:11+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
108824,DISABLED test_lstm_packed (__main__.CPUReproTests),2023-09-08 01:45:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""skipped""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
108805,Export torchvision detection model retinanet_resnet50_fpn,2023-09-07 21:23:44+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""oncall: export"")]"
108798,Dynamo Swallowing Exception In Lambda,2023-09-07 19:51:51+00:00,,0,9,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
108794,[C++ Frontend] Simple Changes for Cleaner Options,2023-09-07 18:56:43+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
108784,Collect more env variables in `collect_env.py`,2023-09-07 16:16:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""needs research"")]"
108779,Tracing interpolate with tensor scale_factor is cursed,2023-09-07 15:59:42+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""oncall: export"")]"
108777,RuntimeError: tried to get Double out of SymFloat,2023-09-07 15:38:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
108773,Sourceforge outage causing multiple CI failures,2023-09-07 15:13:13+00:00,,1,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
108770,SDPA with nested backend: expose a way to avoid recomputing data layout information,2023-09-07 14:41:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
108752,[inductor][cpu] performance regression,2023-09-07 06:36:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
108747,Unable to compile the function which contains dict of types,2023-09-07 04:57:12+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
108746,[dtensor] Add debug tool to visualize sharding,2023-09-07 03:56:57+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dtensor"")]"
108745,[PT2.0] [.Compile] [Dynamic] Pytorch FX/JIT graph's inputs/nodes ordering is changed when FX recompiles even though the graph operations are same,2023-09-07 03:55:34+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
108744,switch more test cases to use MultithreadTestCase,2023-09-07 03:40:20+00:00,,0,3,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: dtensor"")]"
108743,DISABLED test_complex_half_reference_testing_fft_hfft2_cuda_complex32 (__main__.TestCommonCUDA),2023-09-07 03:39:23+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: primTorch"")]"
108742,[dtensor] enable tensor metadata check across ranks when run_check=True,2023-09-07 03:34:56+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dtensor"")]"
108739,"DDP Elastic ""master_addr"" resolution error in environment variables.",2023-09-07 03:14:46+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: elastic"")]"
108716,Support benchmark fusion for TemplateKernel,2023-09-06 23:43:53+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: inductor""), Label(name=""module: dynamo"")]"
108692,Adding Maximal Update Parametrization (µP) to torch.nn.init,2023-09-06 19:56:38+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
108676,RuntimeError when calling conv_transpose2d with groups,2023-09-06 17:45:45+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""triaged"")]"
108671,avg_pool3d_backward fails on meta with grad_input parameter,2023-09-06 17:19:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: meta tensors"")]"
108670,torch.jit.script produces incorrect gradients,2023-09-06 17:19:07+00:00,,0,3,"[Label(name=""oncall: jit"")]"
108665,INTERNAL ASSERT FAILED in `shape_type_inference.cpp`,2023-09-06 16:26:59+00:00,,0,0,"[Label(name=""oncall: jit"")]"
108651,libtorch: runtime error when iterating batch of dataloader,2023-09-06 13:10:06+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
108650,Unsupported: inline in skipfiles: Logger.info,2023-09-06 13:08:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: graph breaks"")]"
108865,Heap buffer overflow with `torch::load` on fuzzy data,2023-09-06 11:51:05+00:00,,1,14,"[Label(name=""oncall: jit"")]"
108645,uninformative OOM error,2023-09-06 09:56:49+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
108642,torch.topk returned values and indices are reordered if sorted=False,2023-09-06 09:45:04+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
108640,torch.onnx.export does not trace all outputs for the HF BLOOM model,2023-09-06 09:05:20+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
108636,torch.compile operation benchmark result is poor,2023-09-06 08:28:19+00:00,,0,6,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
108627,autocast not consistent across different GPUs (A100 and RTX A6000),2023-09-06 06:21:49+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
108621,[inductor] Triton matmul templates should use reduced_precision_reduction flags,2023-09-06 03:14:18+00:00,,1,1,"[Label(name=""feature""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""matrix multiplication"")]"
108602,torchrun fails to run on Windows 11,2023-09-05 22:44:12+00:00,,1,0,"[Label(name=""module: windows""), Label(name=""triaged"")]"
108569,Call for a deterministic implementation of scatter_add_cuda_kernel,2023-09-05 15:02:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
108567,Allow slicing of Nested Tensors along constant dimensions,2023-09-05 14:50:12+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
108565,`bytes(...)` support of torch tensor does not match numpy + it would be nice to support tensor.tobytes() as alias,2023-09-05 12:38:40+00:00,,0,17,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
108532,"Breaking incompatibility with Cuda 12.2, pytorch stable, torchvision",2023-09-04 20:14:33+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged"")]"
108522,nn.Transformer has dropout layers that BERT / GPT-2 do not have,2023-09-04 16:01:31+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
108521,"resutl of (torch.mm(a,b) does not match result of (a[:part,:], b)",2023-09-04 15:54:12+00:00,,0,2,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""matrix multiplication"")]"
108520,[inductor] CPU int32 overflow behavior differs between clang and gcc,2023-09-04 15:11:28+00:00,,0,10,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: m1""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
108519,Pytorch profiler with Tensorboard example not working,2023-09-04 14:12:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
108514,torch model to onnx conversion success but failed when inference,2023-09-04 10:50:35+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
108500,[cond] cache size limit exceeeded,2023-09-03 20:41:20+00:00,,1,7,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""pre_dispatch tracing""), Label(name=""module: higher order operators""), Label(name=""module: pt2-dispatcher"")]"
108496,The CPU version of `torch.cummax` is slow,2023-09-03 17:42:17+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
108494,backend-friendly distributions,2023-09-03 13:00:20+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
108493,RWKV + Adam exp_avg_sq will change from positive to negative after loss.backward(),2023-09-03 12:39:25+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
108491,Suppport Fused AdamW on CPU,2023-09-03 07:20:27+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
108484,DistributedDataParallel to support __getattr__,2023-09-02 21:31:21+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
108483,Efficient and robust calculation of diag(sparse @ diag @ sparse),2023-09-02 19:00:57+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
108474,CNN w variable sized input performance regression 1.10.2 cu113 -> 2.0.1 cu117,2023-09-02 05:10:01+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: regression"")]"
108446,`SymInt` input doesn't get optimized out from `torch.compiled()` graph even if unused,2023-09-01 21:06:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
108445,_foreach_copy_ with scalar second arg,2023-09-01 20:54:54+00:00,,1,3,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: mta"")]"
108442,Torch compile generates incorrect graph on Llama model,2023-09-01 20:04:58+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
108432,Wrong result of first run with torch.compile() when backend is using torch.jit.trace() and model has inplace operators ,2023-09-01 17:53:14+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
108407,torch.einsum() computes different results on cpu and cuda on A100 GPU.,2023-09-01 09:19:57+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
108406,enhance documentation around the developer build,2023-09-01 08:57:32+00:00,,0,1,"[Label(name=""triaged""), Label(name=""topic: docs"")]"
108404,multiple AMD GPUs,2023-09-01 08:22:32+00:00,,1,16,"[Label(name=""module: multi-gpu""), Label(name=""module: rocm""), Label(name=""triaged"")]"
108401,Crash on converting circular padding  to onnx,2023-09-01 07:10:17+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
108399,Generalize weight prepacking during quantized model deserialization,2023-09-01 05:58:58+00:00,,1,6,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
108381,"FSDP always puts parameters to fp32 when loading state_dict, even if state_dict has bf16 params",2023-08-31 23:02:32+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
108378,NCCL ISend is not asynchronous ,2023-08-31 22:00:54+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
108342,ONNX export constant folding messes up with shared weight deduplication,2023-08-31 09:43:58+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
108341,"Added attention mechanism error,Need to modify torch.use_deterministic_algorithms(True)",2023-08-31 09:36:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: determinism"")]"
108332,RuntimeError: dims.value().size() == self->getMaybeRFactorDomain().size(),2023-08-31 07:48:19+00:00,,0,0,"[Label(name=""oncall: jit"")]"
108324,[inductor][cpu] Perf regression,2023-08-31 03:14:18+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
108300,Can't run Test/Inductor test: test_compiled_optimizers.py,2023-08-30 23:33:21+00:00,,0,9,"[Label(name=""module: windows""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
108277,Transformer performance drop due to slow PyTorch GEMMs,2023-08-30 20:08:29+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
108268,ONNX-FX based exporter documentation/tutorial topics for PyTorch 2.1,2023-08-30 18:41:02+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""release notes: onnx"")]"
108246,pack_padded_sequence on GPU device,2023-08-30 16:46:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
108245,Integrate cutlass headers and scripts in pytorch package,2023-08-30 16:17:47+00:00,,0,10,"[Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""topic: binaries""), Label(name=""oncall: pt2"")]"
108244,Pytorch versions without the abi3 flag,2023-08-30 16:15:20+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
108241,Unrecognized attribute: axes for operator ReduceMean during onnx model conversion,2023-08-30 15:44:00+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
108231, DistributedSampler class: Change total_size into num_samples,2023-08-30 13:47:56+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
108226,torch.nn.functional.pad() with value type bool,2023-08-30 10:24:22+00:00,,0,1,"[Label(name=""oncall: jit"")]"
108225,"[docs] F.interpolate(uint8_input, mode = 'bicubic', ...) overshoot behavior: adjust the note in docs to explain that for uint8 saturating store is done and no manual clamp is needed or mention that bicubic is not supported for uint8 inputs",2023-08-30 10:21:01+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
108224,qnnpack quantized model can not be traced,2023-08-30 08:41:40+00:00,,2,4,"[Label(name=""oncall: jit""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
108212,Is there a standard procedure to check the consistency of environment across all nodes in PyTorch DDP training?,2023-08-30 03:57:55+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
108211,[Compile] Running Llama2 with torch.compile and FSDP results in Type mismatch assert in LlamaRotaryEmbedding ,2023-08-30 03:15:21+00:00,,1,6,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
108210,Using distributed RPC and DDP together triggers error.,2023-08-30 03:12:34+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
108209,ninja: build stopped: subcommand failed.,2023-08-30 02:54:36+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
108197,AdaptiveMaxPool documentation is not detailed,2023-08-29 23:55:40+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: pooling"")]"
108190,[FSDP] incorrect backward prefetch order when using BackwardPrefetch.BACKWARD_POST,2023-08-29 22:22:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
108183,[Performance] Pass in head_size_og to FlashAttentionV2 ,2023-08-29 20:45:13+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
108175,Enable FlashAttentionV2 on Windows,2023-08-29 18:31:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
108174,FlashAttentionV2 will OOM when building on ci/cd with default settings,2023-08-29 18:29:55+00:00,,1,4,"[Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged"")]"
108158,TORCHELASTIC_RESTART_COUNT doesn't seem to be broadcasted to all worker,2023-08-29 15:51:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: elastic""), Label(name=""oncall: r2p"")]"
108155,Automate release only changes in https://github.com/pytorch/pytorch/pull/108053,2023-08-29 15:09:23+00:00,,1,1,"[Label(name=""oncall: releng""), Label(name=""module: ci""), Label(name=""triaged"")]"
108152,`Tensor.uniform_` uses illegal argument name `from`,2023-08-29 14:43:21+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
108145,Problems hit when upgrading the version of HF used in CI,2023-08-29 14:07:18+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
108128,nccl:all_reduce is not profiled correctly,2023-08-29 04:24:47+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""oncall: profiler"")]"
108110,[inductor] Minifier fails on resnet50_quantized_qat,2023-08-29 00:12:38+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
108108,[BC BREAKING] Change default behavior of scaled_dot_product_attention's causal masking alignment,2023-08-28 23:47:02+00:00,,0,0,"[Label(name=""module: bc-breaking""), Label(name=""module: nn""), Label(name=""oncall: transformer/mha""), Label(name=""topic: bc breaking"")]"
108107,[inductor] soft_actor_critic training is slower than eager,2023-08-28 23:43:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""internal ramp-up task"")]"
108102,_sampled_addmm_kernel cause 'misaligned address' with new triton pin,2023-08-28 22:37:00+00:00,,1,4,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
108099,DISABLED test_multilayer_var_cpu (__main__.CpuTests),2023-08-28 21:41:02+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""skipped"")]"
108095,[inductor] minifier fails on moco,2023-08-28 20:56:32+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor"")]"
108090,[Optimizer Perf] Improve speed of _init_group to c++,2023-08-28 19:47:57+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
108079,Aliased Input/Output Requirement in `aot_export_joint_simple`,2023-08-28 18:21:02+00:00,,1,6,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
108047,DDP training can not accept subnet address in IPV6,2023-08-28 12:29:24+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
108046,Enhanced Available Backend Discovery and Selection in PyTorch 2,2023-08-28 09:11:22+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: python frontend"")]"
108041,"Undefined Symobl: pybind11::detail::type_caster<at::Tensor, void>::load(pybind11::handle, bool)",2023-08-28 07:09:30+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: pybind"")]"
108030,DISABLED test_autocast_flash_attention (__main__.ActivationCheckpointingViaTagsTests),2023-08-28 00:56:42+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
108023,[FSDP] Ignored modules on meta device seem to be initialized on CUDA device,2023-08-27 10:03:27+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: fsdp"")]"
108022,ShapeEnv produce_guards AssertionError Triggered when tensor is resized,2023-08-27 08:53:38+00:00,,0,5,"[Label(name=""triaged""), Label(name=""has workaround""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
108016,Failure in Initiating Pyotch DDP-style code ( Multi-machine multi-card environment),2023-08-27 06:03:24+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
108014,NameError: name 's1' is not defined,2023-08-27 02:03:08+00:00,,1,5,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor"")]"
108013,Installation with rocm5.6 results in error: assert len(weights) == expected_node_count AssertionError,2023-08-27 01:04:12+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""module: rocm""), Label(name=""triaged"")]"
107999,`upsample_bilinear2d_backward_out_cuda` is nondeterministic,2023-08-26 04:30:27+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: determinism"")]"
107980,DISABLED test_predispatch_with_for_out_dtype_nested_dynamic_shapes (__main__.DynamicShapesExportTests),2023-08-25 21:39:28+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
108065,Batching rule for aten::_scaled_dot_product_attention_math not yet implemented,2023-08-25 17:01:16+00:00,,0,0,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: vmap""), Label(name=""oncall: transformer/mha""), Label(name=""module: functorch"")]"
107961,"aten.lift throws error in dynamo backends -> RuntimeError: !at::functionalization::impl::isFunctionalTensor(self)  INTERNAL ASSERT FAILED at ""../aten/src/ATen/FunctionalizeFallbackKernel.cpp"":167",2023-08-25 15:17:24+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: functionalization"")]"
107960,Torch compile: libcuda.so cannot found,2023-08-25 15:01:07+00:00,,0,10,"[Label(name=""triaged""), Label(name=""dependency issue""), Label(name=""oncall: pt2"")]"
107955,PyTorch profile issues summary,2023-08-25 11:26:59+00:00,,0,3,"[Label(name=""triage review""), Label(name=""module: regression""), Label(name=""oncall: profiler"")]"
107950,DISABLED test_redundant_clone_for_layout_convert_cuda (__main__.FreezingCudaTests),2023-08-25 09:39:41+00:00,,0,2,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
107948,Exporting the operator 'aten::linalg_inv' to ONNX opset version 18 is not supported.,2023-08-25 08:25:31+00:00,,0,19,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
107945,Torch 1.13 Onnx Scope constant name not correct!,2023-08-25 08:00:50+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
107929,Export to onnx error: RuntimeError: ArrayRef: invalid index Index = 3; Length = 3,2023-08-25 04:47:18+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
107925,DISABLED test_conv_weight_layout_convert_cuda (__main__.FreezingCudaTests),2023-08-25 03:39:28+00:00,,0,2,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
107909,Provide a `reset_parameters()` method for MultiheadAttention to support FSDP meta device initializtion,2023-08-25 00:00:11+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
107898,[FakeTensor] fake tensor mode not working with inference mode on Tensor.item(),2023-08-24 20:27:31+00:00,,0,9,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: dynamic shapes""), Label(name=""module: pt2-dispatcher"")]"
107896,[feature request] [ux proposal] Min-max linear normalization to be supported in F.normalize (or in a new function),2023-08-24 20:13:45+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""topic: new features"")]"
107893,DISABLED test_conv_with_as_strided_cpu (__main__.FreezingCpuTests),2023-08-24 19:35:35+00:00,,0,2,"[Label(name=""module: rocm""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""skipped"")]"
107879,FakeMode should not fakify non persistent buffer,2023-08-24 17:43:49+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: pt2-dispatcher"")]"
107873,"[BE] Consolidation of SymNode methods constant_int, maybe_as_int, etc",2023-08-24 16:20:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
107865,Graph break: call_function partial in skip_files,2023-08-24 13:01:12+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107864,`C10_HOST_DEVICE` for `std::isnan(c10::complex<T>)`?,2023-08-24 12:06:07+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
107855,About the multi-node example not working properly,2023-08-24 07:44:12+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
107854,"""file_descriptor"" multiprocessing sharing strategy works incorrectly in dataloading ",2023-08-24 07:41:26+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
107842,nn.AdaptiveMaxPool2d returns identical results within a batch,2023-08-24 03:25:25+00:00,,0,3,"[Label(name=""high priority""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""bug"")]"
107841,Got Expand nodes with static shape input when exporting onnx model with dynamic shape ,2023-08-24 02:57:56+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
107830,FSDP custom args per module,2023-08-23 23:54:39+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
107824,torch.compile() fails when an `autograd.Function` gets called and torch.no_grad() is *not* being used,2023-08-23 22:08:03+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107821,`torch.distributions.Pareto.sample` sometimes gives `inf`,2023-08-23 21:36:32+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
107820,`add_image_with_boxes` method from `torch.utils.tensorboard.writer.SummaryWriter` is broken,2023-08-23 21:32:53+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
107800,[feature request] [discussion] Include basic `ctypes` bindings for `cudart`/`cublasLt`/`cublas`/`nvrtc`/`cudnn` with stock PyTorch,2023-08-23 18:10:56+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas"")]"
107797,"Fake Tensor error 'lengths' argument should be a 1D CPU int64 tensor, but got 1D meta Long tensor",2023-08-23 17:56:40+00:00,,0,3,"[Label(name=""triage review""), Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""mlperf""), Label(name=""module: pt2-dispatcher"")]"
107780,Add caffe2 ideep/onednn tests to OSS CI,2023-08-23 13:27:51+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
107774,DISABLED test_conv_stride_constraints (__main__.CPUReproTests),2023-08-23 09:59:31+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
107771,libtorch infer error : CUDNN_STATUS_INTERNAL_ERROR,2023-08-23 08:24:37+00:00,,0,1,"[Label(name=""oncall: jit"")]"
107770,libtorch vs (onnx+tensorRT) show different object detection results,2023-08-23 08:12:45+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
107751,conv cudnn support integers,2023-08-22 23:19:43+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
107739,DISABLED test_make_fx_symbolic_exhaustive_special_airy_ai_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-08-22 21:40:01+00:00,,0,18,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
107714,[ONNX] Retire FXSymbolicTracer in FX exporter,2023-08-22 17:12:08+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
107705,DISABLED test_multilayer_var_dynamic_shapes_cpu (__main__.DynamicShapesCpuTests),2023-08-22 16:25:27+00:00,,0,8,"[Label(name=""triaged""), Label(name=""skipped""), Label(name=""module: dynamic shapes"")]"
107703,"Hardtanh docs are inaccurate/incomplete, since hardtanh behaves like clamp",2023-08-22 16:03:51+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
107702,Inconsistencies when handling scalars that are out of the range relative to the input tensor's dtype,2023-08-22 15:43:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107701,arange.out produces incorrect output when out tensor has dtype long,2023-08-22 15:35:09+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
107700,where.self_out doesn't fail gracefully when inputs have different dtypes,2023-08-22 15:31:21+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: advanced indexing""), Label(name=""module: edge cases"")]"
107699,index.Tensor_out & index_put.out errors or segfaults with indices list containing only null tensors ,2023-08-22 15:26:46+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
107695,New variables in torch._ops.py pollute the torch.ops namespace,2023-08-22 14:48:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: library"")]"
107694,masked_fill_ outputs incorrect results for 'mps' tensor after transpose,2023-08-22 14:33:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
107693,Inconsistencies when casting to integral types,2023-08-22 13:37:37+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: arm""), Label(name=""module: int overflow"")]"
107691,"torch._dynamo.exc.Unsupported: call_function BuiltinVariable(zip) [ListVariable(), ListVariable(), ListVariable(), UserDefinedObjectVariable(KJTList)] {}",2023-08-22 13:17:33+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107685,Error in ONNX during Export GLU with Opset 18,2023-08-22 12:58:26+00:00,,0,7,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
107684,[Dynamo] 'NoneType' object is not subscriptable from torchrec (bad error message),2023-08-22 12:55:51+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
107680,torch.nn.functional.cross_entropy different loss when providing one_hot_target and class weights,2023-08-22 12:04:15+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
107678,[Torch.fx] Torch fx failed to trace torch extension library,2023-08-22 10:29:26+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
107668,torch.dot gives wrong result on Macos,2023-08-22 07:17:17+00:00,,0,4,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: correctness (silent)"")]"
107663,`RuntimeError: expected scalar type BFloat16 but found Float` with `torch.nn.TransformerEncoder`,2023-08-22 05:46:29+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: amp (automated mixed precision)"")]"
107661,A backward bug of dtensor seems to be caused by new_empty_strided,2023-08-22 04:12:13+00:00,,1,5,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: dtensor"")]"
107639,fullgraph=True doesn't actually raise error when you don't manage full graph inside DDP,2023-08-21 21:28:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107637,[DDP PT2] TypeError: convert_frame_assert.<locals>._convert_frame_assert() missing 2 required positional arguments: 'hooks' and 'frame_state',2023-08-21 21:18:25+00:00,,0,3,"[Label(name=""triage review""), Label(name=""module: performance""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""mlperf""), Label(name=""module: distributed"")]"
107631,torch.fx.Interpreter modules don't get compiled,2023-08-21 20:48:23+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
107630,torch._dynamo.exc.InternalTorchDynamoError: 'NoneType' object has no attribute 'guards',2023-08-21 20:46:10+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107627,ModuleNotFoundError: No module named 'torchgen.code_template',2023-08-21 20:36:44+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
107611,Previous version not found,2023-08-21 18:07:59+00:00,,0,3,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
107605,Support AMD Ryzen Unified Memory Architecture (UMA),2023-08-21 16:41:25+00:00,,0,0,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
107593,dynamo: don't graph break on ctx.mark_dirty,2023-08-21 14:15:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
107591,`repeat_interleave` does not support tensor indexes on different devices while `repeat` does,2023-08-21 14:03:25+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
107590,Select on a coalesced COO tensor returns COO tensor with coalesce flag set to False.,2023-08-21 13:50:13+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
107587,Run transformers.OPTForCausalLM(config=config) occurs 'GraphModule' object has no attribute 'compile_subgraph_reason',2023-08-21 12:27:49+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
107582,[FakeTensor] `to` doesn't error with `allow_non_fake_inputs=False`,2023-08-21 11:00:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
107581,[LibTorch/iOS] Building with METAL support script is freezing,2023-08-21 10:26:59+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
107580,Doc is unclear on how to install pytorch with Cuda via pip,2023-08-21 09:57:56+00:00,,0,9,"[Label(name=""triaged""), Label(name=""topic: docs"")]"
107575,halo，I continue pretrain llama2-13B model ，but save state_dict is about 50GB file,2023-08-21 07:46:21+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
107573,caching keys+values in TransformerDecoderLayer for faster inference,2023-08-21 07:25:47+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
107568,RuntimeError: Unsupported value kind: Tensor while torch.jit.script nn.Module,2023-08-21 04:00:42+00:00,,0,0,"[Label(name=""oncall: jit"")]"
107561,Dynamo guards on unused Tensor variables,2023-08-21 00:52:52+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107556,Integer multiplication overflow when running torch.nn.AdaptiveAvgPool2d,2023-08-20 17:56:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107555,Integer multiplication overflow when running torch.nn.MaxUnpool3d,2023-08-20 17:54:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107554,Integer multiplication overflow when running torch.diagflat,2023-08-20 17:53:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107553,Storage size calculation overflowed when torch.nn.Upsample,2023-08-20 17:52:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107552,Storage size calculation overflowed when running torch.nn.functional.interpolate,2023-08-20 17:37:18+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107550,Integer multiplication overflow when running torch.eye,2023-08-20 17:32:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107548,Integer calculation overflow when running torch.nn.functional.adaptive_avg_pool2d,2023-08-20 16:09:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107546,Integer overflow when running torch.nn.functional.upsample_bilinear,2023-08-20 13:15:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107545,Integer overflow when running torch.nn.functional.upsample,2023-08-20 13:12:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107544,Integer overflow when running torch.nn.ReplicationPad3d,2023-08-20 13:03:07+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107543,Integer overflow when running torch.nn.AdaptiveAvgPool2d,2023-08-20 12:24:46+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107541,Integer overflow when running torch.nn.MaxUnpool2d,2023-08-20 12:04:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107540,Index out of bound when running torch.gather,2023-08-20 12:01:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
107539,Integer overflow when running torch.nn.functional.max_unpool2d,2023-08-20 11:56:07+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: int overflow"")]"
107538,[fx] tracing function with in-place mutation results in unexpected behaviour due to local vars becoming persisted in  `GraphModule(nn.Module)`,2023-08-20 10:27:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
107536,Appending new logs to existing tbevent files when using tensorboard,2023-08-20 09:10:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
107534,NNPACK slow down M1/M2 Mac CPU,2023-08-20 06:36:34+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: nnpack"")]"
107528,Inconsistent results when running torch.arctanh,2023-08-19 23:16:26+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
107522,Export of `quantized::linear_relu` operator not supported with `torch.onnx.export`,2023-08-19 20:07:50+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
107514,conv2d wrong results on 3090/3090ti,2023-08-19 15:01:32+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: half"")]"
107503,[nightly][jit] bad constant exponent (e+38.f) in default_program fused_mul_div_add,2023-08-19 02:37:47+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
107494,Mismatch in type of error raised when reducing along empty slice between eager and primtorch,2023-08-18 23:38:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
107478,Adding batched CSR tensors with different sparsities produces an invalid tensor,2023-08-18 19:45:41+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""bug"")]"
107469,Reference cycles involving code -> co_extra -> compiled output -> reference to code,2023-08-18 16:40:11+00:00,,1,8,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107455,Moving tensor to MPS using .to(torch.device('mps') deletes entries from tensor,2023-08-18 14:12:51+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
107451,Conversion from COO with two sparse dimensions to CSR with dense_dim specified fails,2023-08-18 11:32:03+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged""), Label(name=""bug"")]"
107444,[testing] dynamo testing: we should call `dynamo.reset` before running each test with dynamo.,2023-08-18 08:13:03+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107443,Determinism by using datapipes shuffle,2023-08-18 06:53:17+00:00,,1,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: determinism"")]"
107441,The generated triton MaxPool2d kernel has poor performance on amd vega20/60,2023-08-18 04:52:53+00:00,,0,0,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: inductor""), Label(name=""rocm"")]"
107436,[FSDP]coding to multi-node save optimizer error,2023-08-18 03:39:26+00:00,,2,1,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
107435,make backward function explicit in a layer which is a combination of some ops,2023-08-18 03:00:37+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
107433,No checks when running torch.nn.functional.ctc_loss with bogus inputs,2023-08-18 02:34:31+00:00,,1,5,"[Label(name=""module: loss""), Label(name=""module: cpu""), Label(name=""triaged"")]"
107432,"Inconsistent results when running torch.nn.functional.embedding_bag on CPU (1.12.0, 1.13.0)",2023-08-18 02:32:42+00:00,,1,2,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: embedding"")]"
107429,Abort when running torch.set_num_interop_threads,2023-08-18 01:36:33+00:00,,0,2,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: single threaded"")]"
107426,DISABLED test_memory_format_nn_ConvTranspose1d_cuda_complex32 (__main__.TestModuleCUDA),2023-08-18 00:56:54+00:00,,0,10,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
107425,DISABLED test_wait_i_6 (__main__.TestMultiThreadedWait),2023-08-18 00:56:50+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
107424,DISABLED test_wait_i_5 (__main__.TestMultiThreadedWait),2023-08-18 00:56:47+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
107412,"max_pool1d, max_pool2d, max_pool3d Integers for cpu and cuda",2023-08-17 22:26:01+00:00,,0,4,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: pooling"")]"
107402,Multiple runners shutdown for an autoupdate while still running jobs,2023-08-17 18:41:02+00:00,,1,0,"[Label(name=""triaged""), Label(name=""ci: sev-mitigated"")]"
107396,[regression] Not getting `CUDA error: device-side assert triggered` on main for CUDA_KERNEL_ASSERT2,2023-08-17 17:06:18+00:00,,0,9,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: regression"")]"
107394,[LibTorch/iOS] Unknown custom class type quantized.Conv2dPackedParamsBase. Please ensure it is registered,2023-08-17 17:00:08+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
107392,Overly strict type hints for `torch.utils.data.random_split`,2023-08-17 16:53:23+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""module: typing""), Label(name=""triaged"")]"
107389,caffe does not respect CUDNN_LIB_DIR when building from source (cmake),2023-08-17 16:23:29+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: nvfuser"")]"
107387,Incorrect type hint for `torch.library.Library.define`,2023-08-17 16:17:24+00:00,,0,1,"[Label(name=""module: typing""), Label(name=""triaged""), Label(name=""module: library"")]"
107381,sparse_mask method ignores masked-in elements of sparse compressed input tensors,2023-08-17 15:09:50+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""bug"")]"
107374,DataParallel scatter method split tensor wrong,2023-08-17 10:31:31+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
107372,torch compile error with SyncBatchNorm,2023-08-17 09:57:13+00:00,,1,3,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107363,Regression in text encoding,2023-08-17 06:38:56+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""module: regression"")]"
107355,Getting more human-readable input and output names in the onnx model exported by torch,2023-08-17 03:44:49+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
107352,dist.scatter is incompatible with transpose/permute operation,2023-08-17 03:02:53+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
107321,"using Union[str, Tensor] as an argument to a torch.jit.script function",2023-08-16 19:14:50+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
107302,NumPy 2.0 Support,2023-08-16 15:50:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: python frontend"")]"
107298,dist.destroy_process_group did not destroy the process group well,2023-08-16 15:12:16+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
107294,"'MPS' training Issue(s) with NanoGPT: -Inf, NaN's",2023-08-16 12:55:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
107286,Sparse compressed tensor values autograd support is not implemented,2023-08-16 11:20:51+00:00,,1,0,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""bug"")]"
107278,DISABLED test_find_or_create_pg (__main__.TestPgTag),2023-08-16 03:40:41+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
107277,Translation layer (similar to torch_np) that can reliably lift Python operations into Tensor operations,2023-08-16 03:32:33+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
107276,CUBLAS_STATUS_NOT_SUPPORTED,2023-08-16 03:26:12+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas"")]"
107269,model.forward() get error with torch.compile() when using huggingface llama,2023-08-15 23:28:14+00:00,,1,13,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107256,`torch.float8_e4m3fn` does not support `torch.cat`,2023-08-15 20:52:10+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: float8"")]"
107253,Conda configuration shouldn't pollute $PATH variable,2023-08-15 20:21:51+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""module: ci""), Label(name=""triaged"")]"
107239,torch.compile not tracing ops on tensor subclass,2023-08-15 15:54:28+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
107238,How to export GNN with dict inputs correctly?,2023-08-15 15:43:12+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
107224,"[CPP API] Add Adadelta, Adamax, ASGD, NAdam, RAdam and Rprop",2023-08-15 12:20:41+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
107219,DISABLED test_RNN_input_size_zero (__main__.TestNN),2023-08-15 07:47:19+00:00,,0,2,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
107218,Documenting `__getitems__` for slicing support in `torch.utils.data`,2023-08-15 07:25:47+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: data"")]"
107217,Documenting `IterableDataset`'s needing `StopIteration` for finite data,2023-08-15 07:09:02+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: data"")]"
107214,The difference between input grad computed by channels last backward and the input grad computed by channels first backward of Hardswish on MPS is too large,2023-08-15 06:31:49+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
107211,[ONNX] ONNX doesn't support exporting non-persistent buffer included models in FakeMode,2023-08-15 05:12:10+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
107201,The difference between channels last backward and channels first backward of AvgPool2d on CUDA is too large,2023-08-15 02:15:38+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: memory format"")]"
107200,[inductor] [dynamic shape] 5 HF models fails with `Constraints violated` using transformers v4.31.0,2023-08-15 01:59:42+00:00,,1,10,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
107188,Can't construct a tensor from List[SymFloat],2023-08-14 23:33:27+00:00,,1,6,"[Label(name=""triage review""), Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo""), Label(name=""mlperf"")]"
107183,DISABLED test_RNN_dropout_state (__main__.TestNN),2023-08-14 22:24:35+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
107177,Timeout during NCCL initialization due to store,2023-08-14 21:23:07+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""better-engineering"")]"
107175,"sdp_kernel causes dynamo error on torch.compile(model, fullgraph=True)",2023-08-14 21:05:05+00:00,,1,1,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107174,Surface NCCL and CUDA version incompatibility,2023-08-14 20:57:28+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""better-engineering"")]"
107173,Dynamo test_vmap failures on Python-3.8,2023-08-14 20:39:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
107170,Torch randn cannot take symbol shapes as shape argument.,2023-08-14 20:09:04+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
107166,jit compilation returns an int rather than a bool when using math.isnan(),2023-08-14 19:36:55+00:00,,1,2,"[Label(name=""oncall: jit"")]"
107155,DISABLED test_learnable_forward_per_channel_cpu (quantization.core.test_workflow_ops.TestFakeQuantizeOps),2023-08-14 17:32:07+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""skipped"")]"
107143,[dynamo] calling __torch_function__ with dynamically created subclass of torch.Tensor fails compilation,2023-08-14 14:16:25+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: __torch_function__""), Label(name=""module: dynamo"")]"
107133,torch.inverse throws error when DP but not in DDP or single GPU,2023-08-14 12:14:26+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""module: linear algebra""), Label(name=""module: edge cases"")]"
107130,[docs] Document dtype conversions dtype.to_complex() dtype.to_real(),2023-08-14 11:03:26+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
107125,combining `vmap` with NN containing `MaxPool2d' leads to discrepancies in output,2023-08-14 09:18:31+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
107115,H100 works differently than rtx4090 on same model,2023-08-14 03:54:30+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
107114,DISABLED test_make_fx_symbolic_exhaustive_special_bessel_y1_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-08-14 03:39:36+00:00,,0,15,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: fx""), Label(name=""module: unknown"")]"
107112,from_blob python api,2023-08-14 03:21:14+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: python frontend"")]"
107102,Error when using sparse_coo tensor with optimizer,2023-08-13 18:00:25+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
107099,memoryview support for `torch._C.import_ir_module_from_buffer`,2023-08-13 14:00:02+00:00,,0,0,"[Label(name=""oncall: jit"")]"
107087,RuntimeError with operations on torch.float8_e5m2 and torch.float_e4m3fn data types,2023-08-12 16:21:00+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: float8"")]"
107081,[FSDP] summon_full_params won't change parameters,2023-08-12 08:02:07+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
107076,[Dynamo] Unable to Trace AdamW Optimizer when there is LR Scheduler,2023-08-12 02:59:47+00:00,,1,4,"[Label(name=""high priority""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
107055,"Build a check we can defer to runtime, potentially add to the graph",2023-08-11 19:27:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107054,"Extend dict  and by extension __dict__ modeling in dynamo to support `setdefault`, `get`",2023-08-11 19:23:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107053,Dynamo x FSDP - Issue Tracking Master Task,2023-08-11 19:21:39+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
107041,"I want to calculate the matrix multiplication of two Boolean matrices, but torch.mm will report an error. Is there any more efficient alternative?",2023-08-11 16:34:13+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: boolean tensor"")]"
107040,Dynamo not handling a NamedTuple ,2023-08-11 16:05:03+00:00,,1,2,"[Label(name=""triage review""), Label(name=""module: performance""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""mlperf"")]"
107026,a bug about tensor stride,2023-08-11 09:51:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
107023,"[feature request] [onnx] Support QuantLinear/DequantLinear float16 inputs (opset19 and maybe ""backport""-support them for opset17)",2023-08-11 09:34:02+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement"")]"
107021,torchrun： RendezvousConnectionError when use C10d on multi nodes,2023-08-11 09:25:17+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""oncall: r2p"")]"
107016,cov onnx error,2023-08-11 06:25:40+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
107011,max_pool3d_with_indices_backward_cuda does not have a deterministic implementation,2023-08-11 03:55:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""module: pooling"")]"
107006,Apply fusion more aggressively in NAdam and Adagrad compilation,2023-08-11 02:15:43+00:00,,0,7,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
107005,Dynamic shapes support for inductor foreach codegen,2023-08-11 02:05:48+00:00,,0,6,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor"")]"
107002,"RuntimeError: 0 INTERNAL ASSERT FAILED at ""../torch/csrc/jit/ir/alias_analysis.cpp"":615, please report a bug to PyTorch. We don't have an op for aten::full but it isn't a special case.  Argument types: int[], bool, NoneType, NoneType, Device, bool, ",2023-08-11 01:20:55+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106991,Add cutlass as an alternative backend of PT2 Inductor,2023-08-10 21:59:49+00:00,,1,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
106989,`ray` multiprocessing interference by torch import,2023-08-10 20:41:13+00:00,,0,2,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
106973,Facing error while using onnx from scatterelements,2023-08-10 15:31:38+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106972,RuntimeError: _Map_base::at when exporting squeeze,2023-08-10 15:13:58+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""module: autograd""), Label(name=""triaged"")]"
106971,Found two conflicting CUDA installs,2023-08-10 15:06:08+00:00,,0,8,"[Label(name=""module: build""), Label(name=""triaged"")]"
106967,ONNX Model Producing Different Results Compared to Original PyTorch and JIT Traced Model,2023-08-10 13:59:53+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106959,"`tensor.repeat` quirks: has no `torch.` variant, no `out=` variant, no inplace variant | `torch.tile` also does not have `out=` variant and uses `dims=` instead of `dim=`",2023-08-10 08:19:05+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping""), Label(name=""module: python frontend"")]"
106956,Readily available python wheels for windows ARM,2023-08-10 07:16:05+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: windows""), Label(name=""feature""), Label(name=""triaged"")]"
106951,stride of gradient is not same as the corresponding tensor,2023-08-10 05:56:14+00:00,,1,2,"[Label(name=""module: autograd""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
106942,[Minor Bug] Should consume_prefix_in_state_dict_if_present change ordering of keys?,2023-08-10 03:45:44+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
106939,Cannot export MiVOLO model into `onnx` format using `torch.onnx.export`,2023-08-10 03:00:04+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106931,Other overloads of `_foreach_clamp`,2023-08-10 00:55:01+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable""), Label(name=""module: mta"")]"
106894,[autograd.Function] freevar lifting is too aggressive?,2023-08-09 19:08:58+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
106893,[autograd.Function] torch.compile w/ once_differentiable leads to opaque graph break,2023-08-09 19:03:50+00:00,,1,9,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
106885,Dynamo graph break when using pyton module `heapq` (manipulates with `list`s),2023-08-09 18:18:11+00:00,,0,2,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: dynamo"")]"
106877,[ONNX] Float8 support,2023-08-09 17:38:49+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""low priority""), Label(name=""triaged"")]"
106873,[Dynamo] Integration exporter's diagnostic system into ONNXRuntime backend,2023-08-09 16:52:56+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106872,[Dynamo] revise ONNXRuntime backend's use of CapabilityBasedPartitioner,2023-08-09 16:49:22+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106871,[Dynam] a graph pass in Dynamo-ONNXRuntime backend needs revision,2023-08-09 16:45:49+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106869,[Dyanmo] Pre-allocate flag should be a ONNXRuntime inference session level attribute,2023-08-09 16:38:48+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106868,[Dynamo] ONNXRuntime backend (DORT) requires some guards to re-partition extracted by Dynamo,2023-08-09 16:34:46+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106867,[Dynamo] ONNXRuntime Backend Shold Allow External Allocator,2023-08-09 16:17:39+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106851,RPC all_gather doesn't work with dynamic world size (world_size=None),2023-08-09 08:05:50+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: rpc"")]"
106846,untimeError: The following operation failed in the TorchScript interpreter. Traceback of TorchScript (most recent call last): RuntimeError: nvrtc: error: invalid value for --gpu-architecture (-arch),2023-08-09 06:29:54+00:00,,0,0,"[Label(name=""needs reproduction""), Label(name=""oncall: jit"")]"
106845,`1/torch.inf` produce inconsistent results,2023-08-09 05:40:03+00:00,,1,4,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: type promotion""), Label(name=""module: edge cases"")]"
106828,Use expect tests for error inputs,2023-08-08 23:48:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: testing"")]"
106815,Please verify 1.14.1 ONNX release candidate on TestPyPI,2023-08-08 20:28:03+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: infra"")]"
106802,Optimizers should use learning rates passed as tensors directly,2023-08-08 16:14:52+00:00,,1,9,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: dynamic shapes"")]"
106801,"Timer benchmark stores only one time value, and therefore has broken mean/median/etc metrics",2023-08-08 16:03:51+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: benchmark"")]"
106784,"[ux] Suppot torch.tensor(set([1,2,3]))",2023-08-08 14:18:41+00:00,,0,4,"[Label(name=""triaged""), Label(name=""needs research""), Label(name=""topic: new features""), Label(name=""module: python frontend"")]"
106780,inf and nan are mapped to quant_min in torch.fake_quantize_per_tensor_affine,2023-08-08 13:32:31+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
106770,[Inductor][cpu] torchbench model doctr_det_predictor perf regression,2023-08-08 09:03:18+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
106764,[Feature request] Add new API Tensor.device_as ,2023-08-08 07:43:37+00:00,,0,0,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""module: python frontend"")]"
106748,[FX][ONNX][exporter] Failed to export traced fx graph to onnx model,2023-08-08 02:34:24+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""oncall: export"")]"
106732,Hugging Face safetensor does not work with FakeTensorMode,2023-08-07 22:46:02+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: pt2-dispatcher"")]"
106718,Add AMD image to the .devcontainer spec,2023-08-07 18:50:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
106717,Provide .devcontainer PyTorch - MPS environment,2023-08-07 18:48:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
106713,Dev Container Support for PyTorch,2023-08-07 17:51:14+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
106711,'CUDA out of memory' when using a GPU services for reinforcement learning in Torch rpc tutorial,2023-08-07 16:01:14+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: rpc"")]"
106704,Dataloader extremely slow on in-memory datasets,2023-08-07 13:46:00+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
106700,C++ API `torch::nn::MultiheadAttention` Crashes by division by zero,2023-08-07 11:36:32+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
106699,torch.jit.script: scripting doesn't work with wraps,2023-08-07 11:23:50+00:00,,0,0,"[Label(name=""oncall: jit"")]"
106692,torch.polygamma inconsistent with scipy.special.polygamma for n >= 1,2023-08-07 05:36:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: special"")]"
106690,DDP grads not synced when static_graph=True and module output is a dict subclass?,2023-08-07 04:34:47+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""module: pytree"")]"
106667,[docs] Idea collection of examples of custom ops / inline torch extensions,2023-08-05 17:13:57+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: custom-operators"")]"
106665,Inconsistency between CPU and GPU for `Linear()` layer with input size 0,2023-08-05 12:53:17+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: edge cases"")]"
106664,[docs] URL and link format proposal to make function page URLs more concise,2023-08-05 11:42:07+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
106662,Will torch.sparse.mm support multiplying two boolean matrices?,2023-08-05 09:52:28+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: boolean tensor"")]"
106660,Question about garbage collection without GPU sync ,2023-08-05 06:28:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
106649,Dynamo graph break on triplet_margin_with_distance_loss,2023-08-04 23:39:35+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
106637,Using retain_graph in backward() with FSDP,2023-08-04 21:44:48+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
106634,Confusing error message for DataLoader with num_workers=0 and non-zero timeout,2023-08-04 21:04:36+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
106633,Refcount problem for torch.distributed.Store objects defined in Python,2023-08-04 20:58:25+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
106630,no_grad() changes output of TransformerDecoder module during evaluation ,2023-08-04 18:47:08+00:00,,0,2,"[Label(name=""oncall: transformer/mha"")]"
106624,"[feature request] [ux] Frontend methods for fused  elementwise affine transform: mul+add+dtype convert + support  `integer_tensor.mul_(float_constant)` and `float_tensor.mul(some_constant, out = integer_tensor)` maybe via new args `rounding_mode=...` and `dtype=...` + maybe support OpenCV-style saturated dtype conversions (e.g. `clamp_` before conversion)",2023-08-04 17:37:47+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: python frontend"")]"
106623,Meta implementations of FFT operators often have incorrect strides,2023-08-04 17:25:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fft""), Label(name=""oncall: pt2"")]"
106622,FFT Samples Inputs with More than Three Dimensions,2023-08-04 17:22:25+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: fft"")]"
106614,Case study of torch.compile / cpp inductor on CPU: min_sum / mul_sum with 1d / matmul-like with static / dynamic shapes,2023-08-04 14:19:47+00:00,,0,17,"[Label(name=""triaged""), Label(name=""module: custom-operators""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: pt2-dispatcher"")]"
106608,ROCm & Windows Support,2023-08-04 09:08:01+00:00,,0,9,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
106606,More Performant CachingHostAllocator for Pinned Memory Allocation,2023-08-04 07:57:44+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
106604,Relu6 not able to process nan values,2023-08-04 07:01:39+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
106602, onednn ops supported in pytorch,2023-08-04 06:22:53+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: intel""), Label(name=""docathon-h2-2023"")]"
106601,[ONNX] Keep functional ops as functions in dynamo exported onnx,2023-08-04 06:12:15+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106596,[discussion] move-semantics for tensors,2023-08-04 02:52:42+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
106584,Lacking commutativity of `tensor.expand` and `tensor.flatten`,2023-08-03 23:23:15+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
106580,[dynamo] Unsupported to trace through Boolean Tensor indexing,2023-08-03 22:23:20+00:00,,1,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
106579,"Boolean valued images loaded from disk, when converted to torch int/float tensor, the True valued pixels gets converted to 255 instead of 1",2023-08-03 21:47:27+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: boolean tensor"")]"
106566,DTensor Sharding prop cache stats,2023-08-03 19:06:58+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: dtensor"")]"
106565,install cuda version always get cpuonly,2023-08-03 18:43:55+00:00,,0,1,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
106563,NotImplementedError: Could not run 'aten::multinomial' with arguments from the 'Meta' backend.,2023-08-03 18:19:04+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random"")]"
106557,DISABLED test_cpp_wrapper_cpu (__main__.FreezingCpuTests),2023-08-03 17:06:02+00:00,,1,1,"[Label(name=""triaged""), Label(name=""skipped""), Label(name=""oncall: pt2"")]"
106556,Pytorch: torch.autograd.grad returns NoneType,2023-08-03 16:41:36+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
106549,Can't build PyTorch 1.13.1 with Vulkan support,2023-08-03 15:25:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: vulkan""), Label(name=""ciflow/periodic"")]"
106546,Potential Issue with Pandas Dataframe,2023-08-03 12:44:33+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
106545,`softmax` to handle dimensions comprised of `-inf`,2023-08-03 10:59:35+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
106544,"Branch name in double quotes """"",2023-08-03 09:48:51+00:00,,1,5,"[Label(name=""module: ci""), Label(name=""triaged"")]"
106540,Dataset  with Queue issue,2023-08-03 08:50:38+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
106533,CUDA device support does not register allocator to c10::GetAllocator(...),2023-08-03 07:41:47+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: cuda""), Label(name=""triaged"")]"
106529,Pytorch + ROCm+ Windows,2023-08-03 06:13:09+00:00,,0,2,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
106520,Distributed torch.linalg.eigh (and other functions) on cuda using cuSOLVERMG,2023-08-03 03:12:55+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
106485,Increasing batch size makes network forward 1000 times slower,2023-08-02 21:48:59+00:00,,0,6,"[Label(name=""module: cudnn""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
106469,Extreme slowdown of torch.mm for certain sizes and strides with bfloat16,2023-08-02 17:48:04+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: bfloat16"")]"
106467,nn.CrossEntropyLoss with invalid target generates corrups memory eventualy leading to CUDA error: an illegal memory access,2023-08-02 16:24:15+00:00,,0,7,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
106457,AOTAutograd should detect false aliasing.,2023-08-02 13:54:19+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
106455,"vmap, jacrev, jacfwd, hessian, etc., in libTorch",2023-08-02 12:54:42+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""module: functorch"")]"
106450,Check for output_padding <= stride/dilation in ConvTranspose1d,2023-08-02 11:56:29+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: padding"")]"
106439,DISABLED test_aot_sequence_nr_dynamic_shapes (dynamo.test_aot_autograd.DynamicShapesAotAutogradFallbackTests),2023-08-02 03:40:53+00:00,,0,122,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
106435,"[JIT] .item() dict keys cause `RuntimeError: Cannot create dict for key type 'Scalar', only int, float, complex, Tensor, device and string keys are supported`",2023-08-02 00:33:29+00:00,,0,1,"[Label(name=""oncall: jit"")]"
106432,inconsistent dtype of scale and zero_point in observers,2023-08-01 23:38:28+00:00,,1,0,"[Label(name=""high priority""), Label(name=""oncall: quantization""), Label(name=""triaged"")]"
106427,`torch.nn.utils.clip_grad_norm_()` causes H2D sync with foreach ops.,2023-08-01 23:13:25+00:00,,0,15,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: mta"")]"
106408,PyTorchMPS not showing up in Instruments for `torch.mps.profiler`,2023-08-01 21:15:05+00:00,,1,8,"[Label(name=""triaged""), Label(name=""module: mps"")]"
106388,Better export story for autograd.Function?,2023-08-01 15:59:38+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
106387,[torch.compile] autograd.Function where we assign a Tensor directly to ctx,2023-08-01 15:56:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
106382,Installing torchvision for CPU leads to unwanted upgrade of torch + pip would not install nightly as considers that release is the latest (?),2023-08-01 15:07:53+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
106378,[dynamo] can't compile if tensor subclass implements __torch_function__ using super(),2023-08-01 12:13:47+00:00,,1,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
106377,Command to reproduce error is incorrect,2023-08-01 11:54:23+00:00,,0,2,"[Label(name=""good first issue""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: infra""), Label(name=""module: testing"")]"
106375,nll_loss reference shouldn't be registered as a decomposition.,2023-08-01 11:19:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: primTorch""), Label(name=""module: decompositions"")]"
106373,[ONNX] scatter_reduce does not support `include_self=False`,2023-08-01 09:02:58+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106362,Calling ops.aten.embedding_bag() function got silent crash,2023-08-01 04:00:04+00:00,,1,6,"[Label(name=""module: crash""), Label(name=""module: nn""), Label(name=""triaged"")]"
106361,DISABLED test_ddp_apply_optim_in_backward_ignored_params (__main__.TestDistBackendWithSpawn),2023-08-01 03:40:05+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
106360,Improving save_on_cpu's performance by overlapping memory transfers with compute,2023-08-01 03:38:31+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement"")]"
106359,backwards compatibility about class _LRScheduler,2023-08-01 03:00:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
106341,Transformer.generate_square_subsequent_mask has nan values on MPS device,2023-07-31 22:21:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: mps"")]"
106339,"ReduceLROnPlateau increases learning rate exponentially, causing training to diverge",2023-07-31 22:07:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
106338,Inefficient code generated - does not use 256b registers,2023-07-31 21:44:42+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
106308,DISABLED test_cuda_assert_should_not_stop_common_distributed_test_suite_cuda (__main__.TestTestingCUDA),2023-07-31 14:18:47+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""skipped"")]"
106302,`torch.nn.modules.MultiheadAttention` yields different graph under pre_dispatch tracing,2023-07-31 14:09:01+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: __torch_function__""), Label(name=""pre_dispatch tracing""), Label(name=""oncall: export"")]"
106298,Torch.onnx.export a fp16 model but get the output tensor fp32,2023-07-31 09:19:44+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
106297,Can't build with non-static protobuf,2023-07-31 08:59:59+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
106287,Many tests in test/dynamo fail if run in the context of just 'pytest test/dynamo',2023-07-31 01:15:31+00:00,,3,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: dynamo"")]"
106271,RuntimeError: GlooDeviceFactory::makeUVDevice(): interface or hostname can't be empty,2023-07-30 11:03:11+00:00,,0,11,"[Label(name=""oncall: distributed"")]"
106269,Make our source attribution debug prints more useful for Compiler Explorer,2023-07-30 03:27:21+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
106265,RuntimeError: Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'grad_y',2023-07-30 01:20:59+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: mps"")]"
106256,Runtime Error: Empty tensor,2023-07-29 09:16:35+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: mps"")]"
106251, Improve Error Message in MultiMarginLoss for Inconsistent Target Size,2023-07-29 06:31:31+00:00,,1,4,"[Label(name=""module: nn""), Label(name=""good first issue""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""actionable"")]"
106243,OneCycleLR's state_dict includes a full reference to the optimizer,2023-07-29 01:03:48+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: LrScheduler"")]"
106237,ghstack + mergebot race condition,2023-07-28 23:16:01+00:00,,1,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
106221,RProp improvement tracker,2023-07-28 20:24:53+00:00,,0,5,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
106220,torch compile does not work with torch.nn.functional.softmax ?,2023-07-28 20:21:10+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
106217,[dynamo.export] Assertion Error: Mutating module attribute during export.,2023-07-28 18:45:52+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
106206,Build failure due to C++ version mismatch,2023-07-28 14:52:48+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
106197,Scalar Tensor lowering to Fake Tensor inside Inductor,2023-07-28 09:07:18+00:00,,1,4,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""module: inductor""), Label(name=""module: dynamo"")]"
106183,[dynamo.export] symbolic_shapes.GuardOnDataDependentSymNode,2023-07-28 00:32:49+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
106173,`torch.ops.aten.split.Tensor._schema` return alias annotations are wrong,2023-07-27 22:39:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
106171,torch compile changes model output,2023-07-27 22:29:20+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
106164,distributed.batch_isend_irecv() crash when send/recv refers to itself,2023-07-27 21:00:27+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: crash""), Label(name=""module: c10d"")]"
106144,Pytorch nighlty and openAI/triton cuda,2023-07-27 17:16:16+00:00,,0,12,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
106141,Sparse COO indices are torch.Int64 -- is this necessary?,2023-07-27 16:00:42+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
106137,"`export(..., pre_dispatch=True)` for model in eval mode still inserts autograd ops",2023-07-27 15:37:34+00:00,,0,1,"[Label(name=""triaged""), Label(name=""pre_dispatch tracing""), Label(name=""oncall: export"")]"
106136,bc-linter false positive with TypeAliases,2023-07-27 15:34:59+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: devx"")]"
106135,Registering function that takes const std::vector<c10::SymInt>& to SymInt[] schema gives confusing error message,2023-07-27 15:13:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
106130,torch._subclasses.fake_tensor.DynamicOutputShapeException: aten.nonzero.default,2023-07-27 12:50:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
106129,Allow settingsetGraphExecutorOptimize default for all threads,2023-07-27 12:23:11+00:00,,0,0,"[Label(name=""oncall: jit"")]"
106128,Torchscript optimizer incorrectly applies constant propagation to convert prim::ListConstruct() into prim::Constant,2023-07-27 12:15:41+00:00,,0,0,"[Label(name=""oncall: jit"")]"
106126,Libtorch report C10 error when compiling on my own project,2023-07-27 09:47:22+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""module: cpp""), Label(name=""triaged"")]"
106124,[feature request] Better argument checks and error messaging for `tensor.repeat`,2023-07-27 08:43:39+00:00,,0,3,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""release notes: python_frontend"")]"
106121,Got error when train models with more than one param_group in torch2.0,2023-07-27 08:09:57+00:00,,0,5,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""has workaround"")]"
106112,MPS cumprod gradient is broken even when using cpu fallback on macos 13.2.1,2023-07-27 04:55:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
106110,llama model failed for dynamic shape path,2023-07-27 04:32:29+00:00,,2,10,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
106101,EMFORMER_RNNT not compilable,2023-07-27 02:00:59+00:00,,1,7,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
106073,Potential lack of CI testing on older NVIDIA GPU,2023-07-26 20:58:08+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
106067,"Tensors always get 0/1 specialization guards, even if they're not used",2023-07-26 19:35:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: guards"")]"
106050,"""Graph break: inline in skipfiles:"" is a bad message",2023-07-26 17:17:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
106046,Avoid incrementing refcount of `grad_fn` in `unpack_list`,2023-07-26 16:21:33+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: mta"")]"
106031,torch._dynamo.export does not support symbolic int inputs,2023-07-26 14:45:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""oncall: export"")]"
106029,[FSDP] Investigate sharded GPU gradient lifetime when CPU offloading,2023-07-26 13:02:45+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
106027,DISABLED test_profiler_cuda_sync_events (__main__.TestProfiler),2023-07-26 12:40:59+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
106011,Misleading error message in multilabel_margin_loss when passing incompatible tensor dimensions,2023-07-26 05:38:37+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
106006,[torch.compile] assertion sometimes ignored with inductor backend,2023-07-26 03:43:07+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105997,Flatbuffer torchscipt files don't load in PyTorch Android Lite 1.13.1,2023-07-26 02:35:08+00:00,,0,0,"[Label(name=""oncall: jit"")]"
105982,"vmap and rnn/lstm ""accessing '.data' under vmap transform is not allowed""",2023-07-25 23:03:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
105961,"Error in Profiler : RuntimeError: Expected !config.profile_memory to be true, but got false",2023-07-25 20:11:05+00:00,,0,1,"[Label(name=""oncall: profiler"")]"
105954,Ensure PRs are rebased on top of a recent commit (CI check),2023-07-25 18:51:37+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: devx"")]"
105944,ReplayRecordTests.test_fn_call_args and others fail on my local devserver,2023-07-25 17:22:24+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
105943,PT2 is not thread safe,2023-07-25 17:07:49+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105941,Differences in the results of conv2d calculations in PyTorch 1.8,2023-07-25 16:43:30+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
105934,Flip default on `add_zero_attn` in `torch.nn.MultiheadAttention` to `True`,2023-07-25 15:56:49+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
105933,DISABLED test_cross_entropy_large_tensor_reduction_sum_cuda (__main__.TestNNDeviceTypeCUDA),2023-07-25 15:39:35+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
105929,Dynamo silently ignores TorchDispatchMode,2023-07-25 14:48:28+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
105925,Possible speed up of nn.MultiheadAttention,2023-07-25 14:19:56+00:00,,0,1,"[Label(name=""oncall: transformer/mha"")]"
105918,Torch.jit : RuntimeError:  Unable to extract string literal index for ModuleDict,2023-07-25 13:01:29+00:00,,0,0,"[Label(name=""oncall: jit"")]"
105917,Torch.jit.frontend.NotSupportedError: not supporting functions with variable number of arguments.,2023-07-25 12:49:22+00:00,,0,0,"[Label(name=""oncall: jit"")]"
105916,Missing coalesced flag from `torch.autograd.Function.backward`,2023-07-25 12:41:36+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
105914,torch.compile(cpu) does not handle float16 properly,2023-07-25 12:08:42+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
105912,Batching rule for aten::bincount.,2023-07-25 09:54:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
105904,Libtorch linking Error:undefined reference,2023-07-25 08:07:17+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
105901,Default parameters missing of maxpool2d node generated by dynamo export,2023-07-25 06:57:17+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
105900,torch.jit.frontend.NotSupported when compiling stable-diffusion,2023-07-25 06:52:42+00:00,,0,0,"[Label(name=""oncall: jit"")]"
105878,FakeTensor detach() gives meta tensor other than FakeTensor under `torch._C._DisableTorchDispatch()`,2023-07-24 22:55:32+00:00,,0,3,"[Label(name=""triaged""), Label(name=""tensor subclass""), Label(name=""module: fakeTensor"")]"
105872,PyTorch 2.0.x `CUDA error: operation not supported` when `Tensor.to` a different device,2023-07-24 21:16:19+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: regression"")]"
105863,torch.compile does not respect branching in forward(),2023-07-24 19:03:33+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: guards"")]"
105860,Programmation error enabling unlegal memory access on gpu,2023-07-24 18:21:24+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: mps"")]"
105859,Report model flop utilization (mfu) in benchmark,2023-07-24 18:19:46+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105853,Bug when dealing with fallbacks on CPU,2023-07-24 17:10:14+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
105846,Strange backward behavior with sparse tensors,2023-07-24 15:49:50+00:00,,0,7,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
105840,[FSDP] FSDP doesn't work (random accuracy performance) when using `param_init_fn` and `sync_module_states=True`,2023-07-24 15:00:59+00:00,,1,19,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
105839,"MPS memory issue,  MPS backend out of memory, but works if I empty the MPS cache",2023-07-24 13:15:54+00:00,,0,4,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: mps"")]"
105838,Exporting the operator 'aten::grad' to ONNX opset version 18 is not supported.,2023-07-24 12:45:30+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""module: autograd""), Label(name=""triaged"")]"
105821,JIT input aliasing does not support aten::fill_,2023-07-24 03:51:54+00:00,,0,6,"[Label(name=""oncall: jit"")]"
105804,Conversion Error to ComplexDouble on MPS,2023-07-23 17:29:47+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: mps"")]"
105802,Errors while trying to finetune compiled transformers model,2023-07-23 15:31:23+00:00,,1,11,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
105799,inconsistent signature for dataloader in docs/source/data.rst,2023-07-23 10:54:35+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
105790,torch.sparse.mm() with reduce operator for GPU support and COO matrices,2023-07-22 11:01:24+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: reductions"")]"
105782,"DDP , error . [c10d] The client socket has timed out after 900s while trying to connect to (XX.XX.XX.XX, 8514). ",2023-07-22 05:22:37+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
105779,Mode to warm up PT2 with a regular eager mode execution,2023-07-22 04:07:21+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105778,https://pytorch.org/docs/stable/backends.html does not describe torch.backends.cpu,2023-07-22 02:55:01+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""actionable"")]"
105768,torch.compile uses more memory when using less parameters,2023-07-21 22:03:11+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105751,Revisit checkpoint naming mismatch with torch name (and ONNX initializer name as a consequence),2023-07-21 16:58:05+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105742,`torch.unique()` messes around with order even if `sorted=False`,2023-07-21 14:35:11+00:00,,1,10,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: sorting and selection""), Label(name=""docathon-h2-2023"")]"
105731,Pypi is missing dependencies,2023-07-21 13:38:50+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
105729,[FSDP] using CPUOffload cannot make the code runing stop,2023-07-21 08:50:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
105728,Compile error PyTorch 2.0.1 / GCC 13.1.0,2023-07-21 08:06:46+00:00,,1,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
105726,There is a big precision error between A100 and 3090 when using torch.matmul with fp16 precision,2023-07-21 06:56:04+00:00,,0,8,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: half"")]"
105723,Parameter ... has been marked as ready twice,2023-07-21 05:23:06+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
105716,Dynamo test pipeline failed on MaxPool2d test when changed to use f-string,2023-07-21 03:24:29+00:00,,1,1,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: dynamo"")]"
105706,Unable to build documents,2023-07-21 01:15:42+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
105700,Don't use weak ref finalization for freeing resources when code objects die,2023-07-21 00:22:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
105697,Support symmetry in einsum,2023-07-20 23:34:54+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
105686,Error using torch.compile with HF transformers and model `mosaicml/mpt-7b`,2023-07-20 20:09:56+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
105682,`torch.autocast(bfloat16)` runs bwd matmuls in fp16,2023-07-20 19:29:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
105665,Running Llama 2 on Apple Silicon GPUs - missing MPS types and operators,2023-07-20 15:31:09+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: mps"")]"
105655,Pytorch -  cpu only & caffe2 build failing,2023-07-20 11:52:16+00:00,,0,1,"[Label(name=""module: build""), Label(name=""caffe2""), Label(name=""triaged"")]"
105644,Tensor subclass is not preserved during backward with gradient checkpointing,2023-07-20 04:57:33+00:00,,0,3,"[Label(name=""module: checkpoint""), Label(name=""triaged""), Label(name=""module: __torch_function__""), Label(name=""tensor subclass"")]"
105641,Turn indexing with a scalar tensor into an copy into a view and avoid a D2H synchronization.,2023-07-20 04:37:14+00:00,,0,10,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing""), Label(name=""topic: bc breaking"")]"
105636,Syntax error when compileing Megatron-LM models.,2023-07-20 03:58:50+00:00,,0,2,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2"")]"
105635,FSDP with gradient checkpointing lead to redundant allgathers during backward,2023-07-20 03:48:09+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
105634,[inductor] unexpected dynamic shape error encountered in TritonTemplate,2023-07-20 03:15:20+00:00,,0,8,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
105632,torch.nn.TransformerDecoderLayer lacks parameter validation check,2023-07-20 02:41:58+00:00,,0,2,"[Label(name=""oncall: transformer/mha"")]"
105629,F.pad will accept 0 and negative values as parameter,2023-07-20 02:38:55+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: padding"")]"
105623,[ONNX] fix `test_fx_op_consistency.py` test failure when running on torch built with cuda,2023-07-20 00:40:38+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105597,Out of bounds error with `nn.MultiMarginLoss`,2023-07-19 20:29:18+00:00,,0,1,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105582,RFC: Integrating oneDNN Graph Compiler into Inductor C++/OpenMP Backend for Enhanced Graph Fusion and Performance,2023-07-19 18:53:52+00:00,,1,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
105572,Add color-coding to fx graph readable printouts :),2023-07-19 17:45:51+00:00,,0,0,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105570,Using scans,2023-07-19 17:43:39+00:00,,0,1,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105569,Lowering topk to reductions and pointwise when k is small,2023-07-19 17:43:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105568,Move Inductor-specific decompositions to general decomposition registrations.,2023-07-19 17:43:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105567,replication_pad1d,2023-07-19 17:43:28+00:00,,0,2,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105566,Reflection_pad1d,2023-07-19 17:43:26+00:00,,1,0,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105562,aten.multilabel_margin_loss_backward,2023-07-19 17:43:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105561,aten._cdist_backward,2023-07-19 17:43:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105560,aten._trilinear,2023-07-19 17:43:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105556,aten._cdist_forward,2023-07-19 17:43:02+00:00,,0,0,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105555,"Avoid calling AOTAutograd from AOTInductor, since Export has already done that",2023-07-19 17:43:00+00:00,,1,4,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105554,[easy] Add an option to force recompilation,2023-07-19 17:42:57+00:00,,0,1,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105548,torch.sparse.sampled_addmm doesn't compute gradients for 3D tensors,2023-07-19 17:23:18+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
105534,test_torchinductor_opinfo tracker,2023-07-19 13:53:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""hackathon""), Label(name=""oncall: pt2"")]"
105532,"tts_angular: fail_to_run, torch._dynamo.exc.Unsupported: call_method NNModuleVariable() flatten_parameters [] {}",2023-07-19 13:46:01+00:00,,2,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105530,convit_base: AssertionError: Mutating module attribute rel_indices during export.,2023-07-19 13:37:46+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105529,Efficient BMM for sparse-dense tensors,2023-07-19 13:20:29+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""topic: new features"")]"
105528,DISABLED test_conv_with_as_strided_dynamic_shapes_cuda (__main__.DynamicShapesCudaTests),2023-07-19 12:46:51+00:00,,0,5,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
105526,torch.onnx.export error,2023-07-19 10:32:19+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105520,[ONNX] Exporting the operator 'aten::exponential' to opset version 13 is not supported,2023-07-19 06:34:23+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105519,aten.bernoulli.p is missing in core aten IR opset but does not get decomposed,2023-07-19 06:18:20+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105515,[ONNX] FX produce valid node names in models,2023-07-19 01:32:13+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105499,[FSDP] Revisit mixed-precision casting logic,2023-07-18 20:50:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
105488,torch.save throws an error when the path uses mixed separators on Windows,2023-07-18 18:41:12+00:00,,1,6,"[Label(name=""module: windows""), Label(name=""triaged"")]"
105485,Specifying `FakeTensorMode` for Custom Backends,2023-07-18 17:58:33+00:00,,0,15,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105483,[OpInfo] index.Tensor,2023-07-18 17:55:03+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: testing"")]"
105471,[benchmark] Rename the count field FunctionCount,2023-07-18 15:35:02+00:00,,0,0,"[Label(name=""oncall: profiler"")]"
105465,"[proposal] Bit ops: e.g. setbit/getbit/togglebit/byteswap + introduce well-standardized unsigned dtypes (uint16, uint32, uint64)",2023-07-18 14:37:19+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: python frontend"")]"
105464,[ONNX] Support Fake Tensor Mode on new Dynamo based ONNX exporter,2023-07-18 14:35:44+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""release notes: onnx"")]"
105460,Specify version,2023-07-18 13:24:09+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
105457,Top level Glossary for users (not contributers),2023-07-18 10:00:10+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
105454,torch.onnx.export failed: torch.onnx.errors.SymbolicValueError: Unsupported: ONNX export of convolution for kernel of unknown shape,2023-07-18 08:59:37+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105448,Will nn.unfold support non-4D-tensor input in future version?,2023-07-18 07:13:59+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable"")]"
105447,DISABLED test_cross_entropy_large_tensor_reduction_none_cuda (__main__.TestNNDeviceTypeCUDA),2023-07-18 06:40:37+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
105445,Silent Error of torch.fx.symbolic_trace when forward hooks are registered,2023-07-18 04:14:50+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
105442,`vmap` causes unpredictable behavior when combined with `autocast`,2023-07-18 02:57:54+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""module: amp (automated mixed precision)""), Label(name=""module: functorch"")]"
105382,Need support and testing for Adam optimizer for MPS,2023-07-18 00:59:00+00:00,,1,10,"[Label(name=""high priority""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: mps"")]"
105379,FSDP loading with a partial state triggers KeyError,2023-07-18 00:32:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
105365,Quadric Layer,2023-07-17 22:44:45+00:00,,0,6,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
105349,torch.onnx.export does not support divisor_override in AvgPool2d,2023-07-17 18:28:57+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105348,FSDP Full Shard compatibility with BF16 AMP,2023-07-17 18:22:36+00:00,,1,20,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
105338,[ONNX] Refactor `test_fx_op_consistency.py`,2023-07-17 16:49:23+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
105335,Enable SLEEF on ARM,2023-07-17 16:26:15+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: sleef""), Label(name=""module: arm""), Label(name=""topic: improvements"")]"
105332,DISABLED test_super_resolution_cuda (__main__.TestModels),2023-07-17 15:39:37+00:00,,0,146,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
105329,Softmax doesn't support sparse tensors with the CSR layout,2023-07-17 15:27:16+00:00,,0,17,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""topic: new features"")]"
105328,TorchInductor Hack-a-Day on July 19th,2023-07-17 15:13:51+00:00,,3,0,"[Label(name=""triaged""), Label(name=""tracker"")]"
105326,Can't vmap over torch.tensor constructor,2023-07-17 14:37:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
105325,Padded tensor subclass,2023-07-17 14:32:16+00:00,,0,9,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""tensor subclass"")]"
105322,DeadKernel when training GNN for Cora on MPS,2023-07-17 12:55:46+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
105319,Implementation of torch.sparse.sampled_baddmm,2023-07-17 12:04:37+00:00,,0,13,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""topic: new features"")]"
105318,[docs] torch.sigmoid to make clear equivalence relations to other sigmoid functions,2023-07-17 11:50:31+00:00,,0,9,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable"")]"
105313,Failed to convert model that has LeakyReLU to ONNX,2023-07-17 08:38:49+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105311,Batching rule not implemented for aten::unsafe_chunk,2023-07-17 07:08:04+00:00,,0,1,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: vmap""), Label(name=""module: functorch"")]"
105304,"Backward pass with sparse parameters results in error ""Sparse division requires a scalar or zero-dim dense tensor divisor""",2023-07-17 05:03:46+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""module: loss""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
105299,Support ONNX opset 20 to export GELU to one single op,2023-07-17 01:34:38+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105290,Torch.compile Error: RuntimeError: aten::_conj() Expected a value of type 'Tensor' for argument 'self' but instead found type 'complex'.,2023-07-16 14:48:37+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
105281,Optimize PyTorch C++ part with Profile-Guided Optimization (PGO),2023-07-16 00:21:02+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105279,[Dynamo][Compile]Torch compile with dynamic shapes not working,2023-07-15 22:19:55+00:00,,0,25,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
105264,Inductor generates incorrect CPU code for `uint8` operations,2023-07-15 04:27:34+00:00,,1,20,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
105255,[discussion] Integrate widely used utilities from fvcore into the core repo,2023-07-14 23:18:45+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: LrScheduler"")]"
105254,DISABLED test_fused_optimizers_with_large_tensors (optim.test_optim.TestOptim),2023-07-14 22:52:09+00:00,,0,11,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
105254,DISABLED test_fused_optimizers_with_large_tensors (optim.test_optim.TestOptim),2023-07-14 22:52:09+00:00,,0,11,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
105253,DISABLED test_cross_entropy_large_tensor_reduction_mean_cuda (__main__.TestNNDeviceTypeCUDA),2023-07-14 22:51:42+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
105248,Multiple linux jobs are failing with version `GLIBCXX_3.4.30' not found ,2023-07-14 22:07:13+00:00,,0,6,"[Label(name=""module: ci""), Label(name=""triaged"")]"
105220,Significant time difference of calculating Jacobian matrix using jacrev and oracle functions,2023-07-14 14:33:21+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: functorch"")]"
105217,Export+AOTInductor issue tracker,2023-07-14 13:21:55+00:00,,2,18,"[Label(name=""triaged""), Label(name=""tracker"")]"
105214,[DTensor] Dtensor API should report the correct device when GPU is used,2023-07-14 09:45:40+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: dtensor"")]"
105213,[DTensor] Module parallelized with ColwiseParallel should return a sharded tensor,2023-07-14 09:09:17+00:00,,1,11,"[Label(name=""triaged""), Label(name=""module: dtensor"")]"
105211,autocast + torch.no_grad inference cause backward graph nodes to be lost,2023-07-14 08:40:18+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
105203,Pytorch dataloader not loading first-available data with multiple workers,2023-07-14 04:38:49+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
105196,Error loading TorchScript model with torchvision::nms operation in libtorch,2023-07-14 02:34:46+00:00,,0,0,"[Label(name=""oncall: jit"")]"
105192,Repro str could be displayed with slightly wrong env vars,2023-07-14 01:06:00+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""actionable"")]"
105181,"torch.compile leaks memory after compiled object is deleted, no apparent way to clean",2023-07-13 21:45:35+00:00,,1,6,"[Label(name=""needs reproduction""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
105157,PT2 custom ops does not work with future annotations,2023-07-13 17:55:49+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: custom-operators""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
105134,TypeError: 'NoneType' object is not subscriptable (Occurred when translating col2im). Can't translate torch.nn.functional.fold in opset_version 18.,2023-07-13 08:08:47+00:00,,0,7,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105125,DISABLED test_conv (quantization.jit.test_quantize_jit.TestQuantizeJit),2023-07-13 06:11:39+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
105124,DISABLED test_conv_transpose (quantization.jit.test_quantize_jit.TestQuantizeJit),2023-07-13 06:09:33+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
105123,DISABLED test_observer_with_ignored_function (quantization.jit.test_quantize_jit.TestQuantizeJit),2023-07-13 06:06:54+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
105121,DISABLED test_single_linear (quantization.jit.test_quantize_jit.TestQuantizeJit),2023-07-13 06:04:39+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
105120,DISABLED test_nested (quantization.jit.test_quantize_jit.TestQuantizeJit),2023-07-13 06:00:30+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
105119,DISABLED test_unary_ops (__main__.TestTensorExprFuser),2023-07-13 05:57:00+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
105108,MacOS arm64 runners are not available in CI,2023-07-13 01:42:24+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
105105,Remaining functions without meta registrations,2023-07-13 00:52:18+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: meta tensors"")]"
105494,workaround for using vmap when .item() is being used internally,2023-07-12 22:26:39+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""module: functorch"")]"
105092,[RFC] Proposal to upgrade LLVM version,2023-07-12 21:32:57+00:00,,0,7,"[Label(name=""triaged""), Label(name=""NNC""), Label(name=""module: cpu inductor"")]"
105077,torch.load fails under FakeTensorMode for GPT2 model,2023-07-12 18:30:25+00:00,,1,4,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: dynamo""), Label(name=""release notes: dynamo""), Label(name=""module: pt2-dispatcher"")]"
105073,[ONNX] Support aten::var_mean,2023-07-12 17:49:56+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105068,[linalg] test_ops.py::test_python_ref_meta__refs_linalg_svd_cpu_complex failing,2023-07-12 16:41:03+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: meta tensors"")]"
105066,test_view_dynamic_zero_dim no longer testing zero input,2023-07-12 15:57:07+00:00,,1,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
105062,[feature request] make the input k in rot90 a list of int to rotate tensors individually in a batch,2023-07-12 14:39:31+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
105062,[feature request] make the input k in rot90 a list of int to rotate tensors individually in a batch,2023-07-12 14:39:31+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
105060,extra information messages for mac in setup.py would help. ,2023-07-12 14:28:12+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged"")]"
105058,Support Delay Loading of c10.dll in when using libtorch as a thirdparty library.,2023-07-12 14:16:21+00:00,,0,0,"[Label(name=""module: windows""), Label(name=""module: abi""), Label(name=""triaged"")]"
105053,Multiple dimensions support for `torch.max`,2023-07-12 11:05:11+00:00,,0,10,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""needs design""), Label(name=""module: python frontend"")]"
105042,"`assert has_same_metadata(inpt_new, inpt_old)` fails when capturing forwards + backwards in train_step with resnet18",2023-07-12 06:02:13+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
105024,DISABLED test_homogeneous_attributes (__main__.TestFSDPMiscMultiThread),2023-07-12 00:59:24+00:00,,2,7,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: fsdp"")]"
105013,DISABLED test_compile_vmap_hessian_cuda (__main__.TestCompileTransformsCUDA),2023-07-11 21:46:35+00:00,,0,3,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
104998,[export] tensor creation ops burn in device,2023-07-11 19:48:40+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
104981,NotImplementedError: Could not run 'aten::_spdiags' with arguments from the 'CUDA' backend.,2023-07-11 15:15:08+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
104962,Add a diagram showing the code structure to CONTRIBUTING.md ,2023-07-11 13:08:07+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
104959,Saving a LightningModule torch.jit.ScriptModule is incompatible with torch.amp.autocast,2023-07-11 12:33:15+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""has workaround""), Label(name=""module: amp (automated mixed precision)"")]"
104952,[Inductor] [CPU] performance regression with TORCHINDUCTOR_FREEZING=1,2023-07-11 09:14:54+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
104949,ONNX export process  failed to keep consistence of input_names specified,2023-07-11 08:34:37+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
104943,[torch.compile] RuntimeError during Gradient Computation in torch.compile(),2023-07-11 05:58:55+00:00,,1,3,"[Label(name=""triaged""), Label(name=""has workaround""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
104935,torch version compare,2023-07-11 03:37:13+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
104925,Unnecessary record_stream call for backend:cudaMallocAsync,2023-07-11 02:06:09+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""module: logging""), Label(name=""triaged"")]"
104913,StableDiffusion with dynamic=True still recompiles,2023-07-10 23:04:50+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
104906,torch.jit.frontend.NotSupportedError: keyword-arg expansion is not supported: for dgl.nn.HeteroGraphConv(),2023-07-10 21:01:49+00:00,,0,3,"[Label(name=""oncall: jit"")]"
104899,Refactor Adam and AdamW by abstracting out common code,2023-07-10 19:26:26+00:00,,1,7,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
104884,[dynamo][higher_order_op] assert in check_kwargs leads to error instead of graph-break,2023-07-10 17:19:36+00:00,,0,1,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
104880,torch.onnx.export does not respect nn.Module.forward API when using export_modules_as_functions=True,2023-07-10 16:28:56+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
104878,DISABLED test_custom_op_cuda_cuda_wrapper (__main__.TestCudaWrapper),2023-07-10 15:40:22+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
104875,torch/testing/_comparison.py: If you are a user and see this message during normal operation please file an issue,2023-07-10 14:28:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: testing"")]"
104872,errors in CONTRIBUTING.md,2023-07-10 13:56:56+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
104868,Conversion of a CSR tensor with batches to COO tensor fails,2023-07-10 13:09:41+00:00,,1,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
104867,rfftn and irfftn operations in pt2 return different results compared to v1.12.1,2023-07-10 12:19:05+00:00,,0,8,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: third_party""), Label(name=""module: fft"")]"
104860,torch.nn.Conv2d's padding mode circular cannot accept 3-dim input,2023-07-10 07:06:15+00:00,,1,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
104857,Torch's `LayerNorm` and Adam optimizer vs those in tensorflow,2023-07-10 02:44:26+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: numerical-stability""), Label(name=""module: nn""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
104856,DISABLED test_custom_op_cuda (__main__.CudaTests),2023-07-10 00:58:14+00:00,,0,22,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
104854,DISABLED test_custom_op_cpu_dynamic_shapes_cpp_wrapper (__main__.DynamicShapesCppWrapperCpuTests),2023-07-10 00:58:09+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
104853,torch.norm inconsistency?,2023-07-10 00:44:49+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
104849,[feature request] torch.mix function to generalize/symmetrize addcmul,2023-07-09 22:59:58+00:00,,0,6,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: python frontend"")]"
104845,Implement `diag` method for sparse COO tensors,2023-07-09 16:03:54+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
104832,"MPS matmul with sliced (strided) out argument produces wrong output, may corrupt memory",2023-07-09 00:20:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
104823,Unrelated error messages with torch.nn.AdaptiveAvgPool3d,2023-07-08 09:00:01+00:00,,1,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling"")]"
104933,torch.func.jvp fails with BERT training,2023-07-08 03:37:16+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: forward ad""), Label(name=""module: functorch"")]"
104817,[RFC] Let in-place foreach functions return a list of Tensors,2023-07-08 01:12:07+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mta"")]"
104814,[compile][dynamic] dsplit is seeing a list of mixed ints and symints,2023-07-08 00:38:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
104808,PyTorch built with CuDNN-8.8.1 crashes if CuDNN-8.9.2 is installed on the system,2023-07-07 22:24:00+00:00,,2,0,"[Label(name=""module: cudnn""), Label(name=""module: ci""), Label(name=""triaged"")]"
104791,"inductor/triton fails on `view(..., dtype=torch.int16)`",2023-07-07 18:54:39+00:00,,0,7,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
104789,[BE] Evaluate and improve eager for-loop optimizer memory perf,2023-07-07 18:38:04+00:00,,1,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
104788,Use `isinstance` instead of `type` when checking for `torch.nn.Parameter`,2023-07-07 18:35:54+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
104776,torch.nn.CrossEntropyLoss: class weighting changes label_smoothing,2023-07-07 15:41:47+00:00,,2,4,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
104775,Subgraph matcher returned a false match,2023-07-07 15:22:00+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""oncall: pt2"")]"
104768,Support for `eval` in functional_call,2023-07-07 11:08:07+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: functional UX"")]"
104761,"Torch Filename Storage hangs on ""file_system"" sharing strategy after in-place fill",2023-07-07 05:36:36+00:00,,0,5,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: mps"")]"
104755,fsdp load model causing insufficient CPU memory,2023-07-07 02:38:39+00:00,,2,3,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
104748,torch._dynamo.exc.InternalTorchDynamoError: Could not run 'aten::_local_scalar_dense' with arguments from the 'Meta' backend,2023-07-06 23:37:55+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
104739,Error reporting uses formal parameter names of downstream C++ function,2023-07-06 22:09:37+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
104737,DISABLED test_vmapvjpvjp_linalg_lu_factor_ex_cuda_float32 (__main__.TestOperatorsCUDA),2023-07-06 21:39:57+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: functorch"")]"
104732,"torch.jit.trace says ""Arguments for call are invalid"" on torch.ops.aten.sub(3, x, alpha=3)",2023-07-06 20:08:35+00:00,,0,0,"[Label(name=""oncall: jit"")]"
104729,Add support for NEON ISA in the Inductor C++ backend,2023-07-06 19:33:55+00:00,,0,17,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: inductor"")]"
104719,Nondeterministic segfault in test_content_store.py under Dynamo config,2023-07-06 18:13:56+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: dynamo"")]"
104712,torch.jit slicing error (styleganv2),2023-07-06 16:43:20+00:00,,0,2,"[Label(name=""oncall: jit"")]"
104711,New Loss Function Add In Pytorch,2023-07-06 15:49:43+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: loss""), Label(name=""triaged"")]"
104704,generate_vmap_rule=True sometimes gives batched grad_output,2023-07-06 14:02:02+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
104702,[feature request] Specialized memory layouts and wide blocked/tiled dtypes for cublasLt/onednn: e.g. torch.float16x32 / torch.int8x32 / torch.bits1x512 (akin to torch.quint2x4),2023-07-06 12:26:26+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: memory format"")]"
104701,System memory leak when using different input size of torch.nn.Conv3d,2023-07-06 12:17:30+00:00,,0,3,"[Label(name=""module: cudnn""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
104698,Incorrect Error Message Ordering for nn.AdaptiveAvgPool2d with Incorrect output_size ,2023-07-06 10:31:43+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
104697,LSTM built-in dropout not reproducible on GPU,2023-07-06 10:23:34+00:00,,0,2,"[Label(name=""module: cudnn""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: random"")]"
104695,DISABLED test_cuda_memory_leak_detection (__main__.TestCudaMultiGPU),2023-07-06 09:39:51+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
104678,torch._dynamo.export does not work with bert model,2023-07-06 00:25:53+00:00,,0,5,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
104674,[compile] DDPOptimizer + activation checkpointing not supported,2023-07-05 23:12:24+00:00,,0,3,"[Label(name=""module: checkpoint""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
104653,"vision_maskrcnn: AssertionError: expected size 368==368, stride 156==28 at dim=0",2023-07-05 19:16:30+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
104623,I propose a new overview section in the documentation,2023-07-05 11:43:06+00:00,,0,8,"[Label(name=""triaged""), Label(name=""topic: docs"")]"
104620,`torch.distributed.rpc.backend_registry.register_backend` fails to update `BackendType` enum,2023-07-05 08:36:54+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
104610,"torch.compile fails with ""INTERNAL ASSERT FAILED"" when compiling GPT-2",2023-07-04 21:26:11+00:00,,1,10,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
104606,"Failure in optimize_for_mobile when using conv1d(..., padding='same')",2023-07-04 19:02:39+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: mobile"")]"
104602,"F.adaptive_avg_pool3d(input, 1) returns infinity in half precision",2023-07-04 14:16:11+00:00,,0,0,"[Label(name=""module: numerical-stability""), Label(name=""module: nn""), Label(name=""module: cpu""), Label(name=""triaged"")]"
104598,ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE.,2023-07-04 12:40:42+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged"")]"
104593,Bug in Conv/BN fuser with torch.fx,2023-07-04 09:50:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""oncall: fx"")]"
104591,version libcudnn_ops_infer.so.8 not defined in file libcudnn_ops_infer.so.8 with link time reference,2023-07-04 08:43:35+00:00,,0,15,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
104589,Issue with FSDP does not reduce memory footprint  when scaling up GPUs,2023-07-04 08:27:51+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
104587,Conv1d step-by-step numerical error ,2023-07-04 08:06:20+00:00,,1,12,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: determinism""), Label(name=""module: arm"")]"
104568,Init_rpc() errors when running the test code in the TorchPRC document on two different machines ,2023-07-04 02:23:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
104536,torch compile for jacrev'ed function,2023-07-03 20:02:34+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
104531,[RFC] Optional Modular Representation for FX Graph from `torch.compile()`,2023-07-03 16:46:08+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
104516,vec_test_all_types_xxx with dtype c10::complex<float> and c10::complex<double> has failures on division,2023-07-03 05:41:28+00:00,,1,3,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: vectorization"")]"
104510,"Using the latest version of Torch, when the code executes tcpstore, there is no response",2023-07-02 17:33:42+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
104507,[error] while Implementation of pytorch DistributedParallel,2023-07-02 07:34:19+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
104506,TImeout in NCCL doesn't work,2023-07-02 07:33:57+00:00,,1,13,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
104505,Wrong functionalization of as_strided leads to wrong results,2023-07-02 06:25:03+00:00,,1,3,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
104502,Get errors after compiling and running PyTorch MINIMAL EXAMPLE for c++ Mac M1 with make,2023-07-02 01:14:36+00:00,,0,10,"[Label(name=""module: binaries""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
104479,FSDP Optimizer Overlap - follow ups,2023-06-30 19:37:28+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
104472,Investigate numerical stability of forward-mode AD of some foreach functions,2023-06-30 18:03:18+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: forward ad"")]"
104466,`torch.view_as_real(tensor)` should return `nn.identity(tensor)` if its not complex instead of raising an error,2023-06-30 15:56:35+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex"")]"
104458,[Feature Request] Add a new overload of torch::jit::load to restore traced shape and type ,2023-06-30 03:33:16+00:00,,0,0,"[Label(name=""oncall: jit"")]"
104454,DISABLED test_nnc_correctness_frac_cpu_bfloat16 (__main__.TestNNCOpInfoCPU),2023-06-30 01:15:08+00:00,,0,1,"[Label(name=""skipped""), Label(name=""NNC"")]"
104452,[ONNX][TypePromo] Automate codegen type promotion rules,2023-06-30 00:56:30+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
104450,"Numpy/scipy module works fine with Torch modules, but not TorchScript. How to torchscript a numpy/scipy module?",2023-06-30 00:29:43+00:00,,0,4,"[Label(name=""oncall: jit"")]"
104435,torch.compiled model output gets overwritten despite tensor.detach(),2023-06-29 19:35:52+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
104421,LibTorch 2.0.1 scripting in Debug mode on Windows,2023-06-29 16:29:46+00:00,,0,2,"[Label(name=""module: windows""), Label(name=""module: cpp""), Label(name=""triaged"")]"
104417,Support CUDA 12.2 ,2023-06-29 15:58:24+00:00,,0,20,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
104411,"RuntimeError: t == DeviceType::CUDA INTERNAL ASSERT FAILED at HIPGuardImplMasqueradingAsCUDA.h:60, please report a bug to PyTorch",2023-06-29 13:44:13+00:00,,0,0,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
104405,Detailed error: Tensor-likes are not close! When use torch.jit.trace,2023-06-29 11:50:26+00:00,,0,5,"[Label(name=""oncall: jit"")]"
104403,Inconsistencies in ONNX exporting of operation `torch.full()`,2023-06-29 10:05:56+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""OSS contribution wanted"")]"
104389,distributed hooks want to support custom device,2023-06-29 01:29:39+00:00,,2,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
104367,FakeTensor can't handle meta impls that perform device conversion,2023-06-28 19:26:20+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
104366,DISABLED test_conv3d_64bit_indexing_cuda (__main__.TestConvolutionNNDeviceTypeCUDA),2023-06-28 18:52:41+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
104361,ReduceLROnPlateau will throw IndexError: list index out of range with modified optimizer's param_groups.,2023-06-28 18:25:10+00:00,,0,5,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: LrScheduler"")]"
104342,"Segmentation error while using F.cross_entropy with mps(for code that works fine with device= ""cpu"")",2023-06-28 13:07:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
104328,DISABLED test_backward_ddp_inside (__main__.TensorPipeDdpUnderDistAutogradTest),2023-06-28 06:44:26+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
104322,Illegal Memory Access on H100 `TestSparseCompressedTritonKernelsCUDA.test_triton_sampled_addmm_block_size_16_cuda_bfloat16`,2023-06-28 06:13:44+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
104315,Torch randperm with device mps does not sample exactly uniformly from all possible permutations,2023-06-28 01:46:01+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: mps"")]"
104301,Attempt to use minifier on sam model fails,2023-06-27 21:58:34+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: minifier"")]"
104297,"torch.distributed.all_to_all_single & alltoall_base, size limit INT_MAX",2023-06-27 21:01:43+00:00,,1,1,"[Label(name=""oncall: distributed"")]"
104296,affine_grid and grid_sample operators merge/accelleration,2023-06-27 21:01:03+00:00,,0,29,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""triaged"")]"
104289,getattr on `__slots__` object potentially suspicious,2023-06-27 20:25:07+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
104284,`F.conv1d` and `F.conv2d` propagate `nan`'s incorrectly when minibatch > 15,2023-06-27 19:26:33+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: NaNs and Infs""), Label(name=""module: arm"")]"
104282,Rename `topic: not user facing` to `release notes: not user facing`,2023-06-27 19:10:53+00:00,,0,0,"[Label(name=""triaged"")]"
104265,torch._dynamo.exc.TorchRunTimeError in get_fake_value while performing quantization aware training,2023-06-27 16:23:33+00:00,,1,7,"[Label(name=""oncall: quantization""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
104259,ImportError: libcudnn.so.8: cannot open shared object file: No such file or directory,2023-06-27 14:32:48+00:00,,0,16,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
104258,[FSDP] `ignored_states` is broken with auto wrap,2023-06-27 14:31:27+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
104252,[RFC] Make `_HYBRID_SHARD_ZERO2` public as `HYBRID_SHARD_GRAD_OP`,2023-06-27 12:18:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
104247,"[proposal] ""Name"" string attribute for modules, parameters, buffers, tensors for more pleasant debugging (especially for graph printouts / export / studying compiled generated code)",2023-06-27 10:29:24+00:00,,0,11,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs design"")]"
104244,DISABLED test_mem_get_info (__main__.TestCudaMultiGPU),2023-06-27 09:39:30+00:00,,0,31,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
104230,[ONNX] Investigate `nn.functional.nll_loss` skip/xfail reason,2023-06-27 03:19:10+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
104195,Torchscript with dynamic quantization produces inconsistent model outputs,2023-06-26 16:52:51+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
104194,View ops on fake tensors can dispatch `detach`es to backend kernels,2023-06-26 16:37:04+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
104193,Conversion from strided to batched sparse compressed tensor with a non-constant number of zeros in batches fails,2023-06-26 16:26:47+00:00,,1,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
104191,torch.embedding: Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.,2023-06-26 14:55:11+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: bfloat16""), Label(name=""module: mps"")]"
104188,Add memory managemenet information for Apple silicon mps backend,2023-06-26 13:55:04+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: mps"")]"
104175,No document for parameter `load_debug_files` in `torch::jit::load` in C++ API,2023-06-26 07:53:27+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable"")]"
104174,distributed.scatter memory leak in source rank,2023-06-26 07:44:44+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: memory usage"")]"
104168,Incorrect Reduce collective result with `_coalescing_manager` ,2023-06-26 00:46:38+00:00,,1,2,"[Label(name=""oncall: distributed"")]"
104164,DDP enhancement ,2023-06-25 19:37:54+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
104163,Nested Tensor with PyG dataset custom class,2023-06-25 19:14:06+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""actionable"")]"
104162,"Network does not return any thing, not even None and breaks loops",2023-06-25 18:34:09+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: windows""), Label(name=""triaged""), Label(name=""module: third_party"")]"
104154,Numbers bigger than the range should be inf while the implementation just keeps the original.,2023-06-25 07:52:04+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
104152,Error 101: invalid device ordinal (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.),2023-06-25 04:06:16+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: third_party"")]"
104147,PyTorch2.0 ROCM LayerNorm HIP error: invalid configuration,2023-06-24 18:55:11+00:00,,0,6,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
104146,make_fx: torch.where scalar promotion burns in device,2023-06-24 17:24:36+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
104144,[ONNX] Support symbolic tracing without using external `FakeTensorMode` on public API,2023-06-24 15:28:06+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""release notes: onnx"")]"
104128,Python Crashes When Importing Torch With C API,2023-06-23 21:40:09+00:00,,1,18,"[Label(name=""needs reproduction""), Label(name=""module: windows""), Label(name=""triaged""), Label(name=""module: third_party"")]"
104119,Re-enable `test_typing`,2023-06-23 18:57:45+00:00,,0,2,"[Label(name=""module: typing""), Label(name=""module: ci""), Label(name=""triaged"")]"
104113,Documentation building fails due to torchgen,2023-06-23 17:09:53+00:00,,0,7,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable"")]"
104107,Tensor to_sparse fails on large matrices,2023-06-23 16:21:58+00:00,,0,8,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
104106,batch size unexpectedly affects model inference on Mac M1,2023-06-23 15:32:46+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
104102,Inductor does not check input SymInt invariant on GraphModules passed in,2023-06-23 13:29:40+00:00,,0,12,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor"")]"
104095,(Possible) Memory leak on deleting a compiled model,2023-06-23 08:08:38+00:00,,1,8,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""module: cuda graphs""), Label(name=""oncall: pt2"")]"
104093,RuntimeError: _ivalue_ INTERNAL ASSERT FAILED,2023-06-23 08:01:43+00:00,,0,0,"[Label(name=""oncall: jit"")]"
104088,Regressions with torch.compile + amp + ddp with recent nightly builds,2023-06-23 04:00:54+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
104081,Distributing HSDP checkpoint writing for load balancing ,2023-06-23 00:22:03+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
104053,Tracking issue for optimizer graph not being an inference graph,2023-06-22 18:23:52+00:00,,0,2,"[Label(name=""triaged""), Label(name=""tracker""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
104047,[torch.compile] torch._dynamo.exc.TorchRuntimeError: Failed running call_function <built-in method normal of type object at ***: got an unexpected keyword argument 'device',2023-06-22 17:21:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""oncall: pt2""), Label(name=""module: decompositions"")]"
104045,"""TorchDynamo Deeper Dive"" doc is missing some part",2023-06-22 15:30:31+00:00,,1,1,"[Label(name=""triaged""), Label(name=""topic: docs"")]"
104043,Torch.compile tutorial shows incorrect triton kernel,2023-06-22 14:18:18+00:00,,1,1,"[Label(name=""triaged""), Label(name=""topic: docs"")]"
104041,Scripted model is loaded on GPU but the inference seems to utilize the CPU with zero GPU utilization,2023-06-22 13:47:39+00:00,,0,1,"[Label(name=""oncall: jit"")]"
104040,Improved error checking for custom Function when saving intermediates,2023-06-22 13:35:38+00:00,,0,0,"[Label(name=""module: double backwards""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
104033,Reproducibility documentation should be updated,2023-06-22 09:30:45+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
104029,SummaryWriter.add_embedding not working for RGBA images,2023-06-22 07:40:56+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: tensorboard"")]"
104026,Is memory-efficient FSDP initialization intended to be possible with torch.device('meta')?,2023-06-22 06:37:44+00:00,,1,14,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
104022,[PT2.0][compile] torch._dynamo.config.log_level does not exist,2023-06-22 05:39:16+00:00,,1,0,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
104020,[torch.compile] `permute_linear_fusion` ignores the inplace operation for the tensor,2023-06-22 04:44:24+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: inductor""), Label(name=""module: pt2-dispatcher"")]"
104011,DISABLED test_backward_ddp_outside_uneven_inputs (__main__.TensorPipeDdpUnderDistAutogradTest),2023-06-22 00:58:09+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
104010,Several Torchbench models don't run with float16 or bfloat16 in the inference eager mode,2023-06-22 00:35:30+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: half""), Label(name=""module: benchmark""), Label(name=""oncall: pt2"")]"
103990,[Inductor] Freezing Add support for Caching Parameter Conversions,2023-06-21 20:18:47+00:00,,0,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
103966,'MPS' Issue Running HuggingFace Transformer Pix2Struct Model,2023-06-21 15:32:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
103965,[ONNX] Isolate TorchScript-based code-base from Dynamo-based ONNX exporter for easier deprecation,2023-06-21 15:28:40+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement"")]"
103962,How to unwrap after auto_wrap in FSDP?,2023-06-21 11:27:10+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
103960,CODEOWNERS file has errors due to non existent people being referred to,2023-06-21 09:53:43+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
103959,"Need the full ""Release Compatibility Matrix"" of torch",2023-06-21 09:47:49+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
103958,How to modify gradients of an FSDP model?,2023-06-21 09:33:32+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
103955,when train with multi GPUS,2023-06-21 08:07:16+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
103949,torch.save() fails if path contains multibyte characters,2023-06-21 06:25:05+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
103947,"[torch.fx] Deserialization Error - TypeError: ones() received an invalid combination of arguments - got (tuple, device=Attribute) ",2023-06-21 06:07:37+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: fx""), Label(name=""oncall: fx"")]"
103913,[dynamo] functools.wraps : graph-break when wrapping nested functions.,2023-06-20 19:20:52+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
103895,Issue with loading similar checkpoints in a distributed fashion ,2023-06-20 16:35:31+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
103891,Docker images: faster linker for `torch.compile`,2023-06-20 15:40:51+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: docker""), Label(name=""oncall: pt2"")]"
103883,Runtime Error outerNode->outputs().size() == node->inputs().size() INTERNAL ASSERT FAILED when exporting custom operator,2023-06-20 13:12:57+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
103879,Can ``torch.vmap`` add ``grad_fn``= SelectBackward when maping over some dimension of the inputs?,2023-06-20 11:57:06+00:00,,0,5,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: functorch"")]"
103868,"row.device().is_cpu() INTERNAL ASSERT FAILED at ""csrc/cpu/diag_cpu.cpp"":7",2023-06-19 23:16:10+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: macos"")]"
103863,DISABLED test_create_chunk_dtensor (__main__.TestShardUtilsDistributedDTensor),2023-06-19 20:43:44+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""skipped"")]"
103860,"Long PR description leads to ""Argument list too long"" error from docker",2023-06-19 19:01:35+00:00,,0,7,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: devx"")]"
103857,[ONNX] FX exporter: replace `aten::copy_` with out-place version,2023-06-19 18:41:03+00:00,,1,10,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
103852,Segmentation fault when tensorrt is imported before torch,2023-06-19 15:26:56+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""has workaround"")]"
103848,torch compile aten::floor_divide error,2023-06-19 14:21:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103847,Some parameters are missing type descriptions,2023-06-19 14:18:17+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable"")]"
103846,"The document style is inconsistent with other documents, and the parameter type is not clearly highlight",2023-06-19 14:04:03+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable"")]"
103844,Missing examples in some API docs,2023-06-19 13:50:29+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable"")]"
103841,[question] [docs] Short/mid/long-term status of TorchScript / JIT / torch.jit.trace / FX / symbolic tracing and its replacement by Dynamo,2023-06-19 13:13:34+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: docs""), Label(name=""triaged"")]"
103840,Gradient operations (zero_grad and gradient accumulations) as graphs,2023-06-19 13:12:38+00:00,,0,15,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
103837,type conflict,2023-06-19 11:38:41+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
103836,Please consider the SCFA/dynamic flash attention for your implementation of scaled dot product attention,2023-06-19 11:06:27+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""topic: new features"")]"
103832,Torch 1.13 for GPU breaks if libcublas is already present.,2023-06-19 08:58:16+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: docker"")]"
103831,[dynamo] AssertionError for custom iterable nn.Module,2023-06-19 08:52:02+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103829,RPC Framework support custom backend,2023-06-19 08:01:21+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
103820,Upgrading SpGEMM algorithm to resolve Cusparse SpGEMM insufficient resources problem,2023-06-19 02:55:26+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
103814,"abnormal behavior in function ""scatter""",2023-06-18 15:52:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
103805,Error when building with USE_TENSORRT=1,2023-06-17 16:19:47+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""module: build""), Label(name=""triaged"")]"
103803,Support `Sequence` type in JIT,2023-06-17 15:29:31+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: typing""), Label(name=""triaged""), Label(name=""enhancement"")]"
103802,Eager PTDQ Performs Worse Than Non-Quantized Linear Layer on CPU(in Terms of Speed),2023-06-17 15:25:30+00:00,,1,4,"[Label(name=""triaged"")]"
103800,Mis-annotated return for `F._no_grad_embedding_renorm_` (also JIT related),2023-06-17 11:33:55+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: typing""), Label(name=""triaged""), Label(name=""bug"")]"
103798,Type misalignments in `nn.functional` (also JIT related),2023-06-17 11:05:51+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: typing""), Label(name=""triaged"")]"
103788,"[Torch Mlir] avg_pool1d function padding init value should be (0,)",2023-06-16 23:39:41+00:00,,0,1,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
103787,Generate complete annotations for `torch._C._nn`,2023-06-16 23:36:03+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""release notes: devx"")]"
103785,[PT2] Return int32 indices in max_pool2d_with_indices,2023-06-16 22:54:54+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103764,[ONNX] Handle absence of `onnxscript` module in PyTorch requirements.txt,2023-06-16 19:36:53+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement"")]"
103761,Merge type stubs for `torch.nn.functional`,2023-06-16 18:21:59+00:00,,0,3,"[Label(name=""module: typing""), Label(name=""triaged"")]"
103760,dlrm and hf_T5_generate fails aot_eager with bfloat16+dynamic_shapes,2023-06-16 17:31:53+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
103756,libtorch > 1.9.1 produces segfault on Qt5 gui application exit,2023-06-16 16:00:17+00:00,,2,9,"[Label(name=""high priority""), Label(name=""module: crash""), Label(name=""module: cpp""), Label(name=""triaged"")]"
103752,Pytorch not calling to C code from a docker container,2023-06-16 15:32:09+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: docker""), Label(name=""module: __torch_function__"")]"
103749,SDPA produces NaN with padding mask,2023-06-16 13:59:29+00:00,,1,32,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
103737,[FSDP] train throughput become slow down when loaded shard optimizer dict,2023-06-16 04:41:36+00:00,,2,5,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
103730,[FSDP] save model checkpoint with StateDictType.LOCAL_STATE_DICT and LocalStateDictConfig(offload_to_cpu=True) fail,2023-06-16 02:47:30+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
103727,torch.compile() bug in AOTAutograd or Dynamo,2023-06-16 01:51:06+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103719,DataParallel interfering with TorchDispatchMode,2023-06-15 23:40:53+00:00,,0,9,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""module: __torch_dispatch__""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
103716,Non actionable perf hint: reduction over non-contiguous dims,2023-06-15 23:14:13+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
103713,[ONNX] Discuss improvements to Diagnostic public API,2023-06-15 22:26:46+00:00,,1,6,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
103706,TorchDynamo assertion with `try: return; finally`,2023-06-15 21:20:30+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""release notes: dynamo"")]"
103683,fairseq distributed training dumps core with flash attention,2023-06-15 16:39:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
103682,(fsdp) Support for accessing unsharded parameters for methods other than `forward()`,2023-06-15 16:38:12+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
103681,Exported model with dropout incorrectly applies dropout during eval,2023-06-15 16:31:01+00:00,,0,14,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
103672,detectron2_fcos_r_50_fpn and other models have enough graph breaks that we end up with multiple cache entries on module blocks,2023-06-15 13:26:50+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
103671,"""Y.getIntrusivePtr()->set_storage(X.getIntrusivePtr()->storage()); "" in C++ is not supported",2023-06-15 13:17:59+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
103668,MultiheadAttention should split embed_dim into four parameters,2023-06-15 11:16:01+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
103652,inductor: support horizontal reduction with vec_transpose to improve TIMM swin_base_patch4_window7_224  dynamic shape performance ,2023-06-15 05:15:10+00:00,,2,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
103650,AOT autograd: Avoid dependency on strides for manual regeneration of outputs that are aliased to inputs,2023-06-15 04:33:24+00:00,,0,13,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
103643,"""addmm_out_sparse_csr_impl_mkl"" not implemented for 'Byte'",2023-06-15 01:40:00+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
103640,Disclose C++ ATen ops type promotion rules under OpOverload in Python,2023-06-15 01:26:46+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
103626,2D  model checkpointing hangs on a ViT model,2023-06-14 21:47:44+00:00,,1,0,"[Label(name=""oncall: distributed"")]"
103625,DISABLED test_backward_ddp_outside (__main__.TensorPipeDdpUnderDistAutogradTest),2023-06-14 21:39:29+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
103622,ARM based GPU support for Distributed Data Parallelism Module,2023-06-14 20:18:58+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
103619,torch._dynamo.exc.InternalTorchDynamoError: SymNodeVariable() is not a constant on DynamicShapesMiscTests.test_slice_input,2023-06-14 19:50:54+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
103615,Can't call allow_in_graph inside of a function being torch.compile'd ,2023-06-14 19:22:04+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103608,Installing Torch on AMD Platform Leads to Huge Docker Image,2023-06-14 17:47:16+00:00,,0,2,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
103602,test_fstrings2 fails with dynamic,2023-06-14 17:12:50+00:00,,0,10,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
103589,`interpolate` with `antialias=True` on CUDA doesn't work if the difference of spatial size is large,2023-06-14 12:57:48+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
103588,LSTM/RNN operation agnostic,2023-06-14 12:22:14+00:00,,1,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
103584,torch.cuda.mem_get_info to return 0 if CUDA context isn't initialized,2023-06-14 08:09:55+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""actionable"")]"
103581,Passing dict in datapipe/dataset will have memory leak problem,2023-06-14 06:34:55+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: data"")]"
103580,Support ByteTensor and ShortTensor for nn.Embedding and nn.EmbeddingBag,2023-06-14 05:24:03+00:00,,1,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable""), Label(name=""topic: improvements"")]"
103578,"ImportError: undefined symbol: cublasSetWorkspace_v2, version libcublas.so.11",2023-06-14 04:47:23+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
103573,[ONNX] Support aten::mT,2023-06-14 03:18:56+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""OSS contribution wanted"")]"
103572,[ONNX] Support aten::linalg_solve_triangular,2023-06-14 03:17:48+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
103571,[ONNX] Support aten::linalg_cholesky_ex,2023-06-14 03:17:07+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
103570,File Missing When i build with C++,2023-06-14 03:12:03+00:00,,0,6,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
103553,Request: flag to know model is compiled after torch.compile(),2023-06-13 22:14:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2"")]"
103552,Inject detailed NVTX markers into the Inductor Triton generated kernels,2023-06-13 21:57:57+00:00,,1,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
103539,torch.fx.passes.split_module.split_module doesn't support dynamic shapes,2023-06-13 20:18:29+00:00,,0,2,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
103530,Deduplicate the operands passed into torch.cond after dynamo tracing.,2023-06-13 18:05:08+00:00,,1,3,"[Label(name=""triaged"")]"
103518,`gradcheck` produces false positives with sparse inputs when `masked=False`.,2023-06-13 14:30:16+00:00,,0,14,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
103505,"[functorch] [FakeTensorMode, meta tensor] + aot_autograd Bug.",2023-06-13 12:28:56+00:00,,1,7,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
103499,CUBLAS_WORKSPACE_CONFIG can not be parsed,2023-06-13 10:22:22+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
103498,ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 6047) of binary: /home/win10-ubuntu/anaconda3/envs/vicuna-7b/bin/python,2023-06-13 09:50:22+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
103495,DISABLED test_mem_get_info (__main__.TestCuda),2023-06-13 06:40:18+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
103484,No backward implementation for `torch._native_multi_head_attention`,2023-06-13 03:27:11+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
103483,torch._dynamo.exc.Unsupported: Tensor.backward with aten_graph=True,2023-06-13 03:17:38+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""oncall: export"")]"
103482,Document CI retry rules,2023-06-13 02:39:38+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: devx"")]"
103475,[Inductor] Optimize More Cases of Int32 -> Int64 ,2023-06-13 01:14:05+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: inductor"")]"
103473,Error encountered when tracing model with Dynamo/Functorch for export with trilinear interpolation,2023-06-13 00:38:57+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""oncall: export"")]"
103462,Memory efficient SDP yields wrong gradients,2023-06-12 21:58:31+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
103449,Asynchronous CUDA AveragedModel,2023-06-12 18:59:18+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
103444,Deprecation warning on lr_scheduler.step(num_steps),2023-06-12 18:27:18+00:00,,0,4,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
103439,test_generate_tensor_from_list_of_numpy_primitive_type fails if run under pytest,2023-06-12 15:37:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
103425,The document does not emphasize Illegal value in nn.Bilinear,2023-06-12 10:26:21+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: edge cases"")]"
103424,The document does not emphasize hidden range in nn.Embedding,2023-06-12 10:18:54+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: docs""), Label(name=""triaged"")]"
103423,The document does not emphasize hidden range in nn.MaxPool2d,2023-06-12 10:17:46+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: docs""), Label(name=""triaged"")]"
103422,Possible memory leak when using Torch and Torchvision in conjunction with XGBoost ,2023-06-12 10:06:36+00:00,,0,4,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: vision"")]"
103417,"Torch  model compile error  ""/usr/bin/ld: cannot find -lcuda""  though cuda is installed via run file",2023-06-12 08:08:53+00:00,,0,7,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""upstream triton"")]"
103415,[inductor][cpp_wrapper] Support rand fallback,2023-06-12 06:52:57+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103397,LayerNorm freeze processes using torch multiprocessing,2023-06-11 20:55:04+00:00,,0,2,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
103393,Typing missing on arithmetic ops on `Tensor`,2023-06-11 16:50:19+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged"")]"
103382,NotImplementedError Could not run 'c10d::alltoall_' with arguments from the 'Meta' backend. ,2023-06-11 03:33:30+00:00,,0,1,"[Label(name=""triaged"")]"
103375,Inplace binary ops on tensor subclasses can cause mypy error,2023-06-11 00:11:22+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged"")]"
103372,ImportError: cannot import name 'Store' from 'torch.distributed',2023-06-10 18:28:56+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
103370,torchgen/gen_backend_stubs.py compatibility with DispatchStubs,2023-06-10 14:21:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: codegen""), Label(name=""module: structured kernels"")]"
103369,test_workspace_allocation_error fails on my local devgpu,2023-06-10 13:37:56+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
103367,RuntimeError: CUDA error: unknown error,2023-06-10 12:51:42+00:00,,1,6,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
103359,Libtorch compile error when defining D_GLIBCXX_DEBUG,2023-06-10 01:04:55+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: abi""), Label(name=""triaged"")]"
103354,Add a requirements.txt for windows pip packages,2023-06-09 22:41:58+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: devx"")]"
103352,"[feature request] Native method for iterating Python items of tensors: `iteritems()` and a new `tensor.item(i, j, k, ...)` method",2023-06-09 22:09:56+00:00,,0,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
103343,mps and cpu give far different results when training a transformer.,2023-06-09 20:55:01+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mps"")]"
103336,"python test/inductor/test_split_cat_fx_passes.py -k test_consecutive_split_merge fails, but running all tests together succeeds",2023-06-09 18:16:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103332,Improve `_group_tensors_by_device_and_dtype`,2023-06-09 16:02:55+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable""), Label(name=""module: mta"")]"
103329,"RuntimeError: torch.vmap a function that includes in-place arithmetic operations on a zero-initialized tensor, an error ""vmap: inplace arithmetic(self, *extra_args) is not possible"" is raised.",2023-06-09 15:33:50+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
103322,Disabling ALL TestOptim on the dynamo config,2023-06-09 14:17:22+00:00,,0,6,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
103318,Custom autograd function causes a graph break,2023-06-09 11:25:42+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103316,binary_cross_entropy (loss) seems to be giving incorrect values for very negative logits,2023-06-09 09:58:06+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged"")]"
103313,Fast kernels for low rank matrix multiplication,2023-06-09 08:44:55+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
103312,setup.py fails to pass USE_ROCM to CAFFE2 build ,2023-06-09 07:54:23+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
103306,DTensor uneven sharding corner cases.,2023-06-09 04:29:09+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
103305,distributed.gather shape constraints,2023-06-09 04:08:03+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""topic: docs"")]"
103276,Dynamo trouble shooting dead link,2023-06-08 22:22:52+00:00,,0,5,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""topic: docs""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
103272,oneDNN kernel fails to compile,2023-06-08 21:49:11+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mkldnn"")]"
103258,"Warn / deprecate / remove ProcessGroupNCCL._group_start(), _group_end() APIs",2023-06-08 18:37:29+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
103254,Unexpected High PCIe traffic in Distributed Training since PT 2,2023-06-08 17:05:25+00:00,,0,27,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
103250,torch.jit.script mean(keepdim=True) segfaults on GPU,2023-06-08 14:37:19+00:00,,0,0,"[Label(name=""oncall: jit"")]"
103243,torch.cuda.memory_reserved always returns 0 bytes,2023-06-08 09:23:35+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
103241,Image Processing with Pytorch,2023-06-08 08:18:33+00:00,,0,1,"[Label(name=""triaged"")]"
103231,Benchmark --quick with huggingface runs almost indefinitely on CPU,2023-06-08 04:56:21+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103222,compilation fails `error: invalid argument '-std=c++17' not allowed with 'C'`,2023-06-08 00:46:33+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
103221,[help] did torch.distributed.launch can be applied on k8s cluster with pytorch-operator,2023-06-08 00:44:12+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: elastic"")]"
103213,Undeterministic behavior in testing in dynamo.,2023-06-07 22:48:28+00:00,,2,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
103212,PyTorch can not be compiled with MKLDNN if system compiler is clang,2023-06-07 22:45:41+00:00,,1,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
103194,[inductor] test_fft_real_inputs fails with dynamic shapes,2023-06-07 20:08:07+00:00,,0,2,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor"")]"
103189,(fsdp - maybe a bug) SHARDED_STATE_DICT returns tensor with no data,2023-06-07 19:34:51+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
103173,[RFC] Emit better Telemetry in PyTorch,2023-06-07 18:27:17+00:00,,0,8,"[Label(name=""feature""), Label(name=""module: logging""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103169,breakpoint() in torch.compile region behaves oddly,2023-06-07 18:21:50+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103161,Calling jacrev with LSTM and functional_call  gives error,2023-06-07 17:18:19+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
103160,Allow overriding __repr__ to call dataclass_repr (infinite recursion right now),2023-06-07 17:09:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: codegen"")]"
103150,Build fails at linking torch_shm_manager on aarch64,2023-06-07 12:38:03+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
103131,"error: ‘aligned_alloc’ was not declared in this scope        static_cast<char*>(aligned_alloc(FLATBUFFERS_MAX_ALIGNMENT, size)), free);",2023-06-07 02:12:21+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
103117,Observed regress in DataLoader spawn from PyTorch1.13 to PyTorch2.0,2023-06-06 23:59:48+00:00,,1,6,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: data"")]"
103111,Turn on Inductor Max Pool2d Backward Lowering For Channels Last,2023-06-06 21:38:52+00:00,,1,0,"[Label(name=""feature""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
103109,Increased / more verbose type aliases for improved readability of user defined content,2023-06-06 21:25:17+00:00,,0,7,"[Label(name=""module: typing""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research"")]"
103104,PyTorch should not use `windows.8xlarge.nvidia.gpu` to test binary builds,2023-06-06 19:59:39+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
103101,Refactor mm_plus_mm to check conditions upfront,2023-06-06 19:38:21+00:00,,0,2,"[Label(name=""feature""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
103099,torch.compile specializes on output name,2023-06-06 18:47:59+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103093,Inconsistent memory allocation using FSDP between PT 2.0 and Nightlies,2023-06-06 17:15:47+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
103089,"[OOM] Unable to convert 30B model to ONNX, using 4x A100's",2023-06-06 15:39:17+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
103082,Ambiguitiy in causal-mask in scaled_dot_product_attention,2023-06-06 13:45:10+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
103073,torch.compile crash for tensor computing when tensor size is bigger ,2023-06-06 10:18:49+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
103070,Unexpected failure in LLVM JIT when running TorchScript model in C++,2023-06-06 07:41:20+00:00,,0,3,"[Label(name=""oncall: jit"")]"
103060,Symbolic trace error about torch.nn.functional.pad,2023-06-06 04:19:11+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
103056,[Pytorch 2.0] torch::nn::Dropout output is incorrect on Windows  ,2023-06-06 03:19:56+00:00,,1,1,"[Label(name=""module: binaries""), Label(name=""module: windows""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: regression"")]"
103055,"lit-llama lora fine tuning NetworkXUnbounded: Infinite capacity path, flow unbounded above",2023-06-06 03:10:21+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
103023,MPS bug: padding_idx in nn.Embedding does not prevent gradient accumulation ,2023-06-05 21:35:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
102999,Preserve weight_g/weight_v accessors on new weight_norm,2023-06-05 19:20:14+00:00,,0,14,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: nn.utils.parametrize"")]"
102977,raise `RuntimeError` faster when loading an object with a torch CUDA tensor on a CPU-only machine,2023-06-05 15:51:44+00:00,,1,2,"[Label(name=""module: nn""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""actionable"")]"
102971,Discussion and Design  for Masked Loss Functions which can be used with PackedSequence training (but not exclusively),2023-06-05 14:17:11+00:00,,0,6,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: masked operators"")]"
102966,"how to workaround the error ""don't have an op for vulkan_prepack::create_linear_context"" ?",2023-06-05 09:53:28+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vulkan""), Label(name=""ciflow/periodic"")]"
102963,torch.svd fails on large matrices,2023-06-05 08:47:20+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas""), Label(name=""module: linear algebra"")]"
102953,TypeError: (): incompatible function arguments,2023-06-05 06:17:13+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
102948,[onnx] aten::cumprod cannot be exported to ONNX,2023-06-05 03:16:15+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""OSS contribution wanted"")]"
102947,"torch.onnx.export error ------RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",2023-06-05 02:45:17+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
102938,Support for efficiently processing categorical distributions with varying dimensions,2023-06-04 20:50:26+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research"")]"
102936,torch.cuda.is_available() returns False on GTX 1650 with cuda 11.7 and torch==2.0.0+cpu,2023-06-04 16:17:09+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged"")]"
102921,Unbox expectedml,2023-06-04 01:46:52+00:00,,0,2,"[Label(name=""triaged"")]"
102911,PackedSequences on MPS accelerator yields `grad_y` missing or crashes the kernel.,2023-06-03 18:27:22+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: mps"")]"
102905,nn.ChannelShuffle1d,2023-06-03 06:30:53+00:00,,1,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
102904,Unable to checkpoint model and optimizer state when using Hybrid Sharding Strategy,2023-06-03 05:54:31+00:00,,0,1,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""module: distributed_checkpoint"")]"
102898,After dynamo minifier generates repros that don't entirely match what we minified over,2023-06-03 00:55:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
102894,"BCELoss and BCEWithLogitsLoss differ when one of the input logits is float(""inf"")",2023-06-02 23:51:09+00:00,,1,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
102878,[dynamo] Diffusers - Graph break on OrderedDict ,2023-06-02 21:06:03+00:00,,1,8,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
102870,Inductor: delete code that extracts out sizevars by inspecting tensor inputs to find a size that handled it,2023-06-02 19:14:27+00:00,,0,1,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: inductor"")]"
102853,pdb but for dynamo (and time travel debugging),2023-06-02 17:44:39+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
102852,The operator 'aten::poisson' is not currently implemented for the MPS device,2023-06-02 17:32:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
102839,Dynamo should only unroll loops by a preset factor (unless otherwise explicitly instructed),2023-06-02 13:00:48+00:00,,2,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
102833,LibTorch-Lite 1.13.0.1 Crash on iOS 12 on app startup,2023-06-02 10:27:53+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: ios"")]"
102832,TypeError: (): incompatible function arguments,2023-06-02 09:02:01+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
102830,Unknow error when using `make_graphed_callables`,2023-06-02 07:43:17+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
102821,"Unable to resume job using FSDP with 64 nodes, errors appeared during loading sharded optimizer state dict ",2023-06-02 06:17:56+00:00,,1,11,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
102814,mark_dynamic may error too aggressively,2023-06-02 03:29:34+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
102812,[DTensor] Error in distribute_module with module._apply,2023-06-02 03:21:40+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
102811,`torch.poisson(torch.tensor([torch.inf))` returns 0,2023-06-02 03:11:05+00:00,,0,3,"[Label(name=""module: distributions""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
102805,Do smarter layout decisions with concatenate.,2023-06-02 01:51:24+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
102803,Improve shape padding in training.,2023-06-02 01:42:29+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
102775,DISABLED test_make_fx_symbolic_exhaustive_special_bessel_j0_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),2023-06-01 21:39:31+00:00,,0,138,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: ProxyTensor"")]"
102772,Support In-place Triangular Matrix Multiplication,2023-06-01 20:48:35+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra"")]"
102763,Followup on the extra graph breaks for yolov3 model caused by layout optimization,2023-06-01 18:40:09+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: inductor"")]"
102761,Pytorch Build images for RISCV64 Devices in the nightly builds,2023-06-01 18:21:32+00:00,,0,0,"[Label(name=""module: build""), Label(name=""feature""), Label(name=""triaged"")]"
102753,Error: no matching constructor for initialization of 'at::OptionalIntArrayRef',2023-06-01 17:22:11+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
102751,DISABLED test_ddp_has_finalized (__main__.TestDistBackendWithSpawn),2023-06-01 16:41:02+00:00,,0,2,"[Label(name=""triaged""), Label(name=""skipped"")]"
102741,Unlocking PyTorch's Power: README.md in Multiple Languages! ,2023-06-01 15:24:45+00:00,,0,3,"[Label(name=""triaged""), Label(name=""topic: new features""), Label(name=""topic: docs"")]"
102740,parameterizations.orthogonal does not work as intended with nn.GRU or nn.LSTM,2023-06-01 15:24:36+00:00,,0,5,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: nn.utils.parametrize"")]"
102732,Building NCCL with `make -l $MAX_JOBS` slows down builds,2023-06-01 14:40:30+00:00,,1,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
102731,"[FSDP]  When amp is enabled, there is a noticeable difference during training between `FSDP `and `DDP`",2023-06-01 14:01:57+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
102730,Best practices clarification for initialization strategies,2023-06-01 13:54:50+00:00,,1,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: initialization""), Label(name=""needs research""), Label(name=""module: python frontend"")]"
102727,DISABLED test_Conv2d_dilated_cuda_tf32 (__main__.TestNN),2023-06-01 12:46:40+00:00,,0,9,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
102694,Exporting the operator \\'aten::fused_moving_avg_obs_fake_quant\\' to ONNX opset version 13  is not supported,2023-06-01 02:37:46+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
102673,Fix dynamo-related debug Python 3.11 failures,2023-06-01 00:06:24+00:00,,1,3,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""release notes: dynamo"")]"
102670,Investigate the perf drop on timm for dynamic shape when layout optimization is enabled,2023-05-31 23:40:38+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
102667,Duplicate parameters (_flat_params and original params) in the state_dict when using `use_orig_params=True` and `StateDictType.LOCAL_STATE_DICT`,2023-05-31 23:02:44+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
102663,Test test_vjp_nn_functional_scaled_dot_product_attention_cuda_float32 fails with `query: last dimension must be contiguous` on H100,2023-05-31 22:32:43+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: functorch"")]"
102653,torchscript dataclasses have bad support for class types as fields,2023-05-31 21:49:07+00:00,,0,0,"[Label(name=""oncall: jit"")]"
102631,"Error when exporting to onnx for albert-base-v2, issue with attention_mask",2023-05-31 18:29:29+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
102610,Cannot invoke prims.sum with output_dtype,2023-05-31 11:06:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
102609,[prims] torch.ops.aten.le decomposition confuses scalars and tensors,2023-05-31 10:58:54+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
102600,Support for activation checkpoint on demand in custom function,2023-05-31 06:41:34+00:00,,0,1,"[Label(name=""module: checkpoint""), Label(name=""triaged"")]"
102596,Jetson NX with torch 1.12.0 :cannot import name 'ProcessGroup' from 'torch.distributed'.,2023-05-31 05:19:59+00:00,,0,7,"[Label(name=""oncall: distributed"")]"
102559,Mergebot should merge non-stacked PR,2023-05-30 18:49:11+00:00,,2,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: devx"")]"
102556,test_functional_autograd_benchmark.py::TestFunctionalAutogradBenchmark::test_fast_tasks passes with all NaNs,2023-05-30 18:07:03+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: functorch"")]"
102534,[RFC] Add third-party malloc library to improve pytorch memory performance on Windows,2023-05-30 15:11:59+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: windows""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""intel"")]"
102533,Segfault when running vulkan program linked against libtorch,2023-05-30 14:15:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vulkan""), Label(name=""ciflow/periodic"")]"
102517,[feature request] PyTorch support for sub-interpreters with PEP 684 accepted and release in Python 3.12,2023-05-30 07:20:13+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
102515,pytorch java api documentation is not clear and does not cover example ,2023-05-30 06:31:58+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""oncall: java"")]"
102511,Faster BatchSampler with big batch size,2023-05-30 06:04:53+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
102507,[Inductor] [CPU] hf_Longformer performance regression > 10% on 2023-05-28 nightly release,2023-05-30 03:48:49+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
102501,[Utils][tensorboard]Enhancement: Include 'max_outputs' parameter in torch.utils.tensorboard.summary's 'image' method,2023-05-30 03:20:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
102498,[REQUEST] - Update Multiprocessing best practices with CPU device,2023-05-30 02:45:38+00:00,,1,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""docs-hackathon""), Label(name=""topic: docs"")]"
102479,torch.onnx.errors.CheckerError: The model does not have an ir_version set properly.,2023-05-29 10:48:05+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
102459,Matrix multiplication performance regression in case of an additional dimension of size 1,2023-05-28 22:16:48+00:00,,0,0,"[Label(name=""module: dependency bug""), Label(name=""triaged""), Label(name=""module: cublas"")]"
102457,Batching rule for `aten::_scaled_dot_product_efficient_attention`,2023-05-28 21:52:20+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: vmap"")]"
102453,RuntimeError using torch.nn.functional.pad when using MPS,2023-05-28 17:00:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
102447,"Add additional ""sigmoid"" approximation to GeLu activation?",2023-05-28 13:53:44+00:00,,1,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research"")]"
102438,DDP multi node multi gpu inconsistent params,2023-05-27 15:25:05+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
102437,discuss.pytorch.org signup issue,2023-05-27 14:11:30+00:00,,0,8,"[Label(name=""module: docs""), Label(name=""triaged"")]"
102436,multiple mps for base X86 Mac with multiples gpus,2023-05-27 12:48:56+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
102435,torch.distributed.all_reduce() has inconsistent behavior,2023-05-27 10:30:08+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
102430,Add support ONNX Opset 19,2023-05-27 06:26:57+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
102423,Add default device function interface for device-aware apis,2023-05-27 02:24:20+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
102417,_view_func but without keeping original view tensor alive,2023-05-27 00:08:25+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: viewing and reshaping"")]"
102402,[Composable] Unified way to check if modules are managed by composable API,2023-05-26 20:48:37+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""release notes: distributed (composable)"")]"
102400,Unexpected Behavior when using torch.isclose(),2023-05-26 20:27:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: testing"")]"
102374,Hooks not working in version 2.0.1+cu118,2023-05-26 15:58:12+00:00,,0,11,"[Label(name=""module: nn""), Label(name=""triaged"")]"
102373,"[cuda] Switching CI to CUDA 12.1 timing out linux-bionic-cuda12.1-py3.10-gcc7 / test (distributed, 3, 3, linux.8xlarge.nvidia.gpu)",2023-05-26 15:40:43+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged"")]"
102368,Issue with ShufflerIterDataPipe in torch 1.13.1,2023-05-26 12:43:58+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
102360,PyTorch hangs at import when used together with TensorFlow,2023-05-26 08:58:13+00:00,,0,10,"[Label(name=""triaged""), Label(name=""topic: binaries"")]"
102355,Data type mismatch in `batch_isend_irecv` docstring example,2023-05-26 07:36:55+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
102354,"""Examples"" in ""batch_isend_irecv"" should be modified to get the correct results",2023-05-26 07:25:29+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
102339,[Dynamo] Better graph-break message for unsupported ctx managers,2023-05-26 05:48:21+00:00,,0,1,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
102337,Tensors that share same underlying storage to also share gradient storage,2023-05-26 05:08:05+00:00,,0,12,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: python frontend"")]"
102334,There is a memory leak in torch.load,2023-05-26 04:14:33+00:00,,0,10,"[Label(name=""module: memory usage""), Label(name=""module: serialization""), Label(name=""triaged"")]"
102333,"transformer encoder-layer, the sample-Independent attn_mask(dim=3) has different behaviors when training and validating",2023-05-26 04:13:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
102319,Re-enable Low Memory Dropout,2023-05-26 00:23:39+00:00,,1,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
102285,[Dynamo]Outdated logging setting,2023-05-25 18:19:10+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
102272,"after add /path_to_libtorch/libtorch/lib to LD_LIBRARY_PATH, I can't import torch_scatter.",2023-05-25 15:31:59+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""module: abi""), Label(name=""triaged"")]"
102269,Import of torch breaks standard multiprocessing,2023-05-25 13:47:05+00:00,,1,12,"[Label(name=""module: dependency bug""), Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: openmp"")]"
102261,ExponentialLR unexpectedly calls `step()` when init argument `last_epoch` is larger than -1,2023-05-25 07:34:07+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: LrScheduler"")]"
102227,lintrunner should fail on badly formatted docstrings,2023-05-24 23:56:11+00:00,,0,6,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: devx"")]"
102211,[ONNX] test_op_consistency.py doesn't support constant inputs,2023-05-24 21:36:00+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
102207,skipIfTorchInductor Tracking Issue ,2023-05-24 21:01:30+00:00,,0,1,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
102206,copy_'s functionalized operator keeps copied into tensor live,2023-05-24 20:56:43+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
102205,aot_export_joint_simple on plain callable (not graph module) doesn't attach stack traces,2023-05-24 20:53:50+00:00,,1,1,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
102201,scipy.ndimage.find_objects,2023-05-24 20:32:54+00:00,,1,11,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
102197,torch.func.jvp fails when acting on a DistributedDataParallel model,2023-05-24 19:55:43+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: forward ad""), Label(name=""module: functorch"")]"
102187,Extend fake fast path to more situations,2023-05-24 18:23:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
102186,torch/distributed/_spmd/api.py should aot_module_export instead of make_fx directly,2023-05-24 18:20:43+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
102167,Calling pin_memory() fails for nested tensor ,2023-05-24 13:26:22+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""topic: new features"")]"
102162,NotImplementedError in backprop on on dense-sparse matrices,2023-05-24 12:13:09+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
102157,DISABLED test_build_tuple_unpack_dynamic_shapes (torch._dynamo.testing.DynamicShapesMiscTests),2023-05-24 09:39:23+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
102142,Pytorch CXX11 ABI version,2023-05-24 03:24:31+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: abi""), Label(name=""triaged"")]"
102115,DISABLED test_inplace_grad_index_put_cuda_complex128 (__main__.TestBwdGradientsCUDA),2023-05-23 21:39:48+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: pt2-dispatcher"")]"
102113,DISABLED test_inplace_grad_div_trunc_rounding_cuda_float64 (__main__.TestBwdGradientsCUDA),2023-05-23 21:39:32+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: pt2-dispatcher"")]"
102112,DISABLED test_fn_grad_div_trunc_rounding_cuda_float64 (__main__.TestBwdGradientsCUDA),2023-05-23 21:39:25+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: pt2-dispatcher"")]"
102105,Enable DEBUG asserts for C++ builds,2023-05-23 19:10:24+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: devx"")]"
102085,BatchNorm can't be symbolically traced with torch.fx as a standalone module ,2023-05-23 13:50:21+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
102084,Documentation Error of torch.onnx,2023-05-23 13:46:29+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""module: docs""), Label(name=""triaged"")]"
102081,CPU Fallback does not convert Tensor?[],2023-05-23 13:29:53+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged"")]"
102078,AddressSanitizer: heap-buffer-overflow in test_comprehensive_nn_functional_embedding_bag_cpu_bfloat16 ,2023-05-23 12:33:00+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: embedding""), Label(name=""module: decompositions"")]"
102071,DISABLED test_build_tuple_unpack (__main__.DynamicShapesMiscTests),2023-05-23 09:39:27+00:00,,0,62,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
102109,Can't vmap over a slice expression,2023-05-23 09:30:31+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
102063,[dynamo][BE] Revisit call_method of NNModuleVariable,2023-05-23 06:58:35+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
102044,DISABLED test_comprehensive_empty_strided_cuda_int64 (__main__.TestInductorOpInfoCUDA),2023-05-23 03:39:21+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
102034,DISABLED test_call_parent_non_class_methods_from_child (torch._dynamo.testing.DynamicShapesMiscTests),2023-05-23 00:57:24+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
102033,DISABLED test_comprehensive_empty_strided_cuda_float64 (__main__.TestInductorOpInfoCUDA),2023-05-23 00:57:21+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
102023,torch.compile FakeTensor tracing fails with foreach ops with multiple devices,2023-05-22 23:02:11+00:00,,1,5,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: custom-operators""), Label(name=""release notes: foreach_frontend""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: pt2-dispatcher"")]"
101999,[FSDP] Ensure full precision checkpoints,2023-05-22 18:56:07+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
101998,[FSDP] Summon buffers in full precision,2023-05-22 18:55:09+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
101984,"[dynamo]  BackendCompilerFailed: backend='inductor' raised: NetworkXUnbounded: Infinite capacity path, flow unbounded above.",2023-05-22 16:38:28+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
101974,"Request for adding support for `torch.rand_like`, `torch.randn_like`, `torch.randint_like` with `torch.Generator`",2023-05-22 11:57:18+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: random"")]"
101972,No pytorch_android 2.0.x builds,2023-05-22 11:44:54+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
101968,CrossEntropyLoss output difference on Windows vs. Linux,2023-05-22 09:21:04+00:00,,1,1,"[Label(name=""module: windows""), Label(name=""triaged"")]"
101967,scaled_dot_product_attention produces NaN when input has NaN in masked-out positions,2023-05-22 08:19:33+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: edge cases""), Label(name=""module: multi-headed-attention"")]"
101962,SummaryWriter background thread holds the GIL for too long,2023-05-22 05:14:42+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: tensorboard"")]"
101950,torch.flip is inplaced too aggressively in torch inductor,2023-05-21 12:55:42+00:00,,0,4,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
101936,mps device bug - a weird inconsistency on tensor indexing operations,2023-05-20 21:51:57+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: mps"")]"
101934,Parameter gradient is not moved parameter is moved across devices,2023-05-20 20:54:38+00:00,,1,8,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: correctness (silent)"")]"
101930,[feature request] [minor] Inplace torch.flip_,2023-05-20 17:31:53+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: python frontend"")]"
101929,can not find tensorrt,2023-05-20 15:47:22+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
101918,[compile] Tracker for `torchrec_dlrm` issues,2023-05-20 00:22:23+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: custom-operators""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
101890,Can't reproduce/non-deterministic results with CUDA,2023-05-19 19:07:17+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
101880,Crash on Python //  PyArrow // ,2023-05-19 17:02:16+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
101878,torch.quantile on MPS doesn't sort values when dim is not None,2023-05-19 16:28:30+00:00,,0,12,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
101871,Can group convolution support other grouping methods?,2023-05-19 13:12:44+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged"")]"
101866,torch.compile makes transformers model (llama) generating different outputs compared with the native,2023-05-19 09:14:49+00:00,,2,7,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
101864,"Error, attribute exists on the Python module, but we failed to convert Python type: 'list' to a TorchScript type ",2023-05-19 08:37:10+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: onnx"")]"
101861,Observing negative number in PyTorch profiling,2023-05-19 08:03:04+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
101855,torch.jit.trace() Floating point exception,2023-05-19 05:15:11+00:00,,0,0,"[Label(name=""oncall: jit"")]"
101850,Unexpected modification to CPU affinity of Dataloader workers,2023-05-19 03:12:11+00:00,,0,10,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: openmp"")]"
101801,pytorch-nightly not have torch/version.py.tpl:cuda specified,2023-05-18 15:47:48+00:00,,1,7,"[Label(name=""module: binaries""), Label(name=""module: windows""), Label(name=""triaged"")]"
101798,Fix absolute links in pytorch repository and allow it to be proxied,2023-05-18 12:43:08+00:00,,0,4,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
101795,Implement `to_numpy` method to speed up matplotlib with PyTorch arrays,2023-05-18 09:59:10+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""needs research"")]"
101787,DISABLED test_decoder_padding_and_src_mask_bool_cpu (__main__.TestTransformersCPU),2023-05-18 06:39:55+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: transformer/mha"")]"
101781,Add support for bfloat16 in torch.from_numpy(),2023-05-18 06:09:46+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: bfloat16"")]"
101771,DISABLED test_fn_grad_remainder_cuda_float64 (__main__.TestBwdGradientsCUDA),2023-05-18 03:39:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
101770,DISABLED test_fn_grad___rmod___cuda_float64 (__main__.TestBwdGradientsCUDA),2023-05-18 03:39:28+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
101758,DISABLED test_cond_nested (__main__.MiscTests),2023-05-18 00:58:09+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
101757,DISABLED test_fn_gradgrad_remainder_cuda_float64 (__main__.TestBwdGradientsCUDA),2023-05-18 00:58:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
101755,DISABLED test_fn_grad_index_put_cuda_complex128 (__main__.TestBwdGradientsCUDA),2023-05-18 00:58:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
101716,"[TorchScript] aten::__and__ with argument types: Tensor, bool not supported",2023-05-17 18:55:40+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
101699,[discussion] [feature request] Native tensor-backed string array and basic string processing functions for addition into core + discussion of extremely basic data frames (also for reducing python object heap pressure),2023-05-17 15:29:53+00:00,,0,12,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research"")]"
101669,[refs] inplace references resize the input to match the broadcasted input shape,2023-05-17 06:15:34+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
101666,Unexpected behavior of fmod op in some float32 input,2023-05-17 03:53:35+00:00,,0,4,"[Label(name=""module: numerical-stability""), Label(name=""triaged"")]"
101653,Unexpected behavior comparing uint8 tensor to value greater than 255,2023-05-17 01:17:16+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: edge cases"")]"
101632,torch.profiler.profile has an empty python replay stack under certain circumstances,2023-05-16 23:58:51+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
101625,DISABLED test_compare_cpu__refs_empty_strided_cuda_float32 (__main__.TestCommonCUDA),2023-05-16 22:20:05+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""skipped"")]"
101624,[Dynamo + DDP] If DDP partitions FX graph generated by Dynamo correctly,2023-05-16 22:11:17+00:00,,1,12,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
101609,[Dynamo] Can't inline functions under torch.nn.parallel ,2023-05-16 20:56:44+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
101603,multiple values for argument `softmax_scale`,2023-05-16 19:16:39+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
101586,"/Users/davidlaxer/pytorch/third_party/tensorpipe/third_party/libuv/src/unix/getaddrinfo.c:165:10: error: implicit declaration of function 'uv__idna_toascii' [-Werror,-Wimplicit-function-declaration]     rc = uv__idna_toascii(hostname,",2023-05-16 17:55:36+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
101566,Unable to do tensor comparison on Metal Performance Shaders (MPS),2023-05-16 14:17:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
101536,"torch.cuda.set_device cannot use to set cpu device, but give an ambiguity hint",2023-05-16 09:37:33+00:00,,0,2,"[Label(name=""triaged"")]"
101535, Exporting the operator 'aten::scatter_reduce' to ONNX opset version 15 is not supported,2023-05-16 09:23:31+00:00,,0,8,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
101531,torch.nn.functional.scaled_dot_product_attention() : support both attn_mask and is_causal,2023-05-16 08:16:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
101529,Inconsistent performance degradation of 3x3 convolution (torch 2.0.1+cu118),2023-05-16 07:34:32+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: regression"")]"
101527,DISABLED test_cond_export (__main__.MiscTests),2023-05-16 06:46:30+00:00,,0,13,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
101525,DISABLED test_noncontiguous_samples_matmul_cuda_float32 (__main__.TestCommonCUDA),2023-05-16 06:40:21+00:00,,0,53,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
101506,Support pipeline parallelism with PyG,2023-05-16 04:05:12+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""topic: new features"")]"
101505,Investigate random sequence number broadcast initially incorrect,2023-05-16 03:55:02+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
101502,onnx runtime error,2023-05-16 03:48:53+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
101470,[bazel] add inductor to bazel build,2023-05-16 00:16:34+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: bazel"")]"
101463,Regression in NCCL error handling,2023-05-15 22:36:29+00:00,,0,10,"[Label(name=""oncall: distributed"")]"
101444,RuntimeError: Triton Error [CUDA]: device-side assert triggered when trying torch.compile max-autotune on nanoGPT,2023-05-15 20:30:07+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
101443,Enhance FSDP debugability,2023-05-15 20:24:32+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
101564,not yet implemented the batching rule for torchaudio::_lfilter,2023-05-15 18:12:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: batching""), Label(name=""module: functorch"")]"
101428,2D inputs to linear layers run up to 25% slower than 4D ones on some Nvidia GPUs,2023-05-15 17:57:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
101415,import functorch.dim monkeypatches torch,2023-05-15 15:22:21+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
101407,Delete old vmap prototype,2023-05-15 14:07:29+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: functorch"")]"
101404,problem of compilation for torch2.0,2023-05-15 12:58:51+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
101402,DataParallel for nested modules,2023-05-15 12:05:58+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
101398,ONNX model different to pytorch and jit trace output,2023-05-15 08:55:11+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
101385,torch.Tensor.is_sparse returns false for non-COO sparse tensors,2023-05-15 06:28:47+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
101380,all_to_all_single seems to be missing a check for checkSplitSizes when splitsize=0.,2023-05-15 03:24:44+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
101370,SparseAdam: working with dense parameters but sparse gradients - usecase ,2023-05-14 21:38:32+00:00,,0,15,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
101369,Theme update,2023-05-14 21:26:35+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
101359,RuntimeError in Scaled Dot Product Attention Tutorial Code,2023-05-14 12:01:53+00:00,,0,2,"[Label(name=""module: cpu""), Label(name=""triaged"")]"
101356,inductor: inductor conv2d get a different size and stride with eager mod when input channel is zero,2023-05-14 08:31:07+00:00,,2,4,"[Label(name=""triaged""), Label(name=""ZeroTensor""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
101335,fsdp training with the seq2seqTranier module gets stuck during evaluation.,2023-05-13 11:53:33+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
101334,Functions for Calculating Skewness and Kurtosis ,2023-05-13 10:32:33+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: reductions"")]"
101331,Pytorch 2.1.0.dev20230512 cuda not available,2023-05-13 08:24:22+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
101321,Speed when installing from source is very low with CUDA 11,2023-05-12 23:12:36+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
101319,Deprecated File bug,2023-05-12 22:44:56+00:00,,0,2,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""topic: build"")]"
101314,Shared library loading logic breaks when CUDA packages are installed in a non-standard location,2023-05-12 21:56:07+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: bazel""), Label(name=""topic: build""), Label(name=""bug"")]"
101294,Docs suggestion `FullyShardedDataParallel.summon_full_params` must be called on all ranks/processes,2023-05-12 18:24:23+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
101293,Operations to shared tensors in the forked process could lead to silent crash,2023-05-12 17:58:47+00:00,,0,2,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
101291,fused torch.optim.AdamW isn't faster than the unfused version,2023-05-12 17:05:06+00:00,,0,5,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
101289,Support fake tensor real inputs in dynamo,2023-05-12 16:34:12+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
101288,Should be ok to call _dynamo.export and torch.compile under FakeTensorMode,2023-05-12 16:31:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
101273,IPEX as TorchDynamo Backend Performance Dashboard,2023-05-12 10:09:21+00:00,,0,60,"[Label(name=""triaged""), Label(name=""intel""), Label(name=""oncall: pt2"")]"
101265,"Noisy warning - torch.fx.experimental.symbolic_shapes: [WARNING] Ignored guard (...), this could result in accuracy problems",2023-05-12 06:49:16+00:00,,0,2,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
101255,torch._dynamo.exc.UserError: Dynamic control flow is not supported at the moment.,2023-05-12 04:40:05+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
101251,Mac m2 MPSNDArray.mm:78: failed assertion `[MPSNDArrayDescriptor sliceDimension:withSubrange:] error: dimension index (2) not within number of dimensions (2) 	Dimension indices are 0-based',2023-05-12 03:29:43+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: mps"")]"
101249,`einsum` is about 40x slower on CUDA than manually multiplying and summing,2023-05-12 02:59:52+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
101246,Tool for identifying where in eager model an operation is nondeterministic,2023-05-12 02:50:04+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: determinism"")]"
101241,Different results with vmap when using torch.jit.script,2023-05-12 01:28:50+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: functorch"")]"
101233,"How the [WARNING] using triton random, expect difference from eager arises?",2023-05-12 00:28:35+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
101210,GLCM implementation in pytorch C++ api and cuda,2023-05-11 19:00:14+00:00,,1,3,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
101209,Migrate windows runners to non-ephemeral instances,2023-05-11 18:48:48+00:00,,1,4,"[Label(name=""module: ci""), Label(name=""triaged"")]"
101192,AOTAutograd export path does not support training graphs with parameters that do not receive gradients.,2023-05-11 15:11:50+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
101191,custom_op API follow-ups,2023-05-11 14:53:17+00:00,,0,6,"[Label(name=""triaged"")]"
101189,`dense -> sparse compressed` to work with empty batches.,2023-05-11 14:08:47+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
101188,Weird dataloader performance degradation caused by torch and numpy import order,2023-05-11 14:01:14+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: openmp"")]"
101185,Pure virtual function call exception on Python interpreter exit when using debug wheel,2023-05-11 13:16:02+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
101184,"Fork run CI from upstream remote (more than 10,000 emails) ",2023-05-11 12:54:12+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
101177,version 4.26.1 to 4.29.0 has two bugs,2023-05-11 09:54:38+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
101168,[torch.compile] torch._dynamo.exc.Unsupported: setattr(UserDefinedObjectVariable) for yolov7,2023-05-11 08:03:32+00:00,,1,6,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
101167,round float16 calculation error in mps backend,2023-05-11 07:56:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
101160,Fine-tuning HuggingFace wav2vec 2.0 with `torch.compile`,2023-05-11 06:33:41+00:00,,1,12,"[Label(name=""oncall: distributed""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""ezyang's list""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
101159,Inconsistency between GPU memory usage in torch.cuda.memory_summary and nvidia-smi,2023-05-11 06:15:29+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
101154,[Dynamo] TB hf_Reformer graph breaks,2023-05-11 04:18:54+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
101152,Importing torch after TensorFlow results in std::runtime_error,2023-05-11 03:32:12+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: tensorflow"")]"
101150,[ONNX] OnnxFunction of aten_index_put_bool operation isn't consistent to aten::index_put inx FX exporter,2023-05-11 02:29:34+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
101138,Fault and vauge error when invoking nvcc: The system cannot find the file specified,2023-05-10 23:15:01+00:00,,0,0,"[Label(name=""module: windows""), Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
101135,Pytorch compile failure on Windows with CUDA 12.1 because of lacking NVTX component,2023-05-10 22:36:49+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged"")]"
101117,Barriers to using torch.compile directly in PyTorch library code,2023-05-10 19:47:04+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: dynamo"")]"
101110,Tensorboard graph tracing with torch fx API,2023-05-10 19:04:25+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: tensorboard""), Label(name=""module: fx"")]"
101107,Make compiled models serializable,2023-05-10 18:48:57+00:00,,1,7,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
101106,"addmv doesn't do type promotion correctly,",2023-05-10 18:44:02+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: linear algebra"")]"
101096,[BE] Refactor logic for MultiTensorApply,2023-05-10 17:08:19+00:00,,0,4,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable""), Label(name=""module: mta"")]"
101091,Cannot export quantized model to onnx: cannot call qscheme on UnknownQuantizer,2023-05-10 16:31:48+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
101082,Multiple Learning Rate Scheduler for Specific Parameters Groups,2023-05-10 15:11:07+00:00,,1,4,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: LrScheduler"")]"
101080,Sequence annotation in type hints is wrong,2023-05-10 14:50:13+00:00,,0,4,"[Label(name=""module: typing""), Label(name=""triaged"")]"
101075,torch.lobpcg producing different largest eigenvalue than scipy and np.linalg.eig,2023-05-10 14:18:05+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: linear algebra"")]"
101070,Lazily format C++ stack trace if it is not used,2023-05-10 13:27:41+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged"")]"
101069,"torch.autograd.detect_anomaly should report the original forward trace as part of the error, rather than as out of band warning",2023-05-10 13:25:20+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
101068,"Tensor __getitem__ not documented, sparse grad?",2023-05-10 13:16:46+00:00,,0,12,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
101055,DISABLE libtorch-2.0.0+cu117 destructor exception,2023-05-10 07:38:58+00:00,,0,0,"[Label(name=""oncall: jit"")]"
101039,[torch.compile] the sum of `softmax` isn't `1` on cuda,2023-05-10 01:24:10+00:00,,1,5,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
101033,Exporting the operator 'prim::is_cuda' to ONNX opset version 14 is not supported,2023-05-10 00:19:43+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
101031,[PT2] torch.compile doesn't perform horizontal fusion,2023-05-10 00:05:06+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
101013,Unsupported: ONNX export of operator interpolate (with scales) error,2023-05-09 21:06:10+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
101011,[Placeholder] PyTorch 2.0 Dynamo/Inductor Hack{day/week},2023-05-09 20:54:36+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
100996,ONNX TorchDynamo Exporter  - Ability to export and load ONNX files without parameters,2023-05-09 18:28:31+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
100990,Extending compatibility of LibTorch,2023-05-09 17:34:08+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""feature""), Label(name=""triaged""), Label(name=""needs design"")]"
100989,"RuntimeError: nonzero is not supported for tensors with more than INT_MAX  elements, file a support request",2023-05-09 17:27:03+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: 64-bit""), Label(name=""module: sorting and selection"")]"
100985,"native_batch_norm has different size results on ""CPU"" vs ""META"" device",2023-05-09 16:44:54+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: meta tensors""), Label(name=""module: fakeTensor"")]"
100968,AssertionError: slice.Tensor is not supported with cpp wrapper (llama),2023-05-09 13:02:38+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
100960,Issues building with caffe2 enabled,2023-05-09 08:07:33+00:00,,0,1,"[Label(name=""caffe2""), Label(name=""triaged"")]"
100957,PyTorch installs the file mkldnn.cmake that looks for the package MKLDNN that doesn't exist,2023-05-09 07:40:20+00:00,,1,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
100932,torch.concat fails with float16 input in autocast(device_type=cpu) context,2023-05-09 01:26:39+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: amp (automated mixed precision)"")]"
100914,[MPS] Track failures of test_module.py for MPS backend,2023-05-08 22:06:04+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: backend""), Label(name=""module: mps"")]"
100913,[onnx] UnsupportedOperatorError: Exporting the operator 'aten::l1_loss' to ONNX opset version 17 is not supported,2023-05-08 21:47:59+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
100904,Revise glossary,2023-05-08 20:59:31+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
100884,`torch.distributions.categorical.Categorical` samples indices with zero probability,2023-05-08 18:09:01+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
100879,MPS backend is not supported on MacOS 12.6.3,2023-05-08 14:24:05+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: mps"")]"
100873,onnx.export fails if do_constant_folding=False,2023-05-08 12:52:23+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
100850,[BUG] Poor torch.bmm performance on H100,2023-05-08 05:08:12+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas""), Label(name=""matrix multiplication"")]"
100842,"Accuracy issues with Jitterated complex kernels for acos, acosh, asin, asinh, tan and tanh",2023-05-07 23:31:41+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: jiterator"")]"
100838,Dynamo infers different return type vs. eager for `torch.ops.aten`,2023-05-07 22:18:48+00:00,,0,6,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: decompositions"")]"
100807,[torch.compile] returns output with WRONG SHAPE after `cat_slice_cat`,2023-05-06 18:19:52+00:00,,1,0,"[Label(name=""triaged""), Label(name=""inductor_pattern_match"")]"
100804,Wrong type for `get_lr` inside lr_scheduler.pyi,2023-05-06 16:15:24+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""module: typing""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: LrScheduler"")]"
100801,There is a performance drop because we have not yet implemented the batching rule for aten::native_dropout_backward,2023-05-06 14:21:23+00:00,,0,1,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: functorch"")]"
100796,[Quant][pt2e] Failed to run pt2e flow on LLaMA,2023-05-06 08:28:03+00:00,,0,20,"[Label(name=""oncall: quantization""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
100795,Quickstart notebook fails to train properly with ROCm,2023-05-06 07:50:13+00:00,,0,2,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
100792,inductor cpp wrapper: crash when disable lowmem_dropout,2023-05-06 05:40:19+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
100790,ONNX Opset 16 GridSample Does Not Support 5D Volumetric Input Tensor,2023-05-06 04:01:16+00:00,,0,10,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
100785,compile torch2.0 in debug mode,2023-05-06 03:12:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""topic: build"")]"
100784,[CUDA RPC] Incorrect results of GPU Tensor transferring using RPC when parallelized with other GPU programs,2023-05-06 02:54:35+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: cuda"")]"
100775,[torch.compile] returns NaN for `tensor.mul(big_number).softmax()`,2023-05-06 00:04:43+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
100733,Nightly torch.compile fails with dynamically patched `nn.module.forward`,2023-05-05 18:46:03+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
100730,`torch::jit::EliminateExceptions` lowering pass never completes on specific model,2023-05-05 17:40:03+00:00,,0,0,"[Label(name=""oncall: jit"")]"
100725,[CUDA RPC] Incorrect messages in CUDA Support RPC when parallelized with other GPU programs,2023-05-05 16:31:24+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
100705,torch.cuda.amp.GradScaler initialization ,2023-05-05 10:14:38+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
100704,[Discussion] Investigate possibilities for Windows Arm64 BLAS and LAPACK,2023-05-05 09:58:47+00:00,,0,0,"[Label(name=""module: windows""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
100675,DISABLED test_inplace_gradgrad_remainder_cuda_float64 (__main__.TestBwdGradientsCUDA),2023-05-05 00:56:58+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
100674,Add support for MaxPool3D on the MPS backend,2023-05-05 00:50:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
100656,"On UMA systems, pytorch fails to reserve memory exceeding the initial memory size",2023-05-04 21:15:44+00:00,,0,0,"[Label(name=""module: rocm""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
100637,Optimal Batch Size Selection in Torchdynamo Benchmarks for Different GPU Memory Sizes,2023-05-04 17:30:50+00:00,,0,7,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
100636,tracing does not work when torch.distributions is involved,2023-05-04 17:27:22+00:00,,0,0,"[Label(name=""oncall: jit"")]"
100626,Will Deep Implicit Models ever become first class citizens in PyTorch?,2023-05-04 11:30:17+00:00,,0,13,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
100617,GPU VRAM usage significantly higher for Lenet5 models when compared to other frameworks,2023-05-04 06:17:29+00:00,,0,2,"[Label(name=""triaged""), Label(name=""better-on-discuss-forum"")]"
100584,[doc] torch.scalar_tensor doc is missing,2023-05-03 21:35:09+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
100578,Add support for aten::tril_indices for MPS backend ,2023-05-03 20:42:49+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: mps"")]"
100574,undocumented error on torch.autograd.Function.jvp for non-Tensor forward returns,2023-05-03 19:30:57+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
100562,Use a label instead of body text for merge blocking CI SEVs,2023-05-03 17:33:25+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
100561,[ONNX] Opset 18 support for TorchScript exporter,2023-05-03 17:24:34+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
100528,Backward hook execution order changes when input.requires_grad is False,2023-05-03 06:13:43+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
100520,DISABLED test_inplace_grad_div_floor_rounding_cuda_float64 (__main__.TestBwdGradientsCUDA),2023-05-03 03:39:40+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
100468,"Accuracy repro extraction, constants in graph are not preserved exactly",2023-05-02 14:02:50+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
100461,Arithmetic of single-element Tensors with different dtypes on 'cpu' and 'mps' results in obscure/unhelpful `TypeError`,2023-05-02 08:40:57+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: mps"")]"
100459,DISABLED test_wait_i_3 (__main__.TestMultiThreadedWait),2023-05-02 06:39:22+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
100448,DISABLED test_wait_i_4 (__main__.TestMultiThreadedWait),2023-05-02 03:39:24+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
100425,Higher GPU consumption for Lenet-5 and LSTM models when compared to other frameworks,2023-05-01 22:30:02+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
100419,Subgraph rewriter: Unable to match constant args,2023-05-01 21:27:23+00:00,,2,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
100414,Can't export onnx model from a torch script model,2023-05-01 20:38:29+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: onnx""), Label(name=""triaged"")]"
100411,Sparse Matrix nnz Overflow when casting from COO to CSR,2023-05-01 20:06:07+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
100386,Stop importing HuggingFace transformers in DataClassVariable,2023-05-01 15:09:55+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: startup-tracing-compile time"")]"
100385,Import setuptools.command.build_ext from torch.utils.cpp_extension somehow indirectly imports Cython when it is installed,2023-05-01 15:06:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: startup-tracing-compile time"")]"
100378,VecISA.__bool__ is very expensive (nearly a second) on startup,2023-05-01 14:52:57+00:00,,2,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor""), Label(name=""module: startup-tracing-compile time"")]"
100376,"_sfdp_init is extremely expensive for startup time, even on networks that don't benefit from it",2023-05-01 14:11:04+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: startup-tracing-compile time"")]"
100370,[BUG] add 1 to different tensor but get same value,2023-05-01 10:40:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
100366,some of the enteries in the previous version of pytorch section are invalid ,2023-05-01 06:30:32+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""module: docs""), Label(name=""triaged"")]"
100358,Tensor on shared memory is set to 0 when using concurrent.futures and CUDA,2023-05-01 05:02:33+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
100347,nn.MultiheadAttention doesn't use efficient scaled_dot_product_attention,2023-04-30 20:40:06+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""oncall: transformer/mha"")]"
100343,[torch.compile] `sum` out-of-bound read,2023-04-30 18:44:23+00:00,,2,8,"[Label(name=""triaged""), Label(name=""module: cpu inductor"")]"
100334,MPS device inference all same value,2023-04-30 15:11:02+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: mps"")]"
100320,Compiled function inside vmap,2023-04-29 18:39:20+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
100316,[torch.compile] raises RuntimeError in `sdfp_pattern_1` that `Expected size for first two dimensions of batch2 tensor`,2023-04-29 16:28:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""inductor_pattern_match"")]"
100310,Using ddp training with different machine,2023-04-29 11:32:48+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: elastic"")]"
100289,graph._export_onnx() incorrect data types in the binary string representation,2023-04-28 22:02:59+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
100278,"Dynamo capture for HigherOrderOperators, followups",2023-04-28 20:52:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
100270,[Performance] Potential Performance optimization for SDPA,2023-04-28 19:06:21+00:00,,1,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: inductor""), Label(name=""module: multi-headed-attention"")]"
100253,profiler.export_stacks doesn't return stack trace unless experimental_config is provided,2023-04-28 16:43:13+00:00,,1,13,"[Label(name=""high priority""), Label(name=""module: regression""), Label(name=""oncall: profiler"")]"
100249,"[discussion] ""TensorList"" as first-class abstraction (including python frontend) and as key for dispatch for merging `torch._foreach_*` into regular `torch.*` functions",2023-04-28 15:32:25+00:00,,0,6,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
100244,torch.utils._content_store will deduplicate storage with identical contents; may be problematic for mutation,2023-04-28 14:33:52+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
100241,Interaction of torch.no_grad and torch.autocast context managers with torch.compile,2023-04-28 10:50:28+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
100239,torch.compile is not compatible with DPP with torch.nn.SyncBatchNorm.convert_sync_batchnorm(),2023-04-28 08:55:57+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""module: norms and normalization""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: distributed"")]"
100223,Add missing `OpInfo`s for prims ops,2023-04-28 02:14:24+00:00,,0,5,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: primTorch"")]"
100220,tensor with dims marked with torch._dynamo.mark_dynamic loses dynamic dim marks after being moved to a different device,2023-04-28 00:16:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
100158,`torch.sparse_csc_tensor` matrix multiplication produces MKL error SPARSE_STATUS_ALLOC_FAILED when density is too high,2023-04-27 09:27:21+00:00,,0,6,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
100156,Illegal instruction in ARM64 (ver 2.0.0),2023-04-27 08:46:08+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: arm"")]"
100152,DISABLED test_open_device_registration (__main__.TestCppExtensionOpenRgistration),2023-04-27 06:40:10+00:00,,0,5,"[Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
100145,This flag not work : torch.backends.cudnn.allow_tf32 = False  ,2023-04-27 03:18:10+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
100126,DISABLED test_dtensor_device_mesh_device_conversion (__main__.DTensorMeshTest),2023-04-26 21:39:51+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
100125,Error saving MONAI pytorch model to ONNX,2023-04-26 21:15:57+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
100123,Error building Pytorch from source,2023-04-26 20:57:53+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: rocm""), Label(name=""triaged"")]"
100116,'pip install triton' from pinned hash gives unreliable triton,2023-04-26 19:11:22+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
100105,[pt2-functorch] torch.func.functional_call works with func.vmap but breaks for func.grad,2023-04-26 17:06:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
100096,Inductor origins still not accurate,2023-04-26 15:08:37+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
100087,TransformerEncoderLayer behavior inconsistent between training and evaluation mode,2023-04-26 12:44:11+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
100085,[regression] torch.norm with out dtype bfloat16 cause runtime error,2023-04-26 12:40:00+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: norms and normalization"")]"
100080,[Indexing] Incoherent Tensor indexing for nested lists,2023-04-26 09:43:31+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing""), Label(name=""module: edge cases"")]"
100075,[compile] output does not match eager mode,2023-04-26 07:25:38+00:00,,1,22,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2 accuracy""), Label(name=""module: pt2-dispatcher"")]"
100074,DISABLED test_checkpointing_resets_persistent_refs (__main__.CudaGraphTreeTests),2023-04-26 06:43:53+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: inductor"")]"
100069,Issue with FSDP + HuggingFace generate,2023-04-26 05:53:42+00:00,,0,14,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
100062,add github check that diffs generated code,2023-04-26 04:21:33+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: infra""), Label(name=""module: codegen"")]"
100061,torch.compile() drops the performance of validation / Dynamo is not guarding on attributes on NN modules,2023-04-26 04:18:21+00:00,,0,18,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: pt2 accuracy"")]"
100055,pre_autograd `make_fx` broken with simple F.linear with symbolic shape,2023-04-26 02:17:10+00:00,,0,21,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
100054,Add compile option -Werror=return-type compile error,2023-04-26 02:10:01+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""actionable"")]"
100052,nn.Transformer out[0:-1] not precisely equal to last_out when predicting in tgt mask,2023-04-26 01:57:48+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
100051,Issue of HistogramObserver to handle abnormal value,2023-04-26 01:53:22+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
100044,[Tensor Parallel] Clarify docs,2023-04-25 23:55:50+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
100012,Dataloader multiprocess loading with num_worker > 0 calls __main__ file to run,2023-04-25 19:16:45+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
100006,Revive multigpu testing,2023-04-25 17:53:01+00:00,,1,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
100005,torch.triu() may returns wrong values using MPS,2023-04-25 17:50:00+00:00,,0,4,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
99999,Runtime Error,2023-04-25 17:16:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug"")]"
99994,OpInfo missing for `prims.convert_element_type`,2023-04-25 16:52:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: decompositions"")]"
99989,Copying an MPS tensor to a CPU tensor using a for loop fails,2023-04-25 16:01:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
99982,torch.cuda.is_available() crashes python in systems with disabled gpu,2023-04-25 12:46:39+00:00,,0,3,"[Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
99981,Group Norm crashes on Apple M1/MPS devices for versions 2.0+,2023-04-25 10:24:28+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: mps"")]"
99979,I encountered an error while trying to save the stylegan2 network as torch. onnx. export,2023-04-25 09:47:03+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
99978,torch.jit.trace can not trace buffer by Module.register_buffer() when use DDP Module.,2023-04-25 09:26:36+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
99949,[inductor] Autotuning leads to non determinism,2023-04-25 00:37:15+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
99932,FSDP + gradient clipping raises an odd warning with the simplest model on torch 2.0,2023-04-24 22:17:50+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
99923,benchmarks/dynamo/ci_expected_accuracy/update_expected.py truncates file if only one shard succeeds,2023-04-24 20:04:48+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: benchmark""), Label(name=""oncall: pt2"")]"
99922,ciflow/inductor should run both inference and training even if inference fails,2023-04-24 20:04:05+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: inductor""), Label(name=""module: devx"")]"
99918,[RFC] DebugMode,2023-04-24 19:22:11+00:00,,0,5,"[Label(name=""triaged"")]"
99908,Deprecate torch.distributed.algorithms._optimizer_overlap,2023-04-24 19:07:40+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
99903,Can the CUDA device LUID be exposed as part of _CudaDeviceProperties?,2023-04-24 18:14:52+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable""), Label(name=""needs design"")]"
99893,Many models are failing on periodic dynamic shape benchmark tests dynamic_aot_eager,2023-04-24 17:15:38+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
99873,Dynamo config patching in our code is brittle,2023-04-24 13:03:11+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""oncall: export"")]"
99866,Logs output_code and inductor do not interact as expected,2023-04-24 08:21:46+00:00,,0,0,"[Label(name=""module: logging""), Label(name=""triaged"")]"
99852,Slight numerical divergence between torch.compile and eager; shows up in practice on yolov3,2023-04-24 02:00:32+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: pt2 accuracy"")]"
99836,NTK notebook calculates wrong object - wrong output dimensions,2023-04-23 19:44:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
99825,"When backend is nccl, the distribution group type generated by Pytorch 2.0 shoule be ProcessGroupNCCL, but is ProcessGroup",2023-04-23 12:58:05+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
99821,Tracer cannot infer type of Seq2SeqLMOutput,2023-04-23 09:56:25+00:00,,0,1,"[Label(name=""oncall: jit"")]"
99812,cuda.is_available() error,2023-04-23 06:10:24+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
99807,AOTAutograd/Inductor file system cache,2023-04-23 02:02:03+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
99806,`cat` gradgrad tests failing,2023-04-23 00:36:14+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
99802,torch.multinomial() always returns [0] using MPS,2023-04-22 19:36:19+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: mps"")]"
101073,Windows fatal exception: stack overflow while using pytorch for computing,2023-04-22 19:24:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
99797,Automatic broadcasting for sparse csr tensors,2023-04-22 16:39:17+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
99794,Apple metal (MPS)  device returning incorrect keypoints for YOLOv8 pose estimation model ,2023-04-22 11:08:37+00:00,,1,2,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
99790,Cannot compile torch 1.10 in CentOS 7.3,2023-04-22 06:05:05+00:00,,0,2,"[Label(name=""triaged"")]"
99781,2.0.0+cu118 package missing proper libnvrtc-builtins.so.11.8,2023-04-22 01:17:29+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""module: cpp""), Label(name=""triaged"")]"
99774,"RuntimeError: Cannot call sizes() on tensor with symbolic sizes/strides w/ `dynamo.export`, `make_fx` and `functionalize`",2023-04-21 23:37:12+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""oncall: export""), Label(name=""module: pt2-dispatcher"")]"
99770,Deformable Convolution export to onnx,2023-04-21 22:49:27+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
99722,cuda 12.0 support request for building pytorch from source code,2023-04-21 15:30:05+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
99715,no-duplicate-decl-specifier as a invalid compile flag for CXX in GCC,2023-04-21 11:59:26+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: rocm""), Label(name=""triaged"")]"
99710,pca_lowrank and svd_lowrank broken under automatic mixed precision.,2023-04-21 09:39:09+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""module: linear algebra""), Label(name=""module: amp (automated mixed precision)"")]"
99701,"when convert to onnx with dynamix_axis,  the Reshape op  value is always the same as static,  dynamic_axis is useless, it cant't inference right shape dynamically",2023-04-21 06:28:45+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
99693,"WARNING: The shape inference of prim::PadPacked type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.",2023-04-21 03:29:24+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""onnx-triaged"")]"
99690,"gpu training  work well, but cpu training not work",2023-04-21 03:10:51+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: fft"")]"
99684,In torchelastic support running worker rank 0 on agent rank 0 consistently,2023-04-21 02:08:22+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: elastic"")]"
99681,`torch.ops.aten.empty` is not discoverable from `dir(torch.ops.aten)` until explicitly calling getattr,2023-04-21 00:32:10+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: library"")]"
99652,DistributedDataParallel doesn't work with complex buffers,2023-04-20 19:17:12+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: complex"")]"
99649,[torch.compile] raises an error that expanded size doesn't match when enabling `shape_padding`,2023-04-20 18:49:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
99640,Ban GradScaler scale from being less than 1,2023-04-20 17:12:52+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
99637,Torch hangs at import if tensorflow is imported first,2023-04-20 16:37:15+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
99630,Parameterisation of MultivariateNormal distribution using Cholesky decomposition of precision matrix,2023-04-20 15:18:05+00:00,,0,3,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
99625,Conda Pytorch set processor affinity to the first physical core after fork,2023-04-20 12:49:19+00:00,,0,18,"[Label(name=""high priority""), Label(name=""module: dependency bug""), Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: mkl""), Label(name=""module: third_party""), Label(name=""module: intel"")]"
99615,CUPTI Initialization error ,2023-04-20 09:37:44+00:00,,0,29,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
99614,Make broadcast_coalesced to a op for processgroup,2023-04-20 08:54:46+00:00,,1,1,"[Label(name=""oncall: distributed"")]"
99584,Training Faster R-CNN model with COCO dataset has been consistently unsuccessful.,2023-04-20 00:49:49+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
99562,lintrunner mypy raises error in numpy,2023-04-19 21:16:25+00:00,,1,4,"[Label(name=""module: lint""), Label(name=""triaged"")]"
99561,Pytorch mobile crashes on Android when loading a custom model,2023-04-19 21:03:12+00:00,,0,0,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
99556,torch.func.jacrev fails if model contains full_backward_hook,2023-04-19 19:09:46+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: functorch"")]"
99558,Batching rule not implemented for aten::narrow.Tensor,2023-04-19 17:56:27+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
99544,Cross compile Pytorch for ARM in Bazel,2023-04-19 17:05:53+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: arm"")]"
99573,"Jacfwd become slower after update pytorch (""We’ve integrated functorch into PyTorch---Documentation"")",2023-04-19 16:04:43+00:00,,0,3,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: functorch"")]"
99515,Support polyphase channelizer,2023-04-19 07:59:08+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: fft"")]"
99509,'Illegal instruction (core dumped)' for gpt-j bf16 generation task using greedy search ,2023-04-19 04:24:07+00:00,,1,15,"[Label(name=""module: crash""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: intel"")]"
99455,Not Preserving Grad For Tensor Created Inside torch.compile,2023-04-18 20:24:53+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
99438,vision_maskrcnn failing on periodic dynamic_aot_eager_torchbench,2023-04-18 18:32:57+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
99432,[DTensor] parallelize_module failed with nn.Transformer and the PairwiseParallel plan,2023-04-18 17:39:17+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
99421,Question about GRU(RNN/LSTM) outputs shape,2023-04-18 15:15:34+00:00,,1,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""actionable"")]"
99414,The meta implementation of `index_put` does not do any check,2023-04-18 12:45:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: meta tensors""), Label(name=""release notes: Meta API"")]"
99410,"torch.nn.functional.multilabel_margin_loss cuda lacks checking of ""out of bound""",2023-04-18 11:41:22+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
99407,Torch.fx.symbolic_trace removes some of the keys from module state_dict,2023-04-18 09:43:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
99404,FakeTensor lacks support for sparse compressed tensors,2023-04-18 07:34:49+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
99397,Internal errors with cuda graph (CUBLAS_STATUS_NOT_INITIALIZED and jit failure),2023-04-18 03:39:21+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
99390,torch.compile error,2023-04-18 02:23:53+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
99372,PyTorch 2.0.0 encountered CUDA error: an illegal memory access was encountered,2023-04-17 21:51:17+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
99359,[c++17] Replace lock_guard with scoped_lock ,2023-04-17 18:52:31+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
99352,add `-std=c++20` build-only CI job,2023-04-17 17:25:08+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: devx"")]"
99351,we should make semantically meaningless positional arguments positional only in our operator API,2023-04-17 17:18:10+00:00,,1,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: python array api""), Label(name=""module: python frontend"")]"
99316,torch.linalg.lstsq doc arguments error,2023-04-17 13:58:58+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
99311,Functorch pytrees with custom iterables,2023-04-17 13:40:50+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: pytree""), Label(name=""module: functorch"")]"
99310,Torch func Documentation for trees,2023-04-17 13:33:08+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: functorch"")]"
99305,CI for s390x,2023-04-17 10:47:51+00:00,,0,4,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement"")]"
99304,Need TransformerEncoder to output attention map,2023-04-17 10:19:30+00:00,,0,3,"[Label(name=""oncall: transformer/mha""), Label(name=""topic: new features"")]"
99299,There has implmenet bug in LTC IrBuilder's MakeSizeMul method.,2023-04-17 09:28:30+00:00,,1,1,"[Label(name=""triaged""), Label(name=""lazy""), Label(name=""module: lazy"")]"
99297,Slicing and indexing support negative steps,2023-04-17 09:09:30+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
99293,Automatically set dropout for SDPA depending on training mode / `training` argument,2023-04-17 07:30:30+00:00,,0,2,"[Label(name=""enhancement""), Label(name=""oncall: transformer/mha"")]"
99287,Add `TORCH_ASSERT_ONLY_METHOD_OPERATORS` to functorch codebase,2023-04-17 05:13:44+00:00,,0,3,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: functorch"")]"
99278,Build error on libstc++ header stl_alogbase.h on riscv,2023-04-16 21:21:35+00:00,,0,6,"[Label(name=""module: build""), Label(name=""good first issue""), Label(name=""triaged"")]"
99270,Remove lr_scheduler.print_lr,2023-04-16 18:19:35+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
99268,Embedding layer tensor shape,2023-04-16 17:36:10+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: embedding"")]"
99265,the error message of torch.addcmul is wrong,2023-04-16 13:44:32+00:00,,1,2,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
99248,tools PYTHONPATH trick in run_test.py does not work reliably,2023-04-16 01:48:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: testing"")]"
99247,Broken link for torch dynamo FAQ in docs,2023-04-15 21:52:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""topic: docs"")]"
99230,vision_maskrcnn failing in periodic/trunk,2023-04-15 14:05:52+00:00,,1,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
99225,Libtorch consumes too much memory as 16225,2023-04-15 07:15:22+00:00,,0,5,"[Label(name=""module: cpp""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
99218,Sporadic CUDA error in `test_nccl_warn_not_in_group_debug_detail`,2023-04-15 02:45:51+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
99201,opacus_cifar10 fails in dynamo due to hooks ,2023-04-14 21:04:26+00:00,,2,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
99200,Unused `import torch` followed by `cuml.NearestNeighbors` leads to nondeterministic segfault (during Python process exit?),2023-04-14 20:48:19+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
99176,Add Debug builds for python with pydebug,2023-04-14 18:01:20+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: devx"")]"
99160,"Run ChatRWKV on MBP(intel CPU)+eGPU[rx6800 16G], returna a very big number -9223372036854775808, looks like overflow",2023-04-14 15:49:46+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
99155,TORCH_COMPILE_ABLATE envvar,2023-04-14 15:00:21+00:00,,1,4,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
99149,"Spectral Normalization can not be applied to Conv{1,2,3}d",2023-04-14 13:59:29+00:00,,1,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
99147,`torch.sparse.sum` backward fails when reducing over dense dimensions.,2023-04-14 12:53:28+00:00,,1,2,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
99143,No documentation to show how to implement aten::view for custom backend,2023-04-14 11:36:09+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""module: docs""), Label(name=""triaged"")]"
99142,"More Nested Tensor Functionality (layer_norm, cross_entropy / log_softmax&nll_loss)",2023-04-14 11:02:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""topic: new features"")]"
99140,"Why nn.Upsample/F.interpolate followed by nn.InstanceNorm2d will report error ""Unsupported: ONNX export of instance_norm for unknown channel size.""",2023-04-14 10:02:54+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
99138,torch.cuda.is_available() return False,2023-04-14 09:20:35+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
99126,DISABLED test_fake_crossref_backward_no_amp_index_fill_cuda_float32 (__main__.TestFakeTensorCUDA),2023-04-14 03:39:53+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown""), Label(name=""module: fakeTensor""), Label(name=""module: pt2-dispatcher"")]"
99107,Invalid Reference to Class,2023-04-13 23:53:05+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""topic: docs"")]"
99082,Look into test coverage for `UntypedStorage`,2023-04-13 21:02:55+00:00,,1,0,"[Label(name=""module: typing""), Label(name=""module: tests""), Label(name=""triaged"")]"
99042,Memory allocation issues in distributions.multivariate_normal.MultivariateNormal,2023-04-13 15:37:11+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
99037,AttributeError: type object 'torch._C._profiler.ProfilerActivity' has no attribute 'MPS',2023-04-13 14:15:08+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: profiler""), Label(name=""module: mps"")]"
99035,Issue on building from source: Remove -mfpu=neon option on MacOS with Apple silicon,2023-04-13 12:59:46+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
99025,Is there a way to get the full call stack of pytorch from python to C/C++?,2023-04-13 09:37:21+00:00,,0,5,"[Label(name=""triaged"")]"
99023,Dtype changes while going from FX graph -> Torchscript,2023-04-13 07:49:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""FX-TorchScript Compatibility""), Label(name=""module: fx"")]"
99012,"[BUG]Float32 attention mask not working with torch.autocast(""cpu"")",2023-04-13 03:40:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
99007,create_graph_input and add_grapharg should be combined into one function,2023-04-13 02:56:04+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
98978,[torch.compile] makes `linear(permute(input))` succeed for integer input in `torch.no_grad` context,2023-04-12 21:36:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""module: inductor"")]"
98977,[BE] Dedup the functorch skipOps mechanism and the common_method_invocations one,2023-04-12 21:30:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: testing"")]"
98976,Sparse Tensor: in-place operation on detached tensors no longer raised error,2023-04-12 21:13:05+00:00,,1,5,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
98970,[torch.compile] `replace_fx` ,2023-04-12 20:45:41+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""module: inductor"")]"
98955,Please verify 1.14.0 ONNX release candidate on TestPyPI ,2023-04-12 18:55:41+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
98948,behaviour of `torch.tensor()` changes after editing `Tensor.__getitem__`,2023-04-12 16:53:22+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
98947,Add `torch.cat`  support for torch native sparse tensors. (Need for PyG),2023-04-12 16:36:04+00:00,,0,10,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
98942,[torch.fx] Upgrade on node info,2023-04-12 15:36:22+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
98939,"torch.dist with minus norm returns tensor(0.), while with -inf can return result",2023-04-12 15:19:18+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
98937,TracingContext.get().frame_summary_stack doesn't produce full stack trace,2023-04-12 14:49:19+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
98929,torch.sparse_csr_tensor() stops gradients,2023-04-12 09:54:46+00:00,,1,8,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
98925,Request for deterministic support for reflection_pad2d_backward_cuda,2023-04-12 08:49:07+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: padding"")]"
98924,Integrate open device privateuse1 customized method registration,2023-04-12 08:28:07+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: backend"")]"
98921,Unable to load MultiStepLR with torch.load(weights_only=True) ,2023-04-12 07:57:32+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
98917,Change module to module_ in torch/csrc/api/include/torch/python.h,2023-04-12 07:05:19+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
98907,Move template code to header,2023-04-12 03:32:14+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
98904,Test failure: TestCommonCPU.test_python_ref__refs_abs_cpu_complex32,2023-04-12 02:36:27+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged"")]"
98888,Changes to TorchScript autodiff changing default behavior are no longer accepted,2023-04-11 23:59:42+00:00,,0,1,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
98882,[PT2] AOTAutograd de-dups but skips de-dup guards for DDP,2023-04-11 22:12:36+00:00,,1,11,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98875,DISABLED test_all_to_all_1d (__main__.DeviceMeshCollectiveTest),2023-04-11 21:39:22+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
98872,Expand component configurable logging system to C++,2023-04-11 20:58:05+00:00,,1,4,"[Label(name=""module: logging""), Label(name=""triaged"")]"
98871,Document the user-facing API for the component-level logging system,2023-04-11 20:54:19+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
98864,Support SPDA on non-CUDA backends,2023-04-11 20:17:36+00:00,,0,2,"[Label(name=""oncall: transformer/mha"")]"
98863,Problem with instalation torch2 on a100+cu12.1,2023-04-11 19:52:39+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
98861,Sparse Tensor not working for `torch.cat`,2023-04-11 19:00:20+00:00,,0,6,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
98860,Sharded Grad Scaler Issue Tracker,2023-04-11 18:51:06+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)""), Label(name=""module: fsdp"")]"
98844,[PT2] Some errors with `cond` and `torch.compile`,2023-04-11 14:07:08+00:00,,0,8,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
98836,PyTorch's packaged libgomp causes significant performance penalties on CPU when used together with other Python packages,2023-04-11 10:57:50+00:00,,0,8,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
98827,[functorch] vmap_hessian_fc - fails under torch.compile,2023-04-11 07:01:07+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
98825,[functorch] functorch_maml_omniglot - fails under torch.compile,2023-04-11 06:54:23+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
98822,[functorch] torch.compile - functorch transforms Interaction,2023-04-11 06:40:59+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
98817,[FSDP] summon_full_params with_grad=True CPU offload can crash,2023-04-11 05:01:22+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
98816,File-level retry enhancements,2023-04-11 04:58:57+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: devx"")]"
98814,autocast does not work properly on embedding module,2023-04-11 04:35:21+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
98808,[FSDP] move up the first all gather,2023-04-11 01:53:37+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
98805,Discrepancy of supported Python versions between Get Started page and index of pre-built binaries for PIP installation,2023-04-11 01:37:52+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
98792,DataLoader doesn't accept non-cpu device for loading. ,2023-04-10 22:32:05+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
98768,[SPMD] DistCompiler graph optimization improvement,2023-04-10 18:21:17+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
98727,Pytorch member variable not working after converting to onnx format,2023-04-10 06:52:36+00:00,,1,11,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
98724,Conflict between ``torch.func`` transformations and ``torch.jit.trace``,2023-04-10 05:02:52+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
98707,Ubuntu 22.04 LTS issue <built-in function load_binary> returned NULL without setting an exception,2023-04-09 22:18:38+00:00,,1,13,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98695,Torchscript: Name Mangling prevents Type Refinement,2023-04-09 16:49:20+00:00,,0,0,"[Label(name=""oncall: jit"")]"
98678,DISABLED test_gradgrad_nn_GroupNorm_cuda_float64 (__main__.TestModuleCUDA),2023-04-08 17:00:10+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""skipped"")]"
98677,DISABLED test_grad_nn_GroupNorm_cuda_float64 (__main__.TestModuleCUDA),2023-04-08 16:58:57+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""skipped"")]"
98675,torch.matmul with batched CSR matrix,2023-04-08 16:29:08+00:00,,0,7,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
98673,[ux] Non-blocking tensor constructors,2023-04-08 12:45:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""has workaround""), Label(name=""module: tensor creation"")]"
98668,Cannot use `checkpoint_sequential` with `torch.compile`,2023-04-08 06:01:09+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98617,Add test/distributed/test_c10d_mpi.py,2023-04-07 19:42:01+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
98600,Wrong illustration in README.md,2023-04-07 15:32:27+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
98587,Cannot use AT_CUDA_DRIVER_CHECK from user code,2023-04-07 09:51:24+00:00,,0,2,"[Label(name=""module: build""), Label(name=""module: cpp-extensions""), Label(name=""module: internals""), Label(name=""module: cuda""), Label(name=""triaged"")]"
98566,`F.interpolate` and `F.grid_sample` - documentation error and bug,2023-04-07 02:30:08+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""triaged"")]"
98561,Tracker - Failing models in the torch.compile dashboard,2023-04-07 00:18:32+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98557,torch.jit.script codegen warning with cuda and vmap,2023-04-06 23:43:55+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: functorch"")]"
98542,Training runs 50% slower when using 2 GPUs comparing to 1,2023-04-06 21:20:30+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
98541,Memory corruption using torch.ops.* to access re-registered operator,2023-04-06 21:19:23+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
98537,Segfault when using torch.ops.* to access de-registered op,2023-04-06 20:29:49+00:00,,0,3,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: library"")]"
98533,Dynamo compiled graph gets overwritten by eager in a data dependent branch when False branch is empty,2023-04-06 20:07:03+00:00,,2,8,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98515,torch.cond should work with expressions involving SymInt,2023-04-06 16:52:27+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
98503,Power VSX vectorization support disabled,2023-04-06 14:13:18+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: POWER"")]"
98499,`torch.nn.utils.rnn.unpad_sequence` modifies arguments in-place,2023-04-06 13:03:23+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: rnn""), Label(name=""triaged"")]"
98498,"Higher order derivatives not working when setting compute device to `torch.device(""mps"")`",2023-04-06 12:36:57+00:00,,0,9,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: mps"")]"
98497,[onnx]Unsupported: ONNX export of convolution for kernel of unknown shape,2023-04-06 12:16:13+00:00,,1,7,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
98495,Strided to batch BSR/BSC conversion fails when the number of zeros per block varies while the number of blocks per patch is constant,2023-04-06 11:28:56+00:00,,1,3,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
98487,torch.fx.GraphModule inside custom backend has `training` attribute always set to `True` regardless of the user settings,2023-04-06 08:02:12+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98486,Options are not forwarded to the custom backend,2023-04-06 07:44:40+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98484,Improvements to FSDP debugability,2023-04-06 06:54:50+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
98481,Bring CudaPluggableAllocator to feature parity with the Native Allocator,2023-04-06 04:43:37+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
98467,tacotron2 times out,2023-04-06 00:47:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
98465,Need better error message when a merge cancelled because of timeout,2023-04-05 23:54:00+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
98459,Fail to pass test HAVE_XXX_REGEX while  building pytorch ,2023-04-05 22:56:34+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
98456,README could use link to governance,2023-04-05 22:32:42+00:00,,0,3,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""triaged"")]"
98441,Torch Compile is slightly slower than eager mode.,2023-04-05 19:42:05+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98434,assert callable(unaltered_fn),2023-04-05 18:52:55+00:00,,1,3,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98422,[FX] Symbolic trace over `torch.Tensor.${fn}` APIs,2023-04-05 16:34:29+00:00,,0,0,"[Label(name=""oncall: fx"")]"
98419,Support backward hook optimizers in FSDP,2023-04-05 15:59:27+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
98416,Backwards graph is labeled incorrectly when dynamic=True,2023-04-05 14:19:49+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
98414,"PyTorch 1.12, high failure rate for test_optim/test_nadam",2023-04-05 14:04:46+00:00,,0,13,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
98413,TORCH_COMPILE_DEBUG and TORCH_LOGS interact badly,2023-04-05 14:03:54+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98409,`torch.Tensor.layout` is not documented,2023-04-05 13:45:51+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
98406,Contribute to the privateuse1 backend.,2023-04-05 13:04:15+00:00,,0,8,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: backend"")]"
98386,[PTD][Checkpoint] Enable single_file_per_rank for fsspec storage read/write,2023-04-05 05:56:34+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
98361,pip doesn't install the right version of pytorch when torchtext is involved,2023-04-04 23:13:44+00:00,,0,6,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
98355,Intermittent failure of mobilenet_v3_large,2023-04-04 22:20:41+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""oncall: pt2"")]"
98338,[functorch] [vmap] tests fail when `_set_vmap_fallback_enabled(False)`.,2023-04-04 19:07:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
98296,"""We don't have an op for aten::bitwise_and but it isn't a special case."" when exporting NMS operation as ONNX.",2023-04-04 12:52:38+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: onnx"")]"
98291,Make BetterTransformer implementation non-blocking,2023-04-04 10:39:13+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
98286,"When I use the DDP model, I use a custom loss function, when the batch size changes during training, the process will be stuck.",2023-04-04 09:01:24+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
98273,[Inductor] [CPU] Huggingface model BartForCausalLM & MBartForCausalLM & OPTForCausalLM & PLBartForCausalLM performance regression > 10% on 2023-04-02 nightly release,2023-04-04 03:36:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
98269,"Inconsistent nn.KLDivLoss behavior: 0s in target OK on cpu, but gives nan on mps",2023-04-04 02:39:53+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: mps"")]"
98268,hf_Longformer regression caused by https://github.com/pytorch/pytorch/pull/98119,2023-04-04 02:29:05+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
98260,Broken mypy check in test_type_hints.py::TestTypeHints::test_doc_examples,2023-04-04 00:08:58+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged"")]"
98259,DISABLED test_doc_examples (__main__.TestTypeHints),2023-04-03 23:39:33+00:00,,1,4,"[Label(name=""module: typing""), Label(name=""triaged""), Label(name=""skipped"")]"
98251,[Dynamo] Enable `dynamo.export` for huggingface models w/ `ModelOutput`,2023-04-03 21:52:18+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: pytree""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""oncall: export"")]"
98222,aten::_linalg_solve_ex.result' is not currently implemented for the MPS,2023-04-03 16:44:20+00:00,,1,11,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: mps"")]"
98212,Wrong results for GELU forward pass (CPU vs MPS) while  inferencing a GLPN model from huggingface,2023-04-03 13:36:12+00:00,,1,2,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
98210,torch.jit.script + legacy executor mode has diff in some pattern,2023-04-03 13:27:17+00:00,,0,1,"[Label(name=""oncall: jit"")]"
98208,Add a deterministic version of reflection_pad2d_backward_cuda,2023-04-03 12:25:00+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: determinism""), Label(name=""actionable"")]"
98204,NaN appears when initializing tensor,2023-04-03 09:54:42+00:00,,0,0,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
98203,"AssertionError: was expecting embedding dimension of 22, but got 1320",2023-04-03 08:48:21+00:00,,0,3,"[Label(name=""oncall: transformer/mha"")]"
98200,torch.nn.init functions with `generator` argument,2023-04-03 08:29:54+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: random""), Label(name=""actionable"")]"
98193,"RuntimeError: CUDA error: an illegal memory access was encountered, torch/cuda/streams.py"", line 94, in synchronize",2023-04-03 07:02:15+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
98189,[onnx] AdaptiveMaxPool2d can not convert to GlobalMaxPool,2023-04-03 05:58:40+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
98187,how can i load seperate pytorch_model.bin?,2023-04-03 05:05:07+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
98169,The operator 'aten::_weight_norm_interface' is not currently implemented for the MPS device.,2023-04-02 12:24:26+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: mps"")]"
98164,forward AD implimentation : _scaled_dot_product_efficient_attention ,2023-04-02 08:00:53+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: forward ad"")]"
98142,double free or corruption (fasttop),2023-04-01 13:35:10+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
98136,A Segment Fault can be triggered in torch._grid_sampler_2d_cpu_fallback,2023-04-01 08:58:55+00:00,,0,2,"[Label(name=""module: crash""), Label(name=""module: nn""), Label(name=""triaged"")]"
98133,[interoperability] zero-size cuda arrays do not look supported,2023-04-01 07:49:49+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
98124,PyTorch Profiler fails recording functions,2023-04-01 05:39:06+00:00,,0,2,"[Label(name=""oncall: profiler"")]"
98115,Request to cherrypick a fix into v1.13.1 (v1.8 has a CVE),2023-04-01 01:26:59+00:00,,0,6,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
98100,Unable to run session using exported ONNX model using dictionary input,2023-03-31 22:41:15+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
98089,GroupNorm cpu/gpu parity tests fail with pretty large differences,2023-03-31 18:25:16+00:00,,1,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
98077,Is there a recommended implementation of yuv2RGB for the current torch?,2023-03-31 11:12:54+00:00,,1,6,"[Label(name=""module: onnx""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
98075,Unexpected results with torch.nn.functional.layer_norm,2023-03-31 10:36:41+00:00,,0,4,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
98073, Add PrivateUse1 folder in aten/src/ATen,2023-03-31 10:06:42+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: backend"")]"
98070,Request custom backend device memory Allocator.,2023-03-31 09:01:36+00:00,,0,1,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: backend""), Label(name=""module: CUDACachingAllocator"")]"
98064,Module 'Sequential' has no attribute '_modules' :,2023-03-31 07:13:17+00:00,,0,4,"[Label(name=""oncall: jit"")]"
98059,DISABLED test_scatter_1d (__main__.DeviceMeshCollectiveTest),2023-03-31 03:40:37+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
98049,DISABLED test_all_gather_uneven (__main__.DeviceMeshCollectiveTest),2023-03-31 00:58:29+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
98048,DISABLED test_broadcast_1d (__main__.DeviceMeshCollectiveTest),2023-03-31 00:58:26+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
98013,Automate aarch64 builds,2023-03-30 19:47:41+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
98012,[Nova] Add metadata validation step to the smoke tests for core and domains,2023-03-30 19:46:15+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
98008,Write Binary Builds oncall runbook,2023-03-30 19:39:11+00:00,,1,0,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
98007,Create release checklist template for the Launch Date,2023-03-30 19:38:06+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
98006,Create a plan on removing conda dependency from CI/CD,2023-03-30 19:36:18+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
98004,matmul with CSR matrix in inference mode throws an exception,2023-03-30 19:15:37+00:00,,0,12,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
98002,DataLoader with collate_fn that returns tensors in GPU memory raises warnings when deleted,2023-03-30 18:53:40+00:00,,0,6,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
97992,torch.compile not compatible with multiprocessing pool,2023-03-30 16:45:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
97991,functional collective should respect the whole mesh,2023-03-30 16:39:27+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
97990,Relax version dependencies on CUDA pip wheels?,2023-03-30 16:23:28+00:00,,0,8,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
97976,Dynamo doesn't report accurate line numbers for <resume> in some situations,2023-03-30 12:28:51+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
97966,torch.randn signature is missing generator,2023-03-30 08:54:29+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random""), Label(name=""module: python frontend"")]"
97961,[CI/Infra] Record keeping: runner shutdown spike,2023-03-30 06:55:01+00:00,,0,3,"[Label(name=""triaged"")]"
97915,Investigate Lazy{*}Norm{*}d modules no batch dim support,2023-03-29 21:54:17+00:00,,1,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
97913,BUG torch.jit.annotate on List + torch.stack give wrong DTYPE,2023-03-29 21:40:31+00:00,,0,1,"[Label(name=""oncall: jit"")]"
97909,`torch.func.functional_call` doesn't work with compiled models,2023-03-29 20:54:51+00:00,,1,7,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
97902,Multiple model init using OpenMP in c++ does not speed up,2023-03-29 18:25:45+00:00,,0,5,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
97894,Dropout traces poorly with AotAutograd/make_fx,2023-03-29 17:07:39+00:00,,0,16,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
97892,A parameterized fill value for triu and tril functions,2023-03-29 16:55:54+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: viewing and reshaping"")]"
97888,Type conversion between float/complex,2023-03-29 16:03:32+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""enhancement"")]"
97876,Missing torch import in _contextlib.py when using torch.jit._recursive,2023-03-29 11:21:17+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""oncall: jit"")]"
97872,nn.linear not support bfloat16,2023-03-29 09:47:35+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
97865,Unable to install torch on python 3.8.16,2023-03-29 06:45:08+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged"")]"
97861,"torch.onnx.errors.OnnxExporterError: Unsupported: ONNX export of operator unsafe_chunk, unknown dimension size.",2023-03-29 06:17:41+00:00,,1,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
97856,make tensor data const correct,2023-03-29 05:16:12+00:00,,1,7,"[Label(name=""module: internals""), Label(name=""triaged"")]"
97852,Functionalize crashes on train_step GraphModule,2023-03-29 04:18:46+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functionalization"")]"
97849,TORCH_LIBRARIES variable leads to undefined reference function error in compiling while using libtorch in c++,2023-03-29 03:41:30+00:00,,0,10,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
97848,Document _wrap_fx_args_as_onnxscript_args,2023-03-29 03:19:19+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
97847,CUDA 10.2 cudnn 8.2.4 run Conv2d error,2023-03-29 01:52:30+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
97827,Memory leak when saving an input tensor returned as-is if mark_dirty and running with dual tensors,2023-03-28 21:35:15+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: edge cases""), Label(name=""module: forward ad"")]"
97823,Using `param in param_list` can trigger `non-singleton dimension` error?,2023-03-28 20:39:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
97802,Some c++ library docstrings incorrectly linked/repeated,2023-03-28 17:28:16+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: mps"")]"
97788,Add SSIM as Loss Function,2023-03-28 15:35:47+00:00,,1,1,"[Label(name=""feature""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""needs research"")]"
97784,torch.compile fails with torch._dynamo.exc.TorchRuntimeError on  a function that contains a torch script module,2023-03-28 15:15:01+00:00,,0,9,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
97783,The first epoch is very slow when using torch.compile,2023-03-28 14:49:54+00:00,,0,17,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
97772,consider bumping `DEFAULT_PROTOCOL`,2023-03-28 13:12:53+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
97761,torch.testing.assert_close: allow check to fail on part on the input,2023-03-28 11:06:37+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: testing"")]"
97760,Test Failure: TestUnaryUfuncsCPU.test_reference_numerics_normal_cos_cpu_float32 on s390x,2023-03-28 10:52:04+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
97757,oneDNN 3.0+ support,2023-03-28 07:48:50+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: intel"")]"
97750,irrelevant error output for Minified repro,2023-03-28 06:25:53+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: minifier"")]"
97749,Bug on Minified repro example ,2023-03-28 06:15:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: minifier"")]"
97748,TypeError: 'torch._C._TensorMeta' object is not iterable,2023-03-28 06:09:55+00:00,,1,9,"[Label(name=""module: windows""), Label(name=""module: rocm""), Label(name=""triaged"")]"
97718,Dynamo generates invalid frame when graph-breaking due to opacus_cifar10 hooks,2023-03-27 23:43:27+00:00,,2,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""module: dynamo""), Label(name=""release notes: dynamo"")]"
97711,dynamo sometimes hits the cache size limit due to the foreach flag in optimizer.step(),2023-03-27 21:49:39+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
97693, Compile targts cuda:0 rather than the device the model is on,2023-03-27 19:02:56+00:00,,0,12,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
97681,[FSDP] Consolidate test_fsdp_state_dict.py,2023-03-27 17:00:57+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
97676,Pytorch 2 compile + fsdp + transformers crash,2023-03-27 15:46:56+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: xla"")]"
97670,[FSDP] test model.eval() + keep_low_precision_grads,2023-03-27 14:14:15+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
97668,sparse_csr_tensor matmul wrong output in bfloat16,2023-03-27 13:54:17+00:00,,1,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
97659,How do I get the original object wrapped by the torch.fx.proxy class？,2023-03-27 10:46:30+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: fx"")]"
97656,[bug] Internal assert failed when using pyro,2023-03-27 09:39:20+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: linear algebra""), Label(name=""module: python frontend"")]"
97653,transposed 2d copy bfloat16 support,2023-03-27 07:41:40+00:00,,1,0,"[Label(name=""triaged""), Label(name=""intel"")]"
97652,torch.onnx.export support sparse tensor format,2023-03-27 07:24:09+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
97638,Regression in jit for f-strings with new lines,2023-03-26 19:24:36+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
97635,JAX + PyTorch produces `OMP: Error #13: Assertion failure at kmp_affinity.cpp(532)`,2023-03-26 18:45:39+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
97631,torch.zeros_like on a zero-sized BSR/BSC tensor results invalid tensor,2023-03-26 17:01:05+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
97623,Compile dynamic does not support GroupNorm in module,2023-03-26 08:17:50+00:00,,1,11,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
97606,"MPS: grid_sampler_2d falls back to CPU, even though warning says it is natively supported on macOS >=13.1",2023-03-25 19:13:05+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: mps"")]"
97597,Insufficient MPS Documentation,2023-03-25 09:52:42+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: mps"")]"
97595,can get_submodule be called within a ScriptFunction ?,2023-03-25 08:57:25+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
97580,Torch 2.0 import hangs forever,2023-03-25 00:16:21+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
97575,Multi-output derivative formulas can save unnecessary tensors,2023-03-24 23:42:24+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""actionable"")]"
97552,PackedSequence failure with MPS,2023-03-24 18:09:04+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mps"")]"
97539,InfoNCE loss for contrastive learning,2023-03-24 16:56:25+00:00,,0,0,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""enhancement"")]"
97504,"Burn benchmark suites into CI docker image. Not only this saves test time, but also it will get rid of occasional model installation failures. (@weiwangmeta )",2023-03-24 06:29:25+00:00,,1,0,"[Label(name=""triaged"")]"
97503,torch.cppExtension won't work with wsl2,2023-03-24 06:26:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: wsl"")]"
97501,torch.compile not work in WSL,2023-03-24 06:17:17+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: wsl""), Label(name=""oncall: pt2"")]"
97500,.set_ operation on a view (detach()) of the view tensor changes grad_fn of the original view tensor from ViewBackward0 to AsStridedBackward0,2023-03-24 05:52:29+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""has workaround"")]"
97499,`onnxrt` fails with compilations,2023-03-24 05:44:00+00:00,,1,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
97498,Function Registry for extending collate_fn,2023-03-24 05:08:30+00:00,,0,11,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
97484,[DTensor] Add a unittest to cover default PG condition for DeviceMesh,2023-03-23 23:29:07+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
97474,"make_fx(functionalize(f), tracing_mode='symbolic') breaks on torch.matmul",2023-03-23 22:07:57+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
97469,Improve collectives fingerprinting,2023-03-23 21:17:33+00:00,,0,5,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: c10d"")]"
97456,pytorch dynamic quantized model failed to convert to onnx ,2023-03-23 18:57:19+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
97439,Change progressbar for hub,2023-03-23 13:40:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: hub"")]"
97436,torch.compile not working with gradient checkpointing,2023-03-23 11:55:13+00:00,,1,19,"[Label(name=""module: checkpoint""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
97432,suspicious memory leak when increase DataLoader's prefetch_factor and enable pin_memory,2023-03-23 09:16:05+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
97426,"Unsupported: ONNX export of operator group_norm, unknown input rank.",2023-03-23 08:00:37+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
97421,"After the release of pytorch 2.0.0, the compilation of ACLs is problematic.",2023-03-23 06:27:48+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
97414,Support running torch.compile with meta tensors,2023-03-23 02:13:34+00:00,,0,6,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
97408,Further memcopy improvement at FX body level,2023-03-23 01:34:38+00:00,,0,0,"[Label(name=""triaged"")]"
97402,DISABLED test_checkpoint_trigger (__main__.TestCheckpoint),2023-03-23 00:57:20+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
97397,Import fails when both `USE_TENSORPIPE=OFF` and `USE_DISTRIBUTED=ON`.,2023-03-23 00:40:34+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: tensorpipe"")]"
97395,Expanded weights tests broken,2023-03-23 00:07:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
97352,Sparse is not available on Windows,2023-03-22 14:53:05+00:00,,1,0,"[Label(name=""module: sparse""), Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged"")]"
97344,torch.onnx.export crashes on ReduceMax operator with onnx opset 18,2023-03-22 12:52:09+00:00,,0,7,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
97343,Traced module shows non-deterministic behaviour on CUDA,2023-03-22 12:27:52+00:00,,0,0,"[Label(name=""oncall: jit"")]"
97333,`torch.fmod` produces inconsistent results in eager and compile mode,2023-03-22 09:58:49+00:00,,0,4,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
97329,"torch.ops.aten.pow(2.0, 3) return unexpected value with complex type",2023-03-22 08:33:52+00:00,,0,5,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: custom-operators"")]"
97310,MPS: `unique` and `unique_consecutive` extremely slow when `return_counts=True`,2023-03-22 02:46:50+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: mps"")]"
97295,Torch Dynamo allow_in_graph doesn't capture the custom function in graph,2023-03-21 22:24:39+00:00,,1,19,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
97286,`jacrev` and `jacfwd` raise an error that `Sparse CSR tensors do not have strides`,2023-03-21 21:39:08+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: functorch"")]"
97284,"test_sparse_addmm fails on linux-bionic-py3.11-clang9 / test (crossref, 1, 2, linux.2xlarge)",2023-03-21 20:57:15+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: decompositions"")]"
97283,`jacfwd` fails when computing the gradient for `channels_last` tensor,2023-03-21 20:52:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: functorch"")]"
97271,[composable FSDP] clip_grad_norm,2023-03-21 18:45:27+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
97268,Desync debugger encounters traceMap error,2023-03-21 18:17:42+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""bug"")]"
97246,functorch roll-up issue for 2.1,2023-03-21 13:56:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
97236,Non-deterministic results when training a model on GPU with MPS backend,2023-03-21 11:01:19+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""module: mps"")]"
97225,Incompatibility with complex tensors,2023-03-21 07:31:34+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""oncall: pt2"")]"
97210,"INTERNAL ASSERT FAILED at ""../c10/cuda/CUDAGraphsC10Utils.h"":73, please report a bug to PyTorch. Unknown CUDA graph CaptureStatus32729",2023-03-21 02:36:12+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
97201,aten::sym_size is not using torch._ops.OpOverload in FX graph,2023-03-21 00:28:19+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
97196,Sequential/Partial unpickling and loading of models,2023-03-20 23:10:11+00:00,,0,1,"[Label(name=""module: pickle""), Label(name=""triaged"")]"
97189,torch.randint range for torch.int64 dtype seems wrong,2023-03-20 21:57:52+00:00,,0,5,"[Label(name=""triaged""), Label(name=""topic: docs""), Label(name=""module: python frontend"")]"
97188,Building LibTorch on Ubuntu with Mac M1,2023-03-20 21:53:41+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: torchbind""), Label(name=""module: m1"")]"
97174,Nightly conda binaries failed to pass tests since 2023-03-17 ,2023-03-20 19:08:37+00:00,,1,2,"[Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""module: ci""), Label(name=""triaged"")]"
97163,[FSDP][optim_state_dict] Need more comprehensive tests for optim_state_dict interface,2023-03-20 16:59:41+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
97156,Implement `torch.distributions.Poisson.cdf()`,2023-03-20 15:35:48+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
97155,Custom recurrent network takes very long to compile for long sequences,2023-03-20 15:28:06+00:00,,0,12,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: python dispatcher"")]"
97154,RPC Tutorial can not profile the  rpc operations communication between workers,2023-03-20 15:21:22+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""oncall: profiler"")]"
97146,Problem with Hugging Face model that is not in training loop,2023-03-20 11:35:12+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
97138,RuntimeError: NYI: Named tensors are not supported with the tracer,2023-03-20 08:03:04+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
97135,Incorrect gradient calculation for upsample nearest on CUDA,2023-03-20 07:04:04+00:00,,1,7,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
97128,"MultiHeadAttention, fast path broken with `bias=False` or uneven number of heads",2023-03-20 06:01:36+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
97118,nn.Conv function to compute conv formula,2023-03-19 23:51:25+00:00,,1,4,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
97115,[Dynamo] symbolic_convert returns ValueError: Cell is empty,2023-03-19 20:40:48+00:00,,0,13,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
97114,[Feature Proposal: New Distributed Training Algorithms] LSGD and EASGD,2023-03-19 20:34:34+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
97111,TransformerEncoder truncates output when some token positions are masked by `src_key_padding_mask` across batch,2023-03-19 16:18:44+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""oncall: transformer/mha"")]"
97109,"""Adaptive pool MPS: input sizes must be divisible by output sizes"", I keep getting this error even when I try to adjust for size",2023-03-19 14:27:41+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: mps"")]"
97106,slow torch import on macos ,2023-03-19 06:56:28+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: macos"")]"
97097,torch.cuda.FloatTensor().normal_() generate (partially) different sample on different gpu machines,2023-03-18 20:42:07+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
97088,A Segment Fault can be triggered in torch.embedding,2023-03-18 11:01:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
97087,A Segment Fault can be triggered in torch.adjoint,2023-03-18 10:58:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
97086,A crash due to Floating Point Exception can be triggered in torch.index_select,2023-03-18 10:53:40+00:00,,1,5,"[Label(name=""module: crash""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
97083,Inconsitent results before/after compilation for squeeze + tensor mutation + if statement,2023-03-18 07:46:19+00:00,,0,6,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: inductor""), Label(name=""module: pt2-dispatcher"")]"
97079,[compile] KeyError: example_value,2023-03-18 05:59:25+00:00,,1,4,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
97078,[compile] TypeError: __init__() missing 1 required positional argument: 'parent_module',2023-03-18 05:55:56+00:00,,1,8,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2"")]"
97068,[RFC] CPU float16 performance optimization on eager mode.,2023-03-18 01:26:22+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: half"")]"
97047,Optimize for mobile produces incorrect result with INSERT_FOLD_PREPACK_OPS optimization,2023-03-17 20:22:12+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""oncall: mobile""), Label(name=""actionable"")]"
97030,DDP static graph fails for static model,2023-03-17 16:21:33+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
97026,How to get list of all valid devices?,2023-03-17 15:37:00+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
97016,[Inductor] atomic_add does not support bf16,2023-03-17 12:45:36+00:00,,0,10,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
97014,deprecate integral and boolean dtype support torch.logit and torch.special.logit,2023-03-17 11:07:19+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: special"")]"
97006,[Feature Request] Compile compatible Neighborhood Algorithms for large Tensors,2023-03-17 07:17:43+00:00,,0,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
97004,Small learning rate with `capturable=True` causes Adam optimizer to blow up model parameters.,2023-03-17 06:11:36+00:00,,0,4,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
96996,"Get error: ""tuple index with non-constant index"" when exporting a model to ONNX format",2023-03-17 02:03:44+00:00,,1,8,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
96982,[mps] conv1d outputs zeros,2023-03-16 21:53:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
96981,[ONNX] Export failed for Module with Keyword-only inputs,2023-03-16 21:19:53+00:00,,1,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
96972,Adding sparse `addmv` and `triangular_solve` support on CPU - Mac OS - Apple Silicon M2,2023-03-16 18:43:19+00:00,,1,21,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
96964,GPU：7900xtx Pytorch2.0.0  rocBLAS error:,2023-03-16 17:01:27+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""module: rocm""), Label(name=""triaged"")]"
96926,torch.onnx.export failed for models with Bernoulli operator,2023-03-16 02:21:07+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
96908,Doing inplace on a inplace view of tensor that retains_grad triggers internal assert,2023-03-16 00:46:31+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""has workaround"")]"
96883,Expected scalar type Half but found Float when running nn.MultiheadAttention with AMP,2023-03-15 20:06:24+00:00,,0,1,"[Label(name=""oncall: transformer/mha"")]"
96855,Performance Drop for linalg_ldl_factor and ldl_solve,2023-03-15 01:20:04+00:00,,1,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable""), Label(name=""module: vmap""), Label(name=""module: functorch"")]"
96789,`cumprod` triggers INTERNAL ASSERT FAILED when `out` is a tensor on cuda but input is on cpu,2023-03-15 00:30:22+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
96779, Segmentation fault (core dumped) during Torch finetuning (at random step),2023-03-14 21:36:12+00:00,,0,0,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
96773,[MPS] pinverse dtype error,2023-03-14 20:47:12+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: mps"")]"
96769,`sparse.mm` triggers INTERNAL ASSERT FAILED when backwarding,2023-03-14 20:15:43+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
96766,Follow-ups to do after adding nested checkpoint,2023-03-14 19:27:23+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
96764,Improve checkpoint thread-safety,2023-03-14 19:22:55+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""needs design"")]"
96757,[ONNX] FX exporter 'test_models_onnxruntime.py' tracker,2023-03-14 17:53:09+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
96743,Pruning under channels_last format,2023-03-14 14:44:37+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: pruning"")]"
96742,Pytorch2.0 compile error,2023-03-14 14:41:35+00:00,,1,8,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
96738,Many padding Module fail memory_format tests,2023-03-14 13:20:33+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""actionable""), Label(name=""module: intel"")]"
96735,when run python run_test.py -i test_ops_jit error like this. ValueError: option names {'--junit-xml-reruns'} already added,2023-03-14 07:13:59+00:00,,0,0,"[Label(name=""oncall: jit"")]"
96726,Memory not release after jit.trace/freeze,2023-03-14 05:01:38+00:00,,0,11,"[Label(name=""oncall: jit"")]"
96716,[MPS] `.to('mps')` zeroes out elements in tensors taking up >=2^32 bytes,2023-03-14 02:39:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
96713,[Inductor] [CPU] Huggingface model MobileBertForQuestionAnswering performance regression > 10% on 2023-03-12 nightly release,2023-03-14 02:16:55+00:00,,2,3,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
96704,`logical_xx` operations trigger INTERNAL ASSERT FAIL when `input` is complex tensor on cuda and `other` is on cpu,2023-03-14 00:31:19+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex"")]"
96693,"torch.compile mode=""max-autotune"" precision appears to be lower",2023-03-13 21:46:59+00:00,,0,8,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
96692,[H100] `test_ops.py::TestFakeTensorCUDA.test_fake_crossref_backward_amp_nn_functional_scaled_dot_product_attention_cuda_float32` failed,2023-03-13 21:42:15+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
96686,"No GPU found, using CPU during preprocessing Error processing dataset with NsfHifiGAN ",2023-03-13 21:10:32+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: windows""), Label(name=""module: cuda""), Label(name=""triaged"")]"
96677,[FSDP] Make FSDP support local optimizer state_dict,2023-03-13 20:04:48+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
96670,Harden composable fully_shard: Checklist,2023-03-13 18:31:40+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
96643,PyTorch SGEMV is using 1 single core on AMD CPUs (very slow),2023-03-13 11:28:53+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
96639,Completely different output between .pt and .ptl,2023-03-13 08:38:36+00:00,,0,2,"[Label(name=""oncall: mobile"")]"
96637,Not allow force merge when lint fails and not because of broken trunk,2023-03-13 07:11:05+00:00,,0,4,"[Label(name=""module: ci""), Label(name=""triaged"")]"
96633,Request for adding Warning/Error feature when dropout set to 1.0 in Transformer layer,2023-03-13 03:43:44+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
96632,"torch.cuda.graph ""Invalid capture"" with torch.linalg.solve",2023-03-13 02:20:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
96629,Dataloader should kill & restart workers when timeout is hit,2023-03-13 00:58:44+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
96617,Build errors in two Vulkan files,2023-03-12 10:00:01+00:00,,0,0,"[Label(name=""oncall: mobile""), Label(name=""module: vulkan"")]"
96615,Tensor Permutation Along Given Axis,2023-03-12 09:13:38+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
96614,[MPS] Incorrect results for cumsum with bool tensors,2023-03-12 07:35:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
96613,The output of torch.histc is incorrect on both CPU and CUDA,2023-03-12 05:20:59+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
96608, No matching distribution found for torch==1.13.1+cu117,2023-03-11 16:52:02+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
96602,"[MPS] softmax returns NaN attention probabilities for large tensors, in float16 and float32.",2023-03-11 13:35:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
96595,Why doesn't PyTorch install the REAL nvidia cuDNN pip package?,2023-03-11 04:18:22+00:00,,0,6,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
96585,Proposal: Disable GC in test suite; GC after every test case,2023-03-11 01:32:54+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: infra""), Label(name=""module: testing""), Label(name=""module: devx"")]"
96579,Wrong return type from operation on custom tensor inside registered hook ,2023-03-11 00:54:04+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: __torch_function__""), Label(name=""tensor subclass"")]"
96560,Enable functorch testing for rocm,2023-03-10 22:14:49+00:00,,1,3,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: functorch"")]"
96559,tests for linearize fail under the dynamo CI config,2023-03-10 22:09:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
96555,early stopping,2023-03-10 22:01:43+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs design"")]"
96538,[ONNX] FX exporter 'test_pytorch_onnx_onnxruntime.py' tracker,2023-03-10 19:02:37+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
96523,"MPS Backend Doc, model = YourFavoriteNet() not defined",2023-03-10 15:40:23+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: mps"")]"
96518,fft should ignore dims with shape 1,2023-03-10 14:38:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fft"")]"
96494,The sign of torch.distributions.transforms.PowerTransform seems to be incorrect,2023-03-10 05:11:14+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
96467,"[MINIFIER] Running code snippet with  TORCHDYNAMO_REPRO_AFTER=""dynamo"" leads to error",2023-03-09 23:47:03+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: minifier"")]"
96456,Shape Error when training HF deberta-base with Inductor,2023-03-09 22:08:48+00:00,,0,12,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: meta tensors""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
96449,'aten::affine_grid_generator' to ONNX opset version 14 is not supported,2023-03-09 21:34:30+00:00,,1,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
96448,Unable to move torch.jit.load-ed models to XLA devices,2023-03-09 21:33:59+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""module: xla"")]"
96447,Information about CPU in `collect_env` is too verbose,2023-03-09 21:12:34+00:00,,0,2,"[Label(name=""module: collect_env.py""), Label(name=""triaged"")]"
96428,Compressed sparse constructor allows mixed `int32/int64` indices which leads to dtype promotion/demotion in conversions.,2023-03-09 17:05:36+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
96420,Add location information when exception are thrown in `torch.jit.annotations.try_ann_to_type`,2023-03-09 14:08:48+00:00,,0,2,"[Label(name=""oncall: jit"")]"
96412,Proxy Options for Pytorch Hub,2023-03-09 11:27:41+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: hub"")]"
96409,"Initialization on `meta` device failing for models containing `nn.utils.weight_norm`, with `NotImplementedError: Could not run 'aten::_weight_norm_interface' with arguments from the 'Meta' backend.`",2023-03-09 09:07:17+00:00,,0,3,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: meta tensors"")]"
96396,[dynamo] add hook to modify instructions before/after instructions be generated,2023-03-09 03:50:03+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: dynamo"")]"
96386,"[export] ""strict subset of traced input/output"" error when huggingface `ModelOutput` is returned",2023-03-09 02:35:23+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: dynamo""), Label(name=""oncall: export"")]"
96379,"`dynamo.export` ""input not consistent with traced input"" error when input default value type is `torch.Tensor`.",2023-03-09 01:29:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""onnx-needs-info""), Label(name=""module: dynamo""), Label(name=""oncall: export"")]"
96372,[BE] Avoid .data usage in FSDP buffer casting,2023-03-09 00:46:42+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
96319,views created in __torch_dispatch__ share storage but not version_counter,2023-03-08 18:44:43+00:00,,0,11,"[Label(name=""module: autograd""), Label(name=""module: molly-guard""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: __torch_dispatch__"")]"
96318,Support managed memory backed dlpack with  torch.from_dlpack,2023-03-08 18:36:09+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: dlpack"")]"
96316,`FractionalMaxPool3d` INTERNAL ASSERT FAILED when computing `jacrev`,2023-03-08 18:29:32+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: edge cases"")]"
96305,"Reuse autograd.grad graph for rapid, repeated gradient calculation",2023-03-08 15:12:55+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
96296,Inductor guards are not propagated to Dynamo with dynamic shapes,2023-03-08 13:08:55+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
96292,Better error message when trying to run fp16 weights on CPU,2023-03-08 10:57:00+00:00,,0,6,"[Label(name=""good first issue""), Label(name=""module: error checking""), Label(name=""triaged"")]"
96282,DISABLED test_scatter_uneven (__main__.DeviceMeshCollectiveTest),2023-03-08 06:41:22+00:00,,1,9,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
96282,DISABLED test_scatter_uneven (__main__.DeviceMeshCollectiveTest),2023-03-08 06:41:22+00:00,,1,9,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
96277,A Segment Fault can be triggered in torch.adaptive_max_pool1d with an edge case,2023-03-08 06:10:16+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
96276,A Segment Fault can be triggered in torch.geqrf with an edge case,2023-03-08 06:06:12+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
96275,A Segment Fault can be triggered in torch.pinverse,2023-03-08 05:59:47+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
96265,RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation,2023-03-08 02:17:45+00:00,,0,2,"[Label(name=""triaged"")]"
96236,nn.interpolate scale_factor floors output size with floating ,2023-03-07 23:19:43+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
96225,[MPS] F.conv1d and F.conv2d produce incorrect gradients when minibatch >= 2^16,2023-03-07 22:06:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
96205,[Dynamo] HuggingFace transformers configuration_utils graph break workaround,2023-03-07 17:48:55+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
96198,dynamo + dict subclass + tensor instance check: NotImplementedError,2023-03-07 15:25:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
96187,`gradgradcheck` does not work with sparse inputs.,2023-03-07 10:40:44+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
96185,`ld: error: unknown argument '-force_load'` when linking libtorch on Android,2023-03-07 09:38:11+00:00,,0,1,"[Label(name=""module: build""), Label(name=""oncall: mobile"")]"
96161,[torchdistx] Future of the large model initialization,2023-03-07 01:38:06+00:00,,0,8,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""module: meta tensors""), Label(name=""module: fsdp"")]"
96153,mps bug: failed assertion `[MPSNDArrayDescriptor sliceDimension:withSubrange:] error: subRange.start (6) is not less than length of dimension[0] (6)',2023-03-07 00:07:43+00:00,,0,8,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: viewing and reshaping""), Label(name=""module: mps"")]"
96140,mkldnn matmul kernel may be slower than openblas kernel for very small tensor shapes,2023-03-06 22:24:05+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
96136,`torch.utils.checkpoint` should avoid updating BatchNorm statistics twice,2023-03-06 21:39:23+00:00,,0,1,"[Label(name=""module: checkpoint""), Label(name=""triaged"")]"
96123,make_fx tracing with dynamic shapes should also disable_slice_optimization,2023-03-06 20:01:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
96118,Activation Checkpointing PT2 - AOTAutograd cannot handle set_rng_state ,2023-03-06 19:02:07+00:00,,1,1,"[Label(name=""module: checkpoint""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
96111,Static size boolean masking,2023-03-06 17:44:34+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
96110,torch.where behaves differently from in place replacement,2023-03-06 17:42:50+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""triaged"")]"
96098,Error during inference on iOS: INTERNAL ASSERT FAILED at it_type_base.h:535,2023-03-06 14:40:47+00:00,,0,2,"[Label(name=""oncall: jit"")]"
96088,DISABLED test_nn_sequential_invocation_dynamic_shapes (torch._dynamo.testing.DynamicShapesMiscTests),2023-03-06 09:39:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
96085,Add support for `__collate__` attrib on dataset elements in `default_collate`,2023-03-06 08:29:44+00:00,,0,4,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
96073,Pytorch 2.0 installation tutorial does not work under Macbook,2023-03-06 03:42:12+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: macos"")]"
96060,Linking libtorch with QT5 OpenGL application using llvmpipe mesa opengl crashes,2023-03-05 15:58:01+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
96056,MPS device throws error for `F.adaptive_avg_pool2d`,2023-03-05 11:05:21+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mps"")]"
96047,No speedup and a null pointer exception,2023-03-05 03:13:29+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
96046,Add arm64 builds for libtorch on MacOS with mps support,2023-03-05 02:49:47+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: infra""), Label(name=""module: arm"")]"
96041,Cannot access data pointer of Tensor that doesn't have storage when using `torch.func.jvp` with `torch.compile`,2023-03-04 21:50:31+00:00,,0,6,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
96036,Questions and Possible Features: Pytorch RPC 'future.wait()' will not release GIL which will block other thread's execution when using multithreading.,2023-03-04 14:54:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: multithreading"")]"
96033,Encourage dynamo.export users to assume static by default if they call nonzero / unbacked SymInt,2023-03-04 14:22:39+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""oncall: export"")]"
95973,Graphstate checkpointing doesn't checkpoint ShapeEnv / shape guards,2023-03-03 16:02:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
95960,`@torch.jit.unused` does not properly ignore unsupported function signature,2023-03-03 11:38:31+00:00,,0,3,"[Label(name=""oncall: jit"")]"
95957,FSDP fails to load state dict under inference_mode,2023-03-03 09:32:18+00:00,,1,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""inference mode""), Label(name=""module: fsdp"")]"
95956,[vulkan] missing aten::reflection_pad1d.out operator,2023-03-03 08:46:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vulkan"")]"
95953,The torch.sparse document's typo error,2023-03-03 07:58:05+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""module: docs""), Label(name=""triaged"")]"
95946,"Build from source,  Undefined symbol: c10::detail::maybe_wrap_dim_slow(long long, long long, bool)",2023-03-03 06:11:09+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
95945,CPU time performance is unstable,2023-03-03 05:43:53+00:00,,1,29,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
95944,training hangs at line torch.cuda.synchronize(),2023-03-03 05:10:52+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
95934,arange bug,2023-03-03 02:05:52+00:00,,1,5,"[Label(name=""module: numerical-stability""), Label(name=""triaged"")]"
95921,ROCm distributed flaky on test_distributed_spawn,2023-03-03 00:03:01+00:00,,0,2,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
95917,torchvision Caltech101 collate_fn error,2023-03-02 23:13:10+00:00,,1,1,"[Label(name=""triaged"")]"
95916,autograd.functional.jacobian : tensor instead of function as input for reverse mode?,2023-03-02 22:29:41+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""has workaround"")]"
95895,[PTD] dist.barrier() unreliable when using collectives from multiple threads.,2023-03-02 18:41:46+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
95872,corrupted size vs prev size error,2023-03-02 08:22:09+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: ddp"")]"
95864,Input names provided three but onnx recognizes two inputs only,2023-03-02 06:07:34+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
95858,[JIT] Support string type annotations in NamedTuples,2023-03-02 04:15:44+00:00,,1,0,"[Label(name=""oncall: jit"")]"
95856,`AssertionError: Activation` when compile spconv structure like `BaseBEVBackbone`,2023-03-02 03:55:07+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
95815,Let Nested Tensor Metadata be cached on GPU,2023-03-01 20:32:04+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
95789,drastic speed regression of torch.jit.load starting with the 20230301 nightly,2023-03-01 16:08:28+00:00,,0,3,"[Label(name=""oncall: jit"")]"
95786,Static asserts on accessor templates,2023-03-01 15:43:23+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
95785,Fully quantized model (`torch.quantization.convert`) produces incorrect output compared to analytical solution,2023-03-01 15:38:37+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
95779,SymInt'ify _gather_sparse_backward,2023-03-01 13:14:37+00:00,,0,0,"[Label(name=""triaged"")]"
95776,`torch.Tensor.is_set_to` raises `NotImplementedError` when inputs contain sparse tensor ,2023-03-01 12:32:33+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
96740,Implementing the batching rule for aten::bucketize.Tensor.,2023-03-01 08:49:19+00:00,,1,0,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: vmap""), Label(name=""module: functorch"")]"
95768,Inconsistent behaviour of torch.all(),2023-03-01 07:23:52+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
95756,`torch.nanmedian` return a negative value when input is empty ,2023-03-01 02:51:34+00:00,,0,4,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
95727,dist.barrier() should be able to go through custom backend,2023-02-28 19:46:37+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
95724,"distributed training: lots of ""Exception ignored"" at the end of each epoch",2023-02-28 19:15:01+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
95718,functorch.compile.memory_efficient_fusion errors with: RuntimeError: forward() Expected a value of type 'Tensor (inferred)' for argument 'primals_356' but instead found type 'int'. ,2023-02-28 18:13:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
95712,Multiheadattention module doesn't implement the function about kdim and vdim,2023-02-28 16:46:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: multi-headed-attention"")]"
95711,`copy.deepcopy` does not copy gradients of nn.Parameter,2023-02-28 16:36:46+00:00,,1,6,"[Label(name=""module: bc-breaking""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""topic: bc breaking"")]"
95708,Dynamo + MacOS: fatal error: 'omp.h' file not found,2023-02-28 15:38:28+00:00,,1,16,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""oncall: pt2"")]"
95696,Can only import torch after Tensorflow accessed its gpu device,2023-02-28 09:35:44+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
95677,Unable to import ``torch.linalg``,2023-02-28 02:09:11+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
95648,torch needs to SHOW that it support sm_89 even if functionally the same as sm_86,2023-02-27 21:06:31+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
95645,Create a new Docker image with all inductor benchmarks and pre-trained models downloaded,2023-02-27 20:24:27+00:00,,1,4,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: devx"")]"
95628,Pytorch Home Page does not specify which version of python it requires,2023-02-27 18:27:54+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
95622,"Testing InvokeAI 2.3.1.post1, using mps, with PyTorch nightly dev20230226 yields RuntimeError cross-device copies are not allowed!)",2023-02-27 17:00:48+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: mps"")]"
95613,[onnx] sort / argsort with `stable` argument specified cannot be exported to onnx,2023-02-27 14:16:40+00:00,,1,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
95604,"Performance bugs exists in multiple convolution operations(e.g., `Convtranspose2d`) when useing the `groups` argument",2023-02-27 09:22:52+00:00,,0,16,"[Label(name=""module: cudnn""), Label(name=""module: docs""), Label(name=""module: convolution""), Label(name=""triaged"")]"
95595,TorchInductor fails with memoy violations in `test_comprehensive_grid_sampler_2d_cuda_float16` and `test_reflection_pad2d_dynamic_shapes_cuda`,2023-02-27 05:44:46+00:00,,1,6,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
95590,Confusing error messages from `torch.nn.LazyLinear` in different versions.,2023-02-27 03:31:48+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: lazy"")]"
95572,Support datatype argument for torch.distributed.all_gather() (And the whole distributed module),2023-02-26 07:42:16+00:00,,1,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""module: c10d"")]"
95562,test_layer_norm_backward and test_layer_norm_backward_5d run OOM in slow gradcheck,2023-02-25 20:56:29+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
95560,torch.jit.load documentation doesn't specify if it is safe to load untrusted models or not,2023-02-25 20:20:26+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: docs""), Label(name=""security"")]"
95548," torch.distributions.kumaraswamy.Kumaraswamy generates samples outside its support (0,1)",2023-02-25 07:11:02+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
95538,Tensor.all() fails on MPS for tensors with more than 4 dimensions,2023-02-25 01:07:37+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: reductions""), Label(name=""module: mps"")]"
95501,dynamo+aot improperly handles dupe args via *args,2023-02-24 20:38:42+00:00,,2,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
95497,Import parameters from jit,2023-02-24 20:21:55+00:00,,0,0,"[Label(name=""oncall: jit"")]"
95487,Torch RPC on multiple nodes with GPU returns a EOF error,2023-02-24 17:23:46+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
95485,Enrich shape operations with nested tensors,2023-02-24 17:13:47+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
95481,[BE] Make ActivationWrapper an abstract class,2023-02-24 16:45:01+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering"")]"
95463,`add/add_` for CSC: errors when trying to access non-existent `crow_indices`.,2023-02-24 10:45:14+00:00,,1,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
95462,Extend docs - Fixing out of memory with python garbage collection,2023-02-24 09:30:34+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
95460,torch.profiler.tensorboard_trace_handler Generates an incorrect JSON file,2023-02-24 09:04:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
95434,It seems that `torch.Tensor.addmv` and `torch.Tensor.addr` will check some inputs' dtype if and only if in `backward()`,2023-02-24 01:50:57+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: type promotion""), Label(name=""module: linear algebra""), Label(name=""actionable""), Label(name=""complex_autograd"")]"
95432,Regression bug in `torch.nn.ReLU6` and `torch.nn.Hardtanh` that `inplace=True` doesn't work in PyTorch 1.10.0~1.13.1,2023-02-24 01:47:35+00:00,,1,3,"[Label(name=""high priority""), Label(name=""module: nn""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""actionable"")]"
95412,DISABLED test_variant_consistency_jit_linalg_lstsq_cpu_complex64 (__main__.TestJitCPU),2023-02-23 21:39:28+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
95408,Parallel Associative Scan,2023-02-23 21:09:20+00:00,,0,23,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
95403,test_ddp_apply_optim_in_backward in distributed_test.py fails for gloo backend,2023-02-23 19:50:07+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
95394,Add log highlights to Dr. CI's failed jobs,2023-02-23 18:58:07+00:00,,0,0,"[Label(name=""triaged"")]"
95380,Investigate/add Windows Arm64 support for cpuinfo,2023-02-23 16:04:26+00:00,,1,3,"[Label(name=""module: windows""), Label(name=""triaged""), Label(name=""module: arm"")]"
95374,Add oscillating activation functions to PyTorch.,2023-02-23 12:05:23+00:00,,0,3,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""needs research"")]"
95369,build failed when strictly following the guidelines,2023-02-23 08:59:17+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
95337,Changing behavior of module.to() to better support mixed real- and complex-valued parameters,2023-02-22 23:19:15+00:00,,1,15,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""needs design"")]"
95320,Circular padding error for 3D arrays,2023-02-22 21:57:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: padding"")]"
95309,`torch.distributed.Store` triggers INTERNAL ASSER FAILED when seting,2023-02-22 19:34:45+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
95304,`torch.cartesian_prod` returns inconsistent dimensions with only one input,2023-02-22 18:29:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
95290,Continuous dropout layer,2023-02-22 14:47:02+00:00,,1,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
95276,tabulate is used by `torch.fx.graph_module.GraphModule.print_tabular` but is not installed when installing pytorch,2023-02-22 08:22:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
95244,Make this ridiculously long error message more user friendly,2023-02-21 22:11:07+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: infra"")]"
95238,Pytorch profiler stack exporting does not work,2023-02-21 21:17:30+00:00,,0,0,"[Label(name=""oncall: profiler"")]"
95237,test_foreach failing cuda memory leak check,2023-02-21 21:08:59+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: mta"")]"
95229,ONNX Exporter for circular padding mode in convolution ops,2023-02-21 18:05:55+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
95225,Remove conda virtualenv from the docker image,2023-02-21 16:28:42+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: docker"")]"
95210,Add parallel attention layers and Multi-Query Attention (MQA) from PaLM to the fast path for transformers,2023-02-21 14:21:28+00:00,,0,16,"[Label(name=""oncall: transformer/mha"")]"
95207,"new backend privateuseone with ""to"" op",2023-02-21 13:52:13+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: backend"")]"
95194,High Cuda Memory Consumption for Simple ResNet50 Inference,2023-02-21 09:18:15+00:00,,0,0,"[Label(name=""oncall: jit"")]"
95172,DISABLED test_memory_format_nn_ConvTranspose2d_cuda_complex32 (__main__.TestModuleCUDA),2023-02-20 21:39:26+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
95169,COO @ COO tries to allocate way too much memory on CUDA,2023-02-20 16:08:54+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""matrix multiplication"")]"
95161,AOTAutograd based torch.compile doesn't capture manual seed setting in the graph,2023-02-20 12:15:09+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch"")]"
95160,"Reversing along a dimension, similarly to numpy",2023-02-20 11:54:58+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing"")]"
95146,Whether to consider native support for intel gpu？,2023-02-20 02:30:47+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: intel"")]"
95135,Add local version identifier to wheel file names,2023-02-19 13:05:09+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
95132,Differentiate with regard a subset of the input,2023-02-19 09:17:12+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
95129,Default value of `validate_args` is set to `True` when passed as `None` in `Multinomial`,2023-02-19 06:50:00+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
95124,"`INTERNAL ASSERT FAILED` -When using the PyTorch docker environment released by pytorch, a Vulcan support issue occurs",2023-02-19 02:30:43+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: docker"")]"
95122,CosineAnnealingWarmRestarts but restarts are becoming more frequent,2023-02-18 17:01:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
95121,cuda 12 support request.,2023-02-18 16:59:16+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
95116,"When using `ceil_mode=True`, `torch.nn.AvgPool1d` could get negative shape.",2023-02-18 11:48:49+00:00,,1,0,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: shape checking""), Label(name=""topic: bc breaking"")]"
95112,"Proposal: `@capture`: Unified API for capturing functions across `{fx, proxy_tensor, dynamo}`",2023-02-18 09:59:49+00:00,,1,7,"[Label(name=""module: onnx""), Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
95108,`torch.nn.LazyLinear` crash when using torch.bfloat16 dtype in pytorch 1.12.0 and 1.13.0,2023-02-18 01:15:23+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""intel"")]"
95103,AOTAutograd can add extra as_strided() calls when graph outputs alias inputs,2023-02-17 23:12:16+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
95100,"RuntimeError: view_as_complex is only supported for half, float and double tensors, but got a tensor of scalar type: BFloat16",2023-02-17 22:18:27+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: bfloat16"")]"
95077,Implement a `torch.cuda.visible_device_indexes` function. ,2023-02-17 18:04:18+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
95075,Make artifacts easier to discover on HUD,2023-02-17 17:58:22+00:00,,0,8,"[Label(name=""module: ci""), Label(name=""triaged"")]"
95074,A100 Perf Job artifact zipfiles unzip to generic folder that loses job information,2023-02-17 17:52:37+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
95073,`torch.cuda.device_count` cached return value does not reflect environment changes.,2023-02-17 17:52:37+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
95058,Upsampling ResBlock GPU memory spike,2023-02-17 13:11:04+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
95037,[Inductor] [CPU] Huggingface model AllenaiLongformerBase performance regression > 10% on ww07.4,2023-02-17 04:11:51+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
95034,[Inductor] [CPU] Huggingface model MT5ForConditionalGeneration &T5ForConditionalGeneration & T5Small performance regression > 10% on ww07.4,2023-02-17 03:58:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
95033,[Inductor] [CPU] Torchbench model hf_Longformer performance regression > 10% on ww07.4,2023-02-17 03:53:42+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
95030,[Inductor] [CPU] Torchbench model hf_T5 & hf_T5_large & hf_T5_base performance regression > 10% on ww07.4,2023-02-17 03:37:58+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: inductor"")]"
95024,cuDNN doesn't support convolutions with more than `INT_MAX` elements and native kernel uses too much memory,2023-02-17 02:52:23+00:00,,0,7,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
95021,Custom operations in inductor,2023-02-17 01:31:32+00:00,,1,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: dynamo"")]"
95005,NCCL backend can't be used with a dataset that is IterDataPipe,2023-02-16 22:10:07+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader"")]"
94990,interactions between views + autograd.Function + AOTAutograd causes memory leak,2023-02-16 17:28:50+00:00,,1,17,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
94989,Internal Assert During Distributed Autograd Backprop,2023-02-16 17:14:15+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
94976,[libtorh]Consistency problem of gpu computing,2023-02-16 10:16:44+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
94974,Slow inference of torchscript model in C++,2023-02-16 09:02:55+00:00,,0,2,"[Label(name=""oncall: jit"")]"
94966,CSR matrix add_ error with RuntimeError: CUDA error: kernel launch failure when calling cusparseXcsrgeam2Nnz,2023-02-16 05:14:28+00:00,,1,3,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
94912,PR #88607 breaks build for POWER9 CPU,2023-02-15 17:53:02+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER""), Label(name=""actionable"")]"
94909,[numpy] mean & nanmean should support int dtypes,2023-02-15 16:54:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: reductions"")]"
94908,ASSERT(initialized()) Debug Error after JIT fusion on Windows,2023-02-15 16:18:39+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""module: nvfuser"")]"
94904,"Optimizer ""Lion"" in  Symbolic Discovery of Optimization Algorithms",2023-02-15 15:10:46+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
94893,Memory leak in torch.fft.rfft,2023-02-15 07:17:46+00:00,,0,20,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: fft"")]"
94872,[Inductor] [CPU] as_strided is much slower than empty_strided in single-thread single-batch mode in lennard_jones,2023-02-15 01:29:44+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
94869,aten::cudnn_convolution chooses different conv implementation given the same inputs. ,2023-02-15 00:28:50+00:00,,0,8,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
94857,[FSDP] Gradients not propagating for mixed precision case,2023-02-14 21:50:24+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
94855,torch.compile breaks reproducibility,2023-02-14 21:47:26+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
94844,Dynamo.export should support formatting tensor value within a string,2023-02-14 19:28:18+00:00,,1,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""internal ramp-up task"")]"
94836,Allow Dynamo backends to use Inductor as fallback instead of eager mode,2023-02-14 18:36:47+00:00,,1,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
94827,Linking error with Libtorch,2023-02-14 16:44:06+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: mkl"")]"
94821,Make `torch.onnx.utils._optimize_graph` use several CPU cores,2023-02-14 14:50:17+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""module: onnx""), Label(name=""triaged"")]"
94819,`tag` parameter is ignored from NCCL P2P isend/irecv pair,2023-02-14 14:31:33+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
94816,grid_sample with relative grid,2023-02-14 14:18:34+00:00,,1,6,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: interpolation"")]"
94808,Memory Corruption in torch.lstm caused by edge cases,2023-02-14 09:09:10+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
94806,ImportError: cannot import name 'Backend' from 'torch._C._distributed_c10d' (unknown location),2023-02-14 08:08:36+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
94804,Build Error: no matching function for call to ‘dnnl::graph::stream::stream(<brace-enclosed initializer list>)’,2023-02-14 07:50:38+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
94801,Compiling PyTorch from Source on Xavier,2023-02-14 07:27:17+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vectorization"")]"
94792,Compiling libtorch from Source on Mac Beyond v1.11.0,2023-02-14 02:33:02+00:00,,0,6,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: macos"")]"
94788,pytorch log level API and env var,2023-02-14 01:53:37+00:00,,1,26,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""module: logging""), Label(name=""triaged"")]"
94779,Better Numpy API (interoperability between ML frameworks),2023-02-13 23:00:26+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
94773,`torch.compile` doesn't consider the alias tensor created by `tensor[:]`,2023-02-13 22:24:56+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""internal ramp-up task"")]"
94765,MPS internal error in `torch.gather` when last dimension is a singleton dimension,2023-02-13 21:17:03+00:00,,0,2,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: mps"")]"
94739,Update PyTorch's default C standard to C17 from C11,2023-02-13 16:46:05+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
94718,Option to bypass NOLA check in torch.istft,2023-02-13 06:26:00+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: fft"")]"
94711,Investigate queue disparity between `windows.4xlarge` and `linux.4xlarge`,2023-02-12 20:56:59+00:00,,0,2,"[Label(name=""high priority""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: regression"")]"
94705,Split getitem OpInfo into dynamic and non-dynamic inputs,2023-02-12 16:34:07+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
94704,`where` triggers INTERNAL ASSERT FAILED when `out` is a long tensor due to mixed types,2023-02-12 16:32:30+00:00,,0,4,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
94698,A segment fault can be triggered in torch.avg_pool1d,2023-02-12 06:25:54+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
94696,A segment fault can be triggered in torch.max_pool1d_with_indices,2023-02-12 06:10:39+00:00,,0,2,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
94693,inductor `compile_fx_inner` output is incorrect on graph with trailing copy_(),2023-02-12 01:01:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""module: inductor"")]"
94691,Nan is output by GRU on mps,2023-02-12 00:20:57+00:00,,0,28,"[Label(name=""triaged""), Label(name=""module: mps"")]"
94675,"`UnsupportedOperatorError`, `OnnxExporterError` and `SymbolicValueError` related to MultiheadAttention export to onnx with torch.jit.script",2023-02-11 15:23:16+00:00,,1,9,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
94669,A segment fault can be triggered in torch.svd,2023-02-11 08:51:26+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
94668,A segment fault can be triggered in torch.lstm with edge cases,2023-02-11 08:48:00+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
94654,Missing FX documents for some modules,2023-02-11 03:04:50+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
94652,dynamo: handle contiguous graph breaks ,2023-02-11 02:28:26+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: graph breaks"")]"
94620,[RFC] Add a static_graph mode for FSDP,2023-02-10 20:51:51+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
94614,Jetson CI needs Updates,2023-02-10 19:19:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: jetson"")]"
94609,Lots of different `nn.Sequence` instances trigger the Dynamo cache limits,2023-02-10 17:44:31+00:00,,0,10,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
94602,Saving a `torch.nn.HuberLoss` using `torch.jit.script().save()` doesn't seem to implicitly convert from `int` type to `float` type.,2023-02-10 16:15:34+00:00,,0,0,"[Label(name=""oncall: jit"")]"
94594,A segment fault can be triggered in torch.histogramdd,2023-02-10 13:50:03+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
94593,Memory corruptions can be triggered in torch._remove_batch_dim,2023-02-10 13:46:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: vmap"")]"
94591,Issue with `upsample_nearest2d` decomposition,2023-02-10 13:37:37+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: decompositions"")]"
94590,A Segment Fault can be triggered in torch.affine_grid_generator,2023-02-10 13:28:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
94586,`permute` for named tensors,2023-02-10 12:41:12+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
94575,[Dynamo] Key Mismatch When Loading Checkpoints Trained with Dynamo,2023-02-10 05:17:32+00:00,,0,4,"[Label(name=""high priority""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
94544,Abort Caused by Virtual Function,2023-02-09 22:03:11+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: regression"")]"
94542,torch.lgamma CUDA driver error,2023-02-09 21:02:31+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: special"")]"
94541,DISABLED test_pickle_nn_RNN_eval_mode_cuda_float64 (__main__.TestModuleCUDA),2023-02-09 20:29:56+00:00,,0,1,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
94511,"Performance does not meet expectations when training OPT-30 with FSDP, there may be problems with cpu offloading",2023-02-09 14:35:11+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
94504,[mypy] skipping mypy for a few torch/fx and torch/_subclass files,2023-02-09 11:26:31+00:00,,0,0,"[Label(name=""module: lint""), Label(name=""triaged"")]"
94496,Dynamo captures only CUDA streams in FX graph,2023-02-09 08:08:58+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
94474,pybind11 SymNode binding is a footgun py::cast,2023-02-09 03:21:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: pybind"")]"
94471,[Functionalization] `index_reduce_` op tests with functionalization enabled,2023-02-09 02:50:18+00:00,,1,10,"[Label(name=""triaged""), Label(name=""module: meta tensors""), Label(name=""module: functionalization"")]"
94457,LSTM on CPU is significantly slower on PyTorch compared to other frameworks,2023-02-09 00:34:52+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
94454,Document and promise reproducibility torch.randn / torch.rand / torch.randint family behavior on CPU devices,2023-02-09 00:03:58+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: random"")]"
94451,"`jacrev` raise ""Cannot access storage of TensorWrapper"" error when computing the grad of `storage`",2023-02-08 23:05:47+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: functorch"")]"
94450,Pickling OneCycleLR.state_dict() with an unpickleable optimizer will result in an error.,2023-02-08 22:58:26+00:00,,1,1,"[Label(name=""module: optimizer""), Label(name=""module: pickle""), Label(name=""triaged""), Label(name=""needs research"")]"
94443,A better error msg for `cuda.jiterator` when input is on `cpu`,2023-02-08 22:12:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: jiterator"")]"
94441,`get_debug_state` a script function causes INTERNAL ASSERT FAILED,2023-02-08 21:59:36+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
94434,Exporting the operator 'aten::_transformer_encoder_layer_fwd' to ONNX opset version 13 is not supported,2023-02-08 20:25:29+00:00,,1,8,"[Label(name=""module: onnx""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
94429,[RFC]FSDP API should make limit_all_gathers and forward_prefetch both default to be True,2023-02-08 20:13:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
94414,[fake_tensor] torch._subclasses.fake_tensor.DynamicOutputShapeException when calling torch.nonzero using aot_function,2023-02-08 17:33:41+00:00,,0,10,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: graph breaks"")]"
94397,jacfwd and jacrev are fundamentally broken for complex inputs,2023-02-08 14:11:22+00:00,,0,30,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""complex_autograd""), Label(name=""module: functorch"")]"
94395,`func.jacrev()` should be implemented as `func.jacfwd().mT.contiguous()`,2023-02-08 13:04:32+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: functorch"")]"
94388,Inconsistent results when using torch.Tensor.bernoulli with float instead of Tensor probabilities,2023-02-08 10:04:50+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: determinism"")]"
94374,[fx] const_fold.split_const_subgraphs leads to UserWarning,2023-02-08 05:43:28+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
94371,"QAT + torch.autocast does not work with default settings, missing fused fake_quant support for half",2023-02-08 04:45:22+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
94336,`scatter` fails the gradient computation in reverse mode for `src` when `index` is empty,2023-02-07 20:49:15+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: scatter & gather ops"")]"
94333,cpu log1p for bfloat16 gives wrong result.,2023-02-07 20:29:00+00:00,,0,4,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: bfloat16"")]"
94322,RFC: Enabling AVX512 dispatch for compute-intensive ATen ops,2023-02-07 19:05:12+00:00,,1,0,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: intel"")]"
94311,Unimplemented lowering - torch.jit.script,2023-02-07 16:22:27+00:00,,1,2,"[Label(name=""oncall: jit"")]"
94304,"RuntimeError: p.block != nullptr && p.block->ptr != nullptr INTERNAL ASSERT FAILED at ""../c10/cuda/CUDACachingAllocator.cpp"":1275, please report a bug to PyTorch.",2023-02-07 12:35:54+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: assert failure""), Label(name=""module: CUDACachingAllocator"")]"
94294,CUBLAS_STATUS_NOT_SUPPORTED when calling cublasDgemv,2023-02-07 09:39:08+00:00,,0,9,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas"")]"
94293,torchdynamo.export doesn't work with float multiplication,2023-02-07 09:05:57+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""oncall: export"")]"
94292,What type of attributes does symbolic function support?,2023-02-07 08:46:40+00:00,,0,0,"[Label(name=""triaged"")]"
94286,bugs when try parallel test code,2023-02-07 07:29:03+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
94280,"ONNX export produces hundreds of weight/bias/Matmul/etc. files alongside the `.onnx` file, and the `.onnx` file seems to be incorrect.",2023-02-07 06:23:25+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
94261,GroupNorm ONNX export does not reproduce same output,2023-02-07 02:33:54+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
94238,`PyTorchFileWriter` should drop the GIL while writing files,2023-02-07 00:14:54+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
94233,unsqueeze a single dimension multiple times,2023-02-06 23:27:01+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
94208,`zeros_like` + `fill_` makes the gradient computation in forward mode fail,2023-02-06 19:30:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: forward ad"")]"
94186,Addition of hybrid CSR tensors produces incorrect and invalid CSR tensor,2023-02-06 15:19:42+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""bug"")]"
94185,Addition of CSC/BSR/BSC tensors raises RuntimeError exceptions,2023-02-06 15:15:31+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
94183,Addition of batch CSR tensors produces incorrect and invalid CSR tensor,2023-02-06 15:01:12+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""bug"")]"
94174,[pt2] The min and max parameters of torch.clamp do not support numpy format,2023-02-06 07:43:50+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""internal ramp-up task"")]"
94167,"Faster `pad_sequence` and `tensor_split` function with CUDA kernel, are they possible?",2023-02-06 03:14:30+00:00,,0,3,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
94164,Pytorch 2.0: Detection models from torchvision don't work with onnx and tensorrt backends,2023-02-06 02:33:00+00:00,,1,7,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
94161,JIT: Dropout fails codegen on the third forward passes,2023-02-06 00:42:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
94160,Subclassed Tensors Decrease Training GPU Throughput by ~40% ,2023-02-05 23:26:29+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: __torch_function__""), Label(name=""tensor subclass""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
94132,Asking for a LAZYMODULEMIXIN warning,2023-02-04 08:48:10+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: molly-guard""), Label(name=""triaged""), Label(name=""module: lazy"")]"
94131,faster WeightedRandomSampler implementation based on alias method,2023-02-04 08:31:44+00:00,,0,8,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
94125,A Floating Point Exception can be trigerred in torch._C._nn.slow_conv3d,2023-02-04 04:45:08+00:00,,1,2,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
94115,`cat` fails the gradient computation in forward mode with empty tensors when used with legacy vmap,2023-02-04 01:58:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: edge cases""), Label(name=""module: forward ad"")]"
94111,`svd` triggers INTERNAL ASSERT FAILED when computing jacobian in forward mode,2023-02-04 01:32:54+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""has workaround""), Label(name=""module: linear algebra""), Label(name=""module: forward ad"")]"
94086,`MSELoss` fails to compute the gradients when inputs have different dtype,2023-02-03 23:06:55+00:00,,1,1,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
94085,`unfold` fails in forward mode when unfolding a scalar tensor,2023-02-03 22:57:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: forward ad"")]"
94083,Tracker for `scatter_reduce` additional reduction options requests,2023-02-03 22:34:50+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
94061,[dynamo] enable export path to preserve a meaningful parameter name in the exported graph module,2023-02-03 19:33:54+00:00,,1,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
94021,Set AVX2 is minimum supported instruction set for Linux X86,2023-02-03 01:30:31+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: intel"")]"
94017,Type promotion for accumulate operation differs between eager and CPP dynamo ,2023-02-03 00:27:33+00:00,,1,3,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
94010,Type promotion mismatch between eager and inductor pow,2023-02-02 23:11:39+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
94003,test_nccl_warn_not_in_group_debug_detail is flaky,2023-02-02 21:37:27+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
93982,`linalg.lstsq` fails the gradient computation in forward mode,2023-02-02 19:44:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: forward ad"")]"
93955,"Enable Link Time Optimization in PyTorch 2.0 Release Binaries - Smaller, Faster, Better Binaries",2023-02-02 18:50:29+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""module: performance""), Label(name=""module: build""), Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""topic: performance"")]"
93947,[RFC] Support Huge Model Init Without mallocs for Compile/Distributed Use Cases,2023-02-02 17:24:04+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
93944,error: no member named 'residual_with_sum_zero_point' in 'ideep::attr_t,2023-02-02 16:41:59+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
93943,"`torch.jit.trace` memory usage increase although forward is constant, and gets much slower than forward with model depth increase",2023-02-02 16:34:30+00:00,,0,7,"[Label(name=""oncall: jit"")]"
93938,"[FSDP] `summon_full_params(writeback=True, rank0_only=True)`",2023-02-02 15:10:27+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
93937,onnx_torch.ModelProto exceeded maximum protobuf size of 2GB,2023-02-02 14:36:48+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
93935,[pt20][aot_eager] Exceed Python recursion limit with huge model or frequent recompilation,2023-02-02 14:09:54+00:00,,1,5,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
93923,Dynamo uses CONSTANT_MATCH guards for string inputs,2023-02-02 09:43:36+00:00,,0,14,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""oncall: export"")]"
93913,[BUG] jit.trace not working for torchvision ViT models,2023-02-02 06:44:03+00:00,,0,1,"[Label(name=""oncall: jit"")]"
93900,"Why does the torch model have no memory leaks under gpu, but there is a memory leak under cpu, torch version 1.10.1",2023-02-02 02:26:55+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
93890,[Dynamo] torch.autocast context manager doesn't support graph break ,2023-02-01 23:51:11+00:00,,0,8,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
93884,Importing tensorflow (2.12) before torch (2.0) hangs at import torch,2023-02-01 21:01:23+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
93880,"`PYTORCH_DEBUG_MODE`, better invalid index embedding lookup error message on cuda",2023-02-01 19:58:47+00:00,,1,11,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: python frontend"")]"
93860,Minifier related: perhaps same_two_models should reseed between the regular and optimized runs?,2023-02-01 16:19:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: minifier"")]"
93859,Bitwise-perfect method for (de)serializing tensors in base64,2023-02-01 15:45:31+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: serialization""), Label(name=""triaged"")]"
93857,Minifier has trouble correctly setting up requires_grad'ness of inputs for forward only,2023-02-01 15:31:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: minifier"")]"
93855,Enable CUPTI,2023-02-01 15:26:38+00:00,,1,0,"[Label(name=""module: windows""), Label(name=""triaged"")]"
93854,torchdim can not be compiled for Python-3.11 on Windows,2023-02-01 15:26:31+00:00,,1,3,"[Label(name=""module: windows""), Label(name=""triaged""), Label(name=""module: functorch"")]"
93852,save_config/load_config for torch._dynamo.config and friends hardcodes file paths,2023-02-01 15:08:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
93847,Failures in cuda11.7-py3.10-gcc7-sm86-periodic-dynamo-benchmarks,2023-02-01 13:54:49+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93846,large number of temporary files generated when using dataloader with num_workers>0,2023-02-01 13:43:01+00:00,,0,2,"[Label(name=""high priority""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: openmp"")]"
93843,EmbeddingBag to support mini-batches with offsets,2023-02-01 12:44:02+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: nestedtensor"")]"
93838,"ONNX Export Fails: Model input type is Dict[str, Tensor] ",2023-02-01 09:13:24+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
93830,[pt2] MMDet meets Exception: Please convert all Tensors to FakeTensors first or instantiate FakeTensorMode error with aot_eager backend,2023-02-01 07:15:02+00:00,,1,9,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: fakeTensor""), Label(name=""module: pt2-dispatcher"")]"
93826,torch.jit.script does not work with DataParallel,2023-02-01 06:51:35+00:00,,0,0,"[Label(name=""oncall: jit"")]"
93394,MaskRCNN with `torch.compile` fails with `CUDA error: an illegal memory`,2023-01-31 20:43:13+00:00,,1,4,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2"")]"
93386,"[pt2] cannot compile function having `gt`, `expand` and `add_`",2023-01-31 19:17:07+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
93378,(DDP) RoBERTa_large training with `torch.compile` results in OOM and other issues,2023-01-31 17:26:12+00:00,,0,7,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93367,Aot accuracy minifier with dynamic shapes doesn't work,2023-01-31 14:53:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93366,Option for minifier to dump the actual tensor inputs/parameters to be used,2023-01-31 14:51:41+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93364,Minifier should also dump compilation artifacts from the real execution for ease of sanity checking,2023-01-31 14:42:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93362,Make torch.testing functions overrideable with torch_function?,2023-01-31 14:41:41+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: __torch_function__""), Label(name=""module: testing"")]"
93361,Inductor miscompilation with dynamic shapes from LearningToPaint,2023-01-31 14:25:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93358,Minifier launcher incorrectly runs backwards even when original reproducer didn't run backwards,2023-01-31 14:01:54+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93354,"minifier_launcher.py silently swallows ""ran into runtime exception which is likely an unrelated an issue"" warnings",2023-01-31 12:09:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93350,Tensorboard SummaryWriter with cloud storage does not work on Mac,2023-01-31 10:09:23+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
93347,"when I want to use a new backend, how to deal with the op with 'device' argument? ",2023-01-31 09:34:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: backend"")]"
93346,Quantized Transformer ONNX Export Fails,2023-01-31 09:29:00+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
93345,aten::int_repr not supported in torch.onnx.export,2023-01-31 08:34:45+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
93319,Minifier should not use pickle to save state into minifier launcher,2023-01-30 23:46:01+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: functorch"")]"
93317,Minifier doesn't save/load functorch config,2023-01-30 23:42:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: functorch"")]"
93311,[CI]  PyTorch Windows Test AMIs contains CUDA-11.3 installation,2023-01-30 23:01:42+00:00,,1,1,"[Label(name=""module: windows""), Label(name=""module: ci""), Label(name=""triaged"")]"
93307,`torch.compile()` failed on Huggingface Flan-T5 `torch._dynamo.exc.Unsupported: call_function UserDefinedObjectVariable(forward) [] OrderedDict()`,2023-01-30 21:48:59+00:00,,0,2,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93288,Errors when running the fsdp benchmarks for hf_Bert and hf_T5,2023-01-30 18:20:46+00:00,,1,11,"[Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
93281,Estimate effort needed to bring PyTorch to Windows Arm64,2023-01-30 17:00:13+00:00,,0,1,"[Label(name=""module: windows""), Label(name=""triaged"")]"
93275,Bug in torch.linalg.svd ,2023-01-30 16:05:48+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mkl"")]"
93264,"Bad conversion from torch.split(2d_tensor,splitsize_list) to SplitToSequence OP (onnx export)",2023-01-30 11:46:25+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
93262,`torch.compile` produce wrong result in `interpolate` when `mode=bilinear`,2023-01-30 11:09:57+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
93255,MaskRCNN model loaded fail with torch::jit::load(model_path) (C++ API),2023-01-30 06:46:08+00:00,,0,0,"[Label(name=""oncall: jit"")]"
93240,USE_CUDNN=1 doesn't force cmake to fail if cudnn is not found,2023-01-29 20:17:41+00:00,,0,2,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: build warnings"")]"
93235,Well known way to request user backtrace when inside Dynamo,2023-01-29 19:13:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
93231,"Minifier produces minifier script that doesn't fail accuracy on Background_Matting (dynamic shapes, inductor, inference)",2023-01-29 18:42:46+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: functorch"")]"
93230,"Minifier does not run on LearningToPaint (dynamic shapes, inductor, inference)",2023-01-29 18:37:50+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: inductor"")]"
93227,squeezenet1_1 fails accuracy with AMP (but not on CI and dashboard); minifier does not work (when not using cuDNN?),2023-01-29 18:19:35+00:00,,0,2,"[Label(name=""triaged""), Label(name=""shadow review""), Label(name=""module: amp (automated mixed precision)"")]"
93206,Build from Source Issues on MacOS Ventura 13.2,2023-01-28 17:23:31+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
93197,Add Support for RockChip NPUs (RKNN(2)) ,2023-01-28 13:09:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: arm"")]"
93188,Why is AvgPool2D taking longer than Conv2D for the same input?,2023-01-28 00:17:08+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
93173,"[RFC] PT2-Friendly Traceable, Functional Collective Communication APIs",2023-01-27 21:12:12+00:00,,1,23,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: ProxyTensor""), Label(name=""module: pt2-dispatcher"")]"
93518,TorchDynamo Performance Dashboard (float32),2023-01-27 19:46:55+00:00,,0,64,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93161,Segmentation fault between Numpy and Pytorch using torch.bmm,2023-01-27 18:18:04+00:00,,0,5,"[Label(name=""module: binaries""), Label(name=""module: crash""), Label(name=""triaged"")]"
93154,Support for VeLO optimizer.,2023-01-27 15:45:07+00:00,,1,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
93152,Dynamo doesn't support dict(list_argument),2023-01-27 13:49:57+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
93151,Dynamo doesn't support OrderedDict,2023-01-27 13:48:19+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
93134,Failed to Open libnvrtc-builtins.so.11.7,2023-01-27 04:47:31+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: cuda"")]"
93121,[RFC] Flop counters in PyTorch,2023-01-27 01:25:44+00:00,,0,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
93081,[Releng] [Conda] Optimize PyTorch packaging,2023-01-26 18:20:59+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
93061,DISABLED test_inplace_grad_index_put_cuda_float64 (__main__.TestBwdGradientsCUDA),2023-01-26 12:49:55+00:00,,0,25,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown""), Label(name=""oncall: pt2"")]"
93045,DISABLED test_forward_mode_AD_linalg_det_singular_cuda_complex128 (__main__.TestFwdGradientsCUDA),2023-01-26 06:38:58+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
93044,DISABLED test_fn_grad_linalg_det_singular_cuda_complex128 (__main__.TestBwdGradientsCUDA),2023-01-26 06:36:50+00:00,,0,7,"[Label(name=""module: autograd""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
93017,numpy v1.24 does not work with `writer.add_histogram`,2023-01-25 21:13:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
93002,Replace pattern fails on incompatible function arguments,2023-01-25 19:16:35+00:00,,0,0,"[Label(name=""oncall: fx"")]"
92998,[BE] Improve FSDP <> AC Unit Tests,2023-01-25 19:01:28+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
92990,Feature request: access to variable,2023-01-25 18:27:27+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
92987,Test Failure: TestUpgraders.test_aten_div_scalar_at_3 on a big-endian machine (issue in torch.jit.load()),2023-01-25 18:07:27+00:00,,0,1,"[Label(name=""oncall: jit"")]"
92977,ONNX export of batch_norm for unknown channel size issue.,2023-01-25 13:39:56+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
92967,Tracking issue for segfaults and floating point exceptions on 1.12.0,2023-01-25 04:53:55+00:00,,0,3,"[Label(name=""triaged"")]"
92942,test_jit_fuser_te SIGIOT's frequently during dynamo testing ,2023-01-25 01:32:09+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: testing""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
92927,"Inplace fused (leaky)relu+(leaky)dropout for memory savings (I think, can be made fully allocation-less if never fully allocating random mask in FlashAttention style and recover the mask from the output)",2023-01-24 23:18:52+00:00,,0,21,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
92920,Add Stride Argument For Constructors,2023-01-24 21:33:51+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: tensor creation"")]"
92916,[Functionalization] Some ops need additional meta tensor support after functionalization,2023-01-24 20:53:52+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: xla""), Label(name=""module: meta tensors""), Label(name=""module: functionalization"")]"
92912,functorch.functionalize doesn't error out with logcumsumexp.out,2023-01-24 19:41:54+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: xla""), Label(name=""module: meta tensors""), Label(name=""module: functionalization"")]"
93517,Triton MLIR benchmarks,2023-01-24 18:37:07+00:00,,0,17,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
92910,torch.jit.save() generates different contents in a file among different endian machines,2023-01-24 18:24:24+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""module: POWER"")]"
92909,[RFC] XLA Lazy Backend Support In DistributedTensor API,2023-01-24 18:23:04+00:00,,2,1,"[Label(name=""triaged""), Label(name=""module: xla"")]"
92907,Unable to find an engine to execute when using pip to install but not with conda,2023-01-24 17:51:57+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
92888,[LibTorch] pickle_save output cannot be reloaded using pickle_load in Windows,2023-01-24 02:51:05+00:00,,0,0,"[Label(name=""oncall: jit"")]"
92884,"[RFC] Make more operations inplace (GELU, BatchNorm, LayerNorm)",2023-01-24 01:42:21+00:00,,0,12,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable"")]"
92866,JIT Function Fails when run a second time,2023-01-23 23:11:50+00:00,,0,2,"[Label(name=""oncall: jit"")]"
92855,Profiler documentation doesn't mention some exports are mutually exclusive,2023-01-23 21:48:21+00:00,,0,1,"[Label(name=""oncall: profiler"")]"
92838,Enable OnDemand for Open Source CI ,2023-01-23 19:36:51+00:00,,1,7,"[Label(name=""triaged"")]"
92835,Double free when running torch.linalg.ldl_solve,2023-01-23 18:19:41+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
92828,segfault when running torch.igamma,2023-01-23 17:37:44+00:00,,0,1,"[Label(name=""triaged"")]"
92820,Ability to manually set the gradient in FSDP while inside `summon_full_params` and make it persistent,2023-01-23 16:41:20+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
92818,Segfault when running torch.atan2,2023-01-23 16:33:34+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex"")]"
92812,"torch.fx fails to trace through ""+"" op between torch.Size and torch.fx.proxy.Proxy",2023-01-23 12:35:23+00:00,,0,5,"[Label(name=""oncall: fx"")]"
92811,[complex] Jacobian of a non-holomorphic complex valued function,2023-01-23 11:55:54+00:00,,0,1,"[Label(name=""triaged""), Label(name=""complex_autograd"")]"
92804,Dynamo graph break due to context manager do not resume inside/outside the context manager,2023-01-23 06:27:18+00:00,,1,23,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
92801,"[BE] move _apply_to_tensors from FSDP to torch.distributed.utils, use in _recursive_to",2023-01-23 04:55:52+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: ddp"")]"
92794,Segmentation fault when running torch.ge,2023-01-23 03:01:16+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
92783,Process get killed when running torch.combinations,2023-01-23 00:57:32+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
92781,Floating point exception when running torch.nn.AdaptiveMaxPool3d,2023-01-23 00:31:23+00:00,,0,3,"[Label(name=""triaged"")]"
92778,Process get killed when running torch.normal,2023-01-22 23:41:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
92776,segfault when running torch.lu_unpack,2023-01-22 23:33:45+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: edge cases"")]"
92758,no attribute torch._dynamo unless you explicitly import torch._dynamo,2023-01-22 03:05:37+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
92752,'MPS' issue: torch.multinomial() returning [-9223372036854775808],2023-01-21 16:14:59+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: mps"")]"
92742,[JIT] Consecutive use of `addmm` Leads to Exception,2023-01-21 03:55:09+00:00,,0,2,"[Label(name=""oncall: jit"")]"
92740,[JIT] Applying `conv2d` over Constants Leads to Exception,2023-01-21 03:41:21+00:00,,0,4,"[Label(name=""oncall: jit"")]"
93515,Dynamo can not trace 'int(a_scalar_tensor.item())',2023-01-21 01:16:11+00:00,,1,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
92736,[FSDP] Add `foreach` support to `FSDP.clip_grad_norm_()`,2023-01-21 01:13:59+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
93514,iter(TensorVariable) fail,2023-01-20 23:08:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
92701,set_default_device/torch.device has performance impact for non-factory functions,2023-01-20 19:57:07+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
92694,API to check for errors in c10d.ProcessGroupNCCL,2023-01-20 18:34:46+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
92691,DDP+inductor+profiler crashes on  toy model,2023-01-20 17:49:36+00:00,,1,9,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""oncall: profiler""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
92683,Torchscript troubles with complex values. RuntimeError: isInt() INTERNAL ASSERT FAILED,2023-01-20 15:07:56+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: complex"")]"
92674,[JIT] `Linear` + `BatchNorm2d` Trigger Inconsistency between Eager Mode and JIT,2023-01-20 08:15:59+00:00,,0,1,"[Label(name=""oncall: jit"")]"
92670,14k github models TorchDynamo + TorchInductor bugs umbrella task,2023-01-20 05:38:51+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""module: dynamo"")]"
92654,Traced model output differs on C++ and Python,2023-01-20 00:16:22+00:00,,0,1,"[Label(name=""oncall: jit"")]"
92600,Update quantization to make source files complient with /Zc:lambda,2023-01-19 01:16:20+00:00,,1,0,"[Label(name=""module: windows""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
92594,INTERNAL ASSERT FAILED when mixed dtypes for `addcmul_`,2023-01-18 23:25:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: assert failure""), Label(name=""module: type promotion"")]"
92580,Improve Fake Tensor Error When Data Ptr is Accessed,2023-01-18 21:29:05+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
92563,[JIT] INTERNAL ASSERT FAILED when `Conv2d` and `clamp` used together,2023-01-18 18:46:56+00:00,,0,0,"[Label(name=""oncall: jit"")]"
92561,Spurious side effect diff when cond branches call different functions in outer scope,2023-01-18 18:14:09+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
92558,"[JIT][TracingCheckError] inplace ops incompatible with `contiguous(.., channels_last)`",2023-01-18 18:02:17+00:00,,0,1,"[Label(name=""oncall: jit"")]"
92554,Major bug in Transformers' masks,2023-01-18 17:45:17+00:00,,0,11,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: transformer/mha""), Label(name=""module: correctness (silent)"")]"
92548,[JIT] Inconsistency  in tensor shape between eager mode and JIT,2023-01-18 15:58:19+00:00,,0,0,"[Label(name=""oncall: jit"")]"
92542,Pytorch AMP performance issue.,2023-01-18 13:01:02+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: amp (automated mixed precision)"")]"
92535,multiprocessing not work on WSL2,2023-01-18 10:25:14+00:00,,0,3,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: wsl"")]"
92528,"INTERNAL ASSERT FAILED: Expected OwnerRRef with id GloballyUniqueId(created_on=0, local_id=0) to be created.",2023-01-18 08:14:31+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
92398,[Inductor] support complex dtypes,2023-01-18 05:31:29+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: random""), Label(name=""module: inductor""), Label(name=""module: cpu inductor"")]"
92375,operations failed in TorchScript interpreter,2023-01-18 02:44:38+00:00,,0,0,"[Label(name=""oncall: jit"")]"
92350,TypeError: no implementation found for 'torch._ops.aten.max.default' on types that implement __torch_dispatch__: [<class 'torch.masked.maskedtensor.core.MaskedTensor'>],2023-01-17 23:40:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: masked operators"")]"
93511,support setattr of arbitrary user provided types in tracing,2023-01-17 22:33:23+00:00,,0,4,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
92339,"fft.fftshift, fft.ifftshift, roll not implemented",2023-01-17 21:50:43+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: fft""), Label(name=""module: mps"")]"
92331,backward(inputs= does not need to execute grad_fn of the inputs,2023-01-17 20:10:32+00:00,,0,1,"[Label(name=""module: bc-breaking""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""topic: bc breaking"")]"
92330,Simplify module backward hooks to use multi-grad hooks instead,2023-01-17 20:06:44+00:00,,0,2,"[Label(name=""module: bc-breaking""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""topic: bc breaking"")]"
92310,[Releng] Windows AMI needs to be pinned for release,2023-01-17 16:43:50+00:00,,0,0,"[Label(name=""high priority""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
92302,Cost & performance estimation for Windows Arm64 compilation,2023-01-17 14:09:05+00:00,,0,0,"[Label(name=""module: windows""), Label(name=""triaged"")]"
92294,jit.fork stalls multiprocessing dataloader,2023-01-17 09:52:59+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: dataloader""), Label(name=""module: data"")]"
93510,RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation,2023-01-17 09:31:16+00:00,,0,4,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
92292,"""Get Started"" tells us to use the anaconda installer for PyTorch 3.x - but this should be python 3.x",2023-01-17 09:05:59+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
92285,InstanceNorm operator support for Vulkan devices,2023-01-17 05:30:42+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: vulkan"")]"
92273,Always install cpu version automatically,2023-01-17 02:05:55+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
92260,distributions.Beta returning incorrect results at 0 and 1,2023-01-16 19:18:38+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
92259,[discussion] Fused MLPs,2023-01-16 18:11:32+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
92252,"`model.to(""cuda:0"")` does not release all CPU memory",2023-01-16 15:01:17+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
92251,"`torch.load(..., map_location=""cuda:0"")` allocates memory on both CPU and GPU",2023-01-16 14:52:21+00:00,,0,3,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
92250,torch.cuda.is_available() returns True even if the CUDA hardware can't run pytorch,2023-01-16 14:27:19+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
92246,test_qnnpack_add fails,2023-01-16 13:53:18+00:00,,0,3,"[Label(name=""oncall: mobile""), Label(name=""module: xnnpack"")]"
92245,"CapabilityBasedPartitioner incorrectly sorts the graph, causing optimizer return/output node to be first",2023-01-16 13:52:24+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""oncall: pt2"")]"
92230,Add torch::jit::ScriptModule to the C++ API,2023-01-15 22:31:02+00:00,,0,0,"[Label(name=""oncall: jit"")]"
92226,Hijacked package names from nightly repository,2023-01-15 19:54:05+00:00,,1,3,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""security"")]"
92223,Improve make_fx tracing speed,2023-01-15 17:40:40+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: ProxyTensor"")]"
92217,"false INTERNAL ASSERT FAILED at ""../c10/cuda/CUDAGraphsC10Utils.h"":73, please report a bug to PyTorch. Unknown CUDA graph CaptureStatus32680",2023-01-15 10:30:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
93509,Triton Autotuning Cache-Clearing Adds 256MB Memory Overhead,2023-01-13 22:57:19+00:00,,0,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
92175,test_fx_passes generate bad test names,2023-01-13 21:46:43+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""oncall: fx"")]"
92173,"""multi device"" tests get skipped in standard CI",2023-01-13 21:15:46+00:00,,0,12,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
92171,PyTorch 1.13.1 hangs with `torch.distributed.init_process_group`,2023-01-13 19:50:19+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
92151,Exception in distributed context doesn't propagate to child processes launched with multiprocessing,2023-01-13 15:28:04+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
92148,Occassional OverflowError with mps running yolov7,2023-01-13 14:43:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
92134,[Bug][Dataloader] unable to mmap 2048 bytes from file <filename not specified>: Cannot allocate memory (12),2023-01-13 05:52:05+00:00,,0,20,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
92132,Torchrun seems to have problem with virtual environment,2023-01-13 04:10:50+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: r2p"")]"
92131,DISABLED test_cuda_variable_sharing (__main__.TestMultiprocessing),2023-01-13 03:40:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
92130,Unable to export timm models with torch._dynamo,2023-01-13 03:22:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
92128, Forward arguments are not updated in DDP,2023-01-13 02:36:29+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
92086,Error while building pytorch mobile binaries from source,2023-01-12 17:46:34+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: mobile"")]"
92078,DISABLED test_cdist_large_batch (__main__.TestMPS),2023-01-12 15:47:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: mps"")]"
92073,compilig MultiHeadAttention,2023-01-12 13:17:55+00:00,,0,2,"[Label(name=""oncall: jit"")]"
92072,Implement forward AD with grid_sampler_2d ,2023-01-12 13:14:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: forward ad"")]"
92041,jit testing fails on 3.11 debug build,2023-01-11 22:29:18+00:00,,0,0,"[Label(name=""oncall: jit"")]"
92029,Update docs URLs in torch/_functorch/autograd_function.py to stable before 2.0,2023-01-11 21:06:28+00:00,,0,0,"[Label(name=""triaged"")]"
92011,[Releng] Add repo dispatch via webhook to trigger domain builds after the core,2023-01-11 18:27:57+00:00,,0,2,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
92007,Add plots of LRSchedulers to doc to make it easier to read,2023-01-11 16:48:55+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: LrScheduler"")]"
91996,autograd.functional.jacobian : Imaginary part is lost for functions with real input and complex output.,2023-01-11 08:35:50+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""has workaround"")]"
91990,export does not support boolean tensor indexing,2023-01-11 04:03:16+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
91989,Torch's affinity setting lead to openvino using only one core.,2023-01-11 03:34:07+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: intel""), Label(name=""intel priority"")]"
91986,An error happend when I convert pytorch model to onnx,2023-01-11 03:03:49+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
91982,sympy failure on model when dynamic_shapes=True,2023-01-11 01:04:18+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dynamic shapes""), Label(name=""module: dynamo"")]"
91970,Unknown CUDA graph CaptureStatus21852,2023-01-10 19:29:16+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
93502,Torchdynamo with onnxrt backend generating fake tensor errors,2023-01-10 18:52:14+00:00,,0,3,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
91968,Pytorch is using system-installed mkl-dnn.,2023-01-10 18:36:27+00:00,,0,10,"[Label(name=""module: build""), Label(name=""triaged"")]"
92075,"Hessian produces wrong results, but works if I add a perturbation",2023-01-10 18:17:25+00:00,,0,4,"[Label(name=""triaged"")]"
91965,Proxy/cache server option/hooks for downloading model checkpoints and dataset archive files in cloud environment,2023-01-10 16:00:35+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: hub"")]"
91958,CUDA error `CUBLAS_STATUS_NOT_INITIALIZED` ,2023-01-10 13:14:07+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas"")]"
91951,[PT2.0 Feature Proposal] GNN inference and training optimization on CPU,2023-01-10 09:03:16+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
91950,RuntimeError: philox_cuda_state for an unexpected CUDA generator used during capture,2023-01-10 08:51:39+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: cuda graphs"")]"
93501,_pack_padded_sequence fails in dynamo due to requiring a non-fake 2nd argument,2023-01-10 05:03:16+00:00,,1,7,"[Label(name=""triage review""), Label(name=""module: performance""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""mlperf"")]"
91943,elastic job failed when scale down,2023-01-10 02:37:34+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: r2p"")]"
91940,torchrun elastic always “address already in use” error,2023-01-10 02:18:58+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: r2p"")]"
91936,Fails to build on ppc64le with clang,2023-01-10 01:19:31+00:00,,0,2,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: vectorization"")]"
91908,from torch import * does not import dtypes,2023-01-09 21:17:04+00:00,,0,1,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: python frontend"")]"
91903,Profiling with stack enabled results in error when Python's cProfile is also running,2023-01-09 19:17:27+00:00,,0,0,"[Label(name=""oncall: profiler"")]"
91902,ONNXRuntime outputs numerically incorrect results for mixed precision models.,2023-01-09 19:03:30+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
91898,Lazily start worker threads in the autograd engine,2023-01-09 17:12:20+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
91889,ToTensor deadlock in subprocess,2023-01-09 15:16:41+00:00,,0,4,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
91888,No setting to allow collecting the first trace early.,2023-01-09 15:05:50+00:00,,0,1,"[Label(name=""oncall: profiler"")]"
91887,Only the first logged trace in a given log dir is visible in tensorboard.,2023-01-09 15:04:01+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
91879,ddp vs fsdp,2023-01-09 12:01:48+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
91863,torch.Categorical samples indexes with 0 probability when given logits as argument,2023-01-08 23:31:55+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
91856,torchrun --help is too slow,2023-01-08 13:01:18+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: r2p""), Label(name=""topic: improvements""), Label(name=""topic: performance"")]"
91855,torchrun default value of command line options,2023-01-08 12:18:12+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: r2p"")]"
91942,jacrev over huber function,2023-01-07 11:48:09+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: functorch"")]"
91842,Adding a page for subfolder/subfile overview/descriptions in the developer wiki,2023-01-07 06:55:51+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
91841,torch.onnx.export is throwing RuntimeError: prim::TupleUnpack not matched to tuple construct,2023-01-07 06:42:45+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
91810,[Bug/functorch] Cannot use `tensor.detach().numpy()` for `GradTrackingTensor`: Cannot access data pointer of Tensor that doesn't have storage,2023-01-06 16:29:29+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
91809,Better API for `torch.cov` (and `Tensor.cov`),2023-01-06 16:21:35+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
91760,Inconsistent rank among torch.distributed primitives,2023-01-05 13:15:35+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
91759,"Error while building pytorch from source on windows - Ninja Build Stopped, Subcommand Failed",2023-01-05 10:36:00+00:00,,0,1,"[Label(name=""triaged"")]"
91754,CUDA error: initialization error,2023-01-05 05:44:39+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: nvfuser"")]"
91753,SymIntType gets translated to int when going through pybind,2023-01-05 05:05:30+00:00,,0,8,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
91751,[bazel] replace //c10:headers dependency by //c10 dependency,2023-01-05 03:41:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: bazel"")]"
91738,tracing torchvision detection model results in an error,2023-01-04 23:15:01+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: vision"")]"
91737,[MPS] Improve the performance of torch.linear(),2023-01-04 23:04:36+00:00,,1,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: backend""), Label(name=""module: mps"")]"
91719,Errors using torch.compile() on wav2vec2 model,2023-01-04 19:35:36+00:00,,1,17,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor""), Label(name=""module: dynamo"")]"
91716,linspace (and arange) behaves differently on GPU and CPU,2023-01-04 19:01:31+00:00,,0,3,"[Label(name=""triaged"")]"
91713,Dynamo minifier fails with false internal assert on torch-nightly,2023-01-04 17:55:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
91710,`@torch.compile` fails with `InternalTorchDynamoError` on torch-nightly,2023-01-04 17:39:47+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
91700,Add vmap support for torch.linalg.vander,2023-01-04 15:48:00+00:00,,0,4,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: functorch"")]"
91699,Segmentation fault after trying to create a tensor with float values,2023-01-04 15:30:05+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: rocm""), Label(name=""triaged"")]"
91697,Build from source fails: undefined reference to caffe2::DeviceQuery,2023-01-04 13:54:08+00:00,,0,8,"[Label(name=""module: build""), Label(name=""triaged"")]"
91692,[discussion] Analyzing a list of tensors stored as intermediate values / saved_for_backward in autograd graph,2023-01-04 11:12:40+00:00,,0,9,"[Label(name=""module: autograd""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""actionable"")]"
91686,Sparse tensor not supported (Minkowski Engine),2023-01-04 07:08:23+00:00,,0,0,"[Label(name=""oncall: jit"")]"
91678,Wrong in building torch from source,2023-01-04 02:48:39+00:00,,0,4,"[Label(name=""triaged"")]"
91670,AssertionError: tensor's device must be `meta` when trying to export a fake-initialized module,2023-01-04 01:15:10+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
91661,[FSDP][BE] Add check that compute device equals current device,2023-01-03 21:56:00+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
91655,FakeTensors not moving between device properly on Module.cuda(),2023-01-03 20:22:48+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
91653,Stochastic Illegal Memory Access error mid-epoch on AWS p4d instances,2023-01-03 19:50:56+00:00,,0,9,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas""), Label(name=""matrix multiplication"")]"
91633,Segmentation fault when running torch.nn.functional.fractional_max_pool3d on torch 1.13.1,2023-01-03 15:47:18+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
91630,Periodic ROCM distribtued jobs are broken,2023-01-03 15:33:46+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
91624,trainer,2023-01-03 12:37:21+00:00,,0,2,"[Label(name=""triaged"")]"
91623,Investigate CUDA enabled build-time difference between MSVC and GCC+WSL,2023-01-03 11:50:55+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged"")]"
91622,Cross-compiled libtorch Windows Arm64 binaries,2023-01-03 11:40:28+00:00,,1,0,"[Label(name=""module: windows""), Label(name=""feature""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: arm"")]"
91618,There is no developer documentation about getting started with MPS native debugging,2023-01-03 09:45:41+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: mps"")]"
91617,MPS: `torch.sub` erroneously returns 0 on outputs of `chunk` via `layer_norm`,2023-01-03 09:39:57+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: mps"")]"
91615,"sparse.mm(coo, dense) produces wrong results on T4/V100 GPUs",2023-01-03 09:32:48+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
91608,SSL: CERTIFICATE_VERIFY_FAILED while trying to download pretrained model within a company that transforms SSL certificates for security purposes,2023-01-03 05:54:24+00:00,,1,8,"[Label(name=""triaged""), Label(name=""module: hub"")]"
91604,wrong assert message,2023-01-03 02:20:25+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
91629,vmap + nn.SyncBatchNorm.convert_sync_batchnorm,2023-01-02 20:10:33+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: data parallel""), Label(name=""module: ddp""), Label(name=""module: functorch"")]"
91599,"`mul(CSC, CSC)` fails with layout mismatch between the inputs and the output.",2023-01-02 19:49:26+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
91593,Division by zero error when running torch.nn.functional.lp_pool1d,2023-01-02 18:03:06+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
91590,Crashes of linalg.ldl_solve on different edge cases not coming from linalg.ldl_factor,2023-01-02 17:53:08+00:00,,0,2,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: edge cases"")]"
91582,Softmax function slows down for data with large range,2023-01-02 16:11:42+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
91581,LBFGS wolfe exceeds the maximum allowed iterations,2023-01-02 15:46:04+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
91577,[RFC] FP8 dtype introduction to PyTorch,2023-01-02 10:33:20+00:00,,1,14,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
91574,Add BlockWise Distribution Support to the torch.distributions Package,2023-01-02 00:49:27+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
91570,Security policy impractical / lacks contact information?,2023-01-01 16:46:36+00:00,,2,3,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""security"")]"
93498,torch.compiled mish function is x5 slower than eager (CPU),2023-01-01 11:14:12+00:00,,1,4,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
91566,Build Error: OpenMP library could not be found.  Proceeding might lead to highly sub-optimal performance.,2023-01-01 04:18:14+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: third_party"")]"
91565,min/max not supported for Long dtype on MPS,2023-01-01 03:39:09+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: mps"")]"
91562,`torch::jit::optimize_for_inference` doesn't preserve exported methods when calling `freeze`,2022-12-31 20:18:46+00:00,,0,0,"[Label(name=""oncall: jit"")]"
91557,Segmentation fault when running torch.nn.AdaptiveMaxPool3d,2022-12-31 16:20:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
91556,Overflow when running torch.nn.AdaptiveMaxPool3d on torch 1.12.0 and 1.13.1,2022-12-31 16:11:21+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
91553,Segmentation fault when running torch.nn.AdaptiveMaxPool2d,2022-12-31 15:03:20+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
91552,Overflow when running torch.nn.AdaptiveMaxPool2d,2022-12-31 14:58:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: pooling""), Label(name=""module: edge cases"")]"
91545,Adding label smoothing option to `nn.BCELoss`  and `nn.BCEWithLogitsLoss`?,2022-12-31 08:16:23+00:00,,0,10,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""actionable"")]"
91543,"Python 3.11.1 , even with nightly version of PyTorch: ERROR: No matching distribution found for torch",2022-12-31 04:09:18+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
91542,`torch.compile` frees computation graph in a GAN training setup and tries to call `backward` a second time,2022-12-31 01:40:33+00:00,,0,7,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
91536,The speed of matrix inversion is relatively slow for many small matrices,2022-12-30 13:55:54+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
91535,"When dist.broadcast float32 to int64, it will silently generate wrong results",2022-12-30 10:24:23+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
91533,Cannot cast float64 to float32,2022-12-30 08:02:35+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: numpy"")]"
91524,functorch.so is installed back into the source directory,2022-12-30 00:42:22+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: functorch"")]"
91509,[functorch] make batch norm docs point to UX limitations,2022-12-29 16:31:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
91508,Update map_nt to take into account size and strides,2022-12-29 15:53:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""bug"")]"
91504,torch.jit.script ERR: RuntimeError: Can't redefine method: forward on class: __torch__.SoSadModule,2022-12-29 13:04:39+00:00,,0,1,"[Label(name=""oncall: jit"")]"
91497,DISABLED test_tensor_requires_grad (test_jit.TestScript),2022-12-29 03:42:15+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91495,DISABLED test_rand (test_jit.TestScript),2022-12-29 03:42:12+00:00,,0,10,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91494,DISABLED test_optional_tensor (test_jit.TestScript),2022-12-29 03:41:34+00:00,,0,7,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91493,DISABLED test_prim_grad_undefined (test_jit.TestScript),2022-12-29 03:41:34+00:00,,0,7,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91492,DISABLED test_requires_grad_loop (test_jit.TestScript),2022-12-29 03:41:09+00:00,,0,8,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91489,DISABLED test_successful (jit.test_freezing.TestMKLDNNReinplacing),2022-12-29 03:40:39+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91488,DISABLED test_switch_inputs_to_inplace (jit.test_freezing.TestMKLDNNReinplacing),2022-12-29 03:40:36+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91486,DISABLED test_always_alive_values (jit.test_freezing.TestMKLDNNReinplacing),2022-12-29 03:40:33+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91484,DISABLED test_optional_list (test_jit.TestScript),2022-12-29 03:39:46+00:00,,0,7,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91482,DISABLED test_tensor_as_tensor_shape_prop (test_jit.TestScript),2022-12-29 03:39:40+00:00,,0,8,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91481,DISABLED test_merge_liveness (jit.test_freezing.TestMKLDNNReinplacing),2022-12-29 03:39:37+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
91471,Clean up nt impl duplicates where one can,2022-12-28 22:22:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: nestedtensor""), Label(name=""release notes: nested tensor"")]"
91470,torch.compile loud error on functorch transforms,2022-12-28 22:09:33+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
91469,torch.compile with aotautograd does not support double backwards,2022-12-28 21:55:27+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
91468,torch.compile incorrect when imperative autograd APIs are used,2022-12-28 21:54:17+00:00,,1,4,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
91467,DISABLED test_fs_preserve_sharing (__main__.TestMultiprocessing),2022-12-28 21:41:24+00:00,,0,2,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
91447,"Degenerate ranges are allowed in NumPy, but not in PyTorch.",2022-12-28 17:30:34+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
91439,Pytorch2.0 doesn't support compiling GRU and RNN model,2022-12-28 10:15:53+00:00,,0,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
91437,using Tensor subclass between vmap layers,2022-12-28 08:28:12+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""tensor subclass""), Label(name=""module: functorch"")]"
91435,Batch_first attribute in quantizable multiheadattention,2022-12-28 07:31:43+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
91417,[bazel] error: use of undeclared identifier 'cudaGraphDebugDotPrint',2022-12-27 22:33:40+00:00,,0,6,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
91406,Pytorch clang-tidy header-filter is still broken,2022-12-27 17:02:51+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
91396,[JIT] Zero-channel conv2d cannot be applied with `optimize_for_inference`,2022-12-27 03:42:21+00:00,,0,1,"[Label(name=""oncall: jit"")]"
91395,PyObject preservation and resurrection for `StorageImpl`,2022-12-26 23:08:25+00:00,,1,18,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering"")]"
91387,getting issue 'typeindex' file not found in Littorch-Lite/install/include/ATen/core/custom_class.h,2022-12-26 12:39:29+00:00,,0,2,"[Label(name=""oncall: mobile"")]"
91375,Internal Assert failed,2022-12-24 21:03:33+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
91374,[RFC] `quantile` should work for `float16`/`half` on the GPU,2022-12-24 18:05:04+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: half"")]"
91408,`NotImplementedError` when using `torch.distributed.launch`,2022-12-24 14:04:56+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: functorch"")]"
91368,"PyTorch memory leak reference cycle in for loop, Mac M1 ",2022-12-23 21:24:25+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: arm""), Label(name=""module: mps"")]"
91363,MPS backend does not accept int64 model weights or input data,2022-12-23 16:24:52+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: mps"")]"
91360,Offer `get_buffer` and `get_submodule` in `ScriptModule`?,2022-12-23 14:47:03+00:00,,0,0,"[Label(name=""oncall: jit"")]"
91358,[JIT] .backward() not supported by JIT trace,2022-12-23 11:51:14+00:00,,0,1,"[Label(name=""oncall: jit"")]"
91356,nop_partitioner for AOTAutograd,2022-12-23 10:42:03+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
91353,Perf reduction due to munmap with dataloader pinning thread ?,2022-12-23 07:07:05+00:00,,0,4,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
91352,"Internal error during ONNX export, diagnostic unusable ",2022-12-23 06:43:45+00:00,,1,5,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
91347,Remove redundant logics,2022-12-23 02:33:42+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
91334,Pytorch 1.13 conda package with cuda requires too many unneccessary packages,2022-12-22 23:11:14+00:00,,0,8,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
91325,Support for saving multiple storages/tensors that view same data as different dtypes,2022-12-22 20:17:51+00:00,,1,1,"[Label(name=""feature""), Label(name=""module: serialization""), Label(name=""triaged"")]"
91323,Expand torch.utils._pytree.tree_map,2022-12-22 19:56:47+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: pytree""), Label(name=""module: functorch"")]"
91311,Profiler is not properly recording seq number when any key above autograd is used,2022-12-22 15:30:01+00:00,,0,0,"[Label(name=""oncall: profiler"")]"
91310,AOT Autograd should allow backend compilers to see input mutations,2022-12-22 15:26:20+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
91309,iSTFT produces RuntimeError with center=False and Blackman/Bartlett/Hann windows,2022-12-22 13:32:19+00:00,,0,19,"[Label(name=""triaged""), Label(name=""module: fft"")]"
91305,`nn.TransformerEncoderLayer` fastpath (BetterTransformer) is slower than the normal path when no mask is provided,2022-12-22 11:09:19+00:00,,0,4,"[Label(name=""oncall: transformer/mha"")]"
91300,[🚀 Feature Request] pdf and sampling from Alpha-stable distribution ,2022-12-22 07:42:06+00:00,,0,7,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
91293,torch.fx tracer emits type error when tracing module that directly contains and uses the torch.cat() function,2022-12-22 04:46:54+00:00,,0,8,"[Label(name=""oncall: fx"")]"
91280,custom Function that supports functorch jvp doesn't work with in-place,2022-12-21 23:03:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: forward ad""), Label(name=""module: functorch"")]"
91278,Keep getting ChildFailedError Error,2022-12-21 22:31:18+00:00,,0,6,"[Label(name=""oncall: distributed"")]"
91274,torch.compile for calling func(**kwargs),2022-12-21 22:19:37+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93493,tensor.to_sparse() handling indices incorrectly under dynamo/fake tensor,2022-12-21 21:21:05+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes"")]"
91263,Make quant_min/quant_max required for observer/fake_quant,2022-12-21 20:40:05+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
91252,Open file leak when dataloader is using persistent_workers and pin_memory AND you create multiple dataloaders.  ,2022-12-21 16:41:23+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
91251,Potential bug found with pybind11 dec_ref while gil released,2022-12-21 16:40:44+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: pybind""), Label(name=""shadow review""), Label(name=""bug"")]"
91249,Use dynamo to detect incorrect op schemas automatically,2022-12-21 16:19:18+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
91245,Segmentation faults in DataLoader (in latest torch version).,2022-12-21 13:37:52+00:00,,0,10,"[Label(name=""needs reproduction""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
91244,first class dims leak memeory,2022-12-21 13:37:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
93492,ONNX export question (using torchdynamo),2022-12-21 13:32:27+00:00,,0,8,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
91229,JIT mishandles torch.round() in PyTorch 1.10.1,2022-12-21 05:31:43+00:00,,0,1,"[Label(name=""oncall: jit"")]"
91210,Odd/hand-wavy mathematical notation for Conv2D,2022-12-20 22:41:58+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
91205,dcp resharding does not work for optimizer state_dict,2022-12-20 22:08:20+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: distributed_checkpoint"")]"
91199,functorch.functionalize doesn't work with torch.autograd.grad,2022-12-20 21:21:25+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
91184,DISABLED test_index_add_correctness (__main__.TestTorch),2022-12-20 18:40:51+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: scatter & gather ops"")]"
91182,onednn(mkldnn) backend support for quantized operators,2022-12-20 18:05:09+00:00,,1,20,"[Label(name=""oncall: quantization""), Label(name=""triaged""), Label(name=""module: arm"")]"
91173,not able to import pipelines as torch.distributed is missing,2022-12-20 16:22:11+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""pipeline parallelism"")]"
91165,[FSDP] FSDP with CPU offload consumes `1.65X` more GPU memory when training models with most of the params frozen,2022-12-20 10:49:54+00:00,,0,18,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
91156,`quantile` fails for `float16`/`half` inputs,2022-12-20 06:12:31+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: half"")]"
91136,[Composable] Enable summon_full_params for fully_shard,2022-12-20 00:10:13+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
91135,[BE] Investigate FSDP test _zero_model ,2022-12-20 00:08:49+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
93491,Is there a way to write passes?,2022-12-19 21:50:21+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2"")]"
91099,[Dynamo] Graph Re-compilation Invoked by Changes of Unused Dict Values,2022-12-19 14:48:30+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
91098,[TorchScript] Failed to Forward Correct Number of Arguments to Different Functions,2022-12-19 14:38:07+00:00,,0,4,"[Label(name=""oncall: jit"")]"
93489,Remove redundant memory copy for HF multi-attention submodule for cpu path using MKL prepack,2022-12-19 09:29:44+00:00,,1,3,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
91073,Implement L1 and L2 gradient as hooks with the option of changing the weight decay value.,2022-12-18 06:54:25+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs design"")]"
91072,Unexpected behavior when running torch.max in cuda,2022-12-18 05:08:31+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
93488,"If minifier test fails, stderr/stdout of subprocess calls is not printed",2022-12-17 04:55:49+00:00,,1,0,"[Label(name=""triaged""), Label(name=""bug"")]"
91039,Simple deleting from the sys cache fails on reimport,2022-12-16 21:54:24+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: python frontend"")]"
93486,A Simple Function Causing Graph Break,2022-12-16 18:42:16+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug"")]"
91000,node.stack_trace does not handle escaping correctly,2022-12-16 14:53:54+00:00,,0,1,"[Label(name=""oncall: fx"")]"
90999,overflow (?) on cuda tensor after matrix multiplication,2022-12-16 14:49:24+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged"")]"
90998,"Crash in `index_select` with singleton `self`, non-singleton `index`",2022-12-16 14:09:27+00:00,,0,4,"[Label(name=""triaged"")]"
90992,as_strided_scatter : INTERNAL_ASSERT_FAILED for requires_grad=True and non-config input,2022-12-16 08:51:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functionalization"")]"
93484,TorchDynamo doesn't inline modified nn.Modules forward - Fails with Huggingface Accelerate,2022-12-16 01:43:34+00:00,,1,8,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
90954,[Composable] Enable setting state_dict_type,2022-12-15 21:40:34+00:00,,1,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
90952,Add support for torch.zero_grad in dynamo w/ dynamic shapes,2022-12-15 21:13:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
90923,dynamo.optimizations.training.aot_autograd does not trace correct overload,2022-12-15 15:11:28+00:00,,0,10,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
90920,Support for Transformer Models on Android with Vulkan Backend,2022-12-15 14:26:43+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: vulkan"")]"
90916,Functorch does not work with CrossEntropyLoss and label=-100,2022-12-15 12:49:35+00:00,,0,1,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: functorch"")]"
90915,Torch SummaryWriter import fails with torch 2.0 with an error on numpy.object,2022-12-15 12:47:34+00:00,,0,1,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
93483,Error in guard code crashes process NULL ERROR: /Users/ezyang/Dev/pytorch-metal/torch/csrc/dynamo/eval_frame.c:251,2022-12-15 10:53:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
90905,Retrieve Tensor from Tensor.data_ptr(),2022-12-15 09:04:08+00:00,,0,5,"[Label(name=""triaged""), Label(name=""core issue"")]"
90900,Check that SymPy semantics match Python semantics,2022-12-15 07:26:45+00:00,,0,3,"[Label(name=""triaged"")]"
90895,ModuleNotFoundError: No module named 'torch._C._distributed_c10d'; 'torch._C' is not a package,2022-12-15 03:48:54+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
90894,DISABLED test_numpy_ref_mps_nn_functional_group_norm_mps_float32 (__main__.TestCommonMPS),2022-12-15 03:41:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: mps"")]"
93482,[inductor] Add more matmul configurations to `TORCHINDUCTOR_MAX_AUTOTUNE=1` mode,2022-12-15 01:15:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2"")]"
90885,TorchScript with complex abs doesn't work in backward,2022-12-15 00:21:57+00:00,,0,1,"[Label(name=""oncall: jit"")]"
90878,Exporter for ONNX GroupNormalization operator,2022-12-14 23:28:30+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
93481,Umbrella issue for weakref related Dynamo PyTorch test suite failures,2022-12-14 22:03:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
93480,Umbrella issue for only populate real_value_cache in export test suite fails,2022-12-14 21:42:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
90866,Support arbitrary masks for _nested_tensor_from_mask in nn.TransformerEncoder,2022-12-14 21:37:02+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""oncall: transformer/mha"")]"
93479,Umbrella issue for PyTorch test suite failures from torch.* returned non-Tensor output unimplemented,2022-12-14 21:35:37+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
90857,[FSDP] Prepare to deprecate `FullyShardedDataParallel.<attrs>`,2022-12-14 20:25:25+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
90848,[Distributed] Destruction order fiasco in ProcessGroupNCCL workCleanupLoop(),2022-12-14 17:28:54+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
90844,AOT Autograd doesn't respect no_grad() during input mutations,2022-12-14 16:41:57+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
90842,nn.MultiheadAttention softmax inconsistent in training mode ,2022-12-14 15:12:28+00:00,,0,4,"[Label(name=""oncall: transformer/mha"")]"
90837,[FSDP] `fully_shard` Follow-Ups & Known Issues,2022-12-14 13:36:25+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
90832,Inference Mode docs,2022-12-14 10:11:37+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""inference mode"")]"
90831,Error when using torch.compile with Pytorch2.0,2022-12-14 10:04:14+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
90828,Compare oneDNN and OpenBLAS backend of PyTorch on arm64 architecture,2022-12-14 08:46:39+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: arm"")]"
90827,Support for Pylint,2022-12-14 07:43:09+00:00,,0,0,"[Label(name=""module: lint""), Label(name=""triaged"")]"
90820,Support `divmod` for tensors,2022-12-14 05:26:41+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
90793,nn.CrossEntropyLoss error out when the sample size is large,2022-12-13 20:58:39+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
90786,"[Composable API] Add `fully_shard` state dict unit test after manual ""wrapping"" is supported",2022-12-13 19:43:12+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
90784,[FSDP] Investigate `test_fsdp_pure_fp16.py` inaccuracy,2022-12-13 19:39:37+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
90775,"Extend ""torch.utils.cpp_extension.load"" for both lib64 and **lib**",2022-12-13 17:35:30+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
90774,Cannot compile torchtext model,2022-12-13 17:28:48+00:00,,1,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
90768,PyTorch 2.0 not working on Windows,2022-12-13 15:00:47+00:00,,0,18,"[Label(name=""module: windows""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
90760,Large slow down by not calling `torch.set_num_threads`,2022-12-13 12:26:43+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
90752,Adam (fused=True) issues,2022-12-13 08:32:36+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""module: optimizer""), Label(name=""module: cuda""), Label(name=""triaged"")]"
90751,pytorch prune in libtorch,2022-12-13 08:26:07+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
93477, [Inductor] [CPU] optimize thread parallel and loop collapse,2022-12-13 03:06:27+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
90742,Adopt full_backward_pre_hook in DDP,2022-12-13 01:54:01+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
93476,test_copy_broadcast,2022-12-12 20:13:02+00:00,,1,0,"[Label(name=""triaged"")]"
90708,PixelShuffle/Unshuffle Channels Last Support on GPU,2022-12-12 19:35:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
90703,RuntimeError: kind_.is_prim() INTERNAL ASSERT FAILED. Only prim ops are allowed to not have a registered operator but aten::mul doesn't have one either. We don't know if this op has side effects.,2022-12-12 17:35:13+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: primTorch"")]"
90695,`torch.empty` produces incorrect tensors with `layout=sparse_csr|sparse_csc` on the CPU,2022-12-12 14:43:26+00:00,,1,1,"[Label(name=""module: sparse""), Label(name=""module: docs""), Label(name=""module: cpu""), Label(name=""triaged"")]"
90691,[ONNX] Exporting the operator ::concat to ONNX opset version 13 is not supported.,2022-12-12 11:09:40+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
90688,In distributed get SIGTERM and run crash,2022-12-12 08:55:18+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
90676,RuntimeError: Error in dlopen: libnvJitLink.so.12: cannot open shared object file: No such file or directory,2022-12-12 02:01:29+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: distributions""), Label(name=""triaged"")]"
90663,[Feature Request] An alternative sampling routine for Dirichlet to fix Dirichlet and Beta sampling bugs,2022-12-11 18:10:01+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
90643,[FSDP][BE] `test_fsdp_comm_hooks.py` cleanup,2022-12-11 04:16:04+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
90633,torch.min document not up to date,2022-12-10 22:41:17+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
90613,`torch.inverse` multi-threading RuntimeError: lazy wrapper should be called at most once,2022-12-10 14:35:50+00:00,,0,13,"[Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""module: linear algebra"")]"
90608,Operator overload priority should not rely on static initialization order,2022-12-10 09:55:21+00:00,,0,5,"[Label(name=""oncall: jit"")]"
90607,"Export to ONNX of `as_strided()` hard codes stride in the graph, although it should be dynamic",2022-12-10 09:31:23+00:00,,1,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""release notes: onnx"")]"
90585,[threaded pg] All threads share one Random Number Generator,2022-12-10 00:07:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: dtensor"")]"
93474,AttributeError: 'tuple' object has no attribute 'grad',2022-12-09 23:32:19+00:00,,1,9,"[Label(name=""triaged"")]"
90578,"Multiprocessing ""Error Propagation"" doesn't work for FullyShardedDataParallelism.",2022-12-09 22:36:50+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
90574,Bfloat16 tensor .numpy() support ,2022-12-09 22:13:05+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: bfloat16"")]"
90560,"[discussion, idea] Batched, vectorized base64 decoding / encoding + maybe RLE decoding / encoding",2022-12-09 19:08:10+00:00,,0,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: nestedtensor"")]"
90555,[RFC] Add torch.backends.tbb.is_available(),2022-12-09 18:30:47+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: tbb"")]"
90553,Embedding dynamic quantization is not documented and hard to use,2022-12-09 17:44:22+00:00,,1,9,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
90551,Could not run 'aten::as_strided' with arguments from the 'Metal' backend.,2022-12-09 16:51:38+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: ios"")]"
90549,Abort called in FSDP tests,2022-12-09 15:31:22+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
90547,Unable to link LibTorch against CUDA and CUDNN statically,2022-12-09 15:17:11+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: static linking"")]"
90544,[Dispatchable Collectives] Follow up tasks,2022-12-09 14:57:54+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
90540,torch.compile() BackendCompilerFailed: _compile_fn raised RuntimeError,2022-12-09 12:40:07+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
90536,Illegal hardware instruction following Real Time Inference on Raspberry Pi 4 tutorial,2022-12-09 10:01:11+00:00,,0,4,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: arm"")]"
90535,Illegal hardware instruction using torch.nn.Conv2d on aarch64 (Raspberry Pi 4),2022-12-09 09:52:05+00:00,,0,2,"[Label(name=""module: crash""), Label(name=""triaged"")]"
90526,valgrind failure `Conditional jump or move depends on uninitialised value(s)`,2022-12-09 04:40:42+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: sanitizers"")]"
90521,[A ERROR in Docker] RuntimeError: CUDA error: no kernel image is available for execution on the device,2022-12-09 02:46:16+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: docker"")]"
90509,Can torchrun have a shell completion?,2022-12-08 23:45:57+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
90507,Functionalization on inplace_views should properly reflect autograd metadata,2022-12-08 23:36:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""module: pt2-dispatcher"")]"
90485,Tensor indexing and slicing documentation should explicitly state that indexing follows numpy semantics and link to the numpy indexing documentation.,2022-12-08 18:58:35+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy"")]"
90481,Internal assert when ctx.saved_tensors fails when saving results of an intermediate view tensor with torch.utils.checkpoint and use_reentrant=False,2022-12-08 17:49:17+00:00,,0,2,"[Label(name=""module: checkpoint""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""actionable"")]"
90466,Saving a scripted module to a buffer does not work.,2022-12-08 14:55:59+00:00,,0,0,"[Label(name=""oncall: jit"")]"
90465,[FSDP] Revisit meta device initialization,2022-12-08 13:27:52+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
90464,PR #89436 looks like it causes or enables a memory leak,2022-12-08 12:22:03+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: mps"")]"
90460,"Assertion failed: scales.is_weights() && ""Resize scales must be an initializer!""",2022-12-08 11:15:55+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
90459,Strange issue with tensor asyncio and RPC,2022-12-08 10:36:56+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
90447,Different behavior for complex numbers operations with numpy,2022-12-08 04:51:58+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy""), Label(name=""module: NaNs and Infs"")]"
90440,RuntimeError: Placeholder storage has not been allocated on MPS device!,2022-12-08 03:04:44+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mps"")]"
90439,Torch 1.13 Onnx Scope name not correct!,2022-12-08 02:51:17+00:00,,0,7,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
90424,A few functions in fbgemm_utils.cpp are defined in global namespace,2022-12-07 23:21:57+00:00,,1,4,"[Label(name=""module: cpp""), Label(name=""oncall: quantization""), Label(name=""triaged"")]"
90412,Importing numpy makes Tensor min max crash,2022-12-07 21:17:44+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
90398,IValue(c10::List<IValue>) constructor is confusing and undocumented,2022-12-07 18:03:56+00:00,,0,5,"[Label(name=""module: internals""), Label(name=""triaged"")]"
90395,"Cannot add target-level dependencies to non-existent target ""gloo_cuda"".",2022-12-07 17:38:51+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
90394,FX graph mode quant: backendconfig configuration missing for torch.nn.GRU,2022-12-07 17:30:24+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
90374,torch.utils.tensorboard import fails if a new protobuf > 3.20 is installed (bug in tensorboard/tensorflow but better guard against it),2022-12-07 10:06:38+00:00,,0,2,"[Label(name=""oncall: visualization"")]"
90373,"""Reached a code path in Module.get_extra_state() that should never be called.""",2022-12-07 10:06:35+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
90369,[JIT] Wrong type inference leads to misleading error message,2022-12-07 08:51:36+00:00,,0,0,"[Label(name=""oncall: jit"")]"
93470,Get the error: AttributeError: Can't pickle local object 'convert_frame.<locals>._convert_frame',2022-12-07 08:47:08+00:00,,1,14,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
90367,[JIT] INTERNAL ASSERT FAILED `torch.add` with boolean primitive constant,2022-12-07 08:23:55+00:00,,0,0,"[Label(name=""oncall: jit"")]"
90366,[JIT] INTERNAL ASSERT FAILED `torch.mul` with boolean primitive constant,2022-12-07 08:16:55+00:00,,0,0,"[Label(name=""oncall: jit"")]"
90365,[JIT] INTERNAL ASSERT FAILED when dispatching for `torch.Tensor.view`,2022-12-07 07:57:54+00:00,,0,1,"[Label(name=""oncall: jit"")]"
90347,[ONNX] test_mask_rcnn in test_models_onnxruntime.py failed with ONNX version==1.13.0,2022-12-07 02:25:44+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
90320,[RFC] Allow FSDP mixed precision for only certain type of submodules,2022-12-06 20:55:59+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
90318,[Tracking Issue] Mixed precision does not work with ignored modules ,2022-12-06 20:45:49+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
90305,Inconsistent Hash of IValue between aten/src/ATen/core/ivalue.cpp and aten/src/ATen/core/Dict_inl.h,2022-12-06 19:00:57+00:00,,0,1,"[Label(name=""oncall: jit"")]"
90301,Unknown buildin op: aten::pad,2022-12-06 18:00:49+00:00,,0,0,"[Label(name=""oncall: jit"")]"
93468,torch._dynamo.exc.Unsupported: dynamic shapes: arange,2022-12-06 17:31:39+00:00,,0,62,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
90289,quantization qconfig: can we set per-channel quant as default for qnnpack?,2022-12-06 15:21:35+00:00,,0,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
90288,quantization observers: can we relax the default epsilon value?,2022-12-06 15:14:34+00:00,,1,4,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
90284,Public API definition is not compatible with `torch.testing`,2022-12-06 14:50:20+00:00,,1,11,"[Label(name=""triaged""), Label(name=""module: testing""), Label(name=""module: python frontend"")]"
90277,cannot backward(),2022-12-06 12:43:56+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: mps"")]"
90263,Is it possible to add a parameter in torch.onnx.export to skip the prim::PythonOp subgraph process when exporting the autograd function?,2022-12-06 06:43:53+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
90261,Why torch.mode return different value between CPU and GPU,2022-12-06 06:14:55+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
90256,LibTorch static build from source missing libshm.so,2022-12-06 04:27:56+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
90245,[Distributed] `Invalid scalar type` when `dist.scatter()` boolean tensor,2022-12-06 01:53:56+00:00,,0,5,"[Label(name=""oncall: distributed"")]"
93466,Strategy for optimizing away transient dynamic shapes / device syncs,2022-12-05 22:31:25+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
93465,Graph breaks with HuggingFace Stable Diffusion,2022-12-05 19:30:10+00:00,,1,6,"[Label(name=""triaged""), Label(name=""bug"")]"
90194,Unexpected behaviour of 1.13.0,2022-12-05 17:53:30+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
90181,Graph is renamed in torch.jit,2022-12-05 15:24:44+00:00,,0,0,"[Label(name=""oncall: jit"")]"
93464,wav2vec2 model: error trying to do inference,2022-12-05 14:18:16+00:00,,2,4,"[Label(name=""triaged""), Label(name=""bug"")]"
90171,Option to let DistributedDataParallel know in advance unused parameters at each forward pass,2022-12-05 11:43:12+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""enhancement"")]"
90169,Unable to export CFlow model to ONNX,2022-12-05 11:24:57+00:00,,0,23,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
90147,[Feature Proposal] Extend torch hub to better support cloud serving and edge deployment,2022-12-04 23:28:48+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: hub"")]"
90138,p.block != nullptr && p.block->ptr != nullptr INTERNAL ASSERT FAILED,2022-12-04 16:14:51+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
90126,torch._dynamo.exc.BackendCompilerFailed: compile_fx raised TypeError: tqdm.__init__() got an unexpected keyword argument 'desc',2022-12-03 21:05:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: hub"")]"
90115,Couldn't install pytorch 2.0,2022-12-03 14:41:59+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged"")]"
90114,documentation need to be as per python version,2022-12-03 11:14:42+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
90107,Tensor.uniform_ fails to compile when using torch._dynamo,2022-12-03 04:51:53+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: initialization""), Label(name=""module: dynamo"")]"
90057,[GradScaler] Inconsistent scale values across different GPUs caused by uneven inputs for AMP DDP training,2022-12-02 13:12:54+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
90065,forward-mode AD formula for torch.add (and possibly others) accidentally upcasts float32 to float64,2022-12-02 10:31:11+00:00,,1,9,"[Label(name=""module: performance""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""ZeroTensor""), Label(name=""module: forward ad""), Label(name=""module: functorch"")]"
90052,DDP overlapped optimizer: set grads to None enhancements,2022-12-02 08:13:49+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: data parallel""), Label(name=""module: ddp"")]"
90019,[feature request] Need dtype torch.complex64 support on MPS Device,2022-12-01 20:49:38+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: mps"")]"
93463,Traceable tensor subclasses cannot actually be used with AOTAutograd,2022-12-01 14:25:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""bug"")]"
93462,TensorWithTFOverrideVariable unwraps too early,2022-12-01 14:19:13+00:00,,2,1,"[Label(name=""triaged""), Label(name=""bug"")]"
90000,"Can not use x=torch.tensor(b), to create a Tensor out of a List[List[Tensor]] (A List of Lists of Tensors)",2022-12-01 09:59:20+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
93461,Support getattr/setattr user properties on Tensor,2022-12-01 04:42:19+00:00,,1,1,"[Label(name=""triaged""), Label(name=""bug"")]"
89987,"Error in Adam.step(): If capturable=True, params and state_steps must be CUDA tensors.",2022-12-01 02:52:34+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
93458,minified code can not produce fp64_ref result,2022-11-30 22:21:57+00:00,,0,1,"[Label(name=""triaged"")]"
89959,Calling item() on symbolic shape fake tensor should give more clear error message,2022-11-30 21:01:17+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
89954,"Random sampling from a tensor constructed on MPS device, results in elements returning as torch.zeros(tensor[i].shape)",2022-11-30 20:25:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
89942,Random K compression hook in PyTorch DDP,2022-11-30 19:07:28+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: ddp"")]"
89908,Export to ONNX with export_modules_as_functions works wrong,2022-11-30 11:19:41+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
89907,nn.CrossEntropy/nn.NLLLoss : Request for option to specify invalid ignore_index for perf. optimization,2022-11-30 10:54:50+00:00,,0,5,"[Label(name=""module: loss""), Label(name=""triaged"")]"
93457,[Dynamo] Examples that recompile beyond cache size limit  ,2022-11-30 07:26:36+00:00,,0,0,"[Label(name=""triaged"")]"
93456,Way to run accuracy minifier on only one particular subgraph,2022-11-30 03:55:04+00:00,,1,0,"[Label(name=""triaged""), Label(name=""bug"")]"
89884,[RFC] PyTorch Tensor Parallel(TP) User API for Distributed Training,2022-11-30 00:29:54+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: dtensor"")]"
93455,Performance regression on interpolation in Kornia,2022-11-30 00:03:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug"")]"
89868,No pytorch_jni.dll file in libtorch 1.13.0 lib folder,2022-11-29 21:37:43+00:00,,0,1,"[Label(name=""oncall: java"")]"
89835,torch1.13  quantized model export onnx error,2022-11-29 11:53:40+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
89834,Wrong output type hint for `F.one_hot`,2022-11-29 11:03:07+00:00,,0,1,"[Label(name=""module: typing""), Label(name=""triaged"")]"
89829,update transformer init function,2022-11-29 08:58:37+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
89820,The current example for `torch.mode` is IMHO confusing and has room for improvement.,2022-11-29 03:40:57+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
89817,"Basic math operations produce a ""floating point exception""",2022-11-29 02:36:33+00:00,,2,26,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: cpu""), Label(name=""triaged"")]"
89784,InvokeAI using MPS is broken by torch nightlies since torch-1.14.0.dev20221104 inclusive ,2022-11-28 20:57:36+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
89764,addcmul on CUDA does not have the correct FMA behavior,2022-11-28 17:38:08+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged"")]"
89763,DISABLED test_hf_bert_ddp_inductor (__main__.TestFakeDistributedSingleProc),2022-11-28 17:35:13+00:00,,1,1,"[Label(name=""triaged""), Label(name=""skipped""), Label(name=""module: inductor""), Label(name=""module: distributed"")]"
93454,MMDet 3.x cannot run successfully in inductor mode,2022-11-28 06:11:29+00:00,,1,2,"[Label(name=""triaged""), Label(name=""bug"")]"
89757,third-order gradient of torch.pow with tensor args and certain input returns NaN,2022-11-28 05:33:34+00:00,,0,11,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
89738,[MPS] Add support for aten::repeat_interleave.self_Tensor for MPS backend,2022-11-28 05:12:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
89730,torch.addbmm throws different exception differences on CPU and GPU.,2022-11-28 00:16:24+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
89724,Sample Weighted BatchNorm1d,2022-11-27 19:05:14+00:00,,1,0,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: norms and normalization"")]"
89718,`torch.Tensor.flatten` Trigger Segmentation Fault when trying to provide and output named dim,2022-11-27 09:54:16+00:00,,0,2,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: named tensor"")]"
89716,DDP hangs on forward pass of transformer,2022-11-27 06:08:57+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
89714,Segfault on torch.nn.functional.one_hot with large tensor on Python 3.9,2022-11-27 02:48:01+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
89708,M1 mps issue,2022-11-26 17:39:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
93453,TensorWithTFOverrideVariable don't store fake tensor (they store real tensor),2022-11-25 17:09:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
89688,Enable NCCL for PyTorch on Windows,2022-11-25 15:55:53+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: windows""), Label(name=""triaged"")]"
93452,Dynamo is over-guarding on Tensor locals,2022-11-25 15:51:33+00:00,,1,2,"[Label(name=""triaged""), Label(name=""bug"")]"
89686,MultiProcess tests fail when run on nodes with 1 GPU,2022-11-25 14:51:19+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
93451,PTX codegen race?,2022-11-25 14:47:23+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
89684,`positive_semidefinite` constraint fails on CUDA 11.7,2022-11-25 13:47:59+00:00,,0,4,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
89675,[ONNX] torch.onnx.export snapshots the grads as constants in onnx when op is in cuda device,2022-11-25 05:22:27+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
89673,MPS bug on `torch.transpose` and `torch.log`,2022-11-25 02:24:49+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: mps"")]"
89657,MPS device ComplexFloat,2022-11-24 21:14:08+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fft""), Label(name=""module: mps"")]"
93450,torchinductor tests attempt to access internet,2022-11-24 16:36:32+00:00,,1,3,"[Label(name=""triaged""), Label(name=""bug"")]"
89634,[ONNX] torch.onnx.export can not export the grad of conv when the op is in CPU  ,2022-11-24 14:34:12+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
89630,[dynamo] RuntimeError: Failed running call_function aten.nll_loss_backward(*(FakeTensor(FakeTensor(...,2022-11-24 14:19:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
89629,[dynamo] RuntimeError: Failed running call_function aten.convolution_backward(*(FakeTensor(FakeTensor(..,2022-11-24 14:15:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
89627,[dynamo] RuntimeError: Failed running call_function aten.lift_fresh_copy(*(FakeTensor(FakeTensor(...,2022-11-24 14:07:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
89617,"Can not access to ""sbgemm"" routine with user-defined OpenBLAS",2022-11-24 06:20:57+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: openblas"")]"
89609,NVFuser failing masked.{amax|amin|sum} extremal and correctness tests,2022-11-24 01:10:56+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
89601,Building PyTorch with Vulkan backend fails (1.13 and master),2022-11-23 23:14:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vulkan"")]"
89597,Caching a model's weights and state_dict to disk to save RAM,2022-11-23 22:20:17+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
89574,Finish deprecation of autograd decorator over class objects,2022-11-23 16:51:01+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
93447,[Inductor] [CPU] LSTM is not using oneDNN in tts_angular,2022-11-23 08:50:21+00:00,,1,3,"[Label(name=""triaged"")]"
93446,[Inductor] [CPU] Vectorization not supporting python pass-in scalar double in speech_transformer,2022-11-23 07:37:23+00:00,,1,0,"[Label(name=""triaged"")]"
93445,[accuracy] [aot_eager] mobilenet_v2_quantized_qat fails accuracy ,2022-11-23 07:21:31+00:00,,1,11,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
93444,[Inductor] [CPU] Maxpooling is not vectorized in shufflenet_v2_x1_0,2022-11-23 06:36:02+00:00,,1,0,"[Label(name=""triaged"")]"
93443,Partitioner generates useless constant SymInt edges between forward-backwards,2022-11-23 04:24:14+00:00,,0,5,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
93442,AOTAutograd generates useless tangent inputs for SymInt outputs,2022-11-23 04:21:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
89546,Unable to launch CUDA Graph with DDP model ,2022-11-23 04:20:23+00:00,,0,4,"[Label(name=""oncall: distributed"")]"
89492,Feature Request: deterministic CUDA cumsum,2022-11-22 10:01:05+00:00,,0,12,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
89491,build: cmake: functorch.so not installed at expected location,2022-11-22 08:27:36+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
89490,build: cmake: ability to disable -Werror* (-Werror considered harmful),2022-11-22 08:21:37+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
89489,build: cmake: need to uniformize installation of libraries in CMAKE_INSTALL_LIBDIR (not lib),2022-11-22 08:11:49+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""needs research"")]"
89484,"kind_.is_prim() INTERNAL ASSERT FAILED at ""../torch/csrc/jit/ir/ir.cpp"":1098",2022-11-22 04:31:15+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: cpp"")]"
89483,Unexpected behavior from torchscript (mixing trace with script),2022-11-22 04:13:30+00:00,,0,1,"[Label(name=""oncall: jit"")]"
89482,"torch.split: argument 'split_sizes' (position 1) must be tuple of ints, not list",2022-11-22 03:44:04+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
89459,Higher order derivatives of sinc explode,2022-11-21 21:42:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: derivatives""), Label(name=""actionable"")]"
93438,Partitioner that doesn't require functionalized graph,2022-11-21 20:40:53+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
93437,Accuracy minifier can find spurious accuracy failures involving uninitialized memory,2022-11-21 20:36:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
93436,Accuracy minifier should also work even if an exception is raised,2022-11-21 19:51:56+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
89438,Allow `low` and `high` to be tensors in `torch.randint`,2022-11-21 17:57:05+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: random"")]"
89431,The problem caused by the parameter dim of torch.norm,2022-11-21 15:38:07+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
89421,fx.wrap is ignored with make_fx proxy tensor tracer,2022-11-21 12:14:51+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
89420,Edge case: torch.baddbmm supports double x int8 x int8 inputs on CPU but not CUDA,2022-11-21 12:11:10+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: linear algebra""), Label(name=""module: edge cases"")]"
89419,torch.equal can still run successfully when the parameter types are different.,2022-11-21 11:56:02+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: type promotion"")]"
89418,"torch.floor_divide: The dividend of torch.floor_divide is set to 0, but it can still run on the GPU.",2022-11-21 11:48:42+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
89417,OSError: libcublas.so.11: cannot open shared object file: No such file or directory,2022-11-21 11:37:16+00:00,,0,10,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
89416,"When the torch.masked_select operator passes in the same parameters, it behaves differently on CPU and GPU.",2022-11-21 11:33:48+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: masked operators"")]"
89408,torch.nn.MultiLabelMarginLoss has different performance on CPU and GPU.,2022-11-21 08:45:40+00:00,,0,3,"[Label(name=""module: loss""), Label(name=""triaged"")]"
89407,[MPS] Using unsqueeze in inference mode returns anomalous result,2022-11-21 08:08:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""inference mode""), Label(name=""module: mps"")]"
89406,stacks file from profiler is empty,2022-11-21 07:44:44+00:00,,0,4,"[Label(name=""oncall: profiler"")]"
89395,DISABLED test_coalesce_reference_cycle_cpu_float64 (__main__.TestSparseCPU),2022-11-21 03:52:54+00:00,,0,8,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
89394,torch.nn.TransformerEncoderLayer missing exception description information.,2022-11-21 02:34:36+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
89393,Edge case: CPU bool abs is not supported,2022-11-21 02:11:15+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: edge cases"")]"
89386,How can i patch the torch.jit in the second solution? Could not figure out entrypoint ?,2022-11-20 19:39:06+00:00,,0,0,"[Label(name=""oncall: jit"")]"
89381,torch.nn.ReplicationPad1d:The description of the exception information thrown is not accurate,2022-11-20 15:27:25+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: padding"")]"
89372,prod_cpu not implemented for 'BFloat16',2022-11-20 08:50:47+00:00,,0,9,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: bfloat16"")]"
89370,torch.nn.functional.normalize: whether true is equal to 1,2022-11-20 08:09:07+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
89369,RuntimeError: CUDA error: device-side assert triggered,2022-11-20 07:39:56+00:00,,0,2,"[Label(name=""module: loss""), Label(name=""triaged"")]"
89362,"torch.nn.functional.embedding_bag throws an exception when it runs on a CPU, but it runs successfully on a GPU.",2022-11-20 04:48:13+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: embedding"")]"
89361,Documentation: torch.nn.functional.embedding docs could more clearly state the requirement that weight be a 2D tensor,2022-11-20 04:27:57+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: embedding""), Label(name=""topic: docs"")]"
89357,Quantizable LSTM has different behavior than LSTM in bidirectional setting,2022-11-20 00:41:51+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""module: rnn""), Label(name=""triaged"")]"
89354,Per-sample input xfail / test generation,2022-11-19 21:20:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: testing"")]"
89344,AdaptiveAvgPool1d failed in the lower version,2022-11-19 11:43:05+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling"")]"
89343,AdaptiveAvgPool1d throws different exceptions when using the gpu,2022-11-19 11:18:47+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: pooling"")]"
89342,torch.mm: Exceptions thrown on the CPU and GPU are inconsistent,2022-11-19 08:18:22+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
89336,"Conv2d error on M1 mac, RuntimeError: NNPACK SpatialConvolution_updateOutput failed",2022-11-19 05:29:57+00:00,,0,3,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
93432,Should torchdynamo specialize on nn.Module,2022-11-18 23:49:23+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
89320,`masked_fill` with `FloatTensor` mask will never mask but fails silently.,2022-11-18 22:27:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: masked operators"")]"
89303,code sharing for fundamental ops in quantization,2022-11-18 19:18:19+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
89301,Meta implementation for copy_ is wrong,2022-11-18 18:47:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: meta tensors"")]"
93431,[dynamic shapes] detectron2 dynamic shapes fails,2022-11-18 18:05:11+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
89293,fbgemm_avx512 build failure,2022-11-18 17:54:18+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
93430,[Inductor] [CPU] Crash failure in torchbench model mobilenet_v2_quantized_qat & resnet50_quantized_qat,2022-11-18 17:18:23+00:00,,1,13,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
89283,torch.randn and torch.normal sometimes produce NaN on mps device,2022-11-18 14:07:05+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: mps"")]"
89277,NotImplementedError: The operator 'aten::upsample_nearest1d.out' is not current implemented for the MPS device,2022-11-18 08:53:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
89275,"torch.addcdiv: input, tensor1, and tensor2 parameters should be of the same type",2022-11-18 08:00:56+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
89255,torch.lobpcg should support black-box linear operators like SciPy,2022-11-18 01:09:30+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
89254,"`torch.nn.ReplicationPad2D` Report ""invalid configuration argument"" Error under Compute Sanitizer",2022-11-18 01:00:59+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: padding"")]"
89245,sm_80 support,2022-11-17 23:12:45+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
89241,"Can't use JIT modules traced with AMP autocast, with Triton Server (or any C++ environment) - freeze() issue ?",2022-11-17 21:40:40+00:00,,0,6,"[Label(name=""oncall: jit"")]"
89219,Dynamo + NNC: incorrect results with in-place ops on inputs,2022-11-17 17:21:50+00:00,,0,0,"[Label(name=""triaged""), Label(name=""NNC""), Label(name=""module: dynamo"")]"
89218,"`torch.nn.LayerNorm` Abort with ""invalid device ordinal"" Error",2022-11-17 16:57:43+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
89208,`torch.nn.CTCLoss` Trigger out-of-bound Read under Compute Sanitizer,2022-11-17 13:50:21+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: sanitizers"")]"
89204,Libtorch's CPU inference is much slower on Windows than on Linux,2022-11-17 10:25:08+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: windows""), Label(name=""triaged"")]"
89197,Collective operations do not work with `torch.BoolTensor`s on `gloo` and raise `Invalid scalar type`,2022-11-17 07:12:52+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
93425,[aot-autograd] [hf_BigBird] Output 0 of CompiledFunctionBackward is a view and is being modified inplace,2022-11-17 07:06:51+00:00,,1,8,"[Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""bug""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
89185,[feature request] Add ability to preserve traced shape during torch.jit.save and torch.jit.load,2022-11-17 04:55:09+00:00,,0,2,"[Label(name=""oncall: jit"")]"
89160,Got many TestDTensorOpsCUDA.test_dtensor_op_db_X test failures,2022-11-16 21:24:22+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
89158,Support disallowing calls to certain instance methods in TorchDynamo,2022-11-16 20:46:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
89136,[FSDP] Adam Gives Different Results Where Only Difference Is Flattening,2022-11-16 15:16:55+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
89133,[FSDP] Investigate Unit Testing when Gradient Computation Differs on CPU/GPU,2022-11-16 14:06:25+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
89127,torch.normal(...) on MPS sometimes produces NaN's,2022-11-16 10:40:07+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
89125,binary_cross_entropy/bce_with_logits (+ other loss functions) for nested_tensor,2022-11-16 09:48:15+00:00,,0,2,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
89124,Zero-copy way to make flat tensor into a nested_tensor given a shape,2022-11-16 09:43:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
89116,Implement generic batch normalization layer.,2022-11-16 04:48:02+00:00,,1,10,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
89114,jit.script() fails to resolve/cast Optional[Tensor] fields of sub-modules or base classes of the object being scripted,2022-11-16 03:21:24+00:00,,0,1,"[Label(name=""oncall: jit"")]"
89105,Bad string in GLSL shader,2022-11-16 00:57:17+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: vulkan""), Label(name=""topic: build"")]"
96337,pytreeify decorators,2022-11-15 20:22:11+00:00,,0,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: pytree""), Label(name=""module: functorch"")]"
89080,Unable to backprop through dense weighted sum of sparse_coo_tensors,2022-11-15 19:15:55+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
89076,Transformers model tracing not working,2022-11-15 17:30:08+00:00,,0,2,"[Label(name=""oncall: jit"")]"
89068,view_copy out= does not reshape zero element tensors,2022-11-15 16:03:23+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping""), Label(name=""module: functionalization"")]"
97248,"A more systematic API for resolving the ""vmap-incompatible in-place operation"" error",2022-11-15 15:49:21+00:00,,0,1,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""needs design""), Label(name=""module: functorch"")]"
89065,Improve clarity of meaning of `torch.jit.trace`'s `example_inputs`,2022-11-15 15:14:13+00:00,,0,0,"[Label(name=""oncall: jit"")]"
89064,UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`.,2022-11-15 15:10:43+00:00,,0,3,"[Label(name=""oncall: jit"")]"
89060,Extend test_proxy_tensor tests to support ops test non floating point types,2022-11-15 14:34:49+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: ProxyTensor"")]"
89054,Add a `device` keyword argument to `torch.manual_seed`,2022-11-15 11:46:20+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: random"")]"
89051,caffe2_interface_library CMake macro prevents linking to LibTorch as a transitive dependency,2022-11-15 09:00:40+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
89050,torch.distributed can't establish connection.,2022-11-15 08:48:03+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
89041,"cross compile pytoch using cmake , get an error : protobuf::protoc: command not found",2022-11-15 06:41:52+00:00,,0,0,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
89034,[PT][1.13] torch .numpy() fn broke for some scenario,2022-11-15 03:53:26+00:00,,0,7,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: regression""), Label(name=""actionable""), Label(name=""ZeroTensor"")]"
89006,Add smoke-tests for CPP extensions compilations,2022-11-14 19:18:48+00:00,,1,0,"[Label(name=""high priority""), Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""module: regression"")]"
88992,Incorrect version in the instructions on official website,2022-11-14 14:07:25+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
88991,nvprims.native_batch_norm doesn't support fake tensor inputs,2022-11-14 13:15:45+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
88980,Glog macro redefinition problem when including headers from both libtorch and glog,2022-11-14 06:21:35+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
88968,M1 runner i-090e1df32b6f48a20 run out of disk space,2022-11-13 16:27:08+00:00,,0,4,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: m1"")]"
88950,`torch.nn.functional.embedding_bag` Trigger RuntimeError under UndefinedBehaviorSanitizer,2022-11-12 16:54:50+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: sanitizers"")]"
88949,`torch.set_rng_state` Trigger RuntimeError under UndefinedBehaviorSanitizer,2022-11-12 16:51:50+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: sanitizers"")]"
88948,torch.linalg.matrix_rank memory leak,2022-11-12 16:48:35+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
88947,`torch.Tensor.msort` Trigger RuntimeError under UndefinedBehaviorSanitizer,2022-11-12 16:48:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: sanitizers"")]"
88945,`torch.linalg.eigvals` Trigger RuntimeError under UndefinedBehaviorSanitizer,2022-11-12 16:45:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: sanitizers"")]"
88944,`torch.topk` Trigger RuntimError under UndefinedBehaviorSanitizer,2022-11-12 16:42:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: sanitizers"")]"
88943,`torch.vander` Trigger RuntimeError with UndefinedBehaviorSanitizer,2022-11-12 16:39:18+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: sanitizers""), Label(name=""module: edge cases"")]"
88942,`torch.svd_lowrank` Trigger RuntimeError under UndefinedBehaviorSanitizer,2022-11-12 16:34:02+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""actionable""), Label(name=""module: sanitizers"")]"
88941,`torch.linalg.lstsq` Trigger RuntimeError under UndefinedBehaviorSanitizer,2022-11-12 16:30:33+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""actionable""), Label(name=""module: sanitizers""), Label(name=""module: edge cases"")]"
88931,INTERNAL ASSERT FAILED. Missing scalar type infromation.,2022-11-12 09:51:46+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
93419,"torchdynamo is not properly setting up input tracking (e.g., for symbolic shape guards) for view bases",2022-11-12 05:26:58+00:00,,1,1,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
88902,MPS test_numpy_ref_mps_nn_functional_group_norm_mps_float32 is flaky?,2022-11-11 19:37:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: mps"")]"
93618,[dynamo+ddp+symbolic-shapes] Issue Tracker,2022-11-11 18:40:28+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
88893,RuntimeError: derivative for aten::mps_max_pool2d_backward is not implemented,2022-11-11 17:48:25+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mps"")]"
88883,Investigate why `test_aot_autograd_symbolic_exhaustive_masked_median_cpu_float32` is flaky,2022-11-11 12:37:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
88882,Can't import torch --> OSError related to libcublasLt.so.11,2022-11-11 12:25:35+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: regression"")]"
88880,Add alphatensor support for faster matrix multiplication?,2022-11-11 09:54:33+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""matrix multiplication"")]"
93617,[Inductor] Input Buffers Should Be Representable As Storage And Layout,2022-11-11 01:22:15+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""internal ramp-up task"")]"
88842,test/test_ops.py is segfaulting on master build with DEBUG assets,2022-11-10 21:20:59+00:00,,1,12,"[Label(name=""high priority""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: testing"")]"
88838,[RFC] PyTorch DistributedTensor,2022-11-10 19:27:21+00:00,,0,25,"[Label(name=""oncall: distributed""), Label(name=""module: dtensor"")]"
88813,Inductor may merge two output tensors into one,2022-11-10 15:09:35+00:00,,0,3,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""module: inductor""), Label(name=""internal ramp-up task"")]"
88810,Return the attention weights using the Transformer Encoder class. ,2022-11-10 14:13:50+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
88805,[feature request] Get/set fastmath CPU bit (and some other FPU flags?),2022-11-10 09:08:40+00:00,,0,5,"[Label(name=""module: numerical-stability""), Label(name=""module: cpu""), Label(name=""triaged"")]"
88802,ImportError: libcupti.so.11.2: cannot open shared object file: No such file or directory,2022-11-10 07:10:20+00:00,,0,2,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
88801,[ONNX] Convert to onnx scatter op and LSTMCell op and for Loop,2022-11-10 06:46:48+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
88800,Quantization error between fake-quantized model and quantized model using the new observer,2022-11-10 06:46:18+00:00,,1,9,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
88791,Potential bug in torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,2022-11-10 01:18:31+00:00,,0,3,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: LrScheduler"")]"
88775,Batched Random Number Generators,2022-11-09 23:03:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: random"")]"
88765,torch.jit.trace() - AttributeError: 'NoneType' object has no attribute '__module__,2022-11-09 20:32:15+00:00,,0,8,"[Label(name=""oncall: jit"")]"
88735,RuntimeError: method '__torch__.___torch_mangle_0.MyModule.sin' already defined.,2022-11-09 11:05:42+00:00,,0,0,"[Label(name=""oncall: package/deploy"")]"
88732,scatter_ op convert onnx exception,2022-11-09 08:35:49+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
88721,DISABLED test_extract_gradients_from_optimizer_set_to_none (__main__.TestIdentifyGradients),2022-11-09 03:58:04+00:00,,0,16,"[Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: profiler"")]"
88691,forward AD for _euclidean_dist,2022-11-08 19:28:01+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: forward ad""), Label(name=""module: functorch"")]"
88686,Consolidate binary build matrix for core and validation workflows,2022-11-08 17:00:20+00:00,,1,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
88658,"nn.Linear allocate too many space which lead to CPUAllocator ""allocate memory failure"" if it's BF16. good for FP32.",2022-11-08 07:40:17+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""intel"")]"
93613,Minifier crash,2022-11-08 04:20:42+00:00,,1,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2"")]"
88648,`MultiMarginLoss` doesn't check the value of `target` on CUDA,2022-11-08 03:33:47+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
88647,`ConvTranspose` fails on CPU but returns an empty tensor on CUDA,2022-11-08 03:22:27+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
88643,pack_sequence() always fail after set_default_tensor_type to CUDA,2022-11-08 01:53:29+00:00,,0,1,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
88639,CUDA unknown error after suspend during debugging,2022-11-08 01:22:42+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
88631,GitHub first-time contributors box pops up unexpectedly,2022-11-08 00:49:34+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
88626,Cloud-based rendezvous backend / distributed store?,2022-11-08 00:29:09+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
88621,"[FSDP] FSDP produces different gradient norms vs DDP, and w/ grad norm clipping creates different training results",2022-11-07 23:48:03+00:00,,1,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""release notes: distributed (fsdp)"")]"
88617,"The libtorch tests Simplify.{SimplifySymbolicMinMax,SimplifyNestedMax,SimplifyNestedMin} fail on Apple Silicon",2022-11-07 22:56:56+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: m1"")]"
88616,The libtorch test SequentialTest.ModuleForwardMethodOptionalArg fails on Apple Silicon,2022-11-07 22:54:12+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: m1"")]"
88614,The libtorch test TestScalarTensor.TestScalarTensorMPS fails on Apple Silicon,2022-11-07 22:52:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: mps""), Label(name=""module: m1"")]"
88613,The libtorch test ConstantPropagation.CustomClassesCanBePropagated fails on Apple Silicon,2022-11-07 22:32:43+00:00,,1,4,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: m1"")]"
88612,Bernoulli uses legacy contiguous memory format,2022-11-07 22:27:34+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
88609,quantization convert should warn the user if calibration has not happened,2022-11-07 21:55:50+00:00,,2,4,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
88598,"Despite having aten::diag_embed.out, torch.diag_embed doesn't support out= argument",2022-11-07 19:26:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
88591,`pack_padded_sequence` not compatible with deterministic mode it calls `torch.scatter`,2022-11-07 18:05:08+00:00,,0,0,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: determinism"")]"
88581,"cpp_extension CUDA library path hard-coded as ""lib64"" but may be ""lib""",2022-11-07 15:25:24+00:00,,0,1,"[Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""actionable"")]"
88579,[Quant] Validate FixedQParams observers in eager mode,2022-11-07 15:07:47+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
88576,Dynamo handling for all methods of torch.Generator,2022-11-07 14:30:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
88574,Add support for `torch.Generator` in the FX IR,2022-11-07 13:34:59+00:00,,0,1,"[Label(name=""oncall: fx"")]"
88565,What causes CPU to degrade when I load the weight with torch.hub.load(),2022-11-07 04:37:31+00:00,,0,6,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: hub""), Label(name=""intel"")]"
88563,`nn.functional.embedding_bag` Trigger out-of-bound Read under Compute Sanitizer,2022-11-07 04:20:47+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
93610,We probably are allowing mutations to happen on fake tensor in VariableTracker,2022-11-04 17:05:50+00:00,,1,7,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""module: dynamo"")]"
88505,quantization: error message when using `convert_fx` on a model on cuda should be better,2022-11-04 17:01:02+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
93609,Don't store example_value on FX node meta,2022-11-04 15:41:12+00:00,,1,2,"[Label(name=""triaged""), Label(name=""bug"")]"
88491,torch.set_grad_enabled results in RuntimeError with torch.jit.script,2022-11-04 13:31:41+00:00,,0,0,"[Label(name=""oncall: jit"")]"
88475,DISABLED test_module_attribute_mutation_violation_negative_2 (__main__.MutationExportTests),2022-11-04 03:57:55+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
88474,Mixed precision training fails due to NaN in batch norm running_mean,2022-11-04 03:19:18+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
88472,DISABLED test_index_put_accumulate_large_tensor_cpu (__main__.TestIndexingCPU),2022-11-04 02:38:29+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
88469,DISABLED test_fn_gradgrad_linalg_lu_factor_cuda_complex128 (__main__.TestBwdGradientsCUDA),2022-11-04 00:58:59+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: linear algebra""), Label(name=""skipped""), Label(name=""module: unknown"")]"
88468,DISABLED test_module_attribute_mutation_violation_negative_1 (__main__.MutationExportTests),2022-11-04 00:58:56+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
88467,DISABLED test_module_attribute_mutation_violation_negative_4 (__main__.MutationExportTests),2022-11-04 00:58:53+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
88466,DISABLED test_module_attribute_mutation_violation_negative_3 (__main__.MutationExportTests),2022-11-04 00:58:51+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
88464,MaxPool1D output shapes can be negative when ceil_mode=True,2022-11-04 00:16:45+00:00,,1,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling"")]"
88448,linear mm weight and bias dtypes mismatch bypasses,2022-11-03 20:55:51+00:00,,0,2,"[Label(name=""oncall: jit"")]"
88447,`unique` will reverse the input when `sort=False` on cpu (not sorting),2022-11-03 20:30:11+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""intel"")]"
93607,torch._dynamo.exc.Unsupported: call_function UserDefinedClassVariable() [] {} ([Feature request] Allow custom classes with custom __setattr__ method in torchdynamo),2022-11-03 20:16:50+00:00,,0,5,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2"")]"
88443,Hang: sampling VonMises distribution gets stuck in rejection sampling for small kappa,2022-11-03 19:33:53+00:00,,1,9,"[Label(name=""high priority""), Label(name=""module: distributions""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deadlock"")]"
88423,view_as_real and split_with_sizes links in Tensor Views docs are broken,2022-11-03 14:27:49+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
88415,Enable AMP for MPS devices,2022-11-03 10:15:13+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)""), Label(name=""module: mps"")]"
88413,Flaky dynamo test_indexing flaky with SIGKILL,2022-11-03 06:43:42+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: dynamo"")]"
88410,benchmark cache persist,2022-11-03 06:14:19+00:00,,0,8,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
88408,Unit test with `--subprocess` command doesn't respect the `-k` filter flag and runs all available sub tests,2022-11-03 05:20:55+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: testing"")]"
88389,Whether to support libtorch source code compilation of C++11 ？,2022-11-03 03:01:43+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
88380,cuDNN error (CUDNN_STATUS_NOT_SUPPORTED) for torch.nn.functional.grid_sample(),2022-11-03 00:14:05+00:00,,0,1,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
88375,[PrimTorch] Functionalization pass removes Instance Norm / Batch Norm running stats transformations,2022-11-02 23:20:07+00:00,,1,8,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: primTorch"")]"
93604,TorchBench - moco - RuntimeError: Tensors must be CUDA and dense,2022-11-02 18:28:13+00:00,,1,4,"[Label(name=""triaged""), Label(name=""bug"")]"
88327,MSE documentation is weak,2022-11-02 16:45:28+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""triaged"")]"
88325,Group losses in a common namespace,2022-11-02 16:24:05+00:00,,1,3,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""needs research"")]"
88320,`torch.load()` cannot load data saved at non-zero position in a file (`failed finding central directory`),2022-11-02 15:22:32+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
88309,ASAN shard 4 started to OOM after unrelated commit,2022-11-02 14:15:03+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
88304,AttributeError: module 'tensorboard.compat.tensorflow_stub.io.gfile' has no attribute 'MakeDirs',2022-11-02 12:46:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
88301,1.12.1 incompatible with c++ built for 1.12.0 and vice versa,2022-11-02 10:02:48+00:00,,0,9,"[Label(name=""oncall: jit""), Label(name=""module: cpp"")]"
93602,Diffuser pipeline device attribute broken when using optimized model,2022-11-02 00:28:57+00:00,,1,2,"[Label(name=""triaged""), Label(name=""bug"")]"
88265,build: failure when upgrade oneTBB to 2021.7.0,2022-11-01 23:16:33+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: tbb"")]"
88308,"Hessian is (incorrectly) zero when using MPS on M1 Mac, but not on cpu ",2022-11-01 23:08:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps""), Label(name=""module: functorch"")]"
88264,[ONNX] Flaky CI test failures with different random seed,2022-11-01 23:07:28+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
88251,Weird random SIGTERM occurance,2022-11-01 21:52:19+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""oncall: r2p"")]"
88245,Add `gloo` support for `all_to_all`,2022-11-01 20:54:23+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
88227,Enable `torch.topk` to support `stable` flag ,2022-11-01 18:47:29+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
88194,Add a config option to raise errors instead of warnings in nvFuser integration,2022-11-01 14:24:50+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
88192,[docs] torch.is_neg/torch.Tensor.is_neg not documented,2022-11-01 14:17:06+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
88191,`torch.nn.RReLU` not reporting `lower > upper` on CUDA,2022-11-01 13:34:29+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
88189,Moving tensor to GPU by .cuda() gets stucked when AMD Secure Encripted Virtualization (SEV) is activated,2022-11-01 12:33:31+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: rocm""), Label(name=""triaged"")]"
88185,`torch.mm` Trigger RuntimeError with UndefinedBehaviorSanitizer,2022-11-01 09:27:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: sanitizers"")]"
88148,☂️  Issues that trigger crashes due to corner-case API usages,2022-10-31 22:39:20+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
88147,Conv2d is not deterministic when input tensor has different strides,2022-10-31 22:22:44+00:00,,0,3,"[Label(name=""module: convolution""), Label(name=""triaged"")]"
88144,AvgPool2D output shapes are inconsistent when ceil_mode=True,2022-10-31 22:13:24+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: pooling"")]"
88142,Refactor `torch.return_types.topk` to behave like a `namedtuple` or a `dict`,2022-10-31 22:06:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: sorting and selection"")]"
88137,"Add eq, to, masked_select, index_select, narrow to nested tensors",2022-10-31 20:58:48+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
88136,Placing LSTM model on bfloat16 on GPU causes error,2022-10-31 20:56:56+00:00,,0,3,"[Label(name=""module: rnn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: bfloat16"")]"
88109,Python Dispatcher registrations beyond BackendSelect do nothing,2022-10-31 18:25:16+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: python dispatcher"")]"
88103,ProcessGroupNCCL watchdog can't catch NCCL comm initialization issues,2022-10-31 17:53:00+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
88096,Add nondeterministic alert to `torch.Tensor.scatter()`,2022-10-31 16:42:55+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: determinism"")]"
88081,out of memory with pytorch version after 1.8.1,2022-10-31 12:27:18+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
88072,convert torch.jit.script model to ONNX get wrong result,2022-10-31 07:41:35+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
88062,Cannot import `traverse_dps` from torch.data.utils.graph,2022-10-31 00:18:06+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: data"")]"
88053,Different behaviour in sparse matmul,2022-10-30 17:55:33+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
88047,`torch.nn.CTCLoss` Trigger heap-buffer-overflow under AddressSanitizer,2022-10-30 09:00:12+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: sanitizers""), Label(name=""module: edge cases"")]"
93596,Minifier doesn't work on DebertaForQuestionAnswering,2022-10-30 02:31:47+00:00,,1,2,"[Label(name=""triaged""), Label(name=""bug"")]"
93593,Inductor gives obscure error when FX graph to be compiled returns tuple,2022-10-30 01:15:39+00:00,,1,9,"[Label(name=""triaged""), Label(name=""bug"")]"
93592,Turning on minifier causes bug to go away (on DebertaForMaskedLM),2022-10-30 00:37:29+00:00,,1,1,"[Label(name=""triaged""), Label(name=""bug"")]"
88036,A segment fault can be triggered in fbgemm_pack_gemm_matrix_fp16,2022-10-29 15:01:43+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: third_party""), Label(name=""module: half"")]"
88027,"getting error error: namespace ""cub"" has no member ""Debug"" when try to build v1.8.2 with CUDA 11.6",2022-10-29 02:29:25+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
88025,[WIP] Composable FSDP Follow-Ups,2022-10-29 00:16:08+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
88006,C++ Extensions can't import c10d/reducer.hpp,2022-10-28 21:06:58+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
88002,Einsum Optimization Tracker,2022-10-28 19:42:05+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
87995,multi-node distributed training rank0 hang at dataloader after a few epochs,2022-10-28 18:19:54+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader"")]"
87992,torch.rand(...) is not consistent for large shape dimensions across GPUs (with the same random seed),2022-10-28 17:14:10+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: random"")]"
87979,amp with `bf16`: backward happens in `f16` when using `@torch.cuda.amp.custom_bwd`,2022-10-28 12:29:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: half""), Label(name=""module: amp (automated mixed precision)"")]"
87964,`torch.distributed` crash with abort only inside if,2022-10-28 05:45:27+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: crash"")]"
87961,crash in `torch.package.PackageExporter`,2022-10-28 05:33:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
87960,crash when call `torch.set_num_interop_threads` twice,2022-10-28 05:27:50+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged"")]"
87957,VS2022Preview ParallelCommon.cpp.obj : fatal error LNK1161: invalid export specification,2022-10-28 04:43:10+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: static linking"")]"
87956,Autograd doesn't stop executing backward graph early enough in situations involving set_,2022-10-28 02:59:58+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""actionable"")]"
87955,AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute 'next',2022-10-28 02:39:06+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
88004,link error happen when intergrate libtorch to other tool,2022-10-28 02:23:43+00:00,,0,7,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
93590,test_conv_large_cuda: RuntimeError: CUDA error: an illegal memory access was encountered,2022-10-28 00:05:20+00:00,,0,1,"[Label(name=""triaged"")]"
93589,test_batchnorm_eval_cuda_float32: AttributeError: 'NoneType' object has no attribute 'clone',2022-10-27 23:58:26+00:00,,1,2,"[Label(name=""triaged"")]"
93588,"test_LSTM_grad_and_gradgrad_cuda_float64: ValueError: gradcheck expects at least one input tensor to require gradient, but none of the them have requires_grad=True.",2022-10-27 23:55:20+00:00,,1,1,"[Label(name=""triaged"")]"
93585,"test_memory_format_ao_nn_quantized_MaxPool2d_cuda_float32: assert not memory_format, ""TODO""",2022-10-27 22:57:10+00:00,,0,0,"[Label(name=""triaged"")]"
87902,Permute,2022-10-27 19:11:48+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
87890,"""No CUDA GPUs are available"" coming from GHA g5 runners",2022-10-27 18:56:45+00:00,,1,2,"[Label(name=""oncall: releng""), Label(name=""module: ci""), Label(name=""triaged"")]"
87886,Add aten::empty.memory_format for SparseMPS,2022-10-27 18:26:47+00:00,,0,22,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: mps"")]"
87864,Failure to export scripted models to ONNX when input is a list of tensor,2022-10-27 15:49:06+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
87861,RuntimeError: unable to mmap 29764 bytes from file </torch_10182_3020184674_63991>: Cannot allocate memory (12),2022-10-27 14:37:28+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensor creation"")]"
87859,"M1 Mac, MPS: Buffer is not large enough",2022-10-27 14:02:19+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
93582,[Inductor] Support deterministic parallel reduction in CPP backend,2022-10-27 13:26:49+00:00,,1,1,"[Label(name=""triaged"")]"
87841,`max_unpool3d` will trigger an assertion fail under compute sanitizer,2022-10-27 04:11:29+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: sanitizers""), Label(name=""module: pooling"")]"
87800,[ONNX] Graph passes analysis,2022-10-26 17:15:39+00:00,,2,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
87794,CUDA error: operation not permitted when stream is capturing (2 GPUs),2022-10-26 16:16:30+00:00,,0,5,"[Label(name=""module: multi-gpu""), Label(name=""triaged"")]"
87792,`AvgPool` and `MaxPool` will crash in JIT w/o profiling executor,2022-10-26 16:14:52+00:00,,0,0,"[Label(name=""oncall: jit"")]"
87787,`BatchNorm` a 0-shape tensor will crash in JIT trace w/o profiling executor on cuda,2022-10-26 15:45:52+00:00,,0,0,"[Label(name=""oncall: jit"")]"
87785,"ONNX-exported model cannot output Dict[str, X] or str",2022-10-26 14:58:41+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
93580,AssertionError: Unknown expression s2,2022-10-26 13:50:52+00:00,,1,4,"[Label(name=""triaged""), Label(name=""bug"")]"
87782,Libtorch windows binaries publishing,2022-10-26 13:17:00+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""topic: binaries"")]"
87781,`torchtyping` annotations make saving to Torchscript fail,2022-10-26 12:43:31+00:00,,0,0,"[Label(name=""oncall: jit"")]"
87777,Improvements to fuse optimization,2022-10-26 07:45:40+00:00,,0,2,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: fx"")]"
87755,Autograd precision for CONV + BN  between pytorch version 1.11.0 and 1.12.1,2022-10-26 01:44:52+00:00,,0,4,"[Label(name=""module: numerical-stability""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
87753,`torch.min`/`torch.max` returns bogus values for default int tensors on MPS,2022-10-26 01:24:50+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
87745,TorchDynamo: there has a accuracy issue for conv+unary(binary) post ops for gpu path,2022-10-26 00:48:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamo"")]"
87734,Checkpointing Support for Modularized Optimizers,2022-10-25 22:01:01+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs design"")]"
87733,"FakeTensorMode doesn't support two Scalar inputs, if we use prims' impl as the meta function ",2022-10-25 21:57:05+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: primTorch""), Label(name=""module: fakeTensor"")]"
87706,C++ Adagrad optimizer doesn't initialize parameter state,2022-10-25 15:04:06+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
87701,pytorch/pytorch cpu official Docker images,2022-10-25 14:59:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: docker"")]"
87697,Get https://github.com/pytorch/benchmark working,2022-10-25 14:50:10+00:00,,0,1,"[Label(name=""module: windows""), Label(name=""triaged"")]"
87696,Enable PostLocalSGDOptimizer on CUDA tensors,2022-10-25 14:47:57+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""triaged"")]"
87694,Investigate possibilities of automation for build pipeline,2022-10-25 14:42:44+00:00,,1,2,"[Label(name=""module: windows""), Label(name=""triaged"")]"
87692,"Performance issue on Windows with a ""benchmark"" comparing to Linux and WLS",2022-10-25 14:34:38+00:00,,0,3,"[Label(name=""module: windows""), Label(name=""triaged"")]"
87673,INTERNAL ASSERT FAILED !(has_different_input_dtypes && !config.promote_inputs_to_common_dtype_ && (has_undefined_outputs || config.enforce_safe_casting_to_output_ || config.cast_common_dtype_to_outputs_)),2022-10-25 04:55:13+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: TensorIterator"")]"
87642,`libtorch_cpu.so` is exposing some LLVM symbols,2022-10-24 21:43:57+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
87634,Add tests for ProcessGroup cpp extensions,2022-10-24 20:39:19+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
93579,torchdynamo.export doesn't work with data-dependent control flow,2022-10-24 18:44:25+00:00,,1,2,"[Label(name=""triaged""), Label(name=""enhancement"")]"
87597,ninja: build stopped: subcommand failed,2022-10-24 14:14:28+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
87589,"#error ""Expected GLOO_USE_CUDA to be defined""",2022-10-24 06:37:08+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
87579,Crash on backwards step when using `batch_first=True` for LSTMs on MPS (1.14 nightly build),2022-10-23 18:20:40+00:00,,0,0,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: mps"")]"
87576,Dynamic shapes exhaustive tests should fail (not xfail) if data mismatch,2022-10-23 13:58:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
87575,Functionalization does something wrong with pad backward when it uses as_strided,2022-10-23 13:56:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functionalization"")]"
87574,"DCE produced obviously wrong graph for pad, but test did not catch it",2022-10-23 13:53:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
87571,Testing insufficient to catch incorrect dispatch key for bernoulli.p re functionalization,2022-10-23 04:21:14+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: functionalization"")]"
87559,diagonal of Jacobian matrix,2022-10-22 21:16:29+00:00,,0,10,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement"")]"
87556,The behavior of cast `NaN` is different on cpu and cuda,2022-10-22 19:59:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: edge cases"")]"
87555,Improve `c10d::ReduceOp` & `torch.distributed.distributed_c10d.ReduceOp`,2022-10-22 19:11:45+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
87551,`bmm` will return wrong result on cpu with in-place,2022-10-22 15:31:54+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
87550,[onnx] export repeat_interleave TypeError: z_(): incompatible function arguments,2022-10-22 15:11:41+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
87542,DISABLED test_numpy_ref_mps_nn_functional_conv_transpose1d_mps_float32 (__main__.TestCommonMPS),2022-10-22 04:20:11+00:00,,0,1,"[Label(name=""triaged""), Label(name=""skipped"")]"
87539,RAM leak when copying tensor from cpu to cuda,2022-10-22 02:17:55+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
87514,invalid_arguments.cpp is busted,2022-10-21 22:05:26+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: python frontend"")]"
87504,Loading model trained on MPS cannot be opened on non MPS system,2022-10-21 21:09:01+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
87501,Synchronize domain builds to be executed after core build have completed,2022-10-21 20:04:39+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
87499,"built from source windows static library with multiple ""unresolved external symbol""",2022-10-21 19:34:49+00:00,,1,0,"[Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged"")]"
87497,Gloo errors when process's batch only indexes padding_idx of sparse embedding,2022-10-21 19:11:30+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
87494,Missing docstring for resize_as,2022-10-21 19:03:18+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
87491,TorchDynamo fails to trace the graph when custom op is being used,2022-10-21 18:28:47+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: dynamo""), Label(name=""module: pt2-dispatcher"")]"
87487,[JIT] Inconsistent handling of tracing dict output leads to assertion ,2022-10-21 18:01:00+00:00,,0,0,"[Label(name=""oncall: jit"")]"
87468,Categorical fails simplex validation after its own normalisation on CUDA,2022-10-21 16:07:23+00:00,,0,4,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
87458,Placeholder tensor is empty,2022-10-21 14:18:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
87451,Some operations do not keep `channels_last` memory format which yields accuracy drop,2022-10-21 13:09:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
87449,pytorch could not build from source with cudnn 8.0.5,2022-10-21 11:16:33+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
87448,Semantics of sparse operations clarification - Sparsity of the gradient with respect to a sparse tensor input,2022-10-21 08:32:40+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: masked operators"")]"
87446,ipykernel crash importing torch after scipy in .ipynb file,2022-10-21 06:42:56+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
87433,index_select() applied in sparse tensor can't backprop,2022-10-21 01:14:51+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
87402,`lower_cholesky` constraint incorrectly fails on MPS,2022-10-20 20:48:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mps"")]"
87390,`chunk` a 0-dim tensor will crash in JIT script w/o profiling executor,2022-10-20 19:08:02+00:00,,0,0,"[Label(name=""oncall: jit"")]"
87389,Installing PyTorch with BUILD_SPLIT_CUDA=ON and CUDNN fails on linker error,2022-10-20 19:07:29+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""actionable"")]"
87388,Document dist.new_subgroups,2022-10-20 19:05:42+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged"")]"
87371,Better type annotations for `torch.Tensor` subclasses,2022-10-20 16:05:50+00:00,,0,3,"[Label(name=""module: typing""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""tensor subclass"")]"
87366,"Implementation of CG, and BICGSTAB methods",2022-10-20 14:54:38+00:00,,1,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
87364,test_ao_sparsity fails when build without FBGEMM,2022-10-20 14:38:47+00:00,,0,1,"[Label(name=""triaged"")]"
87358,Triangular solver for sparse matrices,2022-10-20 12:14:08+00:00,,0,20,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
87353,Speed of torch.istft,2022-10-20 08:50:16+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: fft"")]"
87352,RuntimeError: Tensors of type TensorImpl do not have numel,2022-10-20 08:37:05+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: docker"")]"
87351,buffer is not large enough when running pytorch on M1 mps,2022-10-20 05:47:41+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: mps"")]"
87350,OpenCL 3.0 support: support every GPU on earth through rusticl,2022-10-20 05:46:12+00:00,,0,9,"[Label(name=""feature""), Label(name=""triaged"")]"
93556,Tracker for manually running pytorch/examples ,2022-10-20 03:12:14+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93553,Better error message when attempting to `torch.save` an optimized model,2022-10-20 02:30:44+00:00,,0,1,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
87289,'str' object has no attribute '__module__' in jit is_final,2022-10-19 15:06:59+00:00,,0,0,"[Label(name=""oncall: jit"")]"
87283,Missing string parsing for some parameter types in python arg parsing logic,2022-10-19 12:22:47+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: pybind"")]"
87276,torch.save throws ValueError: ctypes objects containing pointers cannot be pickled,2022-10-19 09:43:09+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
87268,register_package has no further documentation,2022-10-19 03:24:54+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""oncall: package/deploy"")]"
87267,The installation commands given on the pytorch website will not install properly,2022-10-19 03:12:10+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
87236,nvprims.div doesn't work with FakeTensor cpu scalars,2022-10-18 20:01:58+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: fakeTensor"")]"
87222,`custom_jvp` and `custom_vjp`,2022-10-18 17:48:46+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
87209,"Reproducible ""CUDA error: an illegal memory access was encountered""",2022-10-18 15:50:00+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged"")]"
87196,Missing `docker` directory in `tools/` ,2022-10-18 14:07:54+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: docker"")]"
87178,The autogenerated out variants via `autogen:` do not check that the dtype of the `out` kwarg via `canCast`.,2022-10-18 08:08:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
87172,Unstable results in sin/arcsin/arccos calls,2022-10-18 05:14:21+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
87170,torch.linalg.cond gives inconsistent results on CPU/CUDA,2022-10-18 04:51:53+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: linear algebra"")]"
87163,New APIs for cuda graph inspection and manipulation,2022-10-18 04:14:17+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
93543,DDPOptimizer+inductor OOMs with hf_GPT2_large and timm_vision_transformer_large,2022-10-18 03:26:24+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
87159,"torch/csrc/utils/python_arg_parser.h:424:94: error: format ‘%ld’ expects argument of type ‘long int’, but argument 7 has type ‘int’",2022-10-18 03:00:14+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: arm"")]"
87157,DISABLED test_expanded_reduction_cpu (__main__.CpuTests),2022-10-18 02:38:07+00:00,,1,2,"[Label(name=""triaged""), Label(name=""skipped""), Label(name=""module: inductor""), Label(name=""module: dynamo""), Label(name=""module: cpu inductor"")]"
87145,Unrecognized data format when using release libtorch libraries in debug build,2022-10-17 22:15:03+00:00,,0,1,"[Label(name=""oncall: jit"")]"
87131,torch.clamp does not clamp out of -0 from 0 when ran on the CPU,2022-10-17 21:04:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: edge cases"")]"
87129,[MPS] sum on a size=1 dim is ~5x slower than squeeze,2022-10-17 20:47:37+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: mps"")]"
87126,Bug in Histogram Observer Implementation,2022-10-17 20:29:29+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
87090,MPS memory usage significantly higher than on CPU,2022-10-17 16:49:15+00:00,,0,2,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: mps"")]"
87087,Failing periodic tests: test_dense_mask_index_cpu (__main__.CpuTests) & est_expanded_reduction_cpu (__main__.CpuTests),2022-10-17 16:43:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
87085,gradcheck failure with sparse matrix multiplication,2022-10-17 16:24:27+00:00,,1,1,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
87080,cppextension host compiler check ignores executable symbolic link in CUDA bin directory,2022-10-17 15:12:55+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
87076,Nandense layer for missing values,2022-10-17 12:50:26+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: masked operators"")]"
87070,DISABLED test_variant_consistency_jit_linalg_lu_cuda_complex64 (__main__.TestJitCUDA),2022-10-17 09:49:20+00:00,,0,9,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
87056,Pipe conveys inconsistent value in GPU env,2022-10-17 02:23:17+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
87041,"Segmentation fault: 11 when running ""import torch"" on Mac OS X",2022-10-16 19:57:31+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: macos"")]"
87033,Saving and loading from physical storage,2022-10-16 05:38:58+00:00,,0,2,"[Label(name=""module: memory usage""), Label(name=""module: serialization""), Label(name=""triaged"")]"
87031,Improve Readability of error(s) when provided unexpected keyword arguments.,2022-10-16 05:06:26+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: python frontend"")]"
87019,Rewrite `narrow_copy_dense_cpu_out` using `copy_` and `narrow`,2022-10-15 21:40:57+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: functionalization"")]"
87003,Multiprocessing DataLoader pickles multiprocessing.Queues incorrectly,2022-10-14 21:49:17+00:00,,0,4,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
86989,Error: unknown architecture `armv7-a;' and Error: selected processor does not support `command' in ARM mode,2022-10-14 20:15:51+00:00,,1,5,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: arm""), Label(name=""topic: build"")]"
86968,Drop deprecated behavior from NumPy-style `T`,2022-10-14 15:50:47+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation"")]"
86965,Upgrade to a newer llvm-openmp version to avoid `/dev/shm` pollution,2022-10-14 12:57:59+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: openmp"")]"
86962,PyTorch RPC crashed when using IB ,2022-10-14 08:17:38+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: rpc"")]"
86929,DISABLED test_vmapvjpvjp_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),2022-10-13 18:50:10+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: functorch"")]"
86919,Importing torch 1.12.0 breaks subprocess module,2022-10-13 17:47:26+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: macos"")]"
86918,torch.cat on empty tensor is bogus,2022-10-13 17:37:59+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
86910,[FSDP] Investigate `torch.cuda.current_stream()` usage in post-backward,2022-10-13 15:43:21+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
86890,View-based advanced indexing (Integer array/LongTensor indexing) of nested_tensor,2022-10-13 09:22:39+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
86888,Broadcasting add for nested_tensor,2022-10-13 08:16:41+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
86887,DISABLED test_variant_consistency_jit_linalg_lu_factor_ex_cuda_complex64 (__main__.TestJitCUDA),2022-10-13 06:57:52+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
86877,compile torch from source,2022-10-13 03:45:27+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
93531,TorchInductor CPU Performance Dashboard,2022-10-13 02:29:48+00:00,,1,317,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
86849,`torch.distributed.all_reduce` allocates excess GPU memory when using NCCL backend,2022-10-12 23:28:55+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: nccl""), Label(name=""has workaround"")]"
86848,.view(dtype) on a quantized tensor throws SegmentationFault,2022-10-12 23:25:37+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
86830,Distributed collective ops fail in `inference_mode` for CPU-only,2022-10-12 21:09:53+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
86819,Could not run select_backward [vmap] [dlrm] [functorch],2022-10-12 19:21:40+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
86818,Forward hooks for ScriptModules,2022-10-12 19:03:12+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86816,JIT model returns different value on cpu with uniform-initialized input,2022-10-12 18:41:08+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86814,Expanding the parameters of `torch.svd_lowrank`,2022-10-12 18:08:01+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
86804,JIT model will have a different jacobian after the first computation,2022-10-12 17:26:21+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86798,TF32 conv_transpose2d with groups has bad precision compared to fp32,2022-10-12 15:29:52+00:00,,0,5,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: tf32"")]"
86791,We don't have an op for vulkan_prepack::conv2d_clamp_prepack but it isn't a special case.,2022-10-12 13:24:15+00:00,,0,4,"[Label(name=""module: convolution""), Label(name=""oncall: mobile""), Label(name=""module: vulkan"")]"
86782,Poisson sampling on GPU fails for high rates,2022-10-12 06:05:15+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: random"")]"
86770,DISABLED test_vmapjvpall_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),2022-10-12 04:13:58+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: functorch"")]"
86733,DISABLED test_vmapjvpvjp_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),2022-10-11 21:44:08+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: functorch"")]"
86732,DISABLED test_variant_consistency_jit_linalg_lu_factor_cuda_complex64 (__main__.TestJitCUDA),2022-10-11 21:43:55+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
86718,Autograd doc does not mention torch.autograd.set_grad_enabled,2022-10-11 19:42:42+00:00,,0,8,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
86717,NVFuser `FusionRootMappingMultipleBroadcast_CUDA` raises exception on sm_80+ ,2022-10-11 19:10:36+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: nvfuser"")]"
86714,NVFuser `FusionComputeAtMultiBCast_CUDA` and `FusionDetectSelfMappedDomains_CUDA` does not raise exception on sm_80+,2022-10-11 19:04:12+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: nvfuser"")]"
86711,DISABLED test_variant_consistency_jit_linalg_lu_cuda_float32 (__main__.TestJitCUDA),2022-10-11 18:48:20+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: unknown"")]"
86710,DISABLED test_attn_cuda (__main__.TestMin),2022-10-11 18:48:18+00:00,,0,29,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: functorch"")]"
86704,Performance tests mnist_hogwild-cpu_memory CPU memory increase by 30%,2022-10-11 17:30:16+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: regression"")]"
86694,Feature request: Deterministic test input generation,2022-10-11 15:25:49+00:00,,1,6,"[Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged"")]"
86684,[ONNX] AssertionError: A mismatch between the number of arguments (5) and their descriptors (4) was found at symbolic function 'scatter',2022-10-11 12:24:49+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: onnx""), Label(name=""triaged"")]"
86683,Documentation and typing hints for RProp,2022-10-11 11:25:18+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
86676,Pytorch built for Jetson errors if CUDA is not found,2022-10-11 07:02:09+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: arm"")]"
86667,Adding a linear layer leads to failure of `optimize_for_mobile`,2022-10-11 03:22:52+00:00,,0,1,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""module: mkldnn"")]"
86662,libtorch throws `required keyword attribute 'profiled_view_size' has the wrong type` on Linux,2022-10-11 02:32:23+00:00,,0,3,"[Label(name=""oncall: jit"")]"
86660,libtorch make failed ,2022-10-11 02:21:28+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
86644,"[NvFuser] INTERNAL ASSERT FAIL ""ScalarType should be static for Tensors in fusion for amp optimization""",2022-10-10 22:20:38+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: assert failure""), Label(name=""module: nvfuser"")]"
86641,RFC(from users): nn.Module behavior with in-place changes,2022-10-10 21:29:51+00:00,,0,2,"[Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: functorch"")]"
86627,[ONNX] CSE pass in export pollutes Scope information,2022-10-10 19:54:52+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""bug"")]"
86618,Move functorch tests from functorch/test/* to test/*; delete functorch CI configs,2022-10-10 17:15:56+00:00,,0,8,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: functorch"")]"
86616,JIT returns different values for a model on cuda and returns a strange error message on cpu,2022-10-10 16:38:30+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: correctness (silent)"")]"
86613,Decomposition table is ignored with use_functionalize=True in AOT Autograd,2022-10-10 15:55:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
86612,Nonoptimal trace of silu_backward with AOT Autograd,2022-10-10 15:50:15+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
86601,NVFuser batch norm with prims: internal assert failure from test suite,2022-10-10 15:05:21+00:00,,1,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
86598,`squeeze_` fails with JIT but succeeds without it,2022-10-10 14:57:24+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86597,JIT returns different values for `cos + frac` on cpu,2022-10-10 14:52:16+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: correctness (silent)"")]"
86596,`CTCLoss` returns a different value with JIT on cuda,2022-10-10 14:42:09+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: cuda""), Label(name=""module: correctness (silent)"")]"
86595,JIT model with `relu+div+sgn` will crash when computing the gradient,2022-10-10 14:38:23+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: crash""), Label(name=""module: functorch"")]"
86594,JIT model with mean will crash when computing the gradients on cuda,2022-10-10 14:35:21+00:00,,0,0,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""module: crash"")]"
86590,"Easy way to ""freeze"" BatchNorm running_mean/running_var",2022-10-10 13:38:30+00:00,,1,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
86572,Instructions for Selective Build for Mobile Linux Platform,2022-10-10 03:13:44+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
86563,[functorch] colab links on functorch 0.2.0 website should be linked to a permalinked version of the colabs,2022-10-09 23:09:56+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: functorch"")]"
86558,Data conversion ops ignore `memory_format=torch.contiguous_format` ,2022-10-09 19:20:05+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
86554,[NvFuser] would change the output for some inaccurate dtype,2022-10-09 14:30:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
86553,`topk` will return the wrong value and could read out-of-bound value after jit,2022-10-09 14:26:13+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86552,`max_unpool` and `max_pool` will trigger INTERNAL ASSERT FAIL in JIT,2022-10-09 14:07:16+00:00,,0,1,"[Label(name=""oncall: jit"")]"
86551,`MultiLabelMarginLoss` will return incorrect values in JIT after the first run on cuda,2022-10-09 14:03:45+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: nvfuser"")]"
86548,About autocast,2022-10-09 11:27:36+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
86547,Segmentation fault (core dumped) in RTX3090,2022-10-09 10:44:46+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
86544,Compile failed at allreduce without gloo,2022-10-09 05:49:42+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
86539,cuda.list_gpu_processes() uses the 'wrong' device order (PCI_BUS_ID),2022-10-09 02:54:55+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
93524,Test for multiple instances inference,2022-10-09 01:16:59+00:00,,2,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: cpu inductor"")]"
93523,[functorch] [vmap] [SymInt][fake tensor],2022-10-08 21:51:32+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
86537,Running JIT trace for many times leads to OOM,2022-10-08 17:15:37+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
86532,Conv2d will crash by using `jit.trace`,2022-10-08 14:41:03+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: crash"")]"
86529,[NvFuser] JIT model with `mul+atan+sgn` will access illegal memory on cuda when computing gradient,2022-10-08 14:16:44+00:00,,1,8,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
86525, [Distributed: RPC] Sending `nn.Parameter` as RPC argument automatically detaches from the computation graph,2022-10-08 06:25:31+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
93520,Tooling Issue Tracking,2022-10-08 02:35:25+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
86518,[ONNX] Memory leak,2022-10-08 02:07:23+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
93718,Inductor doesn't fuse outer dimension softmax into a single kernel.,2022-10-07 23:04:22+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor""), Label(name=""internal ramp-up task"")]"
86506,[ONNX] Create an input adapter for suppling torch module input to onnxruntime,2022-10-07 22:04:45+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""onnx-triaged""), Label(name=""onnx-needs-info"")]"
86494,Automatic broadcasting for batch addition for sparse tensors,2022-10-07 21:00:12+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""enhancement"")]"
86493,`mem_get_info` reserves memory and can not be destroyed / deallocated. ,2022-10-07 20:57:00+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
86481,onnx.export make size operations return Tensor instead of int,2022-10-07 19:28:02+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
86479,FSDP support to load DDP optim checkpoints,2022-10-07 19:18:22+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
86467,torch.tensor obj automatically moved to shared memory upon Process launch,2022-10-07 17:59:49+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
86465,Wrong results with torch.linalg.inv on batched matrices when using cuda,2022-10-07 17:13:07+00:00,,0,9,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: correctness (silent)""), Label(name=""module: magma"")]"
86456,`SyncBatchNorm` doesn't work with subclass of `torch.Tensor`,2022-10-07 10:50:28+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""tensor subclass"")]"
86455,(JIT) x:Optional[T] cannot not expect content type after `if x is None or x.shape[0]==1`,2022-10-07 09:54:13+00:00,,0,0,"[Label(name=""oncall: jit"")]"
93716,End-to-End AMP training with GradScaler,2022-10-07 06:07:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
86449,torch.cuda.empty_cache() is not working,2022-10-07 05:14:14+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
86446,Improve FX naming for getitem calls,2022-10-07 04:23:20+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
86444,Dedicated function for shallow_copy_and_detach,2022-10-07 04:14:22+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""tensor subclass"")]"
86443,Stack trace preservation should work on plain use of make_fx / AOTAutograd,2022-10-07 04:08:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
86433,DISABLED test_rmsprop (optim.test_optim.TestOptim),2022-10-07 00:59:13+00:00,,1,18,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
93715,[minifier] Accuracy minification,2022-10-06 23:46:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: minifier"")]"
86427,[functorch] [aot_autograd] ,2022-10-06 20:10:01+00:00,,0,15,"[Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""module: functionalization""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
86381,OpInfo Tests To Validate that All Operators Are Being Tested With Strided Tensors,2022-10-06 17:34:51+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged"")]"
86356,`conv_transpose` is not similar to `nn.grad.conv_input` when `output_padding` is passed with non-default values.,2022-10-06 07:39:53+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
86351,Jetson JIT: Memory Leak on inference after optimize_for_inference,2022-10-06 05:07:44+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86340,Add complex support for SparseAdam and LBFGS optimizers,2022-10-05 23:53:05+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""actionable"")]"
86339,Add `maximize` support to LBFGS optimizer,2022-10-05 23:51:12+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
86326,`torch.special.round` doesn't support the same dtypes as `torch.round`,2022-10-05 21:31:11+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: special"")]"
86315,Feature request: Tests for `int` should be tests for `numbers.Integral`,2022-10-05 20:22:33+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: python frontend"")]"
86298,AOT Autograd Device Partitioning,2022-10-05 18:56:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
86287,JIT `lgamma` will return `inf` only with dual input in forward mode,2022-10-05 17:52:06+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86279,`torch.multinomial` on MPS crashes with `Error: total bytes of NDArray > 2**32'`,2022-10-05 16:18:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: mps"")]"
86276,JIT miss the argument `as_tuple` for API `nonzero`,2022-10-05 15:44:58+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86274,TransformerEncoder/TransformerDecoder has same initial parameters for all layers,2022-10-05 15:14:54+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
86271,AUTOGRAD is not working on IOS,2022-10-05 14:33:16+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
86270,Autocast with BF16 on CPU slows down model more than 2X,2022-10-05 13:01:39+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: amp (automated mixed precision)"")]"
86265,TORCH_WARN is executed just once per set of parameters,2022-10-05 10:08:41+00:00,,0,7,"[Label(name=""module: logging""), Label(name=""triaged"")]"
86261,"ONNX export of any TorchScript submodule (scripted or traced) fails with ""Modules that are called during a trace must be registered as submodules of the thing being traced"" ",2022-10-05 06:37:25+00:00,,0,7,"[Label(name=""oncall: jit""), Label(name=""module: onnx"")]"
93709,Support guard on thread number,2022-10-05 05:59:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
86225,[Feature] Dispatching PyTorch Distributed Collectives,2022-10-04 19:48:57+00:00,,2,0,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: c10d"")]"
86204,How to perform unstructured interpolation ,2022-10-04 13:03:50+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: interpolation"")]"
86194,path in WORKSPACE,2022-10-04 08:07:09+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: bazel"")]"
86192,fmt/src/os.cc: error: unknown type name 'error_code'; did you mean 'std::error_code'?,2022-10-04 06:45:44+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
93707,Dynamo shouldn't name getitem variables getitem; instead it should derive the name from the variable that was getitem'ed,2022-10-04 03:17:36+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
86162,torch.nn.functional.one_hot only works for int64,2022-10-03 22:44:49+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
86152,MPSNDArray.mm:782: failed assertion; bufer is not large enough Mac M1 MPS,2022-10-03 20:20:59+00:00,,1,17,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: mps"")]"
86131,Debuggability++: Share instructions for building exotic CI configurations,2022-10-03 17:16:56+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
86128,[TorchDispatch] Scalar Only Inputs Gets Matched To Tensor Schema,2022-10-03 16:52:53+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
86124,torch.jit.trace throwing Invalid name for qualified name eror ,2022-10-03 16:09:23+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86120,TransformerEncoder src_key_padding_mask does not work in eval(),2022-10-03 15:46:50+00:00,,1,9,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
86116,JIT fails to trace binary cross entropy with a strange error msg,2022-10-03 15:18:48+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86112,`cdist` should succeed when `p` is integer in JIT,2022-10-03 13:19:04+00:00,,0,0,"[Label(name=""oncall: jit"")]"
86111,When will the torch.sparse module be usable?,2022-10-03 12:38:33+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
86110,JIT return a tensor with different datatype from the tensor w/o gradient and normal function,2022-10-03 12:28:47+00:00,,0,1,"[Label(name=""oncall: jit"")]"
86107,`F.affine_grid` crashes on MPS,2022-10-03 09:22:59+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: mps"")]"
86097,[Activation Checkpointing] Investigate pin_memory for CPU offload,2022-10-03 06:17:03+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: checkpoint""), Label(name=""triaged"")]"
86076,Figure out the future of Metal backend given the existence of MPS,2022-10-02 20:48:46+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: arm""), Label(name=""module: mps"")]"
86074,torch.remainder and torch.fmod produce wrong results,2022-10-02 20:21:47+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
86055,partial view/reshaping,2022-10-01 19:28:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: python frontend"")]"
86048,Significantly worse MPS performance between torch 1.13.0.dev20220922 and torch 1.13.0.dev20220930,2022-10-01 05:17:57+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: mps"")]"
86020,Functorch memory_efficient_fusion gives wrong output batch size,2022-09-30 23:00:34+00:00,,0,8,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: functorch"")]"
85960,Discrepancy in output shape for batch_norm inference mode between CUDA and CPU,2022-09-30 08:38:46+00:00,,0,7,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""actionable"")]"
85949,"[Distributed] Loading distributed checkpoint with FSDP fails with varying key errors (pos.embedding, shared.weight)",2022-09-30 03:00:50+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
85939,CUDA OOM issue when running tests in CI,2022-09-29 22:36:38+00:00,,0,16,"[Label(name=""high priority""), Label(name=""module: ci""), Label(name=""triaged"")]"
85932,Setup ssh sometimes fail,2022-09-29 21:51:29+00:00,,0,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
85909,Steam Deck Core Dump,2022-09-29 18:43:06+00:00,,1,0,"[Label(name=""high priority""), Label(name=""module: rocm""), Label(name=""triaged"")]"
85893,TorchScript does not recognize mix-in types with `Enum`,2022-09-29 14:14:37+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85889,High occupation on GPU 0 when converting Tensor to multi GPU,2022-09-29 10:29:24+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
85879,DISABLED test_aot_autograd_exhaustive_as_strided_scatter_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),2022-09-29 01:23:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: functorch"")]"
85877,JIT model could return 'NaN' gradient after the first execution,2022-09-29 01:15:09+00:00,,0,1,"[Label(name=""oncall: jit"")]"
85852,`torch.mm` produces wrong result on cpu when using in-place computation,2022-09-28 21:19:46+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
85851,Print a warning when user specifies a qconfig for some node and the qconfig is not supported by BackendConfig,2022-09-28 21:16:57+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
85841,Setting the cuda device when using start_processes in Jupyter on Ampere leads to CUDA reinitialization error,2022-09-28 19:30:20+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
85834,[primTorch] Need to update data-dependent check policy,2022-09-28 18:46:57+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
85831,[FSDP] `use_orig_params=True` Follow-Ups & Known Issues,2022-09-28 18:27:16+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
85815,string interning for dispatcher operator names,2022-09-28 15:35:30+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
85813,TorchScript error for `Enum` inside a module,2022-09-28 15:15:59+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85805,"`vector_norm` will trigger ""Tracing failed sanity checks"" for JIT when ord is boolean tensor",2022-09-28 14:08:38+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85804,JIT fails to trace `sparse.mm` with a strange error,2022-09-28 14:00:56+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85792,TorchScript causes range_check error after a few iterations of forward-backward passes,2022-09-28 06:48:25+00:00,,0,2,"[Label(name=""oncall: jit"")]"
85791,nn.CrossEntropyLoss overflow with FP16 and minibatch,2022-09-28 06:31:47+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
85775,Timed out receiving the shared seed from the distribtued store on Rank 2,2022-09-28 00:30:05+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
85773,Conda Pytorch (Pytorch channel) in WSL2 Ubuntu can't find libcudnn shared objects,2022-09-27 23:59:27+00:00,,0,11,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
93701,Replace same with TestCase assertEqual,2022-09-27 23:54:35+00:00,,0,2,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
93699,retro inductor OOM,2022-09-27 23:15:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
93698,imagen inductor errors,2022-09-27 22:43:34+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
93697,Inductor stable baselines assertion errors,2022-09-27 21:52:17+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
85757,[ONNX] Conversion failed when using dict as input to a scripted module,2022-09-27 21:23:48+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
93696,Minifier should not produce repro with backward call if it is not necessary to trigger error,2022-09-27 20:50:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
93695,Composer inductor errors,2022-09-27 20:46:15+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: distributed"")]"
93694,Minifier dumps checkpoints which don't actually reproduce the error,2022-09-27 20:43:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: minifier"")]"
85745,[Quant] Remove or clarify the meaning of Nones in QConfig/BackendConfig,2022-09-27 19:13:40+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
85706,RuntimeError: [enforce fail at CPUAllocator.cpp:68] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 4860032 bytes. Error code 12 (Cannot allocate memory),2022-09-27 14:20:40+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85698,AMP consumes 30x gpu memory with bmm,2022-09-27 11:20:25+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
85671,nn.Embedding weights are not synced across processes with DistributedDataParallel when other parameters are present,2022-09-26 21:59:52+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
85663,[ONNX] torch/onnx is using rank to differentiate between ScalarType and TensorType,2022-09-26 21:12:12+00:00,,0,9,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
85660,[functorch] CUDA Graph failure with AOTAutograd,2022-09-26 21:02:26+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: cuda graphs""), Label(name=""module: functorch"")]"
85656,"[functorch] conv.{1, 2, 3}d should raise errors",2022-09-26 20:35:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
85652,CUDA allocator feature requests,2022-09-26 20:08:03+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
85642,Could not run 'aten::native_batch_norm' with arguments from the 'SparseCUDA' backend.  using batch_norm,2022-09-26 17:24:46+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
85625,How to install pytorch with cuda 11.7 in anaconda envirment?,2022-09-26 13:15:02+00:00,,0,2,"[Label(name=""triaged"")]"
85621,Gloo DDP SocketTimeout error on Windows,2022-09-26 06:15:25+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
85618,Build from source failed with error of different gpu architecture (compiler shows sm_30-related error but I use sm_86 GPU),2022-09-26 01:46:09+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
85613,[MPS?] .to(memory_format=contiguous_format) behaves incorrectly; differently to .contiguous(),2022-09-25 18:19:01+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
85607,[Distributed: RPC] Failed to initialize RPC with >18 workers,2022-09-25 14:39:54+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
85606,Creating NumPy array with `dtype=object` of PyTorch tensors fails,2022-09-25 13:21:37+00:00,,0,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
85604,"Multiple GPUs get  ""errno: 98 - Address already in use""",2022-09-25 11:45:38+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
85590,Solve default argument induced include cycles by not using defaults / moving the defaults to inl,2022-09-24 03:24:29+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: internals""), Label(name=""triaged"")]"
85588,`linalg.norm` cannot compute the grad in forward mode after script,2022-09-24 02:27:47+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85585,`as_tensor` will return a different dtype with script,2022-09-24 01:37:47+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85573,`jit` could make some undifferentiable APIs differentiable,2022-09-23 21:42:26+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85570,`mvlgamma_` will fail when compiling with trace `jit`,2022-09-23 21:29:47+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85568,`detach_` behaves differently when computing the gradients in forward mode w/ `jit`,2022-09-23 20:50:24+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85558,torch.Tensor.transpose().contiguous() on dimension of size 1 gives  wrong stride ,2022-09-23 18:32:22+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
85544,NvFuser single mode changes the output,2022-09-23 14:35:50+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
85538,Iterative Global Pruning Cause GPU Memory Leak,2022-09-23 09:36:07+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: nn""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
85533,"[functorch] transforms like jacrev, jacfwd, grad, etc don't work with BatchNorm",2022-09-23 07:05:25+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
85520,Implement `rand_like` ref and implement nvfuser_impl for `uniform` prim,2022-09-23 00:02:58+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
85514,The reload `MultiLabelMarginLoss` will have different gradients on cuda,2022-09-22 22:09:09+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85513,"Measure impact of JIT decompositions, reconsider the design",2022-09-22 22:08:18+00:00,,0,3,"[Label(name=""oncall: jit"")]"
85505,The reload model has different (and strange) forward computation from original model with `LSTMCell`,2022-09-22 21:34:38+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85499,Execute smoke test for Better Transformer feature ,2022-09-22 20:19:44+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
85485,"`max_pool2d_with_indices(self, ...)` shouldn't need to save `self` for backward",2022-09-22 18:02:58+00:00,,0,12,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
85475,Issue with converting Comet model to ONNX. Split-node error.,2022-09-22 14:30:12+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
93684,Can we rewrite numpy operators to pytorch operators?,2022-09-22 12:06:59+00:00,,1,12,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: numpy"")]"
85450,Cannot index into a tensor using indices from another device - regression from 1.12,2022-09-22 00:13:18+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: advanced indexing"")]"
85439,`aminmax` will trigger INTERNAL ASSERT if input is empty on cuda,2022-09-21 21:21:54+00:00,,0,23,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: edge cases"")]"
85438,Prim Output Spec is Not Always Consistent With Eager,2022-09-21 21:20:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
85425,Feature Request: Deterministic Algorithm for MaxPool3d,2022-09-21 18:24:00+00:00,,0,6,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""module: pooling"")]"
85397,torch.nn.utils.prune.remove reorders the parameters of a module unexpectedly,2022-09-21 09:25:08+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: pruning"")]"
85392,please report a bug to PyTorch. Expected Object but got PyObject,2022-09-21 04:03:15+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: torchbind"")]"
85390,Please put back missing rocm builds of Torch Vision.,2022-09-21 03:02:34+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""module: rocm""), Label(name=""triaged"")]"
85387,very strange speed of torch.bmm with specific tensor shape,2022-09-21 02:25:55+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
85377,CI fails for test_compare_cpu_nn_functional_embedding_cuda_float32 which is not reproducible locally,2022-09-20 21:59:14+00:00,,0,8,"[Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: embedding"")]"
85375,Inconsistency between geometric distributions,2022-09-20 21:32:10+00:00,,0,3,"[Label(name=""module: distributions""), Label(name=""module: molly-guard""), Label(name=""triaged"")]"
85366,More windows for filtering and spectral analysis,2022-09-20 19:33:14+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: scipy compatibility"")]"
85351,Point community docs to master,2022-09-20 17:26:43+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: doc infra"")]"
85342,"JIT fuser issues with {ceil,floor,round,trunc}(int8)  ",2022-09-20 15:26:55+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
85335,functorch aten::scatter_add_  not implemented,2022-09-20 12:33:52+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
85329,Crash in `torch.package.PackageExporter`,2022-09-20 08:25:03+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""oncall: package/deploy""), Label(name=""imported""), Label(name=""module: edge cases"")]"
93680,AOT Autograd traces have instability in defining the same Graph,2022-09-20 05:23:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: aotdispatch""), Label(name=""module: pt2-dispatcher"")]"
85302,Remove `TypedStorage` and use only `UntypedStorage`,2022-09-19 21:00:55+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
85300,torchrun substitutes host names for IP addresses,2022-09-19 20:18:48+00:00,,0,10,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: elastic"")]"
85296,Have NVIDIA driver and other related dependencies as part of the Linux AMI,2022-09-19 19:19:34+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
85258,"nvFuser support for {ceil,floor,round,trunc}(int)",2022-09-19 14:34:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
85235,Add `persistent` option to `nn.Module.buffers`.,2022-09-18 22:43:24+00:00,,1,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
85234,c10d all_gather aborts with Signal 8 (SIGFPE) when tensor.numel() == 0,2022-09-18 21:13:44+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
85230,[MPS] load checkpoints gives zero weights when map_location is mps,2022-09-18 15:18:33+00:00,,0,4,"[Label(name=""triaged""), Label(name=""has workaround""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
85229,TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. ,2022-09-18 13:25:30+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
85227,topk returns different results with the same input in cuda and cpu,2022-09-18 11:59:41+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
85217,Segmentation fault in native_batch_norm,2022-09-17 17:26:23+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
85215,Floating point exception in gather gradient computation.,2022-09-17 17:26:10+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
85214,Segmentation fault in mkldnn_reorder_conv2d_weight and mkldnn_reorder_conv3d_weight,2022-09-17 17:26:03+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: edge cases"")]"
85211,OSError libstdc++.so.6 at import,2022-09-17 17:24:10+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged"")]"
85201,performance between manually created graph and CUDAGraph.replay,2022-09-17 09:42:41+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
85157,NestedTensor 2.0 issue tracking,2022-09-16 16:22:18+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
85149,Pytorch on iOS (iPhone X & XR) throwing can't allocate memory exception. Ref Logs:,2022-09-16 14:34:08+00:00,,0,1,"[Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
85147,torch::quantile performance?,2022-09-16 13:20:03+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged"")]"
85127,[ONNX] Using values from a different tensor to index a tensor returns a tensor with incorrect shape in exported ONNX model,2022-09-15 23:28:47+00:00,,1,16,"[Label(name=""oncall: jit""), Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""bug"")]"
85122,"PT Dispatcher confusing error message ""There were no tensor arguments to this function""",2022-09-15 22:29:24+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
85121,make_traced() doesn't respect setting the seed,2022-09-15 22:25:09+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: primTorch"")]"
93675,Need operator fallback stats,2022-09-15 22:04:18+00:00,,1,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
85116,[ONNX][bug] `nn.Transformer` contains unsupported tensor scalar type,2022-09-15 22:00:46+00:00,,0,11,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""bug"")]"
93674,Need easier way to tell which step of the optimized path fails (dynamo + inductor),2022-09-15 21:43:34+00:00,,2,4,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
85113,[ONNX] Produce error message for incorrect number of dummy inputs instead of Internal assert failure,2022-09-15 21:34:56+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
85105,Python dispatch for PyOps needs to respect tensor subclasses,2022-09-15 20:11:55+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: __torch_dispatch__"")]"
85098,install libtorch cxx11 ABI as default in PyTorch pip installation,2022-09-15 18:56:38+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
93672,[ddp] must set `static_graph=False` when running with dynamo,2022-09-15 18:51:38+00:00,,1,8,"[Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
85096,Update `use_deterministic_algorithms` documentation and tests to include `nn.functional` counterparts for all `nn` modules,2022-09-15 18:24:43+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: determinism"")]"
85093,Memoizing AOT Autograd Input Conversion Breaks Training with Tied Parameters,2022-09-15 16:41:18+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functorch"")]"
85088,reentrant torch.utils.checkpoint does not work with NamedTuple outputs,2022-09-15 15:46:42+00:00,,0,3,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: checkpoint"")]"
85082,"[NNC] loop vectorization fails, `Ramp` and `Broadcast` undefined",2022-09-15 10:35:56+00:00,,0,0,"[Label(name=""triaged""), Label(name=""NNC"")]"
85081,primTorch/nvfuser: have a way to check that refs are added to __all__,2022-09-15 10:29:33+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
85078,"libtorch create a tensor is very slow, who can tell me why",2022-09-15 08:51:58+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cpp""), Label(name=""triaged"")]"
85072,Segmentation fault in `torch.jit.wait`,2022-09-15 06:02:50+00:00,,0,0,"[Label(name=""oncall: jit"")]"
85058,Selectively sync internal Meta discussions / posts to dev-discuss.pytorch.org,2022-09-15 00:10:07+00:00,,0,2,"[Label(name=""triaged"")]"
85036,Add an opaque epilogue in AOTAutograd for aliasing/mutations,2022-09-14 19:54:28+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: functionalization""), Label(name=""module: functorch"")]"
85027,Custom autograd functions are not inlined when export mode is ONNX_ATEN_FALLBACK,2022-09-14 18:58:05+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
85025,[CheckpointWrapper] Revamp API design,2022-09-14 18:30:08+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
84994,Cuda tensor is zero when passed through multiprocessing queue,2022-09-14 10:11:11+00:00,,1,2,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
84990,Segmentation fault in `torch.futures.collect_all`,2022-09-14 07:55:01+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: error checking""), Label(name=""triaged"")]"
84972,Add unit tests for test decorators,2022-09-14 00:05:07+00:00,,1,1,"[Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged"")]"
84944,test_warp_softmax_64bit_indexing_cuda_float16 takes ~147GB of CPU memory and is very slow,2022-09-13 18:41:48+00:00,,0,8,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: testing"")]"
84937,DISABLED test_random_seed (__main__.TestDataLoaderUtils),2022-09-13 16:24:58+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""skipped"")]"
84936,CPU and MPS floating point math is different (in a significant way),2022-09-13 16:19:49+00:00,,1,18,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: mps"")]"
84934,RuntimeError: input_shape.size() > 0 || reshape.size() > 0INTERNAL ASSERT FAILED,2022-09-13 15:41:12+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
84932,Separate doc and binaries build,2022-09-13 14:59:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: doc infra"")]"
84925,`is_pinned()` support in PrimTorch and FakeTensor.,2022-09-13 08:12:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: primTorch""), Label(name=""module: fakeTensor"")]"
84922,Functorch functionalization causes increased memory usage,2022-09-13 05:58:52+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: functionalization""), Label(name=""module: functorch"")]"
84870,Re-Running PR Sanity Check after Adding `skip-pr-sanity-checks` Label Still Fails,2022-09-12 17:28:37+00:00,,0,4,"[Label(name=""module: ci""), Label(name=""triaged"")]"
84864,torch.utils.checkpoint (with use_reentrant=False) doesn't work with all PyTorch features that set TLS,2022-09-12 15:13:00+00:00,,0,1,"[Label(name=""module: checkpoint""), Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""tensor subclass"")]"
84863,View consistency for PrimTorch+nvFuser tests,2022-09-12 15:02:55+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
84860,Feature Request: deterministic adaptive_avg_pool2d_backward_cuda,2022-09-12 14:06:05+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
93667,14k github models on PyTorch 2.0 pass rates dashboard ,2022-09-12 06:12:13+00:00,,1,47,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
84847,ONNX exporter error,2022-09-12 01:03:38+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
84840,"TypeError: finfo(): argument 'type' (position 1) must be torch.dtype, not HFProxy",2022-09-11 17:34:13+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
84839,Profiler Hangs on Non-Blocking H2D Transfer in Non-Default Stream,2022-09-11 17:14:23+00:00,,0,0,"[Label(name=""oncall: profiler"")]"
84835,Batch multiplication for torch.sparse matrix multiplication,2022-09-11 08:19:02+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
84831,INTERNAL ASSERT FAILED for _jit_pass_vulkan_optimize_for_mobile (Google Colab),2022-09-11 01:49:56+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""oncall: mobile""), Label(name=""module: vulkan"")]"
84813,MPS: allow selecting specific MTLDevice by registryID via environment variable,2022-09-10 13:32:52+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: mps"")]"
84805,compiling failed from source,2022-09-10 03:15:07+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
84782,macOS Pyinstaller: libc++abi: terminating with uncaught exception of type c10::Error: Type c10::intrusive_ptr<ConvPackedParamsBase<2>> could not be converted to any of the known types,2022-09-09 20:50:33+00:00,,0,6,"[Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""module: third_party""), Label(name=""needs research""), Label(name=""module: m1"")]"
84751,Allow passing dict (as opposed to OrderedDict) to nn.Sequential,2022-09-09 13:03:16+00:00,,1,15,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
84721,PyTorch-DirectML RFC,2022-09-08 21:53:56+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
84717,Test aten decompositions match their alias information,2022-09-08 19:41:32+00:00,,0,4,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: primTorch"")]"
84716,[ONNX] Speed up unit tests,2022-09-08 19:09:11+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""better-engineering"")]"
84711,Add documentation about backward graph gc behavior,2022-09-08 17:07:36+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
84710,About the different ways to print models,2022-09-08 16:49:52+00:00,,0,0,"[Label(name=""module: printing""), Label(name=""triaged"")]"
84705,Set dtype if tensor converted to numpy,2022-09-08 15:36:54+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: numpy"")]"
84697,NotImplementedError: The operator aten::native_group_norm_backward,2022-09-08 14:28:08+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: mps"")]"
84692,Error when trying to export MONAI model to ONNX,2022-09-08 12:41:08+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
84691,test_public_bindings is not robust to various build options,2022-09-08 12:26:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""topic: build"")]"
84685,[TensorExpr] applying `rfactor` for a Mul Reducer with init value different than 1 results in wrong results,2022-09-08 06:04:46+00:00,,0,0,"[Label(name=""oncall: jit"")]"
84681,JIT will affect the gradient computation of forward mode,2022-09-08 02:02:30+00:00,,0,2,"[Label(name=""oncall: jit"")]"
84673,Autograd will take `init` module API into account when using `jit`,2022-09-07 23:38:05+00:00,,0,2,"[Label(name=""oncall: jit"")]"
84661,[ONNX] Track non-exportable pattern as diagnostics.,2022-09-07 20:49:31+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
84646,JIT script calculation/dtype inconsistent depending on operator expression,2022-09-07 16:20:45+00:00,,0,0,"[Label(name=""oncall: jit"")]"
84630,"torch.nn.functional.interpolate fails on some degenerate shapes, but passes on others",2022-09-07 12:47:37+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: interpolation"")]"
84628,INTERNAL ASSERT when the type of argument is not considered in JIT,2022-09-07 12:35:10+00:00,,0,2,"[Label(name=""oncall: jit"")]"
84625,Beta distribution behaves incorrectly for small parameters,2022-09-07 09:26:52+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
84620,torch.hub.load local model,2022-09-07 07:40:49+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: hub"")]"
84616,Autogenerated out functions are missing at::cpu:: and co bindings,2022-09-07 01:57:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen""), Label(name=""topic: build"")]"
84615,Serialize the warmed up torchscript module,2022-09-07 01:54:32+00:00,,0,1,"[Label(name=""oncall: jit"")]"
93661,"Capture scalar outputs / dynamically sized outputs by default, partition graphs for backends that can't handle it",2022-09-06 22:14:11+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""ezyang's list""), Label(name=""oncall: pt2""), Label(name=""module: dynamic shapes""), Label(name=""module: inductor"")]"
84597,Accept SymInts and SymFloats For Scalar Inputs,2022-09-06 20:49:57+00:00,,0,0,"[Label(name=""triaged"")]"
84593,Uneven and/or Dynamically sized collectives,2022-09-06 19:57:17+00:00,,0,7,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: c10d"")]"
84588,torch.jit.script IndentationError: unexpected indent,2022-09-06 18:57:04+00:00,,0,0,"[Label(name=""oncall: jit"")]"
84578,module: multiprocessing SimpleQueue put cannot bigger 716 in windows.And it is not has any info.The program is blocked and does not move.,2022-09-06 16:55:43+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
84573,Tensor slice copy across multiple devices fails silently,2022-09-06 15:44:31+00:00,,0,13,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
84565,Tensor Subclass that doesn't require grad may wrap a Tensor subclass that requires grad,2022-09-06 13:52:32+00:00,,0,1,"[Label(name=""triaged""), Label(name=""tensor subclass"")]"
84560,[optim] asgd : handling of complex params as real params (NaN vs inf),2022-09-06 07:27:26+00:00,,1,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
84550,Pytorch does not recognize GPU in WSL2,2022-09-05 19:44:48+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: wsl"")]"
84539,list of tensors can't be converted to a torch tensor while list of lists gets easily converted to a pytorch tensor,2022-09-05 12:19:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
84538,OpInfo tests should compare gpu to cpu implementations,2022-09-05 11:37:32+00:00,,1,4,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""topic: not user facing"")]"
84537,Minimal example for torch.optim.SparseAdam,2022-09-05 11:12:49+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""module: docs""), Label(name=""triaged"")]"
84530,`tensordot` not working for dtype int32 and lower when there is only 1 element in the given axis,2022-09-05 06:18:47+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""actionable""), Label(name=""bug"")]"
84529,"test_prims.py:test_nvfuser_no_args_cuda, memory leak",2022-09-05 06:12:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
84524,nn.Softmax should not allow default/implicit/unset dim constructor argument,2022-09-04 16:14:44+00:00,,1,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: deprecation"")]"
84523,"Issue with MPS ops lead to make_grid broken with mps device Tensors, whole grid is the 'first' image",2022-09-04 10:03:37+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mps"")]"
84520,MPS backend appears to be limited to 32 bits,2022-09-04 02:21:00+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: mps"")]"
84515,Torch.FX work with autograd.Function,2022-09-03 14:58:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""fx"")]"
84510,[NVFuser] RuntimeError: ref_id_it != replayed_concrete_ids_.vector().end() INTERNAL ASSERT FAILED,2022-09-03 03:51:53+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: assert failure""), Label(name=""module: nvfuser"")]"
84495,functionalize: Does not compose cleanly with torch.jit.script/torch.jit.trace,2022-09-02 18:24:55+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""module: functionalization"")]"
84489,"For PyTorch Nightly, failure when changing MPS device to CPU after PYTORCH_ENABLE_MPS_FALLBACK occurs.",2022-09-02 14:28:54+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: mps"")]"
84473,Install LibTorch by Conan or other C++ package manager,2022-09-02 10:47:49+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""topic: binaries"")]"
84468,[c10d] Support a public API to retrieve default process group,2022-09-02 08:07:02+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""pt_distributed_rampup"")]"
84445,Strange cuda illegal memory allocation error,2022-09-01 23:15:30+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
84422,Set up tests to run periodically and surface them on HUD,2022-09-01 16:02:17+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
84415,Deepcopy of FX graph fails with nested make_fx and constant tensors,2022-09-01 13:40:14+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""fx"")]"
84414,several questions about pytorch DDP,2022-09-01 13:15:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""module: ddp"")]"
84412,Odd type-casting behaviour in prims.div,2022-09-01 11:17:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: primTorch"")]"
84370,Installation prefix is not passed to CMake appropriately,2022-08-31 20:16:50+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
93656,explain() has confusing explanation of graph breaks,2022-08-31 19:09:44+00:00,,1,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
84353,torch.Size should convert all elements to ints,2022-08-31 14:54:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
84348,"RuntimeError: ""slow_conv2d_cpu"" not implemented for 'Half'",2022-08-31 13:11:19+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: half"")]"
84347,Lack of newly raised optimizers,2022-08-31 12:42:45+00:00,,0,4,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
84346,fix ATen tests that do not compile,2022-08-31 12:30:32+00:00,,0,0,"[Label(name=""triaged"")]"
84340,Floordiv is deprecated.,2022-08-31 11:40:37+00:00,,0,1,"[Label(name=""oncall: jit"")]"
84336,torch 1.12.1 cuda 10.2 runs slower than torch 1.8.2 cuda 10.2,2022-08-31 10:34:01+00:00,,0,13,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
84335,Should enable skipped tests for `to` OpInfo ,2022-08-31 09:38:23+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
84321,[Profiler] Snapshot CudaCachingAllocator on profile begin,2022-08-31 00:45:42+00:00,,0,3,"[Label(name=""module: bootcamp""), Label(name=""oncall: profiler"")]"
84318,[Profiler] Generic Tensor summary,2022-08-31 00:34:27+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""oncall: profiler"")]"
84316,Torch.fx tracing bug with dictionary.update calls on input,2022-08-30 23:56:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""fx"")]"
84311,DecompositionInterpreter creates invalid graph,2022-08-30 22:13:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
84309,Unable to run a single convolutional layer in different CUDA-contexts,2022-08-30 21:35:48+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
84304,op for aten::bitwise_and during torch.jit.trace,2022-08-30 20:39:16+00:00,,0,2,"[Label(name=""oncall: jit"")]"
84290,Fix convert path for fixed qparam ops (sigmoid and softmax),2022-08-30 18:14:56+00:00,,0,6,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
84265,torch.Tensor.to.dtype_layout overload is not available in Python,2022-08-30 13:03:40+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: codegen""), Label(name=""module: python frontend"")]"
84261,relu-gru mse is 0.022 much greater than 0.003 with half dtype.,2022-08-30 11:47:06+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: half"")]"
84259,would you like  upload to the cpp libtorch to  vcpkg  package repo?,2022-08-30 11:26:23+00:00,,0,5,"[Label(name=""module: cpp""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""topic: binaries"")]"
84257,Support dict inputs and outputs when exporting to ONNX,2022-08-30 09:45:08+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
84247,Ensure ops account for offsets and strides,2022-08-30 03:31:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""release notes: nested tensor"")]"
84234,Randomness should be consistent across devices with use_deterministic_algorithms,2022-08-29 23:24:43+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: determinism"")]"
84202,Gradient value calculation error in MultiLabelMarginLoss,2022-08-29 16:30:16+00:00,,0,1,"[Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
84194,Pytorch gets small bias on the result of different types of divisors while doing floating point division.,2022-08-29 15:23:15+00:00,,0,4,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged"")]"
84193,Attach execution time to each node in an fx trace,2022-08-29 15:15:35+00:00,,0,5,"[Label(name=""triaged""), Label(name=""fx""), Label(name=""hacktoberfest"")]"
84192,CUDA 11.6 linux-bionic-cuda11.6-py3-gcc7-slow-gradcheck failure,2022-08-29 13:17:14+00:00,,0,9,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
84189,"RuntimeError: outputs_[i]->uses().empty() INTERNAL ASSERT FAILED at /pytorch/torch/csrc/jit/ir.cpp:1027, please report a bug to PyTorch.  (eraseOutput at /pytorch/torch/csrc/jit/ir.cpp:1027)",2022-08-29 08:20:04+00:00,,0,3,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
84187,[jit] WithInsertPoint can't get back to the prev_ node if the prev_ node has been destroyed,2022-08-29 06:55:51+00:00,,0,0,"[Label(name=""oncall: jit"")]"
84181,Session of Google Colab crashes when `torch.utils::SummaryWriter` is called after importing `torchaudio`,2022-08-28 15:14:37+00:00,,1,4,"[Label(name=""high priority""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: tensorboard"")]"
84178,Support setting strides on quantized weights of Embedding,2022-08-28 09:36:52+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
84175,FSDP Forward order differs from that of first run,2022-08-27 23:34:52+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
84167,`linux-bionic-cuda10.2-py3.9-gcc7`  multigpu test are broken,2022-08-27 14:04:31+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: ci""), Label(name=""module: regression"")]"
84148,[Quant] Reference get_default_qconfig_mapping in docs/tutorials,2022-08-26 21:21:30+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
84140,Please include virtual/physical batch sizes in the tutorials,2022-08-26 20:23:20+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
84138,MPS convolution is sometimes returning NaNs for valid inputs.,2022-08-26 20:07:01+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: mps"")]"
84135,[jit] ignored method calling static method results in an error,2022-08-26 18:51:55+00:00,,0,0,"[Label(name=""oncall: jit"")]"
84071,Move self.subtest calls in FSDP test suite to run_subtests utility,2022-08-25 18:26:08+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
84064,Better error message for qlinear_prepack,2022-08-25 17:00:58+00:00,,0,0,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
84055,scripted fasterRCNN model cannot be loaded with libtorch c++ API,2022-08-25 13:15:21+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""module: cpp"")]"
84052, Index out of bounds Error with PerChannel Quantization ,2022-08-25 12:14:54+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
84051,model.load_state_dict won't work in Child process if a sufficiently large tensor was padded in the Parent (even if empty padded),2022-08-25 11:41:09+00:00,,1,7,"[Label(name=""high priority""), Label(name=""module: multiprocessing""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
84050,I cannot install pytorch by Bad CRC-32 for file 'torch/lib/libtorch_cpu.so',2022-08-25 11:16:00+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
84049,TorchScript unsupport tuple unpacking  as function inputs.,2022-08-25 10:45:55+00:00,,0,0,"[Label(name=""oncall: jit"")]"
84045,COREMLTOOLs/NNPACK Python Issue,2022-08-25 09:06:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nnpack"")]"
84044,"hipErrorNoBinaryForGpu, but reversed",2022-08-25 09:04:21+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
84039,[MPS] MPSNDArray error: product of dimension sizes > 2**31,2022-08-25 06:25:09+00:00,,1,31,"[Label(name=""triaged""), Label(name=""module: mps"")]"
93643,Large number of WONT CONVERTs on detectron2 model,2022-08-25 04:25:31+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
84014,"fill_ OpInfo code not used, also, doesn't test the case where the second argument is a Tensor",2022-08-24 20:39:11+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
84009,[Nested Tensor] Enable Nestedtensor to work with OpInfos,2022-08-24 19:27:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
84003,Linux cuda-11.x binary build  jobs intermittently take more than 4 hours,2022-08-24 18:09:19+00:00,,1,5,"[Label(name=""high priority""), Label(name=""oncall: releng""), Label(name=""module: ci""), Label(name=""triaged"")]"
83994,General NestedTensor op coverage tracking issue,2022-08-24 16:57:07+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
83986,PyTorch EC2 runners can not be used with standard actions,2022-08-24 14:53:54+00:00,,0,5,"[Label(name=""module: ci""), Label(name=""triaged"")]"
83980,Scatter min/max reduce operation that returns the corresponding indices,2022-08-24 14:08:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: scatter & gather ops"")]"
83979,Undefined reference in libtorch_cpu.so `...std::__cxx11::basic_string...`,2022-08-24 13:50:31+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
83977,pytorch 1.12.1 doesn't build with ffmpeg 5.0,2022-08-24 13:18:50+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
83968,"Python3 Depletes 2021 M1 Mac Memory Running Training Ops For Model's M, L and X",2022-08-24 08:02:50+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: macos"")]"
83956,[FSDP] Make sharded / unsharded check more robust,2022-08-24 01:31:25+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
83947,Are PyTorch Android nightly builds getting automatically published,2022-08-23 23:19:36+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: android"")]"
83941,empty_quantized should probably be new_empty_quantized,2022-08-23 21:42:14+00:00,,0,0,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
83948,Add torch nightly builds pipeline for aarch64 linux,2022-08-23 19:31:08+00:00,,0,5,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: arm"")]"
83932,Hitting rate limits for pytorchbot token ,2022-08-23 18:35:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: infra"")]"
83931,primTorch: support refs and decompositions when ATen and Python disagree,2022-08-23 18:32:57+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
83929, ModuleNotFoundError: No module named 'torch.ao.quantization.experimental',2022-08-23 18:27:58+00:00,,0,5,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
83923,Support primtorch view ops in functionalization,2022-08-23 18:13:16+00:00,,1,9,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping""), Label(name=""module: functionalization""), Label(name=""module: primTorch"")]"
83914,"RAM not free when deleting a model in CPU? worse after inference, is there some cache hidden?",2022-08-23 15:31:14+00:00,,0,1,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
83910,Tracking nested tensor functions with backward kernels registered in derivatives.yaml,2022-08-23 15:24:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
83909,Grad strides do not match bucket view strides,2022-08-23 15:10:30+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: ddp"")]"
83902,"Bug in batch names with matmul (result tensor has names=('i', 'i', 'k')).",2022-08-23 08:11:16+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
83901,pytorch 1.12.1 Adam Optimizer Malfunction!!!,2022-08-23 08:09:36+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
83884,Improve FSDP error msg on wrong attr access,2022-08-23 02:44:09+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""pt_distributed_rampup""), Label(name=""module: fsdp"")]"
83863,bfloat16 matmul gives incorrect result on CPU (without mkldnn),2022-08-22 18:41:27+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: linear algebra"")]"
83854,Pytorch/Nova CI should monitor service outages for major dependencies,2022-08-22 16:40:03+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""needs design"")]"
83851,torch fx cannot trace assert for some cases,2022-08-22 16:09:04+00:00,,0,2,"[Label(name=""triaged""), Label(name=""fx"")]"
83826,test_lazy spuriously fails if LAPACK is not installed,2022-08-21 21:55:35+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: lazy"")]"
83824,RuntimeError: Interrupted system call when doing distributed training,2022-08-21 20:49:17+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
93639,Explore TorchInductor optimization pass to reorder kernel bodies,2022-08-21 17:26:17+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
83818,torch.linalg.eigh crashe for matrices of size 2895×2895 or larger on eigen and M1,2022-08-21 07:59:58+00:00,,0,8,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: m1"")]"
83817,[feature request] Add new device type works on CPU,2022-08-21 07:03:42+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement"")]"
83800,torch.var_mean is slower than layer norm,2022-08-20 12:50:12+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
83795,Error on installation,2022-08-20 08:47:08+00:00,,0,6,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
83775,[Nested Tensor] Move nested tensor specific ops to nested namespace,2022-08-19 21:50:44+00:00,,2,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
93638,Inductor Error: aten.fill_.Tensor,2022-08-19 21:44:22+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
83773,[Nested Tensor] view + inplace for autograd. ,2022-08-19 21:42:56+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
83769,[TorchTidy] Check if `set_to_none` would change optimizer semantics.,2022-08-19 20:37:36+00:00,,0,1,"[Label(name=""oncall: profiler"")]"
83764,Missing header file,2022-08-19 19:55:37+00:00,,0,4,"[Label(name=""triaged"")]"
93635,tabulate.tabulate causes a lot of memory to be allocated in yolov3,2022-08-19 18:38:06+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
83749,[Nested Tensor] Update TestCase.AssertEqual,2022-08-19 18:10:16+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""module: testing"")]"
83737,Profiler reports different # of Calls depending on group_by_stack_n,2022-08-19 15:36:53+00:00,,0,1,"[Label(name=""oncall: profiler"")]"
83733,BCELoss results in autocast CUDA warning,2022-08-19 11:40:39+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
83726,nvfuser + prim stack generated illegal PTX code on hardware with sm <= 70,2022-08-19 06:08:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
83721,How to export a simple model using List.__contains__ to ONNX,2022-08-19 03:05:43+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
83714,Build from source failed on MacOS 10.6 with CUDA 10.1 ,2022-08-19 00:36:15+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
83710,[Bug] Circular Import ,2022-08-18 23:55:39+00:00,,0,3,"[Label(name=""caffe2""), Label(name=""triaged"")]"
83702,Inconsistency between index_select and __get_item__,2022-08-18 21:46:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
83694,distributed tests take a long time,2022-08-18 18:40:27+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""module: ci"")]"
93633,botorch dynamo errors,2022-08-18 17:50:42+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
83672,quantization: unexpected casting of tensor min and max to int in histogram observer,2022-08-18 15:18:55+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
93631,[inductor] Lower aten.cumsum,2022-08-18 15:11:31+00:00,,1,14,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: inductor"")]"
83657,[Discussion] Add custom device,2022-08-18 08:03:10+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: backend"")]"
83655,[feature request] PyTorch vmap for efficient Evolutionary Strategies,2022-08-18 06:47:22+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""module: functorch"")]"
83624,Unhelpful error message from torch.linalg.ldl_factor,2022-08-17 20:54:21+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: edge cases"")]"
83606,"test_profiler_experimental_tree_cuda_detailed is too unstable, and as its CUDA only difficult to regen",2022-08-17 16:58:37+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
83589,Speedup for adding images to tensorboard,2022-08-17 13:12:45+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
83585,Segfault when profiling with_stack=True on model with jit.optimize_for_inference,2022-08-17 11:43:22+00:00,,0,0,"[Label(name=""oncall: jit"")]"
83584,Profiler can only print first 5 entries in stack traces because of hard-coded limit,2022-08-17 11:30:51+00:00,,0,0,"[Label(name=""oncall: profiler"")]"
83583,Silent promotion of bool to int in the dispatcher,2022-08-17 09:01:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: pybind""), Label(name=""module: library"")]"
83579,Conv1d: NNPACK SpatialConvolution_updateOutput failed when batchsize or padding is too large,2022-08-17 06:53:13+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: nnpack"")]"
83577,libtorch malloc cause coredump  ,2022-08-17 05:10:28+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: static linking"")]"
83564,KL-divergence of two Generalized Dirichlet distributions,2022-08-17 00:42:53+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
83551,OpenJDK libtorch_cpu.so stack guard warning,2022-08-16 22:12:57+00:00,,0,0,"[Label(name=""oncall: java"")]"
93627,PyTorch test suite regression test_module_backward_global_hook_writeable,2022-08-16 21:29:27+00:00,,1,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
83540,I have the same issue as @samgelman on my MacOS.,2022-08-16 20:40:17+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: openmp""), Label(name=""module: third_party"")]"
83537,Add a new argument `check_inf=True` (by default) or check_pos_inf / check_neg_inf to anomaly mode,2022-08-16 20:04:02+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement"")]"
83529,Adding Levenberg-marquardt optimizer in PyTorch,2022-08-16 18:29:30+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
83521,quantize_per_tensor/quantize_per_channel operators should honor the quant_min/quant_max from observer,2022-08-16 16:44:07+00:00,,0,0,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
83510,Cdist backward dependent on compute_mode,2022-08-16 12:11:59+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
83509, Build and Run QNNPACK on X86,2022-08-16 11:16:10+00:00,,0,8,"[Label(name=""module: build""), Label(name=""triaged"")]"
83507,"[Installation] conda installation hangs on ""Solving environment""",2022-08-16 10:16:41+00:00,,1,5,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
83494,`torch.pinverse` produces wrong output!,2022-08-16 01:57:34+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
83493,Calling torch.linalg.cholesky on a CPU tensor requires compiling PyTorch with LAPACK.,2022-08-16 01:39:12+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
83492,`Frozen` module for transfer learning.,2022-08-16 01:04:56+00:00,,1,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs design"")]"
83441,Find way to add comments to merge_rules json,2022-08-15 18:42:25+00:00,,1,4,"[Label(name=""module: ci""), Label(name=""triaged"")]"
83394,[ONNX] Convert GFPGANv1.3.pth to onnx,2022-08-15 00:22:12+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
83393,Test public bindings in CI gives weird output on error,2022-08-14 13:36:56+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
83392,"How to turn off determinism just for specific operations, e.g. upsampling through bilinear interpolation?",2022-08-14 12:15:32+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
83388,"zero-numel tensor has ""RuntimeError: strides[cur - 1] == sizes[cur] * strides[cur] INTERNAL ASSERT FAILED"" in multi-thread.",2022-08-14 05:29:09+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: nvfuser"")]"
83383,PyTorch profiler is spammy,2022-08-14 01:40:05+00:00,,0,5,"[Label(name=""oncall: profiler"")]"
83381,`test_profiler_experimental_tree_cuda_detailed` fails with mismatches in the profile output,2022-08-13 23:59:52+00:00,,0,2,"[Label(name=""oncall: profiler"")]"
83379,[caffee2] Windows build / 'metanet_pb2' (a circular import)  Anaconda,2022-08-13 19:53:32+00:00,,0,0,"[Label(name=""caffe2"")]"
83376,Complex-Valued Gaussian distributions,2022-08-13 14:32:40+00:00,,0,19,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: random"")]"
93624,"KeyError `shape,stack,cos` on pennylane quantum circuit",2022-08-13 00:06:56+00:00,,1,2,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
83351,DDP + FSDP: Investigate behavior for nn.Module APIs,2022-08-12 20:50:41+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: ddp""), Label(name=""module: fsdp"")]"
83349,checkpoint function is not jit compatible,2022-08-12 20:25:13+00:00,,0,0,"[Label(name=""oncall: jit"")]"
83320, Torch1.10.2 is slower than torch1.9.1,2022-08-12 07:55:24+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
83315,dataparallel function doesn't work,2022-08-12 04:01:17+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
83313,torch.Tag doesn't have accurate mypy info,2022-08-12 03:24:33+00:00,,0,3,"[Label(name=""module: typing""), Label(name=""triaged"")]"
93620,Long test time for PyTorch test_fx::TestVisionTracing with dynamo enabled,2022-08-11 22:35:24+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2"")]"
83292,TorchVision testing in CI + test_fx,2022-08-11 20:18:25+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""fx"")]"
83289,Improvements to ProcessGroupGloo monitored_barrier,2022-08-11 19:29:21+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
83281,addcdiv_ (in and out of place) not implemented for torch.float16 and cpu,2022-08-11 18:29:11+00:00,,0,2,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: half"")]"
83272,bmm operator in bfloat16 has low TFLOPS for some tensor shapes with CUDA 11.6,2022-08-11 17:38:12+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
83271,cannot import name 'ProcessGroup' from 'torch.distributed' ,2022-08-11 17:28:32+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: macos"")]"
83264,Emulating FP64 and increased precisions on Apple silicon,2022-08-11 15:31:00+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: mps"")]"
83257,PyYAML not listed as a dependency,2022-08-11 13:37:48+00:00,,0,1,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
83250,Using Pytorch and Mapbox in the same project,2022-08-11 10:25:23+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
83245,"During DDP training timm densenet121, mobilenetv2(v3) models do not save state_dict correctly.",2022-08-11 09:30:03+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
83244,torch.nn.Upsample's error message is inconsistent with the documentation,2022-08-11 09:25:02+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
83243,RPC: wait method of Future object return 0 sometimes in rpc framework,2022-08-11 09:23:13+00:00,,0,3,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
83241,torch.nn.TripletMarginLoss margin can be less than 0,2022-08-11 08:34:41+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
83238,The type of parameter 'p' in torch.nn.TripletMarginLoss wrong,2022-08-11 08:12:49+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
83234,torch.nn.ReplicationPad{1|2}d supports more input dimension than are written on documentation,2022-08-11 07:19:20+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
83232,torch.nn.PixelShuffle error message wrong,2022-08-11 06:13:25+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
83229,torch.nn.MaxUnpool2d get negative size tensor,2022-08-11 03:55:32+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
83221,torch.nn.InstanceNorm{1|2|3}d doesn't verify the value type of parameter num_features,2022-08-11 00:16:21+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
83214,torchgen.model.FunctionSchema.parse fails with following ops' schema ,2022-08-10 22:53:03+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
83204,Enable freezing parts of the model in Fully Sharded Data Parallel,2022-08-10 21:51:29+00:00,,1,13,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
83197,Check support of FSDP + set_materialize_grads(False),2022-08-10 20:00:40+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
83193,"module 'torch.distributed' has no attribute 'pipeline' - macOS, PyTorch 1.12.1",2022-08-10 19:25:16+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""pipeline parallelism""), Label(name=""release notes: distributed (pipeline)"")]"
83175,"torch.nn.GRU runs long time, when num_layers is large",2022-08-10 14:28:15+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
83169,torch.nn.functional.softplus / torch.nn.Softplus parameter beta can be set to zero,2022-08-10 13:06:35+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
83168,deepcopy of LazyLinear fails,2022-08-10 12:44:12+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
83163,torch.nn.functional.log_softmax  parameter '_stacklevel' undocumented,2022-08-10 09:07:35+00:00,,0,7,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
83161,Optimize for mobile metal model,2022-08-10 08:43:18+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
83159,Expand Learning rate scheduling to any optimization hyperparameter,2022-08-10 08:16:24+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: LrScheduler"")]"
83157,Fail to install torch for source,2022-08-10 08:08:34+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
83153,torch.nn.Hardtanh allows min_val > max_val,2022-08-10 06:44:04+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
83152,"When padding is big int, torch.nn.functional.fold runs too long and can't return result",2022-08-10 06:11:57+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
83151,Make FSDP easier to debug when erroring in backward pass,2022-08-10 06:02:33+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
83149,bf16 strided tensor wrong calculation,2022-08-10 05:44:04+00:00,,0,11,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: correctness (silent)""), Label(name=""module: reductions""), Label(name=""module: intel"")]"
83148,Cannot call CUDAGeneratorImpl::current_seed during CUDA graph capture,2022-08-10 05:22:28+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
83144,[MPS] Bug on training CNN+LSTM,2022-08-10 05:09:28+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: mps"")]"
83143,Bug in building pytorch deploy from source in macos USE_DEPLOY=1 ,2022-08-10 04:53:39+00:00,,0,0,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
83135,torch.nn.functional.avg_pool{1|2|3}d error message does not match what is described in the documentation,2022-08-10 01:11:59+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
83112,One dlpack to rule them all,2022-08-09 21:16:04+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: dlpack"")]"
83111,[FSDP] `test_summon_single_param()` is misleading,2022-08-09 21:15:30+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
83098,Redirect the old metrics.pytorch.org url to the new page,2022-08-09 19:17:16+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
83082,[CI] Create periodic fuzzy testing for PyTorch build flags,2022-08-09 16:22:59+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
83081,[CI] Split up periodic.yml into forward-fixable.yml and periodic.yml,2022-08-09 16:19:38+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
83074,DPP training incompatibility with checkpoint and detach,2022-08-09 15:15:27+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
83070,make_fx + aot_autograd segfaults,2022-08-09 13:54:01+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: fx""), Label(name=""fx""), Label(name=""module: functorch"")]"
83064,Updating the LTS version of the torch (1.8.2 -> 1.10.2\\1.11.2?),2022-08-09 11:05:54+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
83060,torch.empty_strided argument 'size'and 'stride' documentation wrong,2022-08-09 08:35:54+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
83052,FSDP init can crash with shared parameters,2022-08-09 03:24:31+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
83045,[JIT] Scripting modules fails for modules that contain nested NamedTuples,2022-08-09 01:10:03+00:00,,0,2,"[Label(name=""oncall: jit"")]"
83032,Support for CSR Tensor with NN layers,2022-08-08 22:18:23+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""module: nn""), Label(name=""triaged"")]"
83019,TestCommon.test_dtypes error message is confusing,2022-08-08 20:13:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: testing"")]"
83015,Incorrect tensor conversion to m1 MPS.,2022-08-08 19:58:59+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: mps"")]"
82960,torch.bitwise_xor argument 'other' documentation wrong,2022-08-08 08:10:13+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
82951,torch.profiler's FLOPs measure only counts operations involving '+' and '*' .,2022-08-08 04:02:48+00:00,,0,0,"[Label(name=""oncall: profiler"")]"
82926,"Slice operation on ""ragged"" dimension in NestedTensor",2022-08-06 04:56:02+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: nestedtensor"")]"
82919,Adding a warning of non-compatibility with forward hooks for the fast path of TransformerEncoderLayer,2022-08-05 23:01:59+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
82915,DISABLED test_tensorboard_trace_handler (__main__.TestProfiler),2022-08-05 21:40:33+00:00,,0,14,"[Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: profiler"")]"
82902,functorch slow tests not being run in slow CI,2022-08-05 19:10:24+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: functorch"")]"
82894,linalg and lu tests fail when run in parallel on linux cuda,2022-08-05 17:56:30+00:00,,0,14,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
82886,CUDA graph capturing fails for nn.Embedding and large batch sizes,2022-08-05 16:02:52+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: embedding""), Label(name=""module: cuda graphs"")]"
82879,`torch.tensor` and `torch.as_tensor` keyword argument `device` documentation wrong,2022-08-05 08:14:05+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
82872,Unknown builtin op: torchvision::deform_conv2d,2022-08-05 06:10:04+00:00,,0,3,"[Label(name=""oncall: jit"")]"
82871,GPU arch 8.6 is not covered by the `TORCH_CUDA_ARCH_LIST = All` option ,2022-08-05 05:28:59+00:00,,1,1,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
82843,Tensor operation hangs when used with multiprocessing,2022-08-04 20:32:09+00:00,,0,5,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""shadow review"")]"
82831,Error building Pytorch 13.1 from Source on OS X 12.5,2022-08-04 17:58:34+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: protobuf""), Label(name=""triaged"")]"
82823,getDLContext in DLConvertor.h cannot be found,2022-08-04 16:34:45+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: dlpack"")]"
82813,functionalize and make_fx are not composable resulting in segfault and cuda error,2022-08-04 12:06:12+00:00,,0,4,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: fx""), Label(name=""fx""), Label(name=""module: functorch"")]"
82802,"[ROCm] build instruction is haphazard missing information unclear, build does not work",2022-08-04 06:15:18+00:00,,1,5,"[Label(name=""module: docs""), Label(name=""module: rocm""), Label(name=""triaged"")]"
82793,Profiling results on CPU is not reliable,2022-08-04 03:04:34+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""triaged"")]"
82789,[LibTorch] the C++ api needs detailed error reports like pytorch ,2022-08-04 01:38:27+00:00,,0,0,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""enhancement"")]"
82785,UnaryUfuncInfo Sample Generation Ignores sample_kwarg function,2022-08-04 00:23:05+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: testing"")]"
82764,Subclass of Tensor doesn't support __format__,2022-08-03 22:39:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""tensor subclass"")]"
82762,Fill in a bool Tensor not supported in jit,2022-08-03 22:33:54+00:00,,0,0,"[Label(name=""oncall: jit"")]"
82761,torch.Tensor.bag() should automatically implement bagging,2022-08-03 22:33:18+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
82756,Met bugs ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -9) local_rank: 0,2022-08-03 21:11:34+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""oncall: r2p"")]"
82751,Refactor how errors decide whether to append C++ stacktrace,2022-08-03 20:28:56+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
82727,DecompositionInterpreter creates invalid graphs for FX graph modules created with torch.fx.symbolic_trace,2022-08-03 16:00:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""fx"")]"
93797,torchdynamo backend failure suppression is insufficient when backend fails at runtime,2022-08-03 15:31:20+00:00,,0,8,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
82725,"Automating release process - Binary validation, Automatically generating get started page",2022-08-03 15:00:23+00:00,,0,4,"[Label(name=""module: ci""), Label(name=""triaged"")]"
82724,cur_dim == dimINTERNAL ASSERT FAILED at,2022-08-03 13:50:25+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
82718,"tensor.unfold don't check the parameter size value, that maybe less than 0. ",2022-08-03 12:29:34+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
82712,Tensorboard py-profiler shows no device info in Operator view,2022-08-03 11:30:45+00:00,,0,1,"[Label(name=""oncall: profiler"")]"
82710,build fail when using lto with gcc,2022-08-03 10:30:02+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
82687,Move nested-tensor tutorial from prototype,2022-08-02 23:32:26+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
82684,SequentialLR does not work correctly with multiple ConstantLR,2022-08-02 22:43:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
82677,RReLU doc doesn't specify the eval mode behaving just like LeakyReLU,2022-08-02 21:44:16+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""topic: docs"")]"
82669,unittest.subTest and way to selectively mark subTests as expected failures,2022-08-02 20:34:16+00:00,,0,8,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: testing"")]"
82668,Schema information for torch.* operations,2022-08-02 20:27:29+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: __torch_function__""), Label(name=""module: testing"")]"
82660,in-place variants should get their own OpInfos,2022-08-02 18:35:30+00:00,,0,6,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: testing"")]"
82635,[Torchscript] torch.min returns wrong gradient when inputs are equal,2022-08-02 05:16:53+00:00,,0,0,"[Label(name=""oncall: jit"")]"
82634,[Torchscript] some activations backward are not fused when used with linear,2022-08-02 05:11:21+00:00,,0,0,"[Label(name=""oncall: jit"")]"
82627,PyTorch crashes when running with OpenACC,2022-08-01 23:35:50+00:00,,0,6,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: openmp""), Label(name=""module: third_party"")]"
82616,FakeTensor Support For Pickling,2022-08-01 22:35:43+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
82610,contiguous() not work for rank 1 length 1 tensor.,2022-08-01 21:34:03+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: dlpack"")]"
82598,Deep copy models with `create_feature_extractor` produces different parameters,2022-08-01 20:29:17+00:00,,0,6,"[Label(name=""triage review""), Label(name=""triaged""), Label(name=""module: vision""), Label(name=""oncall: fx"")]"
82583,DataLoader parameter pin_memory_device should accept torch.device type,2022-08-01 17:20:42+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
82577,RFC: Add flag for RNN decomposition to all RNN modules,2022-08-01 16:31:07+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: rnn""), Label(name=""triaged"")]"
82565,PyTorch for quantum mechanics,2022-08-01 12:40:41+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""function request""), Label(name=""module: scientific computing"")]"
82550,`torch.cat` can break `torch.jit.ScriptModule` when in inference mode,2022-07-31 16:35:31+00:00,,0,5,"[Label(name=""oncall: jit"")]"
82547,make_fx is broken for all tracing modes,2022-07-31 10:48:28+00:00,,0,6,"[Label(name=""high priority""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: fx""), Label(name=""fx"")]"
82546,Libtorch C++ torch::stack error,2022-07-31 09:09:05+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: cpp""), Label(name=""triaged"")]"
82545,Incorrect CPU implementation of CTCLoss backward step,2022-07-31 08:56:10+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""module: loss""), Label(name=""triaged"")]"
82542,Is there Doc that explains how to call an extension op in another extension implementation?,2022-07-31 06:20:02+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged"")]"
82534,Use NestedTensor in RNN models,2022-07-30 18:26:58+00:00,,0,7,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: nestedtensor"")]"
82532,[ONNX] Memory leak when exporting a jit model to onnx,2022-07-30 17:30:25+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""module: onnx"")]"
82518,Split up `common_methods_invocations.py`?,2022-07-30 01:28:23+00:00,,1,12,"[Label(name=""triaged""), Label(name=""needs research""), Label(name=""better-engineering""), Label(name=""module: testing"")]"
82517,Symbolic tensors are not printable,2022-07-30 01:18:34+00:00,,0,1,"[Label(name=""module: printing""), Label(name=""triaged""), Label(name=""module: dynamic shapes"")]"
82510,Complex addition result in NaN when it shouldn't,2022-07-29 23:43:46+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: NaNs and Infs"")]"
82494,Implement torch.clamp() on sparse tensors with SparseCPU backend,2022-07-29 20:04:40+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
82479,Cloning conjugate tensor in torch_dispatch context produces non equality.,2022-07-29 15:48:43+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: __torch_dispatch__"")]"
93793,Guide for diagnosing excess graph breaks,2022-07-29 15:19:28+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
82465,Does torch.utils.checkpoint compatible with torch.cuda.make_graphed_callables?,2022-07-29 10:59:19+00:00,,0,7,"[Label(name=""module: checkpoint""), Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
82464,SyncBatchNorm does not work on CPU,2022-07-29 10:48:16+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: nn"")]"
82451,add support for bitwise operations with floating point numbers,2022-07-29 03:35:58+00:00,,0,0,"[Label(name=""oncall: jit"")]"
82443,Quantization issue in transformers,2022-07-28 23:46:27+00:00,,2,18,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
82430,Minor inconsistency in description of `attn_output_weights` in MultiheadAttention docs,2022-07-28 20:59:42+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
82419,The torch::deploy document is not updated,2022-07-28 18:15:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: deploy"")]"
82417,[JIT] _unsafe_view returns alias when size(input) = size argument,2022-07-28 17:55:28+00:00,,0,0,"[Label(name=""oncall: jit"")]"
82397,Bilinear interpolation with antialiasing is slow in performance,2022-07-28 05:36:03+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged"")]"
82382,Problems in built-from-source pytorch with USE_DEPLOY=1 in Ubuntu,2022-07-28 00:07:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: deploy"")]"
82377,masked_scatter_ is very lacking,2022-07-27 23:19:37+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
82357,ufmt and flake8 lints race,2022-07-27 19:52:00+00:00,,0,3,"[Label(name=""triaged"")]"
82354,Offer a way to really force merges via pytorchbot,2022-07-27 19:31:28+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
82340,DISABLED test_op_has_batch_rule_nn_functional_conv_transpose3d_cuda_float32 (__main__.TestVmapOperatorsOpInfoCUDA),2022-07-27 18:42:52+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: vmap""), Label(name=""module: functorch"")]"
82324,[JIT] SchemaInfo warning appears out in the wild,2022-07-27 15:47:44+00:00,,0,0,"[Label(name=""oncall: jit"")]"
82318,test_make_fx_symbolic_exhaustive should pass dynamic ints for shape arguments,2022-07-27 14:57:15+00:00,,0,2,"[Label(name=""triaged""), Label(name=""fx""), Label(name=""module: dynamic shapes"")]"
82316,Add more Vulkan operations,2022-07-27 14:26:22+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: vulkan""), Label(name=""ciflow/periodic"")]"
82312,"A/libc: Fatal signal 6 (SIGABRT), code -1 (SI_QUEUE) in tid 9792 (Background), pid 9674 (ample.testtorch)",2022-07-27 13:21:52+00:00,,0,15,"[Label(name=""oncall: mobile"")]"
82308,torch.einsum gets wrong results randomly when training with multi-gpu,2022-07-27 12:52:17+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
82306,when distribute training  load pretrain model error,2022-07-27 11:50:22+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: serialization"")]"
82303,Race condition between torch.tensor's view and /= (/= returns incorrect result),2022-07-27 09:19:22+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: partial aliasing"")]"
82293,pytorch's checkpoint_wrapper does not save memory while fairscale's checkpoint_wrapper saves huge memory,2022-07-27 03:54:20+00:00,,1,4,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""module: checkpoint"")]"
82282,`torch.matrix_exp` doesn't handle NaN properly,2022-07-27 00:28:15+00:00,,1,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: linear algebra"")]"
82276,DEBUG=1 env var doesn't actually set DEBUG preprocessor macro,2022-07-27 00:02:19+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement"")]"
82259,[Reproducibility] Make tests say when unusual environment variables are set that change behavior of the test,2022-07-26 21:07:56+00:00,,1,4,"[Label(name=""module: ci""), Label(name=""triaged"")]"
82242,logspace inconsistently casts inputs to int before performing computation,2022-07-26 19:51:18+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensor creation"")]"
82239,primtorch refs should be composite compliant,2022-07-26 19:35:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""tensor subclass""), Label(name=""module: primTorch"")]"
82230,logspace and linspace off by one on cuda for integer dtypes for some inputs,2022-07-26 17:24:11+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensor creation"")]"
82229,[Profiler] Allow profiler to gracefully fail without interrupting workflow.,2022-07-26 17:16:21+00:00,,1,0,"[Label(name=""oncall: profiler"")]"
82228,[Profiler] Allow profiler to gracefully fail without interrupting workflow.,2022-07-26 17:16:08+00:00,,0,0,"[Label(name=""oncall: profiler"")]"
93791,Reordering test in PyTorch test suite induces dynamo failure,2022-07-26 14:56:54+00:00,,0,2,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
82219,[feature request] DataLoader to accept num_threads argument to auto-set number of threads for OpenMP / intra-op parallelism,2022-07-26 13:47:14+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: openmp"")]"
82218,OOM during backward() leads to memory leaks,2022-07-26 13:30:30+00:00,,0,12,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
82217,backward not available for index and mask ,2022-07-26 12:31:21+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
82216,iOS TestApp from mobile performance recipes tutorial doesn't build on macOS,2022-07-26 12:28:02+00:00,,0,0,"[Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
82212,"RuntimeError: ""reflection_pad2d"" not implemented for 'Half' in autocast enabled region",2022-07-26 09:16:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
82200,"model.to(device) takes time forever on A40-8Q, NVIDIA. cuda11.1, torch1.9.1.",2022-07-26 02:51:02+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
82197,Provide error handling for ops that don't yet support Dynamic Shape,2022-07-26 01:42:50+00:00,,1,3,"[Label(name=""triaged""), Label(name=""lazy"")]"
82185,DataLoader: `pin_memory` should respect object attributes before object collection type,2022-07-25 23:52:07+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
82159,`torch.sum` promotes integral tensors to `int64`.,2022-07-25 20:30:42+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""actionable""), Label(name=""module: reductions"")]"
82156,[Checkpoint] Support multiple unpack in saved tensor hooks,2022-07-25 20:01:54+00:00,,0,0,"[Label(name=""module: checkpoint""), Label(name=""triaged"")]"
82153,DistributedDataParallel hangs when not using GPU 0,2022-07-25 19:45:11+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
82145,set_grad_enabled not respected when running on a web server,2022-07-25 19:11:55+00:00,,0,4,"[Label(name=""module: dependency bug""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
82140,Stop manually binding sparse factory functions,2022-07-25 18:40:44+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
82139,Re-enable DynamicQuantModule in iOS simulator tests,2022-07-25 18:32:25+00:00,,1,2,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: ios"")]"
82132,External libraries cannot have a requirements.txt that needs to install a cpp_extension,2022-07-25 17:06:31+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
82109,Move functorch tests to under test/,2022-07-25 14:26:54+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
82099,UserWarning: operator() sees varying value in profiling,2022-07-25 11:01:00+00:00,,0,2,"[Label(name=""oncall: jit"")]"
82098,[feature request] Discover actually loaded shared libraries at runtime,2022-07-25 10:06:18+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement"")]"
82095,torch.concat type hints fail for keyword argument,2022-07-25 09:25:40+00:00,,0,1,"[Label(name=""module: typing""), Label(name=""triaged"")]"
82093,"When using libtorch v1.10.2, calling at::slow_conv_dilated3d directly returns wrong results on cpu backend",2022-07-25 09:12:07+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: convolution""), Label(name=""triaged"")]"
82091,"RuntimeError: [1] is setting up NCCL communicator and retreiving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: Timeout waiting for key: default_pg/0/0 after 1800000 ms ",2022-07-25 06:54:21+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""module: c10d"")]"
82088,linear.matrix_power is not composite compliant,2022-07-25 04:09:06+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
82084,Untangle TorchScript prim ops in aten namespace,2022-07-25 03:30:26+00:00,,0,0,"[Label(name=""oncall: jit"")]"
82081,Could be clearer that Cross Entropy takes logits as input,2022-07-25 01:43:20+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""actionable"")]"
82077,Using DDP with num_workers > 0 hangs before entering the first training epoch loop,2022-07-24 22:26:24+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader"")]"
82076,Autocast documentation examples would break,2022-07-24 20:34:25+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
82073,CUDACachingAllocator should be cuda memory merge/compact friendly,2022-07-24 11:44:20+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: CUDACachingAllocator"")]"
82072,cant build with USE_VULKAN=1,2022-07-24 06:36:18+00:00,,0,7,"[Label(name=""high priority""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""module: vulkan"")]"
82070,[FSDP] deepcopy FSDP model for EMA results in error,2022-07-24 01:28:04+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
82068,upsample_bilinear2d() received an invalid combination of arguments,2022-07-23 22:02:27+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: regression"")]"
82065,optimize_for_mobile vulkan_prepack::conv2d_clamp_prepack,2022-07-23 20:00:21+00:00,,0,1,"[Label(name=""oncall: mobile""), Label(name=""module: vulkan"")]"
82061,Documentation for torch.cuda.Event(blocking=True) is wrong,2022-07-23 18:12:28+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
82053,Inconsistent implementation of quant_utils:: ChooseQuantizationParams compared with fbgemm:: ChooseQuantizationParams,2022-07-23 08:30:02+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
82041,[Misleading] The doc started using Tensorflow terminology in the document to explain how to use the Pytorch code.,2022-07-23 01:43:39+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
82033,[PyTorch/XLA] Improve the XLA PR landing process,2022-07-23 00:19:19+00:00,,0,7,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: xla"")]"
81996,linspace cpu and sometimes cuda is wrong on integral types,2022-07-22 16:33:41+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: python frontend""), Label(name=""module: edge cases"")]"
81988,Unify c10::Event and at::cuda::CUDAEvent,2022-07-22 15:19:13+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""better-engineering"")]"
81985,"nn.InstanceNorm and nn.GroupNorm are affected by padding, so they need to masking",2022-07-22 14:49:27+00:00,,0,15,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""module: norms and normalization""), Label(name=""module: padding""), Label(name=""module: masked operators""), Label(name=""oncall: pt2"")]"
81983,backwards compatibility ALLOWLIST is misused,2022-07-22 14:29:55+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
81982,test_sparse_matmul_cpu_complex128 fails on my local copy,2022-07-22 14:16:20+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: complex"")]"
81979,test_sparse_spdiags_cpu_bool fails on my local working copy,2022-07-22 14:03:30+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
81963,Tensor.backward type hints clarification,2022-07-22 04:18:52+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""module: typing""), Label(name=""triaged""), Label(name=""actionable"")]"
81959,Overloading multiple signatures for a single ref,2022-07-22 00:42:07+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
81955,Investigate adding shell linter/checker to CI,2022-07-21 23:55:16+00:00,,1,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
81945,Investigate adding Dockerfile linter hadolint to CI,2022-07-21 23:06:39+00:00,,1,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
81943,Investigate if it's okay to throw a RuntimeError instead of TypeError here : https://github.com/pytorch/pytorch/pull/79560/files#diff-415017bcad4fa6cd6d3dfe5f6ea1caffcd7122b46b8c1e4825f7d889efc80a62R1816,2022-07-21 22:51:00+00:00,,0,0,"[Label(name=""triaged"")]"
81938,"Devirtualize sym_sizes, virtualize sym_sizes_custom",2022-07-21 22:40:18+00:00,,0,0,"[Label(name=""triaged"")]"
81937,Add more autograd tests with symints,2022-07-21 22:38:55+00:00,,0,0,"[Label(name=""triaged"")]"
81935,implement sym_numel,2022-07-21 22:37:52+00:00,,0,1,"[Label(name=""triaged"")]"
81932,Make sure we always redispatch through a dispatcher for all SymInt ops,2022-07-21 22:36:21+00:00,,0,0,"[Label(name=""triaged"")]"
81912,Unknown builtin op: aten::broadcast_shapes,2022-07-21 20:22:05+00:00,,0,3,"[Label(name=""oncall: jit"")]"
81899,Dependency header directory is not properly expanded in the utils.cpp_extention in ninja mode,2022-07-21 17:01:12+00:00,,0,4,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
81883,RuntimeError: CUDA error: no kernel image is available for execution on the device,2022-07-21 13:56:00+00:00,,0,19,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
81876,dtype mismatch when after using auto mixed precision,2022-07-21 13:05:41+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
81868,grid_sample and mode='bilinear' induces errors at discrete pixel locations,2022-07-21 11:21:16+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged"")]"
81856,Compatibility with newest MKL,2022-07-21 09:20:12+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkl"")]"
81855,Enable jit error when using FSDP,2022-07-21 07:59:02+00:00,,0,2,"[Label(name=""oncall: jit"")]"
81808,Workflows fail silently when the workflow file is invalid,2022-07-20 20:26:06+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
81801,"Rename DispatchKey Dense/Sparse/etc to DenseFunctionality/SparseFunctionality, use original name for alias",2022-07-20 19:30:33+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged"")]"
81768,TestTagsCPU.test_tags__refs_constant_pad_nd_cpu_float32 flaky with dynamo & pytest,2022-07-20 15:38:50+00:00,,0,6,"[Label(name=""module: ci""), Label(name=""triaged"")]"
81750,Modernize logging tensor in torch.testing._internal,2022-07-20 02:08:59+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""module: logging""), Label(name=""triaged"")]"
81749,BatchNorm for complex tensor,2022-07-20 01:33:02+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: primTorch"")]"
81732,DISABLED test_non_contiguous_tensors_nn_ConvTranspose1d_cuda_complex32 (__main__.TestModuleCUDA),2022-07-19 21:40:44+00:00,,1,13,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: complex""), Label(name=""skipped"")]"
93786,Support JaggedTensor/KeyedJaggedTensor from TorchRec in TorchDynamo,2022-07-19 20:35:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
81722,Inconsistent naming convention for end of enum in DispatchKey,2022-07-19 19:52:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
81717,PyTorch Embedding Op with max_norm is not working as expected,2022-07-19 19:02:22+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: norms and normalization""), Label(name=""module: embedding""), Label(name=""bug"")]"
81703,Dispatcher debug/logging mode,2022-07-19 15:42:32+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
81692,Failed to static link latest cuDNN while compiling,2022-07-19 12:06:31+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
81684,Message exchange failure when perform alltoallv (cpus) ,2022-07-19 06:31:51+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
81682,Python operator registration API for subclasses,2022-07-19 03:52:23+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: __torch_dispatch__"")]"
81681,FakeTensor consolidated strategy for in_kernel_invocation and dispatch keys,2022-07-19 03:28:45+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
81680,Provide an option to disable CUDA_GCC_VERSIONS,2022-07-19 03:18:13+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged"")]"
81678,Export quantized shufflenet_v2_x0_5 to ONNX,2022-07-19 02:53:33+00:00,,1,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
81669,Register refs for CompositeImplicitAutograd ops as decompositions,2022-07-18 23:19:43+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
81667,[Tracker] AO migration of quantization from `torch.nn` to `torch.ao.nn`,2022-07-18 22:34:31+00:00,,5,2,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
81654,[packaging] Conda install missing python local version label (+cu123 or +cpu),2022-07-18 20:46:39+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
81651,optimize_for_mobile has an issue with constant operations at the end of a loop,2022-07-18 18:50:32+00:00,,0,2,"[Label(name=""oncall: mobile"")]"
81650,RFC: auto-generated plain Tensor argument only sparse primitives,2022-07-18 18:50:12+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
81649,Idiom for PrimTorch refs for Tensor methods,2022-07-18 18:26:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
81648,`sparse_coo.to_dense()` produces different results between CPU and CUDA backends for boolean non-coalesced inputs.,2022-07-18 18:20:56+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
81635,Windows Debug binaries crash on forward: assert fail on IListRefIterator destructor,2022-07-18 15:00:49+00:00,,0,1,"[Label(name=""oncall: jit"")]"
81626,DISABLED test_profiler (test_jit.TestJit),2022-07-18 06:45:15+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
81625,[bug] the output shape from torch::mean and torch::var is different  in libtorch,2022-07-18 06:31:34+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
81622,[Distributed] test_dynamic_rpc_existing_rank_can_communicate_with_new_rank_cuda fails in caching allocator,2022-07-18 03:15:32+00:00,,1,1,"[Label(name=""oncall: distributed"")]"
81620,PyTorch 1.12 cu113 Illegal Memory Access or Internal Error instead of Out of Memory cases,2022-07-17 21:43:25+00:00,,0,6,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
81608,"FakeTensorMode cannot handle non-fake tensor, but non-fake tensors can arise from non-interposable Tensor construction calls",2022-07-17 03:51:25+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: pt2"")]"
81568,Improve interaction of PyTorch downstream libraries and torchdeploy,2022-07-15 19:18:13+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: deploy"")]"
81565,__getitem__ is returned as an OverloadPacket instead of an OpOverload in __torch_dispatch__,2022-07-15 18:53:36+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""bug"")]"
81559,[Profiler] Defer thread assignment for python startup events.,2022-07-15 17:55:51+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
81554,float' object is not callable when using scheduler.step() with MultiplicativeLR,2022-07-15 15:10:49+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
81552,Support Swift Package Manager (SPM) for iOS,2022-07-15 11:39:10+00:00,,0,3,"[Label(name=""oncall: mobile"")]"
81545,Precision error from torch.distributed.send() to recv(),2022-07-15 05:45:01+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
81544,Torch does not build with Lazy TS disabled,2022-07-15 05:41:26+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
81543,Linking pytorch libraries causes sstream behavior to be overridden globally,2022-07-15 04:53:09+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
81541,[vulkan]compiling VulkanOpContext.cpp with some errors,2022-07-15 03:40:00+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vulkan"")]"
81539,CapabilityBasedPartitioner treats non-compute ops inconsistently,2022-07-15 03:38:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: CapabilityBasedPartitioner""), Label(name=""module: fx.passes"")]"
81532,forward program terminated from __cxa_pure_virtual,2022-07-15 03:17:53+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: cpp""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""shadow review"")]"
81531,CapabilityBasedPartitioner doesn't support horizontal (vertical?) fusion,2022-07-15 03:03:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
81482,[onnx] Add support for prim::DictConstruct in pytorch-ONNX converter,2022-07-14 18:38:01+00:00,,1,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
81478,[onnx] support more combinations of args/kwargs as model inputs for pytorch-onnx converter,2022-07-14 18:10:42+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
81465,jit gives surprising results with lists of objects,2022-07-14 12:30:38+00:00,,0,0,"[Label(name=""oncall: jit"")]"
81460,[JIT] Request Constant Propagation to keep fake_quantize_per_tensor_affine and fake_quantize_per_channel_affine on the graph,2022-07-14 08:37:34+00:00,,0,1,"[Label(name=""oncall: jit"")]"
81459,Missing corner case handling in ATen ctc_loss implementation,2022-07-14 07:03:28+00:00,,0,0,"[Label(name=""module: loss""), Label(name=""module: error checking""), Label(name=""triaged"")]"
81448,torch.utils.checkpoint optimization opportunity,2022-07-14 01:19:50+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""has workaround"")]"
81446,torch.randint should accept high=2**63,2022-07-14 00:51:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: edge cases"")]"
81428,torch.stft does not normalize non-rectangular windows correctly,2022-07-13 21:04:48+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: fft"")]"
81426,[FSDP] `test_mp_embedding_reduce()` fails with `transformer_auto_wrap_policy()`,2022-07-13 20:41:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
81417,Add a check to detect mutation of the inputs during backward,2022-07-13 18:55:46+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: molly-guard""), Label(name=""triaged""), Label(name=""actionable"")]"
81413,torch.searchsorted error message and documentation is unclear,2022-07-13 17:48:05+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
81412,num_worker and prefetch_factor in DataLoader do not scale,2022-07-13 17:33:20+00:00,,0,11,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
81405,Implement shape/size functions for nestedtensor,2022-07-13 14:50:48+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
81385,"""Attempted to resize a view tensor to a larger size. This is not allowed in the functionalization pass"" reported on non view tensor",2022-07-13 03:49:34+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functionalization"")]"
81383,Investigate ncclRedOpCreatePreMulSum operator for gradient reduction,2022-07-13 03:16:20+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
81381,quantization: QConfigMapping should be easy to print,2022-07-13 00:54:57+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
81361,Segfault with fake tensor,2022-07-12 22:10:11+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fakeTensor"")]"
81358,[Prims+NvFuser] Issue with aten.where.ScalarSelf,2022-07-12 22:02:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
81337,JIT trace takes forever on a simple method,2022-07-12 17:47:06+00:00,,0,3,"[Label(name=""oncall: jit"")]"
81333,Reductions on tensors larger than GPU memory,2022-07-12 16:53:44+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""needs research"")]"
81323,`torch.overrides.get_testing_overrides` does not function as intended for native tensor methods/operations,2022-07-12 15:10:02+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
81317,Incorrect results for mean or sum kernels on aarch64 when building with gcc-7,2022-07-12 14:11:10+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: arm"")]"
81307,[Prims+NvFuser] Non-fusible ops Tracker,2022-07-12 03:44:09+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
81297,Files downloaded with torch.hub should respect umask,2022-07-12 00:16:12+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: hub"")]"
81287,Runtime error in Libtorch cpp project (Didn't find engine for operation quantized::conv2d_prepack NoQEngine),2022-07-11 22:56:17+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
81259,Refactor linter adapters to avoid code duplication,2022-07-11 18:07:08+00:00,,0,1,"[Label(name=""module: lint""), Label(name=""triaged""), Label(name=""enhancement"")]"
81257,High GPU context memory on Torch 1.11.0 but none on Torch 1.10.0,2022-07-11 17:53:17+00:00,,0,9,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
81255,[FSDP] Avoid explicit replace of activation checkpoint prefixes,2022-07-11 17:11:11+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
81245,"Libtorch cannot load TrochScript Module correctly, when a network contains conv2d(inchannels=64, outchannels=128, kernelsize=1) .",2022-07-11 15:44:07+00:00,,0,0,"[Label(name=""oncall: jit"")]"
81244,CapabilityBasedPartitioner does not work correctly with mutating operations,2022-07-11 15:40:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: CapabilityBasedPartitioner"")]"
81240,Functionalization and fake tensors failure in torture test,2022-07-11 14:58:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""module: functionalization"")]"
81229,torch.fx.node.map_aggregate and torch.utils._pytree.tree_map do the same thing,2022-07-11 12:55:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx""), Label(name=""module: pytree"")]"
81213,DISABLED test_trace_dependencies (test_analyze.TestAnalyze),2022-07-11 09:42:39+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: deploy""), Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
81195,torch._weight_norm with specified dim returns wrong output,2022-07-11 05:12:01+00:00,,1,13,"[Label(name=""module: nn""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: norms and normalization"")]"
81186,grad not preserved during copying or pickling,2022-07-10 18:28:35+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
81185,[Mac M1] `torch.mm` sometimes produces incorrect results,2022-07-10 18:21:12+00:00,,1,26,"[Label(name=""high priority""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: arm""), Label(name=""module: m1"")]"
81172,build libtorch with the same mkl as Matlab,2022-07-09 18:22:51+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: mkl"")]"
81167,move bazel files out of pytorch repo root,2022-07-09 07:04:47+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: bazel"")]"
81162,SparseAdam performance issue during optimizer step,2022-07-09 01:58:46+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: sparse""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
81140,libprotobuf version compatibility ,2022-07-08 21:11:16+00:00,,1,7,"[Label(name=""triaged""), Label(name=""module: build warnings"")]"
81127,Docker updates cause subsequent builds to fail,2022-07-08 18:34:06+00:00,,1,2,"[Label(name=""high priority""), Label(name=""module: ci""), Label(name=""triaged"")]"
81115,torch.package can not be used to serialize `resnet18` from TorchVision-0.12,2022-07-08 16:59:33+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: vision""), Label(name=""module: regression""), Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
81110,CI: Run cpu tests in parallel processes?,2022-07-08 15:28:46+00:00,,0,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
81104,Resize/reshape of sparse compressed tensors - design,2022-07-08 12:42:17+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
81102,[discussion] Consolidation of audio-visual I/O in a new package,2022-07-08 11:54:59+00:00,,0,28,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: third_party"")]"
81100,[jit] Failed to load a saved scripted function,2022-07-08 09:42:24+00:00,,0,0,"[Label(name=""oncall: jit"")]"
81085,RuntimeError: required keyword attribute 'value' is undefined,2022-07-08 06:19:32+00:00,,0,19,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit"")]"
81084,[ONNX] Exporting the operator `::svd` to ONNX opset version 13 is not supported.,2022-07-08 05:47:44+00:00,,0,7,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""OSS contribution wanted""), Label(name=""onnx-triaged"")]"
81065,[Releng] Improve the tutorials release process,2022-07-07 22:19:47+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged"")]"
81046,three typing inconsistencies on Tensor methods,2022-07-07 14:17:48+00:00,,0,4,"[Label(name=""module: typing""), Label(name=""triaged"")]"
80986,"[Prims+NVFuser] nvFuser running into ""Tensors of type SparseTensorImpl do not have strides""",2022-07-06 18:54:27+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
80985,Nested tensor: Support Noncontiguous Buffer,2022-07-06 18:52:53+00:00,,1,1,"[Label(name=""triaged""), Label(name=""topic: not user facing""), Label(name=""release notes: nested tensor"")]"
80973,[ONNX] Tool to find mismatch in exported ONNX model,2022-07-06 17:29:58+00:00,,1,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""onnx-needs-info"")]"
80966,[Prims+NVFuser] Aten2Aten decomp hurting performance,2022-07-06 16:21:29+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
80954,ExpandedWeights sometimes fail silently and doesn't compute .grad_sample attribute,2022-07-06 12:33:04+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
80951,ExpandedWeights can't handle modules with tied weights,2022-07-06 12:09:07+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
80946,torch.nn.functional.linear fails for multi-dimensional bias from torch 1.12,2022-07-06 10:00:28+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: regression"")]"
80942,[LTC] OOM on mnist example,2022-07-06 08:08:25+00:00,,1,19,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
80940,Wrong example of sliced computation in doc page Numerical Accuracy,2022-07-06 06:58:51+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
80939,[jit] script backward wrong gradient,2022-07-06 05:53:13+00:00,,0,0,"[Label(name=""oncall: jit"")]"
80932,Position embedding aware global circular convolution,2022-07-06 03:20:33+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
80929,"Interpolation artifacts when using nn.interpolate, trilinear mode for 3D label images",2022-07-06 01:50:39+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
80921,[primTorch] `|` operator does not work with FakeTensor in _refs,2022-07-05 23:46:20+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: meta tensors""), Label(name=""module: primTorch"")]"
80903,make_fx doesn't work with truly dynamic argument functions (e.g. fx.Interpreter),2022-07-05 19:16:23+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: fx"")]"
80875,slow test infra cannot handle nested suites,2022-07-05 14:59:32+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
80874,C++ extensions inject a bunch of compilation flags,2022-07-05 14:57:22+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""better-engineering"")]"
80867,[BE] Refactor FSDP Unit Tests,2022-07-05 14:30:01+00:00,,1,3,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
80863,SummaryWriter add_embedding issue with label_img,2022-07-05 13:28:03+00:00,,0,7,"[Label(name=""oncall: visualization"")]"
80861,"jit.freeze throws RuntimeError: stack_out && stack_out->size() == 1 INTERNAL ASSERT FAILED at ""../torch/csrc/jit/passes/frozen_conv_folding.cpp"":281",2022-07-05 09:41:49+00:00,,0,4,"[Label(name=""oncall: jit"")]"
80857,Compatibility List,2022-07-05 07:06:14+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: docs""), Label(name=""triaged"")]"
80851,[bug][nvfuser] Applying nvfuser to the model leads to runtime error,2022-07-04 22:00:51+00:00,,1,23,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
80832,[DDP] doesn't support multiple backwards when static_graph=True,2022-07-04 08:16:49+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
80829,Can torchscript dump backward graph?,2022-07-04 06:55:11+00:00,,0,1,"[Label(name=""oncall: jit"")]"
80827,Inconsistent computation of gradient in MaxUnPooling,2022-07-04 06:21:56+00:00,,0,19,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""actionable""), Label(name=""module: correctness (silent)"")]"
80826,Ne op does not behaves as expected with nan,2022-07-04 05:45:37+00:00,,0,3,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""triaged"")]"
80824,"When running GPT trainning with megatron,  the program quit due to torch.distributed.elastic.agent.server.api:Received 1 death signal, shutting down workers",2022-07-03 23:41:43+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: elastic"")]"
80821,Add typing support to ModuleList and ModuleDict,2022-07-03 21:55:12+00:00,,0,4,"[Label(name=""module: typing""), Label(name=""triaged"")]"
80808,"The result of doing a dot product between two vectors, using einsum, depends on another unrelated vector",2022-07-03 14:17:11+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
80804,`torch.renorm` gives wrong gradient for 0-valued input when `p` is even and `maxnorm=0`.,2022-07-03 05:03:05+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
80803,`hardshrink` gives wrong gradient for 0 input when `lambd` is 0.,2022-07-03 04:52:04+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
80776,`torch.inverse()` crash in cuda,2022-07-01 17:11:51+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: correctness (silent)"")]"
80774,RPC: Make RRefProxy callable,2022-07-01 15:32:24+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""enhancement""), Label(name=""module: rpc"")]"
80771,Anaconda is not a package manager,2022-07-01 14:29:07+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
80765,Let torch.utils.tensorboard support multiprocessing,2022-07-01 09:14:09+00:00,,0,2,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: tensorboard"")]"
80762,`atan2` will gradcheck fail when `other` is a tensor with `int8` dtype,2022-07-01 07:34:08+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
80761,`det` will return wrong gradient for `1x1` matrix with 0 value.,2022-07-01 07:22:01+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
80756,"[ONNX] RuntimeError: 0 INTERNAL ASSERT FAILED at ""/pytorch/torch/csrc/jit/ir/ir.cpp"":518",2022-07-01 03:55:33+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: onnx""), Label(name=""onnx-needs-info"")]"
92033,Unable to use vmap atop torch.distribution functionality,2022-06-30 22:07:18+00:00,,0,9,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: functorch"")]"
80742,Add TorchDynamo as a submodule to Pytorch?,2022-06-30 21:19:02+00:00,,0,22,"[Label(name=""module: build""), Label(name=""triaged"")]"
80738,Output for `aten::_native_multi_head_attention` appears inconsistent with entry in `native_functions.yaml`,2022-06-30 20:46:37+00:00,,1,2,"[Label(name=""oncall: transformer/mha"")]"
80606,[jit.script] jit.script give uncertain results using torch.half,2022-06-30 14:09:46+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: nvfuser"")]"
80605,pad_sequence and pack_sequence should support length zero tensors,2022-06-30 13:53:13+00:00,,0,0,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""enhancement"")]"
80595,Overlapping Optimizer.step() with DDP backward,2022-06-30 08:06:13+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: optimizer"")]"
80594,RuntimeError: DataLoader worker (pid 22822) is killed by signal: Aborted. ,2022-06-30 07:54:18+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
80588,Semi-reproducible random torch.baddbmm NaNs,2022-06-30 03:54:25+00:00,,0,9,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
80580,`torch.ops.aten.find` inconsistent with `str.find`,2022-06-30 01:05:05+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
80577,2-dimensional arange,2022-06-30 00:38:43+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: nestedtensor""), Label(name=""module: tensor creation"")]"
80574,`bmm_sparse_cuda` kernel for `bfloat16`,2022-06-29 22:55:02+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: bfloat16"")]"
80561,Cannot run scripted BERT_Pytorch,2022-06-29 20:16:46+00:00,,0,0,"[Label(name=""oncall: jit"")]"
80553,Nonliner conjugate gradient optimizer + Hager-Zhang line search,2022-06-29 18:31:49+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
80551,NVFuser should extend caching to remove necessity for PrimTorch's executor to Provide Tensor Contiguity Info,2022-06-29 17:58:52+00:00,,1,9,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
80549,Allow parameterization of Layouts,2022-06-29 17:43:25+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
80541,[Prims+NVFuser] Prims with missing NVFuser ops,2022-06-29 17:17:54+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
80496,DDP find_unused_parameters=True does not work for Sparse gradients,2022-06-29 03:37:12+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
80494,[bug] libtorch bug in nn::MultiheadAttention and nn::Transformer,2022-06-29 03:12:17+00:00,,0,7,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: correctness (silent)"")]"
80488,Negative values still produced by torch.nn.functional.kl_div,2022-06-29 01:16:35+00:00,,0,10,"[Label(name=""high priority""), Label(name=""module: nn""), Label(name=""triaged"")]"
80458,Revisit OpInfo samples for nn.functional.max_poolNd,2022-06-28 16:53:37+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: pooling""), Label(name=""module: testing"")]"
80439,scatter_reduce choosed indices,2022-06-28 09:34:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: scatter & gather ops"")]"
80431,CMake Error: File /opt/pytorch/build_variables.bzl does not exist.,2022-06-28 07:50:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: docker"")]"
80427,Torch fx print line number of each node,2022-06-28 06:39:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
93774,Guard Failures in T5 Model,2022-06-28 02:22:35+00:00,,1,21,"[Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
80420,[DDP] output_device argument appears completely unused,2022-06-28 01:23:06+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: ddp"")]"
80417,[c10d] Async object-based collectives,2022-06-28 01:09:09+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
80411,Tracker: Slow gradcheck failures possibly indicating incorrect gradients,2022-06-28 00:36:38+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
80380,Support for learnable p Values in LPPOOL like Pool,2022-06-27 20:01:05+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
80377,Modify _add_docstr to also set the correct module for the APIs,2022-06-27 19:25:09+00:00,,0,3,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable""), Label(name=""module: python frontend"")]"
80372,[BE] Update ProcessGroupWrapper tests to test other collective message,2022-06-27 18:51:07+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: c10d"")]"
80349,Distributed Store `get` doesn't work well with `add`,2022-06-27 16:05:16+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: c10d"")]"
80338,DISABLED test_lobpcg (__main__.TestAutograd),2022-06-27 12:38:31+00:00,,1,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""skipped"")]"
80337,Illegal Memory Access from nonzero method when Tensor is Too Large,2022-06-27 11:54:09+00:00,,0,3,"[Label(name=""module: dependency bug""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
80321, java.lang.ExceptionInInitializerError         at org.pytorch.NativePeer.initHybrid(Native Method),2022-06-27 07:41:46+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
93772,Add support for torch.nn.quantized.modules.FloatFunctional,2022-06-27 06:54:23+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2"")]"
80308,CosineAnnealingWarmRestarts with initial warm up and weight decay applied on consecutive cycles without warm up,2022-06-26 20:37:06+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
80302,AttributeError: 'LinearPackedParams' object has no attribute '_modules',2022-06-26 16:12:30+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""oncall: quantization""), Label(name=""module: nn""), Label(name=""triaged"")]"
80301,"Need ""valid"" and ""same"" padding mode for convTranspose2d",2022-06-26 14:22:01+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: padding"")]"
80296,Sort tensors inplace,2022-06-26 08:07:08+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
80259,Cudnn batch norm kernel (batchnorm_bwtr_nhwc_semiPersist) gets blocked by overlapping NCCL all_reduce calls,2022-06-25 00:19:56+00:00,,0,4,"[Label(name=""module: dependency bug""), Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""module: memory format"")]"
80256,[complex] dropout and it's variants should support complex tensors,2022-06-24 23:31:44+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: complex"")]"
80242,Write some torch.distributed.nn.* tests for the new dispatcher passable ops,2022-06-24 20:34:50+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
80241,Change c10d APIs in ProcessGroup to accept const std::vector<at::Tensor>&,2022-06-24 20:26:04+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
80238,test_conv_backend tests OOMing in 10.2 slow_gradcheck CI,2022-06-24 19:43:00+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""module: ci""), Label(name=""module: convolution""), Label(name=""triaged"")]"
80231,[Prims+NVFuser] Supports 0-sized inputs,2022-06-24 17:45:17+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
80230,[Prims+NVFuser] Aten2Prim refs tracking items,2022-06-24 17:36:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
80226,Support tensor subclasses as `UninitializedParameter`s,2022-06-24 15:33:37+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: lazy""), Label(name=""tensor subclass"")]"
80221,OpInfos for torch.ops.aten operations,2022-06-24 13:48:30+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged"")]"
80208,F.binary_cross_entropy_with_logits unexpected behaviour,2022-06-24 05:09:30+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
80206,`soft_margin_loss` gives wrong gradient when `target` with dtype uint8,2022-06-24 03:20:22+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
80204,`max_unpool` gives wrong gradient when `indices` has duplicate,2022-06-24 03:18:52+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling""), Label(name=""module: edge cases"")]"
80189,[NVFuser] Investigate models without any fusion groups found ,2022-06-23 23:04:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
80187,[NVFuser] Investigate modules with bad performance relative to eager,2022-06-23 22:55:20+00:00,,1,20,"[Label(name=""triaged""), Label(name=""module: nvfuser""), Label(name=""module: primTorch"")]"
80172,Torch.fx: add reporting of the name of a module not found during tracing,2022-06-23 20:41:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
93770,Catch value errors if cell in match_nested_cell is empty,2022-06-23 19:44:02+00:00,,1,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""bug""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
80168,GEGLU activation,2022-06-23 19:41:15+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research"")]"
80167,AMP step() enforce synchronization,2022-06-23 19:40:18+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
80161,[RFC] Module specific workflows,2022-06-23 18:56:21+00:00,,0,3,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
80157,Elliptic Functions and Integrals,2022-06-23 18:30:44+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: special"")]"
80154,[primTorch] No _refs support for torch.Tensor.requires_grad.__get__,2022-06-23 18:11:51+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
80152,Orthogonal Polynomials,2022-06-23 18:07:17+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: special"")]"
80151,activation checkpointing with non_reentrant implementation memory leaks,2022-06-23 17:37:18+00:00,,1,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
80142,CPUProfilingAllocator greedy allocation plan generation failed,2022-06-23 14:55:49+00:00,,0,2,"[Label(name=""oncall: mobile"")]"
80134,[feature request] Add support for a custom DatasetFetcher in DataLoader ,2022-06-23 12:08:54+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data"")]"
80132,Expose more MAGMA backends for solve_triangular,2022-06-23 11:52:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: magma"")]"
80118,"Allow a user provided ""test name - test time"" mapping file work with pytorch's test sharding mechanism",2022-06-23 02:35:53+00:00,,0,5,"[Label(name=""module: ci""), Label(name=""triaged"")]"
80104,Provide error message when thread pool is exhausted in RPC,2022-06-23 00:01:16+00:00,,0,1,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
80080,Complex support in DDP,2022-06-22 20:26:04+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
80067,"FakeTensor: Support torch.tensor([FakeTensor, 0])",2022-06-22 19:16:12+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: meta tensors"")]"
80061,pow CUDA tensor raised to CPU scalar tensor result can't backward properly,2022-06-22 18:43:33+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
80033,Support `antialias` option on `torch.interpolate` for ONNX export,2022-06-22 14:22:42+00:00,,1,11,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
80025,`torch.special.gammainc` backward pass with respect to the first argument,2022-06-22 12:54:41+00:00,,0,7,"[Label(name=""module: distributions""), Label(name=""module: autograd""), Label(name=""triaged"")]"
80022,memory leaking when doing all_to_all_single communication ,2022-06-22 09:24:49+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
80017,RPC init fails and crashes when world_size is greater than 18,2022-06-22 07:06:01+00:00,,1,15,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
80016,[ONNX] Input node deleted when converting a Conditional random field model,2022-06-22 06:35:56+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
80012,static builds are broken by MKL_DNN,2022-06-22 05:55:39+00:00,,1,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: third_party"")]"
80007,when forward use **kwargs，how to construct the example_ Inputs parameter in jit.trace?,2022-06-22 03:20:17+00:00,,0,2,"[Label(name=""oncall: jit"")]"
79997,Comprehensive documentation for Tensor indexing?,2022-06-22 01:20:01+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
79987,Deterministic `index_put` on CUDA fails when broadcasting is required,2022-06-21 22:33:09+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
79977,[CI] Do we run all cpp tests on CI?,2022-06-21 21:33:47+00:00,,1,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
79967,[feature request] LazyTensor that provides/loads/computes its contents only upon request to be returned from torch.load,2022-06-21 20:19:46+00:00,,0,11,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: lazy"")]"
79895,Modify update-viable-strict GHA to use internal version of checkout,2022-06-20 20:45:13+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
79893,Write lint for isGreen,2022-06-20 20:41:33+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
79888,`CosineAnnealingWarmRestarts` does not update parameters added with `add_param_group`,2022-06-20 19:08:37+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
79877,test_meta_vstack_cuda_int16 (__main__.TestMetaCUDA) Fails with DEBUG=1,2022-06-20 17:26:09+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs research"")]"
79875,"A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 11742 (objectdetection) ",2022-06-20 17:03:14+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""oncall: mobile"")]"
79867,All {view}_scatter variants should support all (or most) dtypes,2022-06-20 14:35:38+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: functionalization"")]"
79853,[bazel] [ci] `//:lazy_tests` Could not run 'aten::mul.Tensor' with arguments from the 'Lazy' backend,2022-06-19 22:31:36+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""lazy""), Label(name=""module: lazy""), Label(name=""module: bazel"")]"
79851,[bazel] [ci] `//:module_test` CUDA error: CUDA driver version is insufficient for CUDA runtime version,2022-06-19 22:21:38+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: bazel"")]"
79848,Automatically calculate output_shape of sequential model (or any other fCNN),2022-06-19 09:57:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: meta tensors"")]"
79847,Multi-node training meets unknown error,2022-06-19 06:57:06+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
79842,Automatically use CUDA,2022-06-18 21:44:09+00:00,,0,2,"[Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: python frontend"")]"
79802,[ONNX] Replace test inheritance for `test/onnx/test_models.py` with parameterizing ,2022-06-17 18:35:52+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
79788,Parameter.__deepcopy__ doesn't preserve view relationships,2022-06-17 16:24:06+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
79787,Improve clarity by making sharding a static nightly update,2022-06-17 14:46:33+00:00,,0,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
79785,android-tests is often flaky,2022-06-17 14:36:17+00:00,,1,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
79766,[FSDP] Test that module using mixed precision can be loaded into non-mp module,2022-06-17 01:38:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
79751,[JIT] failures with nested with blocks + loop continuation,2022-06-16 21:44:45+00:00,,0,0,"[Label(name=""oncall: jit"")]"
79739,quantization: misleading backend config for linear_dynamic_fp16,2022-06-16 19:32:08+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
79715,[FX] TypeError when tracing cat taking split's output as input,2022-06-16 15:37:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
79709,ONEDNN testing is not done properly in quantization codebase,2022-06-16 15:23:28+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
79705,gradgradcheck fails for torch.native_layer_norm,2022-06-16 14:25:56+00:00,,0,0,"[Label(name=""module: double backwards""), Label(name=""module: autograd""), Label(name=""triaged"")]"
79703,Float and double tensors randomly initialized with the same seed get different values for size >= 16,2022-06-16 14:01:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: random"")]"
79684,Does Torch JIT Support Trace High-level Custom Op?,2022-06-16 06:11:51+00:00,,0,0,"[Label(name=""oncall: jit"")]"
79647,tensorboard SummaryWriter.add_graph fails when model uses empty tuples,2022-06-15 22:10:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
79644,[FSDP] Progress of ParamExecOrderWrapPolicy,2022-06-15 21:48:44+00:00,,1,0,"[Label(name=""in progress""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
79629,Missing the time unit in duration time of DDP logging,2022-06-15 17:54:18+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: ddp"")]"
79620,[FSDP] Verify that FSDP-managed parameters are the same across ranks,2022-06-15 17:14:50+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
79606,PyTorch Preview (Nightly) version number does not comply with Conda conventions,2022-06-15 13:20:19+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
79604,Some unit tests are failing,2022-06-15 11:22:26+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: docker"")]"
79592,[LTC] Introduce a `MetricsReport` python binding and allow backend to add their report as string,2022-06-15 01:58:09+00:00,,0,6,"[Label(name=""triaged""), Label(name=""lazy"")]"
79563,__torch__dispatch does not return new output in inplace function,2022-06-14 21:13:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
79542,Unable to use a parameter with torch.sparse_coo layout with DDP,2022-06-14 17:39:46+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: ddp"")]"
79528,test_ops.py extremely slow on cuda11.3,2022-06-14 15:42:45+00:00,,0,3,"[Label(name=""triaged"")]"
79518,"Display a ""reference"" link for ops that points to primTorch implementations",2022-06-14 13:57:40+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: primTorch"")]"
79510,DISABLED test_checkpoint_wrapper_parity (__main__.CheckpointWrapperTest),2022-06-14 06:43:37+00:00,,1,10,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: fsdp"")]"
79477,Implement NestedTensor size function,2022-06-13 23:31:58+00:00,,2,2,"[Label(name=""module: nestedtensor""), Label(name=""oncall: transformer/mha"")]"
79476,[META] Sign up to discuss significantly modifying CI,2022-06-13 23:28:00+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
79469,Add a new _broadcast_coalesced op for DDP,2022-06-13 22:44:22+00:00,,1,0,"[Label(name=""triaged"")]"
79468,Ensure the guards in distributed_c10d.py wrappers get executed in the replay of the graph,2022-06-13 22:43:20+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
79467,Add autograd support for dispatch passable c10d ops,2022-06-13 22:41:53+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
79464,Iteration # 1-offset in DDP logging,2022-06-13 22:04:44+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
79459,[BE][ZeRO] Enable multigpu unit tests,2022-06-13 21:31:38+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering"")]"
79453,[LTC] Make `torch::lazy::BackendImplInterface::ExecuteComputation` takes `ComputationPtr` instead of `Computation`,2022-06-13 20:56:47+00:00,,0,1,"[Label(name=""triaged""), Label(name=""lazy"")]"
79452,Use c10d broadcast_object in Zero,2022-06-13 20:40:30+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup"")]"
79425,API for accessing SymIntNode mandates refcount bump even when it is unnecessary,2022-06-13 16:48:10+00:00,,0,0,"[Label(name=""triaged"")]"
79418,Add doc formatting check to lintrunner,2022-06-13 15:21:07+00:00,,0,1,"[Label(name=""module: lint""), Label(name=""triaged""), Label(name=""better-engineering"")]"
79407,Conda enviroment,2022-06-13 08:29:17+00:00,,0,1,"[Label(name=""triaged"")]"
79395,SymInt equality tests are unsound,2022-06-13 02:31:25+00:00,,0,0,"[Label(name=""triaged"")]"
79388,Init connect timeout when use torch.distributed.run,2022-06-13 01:17:48+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""oncall: r2p"")]"
79387,caffe2_nvrtc is produced even when it won't be used,2022-06-13 00:29:58+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: selective build"")]"
79383,Incorrect image upscaling on MPS backend,2022-06-12 18:58:13+00:00,,1,13,"[Label(name=""triaged""), Label(name=""module: mps"")]"
79382,torch failure to open libcuda.so.1 on macOS,2022-06-12 17:02:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: macos"")]"
79375,TorchScript bidirectional lnlstm from example doesn't work,2022-06-12 08:54:27+00:00,,0,1,"[Label(name=""oncall: jit"")]"
79359,[build] No documented way to install C++ binaries for pure-python development of pytorch,2022-06-12 02:02:08+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
79355,[bazel] build spams warnings,2022-06-11 22:24:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: bazel"")]"
79352,Adam not optimally implemented: unnecessary torch.div,2022-06-11 14:45:23+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
79351,[bazel] ability to run gpu tests on gpu machines in RBE,2022-06-11 14:44:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: bazel"")]"
79349,PyTorch get positive log_prob of a multivariate normal distribution ,2022-06-11 12:28:15+00:00,,0,1,"[Label(name=""triaged"")]"
79337,Conda install from pytorch-nightly channel does not install the expected version on macOS,2022-06-11 05:38:39+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: macos"")]"
79336,Batches are being duplicated from go http call,2022-06-11 03:53:44+00:00,,0,1,"[Label(name=""triaged"")]"
79333,[ONNX] Internal assert error during export,2022-06-11 03:37:37+00:00,,0,10,"[Label(name=""oncall: jit""), Label(name=""module: onnx""), Label(name=""onnx-triaged"")]"
79325,[NVFuser] hitting fallbacks on demucs (from torchbench + lazy tensor),2022-06-10 22:27:21+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
79307,`prepare_qat_fx` docstring doesn't run,2022-06-10 19:40:40+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""triaged""), Label(name=""module: fx"")]"
79299,PyTorch gets stuck when using an NVLink/A6000 and more than two GPUs,2022-06-10 19:20:03+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
93763,allowed_functions_module_string_ignorelist doesn't work very well,2022-06-10 18:01:35+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
79275,testSerializationInterop in test/cpp/jit/torch_python_test.cpp has not run in over two years,2022-06-10 13:50:09+00:00,,0,1,"[Label(name=""oncall: jit"")]"
79272,"PyTorch leaks a macro definition called ""CHECK"" in the C++ version",2022-06-10 11:25:18+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
79261,[NVFuser] bad performance on pyhpc_isoneutral_mixing,2022-06-10 02:37:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
79250,[BE] Generalize recursive wrapping utility,2022-06-09 23:54:45+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
79246,[NVFuser] bad performance on mobilenet_v2 and mobilenet_v3_large,2022-06-09 23:24:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
79244,[NVFuser] bad performance on pyhpc_equation_of_state,2022-06-09 22:54:18+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
79222,scripted fft Convolutions are faster than nn.Conv1d with large kernels,2022-06-09 18:33:19+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
79208,[ONNX] Enable more operators to support data propagation,2022-06-09 17:31:00+00:00,,1,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
79205,out-of-place functional optimizers: functional optimizers may not be composite compliant,2022-06-09 16:51:05+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: __torch_dispatch__""), Label(name=""tensor subclass"")]"
79202,[bug] Device dispatcher can choose CPU path for CUDA tensors.,2022-06-09 16:02:21+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: codegen"")]"
79197,[feature request] Support dataclass derivations of nn.Module,2022-06-09 15:02:27+00:00,,0,7,"[Label(name=""module: nn""), Label(name=""triaged"")]"
79195,"[bug] fill_, masked_fill_ : fill ops allow lossy downcasting of fill value",2022-06-09 13:49:56+00:00,,0,0,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""topic: bc breaking""), Label(name=""module: primTorch"")]"
79421,Mismatch in clang toolchain lead to binary incompatibilities on M1 between torch and torchvision,2022-06-09 08:13:37+00:00,,1,18,"[Label(name=""module: binaries""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
79191,"Triangular solve fails on batches of matrices of size > (*, 524280)",2022-06-09 07:08:12+00:00,,0,10,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
79177,_make_elementwise_unary_reference and other function factories in torch._refs don't set __name__ correctly,2022-06-09 01:30:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
79171,DistributedDataParallel `static_graph=True` fails to handle unused parameters,2022-06-09 00:03:29+00:00,,1,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
79164,PyTorch/XLA's DDP XLABackend is broken by upstream change,2022-06-08 22:03:08+00:00,,1,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: xla""), Label(name=""module: ddp"")]"
79145,Redundant info are saved when using torch.save to save part of torch.tensor,2022-06-08 19:24:47+00:00,,0,3,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
79138,[AUTOGRAD] support implicit reductions with SymInts in autograd.,2022-06-08 18:08:40+00:00,,1,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
79137,[AUTOGRAD] codegen to use sym_sizes for ops w/ symint overloads in derivative formulas,2022-06-08 18:03:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
79130,torchvision.models.mobilenetv3 can't save pre-trained model to custom dir?,2022-06-08 16:47:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vision"")]"
79120,Hide or fuse TupleConstruct / TupleUnpack from tensorboard graph,2022-06-08 11:59:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
79117,[ONNX] `.squeeze(1)` on the B X T (not B X 1 X T) tensor causes export error in masking,2022-06-08 10:40:20+00:00,,0,0,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
79118,About the source code of ,2022-06-08 09:27:13+00:00,,0,1,"[Label(name=""triaged""), Label(name=""topic: docs"")]"
79091,Error with Named Tensors and multiple threads,2022-06-08 00:27:27+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
79089,Improve PrimTorch testing for view consistency.,2022-06-08 00:22:55+00:00,,0,3,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: viewing and reshaping""), Label(name=""module: primTorch"")]"
79083,CI workflow creates too many tags in RSS feed,2022-06-07 23:37:30+00:00,,1,4,"[Label(name=""module: ci""), Label(name=""triaged"")]"
79073,"Multi-node, Multi-GPU set up tutorial for Slurm cluster",2022-06-07 22:26:13+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
93760,inspect.signature.bind is not supported,2022-06-07 22:09:35+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
79053,[MetaIssue] Propagating SymInts through Autograd,2022-06-07 20:18:12+00:00,,0,1,"[Label(name=""triaged""), Label(name=""lazy"")]"
79052,Mirror and implement `SymbolicIntNode` API for `SymInt` so we can trace in C++,2022-06-07 20:04:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
79050,[MetaIssue] Investigate if we should be reusing primtorch formulas for `is_dynamic`,2022-06-07 20:01:12+00:00,,1,1,"[Label(name=""triaged""), Label(name=""lazy"")]"
79049,DDP Freezes w/ No Output for PyTorch Geometric GNN Multi-GPU Node Classification,2022-06-07 19:44:23+00:00,,0,10,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
79039,Add Autograd Support for Nested Tensor,2022-06-07 18:44:00+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
79032,Add a test that shows that lazy_ir reuse breaks SizeNodes,2022-06-07 17:44:23+00:00,,1,2,"[Label(name=""triaged""), Label(name=""lazy"")]"
79031,Implement SymbolicIntNode interface for lazy (i.e. lazy::SymbolicIntNode),2022-06-07 17:33:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
79030,Devirtualize `sym_sizes`. It still has to work for python tensor subclasses and LTC/Xla,2022-06-07 17:31:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""lazy"")]"
79021,Building PyTorch from Source with BUILD_LAZY_TS_BACKEND_ON,2022-06-07 17:14:53+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
79020,"When setting sizes and strides on a tensor subclass in `THPVariable_make_wrapper_subclass`, also make offset symbolic",2022-06-07 17:12:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""lazy""), Label(name=""module: lazy"")]"
79018,Random functions should infer device from user-specified Generator,2022-06-07 15:42:50+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random"")]"
79016,Corner cases of ShardedTensor checkpoint when using TorchRec,2022-06-07 13:21:44+00:00,,1,6,"[Label(name=""oncall: distributed""), Label(name=""module: checkpoint""), Label(name=""triaged""), Label(name=""sharded_tensor""), Label(name=""release notes: distributed (sharded)"")]"
79014,RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR,2022-06-07 13:09:54+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: ddp"")]"
79013,Multi30k can't be downloaded the destination domain can't be reached,2022-06-07 13:07:01+00:00,,0,1,"[Label(name=""triaged"")]"
79008,torchscript jit trace support custom op without  specific csrc and .so,2022-06-07 11:43:00+00:00,,0,0,"[Label(name=""oncall: jit"")]"
79004,Doc on index of CPU Device seems wrong,2022-06-07 08:49:50+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
79003,Libtorch C++ mobile build linking error,2022-06-07 08:29:21+00:00,,0,3,"[Label(name=""module: build""), Label(name=""oncall: mobile"")]"
78987,DataLoader leaking resources?,2022-06-07 01:26:18+00:00,,0,9,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
78961,[forwardAD] torch.no_grad has no effect under forward_ad,2022-06-06 19:50:23+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: forward ad"")]"
78954,Can we have Additive Attention?,2022-06-06 18:38:56+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
78929,Add type() support for mps backend,2022-06-06 14:45:05+00:00,,1,1,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: mps"")]"
78924,"If large enough tensor is being cloned, parallel dataloading hangs on M1 Mac",2022-06-06 13:26:11+00:00,,0,10,"[Label(name=""high priority""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: deadlock""), Label(name=""module: arm"")]"
78921,Do we really need sampler for IterableDataset?,2022-06-06 09:35:07+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
78920,Strange tracing result with torchscript,2022-06-06 07:26:45+00:00,,0,0,"[Label(name=""oncall: jit"")]"
78917,LambdaLR changes the learning rate in an undesired way,2022-06-06 06:35:58+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
78892,torch.fx deepcopy does not copy attributes added to GraphModule or Nodes,2022-06-05 12:57:07+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
78885,[distributed_test.py] Improve `test_barrier`,2022-06-05 07:41:25+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""better-engineering"")]"
78884,Abnormal GPU memory usage when using CUDA tensors with multiprocessing,2022-06-05 03:36:22+00:00,,0,4,"[Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: jiterator"")]"
78882,Cannot build master on AWS cluster: error: ‘__fatDeviceText’ was not declared in this scope,2022-06-04 20:01:50+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
78880,fatal_signal_asan_no_sig_test in current master hang.,2022-06-04 12:32:12+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""module: testing"")]"
78878,Improving clarity in the docs of different losses,2022-06-04 09:20:39+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
78876,Remove const from function return type if returning const value,2022-06-04 09:03:13+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
78873,[Profiler] Capture more information about inputs,2022-06-04 04:04:14+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
78871,[RecordFunction] Hold a durable schema reference,2022-06-04 03:47:58+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
78848,MPS: Adding int64 tensor does not work on AMD GPU,2022-06-03 21:28:08+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: mps"")]"
78845,"[Modes] no_dispatch is not the same as DisableTorchFunction, causing differences in modes",2022-06-03 20:39:19+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: __torch_function__""), Label(name=""module: __torch_dispatch__"")]"
78842,Add TORCH_SHOW_CPP_STACKTRACES when TORCH_DISTRIBUTED_DEBUG = detail,2022-06-03 20:11:31+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""pt_distributed_rampup""), Label(name=""module: c10d"")]"
78834,[ONNX] Re-design `torch.onnx.export`,2022-06-03 18:06:25+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""onnx-triaged"")]"
78831,Mac M1 Build Failure on DEBUG=1,2022-06-03 17:49:58+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
78829,Certain import order triggers segmentation fault,2022-06-03 17:38:39+00:00,,0,11,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""has workaround"")]"
78812,TorchScript inference get intermediate result?,2022-06-03 15:14:37+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""feature"")]"
78809,Feature Request: Hessenberg and Schur decompositions,2022-06-03 14:21:29+00:00,,0,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
78808,Feature request: Integer system decompositions,2022-06-03 14:17:03+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
78805,"torch.jit.script segmentation fault (pytorch debayer module) 1.10, 1.11 and nightly",2022-06-03 13:43:05+00:00,,0,0,"[Label(name=""oncall: jit"")]"
78800,Efficiency of unary operations on CPU for large tensors,2022-06-03 11:07:31+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged"")]"
78786,Deprecate hardtanh type promotion behavior.,2022-06-03 01:01:45+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: primTorch"")]"
78774,[FSDP] Customizable gradient pre-divide for mixed precision training,2022-06-02 22:22:33+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
78761,Extend tag testing for aliases,2022-06-02 20:48:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: testing"")]"
78759,Add `inplace_view` tag for `resize_`,2022-06-02 20:43:36+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
78754,Getting NotImplementedError when trying to implement E2E support for `prim::is_nested` Op in torch-mlir.,2022-06-02 20:04:49+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""oncall: transformer/mha"")]"
78744,Unable to programmatically update models using references from model.named_modules()...requires additional parsing,2022-06-02 17:32:02+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
78743,Expose docs from the yaml for each torch.Tag in Python ,2022-06-02 17:17:57+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: library"")]"
78742,Add a gallery of examples with sphinx-gallery,2022-06-02 17:05:47+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
78741,Test approximation and numerical stability of numerical operators ,2022-06-02 17:01:48+00:00,,0,0,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: testing"")]"
78738,[primTorch] Sensible Error Messages,2022-06-02 16:48:08+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
78737,New c10 constants,2022-06-02 16:46:43+00:00,,0,3,"[Label(name=""module: internals""), Label(name=""triaged"")]"
78729,[Better Engineering] Make OpInfo-based test failures easy to reproduce,2022-06-02 14:56:24+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
78722,AlBert quantization,2022-06-02 12:41:20+00:00,,1,4,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
78721,[ONNX] Scripted `reshape` incorrect if shape is dynamically calculated,2022-06-02 12:38:50+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""bug"")]"
78720,ValueError during `yaml.dump(dtype)`,2022-06-02 12:34:29+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
78708,BuildExtension does not choose correct CUDA installation,2022-06-02 07:07:24+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""module: cuda""), Label(name=""triaged"")]"
78681,"Unable to install Preview (Nightly) on M1 macOS: ""Symbol not found""",2022-06-01 21:55:11+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
78656,Allow batch_norm_backward_elemt and batch_norm_gather_stats_with_counts handle 0 counts,2022-06-01 19:19:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: norms and normalization"")]"
78638,"torch.distributed.init_process_group(backend=""nccl"") NCCL version error",2022-06-01 18:23:38+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
78634,Debug job does not build in debug mode,2022-06-01 18:13:53+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
78624,linalg.pinv_singular tests are slow,2022-06-01 16:19:10+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
78618,Module parameters/submodules can be shadowed by class attributes silently,2022-06-01 13:39:55+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
78606,[FSDP] Enhance sync_module_states for auto wrapping,2022-06-01 04:47:24+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
78605,torch.svd_lowrank fails for complex matrices,2022-06-01 04:43:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: linear algebra"")]"
78581,RFC: Improve the performance and usability of linear algebra on CUDA devices,2022-05-31 21:24:56+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: magma"")]"
78559,[JIT] autodiff implementation of rand_like function is outdated ,2022-05-31 19:09:26+00:00,,0,0,"[Label(name=""oncall: jit"")]"
78530,LibTorch cannot be used without nvcc,2022-05-31 14:56:31+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
78519,test_python_dispatch fails on DEBUG=1,2022-05-31 11:46:03+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
78518,Exponentiating floating number with cuda tensor is slow,2022-05-31 11:25:45+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""topic: performance"")]"
78513,clear input shape declaration  on pytorch model inputs and outputs,2022-05-31 10:11:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: shape checking""), Label(name=""module: python frontend"")]"
78507,Parallel execution of multiple unrelated statements written sequentially,2022-05-31 05:28:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement"")]"
78489,[1.9.1] [collect_env] collect_env does not collect actual runtime-loaded cudnn version,2022-05-30 15:21:46+00:00,,0,6,"[Label(name=""module: cudnn""), Label(name=""module: collect_env.py""), Label(name=""triaged""), Label(name=""enhancement"")]"
99719,New feature requested: vmap for torch.histc,2022-05-30 15:05:00+00:00,,0,10,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: functorch"")]"
78487,torch.fx: symbolic_trace: ones() received an invalid combination of arguments,2022-05-30 12:59:44+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
78486,Exception in torch.jit.script doesn't indicate where in the code the problem lies.,2022-05-30 10:59:41+00:00,,0,2,"[Label(name=""oncall: jit"")]"
78484,torch.lerp: discrepancy between CUDA and CPU (with extremal inputs),2022-05-30 09:50:06+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
78483,is the issue resolved? windows not pytorch_jni in path,2022-05-30 05:48:42+00:00,,0,1,"[Label(name=""oncall: java"")]"
78482,RuntimeError: Event device type CUDA does not match blocking stream’s device type CPU ,2022-05-30 05:22:21+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged"")]"
78481,[onnx] RuntimeError: Attribute 'axes' is expected to have field 'ints',2022-05-30 03:09:12+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
78475,`with torch.backends.cudnn.flags(deterministic=True)` doesn't give an exception for ctc_loss backward on CUDA,2022-05-29 14:23:20+00:00,,1,21,"[Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""module: determinism"")]"
78450,"Softmax, LogSoftmax are over parameterized",2022-05-28 09:26:02+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
78444,`layer_norm` triggers INTERNAL ASSERT with input requiring grad + zero-size int tensor,2022-05-28 01:47:09+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
78443,`index_fill` will trigger INTERNAL ASSERT when float tensor requiring grad + int tensor,2022-05-28 01:29:24+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
78435,fx.Tracer with param_shapes_constant=True not working for RobertaForMaskedLM,2022-05-27 21:33:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
78422,Permutation of Sparse Tensor,2022-05-27 13:15:49+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
78414,.lldbinit for lldb debuger,2022-05-27 08:30:53+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""actionable"")]"
78413,torch.angle differs from np.angle for -0.,2022-05-27 07:47:11+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: primTorch"")]"
93756,Torchdynamo for Deepspeed and FSDP,2022-05-26 21:46:51+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: fsdp""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: distributed"")]"
78367,Split up and reorganize RPC tests,2022-05-26 16:14:38+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
78346,`gradcheck` fails for `torch.distribution.transform` APIs in forward mode,2022-05-26 07:35:05+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: forward ad"")]"
78332,TRACK: integral + floating inputs to an op with floating requiring grad result in INTERNAL_ASSERT,2022-05-26 02:26:46+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
78274, Memory allocation errors when attempting to initialize a large number of small feed-forward networks in RAM with shared memory despite having enough memory ,2022-05-25 17:08:36+00:00,,0,4,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
78262,Request for adding the possibility for training on sparse tensors,2022-05-25 15:52:10+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
78261,"pytorch-android-lite use its own libfbjni.so, which is not compatible with any other version at all..",2022-05-25 15:34:38+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: android"")]"
78260,[CI] Detect when tests are no longer running from CI,2022-05-25 15:25:31+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
78255,Floating point exception in _conv_depthwise2d,2022-05-25 14:33:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78253,Any plan to add Noam scheduling?,2022-05-25 12:22:13+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
78249,`max_unpool2d` is not deterministic,2022-05-25 10:24:51+00:00,,1,3,"[Label(name=""module: numerical-stability""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""module: pooling"")]"
78248," USE_NATIVE_ARCH flag causes nvcc build failure due to ""'arch=native': expected a number""",2022-05-25 07:32:46+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
78210,Performance with MPS on AMD GPUs are worse than CPU,2022-05-24 21:31:11+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: mps"")]"
78205,DISABLED test_complex_half_reference_testing_as_strided_scatter_cuda_complex32 (__main__.TestCommonCUDA),2022-05-24 20:58:14+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""skipped"")]"
78201,nn.Sequential causes fx.replace_pattern to not find any match. ,2022-05-24 20:43:51+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
78185,test_to (__main__.TestTorch) fails with multiple gpus,2022-05-24 17:22:31+00:00,,0,1,"[Label(name=""module: multi-gpu""), Label(name=""triaged""), Label(name=""actionable"")]"
78172,Allow specifying pickle module for torch.package,2022-05-24 12:19:47+00:00,,0,0,"[Label(name=""enhancement""), Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
78170,[chalf] reference_testing: low quality test for fast growing ops,2022-05-24 11:31:50+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: half"")]"
78159,[Optimizer Overlap] Parameter group support,2022-05-24 04:09:52+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
78158,[Optimizer Overlap] Proper checkpointing support,2022-05-24 04:07:20+00:00,,2,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
78157,[Optimizer Overlap] Custom optimizer registration,2022-05-24 03:55:57+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
78153,`pack_sequence` crash,2022-05-24 01:53:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78151,`ctc_loss` will backward crash,2022-05-24 01:29:33+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
78143,`baddmm` triggers INTERNAL ASSERT FAILED when input requires grad,2022-05-24 00:50:01+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
78141,"`matmul, mm` triggers INTERNAL ASSERT FAILED when input requires grad",2022-05-24 00:44:42+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
78133,Enhancements to AliasDB to handle in-place operations,2022-05-23 21:58:37+00:00,,0,0,"[Label(name=""oncall: jit"")]"
78131,Segfault in _pad_packed_sequence,2022-05-23 21:11:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78130,Segfault in _grid_sampler_2d_cpu_fallback,2022-05-23 21:10:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78129,Segfault in _embedding_bag_forward_only,2022-05-23 21:09:16+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78128,Segfault in torch._C._nn.thnn_conv2d,2022-05-23 21:06:50+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78127,Segfault in torch._C._nn.reflection_pad2d,2022-05-23 21:05:18+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78126,Segfault in max_unpool3d,2022-05-23 21:00:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78125,Segfault in grid_sampler_3d,2022-05-23 20:57:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78122,Segfault in bincount,2022-05-23 20:50:38+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: edge cases"")]"
78109,Doesn't work when register hook to torch.nn.MultiheadAttention.out_proj,2022-05-23 18:21:24+00:00,,1,9,"[Label(name=""oncall: transformer/mha"")]"
78102,[ONNX] Support tensors as scale and zero_point arguments,2022-05-23 17:13:00+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""OSS contribution wanted""), Label(name=""onnx-triaged"")]"
78082,RFC: Move functorch into pytorch/pytorch,2022-05-23 14:36:17+00:00,,0,6,"[Label(name=""triaged"")]"
78075,torch.multiprocessing.spawn raise PicklingError inside a decorator,2022-05-23 10:40:18+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""module: serialization""), Label(name=""triaged"")]"
78071,[primTorch] item prim can't return a bool properly,2022-05-23 04:01:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
78070,[primTorch] Meta function for item creates a dummy value,2022-05-23 03:46:07+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
78068,DISABLED test_init_from_local_shards (__main__.TestShardedTensorFromLocalShards),2022-05-23 00:57:36+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
78067,Installation on Jetson target board,2022-05-23 00:36:25+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: jetson"")]"
78065,Gamma and Related Functions,2022-05-22 21:04:05+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: special"")]"
78064,nn.CosineSimilarity returns value larger than 1,2022-05-22 19:57:02+00:00,,1,14,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
78063,Adam is 30% slower than SGD on Apple Metal.,2022-05-22 18:08:45+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: mps"")]"
78061,Python memory allocator called without holding the GIL when running torchrun under Python debug version,2022-05-22 12:35:11+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: r2p"")]"
78053,toleranceOverride should override atol and rtol even when explicitly specified in a test,2022-05-22 00:39:00+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: primTorch"")]"
78050,RFC: [primTorch] Stride-agnostic Operator Semantics,2022-05-21 21:49:30+00:00,,0,13,"[Label(name=""triaged""), Label(name=""module: python frontend""), Label(name=""module: primTorch"")]"
78047,DDP multi host with single GPU each. ,2022-05-21 20:07:36+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
78044,FFT operators are not supported on MPS device,2022-05-21 16:07:39+00:00,,0,46,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: fft""), Label(name=""topic: new features""), Label(name=""module: mps"")]"
78034,"Error occurred , when compile source code setting  BUILD_CAFFE2=ON",2022-05-21 04:38:29+00:00,,0,1,"[Label(name=""module: build""), Label(name=""caffe2""), Label(name=""triaged"")]"
78018,Three memory copies of every dataloader cpu tensor,2022-05-20 21:46:01+00:00,,0,3,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
77981,Override sym_sizes to create LTC IR for SymIntNode,2022-05-20 17:28:14+00:00,,1,1,"[Label(name=""triaged""), Label(name=""lazy"")]"
77973,"forward-mode support for ""logically composite"" operators",2022-05-20 15:44:10+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: derivatives""), Label(name=""module: forward ad"")]"
77967,Inference Tensors should not be allowed to hold `grad_fn`,2022-05-20 15:15:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""inference mode"")]"
77963,`logaddexp2` fails to backward,2022-05-20 14:46:58+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
77962,Operating on boolean torch tensor and numpy array casts to `unit8`,2022-05-20 13:42:42+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: type promotion""), Label(name=""module: boolean tensor"")]"
77961,Exporting the operator isinstance to ONNX opset version 13 is not supported,2022-05-20 12:57:34+00:00,,0,8,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
77955,NaN tensor values problem for GTX16xx users  (no problem on other devices),2022-05-20 08:52:39+00:00,,0,1,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
77951,`topk` returns different results with the same input twice in cuda,2022-05-20 07:48:48+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
77946,[failing test] test_foreach::test_binary_op_scalarlist_fastpath,2022-05-20 06:16:59+00:00,,0,5,"[Label(name=""triaged"")]"
77939,Fails to compile with GCC 12.1.0,2022-05-20 04:14:42+00:00,,0,12,"[Label(name=""module: build""), Label(name=""triaged"")]"
77901,Heap corruption in slow_conv_transpose3d,2022-05-19 21:23:21+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
77900,Floating point exception in slow_conv3d,2022-05-19 21:23:17+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
77899,Floating point exception in native_channel_shuffle,2022-05-19 21:23:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""release notes: python_frontend"")]"
77894,Floating point exception in channel_shuffle,2022-05-19 21:22:46+00:00,,0,0,"[Label(name=""triaged""), Label(name=""release notes: python_frontend"")]"
77893,Segmentation fault in _remove_batch_dim,2022-05-19 21:22:41+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: vmap"")]"
77880,Make the appropriate backend `DimensionNode` visible to LTC core,2022-05-19 19:39:03+00:00,,1,1,"[Label(name=""triaged""), Label(name=""lazy"")]"
77869,Throw warning if python optimise flags are enabled,2022-05-19 18:26:18+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: python frontend"")]"
77844,Conv2D with large different number of input and output channels gives a CUDNN_STATUS_INTERNAL_ERROR,2022-05-19 10:30:25+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
77842,ONNX export of CumSum produces different data type,2022-05-19 10:02:29+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
77840,Legacy model format is not supported on mobile,2022-05-19 08:45:31+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
77839,BUG: reference count leak when using `THPLayout_New` and `THPMemoryFormat_New` (static analyzer reports),2022-05-19 08:40:38+00:00,,0,1,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
77838,Sporadic convolution error with dilation=0,2022-05-19 08:28:27+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged"")]"
77837,TorchScript attempts to compile dead branch of torch.jit.is_scripting,2022-05-19 07:59:31+00:00,,0,2,"[Label(name=""oncall: jit"")]"
77821,cannot convert to channels last format for conv2d conv3d hybrid model,2022-05-19 02:45:17+00:00,,0,4,"[Label(name=""module: convolution""), Label(name=""triaged"")]"
77818,torch.nn.Conv3D on MPS backend,2022-05-19 01:46:03+00:00,,0,16,"[Label(name=""triaged""), Label(name=""topic: new features""), Label(name=""module: mps"")]"
77814,"`addmv, mv` will trigger INTERNAL ASSERT FAILED when input requiring grad",2022-05-19 01:35:36+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
77808,`Could not start gRPC server` flakiness in XLA tests,2022-05-19 00:16:08+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: xla"")]"
77801,`torch.utils.benchmark.examples.blas_compare` can not be parsed by Python-3.7 runtime,2022-05-18 22:38:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: benchmark"")]"
77764,General MPS op coverage tracking issue,2022-05-18 18:12:47+00:00,,0,936,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: mps"")]"
77742,strange behaviour in torch.div,2022-05-18 14:09:33+00:00,,1,2,"[Label(name=""high priority""), Label(name=""triaged"")]"
77738,net_observer_reporter_print.h missing,2022-05-18 13:35:12+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
77737,"torchrun leads to `ModuleNotFoundError: No module named 'tensorboard'`, but python -m torch.distributed.launch is ok",2022-05-18 12:59:24+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: r2p"")]"
77736,TimeSeriesDataset retrieve columns,2022-05-18 12:40:55+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged"")]"
77733,Adding Vulkan Support ,2022-05-18 08:30:33+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: vulkan"")]"
77731,complex abs strides are wrong on empty tensors and tensors with 1 dimension,2022-05-18 06:40:41+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: primTorch"")]"
77724,FSDP: enhanced shared parameter support,2022-05-18 04:02:58+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
77675,PrimTorch refs do not match argument naming with their PyTorch counterparts,2022-05-17 19:46:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
77668,Extend BC test to test for __torch_function__ overridability,2022-05-17 18:30:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
77646,Werror=nonnull in dataloader.cpp (part of tests),2022-05-17 13:52:37+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
77614,PyTorch fails to build on gcc 12 due to gloo,2022-05-17 00:20:36+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
77589,How to handle __module__  attribute for Public API bindings,2022-05-16 20:40:52+00:00,,2,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
77583,FSDP: test mixed precision with checkpoint,2022-05-16 18:42:02+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
77576,`stateless.functional_call` doesn't work with `nn.DataParallel`,2022-05-16 18:14:58+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""actionable"")]"
77558,Investigate sharded gradscaler OOM on CPU workloads,2022-05-16 16:06:16+00:00,,2,0,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
77552,Functional Jacobian does not work with Torchdiffeq,2022-05-16 15:24:53+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
77548,lintrunner doesn't give good error message suggesting lintrunner init,2022-05-16 14:42:03+00:00,,0,1,"[Label(name=""module: lint""), Label(name=""triaged"")]"
77546,Build check for AVX512 fails with AMD CPU and march=native,2022-05-16 14:30:43+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vectorization"")]"
77544,Modernize LoggingTensorMode,2022-05-16 13:40:09+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
77538,Failed to run on iOS - Couldn't find an operator for `aten::conv1d`,2022-05-16 13:04:25+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: ios"")]"
77537,batch Kronecker product ,2022-05-16 12:31:30+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement"")]"
77529,softmarginloss should use `log1p` and has an incorrect out= behaviour.,2022-05-16 10:18:45+00:00,,0,0,"[Label(name=""module: loss""), Label(name=""triaged"")]"
77527,CUDA: Illegal memory access in `torch.linalg.solve()`,2022-05-16 08:24:55+00:00,,0,12,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
77523,DDP window TCP bug [socket.cpp:558] [c10d] The client socket has failed to ,2022-05-16 07:49:09+00:00,,0,10,"[Label(name=""oncall: distributed"")]"
77515,Inplace Bool API + `sum` will trigger INTERNAL ASSERT FAILED,2022-05-16 00:52:17+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: edge cases"")]"
77514,`max_pool1d` can succeed when padding is negative for tensor requiring grad,2022-05-16 00:41:37+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: pooling""), Label(name=""module: edge cases"")]"
77478,Standalone unittests for checkpoint_wrapper,2022-05-14 07:58:15+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
77463,conda CPU installation for LTS fails with UnsatisfiableError,2022-05-13 22:52:28+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: lts"")]"
77454,More clarity in doc for `torch.cuda.Event.record`?,2022-05-13 21:45:13+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
77439,FSDP: Mixed precision should not cast ignored buffers,2022-05-13 19:01:28+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
77415,Suboptimal error message - nn.Linear with double argument,2022-05-13 13:51:41+00:00,,0,3,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
77413,Process hangs after calling conv2d() in pytorch 1.11.0 with CUDA 11.3,2022-05-13 13:02:38+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
77411,Allow force building with/without AVX,2022-05-13 10:53:31+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
77410,torch.onnx.export does not track Tensor.data.size() for dynamic axes,2022-05-13 10:53:02+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""release notes: onnx"")]"
77397,Large numerical inconsistency for `torch.einsum` on RTX30 series GPU.,2022-05-13 01:27:22+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: tf32"")]"
77380,microbenchmark-style tests,2022-05-12 21:55:17+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
77374,[distributed] c10d crashing on assert,2022-05-12 21:07:39+00:00,,0,4,"[Label(name=""oncall: distributed"")]"
77354,"outputs_[i]->uses().empty()INTERNAL ASSERT FAILED at ""/opt/conda/conda-bld/pytorch_1646755853042/work/torch/csrc/jit/ir/ir.cpp"":1314, please report a bug to PyTorch. ",2022-05-12 15:49:38+00:00,,1,0,"[Label(name=""oncall: jit"")]"
77342,DISABLED test_ddp_profiling_autograd_profiler (__main__.TestDistBackendWithSpawn),2022-05-12 06:47:01+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
77340,Disable issue doesn't disable multiple dtypes correctly,2022-05-12 06:37:01+00:00,,1,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
77332,"wrong overload resolved for `torch.mul(x, 4)` in `__torch_dispatch__`",2022-05-12 06:14:45+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
77317,DISABLED test_DistributedDataParallel (__main__.TestDistBackendWithSpawn),2022-05-12 00:57:50+00:00,,1,6,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
77284,non-rentrant checkpointing uses same memory as non-checkpointed code,2022-05-11 19:58:59+00:00,,1,0,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""module: checkpoint""), Label(name=""triaged"")]"
77265,Subclasses with unwrapping `__torch_dispatch__` impls as parameters,2022-05-11 16:07:31+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""tensor subclass"")]"
77256,CrossEntropyLoss computes SoftMax always across the second dimension,2022-05-11 15:10:08+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""actionable"")]"
77253,lintrunner not working,2022-05-11 14:38:54+00:00,,0,4,"[Label(name=""module: lint""), Label(name=""triaged"")]"
77251,The codegen unconditionaly generate code even when it is not going to be used,2022-05-11 14:21:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
77241,libtorch1.8 torch::sigmoid is wrong,2022-05-11 09:27:06+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: jetson"")]"
77233,`tensordot` does check the dtype of empty tensor,2022-05-11 05:41:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
77232,Write decomposition conditionals in a way that leads to simpler shape expressions,2022-05-11 05:14:32+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
77231,`torch.scatter_add` will succeed when the `index` is a complex tensor,2022-05-11 05:12:17+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
77230,fast `gradcheck` fails when outputs that do not require grad precede outputs that do,2022-05-11 04:11:59+00:00,,0,7,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""actionable"")]"
77223,torch.ops.aten.ceil(1.5) returns Tensor rather than scalar,2022-05-11 02:33:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: type promotion"")]"
77216,[primTorch] Reduction references don't return views consistent with their original operators,2022-05-11 01:15:47+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
77200,[RFC] Allow device override during Tensor unpickling without torch.load,2022-05-10 21:28:32+00:00,,0,1,"[Label(name=""module: pickle""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""enhancement"")]"
93753,Don't populate f_locals to check guards,2022-05-10 19:05:31+00:00,,1,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
77184,Undefined symbol error when compiling and loading C++ extension,2022-05-10 18:17:29+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""module: cpp""), Label(name=""triaged"")]"
77176,Improve the overall design of MPSGraphCache,2022-05-10 17:09:39+00:00,,1,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: backend""), Label(name=""module: mps"")]"
77171,Allow users to express fused matmul/bias/relu,2022-05-10 16:34:30+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research""), Label(name=""module: python frontend"")]"
77170,Move the MPSGuardImpl to inherit from NoOpDeviceGuardImpl,2022-05-10 16:33:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: backend""), Label(name=""module: mps"")]"
77167,nn.functional.pad accepts bool values but raises internal assert when converted to JIT,2022-05-10 15:11:31+00:00,,0,1,"[Label(name=""oncall: jit"")]"
77166,"torch.cholesky has been deprecated in favour of torch.linalg.cholesky. However, torch.cholesky_inverse remains as is. It should also be moved to torch.linalg",2022-05-10 14:31:13+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
77165,Automate cleanup of header includes,2022-05-10 14:24:50+00:00,,1,2,"[Label(name=""module: internals""), Label(name=""triaged"")]"
77161,SymInt shouldn't be in dynamic_type.h,2022-05-10 11:44:39+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
77159,"A somewhat cryptic error message (for newcomers) - ""Cannot re-initialize CUDA in forked subprocess"" - report and suggestion for a possible solution",2022-05-10 09:32:18+00:00,,0,15,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
77155,FSDP: ability to ignore parameters,2022-05-10 09:09:15+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
77154,Distributed Weighted Sampler.,2022-05-10 08:51:35+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
77144,Add Tensor compare support for MPS backend,2022-05-10 05:31:46+00:00,,2,4,"[Label(name=""triaged""), Label(name=""module: backend""), Label(name=""module: testing""), Label(name=""module: mps"")]"
77141,[FSDP] `ignored_modules` follow-ups,2022-05-10 03:48:36+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
77140,"torch.randperm uses too much cpu, but not efficient.",2022-05-10 03:46:41+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: multithreading"")]"
77118,__name__ on OpOverload should not contain period,2022-05-10 00:23:41+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
77113,broadcast_object_list with GPU tensors can lead to deadlock on PyTorch CI machines,2022-05-09 23:36:46+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
77067,Unable to continue adding modules to `nn.Sequential` after using `del` method,2022-05-09 10:31:19+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
77053,Incorrect documentation in ``gumble_softmax`` function.,2022-05-08 19:51:15+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
77052,Building from source results in broken __version__,2022-05-08 18:30:52+00:00,,1,6,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
77050,ENORMOUS OVERHEAD from mp.get_context('spawn'),2022-05-08 15:57:54+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: POWER"")]"
77049,Peak GPU-memory usage extremely huge when sorting with torch.sort,2022-05-08 15:35:39+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
77047,Stop calling sizes/numel/dim/is_contiguous on undefined tensors,2022-05-08 12:34:14+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
77046,torch.stack test_conj_view and test_neg_view are failing after 77043,2022-05-08 08:28:08+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: viewing and reshaping""), Label(name=""module: primTorch"")]"
77027,Kill use of TensorImpl::ShareExternalPointer in torch/csrc/jit/tensorexpr/external_functions.cpp,2022-05-07 17:18:44+00:00,,0,0,"[Label(name=""oncall: jit"")]"
77016,Where is fx2trt fx to tensorrt tool?,2022-05-07 08:43:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
76972,Display EC2 information,2022-05-06 17:37:27+00:00,,1,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
76966,[bug] `NATIVE` and `OMP` `parallel_for` implementations are inconsistent.,2022-05-06 16:19:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: openmp""), Label(name=""module: multithreading"")]"
76962,DISABLED test_comprehensive_linalg_ldl_factor_ex_cuda (__main__.TestDecompCUDA),2022-05-06 14:25:09+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""skipped"")]"
76960,"When using Rsqrt, the output of the 1/x process is very likely to have nan/inf",2022-05-06 13:55:35+00:00,,0,0,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
76959,"When using Lambda, the output of the 1/x process is very likely to have nan/inf",2022-05-06 13:53:35+00:00,,0,0,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
76956,GlobalAvgPool2d causes the inconsistency of output between frameworks,2022-05-06 12:56:36+00:00,,0,0,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
76955,GaussianNoise causes the inconsistency of output between frameworks,2022-05-06 12:50:31+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
76954,ReduceSum causes the inconsistency of output between frameworks,2022-05-06 12:47:55+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
76944,primTorch references don't handle scalar x scalar inputs correctly,2022-05-06 06:22:46+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: primTorch"")]"
76936,"Private API for accessing all ""internal"" attributes on Tensors",2022-05-06 02:07:57+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
76933,NVFuser opinfos - check for CudaFusionGroup in the graph,2022-05-06 01:03:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
76927,Can't pickle model torch._C._distributed_c10d.ProcessGroupNCCL' object ,2022-05-05 23:54:13+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: c10d""), Label(name=""module: ddp"")]"
76924,[RFC] Upstream current implementation of ssd_offload from fairscale FSDP to Torch Distributed FSDP,2022-05-05 22:49:16+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
76920,Avoid Self-loops on Module Creation,2022-05-05 21:04:55+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
76913,Pytorch return TCPStore( RuntimeError: Connection reset by peer) ,2022-05-05 20:07:05+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
76906,torch.nn.functional.linear sometimes incorrectly accepts arguments of the different type,2022-05-05 18:39:19+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
76891,Unwanted behavior with some in-place operations on CPU,2022-05-05 11:52:39+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
76887,Multiprocessing DataLoader hangs on exception inside iterator when using a simple queue and a producer thread,2022-05-05 09:32:36+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
76885,EmbeddingBag: Does CUDA calculate error in EmbeddingBag forward when include_last_offset=True ?,2022-05-05 09:03:39+00:00,,1,7,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: embedding"")]"
76881,RecursionError when running torch.jit.script inside JitTestCase,2022-05-05 06:18:00+00:00,,0,0,"[Label(name=""oncall: jit"")]"
76871,PrimTorch binary refs do not handle CUDA + CPU scalar tensors correctly,2022-05-05 03:13:15+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
76865,Object-base collectives create tensors at unexpected devices,2022-05-05 00:17:03+00:00,,1,3,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: c10d"")]"
76856,Feature requests for optimizer overlapping,2022-05-04 22:49:10+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: ddp""), Label(name=""module: fsdp"")]"
76853,Inconsistent results between Pow and Float Pow with their numpy references for complex types,2022-05-04 22:32:54+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: NaNs and Infs"")]"
76844,Unify torch.ops argument parsing code with PythonArgParser,2022-05-04 20:53:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__""), Label(name=""module: python frontend"")]"
76838,Windows CUDA TTS tracking task,2022-05-04 18:54:24+00:00,,1,18,"[Label(name=""module: ci""), Label(name=""triaged"")]"
76827,TYPEIGNORE lint run locally disagrees with CI,2022-05-04 17:57:11+00:00,,0,0,"[Label(name=""module: lint""), Label(name=""triaged""), Label(name=""module: macos"")]"
76807,There is a bug with latest stable torch version and the following Nightly versions related to `optimize_for_mobile`,2022-05-04 10:31:31+00:00,,0,5,"[Label(name=""oncall: mobile"")]"
76806,torch.Tensor.__rdiv__ long x scalar float type promotion is incorrect,2022-05-04 10:03:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: primTorch"")]"
76804,"torch.add bool x bool allows integer alpha, inconsistent with other dtype type checking",2022-05-04 09:53:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: primTorch"")]"
76798,`gradcheck` for `torch.solve` may trigger INTERNAL ASSERT FAILED,2022-05-04 08:22:17+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""triaged"")]"
76786,"`cumprod, prod` will backward fail if `dtype` argument is different than the dtype of input tensor",2022-05-04 02:35:22+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""complex_autograd"")]"
76785,"`addr, baddmm, dist, l1_loss` will backward fail when input tensors have different dtypes",2022-05-04 02:31:27+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""actionable""), Label(name=""complex_autograd"")]"
76783,`gradcheck` fails for `torch.trace`,2022-05-04 02:02:09+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
76780,`gradcheck` should support the comparison of NaN,2022-05-04 00:47:35+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable"")]"
76779,"Strange warning from `matmul(..., out=...)`",2022-05-04 00:31:34+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
76778,`torch.addmv` backward fails,2022-05-04 00:28:15+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""actionable"")]"
76775,[JIT] Infinite RecursionError with self-referential models (also affects `__repr__`)!!,2022-05-03 23:37:28+00:00,,0,1,"[Label(name=""oncall: jit"")]"
76774,Support Positional-only Arguments in JIT,2022-05-03 22:44:42+00:00,,0,1,"[Label(name=""oncall: jit"")]"
76772,[typing] distribution.lazy_property is not typed,2022-05-03 20:47:44+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
76760,hanging process with init_process_group(backend='mpi') cannot be killed ,2022-05-03 18:27:04+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
76755,Quantization in Libtorch,2022-05-03 17:59:40+00:00,,0,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
76751,Default repr of __get__ methods in __torch_function__ is bad,2022-05-03 17:11:52+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
76750,Bug in dataloader iterator found by mypy,2022-05-03 16:58:25+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
76747,[checkpoint] Stable file format for checkpoints,2022-05-03 16:46:52+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""sharded_tensor"")]"
76745,[checkpoint] Handle overlapping storage during save and load,2022-05-03 16:40:09+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""sharded_tensor"")]"
76743,Supporting torch.tensor.apply_ over GPU,2022-05-03 16:12:50+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
76734,__torch_function__ callers should always pass kwargs,2022-05-03 14:08:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
76733,test_python_reference_meta_functions takes too long to run,2022-05-03 13:57:53+00:00,,0,5,"[Label(name=""module: tests""), Label(name=""triaged"")]"
76732,Adding Polyloss to `torch`,2022-05-03 13:47:21+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
76730,[JIT] magic methods do not work after reloading model,2022-05-03 13:01:32+00:00,,0,0,"[Label(name=""oncall: jit"")]"
76726,Torchscript model Runtime Error after quantization,2022-05-03 08:13:01+00:00,,0,15,"[Label(name=""oncall: jit""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
76709,`reshape` for distributions.,2022-05-03 00:27:53+00:00,,0,6,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
76705,"Torch `x += y.bmm(z)` is faster than `x.baddbmm_(y, z)`",2022-05-02 23:50:13+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
76689,Performance bad on ARM AArch64 for PyTorch C++,2022-05-02 20:22:07+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: arm"")]"
76686,[torch::deploy] Remove `manager_` from the constructor and deconstructor of `InterpreterSession`,2022-05-02 19:02:27+00:00,,1,1,"[Label(name=""module: deploy""), Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
76685,[torch::deploy] move create_movable to interpreter_manager,2022-05-02 19:00:53+00:00,,1,0,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
76683,[torch::deploy] remove reliance on manager_ for unload,2022-05-02 18:45:35+00:00,,1,0,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
76682,[torch::deploy] Remove manager_ from AquireSession,2022-05-02 18:40:03+00:00,,1,0,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
76672,C++ CUDA assign existing memory to forward method.,2022-05-02 17:28:34+00:00,,0,1,"[Label(name=""oncall: jit"")]"
76659,Remove all docstrings when python is running in optimization mode,2022-05-02 15:02:34+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: python frontend"")]"
76656,Clarify dependency on NumPy (related to maskedtensor?),2022-05-02 13:34:42+00:00,,0,5,"[Label(name=""triaged"")]"
76655,[feature request] no-param sort to exploit parallelization,2022-05-02 12:50:40+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""module: sorting and selection"")]"
76654,`torch.sort` does not exploit parallelization when invoked without the `dim` parameter.,2022-05-02 12:22:21+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
76649,Add `ldl_unpack` functionality,2022-05-02 07:27:57+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
76646,`torch.nn.HuberLoss` backwards unexpectedly fail,2022-05-02 02:42:47+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
76644,`torch.smm` backward fail with strange error message,2022-05-02 02:09:23+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
76643,Pytorch can't process special unicode,2022-05-02 01:25:56+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: serialization""), Label(name=""triaged"")]"
76638,Design API for accessing sparse tensor indices,2022-05-01 20:32:20+00:00,,0,9,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
76636,WeightNorm: Add reset_parameters Linear override,2022-05-01 17:33:08+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
76632,RestrictPtrTraits in CUDA potentially has no effect.,2022-05-01 08:56:57+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""better-engineering"")]"
76627,`Tensor.logit`'s signature in doc misses `eps` argument,2022-05-01 05:42:16+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
76618,pylint segfault,2022-04-30 12:38:33+00:00,,0,0,"[Label(name=""module: lint""), Label(name=""triaged"")]"
76617,Improve error message for `unfold` when generating tensor with negative dimension,2022-04-30 11:49:08+00:00,,0,2,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: shape checking""), Label(name=""module: viewing and reshaping"")]"
76613,MeanVarianceNormalization,2022-04-30 03:05:00+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
76612,OpInfo incorrectly advertises lu_solve support on CUDA even when compiled without magma,2022-04-30 02:20:01+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: linear algebra"")]"
76611,OpInfo CUDA bfloat16 support detection is buggy,2022-04-30 02:15:26+00:00,,0,4,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
76609,AttributeError: '_thread._local' object has no attribute 'rel_tol' (cannot use TestCase.assertEqual from other threads),2022-04-30 01:41:17+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
76585,`torch.linalg.cond` has different results for tensor requiring autograd,2022-04-29 11:02:16+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
76580,Random Generator for Dropout,2022-04-29 05:07:48+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: random"")]"
76578,[JIT][Autocast] Batchnorm folding pass during freezing doesn't preserve types,2022-04-29 02:37:09+00:00,,1,0,"[Label(name=""oncall: jit"")]"
76571,torch.unique() nondeterministic behavior on nan inputs (on GPU),2022-04-29 00:29:32+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: determinism""), Label(name=""module: sorting and selection"")]"
76558,[jiterator] perf regression when jiterating few ops for complex dtype,2022-04-28 19:43:46+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: jiterator"")]"
76557,Pip packaging and publishing improvements in pytorch wheels for better integration with poetry,2022-04-28 19:40:35+00:00,,0,11,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
76555,[numpy] Missing Tensor-Scalar support for multiple binary ops ,2022-04-28 19:32:25+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: python frontend"")]"
93749,Better handling for exec,2022-04-28 17:28:19+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
76543,Segfault in ~PyFunctionPreHook,2022-04-28 17:26:02+00:00,,0,18,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: autograd""), Label(name=""triaged"")]"
76532,Add ability to add custom suffixes to tensor repr,2022-04-28 14:10:54+00:00,,0,5,"[Label(name=""module: printing""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs design""), Label(name=""tensor subclass""), Label(name=""module: python frontend"")]"
76528,Discrepancy in einsum when done in batch vs non-batch,2022-04-28 10:49:49+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: tf32"")]"
76527,Non target rank receives result of 'reduce' op when backend is 'gloo',2022-04-28 10:47:38+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
76522,`torch.clamp` does not distribute gradients as element-wise`min/max` do,2022-04-28 04:40:04+00:00,,0,10,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
76519,Fix layout of masked output when all sparse dimensions are reduced,2022-04-28 03:58:24+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
76514,Clean up PyTorch's private operators,2022-04-28 01:43:44+00:00,,0,2,"[Label(name=""module: internals""), Label(name=""triaged"")]"
76512,Make Torch FX function `_torchscript_type_to_python_type` public,2022-04-28 01:23:10+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: fx"")]"
76510,`Tensor.register_hook()` Source Link Broken,2022-04-28 00:36:39+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
76503,[JIT] make IRAttributeError extend jit::Error,2022-04-27 23:11:02+00:00,,0,0,"[Label(name=""oncall: jit"")]"
76491,[NVFuser] Automated generation of microbenchmarks,2022-04-27 21:30:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
76487,`F.interpolate` uses incorrect size when `align_corners=True`,2022-04-27 21:15:27+00:00,,1,7,"[Label(name=""triaged""), Label(name=""module: interpolation"")]"
76486,[Tracer] RuntimeError: _Map_base::at when tracing fake quantization,2022-04-27 21:10:50+00:00,,2,8,"[Label(name=""oncall: jit"")]"
76483,Expand pow and float_pow sampling function for more coverage,2022-04-27 21:05:57+00:00,,0,7,"[Label(name=""module: tests""), Label(name=""triaged"")]"
76465,Pyre type checking fails ,2022-04-27 19:03:47+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged"")]"
76464,Add post-AccumulateGrad hook as a nice public API,2022-04-27 19:03:20+00:00,,1,5,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""actionable"")]"
76451,[checkpoint] Extension hooks to support logging and telemetry,2022-04-27 16:37:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""sharded_tensor"")]"
76449,Enhance _verify_param_shape_across_processes,2022-04-27 16:32:19+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup"")]"
76441,[checkpoint] Switch away from pickle-base serialization,2022-04-27 15:04:39+00:00,,0,4,"[Label(name=""triaged""), Label(name=""sharded_tensor"")]"
76433,Remove _log_softmax/_softmax in favor of log_softmax and softmax respectively.,2022-04-27 09:07:31+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
76410,TorchFunction handling and overload resolution very slow in `torch.ops`,2022-04-26 22:17:12+00:00,,0,2,"[Label(name=""oncall: jit"")]"
76395,[checkpoint] SPMD distributed checkpoint coordination,2022-04-26 19:14:05+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""sharded_tensor"")]"
76389,Error in DistributedDataParallel with 'CPU' device,2022-04-26 18:03:21+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
76387,[checkpoint] Make prepare_sharded_tensor_read and prepare_sharded_tensor_write public,2022-04-26 17:54:09+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""sharded_tensor"")]"
76383,Suggestion to throw a UserWarning when a user forgot .eval() mode during inference,2022-04-26 16:59:59+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""module: molly-guard""), Label(name=""triaged"")]"
76371,[ONNX] Intermediate values are encoded when exporting operators with custom namespace,2022-04-26 14:14:43+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
76370,onnx export fails when using torchvision.transforms.CenterCrop,2022-04-26 14:14:06+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
76362,Whether 'targetSize' in inferExpandGeometryImpl needs to be checked when it is less than 0,2022-04-26 03:37:57+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
76354,NVFuser failing extremal opinfos,2022-04-26 00:18:40+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
76347,`index_select` allows negative `index` for sparse but not for strided `self`,2022-04-25 22:28:40+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
76344,"[ONNX] Use topk to export max(dim,keepdim) to onnx",2022-04-25 22:06:43+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""bug"")]"
76338,torch.bucketize doc typo on the left boundary when 'right=True',2022-04-25 20:51:11+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
76331,[checkpoint] Avoid loading whole tensor when resharding ,2022-04-25 19:05:37+00:00,,0,0,"[Label(name=""triaged""), Label(name=""sharded_tensor"")]"
76327,[checkpoint] Add extension points to avoid the default serialization behavior,2022-04-25 18:29:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""sharded_tensor"")]"
76326,[checkpoint] Support models with different cross-rank metadata,2022-04-25 18:15:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""sharded_tensor"")]"
76325,[checkpoint] Use fsspec to support object storage,2022-04-25 18:12:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""sharded_tensor"")]"
76324,Bessel and Related Functions,2022-04-25 18:10:09+00:00,,0,12,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: special"")]"
76323,[Checkpoint] Add module documentation,2022-04-25 18:05:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""sharded_tensor"")]"
76309,More understandable name column of the table of the profiling result.,2022-04-25 14:02:16+00:00,,0,1,"[Label(name=""oncall: profiler"")]"
76304,Quantization fails when padding parameter given as string,2022-04-25 12:28:18+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
76300,Unexpected _LinAlgError appeared only on my device,2022-04-25 09:11:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
76295,TorchScript: jit.script fails when using 'tolist' with int32 tensors.,2022-04-25 03:38:55+00:00,,0,2,"[Label(name=""oncall: jit"")]"
76294,torch._remove_batch_dim is interceptable by __torch_function__ / batch tensors don't print correctly,2022-04-25 02:29:44+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""module: __torch_function__"")]"
76288,Multi-GPU distributed training reports errors,2022-04-24 18:04:55+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
76287,torch.elastic fails to shutdown despite crashed processes,2022-04-24 15:38:37+00:00,,0,31,"[Label(name=""oncall: distributed""), Label(name=""module: elastic"")]"
76282,`torch.cuda.amp.GradScaler` may skip parameter synchronization required by post localSGD optimizer,2022-04-24 07:57:07+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: amp (automated mixed precision)"")]"
76274,[ONNX] About custom operator convert PreciseRoIPooling to ONNX,2022-04-24 02:28:40+00:00,,0,7,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
76244,Initial integration of ZenDNN as backend into PyTorch,2022-04-22 16:50:48+00:00,,0,8,"[Label(name=""feature""), Label(name=""module: convolution""), Label(name=""triaged"")]"
76232,Observing a strange behavior - Row parallelism,2022-04-22 14:02:17+00:00,,0,5,"[Label(name=""module: numerical-stability""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
76225,"RuntimeError: bucket_count == per_bucket_sizes.size()INTERNAL ASSERT FAILED at ""/opt/conda/conda-bld/pytorch_1646755853042/work/torch/csrc/distributed/c10d/reducer.cpp"":980, please report a bug to PyTorch. ",2022-04-22 07:40:09+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
76206,Update NCCL to 2.12,2022-04-22 00:07:11+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: build""), Label(name=""triaged"")]"
76191,"[Feature request] Exclusive prefix sum, `torch.cumsum(input, dim=0, exclusive=True)`",2022-04-21 19:53:49+00:00,,1,5,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: reductions"")]"
76186,fx: cannot find module <built-in method matmul> when using apex.amp,2022-04-21 18:40:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
76185,Ensure custom Function are correct in double backward setting,2022-04-21 18:01:03+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable"")]"
76181,Allow `torch.fx` tracing on TorchScript models,2022-04-21 16:58:52+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""module: fx"")]"
76176,Indexing assignment can have no effect on CUDA with deterministic algorithms,2022-04-21 14:56:38+00:00,,0,7,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
76175,Many dispatch keys do not print to string correctly,2022-04-21 14:38:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
76166,at::real and at::imag as methods,2022-04-21 09:10:16+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: complex"")]"
76160,test_wishart_log_prob fails locally for me,2022-04-21 03:29:34+00:00,,0,4,"[Label(name=""module: distributions""), Label(name=""module: tests""), Label(name=""triaged"")]"
76155,Replace `RuntimeError` by custom exception for unsupported ONNX operators during export,2022-04-20 23:41:56+00:00,,0,7,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""topic: improvements"")]"
76138,Coverage test is only checking packages and not all submodules,2022-04-20 20:42:44+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
76128,test_license_for_wheel always fails on my local dev copy,2022-04-20 19:04:56+00:00,,1,6,"[Label(name=""module: tests""), Label(name=""triaged"")]"
76127,run_test.py option to write out failed tests,2022-04-20 19:02:37+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
76113,Deprecation warning from SequentialLR,2022-04-20 15:49:50+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: LrScheduler"")]"
76108,RuntimeError: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\caffe2\\serialize\\inline_container.cc:300],2022-04-20 14:10:30+00:00,,0,15,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
76106,Allow any operation that takes a Storage to also take a contiguous Tensor instead,2022-04-20 13:48:10+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
76105,Failed to build on Ubuntu 18.04 due to bad MPI linker flags,2022-04-20 13:47:29+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged"")]"
76103,Some test failed when running in parallel.,2022-04-20 13:27:18+00:00,,0,14,"[Label(name=""oncall: distributed"")]"
76082,Eliminate uses of deprecated `FindCUDA.cmake`,2022-04-20 01:45:58+00:00,,1,6,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""better-engineering"")]"
76071,HIPFFT_EXEC_FAILED when using AMD GPU run FFT,2022-04-19 22:10:55+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: fft"")]"
76070,NVFuser microbenchmark classifier - hash on memory formats,2022-04-19 21:16:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
76069,`init_process_group` hanging on HPC multi-node system w GPU ,2022-04-19 21:10:02+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
76047,NNC failing opinfo accuracy tests,2022-04-19 15:56:51+00:00,,0,0,"[Label(name=""NNC"")]"
76043,RuntimeError: bucket_count == per_bucket_sizes.size() INTERNAL ASSERT FAILED,2022-04-19 15:35:44+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: ddp"")]"
76040,SSL certificate error: urlopen error [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1091)>,2022-04-19 14:56:14+00:00,,0,1,"[Label(name=""triaged"")]"
76039,[RFC] NPU device for PyTorch,2022-04-19 14:40:13+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
76037,__torch_function__ and generator input hazard,2022-04-19 13:25:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
76031,Computer using CPU instead of GPU nvidia with CUDA,2022-04-19 10:56:14+00:00,,0,12,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
76030,Dirichlet with small concentration,2022-04-19 10:20:18+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
76029,Mobile assets upload could break third party mirrors due to binary data size,2022-04-19 10:09:34+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
76028,A bug in instructions for building PyTorch with ASAN,2022-04-19 09:58:36+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""topic: bug fixes"")]"
76026,Jit torchscript for prediction is missing 'forward' when using forward hooks,2022-04-19 09:25:27+00:00,,0,0,"[Label(name=""oncall: jit"")]"
76025,Numerical instability: matrix multiplication got different results on cpu and gpu ,2022-04-19 09:21:30+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: tf32"")]"
76024,The prediction results of different equipment are inconsistent,2022-04-19 09:05:28+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""triaged"")]"
76013,test_jit.py TestWarn.test_warn and friends doesn't work under pytest,2022-04-19 02:29:40+00:00,,0,1,"[Label(name=""oncall: jit"")]"
76012,torch.nn.LayerNorm is very slow on GPU (much slower than a custom LayerNorm version in the ConvNext model),2022-04-19 02:27:00+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
76011,backcompat tests in test_nn.py are slow,2022-04-19 01:48:45+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: tests""), Label(name=""triaged"")]"
76007,"Build a default NVFuser comparison callback, e.g. for use with torchbench",2022-04-19 00:32:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
75986,gql_mocks.json has really long lines,2022-04-18 18:54:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
75984,DISABLED test_zero_model_parallel_parameters_as_bucket_view_True (__main__.TestZeroRedundancyOptimizerDistributed),2022-04-18 18:20:38+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: rocm""), Label(name=""skipped"")]"
75982,"API to determine if a torch.return_type is a ""structseq""",2022-04-18 17:26:24+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
75963,Add build support for GCC 11.2,2022-04-18 12:43:47+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
75960,"jit/_trace.py"", line 71, in _unique_state_dict     filtered_dict[k] = v.detach() AttributeError: 'torch.dtype' object has no attribute 'detach'",2022-04-18 08:14:00+00:00,,0,2,"[Label(name=""oncall: jit"")]"
75956,[JIT] [Autocast] JIT Autocast Pass operations' list should be extendable and consistent with imperative path,2022-04-18 02:35:16+00:00,,2,4,"[Label(name=""oncall: jit"")]"
75949,Potential memory leak in Adam optimizer in AMD chips (CPU),2022-04-17 19:54:01+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: optimizer""), Label(name=""module: rocm""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
75943,FSDP remove the requirement of all trainable parameters  ,2022-04-17 00:44:29+00:00,,1,12,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
75940,Add nesting of nested Tensor,2022-04-16 09:53:27+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
75936,AllGather with backward support async_op=True,2022-04-16 06:37:17+00:00,,0,0,"[Label(name=""oncall: distributed"")]"
75935,torch.jit.trace error when custom autograd function used in the model,2022-04-16 02:54:16+00:00,,0,3,"[Label(name=""oncall: jit"")]"
75926,Disable TracerWarnings on NVFuser opinfo tests,2022-04-15 22:58:19+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
75925,autogen-58 microbenchmark fails on NNC gpu fusion,2022-04-15 22:50:36+00:00,,0,0,"[Label(name=""NNC"")]"
75923,aten::_softmax.out doesn't work with non-contiguous Tensors ,2022-04-15 21:59:19+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
75912,"interaction with psychopy during imports, script exits with: free(): invalid pointer. Aborted (core dumped)",2022-04-15 20:21:57+00:00,,0,6,"[Label(name=""triaged"")]"
75911,'python setup.py build' failed but succeed using  'pip install -v .' which calls 'python setup.py build'.,2022-04-15 20:16:56+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
75910,[FSDP] Verify buffer checkpointing,2022-04-15 20:11:59+00:00,,1,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
75909,Add batching rules for `{view}_copy` operators,2022-04-15 19:55:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: batching"")]"
75904,Move _SKIP_PYTHON_BINDINGS to native_functions.yaml,2022-04-15 19:00:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
75903,torch.jit.script'd function very slow on first invocation on latest nightly,2022-04-15 18:48:12+00:00,,0,17,"[Label(name=""oncall: jit""), Label(name=""NNC""), Label(name=""module: nvfuser"")]"
75895,add -D_GLIBCXX_ASSERTIONS in debug mode,2022-04-15 17:16:22+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
75864,"INTERNAL ASSERT FAILED at ""vulkan_rewrite.cpp"":272",2022-04-15 08:51:48+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
75862,LayerNorm and GroupNorm with num_groups=1 not equivalent,2022-04-15 08:04:15+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
75798,Fix workaround `__module__` used to appease public binding checks,2022-04-14 15:59:55+00:00,,0,0,"[Label(name=""triaged"")]"
75794,Different result with JIT,2022-04-14 14:36:54+00:00,,0,2,"[Label(name=""oncall: jit"")]"
75788,`torch.jit.script` Script functions do return `requires_grad = False` if `torch.no_grad()` has been used,2022-04-14 09:50:58+00:00,,1,1,"[Label(name=""oncall: jit"")]"
75785,"[ONNX] Expected quantizer->qscheme() == kPerTensorAffine to be true, but got false.",2022-04-14 06:23:09+00:00,,0,2,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
75778,`torch.matmul` produces wrong results on A4000 for matrices (n*m) with large m and small n ,2022-04-14 02:24:03+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: tf32"")]"
75773,Handle noncontiguous inputs in distributed backend layer,2022-04-14 00:46:24+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
75747,Depthwise Conv1d performance (a naive CUDA kernel is 10x faster),2022-04-13 18:08:27+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
75740,Large numerical error when applying nn.Linear in RTX A6000 with cuda>=11.1,2022-04-13 16:26:38+00:00,,0,3,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: tf32"")]"
75737,torch.device missing doctring,2022-04-13 15:33:39+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
75733,"`torch.sum, prod, cumsum, cumprod, sparse.sum` INTERNAL ASSERT FAIL",2022-04-13 14:27:35+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: reductions"")]"
75725,Warning originating in C10 backend does not get translated to Python warning if run from subprocess,2022-04-13 09:09:54+00:00,,0,4,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed"")]"
75721,Support batch indexing with sparse tensors with torch.sparse,2022-04-13 03:04:41+00:00,,0,6,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
75703,Let's host NVIDIA dependencies in our own S3,2022-04-12 22:14:54+00:00,,2,14,"[Label(name=""module: ci""), Label(name=""triaged"")]"
75701,Einsum should have an `out=` parameter,2022-04-12 20:53:29+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
75680,Addressing skips in OpInfo nn.functional.binary_cross_entropy_with_logits,2022-04-12 18:29:54+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: tests""), Label(name=""triaged"")]"
75673,Tensorboard Issue with visualizing the connections of encoder-decoder network,2022-04-12 17:19:19+00:00,,0,1,"[Label(name=""oncall: visualization"")]"
75667,Implement histc for bfloat16 on CPU,2022-04-12 15:34:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: sorting and selection"")]"
93746,Off main thread symbolic evaluation,2022-04-12 13:55:35+00:00,,0,4,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo""), Label(name=""module: startup-tracing-compile time"")]"
75662,"multiprocessing and torch.tensor, Cannot allocate memory error",2022-04-12 12:43:52+00:00,,0,5,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
75659,Misleading documentation for cholesky_inverse,2022-04-12 11:14:35+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
75657,1.11.0 distribution train different with 1.8.1,2022-04-12 10:44:06+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
75655,`jit(Function)` results in double execution,2022-04-12 09:41:23+00:00,,0,3,"[Label(name=""oncall: jit"")]"
75654,jit fails when trying to assign values to model via hook,2022-04-12 08:50:35+00:00,,0,1,"[Label(name=""oncall: jit"")]"
75652,Op segfaults with ForwardAD and Subclassed Tensor as Tangent,2022-04-12 07:11:58+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: forward ad"")]"
75634,[ONNX] Enable stacktrace print for TORCH_INTERNAL_ASSERT errors in export.,2022-04-11 23:02:26+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
75625,[ONNX] Support unit tests in scripting that we already support in tracing,2022-04-11 22:23:52+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
75599,kthvalue 20x slower than sort ,2022-04-11 16:50:24+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
75586,Add ZeroTensor support for `mm`,2022-04-11 00:51:16+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""ZeroTensor"")]"
75582,Add `balance` flag to `random_split`,2022-04-10 13:26:15+00:00,,0,7,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data"")]"
75577,Cannot use socks5h proxy because of urllib: `urlopen error Remote end closed connection without response`,2022-04-09 19:08:47+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: hub"")]"
75568,mypy typing strategy for Tensor-likes (`__torch_function__`),2022-04-09 16:08:29+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
75565,make lint should advertise make setup_lint,2022-04-09 15:54:40+00:00,,0,2,"[Label(name=""module: build""), Label(name=""module: lint""), Label(name=""triaged"")]"
75562,"clang-tidy ""error: do not use const_cast"" cppcoreguidelines-pro-type-const-cast is counterproductive",2022-04-09 15:26:18+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""module: lint""), Label(name=""triaged"")]"
75556,[JIT] `torch.jit.ignore` is not working on hooks,2022-04-09 04:47:59+00:00,,0,0,"[Label(name=""oncall: jit"")]"
75554,torch.overrides testing is not catching people adding new kwargs and not passing on to handle_torch_function,2022-04-09 03:09:58+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
75549,`torch.linalg.lstsq` raises `CUBLAS_STATUS_EXECUTION_FAILED` for large `B` in CUDA tensors,2022-04-09 01:52:41+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
75512,Connection closed by peer when using dist.isend in gloo backend,2022-04-08 13:44:31+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
75510,"[doc] view appears to mean different things, `view/reshape` vs `transpose/permute`.",2022-04-08 13:29:40+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: partial aliasing""), Label(name=""module: viewing and reshaping""), Label(name=""topic: docs"")]"
75504,Profiling graphed callables or cuda graphs raises a RuntimeError,2022-04-08 09:02:47+00:00,,0,7,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: profiler""), Label(name=""module: cuda graphs"")]"
75503,make_dual errors out when primal is a Tensor and tangent is a subclass Tensor,2022-04-08 07:49:20+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: forward ad"")]"
75502,TensorBoard frontend fails to display embeddings when `add_embedding()` writes large `label_img`,2022-04-08 07:45:29+00:00,,0,2,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
75500,RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED,2022-04-08 07:26:46+00:00,,0,3,"[Label(name=""module: dependency bug""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
75495,Forward AD convolution fails for the empty backend ,2022-04-08 05:23:51+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: forward ad"")]"
75494,`torch.pinverse` on CUDA tensors produces non-optimal output for certain type of (invertible) matrix on torch > 1.7.1 but not on torch <= 1.7.1,2022-04-08 04:34:49+00:00,,0,7,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
75480,IndexError: Caught IndexError in replica 0 on device 0.,2022-04-08 02:16:32+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
75474,[NVFuser] call kernels with informative names (e.g. pow_mul_add),2022-04-07 23:27:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
75467,torch.package: log.info when loading packages w/ externed modules + documentation,2022-04-07 22:17:23+00:00,,1,0,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
75465,[JIT] Bool Should Subtype NumberType,2022-04-07 21:58:48+00:00,,0,1,"[Label(name=""oncall: jit"")]"
75462,NotImplemented confusion between __torch_function__ and __rpow__ (and other dunder magic methods),2022-04-07 21:15:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
75458,Placing model on bfloat16 on CPU make it freeze/hang,2022-04-07 20:28:28+00:00,,2,11,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""module: bfloat16""), Label(name=""module: intel"")]"
75440,[quant] PackedLinearWeight::apply_dynamic_impl does not handle ReLUFused template argument,2022-04-07 16:54:48+00:00,,0,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
75432,Rollup: Top forward-over-reverse formulas,2022-04-07 16:10:07+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: forward ad"")]"
75427,`torch.cuda.is_bf16_supported()` seem to not work properly,2022-04-07 14:37:13+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: bfloat16"")]"
75419,Require PyTorch test suite to be warnings clean,2022-04-07 13:26:47+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
100628,Feature request: fast way to approximate the diagonal of the hessian,2022-04-07 07:26:37+00:00,,0,11,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs design""), Label(name=""module: functorch"")]"
75391,Pytorch linalg test failure with cuda 11.6,2022-04-07 00:09:33+00:00,,0,10,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
75383,[ONNX] Error when exporting adaptive_max_pool2d to ONNX,2022-04-06 23:10:47+00:00,,0,5,"[Label(name=""module: crash""), Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""bug"")]"
75375,Pytorch test failure with CUDA 11.6,2022-04-06 22:29:18+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
75371,"NVFuser bad ""reshape"" performance",2022-04-06 22:03:27+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: nvfuser"")]"
75363,conv3d has numerical issue where same input produces output that are not bit-wise identical,2022-04-06 21:39:33+00:00,,0,2,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: determinism"")]"
75342,`torch.fx.operator_schemas.normalize_function` is too permissive,2022-04-06 18:16:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
75336,Libtorch Crash after Attempting to Evaluate Model after Opening an OpenGL Context,2022-04-06 17:27:53+00:00,,1,24,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
75334,ProcessGroupNCCL is relying on UB to support bool data type,2022-04-06 17:06:04+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
75309,[jit] failing OpInfo JIT tests for conv1d and complex input,2022-04-06 05:13:28+00:00,,1,5,"[Label(name=""oncall: jit"")]"
75308,Using Adaptive Model for Pytorch Mobile,2022-04-06 04:09:07+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
75287,[RFC] Consolidated and unified state_dict and load_state_dict hooks,2022-04-05 22:31:35+00:00,,1,14,"[Label(name=""module: bootcamp""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup"")]"
75280,[JIT] log_extract.py improvements,2022-04-05 21:26:42+00:00,,0,0,"[Label(name=""oncall: jit"")]"
75265,Kernel Dies while using conv2d layer / function,2022-04-05 17:57:42+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
75251,Potential runtime optimization of Mish activation,2022-04-05 09:38:52+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
75242,"large model, low memory: need `torch.load` that loads one submodule at a time",2022-04-05 01:05:43+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
75240,Large cumulative sums appear to be nondeterministic. ,2022-04-05 00:45:49+00:00,,0,25,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
75225,One of the backends for `lu_factor` fails on windows.,2022-04-04 21:31:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
75217,Storing LTC tensor shape information in jit::Value,2022-04-04 20:22:26+00:00,,0,5,"[Label(name=""oncall: jit"")]"
75215,[torch.distributed] Document bfloat16 support,2022-04-04 20:02:51+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: docs"")]"
75213,Improve wording in _store_based_barrier logging and identify ranks that have not joined,2022-04-04 19:47:35+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering"")]"
75198,`torch.cuda.get_device_name` fails to identify RTX 3090 Ti ,2022-04-04 16:36:02+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
75186,Failed to build `convert_and_benchmark.cc` due to missing `net_observer_reporter_print.h`.,2022-04-04 14:32:13+00:00,,0,5,"[Label(name=""caffe2""), Label(name=""triaged"")]"
75184,"PyTorch source code compile fail after ""Built target fbgemm_avx2""",2022-04-04 13:40:52+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
75180,Add BUILD_LAZY_CUDA_SPARSE option,2022-04-04 11:46:59+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
75173,LowRankMultivariateNormal doesn't work with 0 diagonal,2022-04-04 06:42:24+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
75172,Runtime configuration to disable TORCH_WARN temporally?,2022-04-04 06:26:33+00:00,,0,3,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""enhancement"")]"
75171,torch.jit.load fails when path contains non-ascii characters,2022-04-04 04:31:55+00:00,,0,0,"[Label(name=""oncall: jit"")]"
75168,DISABLED test_reduce_full_group_max (__main__.TestDistBackendWithSpawn),2022-04-04 03:26:28+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""skipped"")]"
75166,Disable Python mode (torch dispatch mode) inside of mode-induced __torch_dispatch__call,2022-04-04 02:44:56+00:00,,0,3,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: __torch_dispatch__"")]"
75158,Offical libtorch (pytorch c++ frontend) docker image,2022-04-03 15:36:08+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""feature""), Label(name=""triaged"")]"
75147,Dataloader hangs. Potential deadlock with `set_num_threads` in worker processes?,2022-04-02 18:00:03+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
75139,DISABLED test_post_localSGD_optimizer_parity_with_hierarchical_sgd_grad_is_view (__main__.TestDistBackendWithSpawn),2022-04-02 00:57:16+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: rocm""), Label(name=""skipped"")]"
75129,[BE] add documentation for adjust learning rate when going to distributed training,2022-04-01 19:35:52+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering"")]"
75097,destroy_process_group() has a certain probability of hangs,2022-04-01 10:09:10+00:00,,0,6,"[Label(name=""oncall: distributed"")]"
75090,torch.fx deepcopy bug,2022-04-01 06:55:38+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
75087,extend torch.distributed's `--tee` to log the nodename,2022-04-01 04:17:08+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""enhancement""), Label(name=""oncall: r2p"")]"
75052,DISABLED test_post_localSGD_optimizer_parity_with_hierarchical_sgd (__main__.TestDistBackendWithSpawn),2022-04-01 00:58:09+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: rocm""), Label(name=""skipped"")]"
75038,Generate source location information in TS LTC backend,2022-03-31 20:55:40+00:00,,0,0,"[Label(name=""oncall: jit"")]"
93745,Make it possible to use TorchDynamo from within PyTorch core,2022-03-31 20:04:27+00:00,,1,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
75031,comm hook error in BWD pass,2022-03-31 18:51:32+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
75025,torch.cuda.init() unstacks existing CUDA contexts,2022-03-31 16:57:06+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
75012,[JIT] nested dictionaries are not traced correctly.,2022-03-31 09:29:51+00:00,,1,3,"[Label(name=""oncall: jit"")]"
75005,Cannot create TorchScript file after converting into a quantized model,2022-03-31 05:54:54+00:00,,0,4,"[Label(name=""oncall: jit"")]"
75002,JIT autocasting fails on Optional[Tensor],2022-03-31 04:03:29+00:00,,0,1,"[Label(name=""oncall: jit"")]"
74991,Tensor Subclass not preserved for Tensor subclasses created via inheritance of a TensorImpl subclass,2022-03-30 22:37:22+00:00,,0,4,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: __torch_dispatch__""), Label(name=""tensor subclass"")]"
74964,Add Unit Tests for Torch.Package Subclasses [Waiting on changes to land],2022-03-30 18:11:05+00:00,,1,0,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
74956,Allow `torch.package` to accept `*.pyc` files,2022-03-30 14:25:23+00:00,,0,0,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
74953,LSTM quantization fails if proj_size > 0,2022-03-30 13:23:31+00:00,,0,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
74952,[feature request] Make `index_select` parallel.,2022-03-30 13:00:10+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
74951,[feature request] `coalesce` to support `dim` argument.,2022-03-30 12:08:06+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
74943,Calling `torch.ops.aten.add_` is ludicrously slow,2022-03-30 02:10:08+00:00,,1,8,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
74942,Store SourceDataset in MapDataset using pointer,2022-03-30 01:29:40+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
74940,Feature Request: Add J0 J1 J2 H0 H1 H2 Bessel functions,2022-03-30 01:06:39+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: special"")]"
74937,[docs] RandomSampler has unrendered back-ticks,2022-03-30 01:01:49+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
74935,[RFC]A suggestion of channels last memory format implementation for 3D tensor,2022-03-30 00:08:17+00:00,,0,12,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: memory format"")]"
74911,"Include finfo(dtype).[min, max, eps, tiny] in the extremal test case",2022-03-29 16:29:11+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
74909,torch.package fails to import if dataclass and __future__.annotations present,2022-03-29 15:47:08+00:00,,0,0,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
74907,[Proposal] Use batched oprations to accelerate PowerSGD,2022-03-29 13:47:21+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""oncall: distributed""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""module: mta"")]"
74904,Adding novel 'AdaFamily' optimizer ,2022-03-29 10:08:43+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""function request"")]"
74901,"torch.fx.wrap will not work, when encapsulate the code",2022-03-29 07:50:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
74896,Install PyTorch from source on power machine,2022-03-29 07:15:57+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER"")]"
74884,Problematic ASGD Optimizer,2022-03-29 01:58:52+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: LrScheduler"")]"
74876,Failure to set number of threads on AWS Lambda,2022-03-29 00:56:24+00:00,,0,3,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
74855,Enable dtype keyword argument for to_dense method,2022-03-28 19:37:31+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""enhancement"")]"
74842,error in quantization by quantize_fx.prepare_fx,2022-03-28 17:58:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
74839,Feature request: Root-finding functionality (like scipy.optimize.root_scalar),2022-03-28 17:15:39+00:00,,0,11,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: scientific computing"")]"
74824,C10d Elastic Training master_addr ERROR,2022-03-28 08:51:32+00:00,,0,21,"[Label(name=""oncall: distributed""), Label(name=""oncall: r2p"")]"
74809,Incorrect results for `torch.distributed.gather` for tensor created from permuted NumPy array,2022-03-27 13:53:47+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
74801,[ONNX] Export fails with inplace assignments,2022-03-26 15:17:28+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""onnx-needs-info"")]"
74799,Irrelevant warning during ONNX export of torch.jit.ScriptFunction: Model has no forward function,2022-03-26 14:35:33+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: onnx""), Label(name=""onnx-triaged"")]"
74788,[Structured] Make it possible to override create_out implementation on a per dispatch key basis (structured sparse),2022-03-26 02:26:31+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: structured kernels"")]"
74771,[bug] `torch.multinomial` should throw error as documented,2022-03-25 19:27:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""topic: docs"")]"
74748,[jiterator] Jiterate Complex Ops,2022-03-25 15:35:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: jiterator"")]"
74746,Change the type hint for nn.Module.__call__ to be friendly to overrides.,2022-03-25 15:01:38+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""module: typing""), Label(name=""triaged""), Label(name=""enhancement"")]"
74739,GradScaler support FP16 gradients?,2022-03-25 06:47:59+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
74734,RuntimeError: Unconvertible NCCL type Short when sending torch.cuda.ShortTensor.,2022-03-25 03:15:29+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
93743,Support data-dependent control flow operators,2022-03-25 00:54:29+00:00,,1,15,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
74679,Embedding isn't determinstic on linux-xenial-cuda11.3-py3.7-gcc7,2022-03-24 14:52:55+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: embedding"")]"
74677,`check_batched_forward_grad` fails for `torch.norm` and related ops,2022-03-24 14:43:22+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: batching""), Label(name=""module: norms and normalization"")]"
74670,Can't install Pytorch,2022-03-24 11:05:16+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
74669,String dtypes for torch Tensors,2022-03-24 10:26:06+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged"")]"
74666,Re-initializing torch.distributed process_group hangs with destroy_process_group,2022-03-24 05:56:04+00:00,,0,4,"[Label(name=""oncall: distributed"")]"
74642,Some easy way to add xfails to OpInfos,2022-03-23 21:38:20+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: testing"")]"
74634,Sampling Issue With Distributions,2022-03-23 20:22:57+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: half"")]"
74627,Feature request: INT4 format support,2022-03-23 18:54:05+00:00,,2,20,"[Label(name=""oncall: quantization""), Label(name=""feature""), Label(name=""triaged"")]"
74620,Improve sharding algorithm for ASAN (any maybe other jobs as well),2022-03-23 17:04:46+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement"")]"
74616,"__rpow__(self, other) OpInfo should not test the case where `other` is a Tensor",2022-03-23 15:28:17+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged"")]"
74614,compilation error with PyTorch v1.11 for CPU on ppc64le,2022-03-23 14:08:12+00:00,,0,18,"[Label(name=""triaged""), Label(name=""module: POWER"")]"
74613,OpInfo request for `nn.functional` and `unbind`,2022-03-23 14:02:06+00:00,,0,0,"[Label(name=""high priority""), Label(name=""module: tests""), Label(name=""triaged"")]"
74605,torch.profiler.profile does't work well for CPU model when not using torch.profiler.schedule ,2022-03-23 09:45:16+00:00,,0,6,"[Label(name=""oncall: profiler"")]"
74604,"Training, Forward / backward pass with _different_ batch-size, no speedup observed when backward pass has smaller batch-size",2022-03-23 08:36:15+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
74602,My_rank in the implementation of torch.distributed.scatter_object_list should be global,2022-03-23 06:14:44+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
74593,torch.nn.ConvTranspose2d's example in docstring is invalid,2022-03-23 01:02:34+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
74590,[CTA] Let's Stamp Out Flaky Tests!,2022-03-22 23:07:39+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""oncall: jit""), Label(name=""module: sparse""), Label(name=""module: onnx""), Label(name=""oncall: quantization""), Label(name=""module: multiprocessing""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""module: optimizer""), Label(name=""module: dataloader""), Label(name=""module: cuda""), Label(name=""module: rocm""), Label(name=""module: tests""), Label(name=""module: hub""), Label(name=""module: data parallel""), Label(name=""module: linear algebra""), Label(name=""module: rpc""), Label(name=""oncall: profiler""), Label(name=""module: mta""), Label(name=""onnx-triaged""), Label(name=""oncall: r2p"")]"
74589,Test test_ops_jit is taking too much time on ASAN,2022-03-22 23:00:41+00:00,,0,1,"[Label(name=""oncall: jit"")]"
74588,[FSDP]  using CPUOffload creates 3-10x slowdown due to slow cpu optimizer step/update,2022-03-22 22:50:02+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
74554,Specifying left-right-padding as tuple for asymmetric padding,2022-03-22 17:06:28+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: padding"")]"
74547,importing open3d before pytorch causes matmul to produce a segfault,2022-03-22 15:30:55+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas""), Label(name=""module: regression""), Label(name=""module: third_party"")]"
74544,Many inplace operators are not being tested for variant consistency (test_variant_consistency_eager),2022-03-22 14:48:36+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
74540,No factory functions for strided quantized tensors,2022-03-22 13:50:03+00:00,,0,6,"[Label(name=""oncall: quantization""), Label(name=""feature""), Label(name=""low priority""), Label(name=""triaged"")]"
74539,Making PyTorch more pythonic:  the PyTorch functions should be inspectable.,2022-03-22 13:46:53+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
74537,ComplexHalf Coverage Tracker,2022-03-22 13:35:08+00:00,,1,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: half"")]"
74531,Feature Request: torch.testing.make_scalar (make_tensor for scalars),2022-03-22 08:15:23+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: testing"")]"
74528,Supports for dist.send/dist.recv sending and recving torch.shorttensor,2022-03-22 07:06:43+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: c10d""), Label(name=""function request"")]"
74519,Lazy TS Test Failures,2022-03-22 03:32:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
74514,Figure out a lint for directly returning a nullptr instead of raising python_error,2022-03-22 01:26:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""release notes: python_frontend"")]"
74503,Compilation error on M1 Mac,2022-03-21 22:15:36+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
74500,One should be able to query if a DecorateInfo is a xfail or skip,2022-03-21 21:47:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: testing"")]"
74491,__torch_function__ is hitting private functions in some cases,2022-03-21 20:09:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: __torch_function__"")]"
74485,dir(torch._VF) doesn't work,2022-03-21 19:09:44+00:00,,0,1,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""release notes: python_frontend"")]"
74454,torch has no attribute sparse_csr_tensor,2022-03-21 06:14:51+00:00,,0,20,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
74442,kron has unnecessary and undocumented dependence on memory layout,2022-03-20 22:17:05+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
74422,Embedding Pytorch in C++ using pybind fails on interpreter shutdown,2022-03-19 01:30:46+00:00,,0,2,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: pybind""), Label(name=""module: third_party"")]"
74421,"can not build pytorch, failing due to missing _ctypes module",2022-03-18 23:35:14+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
74420,`torch.histogram` has wrong output dtype and doesn't support integer inputs,2022-03-18 23:13:11+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: sorting and selection"")]"
74415,"Warning: ""Specified kernel cache directory could not be created""",2022-03-18 15:02:22+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: jiterator"")]"
74411,"UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.",2022-03-18 08:19:12+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
74398,_run_ninja_build failing with clang,2022-03-18 00:17:51+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
74393,Quantized cannot inference with cuda,2022-03-17 22:36:41+00:00,,1,5,"[Label(name=""oncall: quantization""), Label(name=""module: cuda""), Label(name=""triaged"")]"
74391,Can this cudaDeviceSynchronize call be removed?,2022-03-17 21:49:05+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
74389,torch.package unpickling transforms: ModuleNotFoundError: No module named 'torch._C._linalg'; 'torch._C' is not a package,2022-03-17 21:04:28+00:00,,0,3,"[Label(name=""module: pickle""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
74384,Package and Deploy: Generate External Python Registration files at runtime [WIP],2022-03-17 19:47:17+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: deploy"")]"
93739,"[Dynamo] Prints, logging, and warnings",2022-03-17 16:01:44+00:00,,0,1,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
93737,Improve handling of generators,2022-03-17 15:33:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
74363,"Efficient very large (e.g., 31x31) depth-wise convolution",2022-03-17 04:38:06+00:00,,0,2,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""needs research"")]"
74337,None returned from data loader causes debugging difficulty from collate function,2022-03-16 21:10:04+00:00,,0,5,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
74329,CompositeImplicitAutograd addr implementation does not have correct behavior for bool (meta gives wrong dtype),2022-03-16 20:13:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: meta tensors"")]"
74328,instantiate_device_type_tests is misnamed,2022-03-16 20:05:49+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: testing"")]"
74324,torch.combinations requires unnecessary CUDA sync,2022-03-16 19:26:57+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""topic: performance"")]"
74323,[c10d] `gather`/`scatter` inconsistency behavior on non-dst/src rank,2022-03-16 19:21:38+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: c10d"")]"
74320,Make OpInfo repr more useful,2022-03-16 19:05:52+00:00,,0,3,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: testing"")]"
74301,Error in lobpcg when using largest=False,2022-03-16 15:11:14+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: masked operators"")]"
74300,repeat_interleave is not meta friendly; not transform friendly either,2022-03-16 14:42:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""tensor subclass"")]"
74299,Gradients tests are very time consuming,2022-03-16 14:32:57+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""module: ci""), Label(name=""triaged"")]"
74296,Time Gated Lstm,2022-03-16 13:42:51+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
74295,"TypeError: new_empty(): argument 'size' (position 1) must be tuple of ints, not list",2022-03-16 13:40:47+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
74290,Loading of packaged model object fails with torch==1.11.0,2022-03-16 10:37:57+00:00,,0,1,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
74282,RuntimeError: cuDNN error: CUDNN_STATUS_VERSION_MISMATCH for torchvision models,2022-03-16 05:40:45+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""module: vision"")]"
74281,Move torchbench workflow to `workflow_dispatch`?,2022-03-16 05:03:09+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
74272,[PyTorch] Lightweight dispatch,2022-03-16 00:57:53+00:00,,1,1,"[Label(name=""oncall: mobile""), Label(name=""mobile_perf"")]"
74368,"Can't download torch vision models for older versions via torch.hub.load: ""multiple choices""",2022-03-15 21:53:43+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: hub""), Label(name=""module: models"")]"
74256,Create secure credential storage for metrics credentials and associated documentation on how to regenerate them if needed,2022-03-15 20:21:20+00:00,,1,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
74248,dir() on torch.ops.aten doesn't work,2022-03-15 18:45:57+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""tensor subclass"")]"
74236,"""histogram_cpu"" not implemented for 'Int'",2022-03-15 09:26:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
74235,RuntimeError: CUDA error: unspecified launch failure,2022-03-15 09:23:09+00:00,,0,32,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
74222,Autograd API to get saved for backwards tensors for an autograd graph,2022-03-15 03:38:33+00:00,,0,1,"[Label(name=""module: double backwards""), Label(name=""module: autograd""), Label(name=""triaged"")]"
74221,`package.PackageExporter` does not actually appear to have a `file_structure` method,2022-03-15 03:10:23+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
93724,Don't over-specialize on list append/clear,2022-03-15 02:46:40+00:00,,1,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
74218,Cannot get op through FX when using nn.Sequential,2022-03-15 02:28:16+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
74208,DISABLED test_trace_buffer_slice (__main__.TestFX),2022-03-14 23:11:14+00:00,,0,2,"[Label(name=""triaged""), Label(name=""skipped""), Label(name=""module: fx"")]"
74187,[docker] test_corrcoef_cpu_complex64 fails on CPU build,2022-03-14 19:52:57+00:00,,0,3,"[Label(name=""module: tests""), Label(name=""triaged"")]"
74185,[DDP] Parallelize initialization collectives,2022-03-14 19:45:31+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
74180,DISABLED test_init_rpc_twice (__main__.TensorPipeRpcTest),2022-03-14 18:41:19+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: rpc""), Label(name=""skipped"")]"
74167,Slower performance of `torch.mm` method with sparse CSR tensor,2022-03-14 15:50:55+00:00,,1,5,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: mkl"")]"
74162,consume_prefix_in_state_dict_if_present can not remove prefix of _metadata.,2022-03-14 09:15:00+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
74155,[Android Studio] DefaultCPUAllocator: not enough memory: you tried to allocate 280166432 bytes,2022-03-14 01:29:24+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: android"")]"
74153,[BE][Docs][FSDP] Clarify microbatching support and tradeoffs,2022-03-13 23:05:19+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
74152,All-caps names for pages are confusing,2022-03-13 20:22:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: doc infra"")]"
74148,powersgd can not get linear growth due to  extra 2 times allreduce ,2022-03-13 13:31:08+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""topic: performance"")]"
74146,RuntimeError: Connection reset by peer when backened by NCCL,2022-03-13 11:56:36+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: nccl"")]"
74143,Tracing model parameter shapes without instantiating the model parameters,2022-03-13 04:49:16+00:00,,0,12,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
74138,`torch.set_printoptions` overwrites settings of its own previous calls,2022-03-12 03:44:45+00:00,,0,6,"[Label(name=""module: printing""), Label(name=""triaged""), Label(name=""module: ux"")]"
74134,No module named 'pygame': soft_actor_critic,2022-03-12 01:33:57+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
93720,Support capturing code in exception handlers,2022-03-11 20:11:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
74115,DistributedDataParallel high peak memory usage with find_unused_parameters=True,2022-03-11 18:17:58+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
74112,torch.jit.script does not custom state_dicts,2022-03-11 17:26:42+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
74101,C++ Context::setDeterministicAlgorithms default 2nd arg not defined in header,2022-03-11 14:49:00+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: determinism"")]"
74095,torchscript RNN modules cannot move between GPU,2022-03-11 10:12:45+00:00,,0,2,"[Label(name=""oncall: jit"")]"
74092,Two consecutive nn.LayerNorm are used in transformer model when norm_first is False,2022-03-11 06:42:21+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
74058,torch.fx.symbolic_trace is non-deterministic,2022-03-10 21:27:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
74052,assertEqual gives confusing error when comparing tuple with Tensor with Tensor,2022-03-10 20:14:15+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
74041,FSDP does not work on GLOO backend,2022-03-10 17:45:18+00:00,,1,7,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
74036,torch.nn.Module.__init__ does not call super().__init__,2022-03-10 16:45:42+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged"")]"
74034,[torch.onnx] ONNX export failed on adaptive_avg_pool2d because input size not accessible not supported,2022-03-10 14:26:04+00:00,,1,12,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
74032,ONNX export of torch.histc,2022-03-10 13:25:08+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
74030,"[JIT] tuple of float is accepted in List[float] but not in Union[float, List[float]]",2022-03-10 12:43:32+00:00,,1,4,"[Label(name=""oncall: jit"")]"
74024,Ambiguous docstring on `register_module_forward_hook`,2022-03-10 07:36:35+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
74022,Inconsistent implementation on SWA,2022-03-10 07:25:56+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
74019,https://discuss.pytorch.org/ is down,2022-03-10 06:31:19+00:00,,0,6,"[Label(name=""triaged"")]"
74014,torch.utils.data.Dataset combined with pycuda issue,2022-03-10 03:18:39+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: data"")]"
73994,Lazy: add support for index ops,2022-03-09 23:51:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
73992,[FX] Tensor constants are not lifted to attributes in direct Graph construction,2022-03-09 23:34:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
73989,Invalid example tensor: detectron2_maskrcnn,2022-03-09 22:41:22+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
73985,Release note bot is not sending messages on PRs anymore,2022-03-09 22:20:34+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
73972,Forward_AD and Torchscript Functions results in Nones or wrong values.,2022-03-09 17:06:44+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: autograd""), Label(name=""module: forward ad"")]"
73960,processes hang when executing cross-machine asynchronous P2P communication on NCCL backend,2022-03-09 13:47:41+00:00,,1,6,"[Label(name=""oncall: distributed""), Label(name=""module: nccl""), Label(name=""module: c10d"")]"
73941,"[Quant] Framework observes weight in convert, changing numerics",2022-03-08 21:48:52+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
73930,"User raised TypeError from __torch_dispatch__ gets turned into generic ""unsupported operand type"" message",2022-03-08 18:38:02+00:00,,0,7,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
73924,torch.cuda.amp: Remove SPMD DDP doc portion,2022-03-08 16:34:25+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
73920,"pytorch/pytorch:1.8.1-cuda10.2-cudnn7-devel docker container contains cudnn 8.2, not 7.x as the name implies",2022-03-08 16:19:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: docker"")]"
73916,Invalid code inrandom_ kernel,2022-03-08 12:15:22+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
73910,Adam optimizer doesn't work with CyclicLR scheduler but works with OneCycleLR.,2022-03-08 08:26:26+00:00,,0,5,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
73909,SummaryWriter reports encoding error,2022-03-08 07:22:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
73885,operation not supported crash when initializing RPC tensorpipe,2022-03-07 23:01:57+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: crash""), Label(name=""triaged"")]"
73883,Possible issue with memory allocation.,2022-03-07 22:49:59+00:00,,0,3,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: numpy"")]"
73871,ONNX: Document public API for shape inference for custom symbolics,2022-03-07 20:41:30+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
73870,max_pool1d() returns when given invalid large `kernel_size` inputs,2022-03-07 20:32:16+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: edge cases"")]"
73869,[FSDP][BE] TestAutoWrap should inherit from MultiProcessTestCase,2022-03-07 20:17:58+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
73860,tensor subclass and `__torch_function__` performance issues,2022-03-07 18:25:50+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
73848,torch.distributions.multinomial.Multinomial (an example mistake of docs)?,2022-03-07 09:22:50+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""module: docs""), Label(name=""triaged"")]"
73841,max_pool1d(): `RuntimeError: [enforce fail at CPUAllocator.cpp:68] . DefaultCPUAllocator: can't allocate memory`,2022-03-06 22:18:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: pooling"")]"
73840,"max_pool1d(): argument 'dilation' must be tuple of ints, but found element of type int at pos 1",2022-03-06 21:57:33+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: pooling""), Label(name=""module: edge cases"")]"
73838,"Tensor.new_tensor now preserves input tensor device, making it inconsistent with documentation",2022-03-06 16:18:28+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: tensor creation"")]"
73833,Support unscaling grad on CPU,2022-03-06 06:37:55+00:00,,2,1,"[Label(name=""feature""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
73832,Legacy sparse tensor constructor (e.g. torch.cuda.sparse.FloatTensor) silently ignores device kwarg,2022-03-06 04:10:45+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: tensor creation"")]"
73829,"Run libtorch examples, export error ""undefined reference to xxx""",2022-03-05 14:01:44+00:00,,0,6,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""module: abi""), Label(name=""triaged"")]"
73828,torch.profiler schedule function doesn't work as expected,2022-03-05 13:53:59+00:00,,0,0,"[Label(name=""oncall: profiler"")]"
73826,Better Error report in torch.distribution.*.sample (when passing a non-iterable),2022-03-05 08:04:10+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""module: error checking""), Label(name=""triaged"")]"
73825,TypeError: cannot pickle 'torch._C._distributed_c10d._ProcessGroupGloo' object,2022-03-05 07:54:10+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""module: ddp"")]"
73792,Bug: torch.distributions.mixture_same_distribution._pad_mixture_dimension,2022-03-04 17:03:58+00:00,,0,2,"[Label(name=""high priority""), Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
73784,[FSDP] Add Gradient Accumulation Outside `no_sync()` Compatibility with CPU Offloading,2022-03-04 14:45:45+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
73767,[Discussion][FSDP] Enhancements to auto_wrap_policy,2022-03-04 00:41:08+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
73764,Group convolution slower than manually running separate convolutions in CUDA streams,2022-03-03 23:45:33+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
73755,CI: Bake as many dependencies as we can in the AMI (windows),2022-03-03 20:45:59+00:00,,1,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
73738,torch.ao.quantization.ReuseInputObserver should also reuse the dtype of the input,2022-03-03 14:44:46+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
73722,Why is distributed RPC using the default pickler?,2022-03-03 03:43:23+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
73721,Audit exception rewrapping to ensure stack traces are preserved,2022-03-03 03:28:05+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
73714,Release pytorch docker images with newer python versions,2022-03-03 01:15:47+00:00,,1,14,"[Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""module: docker"")]"
73711,"Refactor/Cleanup LazyTensor, LTCTensorImpl, Data",2022-03-03 01:05:09+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
73710,Refactor/Cleanup Lazy Tensor Core,2022-03-03 01:02:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
73709,DropIT: Dropping Intermediate Tensors for Memory-Efficient DNN Training,2022-03-03 00:48:13+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
73699,How to get tolerance override in OpInfo-based test?,2022-03-02 22:48:11+00:00,,0,8,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: testing"")]"
73697,Improving error message RuntimeError: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.,2022-03-02 22:28:46+00:00,,0,20,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
73683,test_broadcast_coalesced_nccl fails on A100 GPUs,2022-03-02 20:07:12+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
73665,Nice way to override string representation of tensor subclasses,2022-03-02 17:13:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""tensor subclass"")]"
73661,`torch.fx.ProxyableClassMeta` does not work if Proxy objects are not included in constructor arguments,2022-03-02 16:54:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
73656,torchrun: Hostname/endpoint mismatch not handled,2022-03-02 16:01:16+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: c10d"")]"
73646,Pure C binding/wrapper with libtorch for inference applications,2022-03-02 14:41:18+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged"")]"
73640,[Feature Request] Allow torch.Generator to be passed to torch.nn.init functions,2022-03-02 10:21:39+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
73638,addcdiv is failing the ASAN test for zero divisors,2022-03-02 08:10:43+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""module: tests""), Label(name=""triaged"")]"
73608,`torch.jit.load` fails when function parameters use non-ASCII characters,2022-03-01 23:09:45+00:00,,0,0,"[Label(name=""oncall: jit"")]"
73604,Support views in custom autograd functions,2022-03-01 21:21:40+00:00,,0,7,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable""), Label(name=""tensor subclass"")]"
73602,Report DDP efficiency metric to users and guide them for setting up DDP correctly,2022-03-01 20:39:34+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
73600,Add a section in DDP tutorial to explain why DDP sometimes is slower than local training and how to improve it,2022-03-01 20:34:58+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
73585,Add optional log_scale argument for torch.distributions.Normal,2022-03-01 18:52:51+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
73571,conv with padding='same' fails on lazy torchscript nvfuser,2022-03-01 16:49:08+00:00,,0,0,"[Label(name=""oncall: jit"")]"
73568,Bug when using `nn.Linear`,2022-03-01 16:20:12+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
73563,Pytorch Installation from source fails,2022-03-01 08:59:45+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
73556,Files exported by `profiler.export_stacks()` are not compatible with flamegraph,2022-03-01 02:22:37+00:00,,0,2,"[Label(name=""oncall: profiler"")]"
73554,Build failure using GCC 11.2.0,2022-03-01 01:27:40+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: third_party"")]"
73542,Investigate why tensor shapes are not populated when printing WorkNCCL for broadcast,2022-02-28 23:07:43+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: c10d""), Label(name=""module: ddp"")]"
73537,Functionalization doesn't work when applied twice with wrapper tensor,2022-02-28 21:25:17+00:00,,0,7,"[Label(name=""triaged""), Label(name=""tensor subclass""), Label(name=""module: functionalization"")]"
73534,"PyTorch for ROCm on a Supported Device Throws ""hipErrorNoBinaryForGpu""",2022-02-28 21:11:21+00:00,,0,4,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
73531,Mention docker build process in RELEASE.md and automate building those for release,2022-02-28 20:08:35+00:00,,1,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: docker"")]"
73517,Teach tools.codegen.api.translate about IValues,2022-02-28 16:59:53+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: codegen"")]"
73515,`torch.distributed.nn.functional.all_gather`: Tensors must be contiguous,2022-02-28 16:28:24+00:00,,1,6,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: c10d"")]"
73513,Wrapper tensor level confusion,2022-02-28 16:07:41+00:00,,0,4,"[Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: __torch_dispatch__""), Label(name=""tensor subclass"")]"
73507,Implement SiLU method for the QuantizedCPU backend,2022-02-28 14:44:23+00:00,,0,2,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
73506,Idiom for extensible string printing for TensorImpl subclasses,2022-02-28 14:36:51+00:00,,0,4,"[Label(name=""module: internals""), Label(name=""module: printing""), Label(name=""triaged"")]"
73505,Figure out what to do with functions that take both Tensor and TensorOptions,2022-02-28 14:03:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
73504,`ge` and `div` behaves differently when converting an overflow number,2022-02-28 12:52:37+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: edge cases"")]"
73502,`storage` does support `complex32` tensor,2022-02-28 11:23:57+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: half"")]"
73501,`index_copy` has different index behavior with `index_fill`,2022-02-28 11:15:12+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
73488,After XNNPack update `TestXNNPACKSerDes.test_linear` started to fail,2022-02-28 00:44:45+00:00,,1,4,"[Label(name=""high priority""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: xnnpack"")]"
73487,PyTorch not recognizing GPU on WSL - installed cudnn and cuda,2022-02-27 23:35:31+00:00,,0,42,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: wsl"")]"
73484,Rename `keep_vars` in `nn.Module.state_dict`,2022-02-27 17:09:52+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
73479,Strange case of empty non-coalesced sparse tensor,2022-02-26 22:22:32+00:00,,0,16,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
73475,different results on each batch_size in torch==1.10.2+cu113 on RTX 3080,2022-02-26 18:38:13+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
73474,DISABLED test_python_ir_utils (__main__.TestJit),2022-02-26 17:33:59+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""skipped"")]"
73469,torch.fx failed when tracing functions from other Libs.,2022-02-26 07:16:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
73466,[feature request] torch.hub.load_state_dict_from_url to be replaced by a new good general download-a-file function and to also support local paths and google drive links / private github release links,2022-02-26 01:33:00+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: hub"")]"
73461,`TestCommonCUDA.test_noncontiguous_samples_pca_lowrank_cuda_float32` fails on A100 due to TF32 operation in `svd_lowrank`,2022-02-25 23:49:38+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: tf32"")]"
73446,[FSDP] test full_state_dict if we are already in full parameter summoning context,2022-02-25 18:56:30+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
93719,Use bytecode rewriting to offer a __future__ feature,2022-02-25 15:47:56+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: pt2""), Label(name=""module: dynamo"")]"
73425,ufunc codegen support for dtypes that are supported on CUDA but not CPU,2022-02-25 14:12:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
73424,"""munmap_chunk(): invalid pointer"" interaction error with pytorch (< 1.10), pybind, and cv_bridge",2022-02-25 13:12:06+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: lts"")]"
73419,test_jit_cuda_fuser fails on non-CUDA node for 1.11.0rc3,2022-02-25 10:42:13+00:00,,0,0,"[Label(name=""oncall: jit"")]"
73417,MaybeEncodingError: Error sending result,2022-02-25 09:40:19+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
73413,Conv3D consumes lots of memory on Mac with Apple Silicon,2022-02-25 03:03:24+00:00,,0,1,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: macos"")]"
73412,Build from source failed,2022-02-25 02:33:16+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
73394,Make it easier to figure out if packages need to be interned/mocked/externed,2022-02-24 21:58:45+00:00,,1,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
73380,elastic/rendezvous: _matches_machine_hostname doesn't resolve hostnames fully,2022-02-24 20:51:50+00:00,,2,1,"[Label(name=""triaged""), Label(name=""module: elastic""), Label(name=""oncall: r2p""), Label(name=""topic: bug fixes"")]"
73359,"Pytorch Typing, for Tensor type annotations",2022-02-24 16:41:20+00:00,,0,2,"[Label(name=""module: typing""), Label(name=""triaged"")]"
73355,Review and refactor  the way libcublas static libraries are linked,2022-02-24 14:43:12+00:00,,0,0,"[Label(name=""module: build""), Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""module: cublas"")]"
73354,Add the capability to export GradMultiply to ONNX,2022-02-24 12:17:59+00:00,,1,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
73352,Segfault on unloading a model,2022-02-24 09:34:17+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: crash""), Label(name=""module: cpp"")]"
73349,Large performance difference of loss.backward() between torch-1.9.0 and torch-1.8.0,2022-02-24 09:07:58+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: regression"")]"
73332,BatchNorm with LSTM in DistributedDataParallel throws one of the variables needed for gradient computation has been modified by an inplace operation,2022-02-24 00:35:04+00:00,,0,4,"[Label(name=""oncall: distributed"")]"
73304,"fx.symbolic_trace docs says that it ignores different values of concrete_args, but it doesn't",2022-02-23 18:43:31+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
73303,"[FSDP] test state_dict APIs with arguments such as destination, prefix",2022-02-23 18:41:53+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
73294,Internal assert failed at rref_context.cpp,2022-02-23 15:55:24+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: crash"")]"
73268,Add detection of interned submodule of externed module in PackageExporter,2022-02-23 01:22:11+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: deploy"")]"
73236,Inconsistent numpy indexing,2022-02-22 20:33:51+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing"")]"
73222,Having rrelu functional + module take a generator object to match native functions entry,2022-02-22 18:58:06+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: random"")]"
73218,"This is not completely a bug, but something that will be amazing if can be taken care of regarding nn.DataParallel.",2022-02-22 18:44:54+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
73205,Bug in label smoothing with ignored samples,2022-02-22 12:35:23+00:00,,0,4,"[Label(name=""module: loss""), Label(name=""triaged"")]"
73196,`torch.pow` errors out on specific input,2022-02-21 21:26:48+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
73190,Segmentation fault in max_pool1d,2022-02-21 17:37:00+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: pooling""), Label(name=""module: edge cases"")]"
73186,Segmentation fault in fractional_max_pool3d,2022-02-21 17:31:43+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: cpu""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: pooling"")]"
73185,Segmentation fault in fractional_max_pool2d,2022-02-21 17:30:40+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: cpu""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: pooling"")]"
73182,Segmentation fault in _sobol_engine_scramble_,2022-02-21 17:28:15+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: edge cases"")]"
73181,Segmentation fault in _sobol_engine_initialize_state_,2022-02-21 17:26:58+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: edge cases"")]"
73180,Segmentation fault in _sobol_engine_ff_,2022-02-21 17:25:46+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: edge cases"")]"
73179,Floating point exception in _nnpack_spatial_convolution,2022-02-21 17:23:42+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: cpu""), Label(name=""module: error checking""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: nnpack"")]"
73176,"Cuda lacks checking of ""out of bound""",2022-02-21 14:44:36+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
73175,[feature request] Support tensor count vector argument in torch.split ,2022-02-21 14:25:48+00:00,,0,5,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement"")]"
73174,`LayerNorm` triggers INTERNAL ASSERT,2022-02-21 12:55:16+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: cpu""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
73172,LazyLinear with equal in_features and out_features,2022-02-21 12:13:41+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
73171,libtorch need operator= in torch::Device,2022-02-21 10:47:57+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement"")]"
73161,native_batch_norm and native_layer_norm have strange epsilon behaviors,2022-02-20 19:29:35+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
73160,Preprocessing function for backend coreml is not registered,2022-02-20 18:55:40+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: mobile"")]"
73154,`max_unpool2d` returns a tensor with negative dimension,2022-02-20 10:20:12+00:00,,0,3,"[Label(name=""high priority""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: pooling"")]"
73150,How do we handle metadata-modifying in-place operators (like `squeeze_`) with `__torch_dispatch__`?,2022-02-20 00:56:15+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
73145,DISABLED test_sparse_addmm_cpu_bfloat16 (__main__.TestSparseCPU),2022-02-19 21:02:09+00:00,,1,22,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""skipped"")]"
73143,Add nan-safe einsum and bilinear,2022-02-19 16:04:31+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra""), Label(name=""needs design"")]"
73142,Support passing Python code as a string to torch.jit.script,2022-02-19 11:18:56+00:00,,0,3,"[Label(name=""oncall: jit"")]"
73141,libtorch: `DistributedRandomSampler` uses the same random order in every epoch,2022-02-19 10:19:49+00:00,,0,15,"[Label(name=""triaged""), Label(name=""module: data"")]"
73137,`create_graph=True` results in grad_fn error for differentiable functions,2022-02-19 03:42:48+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
73134,Test functionalization doesn't run,2022-02-19 01:11:57+00:00,,1,1,"[Label(name=""module: internals""), Label(name=""triaged"")]"
73131,Support writing tensorboard traces to AWS S3 (and other cloud storage services) in profiler,2022-02-19 00:23:03+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
73121,make c++ logger preamble meaningful,2022-02-18 22:30:07+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: c10d"")]"
73113,PyTorch fails to compile on gcc 11.2 due to breakpad,2022-02-18 20:34:28+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
73083,Improve test_test_history.py,2022-02-18 16:57:26+00:00,,1,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
73081,Additional out of the box DDP comm hooks,2022-02-18 16:34:09+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering"")]"
73080,[FSDP checkpoint] Test replace_by_prefix util,2022-02-18 15:43:26+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
73074,Multiple new caffe2-related build failures.,2022-02-18 12:38:27+00:00,,0,1,"[Label(name=""module: build""), Label(name=""caffe2""), Label(name=""triaged"")]"
73072,Exporting model to TorchScript fails once I load the saved torchscript file,2022-02-18 10:13:12+00:00,,0,0,"[Label(name=""oncall: jit"")]"
73070,`enumerate_support` for continuous distributions,2022-02-18 08:21:01+00:00,,1,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
73065,`index_fill_` accepts wrong dtype for meta tensors,2022-02-18 07:36:53+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: meta tensors"")]"
73062,"Clang Compilation Error: more than one constructor applies to convert from ""ptrdiff_t"" to ""c10::Scalar""",2022-02-18 04:05:06+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: macos"")]"
73051,Cannot install latest pytorch into Docker on Apple M1,2022-02-17 23:24:21+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
73050,aten::batch_norm schema does not mention mutation of running_mean/running_var,2022-02-17 23:01:41+00:00,,0,7,"[Label(name=""triaged"")]"
73048,Enhanced local_state_dict FSDP checkpoint tests,2022-02-17 22:54:39+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
73046,Run test_fsdp_core parity test for FSDP model checkpoint,2022-02-17 22:38:58+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""module: fsdp"")]"
73043,[Main Issue] FSDP Model Checkpoint,2022-02-17 22:32:10+00:00,,2,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
73034,Is it intentional that PyTorch linux binaries aren't manylinux1 compliant?,2022-02-17 21:08:57+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
73016,Unable to build and use libtorch function via pybind11: undefined symbol error upon import,2022-02-17 17:11:11+00:00,,0,14,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
73009,Improve loading for nn.modules.lazy.LazyModuleMixin,2022-02-17 15:09:19+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
73008,Followup requires for MKL link issue / cannot find -lmkl_core,2022-02-17 14:55:55+00:00,,0,7,"[Label(name=""module: binaries""), Label(name=""module: cpp""), Label(name=""triaged"")]"
73007,Feature: support better rendering for ..deprecated Sphinx directive,2022-02-17 14:29:33+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
73003,pin_memory hangs instead of throwing,2022-02-17 08:52:24+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""module: cuda""), Label(name=""triaged"")]"
72960,Refactor/Cleanup lazy IR codegen,2022-02-17 00:34:22+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
72948,Feature: a consistent Python and C++ logging facility that handles different classes of warnings,2022-02-16 21:58:59+00:00,,1,10,"[Label(name=""module: logging""), Label(name=""triaged"")]"
72933,Why there are 8 flavors of iOS build jobs for every commit,2022-02-16 20:01:24+00:00,,0,7,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: ios"")]"
72915,Is the current behavior with addcmul and integer dtypes intended?,2022-02-16 15:13:21+00:00,,0,3,"[Label(name=""module: tests""), Label(name=""triaged"")]"
72911,Vectorized Jacobian and Hessian errors with ffts,2022-02-16 12:13:19+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: vmap"")]"
72909,"`torch.svd_lowrank` should set the default value of `q` as `min(6, m, n)`",2022-02-16 11:33:01+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
72906,Replace deprecated distutils package in torch/utils/tensorboard/__init__.py,2022-02-16 08:32:26+00:00,,0,2,"[Label(name=""oncall: visualization"")]"
72897,Hanging Validation,2022-02-16 00:19:13+00:00,,0,11,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""module: amp (automated mixed precision)""), Label(name=""module: ddp"")]"
72880,Bazel fails in an obscure way if submodules are not initialized,2022-02-15 20:30:01+00:00,,0,3,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: third_party""), Label(name=""module: bazel"")]"
72874,SequentialLR scheduler incorrect initialization,2022-02-15 19:53:38+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
72859,Profiler crashes with ProfilerActivity.CUDA on AWS p4d.24xlarge with A100-SXM4-40GB,2022-02-15 16:57:09+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: cuda""), Label(name=""oncall: profiler"")]"
72858,Profiler crashes in export_chrome_trace with seg fault if any of record_shapes=True or with_flops=True,2022-02-15 16:54:31+00:00,,0,2,"[Label(name=""oncall: profiler"")]"
72850,N-dimensional Convolutions,2022-02-15 13:33:52+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement"")]"
72835,torch.distributed hangs at barrier(),2022-02-15 00:35:42+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
72831,Toggling deterministic mode for individual autograd backward functions,2022-02-15 00:20:51+00:00,,1,11,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: determinism"")]"
72824,Some loss functions support `dtype` broadcast but some do not,2022-02-14 23:54:56+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
72821,"`{Batch,Instance}Norm{1,2,3}d` works when `num_features != C`!",2022-02-14 23:43:38+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
72814,Standardize Naming for Workflows/Jobs,2022-02-14 21:58:57+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
72791,"why ram memory surges while loading model, with change in torch load device from CPU to GPU",2022-02-14 09:49:00+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
72788,Docs bug: type annotations for linspace (and logspace) start and end arguments is wrong,2022-02-14 07:37:24+00:00,,1,8,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
72784,Torch version in docker container does not match tag,2022-02-14 01:10:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: docker"")]"
72782,Error during training: falseINTERNAL ASSERT FAILED,2022-02-13 23:31:53+00:00,,0,12,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
72775,[vulkan] Vulkan backend fails creating tensor on x86_64 Linux,2022-02-13 12:31:36+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: vulkan"")]"
72768,Add NCCL and MPI version printing to torch.utils.collect_env,2022-02-12 18:40:57+00:00,,0,0,"[Label(name=""module: collect_env.py""), Label(name=""triaged""), Label(name=""module: mpi""), Label(name=""enhancement""), Label(name=""module: nccl"")]"
72766,Feature Request: Deterministic MaxPool3d and AvgPool3d,2022-02-12 06:44:23+00:00,,0,7,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""module: pooling"")]"
72759,Add softplus inverse,2022-02-12 00:25:16+00:00,,0,4,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""function request"")]"
72749,"pytorchmergebot doesn't react to comments left from ""files"" tab",2022-02-11 22:03:32+00:00,,1,6,"[Label(name=""module: ci""), Label(name=""triaged"")]"
72746,CPU execution/dispatch time dominates and slows down small TorchScript GPU models ,2022-02-11 21:33:48+00:00,,0,0,"[Label(name=""oncall: jit"")]"
72737,Pattern Matching with Tensors,2022-02-11 20:05:48+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""function request"")]"
72714,Add `pct_end` parameter to `OneCycleLR`,2022-02-11 15:32:04+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: LrScheduler"")]"
72712,Better support for pypip packages implementing torch cuda extentions,2022-02-11 14:48:25+00:00,,0,6,"[Label(name=""module: binaries""), Label(name=""feature""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""release notes: releng"")]"
72711,Feature request: Implement `gelsd` backend for `linalg.lstsq` via `linalg.svd`,2022-02-11 13:54:22+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
72709,Feature: Use iterative refinement algorithm from cuSOLVER for the least-squares solver on CUDA,2022-02-11 11:24:33+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
72672,nn.functional No-batch-dim support should have OpInfo examples,2022-02-10 21:02:50+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: tests""), Label(name=""triaged"")]"
72659, Add a unit test which uses an extension module + ordered importer ,2022-02-10 16:57:15+00:00,,1,0,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
72650,Some inplace ops don't raise on incompatible shapes and meta device,2022-02-10 07:58:15+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: meta tensors"")]"
72643,upstream `apex.normalization.FusedRMSNorm`,2022-02-10 01:41:39+00:00,,0,24,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
72617,TorchScript assertion failure for a `List[...]` inside a `NamedTuple`,2022-02-09 21:06:39+00:00,,0,0,"[Label(name=""oncall: jit"")]"
72591,"Can't forward pass conv2d with kernel_size=1, and padding=1",2022-02-09 17:30:59+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: nnpack""), Label(name=""module: arm"")]"
72582,"Avoid using thrust:: directly, use THRUST_NS_QUALIFIER:: instead",2022-02-09 12:48:12+00:00,,0,7,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
72581,Zero-copy on shared memory of NVIDIA Jetson devices,2022-02-09 12:14:21+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: jetson"")]"
72580,"Setting a list of Modules as an attribute does not work like setting a Module as an attribute, and throws no warning",2022-02-09 11:30:40+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged"")]"
72558,Pin dependencies + expand the current linter ,2022-02-08 23:14:27+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""module: ci""), Label(name=""triaged"")]"
72556,"Clarify test dependencies (e.g., into a test-requirements.txt file)",2022-02-08 23:11:30+00:00,,0,2,"[Label(name=""module: bootcamp""), Label(name=""module: ci""), Label(name=""triaged"")]"
72555,Enforce quotas on CI users,2022-02-08 23:05:01+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement"")]"
72545,Split up torch.distributions docs into multiple pages,2022-02-08 20:55:14+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""module: docs""), Label(name=""triaged"")]"
72537,Feature: Add tril_embed and triu_embed,2022-02-08 19:28:17+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: tensor creation"")]"
72536,Remove Caffe2,2022-02-08 19:26:11+00:00,,0,0,"[Label(name=""triage review""), Label(name=""caffe2""), Label(name=""better-engineering"")]"
72525,KL divergence between two Continuous Bernoulli is negative,2022-02-08 18:00:16+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
72516,test_del (jit.test_builtins.TestBuiltins) fails due to highlight assertions,2022-02-08 10:38:51+00:00,,1,2,"[Label(name=""oncall: jit"")]"
72498,torch.jit.script + torch.split + onnxruntime incompatibility,2022-02-08 06:21:36+00:00,,0,1,"[Label(name=""oncall: jit"")]"
72482,Improve torch::deploy documentation,2022-02-08 00:31:23+00:00,,2,0,"[Label(name=""module: deploy""), Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
72452,Re-raise the exception when the `forward` of a parametrization raises,2022-02-07 21:02:10+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: nn.utils.parametrize"")]"
72450,Memory parity with JAX attention,2022-02-07 20:20:45+00:00,,0,20,"[Label(name=""module: memory usage""), Label(name=""oncall: transformer/mha"")]"
72448,Use Module `__getattr__` in `torch.ops` and friends,2022-02-07 19:45:42+00:00,,0,2,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
72435,ProcessGroupWrapper: Additional Improvements,2022-02-07 16:48:29+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: c10d""), Label(name=""module: ddp"")]"
72421,Feature Request: A simpler decorator for disabling mixed precision,2022-02-07 14:02:58+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
72418,input.dim() == 4 INTERNAL ASSERT FAILED mkldnn/Pooling.cpp:201,2022-02-07 10:57:21+00:00,,0,1,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: pooling"")]"
72408,Matrix multiplication is 30 times slower for integers than floats on CPU,2022-02-07 04:58:18+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
72393,Some system-installed headers are mistakenly used.,2022-02-06 13:41:37+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
72388,ArgMax for Multi Dimensional Tensor,2022-02-05 07:24:22+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: ux""), Label(name=""module: reductions"")]"
72366,Custom ProcessGroup Destructor Not Correctly Called in PT 1.10,2022-02-04 21:50:26+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: c10d""), Label(name=""module: ddp"")]"
72362,Add ZeroTensor fastpath for torch.bmm,2022-02-04 20:32:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""ZeroTensor"")]"
72361,Add ZeroTensor fastpath for torch.baddbmm,2022-02-04 20:31:08+00:00,,0,0,"[Label(name=""triaged""), Label(name=""ZeroTensor"")]"
72359,Add ZeroTensor fastpath for torch.addmv,2022-02-04 20:29:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""ZeroTensor"")]"
72358,Add ZeroTensor fastpath for torch.addbmm,2022-02-04 20:28:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""ZeroTensor"")]"
72347,Add ZeroTensor fastpath for torch.addcmul,2022-02-04 18:37:16+00:00,,0,0,"[Label(name=""triaged""), Label(name=""ZeroTensor"")]"
72346,torch.distributed.new_group() should consolidate the type of rank list,2022-02-04 18:35:27+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
72345,Add ZeroTensor fastpath for torch.addmm,2022-02-04 18:34:48+00:00,,1,0,"[Label(name=""triaged""), Label(name=""ZeroTensor"")]"
72341,InstanceNorm doesn't preserve memory format,2022-02-04 17:55:53+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: norms and normalization"")]"
72338,[JIT] Channels last optimization pass,2022-02-04 16:52:36+00:00,,0,0,"[Label(name=""oncall: jit"")]"
72332,Ability to assign to `tensor.require_grad` might lead to bugs,2022-02-04 12:30:55+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: ux"")]"
72330,Add and Mul torch tensors on Metal (IOS),2022-02-04 10:05:57+00:00,,1,2,"[Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
72329,Can't Export Pytorch Model to ONNX,2022-02-04 09:45:13+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
72317,Feature request: a mode to disallow calling prototype or beta features,2022-02-04 07:34:32+00:00,,0,2,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""topic: bc breaking""), Label(name=""module: python frontend"")]"
72295,[JIT][Autocasting] Add autocasting & constant propagation as part of freezing,2022-02-03 21:50:06+00:00,,0,0,"[Label(name=""oncall: jit"")]"
72283,Add Sparsemax function to libtorch,2022-02-03 19:28:54+00:00,,0,7,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
72280,DISABLED test_memory_profiler (__main__.TestProfiler),2022-02-03 19:11:52+00:00,,0,11,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""oncall: profiler"")]"
72263,Removing deprecated `cpp_custom_type_hack`,2022-02-03 16:02:21+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""oncall: quantization""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""oncall: profiler"")]"
72258,NotImplementedError in torch.distributions,2022-02-03 15:35:18+00:00,,0,4,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
72257,`torch.hasnan`,2022-02-03 14:58:47+00:00,,0,3,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: NaNs and Infs"")]"
72254,Caffe2 uses FFMPEG functions that are deprecated in FFMPEG 4.0 and gone in 5.0,2022-02-03 11:50:46+00:00,,0,4,"[Label(name=""module: dependency bug""), Label(name=""caffe2""), Label(name=""triaged"")]"
72253,Transformer Initialization,2022-02-03 10:08:48+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""oncall: transformer/mha"")]"
72252,Mobile: minimize inferencing latency by having better control over available CPU cores,2022-02-03 09:54:52+00:00,,1,0,"[Label(name=""oncall: mobile"")]"
72240,recurrent neural network module,2022-02-03 05:47:56+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
72220,[JIT] Assert that the autodiff implementation of backward() returns the correct number of values,2022-02-03 00:28:14+00:00,,1,0,"[Label(name=""oncall: jit"")]"
72194,`TestCase.assertEqual` has `equal_nan` default to `True`,2022-02-02 19:41:34+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: testing"")]"
72189,test_fn_fwgrad_bwgrad_[trapezoid|trapz]_cuda_complex128 causes CUDA memory exception,2022-02-02 18:35:18+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""ZeroTensor"")]"
72182, test_fn_fwgrad_bwgrad_special_ndtr_cuda_float64 fails,2022-02-02 17:13:51+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""ZeroTensor"")]"
72179,"Mechanism for Tensor subclasses to ""disable autograd""",2022-02-02 16:31:21+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: __torch_dispatch__"")]"
72175,"Torch.onnx.export, RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",2022-02-02 13:27:31+00:00,,0,14,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
72146,Also allow dicts as type of `params=` field in param groups of optimizers,2022-02-01 22:17:10+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
72138,[RFC] PyTorch Sharder for distributed training,2022-02-01 20:29:49+00:00,,2,7,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""sharded_tensor"")]"
72134,Add support for `complex` `mean` to the `normal` operator,2022-02-01 20:06:18+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: complex"")]"
72117,Force PyTorch to clear CUDA cache,2022-02-01 17:11:52+00:00,,0,8,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
72112,Unable to parse IR generated by Lazy Tensor Core with TorchScript Backend,2022-02-01 15:53:46+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""module: lazy"")]"
72110,Conversion Error in pytorch mobile with metal,2022-02-01 15:26:18+00:00,,0,2,"[Label(name=""module: memory format""), Label(name=""oncall: mobile"")]"
72107,DistributedDataParallel creates too many threads,2022-02-01 13:47:57+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader""), Label(name=""better-engineering""), Label(name=""module: ddp"")]"
72106,Update MKL version used with MAGMA,2022-02-01 13:38:35+00:00,,0,4,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: magma"")]"
72105,ImportError: cannot import name '_VF' from partially initialized module 'torch',2022-02-01 12:50:53+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""low priority""), Label(name=""triaged"")]"
72099,halt or exit function implementation,2022-02-01 03:06:47+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: c10d"")]"
72065,Batched sparse-sparse matrix multiplication/ sparse torch.einsum,2022-01-31 16:26:53+00:00,,0,8,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
72061,"`svd_backward`: does not handle inputs of rank `r < min(m, n)`.",2022-01-31 15:00:33+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
72055,index_add : Inconsistent between CPU and CUDA,2022-01-31 10:08:26+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""triaged"")]"
72053,index_put : INTERNAL ASSERT FAILED,2022-01-31 08:36:29+00:00,,1,1,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged"")]"
72046,Building PyTorch with Vulkan backend don't work,2022-01-30 18:20:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vulkan"")]"
72045,`pip==22.0` breaks installation process,2022-01-30 14:42:55+00:00,,0,14,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
72041,RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward,2022-01-29 19:25:30+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: nn.utils.parametrize"")]"
72034,Bug about distributed launch,2022-01-29 01:51:55+00:00,,0,6,"[Label(name=""oncall: distributed"")]"
72029,JIT function crashing or failing (depending on profiling),2022-01-29 00:48:44+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
72025,[c10d] destruction of Store objects,2022-01-28 23:17:11+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
72022,[PT-D] To make the ShardedTensor Reshard more generic,2022-01-28 22:59:32+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""sharded_tensor"")]"
71988,multiple PRs on pytorch are closed by push to unrelated branches such as pytorch-canary,2022-01-28 15:26:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: third_party"")]"
71978,from_blob / make_tensor support MemoryFormat,2022-01-28 06:18:58+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
71951,Multivariate normal defined by eigendecomposition ,2022-01-27 23:42:23+00:00,,0,3,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
71929,[JIT] Results are different when saving in TorchScript Format through train/eval mode,2022-01-27 19:04:24+00:00,,0,1,"[Label(name=""oncall: jit"")]"
71919,Graph Mode Quantization does not keep NamedTuple Information,2022-01-27 16:12:51+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: fx"")]"
71918,Support mixed python scalar/tensor types for torch.clamp's min/max args,2022-01-27 16:01:59+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
71912,`torch._sources.normalize_source_lines()` and consequently `torch.jit.script` fail with lambda functions,2022-01-27 13:46:02+00:00,,0,2,"[Label(name=""oncall: jit"")]"
71911,Functions depending on SVD are broken for inputs with non-finite values with MKL 2022+ and OpenBLAS 0.3.15+,2022-01-27 12:55:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mkl""), Label(name=""module: linear algebra""), Label(name=""module: openblas"")]"
71896,CUDA Graph API Improvement,2022-01-27 01:58:33+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
71889,Make scale/zero_point accessible from TorchScript traced module for QFlaotFunctional modules,2022-01-26 23:00:15+00:00,,0,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
71877,Add `output_size` argument to `Upsample` forward method (just like for `ConvTranspose` Modules),2022-01-26 20:08:41+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
71872,Clarify the behavior of DataLoader sampler and batch_sampler parameters,2022-01-26 19:06:53+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
71855,Regression in multi-node training speed with Transformers + PyTorch,2022-01-26 12:57:06+00:00,,0,3,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""oncall: transformer/mha""), Label(name=""module: ddp"")]"
71849,"addcmul, byte_channels_last fail test_nnc_correctness opinfo tests under UBSAN",2022-01-26 07:00:16+00:00,,0,0,"[Label(name=""module: sanitizers""), Label(name=""NNC"")]"
71843,Migrate master to main: https://github.com/pytorch/tutorials ,2022-01-26 04:19:51+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71842,Migrate master to main: https://github.com/pytorch/ignite ,2022-01-26 04:19:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71841,Migrate master to main: https://github.com/pytorch/ELF ,2022-01-26 04:19:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71840,Migrate master to main: https://github.com/pytorch/captum ,2022-01-26 04:19:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71839,Migrate master to main: https://github.com/pytorch/glow ,2022-01-26 04:19:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71838,Migrate master to main: https://github.com/pytorch/serve ,2022-01-26 04:19:37+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71837,Migrate master to main: https://github.com/pytorch/xla ,2022-01-26 04:19:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71836,Migrate master to main: https://github.com/pytorch/QNNPACK ,2022-01-26 04:19:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71835,Migrate master to main: https://github.com/pytorch/tnt ,2022-01-26 04:19:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71834,Migrate master to main: https://github.com/pytorch/hub ,2022-01-26 04:19:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71833,Migrate master to main: https://github.com/pytorch/extension-cpp ,2022-01-26 04:19:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71832,Migrate master to main: https://github.com/pytorch/android-demo-app ,2022-01-26 04:19:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71831,Migrate master to main: https://github.com/pytorch/translate ,2022-01-26 04:19:16+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71830,Migrate master to main: https://github.com/pytorch/elastic ,2022-01-26 04:19:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71828,Migrate master to main: https://github.com/pytorch/tvm ,2022-01-26 04:19:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71826,Migrate master to main: https://github.com/pytorch/ios-demo-app ,2022-01-26 04:19:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71825,Migrate master to main: https://github.com/pytorch/accimage ,2022-01-26 04:19:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71824,Migrate master to main: https://github.com/pytorch/extension-ffi ,2022-01-26 04:18:58+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71823,Migrate master to main: https://github.com/pytorch/nestedtensor ,2022-01-26 04:18:56+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71822,Migrate master to main: https://github.com/pytorch/cppdocs ,2022-01-26 04:18:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71821,Migrate master to main: https://github.com/pytorch/workshops ,2022-01-26 04:18:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71820,Migrate master to main: https://github.com/pytorch/extension-script ,2022-01-26 04:18:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71819,Migrate master to main: https://github.com/pytorch/java-demo ,2022-01-26 04:18:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71818,Migrate master to main: https://github.com/pytorch/csprng ,2022-01-26 04:18:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71817,Migrate master to main: https://github.com/pytorch/pytorch_sphinx_theme ,2022-01-26 04:18:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71816,Migrate master to main: https://github.com/pytorch/rfcs ,2022-01-26 04:18:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71815,Migrate master to main: https://github.com/pytorch/add-annotations-github-action ,2022-01-26 04:18:37+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71814,Migrate master to main: https://github.com/pytorch/ossci-job-dsl ,2022-01-26 04:18:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71813,Migrate master to main: https://github.com/pytorch/pytorch-integration-testing ,2022-01-26 04:18:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71812,Migrate master to main: https://github.com/pytorch/pytorch-ci-dockerfiles ,2022-01-26 04:18:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71810,Migrate master to main: https://github.com/pytorch/labeler-github-action ,2022-01-26 04:17:56+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71806,Migrate master to main: https://github.com/pytorch/pytorch,2022-01-26 03:24:13+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: infra"")]"
71784,[JIT] addmm differs from eager mode,2022-01-25 22:21:52+00:00,,0,1,"[Label(name=""oncall: jit"")]"
71774,matmul returns uninitialized memory for int64 tensors with inner dimension of zero,2022-01-25 18:11:30+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: correctness (silent)"")]"
71772,[ONNX] Support aten::bilinear,2022-01-25 17:51:43+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
71760,Adapting the citation style according to GitHub's CFF,2022-01-25 11:40:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: doc infra"")]"
71725,"When someone calls detach() on a __torch_dispatch__ object, detach() gets called twice",2022-01-24 21:48:40+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
71721,Improve performance of index for quantized ops,2022-01-24 21:10:28+00:00,,0,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
71715,[FX] Support call_method in NormalizeArgs,2022-01-24 18:44:37+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
71704,M1 Pro Apple Silicon chip support.,2022-01-24 15:14:36+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: nnpack""), Label(name=""module: arm"")]"
71698,[libtorch]can not save a  vector<int> to AutogradContex->saved_data.,2022-01-24 09:57:12+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""module: autograd""), Label(name=""triaged"")]"
71697,Libtorch dlls delayed loading,2022-01-24 09:01:42+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: static linking"")]"
71689,torch.distributions.categorical.Categorical does not work with 0 batch size,2022-01-24 02:08:52+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
71683,EMA optimizer: class-form and function-form (using new foreach_lerp) - can be used for explicit robust updates of BatchNorm stats,2022-01-23 10:06:36+00:00,,0,7,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""function request""), Label(name=""module: mta"")]"
71682,_GLIBCXX_USE_CXX11_ABI=0 does not work when building from source code,2022-01-23 06:13:47+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
71678,torch.bmm backward with sparse input,2022-01-22 22:13:28+00:00,,0,7,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
71673,Fancy indexing bug when combining masks with indexes,2022-01-22 11:22:12+00:00,,0,18,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing"")]"
71671,Many APIs `INTERNAL ASSERT FAILED` when promoting `complex32` dtype,2022-01-22 06:13:50+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: complex"")]"
71660,Build release binaries with USE_GLOG=ON by default,2022-01-21 23:09:43+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: infra"")]"
71636,`torch.median` will return -2147483648 when input is an empty tensor,2022-01-21 14:09:14+00:00,,0,3,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
71635,"`torch.nn.functional.{instance, batch}_norm` trigger INTERNAL ASSERT FAILED when input is empty tensor with `complex32`",2022-01-21 14:03:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: half"")]"
71633,Negative Exponents of Int tensors result in output of zero,2022-01-21 12:24:54+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
71631,Wrapping make_graphed_callables with autocast issue,2022-01-21 07:48:49+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)""), Label(name=""module: cuda graphs"")]"
71630,More than 4 Dimensions for Channel Last Memory Format,2022-01-21 07:12:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: memory format"")]"
71629,"`torch.{max,min}` have strange error message when `input.numel()==0`",2022-01-21 06:37:39+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: reductions"")]"
71613,NCCL Backend does not support ComplexFloat data type,2022-01-21 00:59:17+00:00,,0,27,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: complex""), Label(name=""module: nccl""), Label(name=""has workaround"")]"
71595,Optimizer Overlap: Follow up features,2022-01-20 22:39:48+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
71575,Better Engineering: test_..._mem_overlap in test_torch.py should be ported to ErrorInputs,2022-01-20 19:54:42+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
71574,Better Engineering: Create test_dlpack,2022-01-20 19:52:00+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
71552,[docs] Tensor.uniform_ docs are not clear about whether from/to boundary values are included in sampling or not,2022-01-20 15:06:26+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: random"")]"
71548,Support freezing of models containing ModuleContainerIndex,2022-01-20 12:54:35+00:00,,0,0,"[Label(name=""oncall: jit"")]"
71545,pip installation SSLError [SSL: CERTIFICATE_VERIFY_FAILED],2022-01-20 08:58:23+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged"")]"
71543,Initialize DataLoader workers in parallel,2022-01-20 07:15:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: data"")]"
71541,"`torch.sub` behaves differently with `add`, `mul`, `div`",2022-01-20 06:23:00+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
71518,Compilation instructions are not exhaustive: <<parameter packs not expanded with ‘...’>> on Fedora 35/CUDA 11.6,2022-01-20 01:13:24+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged"")]"
71495,Memory Leak in PyTorch 1.10.1,2022-01-19 21:36:16+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
71479,[numpy compat] torch.stack and torch.tensor doesn't support nested list+tensors (NumPy does support) - at least document the difference in the error message,2022-01-19 16:37:46+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""needs design""), Label(name=""module: viewing and reshaping"")]"
71477,"`torch.cum{min,max}, torch.sort, argsort` do not check the `dim` when the input is 0-d tensor",2022-01-19 15:51:54+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
71475,The signature of `torch.nanmedian` in the doc is wrong,2022-01-19 14:35:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
71473,pytorch installation error with cuda!!,2022-01-19 13:35:40+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
71472,Feature request: Add complex support to `torch.nanmean`,2022-01-19 09:28:08+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: NaNs and Infs""), Label(name=""module: reductions"")]"
71471,"[pytorch1.5.0] subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '-j', '6']' returned non-zero exit status 2.",2022-01-19 09:17:27+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
71470,torch.jit.script failed to compile nn.MultiheadAttention when specifying the kdim and vdim parameters.,2022-01-19 07:52:50+00:00,,0,1,"[Label(name=""oncall: jit"")]"
71465,torch.nn.LayerNorm support for arbitrary axis in order to allow NCHW application,2022-01-19 05:31:20+00:00,,0,19,"[Label(name=""high priority""), Label(name=""module: nn""), Label(name=""triaged"")]"
71446,Discussion of TorchQuantum and QuantumNAS,2022-01-18 21:03:12+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""complex_autograd"")]"
71414,Gamma distribution returns some wrong extreme values ,2022-01-18 17:19:37+00:00,,0,0,"[Label(name=""module: numerical-stability""), Label(name=""module: distributions""), Label(name=""module: cuda""), Label(name=""triaged"")]"
71409,Random Shuffle along Axis,2022-01-18 16:17:30+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: random"")]"
71407,"Push to fork failed with cryptic ""refusing to allow a Personal Access Token to create or update workflow `.github/workflows/run_torchbench.yml` without `workflow` scope""",2022-01-18 15:40:32+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
71404,[feature request] [discussion] Generalize / recommend behavior of reset_parameters (and potentially rename),2022-01-18 12:40:01+00:00,,0,11,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: fx"")]"
71403,[discussion] torch.flatten to allow unsqueeze of inexisting dimension,2022-01-18 12:15:26+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: batching"")]"
71398,cannot pickle 'torch._C.Generator' object for torch.Generator,2022-01-18 06:20:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: random"")]"
71396,a lot nightly builds are canceled due to VM errors since Jan14,2022-01-18 04:07:54+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged"")]"
71392,Error in `torch.trapz` documentation,2022-01-18 01:50:10+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""triaged"")]"
71391,Calling .backward() inside of an LBFGS closure function throws an exception in Libtorch v1.6.0+,2022-01-18 01:37:36+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: regression"")]"
71389,Create a nested directory while saving objects using `torch.save`,2022-01-17 20:57:58+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""enhancement"")]"
71386,Direct Implementation of K-Nearest neighbor (KNN) in pytorch,2022-01-17 16:37:11+00:00,,0,11,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs design"")]"
71383,Allow to shutdown persistent workers,2022-01-17 12:04:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: multithreading"")]"
71379,Leaky cmake cuda compile options,2022-01-17 06:28:16+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cpp-extensions""), Label(name=""module: cpp""), Label(name=""triaged"")]"
71377,is_alias_of support for storageless tensors,2022-01-17 06:18:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: partial aliasing""), Label(name=""module: ddp""), Label(name=""module: lazy"")]"
71367,"F.cross_entropy do not have a deterministic implementation,  adding deterministic support for this operation.",2022-01-16 12:13:33+00:00,,0,0,"[Label(name=""module: loss""), Label(name=""triaged"")]"
71366,nn.Batchnorm1d input shape notation inconsistency,2022-01-16 09:45:43+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
71364,make pytorch support different hardware acceleratioin configuration,2022-01-16 07:27:28+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""low priority""), Label(name=""triaged"")]"
71359,"Torchvision Installation Logic Python vs C++ ""Mismatch""",2022-01-15 23:36:07+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
71357,[feature request] Multidim support for softmax/log_softmax/softmin ,2022-01-15 16:20:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: norms and normalization"")]"
71340,locally installed PyTorch upgraded or superseded on windows/macos conda tests,2022-01-15 00:15:59+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: lts"")]"
71331,Change the order of checks for tensor indexing errors,2022-01-14 21:29:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
71330,[RFC] Gossip SGD (as a DDP Communication Hook),2022-01-14 21:27:21+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: ddp"")]"
71329,"[RFC] Implement array methods (extend, insert, pop, etc) for container classes",2022-01-14 21:15:37+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
71322,Allow users to pass use_reentrant=False to checkpoint_sequential,2022-01-14 19:47:51+00:00,,0,0,"[Label(name=""module: checkpoint""), Label(name=""triaged"")]"
71317,[torch.deploy] Using zipped torch modules in torch.deploy interpreter ,2022-01-14 18:45:45+00:00,,1,0,"[Label(name=""triaged""), Label(name=""days""), Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
71309,"path\\tp\\torch\\torch.h(14,1): fatal error C1001: Internal compiler error.",2022-01-14 15:18:12+00:00,,1,9,"[Label(name=""module: dependency bug""), Label(name=""module: windows""), Label(name=""module: cpp""), Label(name=""triaged"")]"
71305,Convert a tensor with type caffe2::TypeMeta to std::vector,2022-01-14 12:32:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: meta tensors"")]"
71303,[RFC] Cross-Process Performance Analysis: Straggler Detection,2022-01-14 09:31:25+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: c10d""), Label(name=""module: ddp"")]"
71301,Why AMP make backward speed more slow?,2022-01-14 07:51:21+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
71300,"Kernel fusion for Gather, Apply, Scatter (GAS) model",2022-01-14 07:40:52+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
71288,`memory_format` argument isn't supported in torchscript for tensor.is_contiguous(),2022-01-13 23:51:05+00:00,,0,0,"[Label(name=""oncall: jit"")]"
71286,"[JIT][tensorexpr] cat, batch_norm opinfo tests failing",2022-01-13 23:22:28+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
71277,JIT support for `torch.__version__` & str comparison operations,2022-01-13 19:58:49+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp"")]"
71274,upstream `apex.optimizers.FusedAdam` to replace `torch.optim.AdamW`,2022-01-13 19:34:59+00:00,,0,12,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
71272,"UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate   warnings.warn(""Seems like `optimizer.step()` has been overridden after learning rate scheduler",2022-01-13 19:03:46+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
71266,"""Memory Leak"" when creating an iterator from a tensor",2022-01-13 14:32:52+00:00,,0,2,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
71263,AdaptiveAvgPool2d Failed to jit script,2022-01-13 12:06:29+00:00,,0,4,"[Label(name=""oncall: jit"")]"
71261,The jit model will fail when calling the torch.autograd.functional.jacobian with multiple inputs and setting the vectorize to true.,2022-01-13 09:32:04+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""NNC"")]"
71249,[docs] nn.Sequential docs should list member functions,2022-01-12 23:47:00+00:00,,0,8,"[Label(name=""module: docs""), Label(name=""triaged"")]"
71228,1.10.11 fails to compile libtorch_cpu with -fopenmp,2022-01-12 18:16:52+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: undefined reference"")]"
71227,Move torch::deploy tests to their own workflow job,2022-01-12 18:11:57+00:00,,1,2,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: deploy"")]"
71222,torch.linalg.lstsq is nondeterministic,2022-01-12 17:16:23+00:00,,0,26,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""module: linear algebra"")]"
71211,Lack of type check in `nn.functional` APIs,2022-01-12 14:57:05+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
71210,axis to dim remapping is not working for flip and roll,2022-01-12 13:57:58+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: python array api"")]"
71209,support setting `keepdim` without setting `dim`,2022-01-12 13:56:27+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: python array api"")]"
71205,Possible security issue of `torch.hub.load`,2022-01-12 08:53:50+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: hub"")]"
71204,`torch.diag` unexpectedly fails,2022-01-12 08:41:06+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: viewing and reshaping"")]"
71203,Keys of a `ModuleDict` cannot have the same name as existing `ModuleDict` class attributes.,2022-01-12 07:41:29+00:00,,0,9,"[Label(name=""module: nn""), Label(name=""triaged"")]"
71195,DISABLED test_send_recv_all_to_all (__main__.ProcessGroupGlooTest),2022-01-12 02:13:14+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""skipped"")]"
71187,DataLoader tests are quite flaky,2022-01-11 23:04:08+00:00,,0,16,"[Label(name=""high priority""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
71165,traced module fails on second execution,2022-01-11 18:22:14+00:00,,0,3,"[Label(name=""oncall: jit"")]"
71156,Slow backward for matrix multiplication of two sparse COO tensors on CPU,2022-01-11 11:02:07+00:00,,0,9,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
71155,PyTorch bug: Cannot pass gradient through index_add,2022-01-11 07:45:14+00:00,,1,5,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""module: correctness (silent)"")]"
71152,clang format hash mismatched for linux64,2022-01-11 06:28:10+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""module: lint""), Label(name=""triaged"")]"
71151,The implement of `containsTensorType(const TypePtr& t)` in jit pass `PropagateInputShapes` ignore some situation?,2022-01-11 04:53:02+00:00,,0,0,"[Label(name=""oncall: jit"")]"
71149,Memory leak in distributions.multivariate_normal.MultivariateNormal,2022-01-11 01:58:24+00:00,,0,6,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: distributions""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
71134,Slowdown in torch.distributed.new_group when scaling to large clusters. ,2022-01-10 23:40:28+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
71117,Rollup: forward-mode AD operator coverage,2022-01-10 18:23:09+00:00,,0,6,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: forward ad"")]"
71095,`TestOperators.test_c2_op` : different raw data generated for the test in my local and CI environment,2022-01-10 15:19:58+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
71084,"`torch.{inverse,cholesky}` have wrong shape check of square matrices",2022-01-10 08:38:16+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
71082,`torch.combinations` will allocate large memory when `r` is greater than the length of input,2022-01-10 08:28:08+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
71078,"`torch.nn.{Constant,Zero}Pad` unexpectedly fail",2022-01-10 06:04:25+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: padding"")]"
71076,Error in `torch.Tensor.logit` documentation,2022-01-10 04:44:04+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
71071,Feature Request: torch.special.ellipe,2022-01-09 20:09:52+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: special"")]"
71069,C++ torch::nn::Sequential clone() method overwrites child module names,2022-01-09 16:32:58+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
71059,`torch.scatter` will return random value when `input` is empty tensor,2022-01-08 15:37:31+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
71058,`torch.Tensor.where` cannot work when `y` is float,2022-01-08 15:18:11+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: type promotion"")]"
71049,Distributed broadcast fails with simple GPU tensor on Windows + GLOO,2022-01-08 05:49:44+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
71029,"remote failure INTERNAL ASSERT FAILED at ""../torch/csrc/distributed/rpc/rref_context.cpp"":389",2022-01-07 22:28:28+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
71028,Skip LSTM quantization by default in get_default_qconfig_dict and get_default_qat_qconfig_dict,2022-01-07 22:24:49+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
71022,installation of pytorch `cpuonly` from conda with `nomkl` installs `mkl`,2022-01-07 21:15:33+00:00,,1,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
70995,Rewrite tests in test_nn to not depend on LAPACK,2022-01-07 15:32:45+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""actionable"")]"
70970,argmin/argmax incorrect doc for the first form,2022-01-07 04:33:48+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: reductions"")]"
70954,Training grouped Conv2D is slow,2022-01-06 23:32:39+00:00,,0,16,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
70951,A diagnostics mode to report when constraints aren't being met for optimal performance,2022-01-06 23:08:32+00:00,,0,7,"[Label(name=""oncall: profiler"")]"
70940,"ThreadLocalState::setThreadLocalState is not setting the ""enabled"" flag of SavedTensorDefaultHooks",2022-01-06 18:58:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: multithreading"")]"
70931,Redefinition of `cub` namespace misses Debug,2022-01-06 17:59:24+00:00,,0,8,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
70926,Feature Request: Implement `torch.sparse.spdiags` and `torch.sparse.diags`,2022-01-06 14:55:24+00:00,,1,10,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
70925,allow `dim=None` in `concat`,2022-01-06 14:51:17+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping""), Label(name=""module: python array api"")]"
70924,change supported arguments for parameter `dim` in `squeeze`,2022-01-06 14:50:45+00:00,,0,4,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: python array api""), Label(name=""topic: bc breaking"")]"
70921,`sort` should only return the sorted input,2022-01-06 14:36:23+00:00,,0,1,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: sorting and selection""), Label(name=""module: python array api""), Label(name=""topic: bc breaking"")]"
70920,`unique` should be split into four partial functions,2022-01-06 14:19:19+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: python array api"")]"
70919,`linspace` should support an `endpoint` parameter,2022-01-06 14:05:24+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: tensor creation""), Label(name=""module: python array api"")]"
70916,uint8 scalar tensors cannot be used for integer indexing,2022-01-06 13:54:27+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: python array api"")]"
70915,`arange` should return empty array if bounds are inconsistent with step sign,2022-01-06 13:45:38+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensor creation""), Label(name=""module: python array api"")]"
70914,support setting `step` in `arange` without setting `end`,2022-01-06 13:43:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensor creation""), Label(name=""module: python array api"")]"
70910,`eye` should support other diagonals than the main one,2022-01-06 11:12:45+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: tensor creation""), Label(name=""module: python array api"")]"
70906,`full` should take an integer size,2022-01-06 10:49:23+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: tensor creation""), Label(name=""module: python array api"")]"
70901,Accuracy problem of `torch.batch_norm_gather_stats_with_counts` when `running_mean` is half tensor,2022-01-06 08:53:29+00:00,,0,4,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: half"")]"
70892,Memory leak while training model generated by torch.fx.symbolic_trace() in data parallel mode,2022-01-06 06:46:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
70870,Add flag for functional.Jacobian to return output as well,2022-01-05 21:01:32+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement"")]"
70865,Support hooks-based checkpointing API with DDP,2022-01-05 19:56:33+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
70755,DISABLED test_barrier_timeout_group (__main__.TestDistBackendWithSpawn),2022-01-05 17:47:14+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""skipped"")]"
70754,DISABLED test_all_reduce_coalesced_group_min (__main__.TestDistBackendWithSpawn),2022-01-05 17:45:57+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""skipped"")]"
70753,DISABLED test_gpu_simple (__main__.TensorPipeCudaDistAutogradTest),2022-01-05 17:45:50+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""module: rpc""), Label(name=""skipped"")]"
70735,named tensor doesn't work with deepcopy,2022-01-05 16:53:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
70702,conv3d padding=`same` gradgradcheck fails on CUDA,2022-01-05 15:20:17+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: determinism"")]"
70701,AdaptiveAvgPool1d - RuntimeError: shmem_size <= sharedMemPerBlockINTERNAL ASSERT FAILED,2022-01-05 15:14:11+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
70678,Decouple `TensorIteratorBase` output from structured kernel outputs.,2022-01-05 13:36:55+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: structured kernels"")]"
70669,CUSOLVER_STATUS_EXECUTION_FAILED when using the torch.logdet(),2022-01-05 09:15:56+00:00,,0,16,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
70660,[FSDP] Run parity tests for activation checkpoint and offload,2022-01-05 03:07:29+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
70654,[RFC] UCC integration in ProcessGroupNCCL,2022-01-05 00:03:56+00:00,,0,13,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
70627,Torchscript Compiled functions don't support keyword-only arguments with defaults,2022-01-04 19:38:49+00:00,,0,0,"[Label(name=""oncall: jit"")]"
70609,gloo_test test_close_connection not working as intended due to unwanted comma,2022-01-04 17:10:57+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
70608,Cannot compile C++ documentation: Sphynx assertion,2022-01-04 16:58:18+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
70583,Add nondeterministic alert to `torch.scatter_`,2022-01-03 17:46:32+00:00,,1,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
70573,JIT magic method which returns class instance fails.,2022-01-03 09:48:23+00:00,,0,0,"[Label(name=""oncall: jit"")]"
70559,Behavior of torch.nn.functional.interpolate with unchanged output size and recompute_scale_factor=False,2022-01-02 18:01:59+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
70555,[feature request] Exponential moving average (EMA) of a tensor across a dimension,2022-01-02 09:06:31+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
70546,DISABLED test_tensorpipe_set_default_timeout (__main__.TensorPipeTensorPipeAgentRpcTest),2022-01-01 03:26:48+00:00,,1,11,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""module: rpc""), Label(name=""skipped"")]"
70544,Tensor loses `bool` method during scripting,2021-12-31 19:00:18+00:00,,0,0,"[Label(name=""oncall: jit"")]"
70540,cumcount / cumulative count,2021-12-31 07:44:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement"")]"
70533,JIT / TorchScript should support for sum(List[torch.Tensor]) like non-JIT PyTorch already does,2021-12-30 22:16:24+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
70529,BatchNorm on variable-length sequences or batches,2021-12-30 16:21:47+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged"")]"
70521,tmpxft_00008487_00000000-6_THCStorage.compute_86.cudafe1.cpp:(.text+0x60b): additional relocation overflows omitted from the output when build PyTorch 1.8.2 from source,2021-12-30 08:15:25+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
70519,RuntimeError: cublas runtime error,2021-12-30 06:32:55+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: cublas"")]"
70513,Conda Repodata.json file not found in Pytorch channel,2021-12-30 03:37:06+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
70511,Strange behavior of torch.jit.trace when moving parameters across device,2021-12-30 02:55:26+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
70505,`UninitializedParameter.to(device='meta')` creates a zero-sized meta tensor instead of remaining uninitialized,2021-12-29 21:45:54+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: meta tensors""), Label(name=""module: lazy"")]"
70504,backward checks len of inputs before it's converted to a tuple,2021-12-29 21:17:55+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
70502,torch.get_autocast_cpu_dtype() returns a new dtype (still?),2021-12-29 18:14:24+00:00,,0,7,"[Label(name=""high priority""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
70500,Adding the new Phish activation function,2021-12-29 17:49:27+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request""), Label(name=""Stale"")]"
70498,Multiple invalid summaries in torch.nn documentation page,2021-12-29 16:58:34+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
70490,Cuda sync mode input checking is wrong for non-string/int inputs.,2021-12-29 13:54:49+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""Stale"")]"
70487,Fusion of Convolution and BatchNorm,2021-12-29 07:09:45+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""feature""), Label(name=""triaged"")]"
70485,Cannot run FX tracer on a vision transformer model,2021-12-29 06:49:19+00:00,,0,0,"[Label(name=""triaged""), Label(name=""Stale""), Label(name=""module: fx"")]"
70480,Dynamic quantified Conv2d have accuracy issue,2021-12-29 03:20:08+00:00,,1,6,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
70455,Make it possible to remove all hooks on a specified module without needing the hook handles,2021-12-28 17:15:31+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""Stale"")]"
70454,Building docs locally fails,2021-12-28 16:53:38+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
70450,torch.jit.optimized_execution is not mentioned anywhere in the docs,2021-12-28 15:16:55+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
70449,[FX] Detect attribute mutation during tracing,2021-12-28 14:58:10+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
70447,The same code can not be reproduced on multiple GPUs with dataparallel,2021-12-28 12:33:55+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""Stale"")]"
70446,Exporting the operator prim_DictConstruct to ONNX opset version 13 is not supported,2021-12-28 12:21:31+00:00,,0,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
70419,LazyModules `cls_to_become` field exposes implementation detail,2021-12-27 07:53:53+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""Stale"")]"
70416,libtorch cuda use too much system memory,2021-12-27 03:03:04+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""Stale"")]"
70413,"PyTorch crashes without an error message, when running this code snippet with torch.tensor subclassing & forward hooks (Not sure what the exact cause is, but the code snippet reliably causes it)",2021-12-26 18:33:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""Stale""), Label(name=""tensor subclass"")]"
70398,`torch.broadcast_to` can create tensor with negative dimension.,2021-12-25 07:21:20+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: shape checking"")]"
70397,`torch.empty_strided` works when the stride is negative!,2021-12-25 04:58:50+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: tensor creation"")]"
70394,Intel MKL FATAL ERROR: This system does not meet the minimum requirements for use of the Intel(R) Math Kernel Library.,2021-12-24 16:29:23+00:00,,0,6,"[Label(name=""module: dependency bug""), Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: mkl""), Label(name=""module: intel"")]"
70392,third_party/breakpad/ compilation failure,2021-12-24 14:46:20+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: third_party"")]"
70391,linalg.lstsq INTERNAL ASSERT FAILED,2021-12-24 13:28:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: mkl""), Label(name=""module: linear algebra""), Label(name=""Stale"")]"
70388,RuntimeError: tensor has too many (>25) dims when permuting tensor with GPU backend,2021-12-24 11:44:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: assert failure""), Label(name=""Stale"")]"
70386,AT_ASSERT fail with DataLoaderOptions().drop_last(),2021-12-24 07:14:34+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""Stale"")]"
70352,Rprop Optimizer: UnboundLocalError: local variable 'step_size_min' referenced before assignment,2021-12-23 16:11:58+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
70350,Core dumped with large matmul on aarch64,2021-12-23 14:06:12+00:00,,0,4,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: arm""), Label(name=""Stale"")]"
70348,nan return by nn.CrossEntropyLoss when all the labels are ignore_index in torch 1.11,2021-12-23 12:33:40+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""Stale"")]"
70347,boolean mask + ellipsis lead to incorrect indexing,2021-12-23 11:59:04+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing""), Label(name=""Stale"")]"
70346,Add hints for gradient long time overflow when using torch.cuda.amp,2021-12-23 07:04:43+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)""), Label(name=""Stale"")]"
70342,Empty or NaN data pollute gradient even if they are not involved during backward,2021-12-23 03:31:37+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
70267,Inconsistent multi-node latency with NCCL and OpenMPI,2021-12-21 22:53:34+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: nccl""), Label(name=""module: openmp"")]"
70265,"Shape parameter inconsistency in torch.Tensor.view, torch.reshape, torch.Tensor.reshape",2021-12-21 22:37:00+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
70245,"SEGFAULT on ""import torch""",2021-12-21 13:27:18+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
70243,Unable to compile PyTorch when libcudart_static.so is not available ,2021-12-21 12:36:59+00:00,,0,10,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
70242,`TensorIterator`: provide a two-argument version of `set_output`,2021-12-21 12:27:21+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: TensorIterator""), Label(name=""module: structured kernels"")]"
70241,CPU parallelization across batch has random faulty behavior on backward,2021-12-21 12:25:08+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: multithreading"")]"
70240,JIT: wrong list/tuple length if using Union,2021-12-21 12:00:51+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
70239,`pytorch` hangs during interaction with `ray` package,2021-12-21 11:10:16+00:00,,0,3,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
70238,`TensorIterator`: refactor `build_ternary_op` to match binary versions,2021-12-21 11:04:56+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: TensorIterator"")]"
70223,"jit: Confusing behavior w/ torch.autograd.grad, iterative loop, and printing?",2021-12-21 04:47:14+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
70222,Grad strides do not match bucket view strides,2021-12-21 03:12:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: ddp"")]"
70199,Missing Docker image for 1.10.1,2021-12-20 19:45:55+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: docker""), Label(name=""Stale"")]"
70191,[libtorch] Loading in Java two differente libtorch_cpu.so from different versions fails,2021-12-20 17:58:43+00:00,,0,5,"[Label(name=""module: binaries""), Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: java"")]"
70184,Optimization: convolution_backward doesn't always need to call .contiguous on certain inputs,2021-12-20 15:35:37+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: convolution""), Label(name=""triaged"")]"
70180,Can you provide the torch.trt module to directly convert the pytorch weights to tensorrt?,2021-12-20 12:54:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: unknown"")]"
70173,Dynamic Tensor Rematerialization (DTR),2021-12-20 07:08:43+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
70171,Channels last performance problem,2021-12-20 05:05:43+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""Stale"")]"
70170,EmbeddingBag allows out of index ranges.!,2021-12-20 03:36:20+00:00,,0,7,"[Label(name=""module: dependency bug""), Label(name=""triaged"")]"
70166,[feature request] Autocast module and function wrappers,2021-12-19 21:45:14+00:00,,0,10,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
70162,Dot product return completely incorrect result when using pip but not when using conda,2021-12-19 10:43:51+00:00,,0,9,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: lts"")]"
70160,NewOperatorRegistrationTest.testImplNoDefGetsCaught failed.,2021-12-18 22:36:44+00:00,,0,4,"[Label(name=""module: cpp""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
70159,[Android] Unknown builtin op: aten::reflection_pad3d,2021-12-18 22:18:32+00:00,,0,1,"[Label(name=""oncall: mobile""), Label(name=""Stale"")]"
70158,pin_memory *still* destroys custom containers ,2021-12-18 20:50:39+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""Stale"")]"
70155,RuntimeError: Tensor must be CUDA and dense when calling all_gather_object even though there is no tensor in the object.,2021-12-18 16:48:24+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
70138,build_ios.sh prevents iOS.cmake from configuring ios deployment target correctly,2021-12-17 22:31:06+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: ios""), Label(name=""Stale"")]"
70135,API to support combined activation offloading or checkpointing,2021-12-17 21:43:59+00:00,,1,16,"[Label(name=""oncall: distributed""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""module: fsdp"")]"
70125,channels_last/channels_last_3d memory format not supported for some modules on ROCm that should be supported on CUDA,2021-12-17 19:39:56+00:00,,0,0,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""Stale"")]"
70108,Derivative for _ctc_loss_backward,2021-12-17 15:39:39+00:00,,0,8,"[Label(name=""high priority""), Label(name=""module: double backwards""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
70102,torch jit script segm fault,2021-12-17 11:47:32+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
70100,Feature Request: dim parameter of torch.nn.functional.normalize should accept tuples,2021-12-17 10:03:49+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: norms and normalization""), Label(name=""Stale"")]"
70099,"Question:  what is ""Parameter indices""?",2021-12-17 09:34:29+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""Stale"")]"
70095,Add support for a `default` arg in `ModuleDict.pop`,2021-12-17 07:39:17+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""Stale"")]"
70073,Feature request: [STFT] Add warning message if signal length is not a multiple of hop_length in torch.stft,2021-12-16 23:05:30+00:00,,0,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: fft"")]"
70065,Tool for detecting inefficent striding for nn.Conv2d,2021-12-16 21:31:53+00:00,,0,2,"[Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: profiler""), Label(name=""Stale"")]"
70060,[RFC] Activation Checkpoint API improvements,2021-12-16 21:06:48+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""module: checkpoint""), Label(name=""module: ddp""), Label(name=""Stale""), Label(name=""module: fsdp"")]"
70058,Unknown builtin op: spconv::get_indice_pairs ,2021-12-16 20:56:33+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
70054,[c10d] have a way to determine two ranks on the same hosts or not,2021-12-16 18:51:00+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
70051,[feature request] Support python decorators in TorchScript,2021-12-16 17:37:08+00:00,,0,1,"[Label(name=""oncall: jit"")]"
70048,Tensor transfer between gpus doesnt work,2021-12-16 16:03:23+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""Stale"")]"
70047,[JIT] Cannot `jit.export` a `@staticmethod`,2021-12-16 14:13:29+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
70045,Could we leave the _two_ most recent nightlies in the conda channel?,2021-12-16 13:27:56+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""feature""), Label(name=""module: ci""), Label(name=""triaged"")]"
70041,Multiprocessing - shared memory,2021-12-16 12:21:00+00:00,,0,2,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
70040,Error in `torch.cdist` documentation,2021-12-16 12:08:03+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: distance functions"")]"
70038,comile error,2021-12-16 09:56:15+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: third_party"")]"
70037,Question about collect tensor in distributed dataparallel?,2021-12-16 09:40:42+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""Stale"")]"
70015,Multigpu test configs intermittently timeout,2021-12-16 00:20:23+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""module: flaky-tests"")]"
70008,Torch function runtime seemingly dependent on scipy call,2021-12-15 22:41:53+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
69991,Composite Compliance Problems Tracker,2021-12-15 20:32:28+00:00,,0,7,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: __torch_dispatch__"")]"
69984,Docs for torch.nn.MSELoss are confusing,2021-12-15 18:04:19+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""Stale"")]"
69972,torchscript does not work with `SyncBatchNorm` layers,2021-12-15 13:16:02+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
69969,cpu - gpu calculation results differs by far with torch.nn.functional.linear,2021-12-15 08:55:53+00:00,,0,3,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged"")]"
69966,torch.nn.DataParallel caused inference failure with cpu set as device on NV machine,2021-12-15 06:49:31+00:00,,0,0,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""Stale"")]"
69960,"FeatureAlphaDropout doesn't drop channels for (C, D, H, W)",2021-12-15 04:30:04+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: batching""), Label(name=""Stale"")]"
69938,"JIT is overriding variables of type List[int] to type Tuple[int, int] for an unknown reason during function calls",2021-12-14 22:34:53+00:00,,0,0,"[Label(name=""oncall: jit"")]"
69932,"Would pytorch like some free multi-factor authentication (MFA) tokens from Google & GitHub, via the OpenSSF?",2021-12-14 22:09:21+00:00,,0,1,"[Label(name=""triaged"")]"
69931,[JIT] torch.exp roughly 20 times slower in TorchScript vs. PyTorch,2021-12-14 21:56:39+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
69921,Context manager to enable/disabled TensorFloat32 on demand,2021-12-14 19:10:07+00:00,,0,14,"[Label(name=""triaged""), Label(name=""module: tf32"")]"
69912,"torch.nn.functional.ctc_loss with invalid input produce NaN or infinity gradient, while the batch entries are fine",2021-12-14 17:50:54+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""Stale"")]"
69900,Port MarginRankingLoss to TensorIterator,2021-12-14 14:33:59+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""enhancement"")]"
69893,subclassing torch.Tensor,2021-12-14 10:15:37+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""tensor subclass"")]"
69892,[feature request] Support `like=` argument in tensor factory methods,2021-12-14 09:44:38+00:00,,0,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: tensor creation"")]"
69891,[FSDP] Enable tests for Gloo backend,2021-12-14 09:18:04+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""Stale""), Label(name=""module: fsdp"")]"
69889,Exporting the operator unfold to ONNX is not supported.,2021-12-14 08:26:20+00:00,,0,11,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
69858,Feature Request: Bayesian Personalized Ranking Loss,2021-12-13 18:59:48+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""actionable"")]"
69841,`CosineAnnealingWarmRestarts` should use integer epoch,2021-12-13 15:13:09+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
69831,Incorrect error for integer `out=` dtypes when a float is expected.,2021-12-13 12:26:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: structured kernels"")]"
69830,Conversion error from pytorch model to libtorch model,2021-12-13 12:25:10+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
69822,Implement torch.*_like tensor creation functions on sparse inputs,2021-12-13 08:41:28+00:00,,0,13,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
69814,JIT / TorchScript docs missing any mention of typing.cast,2021-12-12 16:36:22+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
69804,typing error in the signatures of `torch.unbind` when getting them using `torch.fx`.,2021-12-11 15:00:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
69803,torchrl,2021-12-11 12:12:15+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged"")]"
69801,"Dropout2d doesn't drop channels for (C, H, W)",2021-12-11 01:59:55+00:00,,1,5,"[Label(name=""high priority""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
69800,Incomplete error message at tensor indexing (when indexing with set),2021-12-11 01:01:43+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""Stale"")]"
69794,torch.optim.lr_scheduler.SequentialLR.get_last_lr() does not work,2021-12-10 22:32:53+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
69786,Implement aten::equal for sparse tensors,2021-12-10 19:51:59+00:00,,0,6,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""Stale"")]"
69782,Torch Profiler does not count FLOPs for backward pass ,2021-12-10 19:23:53+00:00,,0,6,"[Label(name=""oncall: profiler"")]"
69772,RuntimeError: t == DeviceType::CUDAINTERNAL ASSERT FAILED when trying to calculate gradients,2021-12-10 18:05:04+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
69757,[Feature request] nn.Model API: Standard model interface,2021-12-10 13:32:23+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
69756,Introduction of nn.LazyRNNs,2021-12-10 13:25:18+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""Stale"")]"
69753,last_epoch parameter of CyclicLR and OneCycleLR is not the number of epochs,2021-12-10 11:05:54+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""Stale""), Label(name=""module: LrScheduler"")]"
69744,Add ability to ignore arguments/outputs in `torch.autograd.functional.jacobian`,2021-12-10 02:18:05+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""Stale"")]"
69741,JIT: Support for `torch.autograd.functional.jacobian` in TorchScript,2021-12-10 02:02:42+00:00,,0,14,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
69721,Alternative to keras StringLookup in Pytorch,2021-12-09 22:01:15+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
69714,Possibly out of date error in autograd codegen,2021-12-09 20:24:31+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""Stale"")]"
69689,[bug] the LTS torch==1.8.2 pip package is incomplete,2021-12-09 17:35:33+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""Stale""), Label(name=""module: lts"")]"
69688,`torch.cuda.set_per_process_memory_fraction()` does not perform VRAM isolation,2021-12-09 16:54:34+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
69687,Performance improvement in Autograd Forward AD using ZeroTensors,2021-12-09 16:37:06+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: forward ad"")]"
69685,Wrong PyTorch version in Docker image,2021-12-09 16:08:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: docker""), Label(name=""Stale"")]"
69676,"[LazyTensor] model after to(device), traced IR changed and lose type info",2021-12-09 11:04:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy""), Label(name=""Stale"")]"
69665,No dtype check for zero sparse tensor!,2021-12-09 06:19:28+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""Stale"")]"
69663,"After updated to pytorch1.10.0 cuda11.1, NCCL is not available",2021-12-09 03:53:39+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""Stale"")]"
69659,DISABLED test_fs_pool (__main__.TestMultiprocessing),2021-12-09 03:13:12+00:00,,0,17,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: multiprocessing""), Label(name=""module: flaky-tests""), Label(name=""skipped"")]"
69654,Fused AlphaFold 2 modules,2021-12-09 01:04:14+00:00,,0,6,"[Label(name=""feature""), Label(name=""triaged"")]"
69627,c2r fft input generation,2021-12-08 19:34:13+00:00,,0,3,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: fft"")]"
69616,Multi-GPU training stuck when using grad scaler,2021-12-08 17:59:32+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""module: amp (automated mixed precision)""), Label(name=""Stale"")]"
69611,_pickle.UnpicklingError: pickle data was truncated - Windows multiprocessing during training,2021-12-08 15:15:15+00:00,,0,5,"[Label(name=""module: windows""), Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""module: serialization""), Label(name=""triaged"")]"
69610,[Question] How to extract/expose the complete PyTorch computation graph (forward and backward)?,2021-12-08 14:37:00+00:00,,0,12,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""oncall: visualization"")]"
69609,[mobile_optimizer] RuntimeError: We don't have an op for metal_prepack::conv2d_prepack,2021-12-08 13:36:18+00:00,,0,5,"[Label(name=""oncall: mobile""), Label(name=""Stale"")]"
69608,Optimize For Inference - add warning/error upon serialization,2021-12-08 13:02:54+00:00,,0,1,"[Label(name=""oncall: jit"")]"
69594,RuntimeError: Operation not supported  ,2021-12-08 04:02:14+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: c10d""), Label(name=""Stale"")]"
69591,Make DDP + Zero have the same communication volume as regular DDP,2021-12-08 02:26:46+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: ddp""), Label(name=""Stale"")]"
69577,[subgraph_rewriter] Add match_filter for the matches,2021-12-07 23:54:05+00:00,,1,1,"[Label(name=""triaged""), Label(name=""Stale""), Label(name=""module: fx"")]"
69563,[Distributed Tests] Print stacktraces of all processes when one fails,2021-12-07 21:48:00+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""Stale"")]"
69538,cuSOLVER backend for Sparse CSR direct linear solvers,2021-12-07 17:01:58+00:00,,0,8,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
69532,[feature request] A rank-revealing SVD for better stability in backward.,2021-12-07 15:55:22+00:00,,1,0,"[Label(name=""module: numerical-stability""), Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
69531,"`(svd|pca)_lowrank`: backward is unstable when for a matrix `A`, the parameter `q` is set to a value `q > rank(A)`.",2021-12-07 15:33:29+00:00,,0,6,"[Label(name=""module: numerical-stability""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""Stale"")]"
69530,Extend composite compliant testing to backward formulas,2021-12-07 14:38:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""Stale""), Label(name=""module: __torch_dispatch__"")]"
69524,[feature request] Accepting python scalar inputs for torch.minimum/torch.maximum and friends,2021-12-07 11:44:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: distance functions"")]"
69522,PyTorch 1.9.1 incorrect result for all-reduce,2021-12-07 10:26:03+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
69520,race condition of agent's TCP store on exit_barrier(),2021-12-07 09:39:19+00:00,,0,1,"[Label(name=""triaged""), Label(name=""Stale""), Label(name=""oncall: r2p"")]"
69519,Feature Request: CUDA torch.histogram (and histogramdd),2021-12-07 09:06:54+00:00,,0,11,"[Label(name=""module: bootcamp""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: sorting and selection"")]"
69516,`torch.sparse.softmax` and `torch.sparse.log_softmax` do not support negative dim.,2021-12-07 07:49:01+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""Stale"")]"
69512,Inconsistent behavior of cosine_similarity between fp16 and fp32 inputs,2021-12-07 05:47:48+00:00,,0,3,"[Label(name=""high priority""), Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""module: distance functions"")]"
69506,[performance] a profiler util to show a rough break-down of the types of ops used by a model,2021-12-07 02:20:15+00:00,,0,1,"[Label(name=""oncall: profiler""), Label(name=""Stale"")]"
69505,"with the same environment ,pytorch 1.8 worked but 1.10 can't work",2021-12-07 01:35:16+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""Stale""), Label(name=""module: wsl"")]"
69491,[RFC] Support MemoryView for Tensors,2021-12-06 22:32:20+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: viewing and reshaping"")]"
69471,Include Declarations.yaml in Libtorch distributions,2021-12-06 19:19:15+00:00,,0,12,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: codegen""), Label(name=""Stale"")]"
69469,Distribution `covariance` property,2021-12-06 19:00:49+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
69467,Distribution `cross_entropy` method,2021-12-06 18:58:40+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
69453,Jacobian elliptic functions,2021-12-06 15:04:42+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: special"")]"
69452,Complete elliptic integral of the first kind,2021-12-06 15:01:42+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: special"")]"
69451,Exponentially scalable modified Bessel function of the second kind,2021-12-06 14:57:06+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: special"")]"
69448,RuntimeError: PyTorch convert function for op 'inverse' not implemented.,2021-12-06 13:21:23+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
69442,The formula for KL-divloss is wrong in the document,2021-12-06 07:58:24+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""Stale"")]"
69435,"torch.is_tensor(obj) doesn't work with JIT, despite the fact that isinstance(obj, Tensor) already works with JIT",2021-12-05 19:52:10+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
69434,"JIT RuntimeError:  'Union[Tensor, List[float], List[int]]' object is not subscriptable",2021-12-05 19:27:07+00:00,,1,4,"[Label(name=""oncall: jit"")]"
69433,`torch.transpose` should raise an error when indexing 0 for 0 dimensional tensor.,2021-12-05 14:34:42+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
69431,"[proposal] [util] torch.to(obj, device) supporting recursive lists/dicts/tuples of tensors probably by uplifting/promoting torch.distributed.utils._recursive_to",2021-12-05 13:46:06+00:00,,0,16,"[Label(name=""triaged""), Label(name=""needs research""), Label(name=""function request"")]"
69425,Integrate Libtorch into Unreal Engine 4: _ivalue_INTERNAL ASSERT FAILED,2021-12-05 04:48:49+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
69408,`torch.hstack` should raise an error when tensor is 0 dimensional,2021-12-04 02:04:13+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""Stale"")]"
69386,Port `normal` to structured kernel,2021-12-03 20:46:50+00:00,,0,15,"[Label(name=""triaged""), Label(name=""module: structured kernels"")]"
69364,"[feature request] quantized and low-level int8 operators (matmul, gemm etc) on CUDA + integrate LLM.int8 + integrate ZeroQuant?",2021-12-03 13:09:26+00:00,,2,51,"[Label(name=""oncall: quantization""), Label(name=""module: cuda""), Label(name=""triaged"")]"
69363,"Citation request for ""probabilities for each class"" in the doc's description on cross-entropy",2021-12-03 11:34:50+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
69360,1.10.0 failed to build due to missing TensorBody.h,2021-12-03 10:22:44+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""Stale"")]"
69359,"[feature request] More masked reductions: amin/amax, argmin/argmax, quantile, mean/var/std/std_mean/var_mean",2021-12-03 10:19:09+00:00,,0,6,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: masked operators"")]"
69354,Missing instruction in recipe for Andoid/mobile interpreter,2021-12-03 08:10:27+00:00,,0,0,"[Label(name=""oncall: mobile""), Label(name=""Stale"")]"
69353,Pruning `torch.nn.MultiheadAttention` causes RuntimeError,2021-12-03 08:04:23+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""module: pruning""), Label(name=""Stale"")]"
69352,I want to know how to read the LMDB file once when using DDP,2021-12-03 07:34:16+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader"")]"
69348,`torch.sspaddmm` should broadcast the input tensor,2021-12-03 06:55:32+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""Stale"")]"
69347,Memory leak when moving tensors between Metal and CPU on iOS,2021-12-03 05:04:04+00:00,,0,7,"[Label(name=""oncall: mobile"")]"
69325,`nn.functional.fractional_max_pool2d` and `nn.functional.fractional_max_pool3d` produce incorrect output on non-contiguous inputs,2021-12-02 22:31:31+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""Stale"")]"
69321,Poor Transformer inference scalability on CPU,2021-12-02 21:53:44+00:00,,0,3,"[Label(name=""oncall: transformer/mha""), Label(name=""Stale"")]"
69320,[JIT] Break up JIT Opinfo Tests ,2021-12-02 21:45:42+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""better-engineering"")]"
69316,`torch.tensor` relies on implicit conversion being deprecated in Python 3.10,2021-12-02 21:11:08+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: tensor creation"")]"
69308,Enable DDP checkpointing tests for Gloo backend,2021-12-02 20:32:30+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: ddp""), Label(name=""Stale"")]"
69290,Deprecation warnings generated when including header files in C++17 code,2021-12-02 11:59:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: build warnings""), Label(name=""Stale"")]"
69288,Inplace and `out` variants for `positive` operator in PyTorch,2021-12-02 09:36:51+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: ux""), Label(name=""Stale"")]"
69287,`out=` variant for `conj` unary operator,2021-12-02 09:35:09+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""Stale"")]"
69286,"subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '-j', '32']' returned non-zero exit status 1.",2021-12-02 09:22:09+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""Stale"")]"
69281,Implement reparameterized sampling for LKJCholesky distribution w.r.t. concentration parameter,2021-12-02 07:16:38+00:00,,1,1,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""Stale"")]"
69250,TorchScript incomptaible with non-persistent buffers,2021-12-01 20:45:50+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
69233,[ROCM] elementwise kernel launch,2021-12-01 17:29:32+00:00,,0,0,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""Stale"")]"
69213,torch.stack should have a pin_memory parameter,2021-12-01 14:08:15+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
69207,Function(s) expecting a tuple argument don't accept generators,2021-12-01 11:22:01+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""Stale"")]"
69203,Error in SVD cusolver on Linux,2021-12-01 09:04:14+00:00,,0,19,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
69202,CPU only mode with cudatoolkit 11.3,2021-12-01 08:58:21+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
69199,Protocol buffers library mismatch.,2021-12-01 07:57:08+00:00,,0,2,"[Label(name=""module: protobuf""), Label(name=""triaged""), Label(name=""module: tensorboard"")]"
69197,RendezvousConnectionError when use C10d on multi nodes,2021-12-01 07:18:27+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: r2p"")]"
69179,DISABLED test_builtin_remote_message_dropped_timeout_to_self (__main__.FaultyFaultyAgentRpcTest),2021-12-01 00:06:15+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""module: rpc""), Label(name=""skipped"")]"
69178,DISABLED test_remote_timeout_to_here_in_jit (__main__.FaultyJitFaultyAgentRpcTest),2021-12-01 00:05:55+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""oncall: jit""), Label(name=""module: flaky-tests""), Label(name=""module: rpc""), Label(name=""skipped"")]"
69158,Fusing module with multiple hooks causes `RuntimeError: OrderedDict mutated during iteration` in fuse_known_modules,2021-11-30 21:08:10+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""Stale"")]"
69095,[FX] `concrete_args` with unpacking breaks `fx.Interpreter`,2021-11-30 18:23:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""Stale""), Label(name=""module: fx"")]"
69086,Confusing value of `TORCH_CUDA_ARCH_LIST`,2021-11-30 17:01:06+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""Stale"")]"
69084,Unicode Normalization with Torchscript,2021-11-30 16:38:26+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
69080,Generalized matmul,2021-11-30 15:45:45+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
69078,RuntimeError: Global alloc not supported yet in TorchScript,2021-11-30 15:14:05+00:00,,0,7,"[Label(name=""oncall: jit"")]"
69072,Libtorch dll versioning,2021-11-30 11:10:44+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""Stale"")]"
69063,make: Makefile: No such file or directory,2021-11-30 03:05:03+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""Stale"")]"
69033,Lazy Tensor Core Documentation Out-of-Date,2021-11-29 22:04:32+00:00,,0,24,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: xla""), Label(name=""module: lazy"")]"
69031,DDP only syncs parameters used in most recent pass when `find_unused_parameters` is True.,2021-11-29 21:56:47+00:00,,1,5,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp""), Label(name=""Stale"")]"
69025,[subgraph_rewriter] Support skipping matching for some ops,2021-11-29 20:53:56+00:00,,0,0,"[Label(name=""triaged""), Label(name=""Stale""), Label(name=""module: fx"")]"
69023,`TestProfilerCUDA. test_mem_leak` failing for CUDA 11.5 on Linux,2021-11-29 20:27:56+00:00,,1,4,"[Label(name=""triage review""), Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""module: memory usage""), Label(name=""module: infra""), Label(name=""oncall: profiler"")]"
69013,libtorch_cuda links against wrong libnccl.so,2021-11-29 18:35:40+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: abi""), Label(name=""triaged""), Label(name=""module: third_party""), Label(name=""Stale"")]"
69009,Mamba does not respect `cpuonly` when creating a conda environment from YAML file,2021-11-29 17:54:10+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""Stale"")]"
69006,[JIT] allow `Optional[torch.Generator]` be tracable in Python,2021-11-29 17:31:45+00:00,,0,4,"[Label(name=""oncall: jit"")]"
68987,Operator is not supported in mobile module.,2021-11-29 14:19:37+00:00,,0,2,"[Label(name=""oncall: mobile"")]"
68984,speed_benchmark_torch crashes when trying to run a model using Vulkan backend on Android,2021-11-29 12:21:55+00:00,,0,0,"[Label(name=""oncall: mobile""), Label(name=""Stale"")]"
68982,PyTorch installation doesn't work with Python 3.10.0 ,2021-11-29 12:01:21+00:00,,0,6,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
68979,Support for arbitrary schedulers in SequentialLR,2021-11-29 09:10:11+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
68978,SequentialLR cannot be used with ReduceLROnPlateau due to .step() not allowing for optional arguments,2021-11-29 09:02:48+00:00,,0,7,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
68968,torch.jit.trace with pack_padded_sequence  cannot do dynamic batch,2021-11-29 02:07:56+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
68967,[feature request] torch.argminmax,2021-11-28 22:33:07+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
68966,`torch.ldexp` generated tests fail on call to `torch.mul`,2021-11-28 22:10:39+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
68961,Deterministic implementation for upsample_bilinear2d_backward_cuda,2021-11-27 16:39:02+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
68959,Deterministic implementation for grid_sampler_2d_backward_cuda,2021-11-27 15:53:37+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
68946,Strange ouput of torch.histc,2021-11-26 19:11:27+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: sorting and selection"")]"
68944,Pytorch to ONNX model conversion,2021-11-26 13:26:15+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
68940,Breakpoint training in a Tensorboard log,2021-11-26 11:07:51+00:00,,0,0,"[Label(name=""oncall: visualization""), Label(name=""Stale"")]"
68935,repeat_interleave hangs in a forked subprocess,2021-11-26 08:54:37+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
68931,Dead lock happened ran pytorch 1.9.0 cuda11.2 on xeon gold 6326 cpu,2021-11-26 07:33:50+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
68927,Thank you for the diagnostic script.,2021-11-26 04:16:14+00:00,,0,1,"[Label(name=""oncall: visualization"")]"
68925,How to implement `bucket_by_sequence_length` with IterableDataset and DataLoader,2021-11-26 03:06:17+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
68923,[cpp extension] making it possible to parallelize the building process,2021-11-26 02:14:02+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cpp-extensions""), Label(name=""module: ci""), Label(name=""triaged"")]"
68921,[Bug] forward function error occurs when the scriptmodule (made in Python) including the hook function is loaded from C++(Libtorch1.8.2),2021-11-26 01:52:51+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
68920,Breakes with -OO flag in script,2021-11-25 19:57:00+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: regression"")]"
68917,"Bugs related to NCCL on RTX 6000, code freezes with no output when using DistributedDataParallel ",2021-11-25 16:03:15+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
68916,Crash loading fairseq based model,2021-11-25 14:27:32+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: hub"")]"
68909,Bug about Dropout CUDA Kernel,2021-11-25 07:50:43+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
68905,Shared `~/.cache/torch_extensions` needs to be pytorch version aware.,2021-11-25 02:18:38+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""enhancement"")]"
68901,Python version is 3.7.11 in latest pytorch docker image,2021-11-24 22:52:30+00:00,,0,3,"[Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""module: docker"")]"
68893,NCCL Network is unreachable / Connection refused when initializing DDP,2021-11-24 19:17:30+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
68892,fusion in fx graph mode did not take care of direct attribute access,2021-11-24 18:46:56+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
68880,Setting 'padding' to a string will fail exporting Conv2d operator to ONNX.,2021-11-24 16:03:07+00:00,,0,9,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
68879,Stop gradient option for padding,2021-11-24 15:32:40+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research""), Label(name=""Stale"")]"
68871,[LibTorch-Lite] Add a custom flag to build LibTorch-Lite with LAPACK included,2021-11-24 09:45:55+00:00,,0,5,"[Label(name=""enhancement""), Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
68866,wait() does not block the default stream for NCCL's asynchronous P2P operations,2021-11-24 08:26:05+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
68864,Incorrect accuracy  pytorch(1.0.1) and libtorch   because of nn.LSTM,2021-11-24 07:32:45+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
68862,find_unused_parameters of DDP,2021-11-24 06:52:29+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
68861,[In Gunicorn & multiprocessing environment] Cannot re-initialize CUDA in forked subprocess,2021-11-24 06:19:27+00:00,,0,4,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""Stale"")]"
68809,torch.profiler.profile().export_stacks() never finishes.,2021-11-23 10:40:25+00:00,,0,5,"[Label(name=""oncall: profiler""), Label(name=""Stale"")]"
68803,[DDP] Verify ignored parameter names in debug mode during init,2021-11-23 09:03:50+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: c10d""), Label(name=""Stale"")]"
68800,[1.10 regression][jit][cuda fuse] cat codegen wrong var name,2021-11-23 06:27:20+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
68798,Clarify variables of BatchNorm*d functions,2021-11-23 04:12:45+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: norms and normalization""), Label(name=""Stale"")]"
68789,[FSDP] Wrap API improvements,2021-11-23 01:33:41+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fsdp"")]"
68785,[elastic/distributed] API to retrieve consolidated worker information,2021-11-23 00:36:13+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""oncall: r2p"")]"
68781,[docs] Clarify DDP activation checkpointing support,2021-11-22 23:30:15+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp""), Label(name=""Stale"")]"
68780,Incorrect documentation for `BCEWithLogitsLoss` `weight`?,2021-11-22 23:23:39+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""Stale"")]"
68768,[feature request] making pytorch less noisy ,2021-11-22 21:15:21+00:00,,1,10,"[Label(name=""high priority""), Label(name=""module: cpp-extensions""), Label(name=""feature""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: ux"")]"
68759,`test_variant_consistency_jit` errors for `torch.nn.functional.prelu`,2021-11-22 20:36:16+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""Stale"")]"
68752,`softmin` and `softmax` operators support different input dtypes based on whether the `dtype` kwarg is passed,2021-11-22 19:37:52+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: ux"")]"
68746,Add kl_divergence between Normal and Laplace distribution.,2021-11-22 18:38:42+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""Stale"")]"
68742,RFC: Deprecate Bottleneck,2021-11-22 18:22:14+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""module: deprecation""), Label(name=""oncall: profiler""), Label(name=""Stale"")]"
68734,SequentialLR object has no attribute '_last_lr',2021-11-22 16:30:51+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
68726,Failed to create Gloo new group after initialized with NCCL,2021-11-22 10:20:41+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
68712,torch.utils.data.Sampler is not recognized as a collections.abc.Sized,2021-11-21 21:15:07+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""module: typing""), Label(name=""triaged""), Label(name=""Stale"")]"
68703,Feature request: Extend `torch.eye` for creating a batch of eye matrices ,2021-11-21 13:25:55+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
68701,Tensor precision manifests differently between CPU and GPU.,2021-11-21 11:46:52+00:00,,0,5,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: arm""), Label(name=""Stale""), Label(name=""module: jetson"")]"
68699,Transpose of a sparse tensor is not a view operation,2021-11-21 10:11:52+00:00,,0,6,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: viewing and reshaping""), Label(name=""Stale"")]"
68696,Is it possible to use torch.linalg.cholesky for cholesky decomposition of a huge matrix that doesn't fit in memory?,2021-11-20 23:33:34+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""Stale"")]"
68655,[ux] F.binary_cross_entropy (and maybe other losses) to auto-cast bool category mask to float,2021-11-19 18:11:39+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: ux""), Label(name=""Stale"")]"
68648,[feature request] Sticky/force regime of train/eval modes,2021-11-19 15:52:09+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research""), Label(name=""module: ux"")]"
68643,DISABLED test_ind_worker_queue (__main__.TestIndividualWorkerQueue),2021-11-19 14:16:46+00:00,,0,11,"[Label(name=""high priority""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""skipped"")]"
68638,ONNX export support for quantize_fx,2021-11-19 08:58:01+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""Stale""), Label(name=""onnx-triaged"")]"
68626,`jit.script` doesn't support `device(type='cuda')`,2021-11-19 01:54:08+00:00,,0,1,"[Label(name=""oncall: jit"")]"
68622,"torch.{tensor, Tensor, LongTensor, ...} isn't captured under `enable_python_mode()`",2021-11-19 00:41:42+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
68616,"`torch.flip`, `torch.roll`, `torch.tile` has arguments `dims=` for both dim/multidim while other functions have argument `dim=` for the same usage",2021-11-18 23:48:15+00:00,,0,7,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: python frontend"")]"
68610,`torch.unique_consecutive`: passing positional optional arguments results in empty tensors,2021-11-18 20:26:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
68595,Inconsistent list indexing behavior,2021-11-18 16:16:21+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
68575,[ux] Print tensor's dtype by default,2021-11-18 10:06:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: ux"")]"
68568,"About ModuleDict indexing when save model based on ""torch.jit.script()"" method",2021-11-18 02:55:06+00:00,,0,2,"[Label(name=""oncall: jit"")]"
68559,LibTorch -> TorchScript -> PyTorch (Python) fails with `AttributeError: 'RecursiveScriptModule' object has no attribute 'forward'`,2021-11-18 01:16:43+00:00,,0,4,"[Label(name=""oncall: jit"")]"
68553,[distributed] elastic/agent/server/api.py could react faster on exit / Ctrl+D / Ctrl+C,2021-11-17 23:27:59+00:00,,0,4,"[Label(name=""triaged""), Label(name=""oncall: r2p"")]"
68538,`vmap` performance warnings from `jacobian`,2021-11-17 20:26:52+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: vmap"")]"
68536,Exporting a model with `_save_for_lite_interpreter()` fails with Segmentation fault,2021-11-17 20:09:31+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
68519,dataloader will miss batch data when num worker>0,2021-11-17 14:07:54+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
68516,"[ux] [feature request] Arguments to modules(), named_modules(), children(), named_children() to filter modules of specific types",2021-11-17 11:16:51+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research"")]"
68514,Add common regularizations to PyTorch.,2021-11-17 09:17:08+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: norms and normalization"")]"
68513,torch.fx cannot trace torch.Size() properly,2021-11-17 08:15:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
68512,'replicate' padding in convolution is 77 times slower on cpu than 'zeros',2021-11-17 07:38:20+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: padding"")]"
68507,Multiprocessing hang and queue short circuiting,2021-11-17 05:26:18+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
68506,cudnn_convolution_relu is 17x slower for 7x7 convolutions and channels last,2021-11-17 04:08:10+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
68498,Review disabling tests workflow,2021-11-17 00:59:02+00:00,,1,1,"[Label(name=""triaged"")]"
68475,[LTC][BE] Make the compile flags more strict,2021-11-16 21:50:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
68474,[LTC][BE] Fix all compile warnings,2021-11-16 21:50:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
68464,"Changing the type of dtype argument in softmax, log_softmax, and softmin is possibly BC-breaking.",2021-11-16 20:18:10+00:00,,0,0,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: norms and normalization""), Label(name=""topic: bc breaking"")]"
68430,Strides issue on unsqueezed channels last tensor,2021-11-16 15:27:20+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
68429,istft gradcheck fails on ROCm,2021-11-16 15:23:18+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: fft"")]"
68423,`torch.utils.checkpoint.checkpoint_sequential` is not optimal,2021-11-16 13:21:51+00:00,,0,0,"[Label(name=""module: checkpoint""), Label(name=""triaged"")]"
68422,There is a problem with GPU memory reclamation,2021-11-16 12:59:49+00:00,,0,10,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
68420,`nn.functional.max_unpool(2|3)d`: failing shape check for correct inputs (with `dilation > 1`) with specified `output_size`,2021-11-16 11:45:43+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling"")]"
68407,[Runtime Error in ddp_pipeline.py] RuntimeError: unsupported operation: some elements of the input tensor and the written-to tensor refer to a single memory location. Please clone() the tensor before performing the operation.,2021-11-16 04:01:35+00:00,,1,14,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: ddp"")]"
68405,"Windows multi machine multi card training, card initialization in GLOO communication.",2021-11-16 03:27:27+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: windows""), Label(name=""triaged"")]"
68394,"INTERNAL ASSERT FAILED at ""../aten/src/ATen/MapAllocator.cpp"":323, please report a bug to PyTorch. unable to mmap 68 bytes from file </torch_530808_7992>: Cannot allocate memory (12) ---------------------------------------------------------------------------",2021-11-16 00:04:06+00:00,,0,5,"[Label(name=""module: multiprocessing""), Label(name=""module: cpu""), Label(name=""triaged"")]"
68393,[subgraph_rewriter] Support for non-Tensor replacement,2021-11-16 00:00:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
68385,ImportError: cannot import name 'ProcessGroup' from 'torch.distributed',2021-11-15 22:12:10+00:00,,0,8,"[Label(name=""module: binaries""), Label(name=""oncall: distributed""), Label(name=""module: macos"")]"
68377,Misleading Error Message from nn.RNN when Passing Incorrect Data Type,2021-11-15 19:51:36+00:00,,0,1,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
68352,`Delta` not defined in the docs of `HingeEmbeddingLoss`,2021-11-15 15:17:40+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""actionable"")]"
68349,"SIGILL, Illegal Instruction from libtorch_cpu.so when callling backward() function in a VM.",2021-11-15 14:50:51+00:00,,0,2,"[Label(name=""module: dependency bug""), Label(name=""module: crash""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
68340,Torch 1.10.0 - RuntimeError: requires_grad_ is not supported on ScriptModules,2021-11-15 14:19:20+00:00,,0,1,"[Label(name=""oncall: jit"")]"
68337,"`nn.functional.max_unpool{n}d`: shape checks fail with `output_size=(C, ...)`.",2021-11-15 12:16:39+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling"")]"
68332,[feature request] Provide functional form of scheduler formulas (and reconsider older decisions of not doing it),2021-11-15 11:05:46+00:00,,0,9,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: LrScheduler"")]"
68331,Casting real parameter to complex during forward produces warning on backward,2021-11-15 09:51:33+00:00,,0,14,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""complex_autograd"")]"
68330,"isObject()INTERNAL ASSERT FAILED at ""../aten/src/ATen/core/ivalue_inl.h"":115, please report a bug to PyTorch. Expected Object but got Tensor",2021-11-15 09:34:37+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
68323,sparse.mm: CUDA error: internal error when calling `cusparseSpGEMM_workEstimation [...]`,2021-11-14 10:42:09+00:00,,1,10,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
68320,Potential race conditions between multiple workers trying to download and cache the same file in torch.hub.load_state_dict_from_url and torch.hub.download_url_to_file <- duplicate dataset/model downloads across DDP workers,2021-11-13 22:04:43+00:00,,0,21,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: hub""), Label(name=""actionable"")]"
68315,[docs] Strange signatures for torch.autocast,2021-11-13 03:42:30+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
68301,[FX] [BUG] Tensor.{inplace_method}_(.) is eliminated as dead code,2021-11-13 00:03:32+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: fx"")]"
68298,[Lazy] Add torch.autograd.Function wrappers for the following ops in order to support dynamic shapes,2021-11-12 23:27:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
68297,[DDP] Debug mode should ensure reduction is finished in backward pass,2021-11-12 23:18:01+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
68291,"INTERNAL ASSERT FAILED at ""/opt/conda/conda-bld/pytorch_1634272068185/work/aten/src/ATen/native/LinearAlgebraUtils.h"":244",2021-11-12 22:38:26+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
68288,List of issues to unblock dynamic shapes in Lazy Tensor,2021-11-12 22:31:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
68287,[Lazy] Add torch.autograd.Function wrappers for the following ops in order to support dynamic shapes,2021-11-12 22:16:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy"")]"
68272,Query CUDA version LibTorch has been compiled with,2021-11-12 19:58:32+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""function request"")]"
68258,Option to configure TorchElastic multiprocessing/api.py PContext.close() timeout,2021-11-12 17:15:06+00:00,,1,1,"[Label(name=""triaged""), Label(name=""enhancement"")]"
68256,RuntimeError: CUDA error: initialization error when calling torch.distributed.init_process_group using torch multiprocessing,2021-11-12 16:31:34+00:00,,0,4,"[Label(name=""oncall: distributed"")]"
68249,Does Pytorch1.10 enable cuda graph default?,2021-11-12 13:19:03+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
68248,"bug when loss backward, related to AdaptiveAvgPool1d",2021-11-12 13:10:44+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: pooling"")]"
68208,Make `torch.Tensor.view` support autograd for appropriate cases,2021-11-11 22:41:02+00:00,,1,8,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: viewing and reshaping"")]"
68204,Feature Request: Scriptable Python Source-of-Truth for operator shape functions,2021-11-11 21:31:13+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged"")]"
68193,clang-tidy shows false positive failure on PRs that rename files,2021-11-11 19:13:58+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""module: lint""), Label(name=""triaged"")]"
68190,[FX][docs] Document gotcha about `training` flag,2021-11-11 19:06:32+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
68179,torch.nn.Linear wrong type annotation for bias,2021-11-11 16:00:22+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""module: typing""), Label(name=""triaged"")]"
68174,RFC: “What’s in a (NumPY) name?” — Changing PyTorch Operator Names,2021-11-11 14:33:39+00:00,,0,7,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: numpy"")]"
68171,DISABLED test_nadam (__main__.TestOptim),2021-11-11 14:17:12+00:00,,0,25,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: flaky-tests""), Label(name=""skipped""), Label(name=""module: dynamo"")]"
68169,torch.histogram: Sum of PDFs is num of bins instead of 1,2021-11-11 10:48:40+00:00,,1,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
68165,Upgrade NCCL2.11.4 in the new PyTorch,2021-11-11 08:03:31+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
68163,wsl2 install failed from source code,2021-11-11 06:37:37+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkl"")]"
68144,Unstable buggy calculation.,2021-11-11 01:23:11+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
68114,CPU Memory Deallocation ,2021-11-10 13:07:47+00:00,,0,5,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
68110,zeta(1/2) returns nan,2021-11-10 07:24:23+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: special"")]"
68105,Some type combinations of cublas gemm are not supported when they should,2021-11-10 04:44:40+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: linear algebra"")]"
68104,DDP is not working with Pytorch Lightning,2021-11-10 04:32:00+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
68102,Can not guarantee reproducible for `nn.ReflectionPad2d`,2021-11-10 02:45:04+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
68088,[distributed] Restructure our distributed collective tests,2021-11-09 22:10:10+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
68081,[rfc] Target Determinator,2021-11-09 20:30:43+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
68070,C++ at::Tensor's pinned_memory status is not printing out correctly.,2021-11-09 18:02:15+00:00,,1,1,"[Label(name=""high priority""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
68065,Incorrect return type annotation for _get_mobile_model_contained_types,2021-11-09 15:46:35+00:00,,0,0,"[Label(name=""oncall: jit"")]"
68064,In place `or` operator doesn't work in torchscript,2021-11-09 15:40:04+00:00,,0,0,"[Label(name=""oncall: jit"")]"
68063,pytorch/ExampleRepo,2021-11-09 15:37:12+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
68060,functorch transforms are silently incorrect with autograd.Function,2021-11-09 15:05:02+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""module: correctness (silent)"")]"
68058,Some lr-schedulers docs seems to have typos/missing information,2021-11-09 13:58:06+00:00,,0,8,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
68055,Release official Python 3.9 images,2021-11-09 10:23:47+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
68049,Request to revise the Pytorch tutorial.,2021-11-09 05:48:03+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""module: docs""), Label(name=""module: cpp"")]"
68046,"register_ Hook causes the CUDA out of memory, and remove() is useless",2021-11-09 03:38:15+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
68041,[RFC] APEX style fused optimizers in PyTorch,2021-11-09 01:47:05+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: mta"")]"
68017,MacOS CI result is not in /README.md,2021-11-08 19:01:29+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""actionable"")]"
68014,Add TORCHELASTIC_RESTART_COUNT env variable to DDP logging,2021-11-08 18:26:04+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
68009,Properly document the `to.dtype_layout` overload of `Tensor.to`,2021-11-08 17:38:59+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""actionable"")]"
67999,Improved Transformer and MultiHeadAttention design,2021-11-08 14:31:33+00:00,,0,3,"[Label(name=""oncall: transformer/mha"")]"
67989,the abnormal display of bottleneck of resnet in tensorboard,2021-11-08 10:16:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
67983,torch.jit.export does not working,2021-11-08 06:31:16+00:00,,0,7,"[Label(name=""oncall: jit"")]"
67979,Feature Request: Support prelu_cuda for BFloat16,2021-11-08 03:33:05+00:00,,0,4,"[Label(name=""module: bootcamp""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: bfloat16"")]"
67978,c10::CUDAError,2021-11-08 03:07:27+00:00,,0,24,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: nccl"")]"
67972,Distributed.TCPStore,2021-11-07 22:46:24+00:00,,0,8,"[Label(name=""oncall: distributed"")]"
67970,Error when using torch.fx on bert,2021-11-07 15:18:50+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: fx"")]"
67969,"[docs] F.multilabel_soft_margin_loss does not list arg reduction, but lists outdated size_average/reduce (true for other losses as well)",2021-11-07 11:29:49+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
67968,"unresolved external symbol ""__declspec(dllimport) struct _object * __cdecl THPVariable_Wrap",2021-11-07 10:12:26+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged"")]"
67958,The `SequentialLR` scheduler uses a deprecated pattern ,2021-11-06 17:20:17+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
67955,Torch 1.9.1.post3 - Error in magma_getdevice_arch: MAGMA not initialized (call magma_init() first) or bad device,2021-11-06 14:24:34+00:00,,0,5,"[Label(name=""triaged"")]"
67937,Add support for LTC ops needed by backwards/autograd/autocast,2021-11-05 23:05:55+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
67913,Tracker: ModuleInfo-based testing,2021-11-05 14:49:07+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""tracker"")]"
67902,torch::jit::pickle_load is unable to read some files saved by torch.save,2021-11-05 08:42:17+00:00,,0,4,"[Label(name=""oncall: jit"")]"
67893,AdaptiveMaxPool2d bug,2021-11-05 04:21:16+00:00,,0,1,"[Label(name=""oncall: jit"")]"
67889,[libtorch][torch.jit.script][input dynamic shape]Error in loading “. Pt” file on C + +: index out of range,2021-11-05 02:30:17+00:00,,0,0,"[Label(name=""oncall: jit"")]"
67887,Add more explanation on multithreaded graph building of Autograd,2021-11-04 23:52:44+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""module: multiprocessing""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""actionable"")]"
67879,AMP does not improve performance,2021-11-04 22:15:46+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
67838,`test_variant_consistency_jit_contiguous_cpu_float32` from `test_ops` fails,2021-11-04 11:14:04+00:00,,0,0,"[Label(name=""oncall: jit"")]"
67835,It seems to be a bug！！！,2021-11-04 10:36:17+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
67834,Model tracing not working,2021-11-04 09:56:22+00:00,,0,5,"[Label(name=""oncall: jit"")]"
67797,Conv2d kernel performance regression on CPU since PyTorch 1.9,2021-11-03 23:00:04+00:00,,0,23,"[Label(name=""module: performance""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: regression"")]"
67773,Instability in `test_input_weight_equalization_activation_values` test for random test values.,2021-11-03 16:32:01+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""module: tests""), Label(name=""triaged"")]"
67772,Functions are rendered incorrectly,2021-11-03 16:21:54+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged"")]"
67761,Allow LRScheduler to take in param_groups directly without an optimizer,2021-11-03 11:19:38+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: LrScheduler"")]"
67760,Add an LRScheduler interface for torch schedulers.,2021-11-03 10:36:58+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: LrScheduler"")]"
67758,Building libtorch from source requires too much RAM,2021-11-03 08:40:09+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
67751,Remove logic for constructing symbolic shapes in Profiler,2021-11-03 06:02:31+00:00,,1,1,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""jit-backlog"")]"
67745,A `sieve` operation for separating values of a tensor into two tensors based on a condition.,2021-11-03 03:43:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: ux""), Label(name=""module: viewing and reshaping"")]"
67740,`torch.utils.data.random_split` example broken in 1.10,2021-11-03 03:16:50+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: data"")]"
67712,"Decorate tests with a ""deadline""",2021-11-02 21:16:38+00:00,,2,2,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""better-engineering"")]"
67687,"Trying to quantize and save a pre-trained deberta model, where i get a runtime error ",2021-11-02 16:35:23+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
67684,[feature request] torch.clamp on BoolTensors,2021-11-02 16:28:59+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: boolean tensor"")]"
67683,PyTorch Profiler for distributed time count,2021-11-02 16:10:50+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: tensorboard""), Label(name=""oncall: profiler"")]"
67682,Feature request: bfloat16 support for CUDA matmuls,2021-11-02 15:59:36+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: bfloat16""), Label(name=""matrix multiplication"")]"
67680,OOM with a lot of GPU memory left,2021-11-02 13:55:04+00:00,,0,36,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
67674,torch.jit.script fails to find attribute '_modules' of nn.Module,2021-11-02 09:48:44+00:00,,0,1,"[Label(name=""oncall: jit"")]"
67662,"""self.graph.owning_module not set for purity check"" error when trying to remove a node from torch.fx.graph",2021-11-02 04:19:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
67659,`test_variant_consistency_jit` failing for `max_unpool2d`,2021-11-02 03:25:15+00:00,,0,0,"[Label(name=""oncall: jit"")]"
67653,"TSAN issue in autograd ""set_next_edges""",2021-11-02 02:12:08+00:00,,0,10,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: sanitizers"")]"
67651,MultiHeadAttention in quantizable seems incorrect with batch_first=True,2021-11-01 23:47:47+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
67646,test_jit_fuser_legacy and test_jit_fuser_te are failing with SIGIOT,2021-11-01 22:32:36+00:00,,0,35,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""module: tests""), Label(name=""NNC"")]"
67642,Is there a pre-built pytorch package for CUDA 10.1?,2021-11-01 21:56:30+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
67634,Feature request: Grid sample on complex tensors with float grid,2021-11-01 19:57:37+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""needs research""), Label(name=""module: interpolation"")]"
67603,The minimum supported version of pytorch when using toch-mobile？,2021-11-01 01:28:02+00:00,,1,0,"[Label(name=""oncall: mobile"")]"
67602,[feature request] Add no-op set_epoch on Sampler class,2021-10-31 21:49:31+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
67599,"Mobile builds need to make custom build of libtorch to run, let's just include it to make it easier",2021-10-31 19:45:13+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
67598,unnecessary warning with autocast ,2021-10-31 13:10:12+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
67597,torch.kthvalue (and maybe torch.quantile) should support argument descending/largest (=True) like topk/sort,2021-10-31 10:10:54+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
67594,Feature request: set_grad_enabled(*mods_or_params) as a safe context manager,2021-10-31 01:45:22+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""low priority""), Label(name=""triaged"")]"
67590,Add `OptState.UPDATED` to `torch.cuda.amp.GradScaler`,2021-10-30 16:22:53+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
67589,Expose the `OptState` in `torch.cuda.amp.GradScaler`,2021-10-30 16:22:43+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
67587,Re-implement `Optimizer.__repr__`,2021-10-30 14:41:47+00:00,,0,4,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: python frontend"")]"
67586,SequentialLR have a question and why it use `step(epoch)`,2021-10-30 08:25:40+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
67571,[discussion] Have default size/shape equal to a scalar,2021-10-29 22:00:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random"")]"
67570,RFC: Overlap optimizer computation with DDP/FSDP backward,2021-10-29 21:43:54+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
67565,Adding a new kwarg to a torch.nn.functional function breaks FC for JIT ,2021-10-29 20:03:59+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""better-engineering"")]"
67543,[FX] Support `int` and similar variants in FX,2021-10-29 11:01:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
67542,Segfault from ONNX exporting code where torch.jit.script and torch.no_grad are used together,2021-10-29 10:42:03+00:00,,0,0,"[Label(name=""oncall: jit"")]"
67541,TestBenchNetwork::test_forward[resnet50_jit-profiling-te] is failing intermittently,2021-10-29 09:02:29+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""NNC"")]"
67540,LTC asynchronous executor is not synced with python code and ignores context manager.,2021-10-29 08:38:59+00:00,,0,3,"[Label(name=""triaged""), Label(name=""LazyTensor_nvfuser_integration""), Label(name=""module: lazy"")]"
67535,[LTC] `UncachedCompile` numbers increases for several iterations until fixed ,2021-10-29 05:20:02+00:00,,0,4,"[Label(name=""triaged""), Label(name=""lazy""), Label(name=""module: lazy"")]"
67493,XLA not being tested in TestAutogradDeviceType,2021-10-28 23:03:01+00:00,,0,7,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: xla"")]"
67482,Improve docs coverage testing,2021-10-28 21:09:28+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""better-engineering"")]"
67481,Batchnorm2D does behaves differently with different shapes when batch_size=1,2021-10-28 21:07:25+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
67474,[JIT][Feature] Runtime Verifier of Alias Annotations,2021-10-28 20:33:56+00:00,,0,2,"[Label(name=""oncall: jit"")]"
67473,"[Feature] Separate, Queryable Alias Parser ",2021-10-28 20:29:44+00:00,,0,2,"[Label(name=""oncall: jit"")]"
67470,"integer (and possibly float16) matmul fails test_noncontiguous_samples on CPU (and all backward dtypes, too?)",2021-10-28 20:17:05+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: correctness (silent)"")]"
67463,`test_forward_mode_AD` hangs for `nn.functional.cosine_embedding_loss`,2021-10-28 19:25:28+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""module: forward ad"")]"
67462,Jacobian mismatch for `nn.functional.ctc_loss`,2021-10-28 19:20:47+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: correctness (silent)"")]"
67458,OpInfo JIT tests fail for torch.nonzero,2021-10-28 18:28:58+00:00,,0,0,"[Label(name=""oncall: jit"")]"
67457,"Reductions on zero-size dims: 1) by accepting a custom default value, 2) if tensor has another non-reduced zero-size dim",2021-10-28 17:58:38+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: reductions"")]"
67450,CUDA gradcheck tests can occasionally leak memory in HUD CI,2021-10-28 15:42:37+00:00,,0,9,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""module: tests""), Label(name=""triaged"")]"
67448,Deadlock in test_multiprocessing_spawn.py,2021-10-28 15:28:23+00:00,,0,0,"[Label(name=""high priority""), Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
67446,`/var/lib/jenkins/workspace/xla/test/test_mp_rendezvous.py` potentially flaky,2021-10-28 15:19:04+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: xla"")]"
67439,Exception in thread when using dataloader,2021-10-28 12:22:52+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
67420,Avoid warnings when jitting pytorch modules,2021-10-28 05:21:31+00:00,,0,0,"[Label(name=""oncall: jit"")]"
67402,[Documentation] Incomplete FX module,2021-10-27 23:43:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
67392,Missing doc for torch.jit functions,2021-10-27 22:44:55+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: docs"")]"
67390,Missing doc for torch.distributions functions,2021-10-27 22:43:34+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""module: docs""), Label(name=""triaged"")]"
67389,Missing doc for torch.distributed functions,2021-10-27 22:42:14+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""better-engineering"")]"
67388,Missing doc for torch.cuda functions,2021-10-27 22:39:48+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
67387,Missing doc for torch.autograd functions,2021-10-27 22:36:04+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged"")]"
67377,[LTC] Replace mv with addmv in ts_native_functions.yaml,2021-10-27 21:30:26+00:00,,1,0,"[Label(name=""triaged"")]"
67364,[FX] FX torchvision tests fail with torchvision 0.10,2021-10-27 20:32:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
67362,JIT fuser throws compilation error (1.10 regression),2021-10-27 20:03:41+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: regression""), Label(name=""NNC"")]"
67350,[FX] autowrap_functions doesn't work for module-scoped functions,2021-10-27 18:35:13+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
67349,PyTorch Profiler built with Bazel doesn't produce GPU trace,2021-10-27 18:31:35+00:00,,0,6,"[Label(name=""oncall: profiler""), Label(name=""module: bazel"")]"
67337,Support prim_layout operator in onnx,2021-10-27 15:59:42+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
67333,Feature request: Complex Number Support for Special Functions,2021-10-27 15:21:00+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: special"")]"
67324,torch.stft - fill_cuda not implemented for ComplexHalf,2021-10-27 08:20:24+00:00,,0,9,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: half"")]"
67321,alias to generate tensor with random uniform distribution.,2021-10-27 06:15:46+00:00,,0,14,"[Label(name=""feature""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: random"")]"
67312,ProcessGroupNCCLTest.testSequenceNumInit is failing on 4xlarge,2021-10-27 03:24:47+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
67284,Failed to build with master.,2021-10-26 20:46:37+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkl"")]"
67279,register_dispatch_key should provide a way to tell if a native function has a no-op meta kernel,2021-10-26 19:08:03+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: lazy"")]"
67247,pytorch_linux_xenial_py3_6_gcc5_4_test may timeout during test_multiprocessing_spawn,2021-10-26 05:42:32+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: multiprocessing""), Label(name=""module: tests""), Label(name=""triaged"")]"
67241,"init_process_group hangs for multi-node, Pytorch > v1.3.1 and file init_method",2021-10-26 03:31:10+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: nccl""), Label(name=""module: deadlock"")]"
67240,Feature: Add derivative for channel_shuffle,2021-10-26 03:15:54+00:00,,1,11,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
67237,[docs] Google finds docs pages that give 404,2021-10-26 02:02:29+00:00,,1,15,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""triaged"")]"
67208,TestForeachCUDA.test_binary_op_tensorlists_fastpath__foreach_add_cuda_bool and TestForeachCUDA.test_pointwise_op_fastpath__foreach_addcmul_cuda_uint8 fail intermittently,2021-10-25 20:23:44+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: mta"")]"
67187,Expose `isDifferentiableType` to python,2021-10-25 15:24:41+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
67168,Multiply two named tensor causes RuntimeError,2021-10-25 03:10:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
67160,"Include function name in ""This Python function is annotated to be ignored and cannot be run"" error message",2021-10-24 20:16:59+00:00,,0,0,"[Label(name=""oncall: jit"")]"
67159,test_local_optimizer_parity (__main__.TestZeroRedundancyOptimizerDistributed) is flaky on rocm,2021-10-24 20:15:48+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: rocm""), Label(name=""module: flaky-tests"")]"
67158,Make streams used for NCCL operations configurable,2021-10-24 17:13:26+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl"")]"
67153,Build not working with cuda 11.5,2021-10-24 05:39:28+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
67146,`torch.jit.is_scripting()` not set when scripting a Module,2021-10-23 13:34:23+00:00,,0,6,"[Label(name=""oncall: jit"")]"
67142,"enumerate(..., start=idx) is not working correctly while scripting",2021-10-23 10:47:45+00:00,,0,3,"[Label(name=""oncall: jit"")]"
67136,addition of loss function RMSE in the torch.nn ,2021-10-23 04:51:44+00:00,,0,8,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""actionable"")]"
67111,[doc] Can we update TorchScript union support?,2021-10-22 20:04:54+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: docs"")]"
67099,JIT: inconsistency in LSTM.forward,2021-10-22 16:38:47+00:00,,0,0,"[Label(name=""oncall: jit"")]"
67092,Sparse matrix multiplication (torch.sparse.mm) NotImplementedError,2021-10-22 15:00:11+00:00,,1,1,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
67087,Feature Request: 1d grid sample,2021-10-22 11:58:49+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
67084,Failing test_neg_view_nn_functional_embedding_cuda_float64,2021-10-22 09:16:57+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""module: flaky-tests""), Label(name=""module: complex""), Label(name=""actionable"")]"
67071,Forward results vary depending on batch size on A100 machine,2021-10-22 02:15:36+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
67030, fx graph mode quantizing error  ,2021-10-21 17:24:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
67011,Importing numpy interacts with `tensor.sum` perf,2021-10-21 10:19:01+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: numpy"")]"
67008,kwonly arguments without defaults don't work with test_overrides.py,2021-10-21 08:56:58+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
66992,Bug? :Run torch.unique twice get different running time? ,2021-10-21 03:29:24+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: sorting and selection""), Label(name=""module: benchmark"")]"
66963,Significantly difference in execution time when convolution is run as nn.Conv2d and as nn.Sequential,2021-10-20 20:31:54+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
66937,[doc] Long Function Name (C++) overlapping on the side menu,2021-10-20 12:56:57+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
66936,Lifetime issues when recording external CUDA streams with the caching allocator,2021-10-20 12:15:00+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
66930,JIT vs. eager mismatches for jit.traced `int8` to `int32` casting,2021-10-20 08:56:58+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
66924,[BUG] Inconsistent initialization on different machines (tensor.uniform_()),2021-10-20 03:41:25+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: random"")]"
66921,readme not update,2021-10-20 01:41:20+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
66907,torch.chunk return type may not be documented correctly,2021-10-19 23:38:46+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
66902,Modify Dr. CI so it could detect runner disconnection failures,2021-10-19 23:13:55+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
66894,test_nccl_barrier_timeout_new_group_non_member fails intermittently,2021-10-19 20:21:48+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: tests"")]"
66875,"Make the evaluated value of function f(x) accessible from `torch.autograd.functional.jacobian(f,x)`",2021-10-19 15:53:50+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
66874,Error using _stateless version of Module,2021-10-19 15:53:44+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable"")]"
66868,torch.triu behaves differently when diagonal out of range,2021-10-19 14:41:19+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
66858,CUDAgraph error while capturing ,2021-10-19 10:35:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
66853,"Libtorch C++ model forward  crashed on windows10, CUDA 11.2, Qt ,RTX 3070, but libtorch C++ works with cpu successfully",2021-10-19 03:37:24+00:00,,0,9,"[Label(name=""module: windows""), Label(name=""triaged"")]"
66841,"[Torchscript] Comparison between list and int returns true  [1] == (1, ) == 1",2021-10-19 02:17:15+00:00,,0,0,"[Label(name=""oncall: jit"")]"
66824,Migrate C++ tests to Python runner,2021-10-18 23:54:10+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
66816,Jit fuser half precision support,2021-10-18 20:34:19+00:00,,0,5,"[Label(name=""oncall: jit"")]"
66813,Use `__slots__` for the `nn.Module` class,2021-10-18 20:12:49+00:00,,1,11,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
66806,Missing doc for `torch.segment_reduce`,2021-10-18 18:25:09+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy"")]"
66791,jit tracer：Lost imported pre-model parameters,2021-10-18 14:42:30+00:00,,0,0,"[Label(name=""oncall: jit"")]"
66787,loading large model not finished after 16 hours,2021-10-18 10:20:20+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: serialization""), Label(name=""triaged"")]"
66782,"Segmentation Fault when importing Torch, 2021 version",2021-10-18 09:22:36+00:00,,0,17,"[Label(name=""module: binaries""), Label(name=""module: crash""), Label(name=""triaged"")]"
66781,lr_scheduler.py  /  list index out of range,2021-10-18 08:58:41+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
66775,Feature request: FFT operations on Metal,2021-10-18 05:20:16+00:00,,0,7,"[Label(name=""feature""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""oncall: mobile""), Label(name=""module: fft"")]"
66768,Error: `copy_to_metal_ is implemented only for float dtype`,2021-10-17 16:55:04+00:00,,0,0,"[Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
66755,Domain Transformation APIs for LibTorch and LibTorch-Lite,2021-10-16 12:12:54+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: data"")]"
66751,torch.nn.functional.embedding behave differently in two cases of cpu and cuda,2021-10-16 02:52:15+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: embedding"")]"
66750,torch.nn.EmbeddingBag behave differently in two cases of cpu and cuda,2021-10-16 02:40:55+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: embedding"")]"
66707,`layer_norm` needs to be done in fp32 for fp16 inputs,2021-10-15 18:30:53+00:00,,0,9,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""actionable""), Label(name=""module: norms and normalization"")]"
66678,Adding modern linear transformer variants to `transformer` module,2021-10-15 03:27:47+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
66656,RFC: Create unified CI experience for pytorch and domain libraries,2021-10-14 20:50:51+00:00,,1,0,"[Label(name=""module: binaries""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""better-engineering"")]"
66651,[JIT] Profile optional tensor,2021-10-14 20:16:33+00:00,,0,0,"[Label(name=""oncall: jit"")]"
66640,Static Build of Libtorch not linking correctly,2021-10-14 18:04:50+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
66627,Overhaul error handling in `TCPStore`,2021-10-14 15:23:52+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""better-engineering"")]"
66624,Separate libtorch and non-libtorch specific files under `torch/csrc/distributed`,2021-10-14 14:58:36+00:00,,0,0,"[Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
66623,Constant folding in symbolic shape inference fails: expected scalar type Long but found Float,2021-10-14 14:02:02+00:00,,0,2,"[Label(name=""oncall: jit"")]"
66573,tools/amd_build/build_amd.py should fail if any file fails to write,2021-10-13 20:52:38+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: rocm""), Label(name=""triaged"")]"
66565,Bazel target all_tests improperly reports failures on CPU-only (non-CUDA) build,2021-10-13 19:06:07+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: bazel"")]"
66563,Give a better error message when REGISTER_DISPATCH is used in improper context,2021-10-13 18:49:29+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
66547,"destroy_process_group() does not clear worker count, leading to ""Timed out initializing process group in store based barrier""",2021-10-13 10:59:23+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
66545,Forward method slows down at some point if it is executed repeatedly on Android with NNAPI,2021-10-13 08:52:42+00:00,,0,0,"[Label(name=""module: android""), Label(name=""oncall: mobile""), Label(name=""mobile_perf"")]"
66542,Is there a bug in transposed convolution？,2021-10-13 06:12:20+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
66504,BatchNorm runtimeError: one of the variables needed for gradient computation has been modified by an inplace operation,2021-10-12 20:27:16+00:00,,1,10,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""better-engineering""), Label(name=""module: ddp"")]"
66491,Normalize handling of scalar arguments,2021-10-12 17:45:44+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
66489,The uniform operator param names in the C++ impl use python keywords,2021-10-12 17:10:22+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
66482,BAR1 memory of GPU is not released when main process is killed.,2021-10-12 15:30:30+00:00,,0,19,"[Label(name=""module: dataloader""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
66476,"0INTERNAL ASSERT FAILED, We don't have an op for aten::eq but it isn't a special case",2021-10-12 11:24:24+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
66473,nccl comm init needs a global barrier.,2021-10-12 06:30:09+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: nccl"")]"
66460,Inconsistencies in LSTM outputs when processing sequence stepwise on CPU,2021-10-11 23:37:26+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""module: rnn""), Label(name=""triaged"")]"
66410,CIFAR10 doesn't work on M1 MacBook ,2021-10-11 10:24:57+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: arm"")]"
66408,Feature Request: Source code pages should include link to GitHub file,2021-10-11 08:31:54+00:00,,0,14,"[Label(name=""module: docs""), Label(name=""feature""), Label(name=""triaged"")]"
66403,[opinfo] Confusing interface for `ops` decorator ,2021-10-11 06:39:33+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
66366,Feature Request: Add constant padding_mode for grid_sample,2021-10-09 11:50:40+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: padding""), Label(name=""module: interpolation"")]"
66364,Hope to obtain authorization for Chinese translation of official tutorials.,2021-10-09 11:29:08+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
66359,question on installing GPU-enabled Pytorch,2021-10-09 05:11:56+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: lts"")]"
66357,OpInfos disabled for batched forward grad computation,2021-10-09 02:25:49+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: vmap""), Label(name=""module: forward ad"")]"
66341,Invalid handling of out args with type Tensor[] in native_functions.yaml,2021-10-08 20:43:47+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: codegen"")]"
66335,`torch.fx.symbolic_trace()` loses module class information,2021-10-08 19:02:07+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: fx"")]"
66305,Modify convolution kernels for ops,2021-10-08 06:19:20+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fft"")]"
66284,Memory leak issue with pytorch_java_only 1.9.0 and libtorch 1.9.0+cpu,2021-10-07 21:25:56+00:00,,0,6,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile""), Label(name=""oncall: java""), Label(name=""mobile_perf"")]"
66271,1.10.0-rc1 fails to compile with gcc 6.4.0,2021-10-07 18:21:36+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged"")]"
66251,Should the drop_last parameter of Dataloader be mutually exclusive with the batch samplers?,2021-10-07 14:40:08+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
66249,Latency issue with torch.sin,2021-10-07 12:32:34+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""triaged"")]"
66247,Floating point exception in mkl_vml_serv_GetMinN () on a specific computer,2021-10-07 12:20:07+00:00,,0,4,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: mkl"")]"
66224,[feature request][quant] Support FakeQuant qconfigs in `test_module_init`,2021-10-06 20:38:11+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
66223,Data Loader tests hang when run in ASAN test job,2021-10-06 20:18:11+00:00,,0,4,"[Label(name=""module: dataloader""), Label(name=""module: tests""), Label(name=""triaged"")]"
66208,Add LTC-TS support for ops used in SGD optimizer,2021-10-06 17:05:01+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
66200,An exported onnx model can't reduce on dim with value of 0 if 'keepdims' is false,2021-10-06 14:40:29+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
66199,Move the `queue_callback()` API out of `Variable._execution_engine` and into a public API,2021-10-06 14:18:30+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
66197,`torch.fx.replace_pattern` doesn't work with untraceable wrapped functions,2021-10-06 12:12:49+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
66196,Specifying USE_VULKAN=0 in launching build_android.sh does not disable Vulkan,2021-10-06 12:04:51+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vulkan"")]"
66162,Cuda Out of Memory - MMDMatic,2021-10-05 20:37:13+00:00,,0,3,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
66150,JIT: empty_like doesn't support requires_grad,2021-10-05 18:04:58+00:00,,0,0,"[Label(name=""oncall: jit"")]"
66116,Removal of BufferedShuffleDataset,2021-10-05 09:11:40+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: data"")]"
66094,[JIT][Sym Shape Analysis] Extend analysis to extract output shape logic,2021-10-04 22:29:34+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp"")]"
66083,[feature request] Allow broadcasting for F.huber_loss and potentially other losses,2021-10-04 15:59:50+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: shape checking"")]"
66076,Bad Input to torch.nn.NLLLoss causes CUDA Error,2021-10-04 12:59:20+00:00,,0,2,"[Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""triaged"")]"
66073,[feature request] BatchNorm frozen mode in core,2021-10-04 12:08:14+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: norms and normalization"")]"
66066,Finishing OpInfos: test_autograd.py,2021-10-04 08:13:14+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""hackathon"")]"
66065,torch.jit.script fails to cast explicit Optional parameter to bool,2021-10-04 06:35:51+00:00,,0,0,"[Label(name=""oncall: jit"")]"
66046,PicklingError when saving a ddp module with torch.save(),2021-10-02 06:10:12+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
66042,[LTC] Investigate why max_pool2d_with_indices needs explicit eager fallback,2021-10-02 04:21:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""lazy""), Label(name=""module: lazy"")]"
66033,Crashed with `terminating with uncaught exception of type std::__1::system_error: condition_variable wait failed: Invalid argument`,2021-10-01 22:11:03+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: multithreading"")]"
66026,`__torch_dispatch__` can result in returning `None` for an op that should return Tensors.,2021-10-01 21:25:13+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: pybind""), Label(name=""module: __torch_dispatch__"")]"
66017,Torchscript `jit.script` breaks with OSError if dataclass used to pass results during model execution,2021-10-01 18:53:32+00:00,,0,0,"[Label(name=""oncall: jit"")]"
65985,torch.cuda.power_usage (ESG 🌱),2021-10-01 06:32:34+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""oncall: profiler"")]"
65984,libtorch: collate_fn equivalent,2021-10-01 06:14:18+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
65983,"traced EmbeddingBag cannot be used with different batch size, functional.embedding_bag is not de",2021-10-01 06:10:47+00:00,,0,2,"[Label(name=""oncall: jit"")]"
65950,"Storage `is` should work if the storages ""are the same""",2021-09-30 20:49:15+00:00,,1,2,"[Label(name=""feature""), Label(name=""triaged"")]"
65949,torch.unique signature is not descriptive,2021-09-30 20:47:07+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
65936,[POLL][RFC] DataParallel Deprecation,2021-09-30 17:38:39+00:00,,0,19,"[Label(name=""triaged""), Label(name=""module: deprecation"")]"
65918,C++ extensions don't correctly set USE_C10D_FOO preprocessor macros,2021-09-30 12:25:45+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
65915,"I am getting undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE error. This I am getting when I am trying to ""import torch from nemo.collections import nlp"". I am trying to use pytorch ngc container 21.05. I tried to import torch before the nemo extension. Please suggest how I can resolve this.",2021-09-30 12:08:43+00:00,,0,1,"[Label(name=""oncall: jit"")]"
65913,Support differentiability through clone and update,2021-09-30 10:57:26+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs design"")]"
65910,Deprecation: Remove nn.functional.sigmoid ,2021-09-30 08:54:48+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: deprecation"")]"
65907,Inplace error of BatchNorm layer in DistributedDataParallel module,2021-09-30 08:28:19+00:00,,0,3,"[Label(name=""oncall: distributed"")]"
65890,`pad_packed_sequence` is not exactly the inverse of `pack_padded_sequence`,2021-09-30 07:15:30+00:00,,0,0,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
65881,torch.hub.load can confuse external python package with local python package. ,2021-09-30 06:03:53+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: hub"")]"
65868,torch.mul is not consistent with torch.multiply,2021-09-30 00:29:04+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: numpy"")]"
65837,NVFuser Examples to Help with Integration with Lazy Tensor Core,2021-09-29 19:00:07+00:00,,1,11,"[Label(name=""triaged""), Label(name=""LazyTensor_nvfuser_integration""), Label(name=""module: lazy"")]"
65825,Incorrect reference to previous kernel in the warning displayed when overriding a previously registered kernel for the same operator and the same dispatch,2021-09-29 16:38:45+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
65824,Failing to compile /torch/csrc/jit/frontend/ir_emitter.cpp with pointer is null warning,2021-09-29 16:05:37+00:00,,0,1,"[Label(name=""oncall: jit"")]"
65815,Overflow error in torch.linalg uncaught,2021-09-29 12:49:03+00:00,,0,10,"[Label(name=""high priority""), Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""module: linear algebra""), Label(name=""module: correctness (silent)""), Label(name=""module: reductions"")]"
65814,INTERNAL ASSERT FAILED when reusing JIT compiled module,2021-09-29 11:52:06+00:00,,0,0,"[Label(name=""oncall: jit"")]"
65813,[RFC] Low-level speed optimizations for PowerSGD,2021-09-29 11:46:45+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""enhancement""), Label(name=""module: ddp"")]"
65811,"Beta distribution yields wrong results for a,b >1 and x=0 or x=1",2021-09-29 08:47:04+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
65788,Autocast sometimes discards changes to mutable arguments,2021-09-28 22:52:37+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)""), Label(name=""module: intel"")]"
65776,`torch.jit.save` fails on Windows,2021-09-28 20:42:03+00:00,,0,0,"[Label(name=""oncall: jit"")]"
65774,Non-persistent modules,2021-09-28 20:31:45+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""low priority""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""enhancement"")]"
65766,Temporarily disabling grad doesn't work if AMP is enabled,2021-09-28 19:20:47+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
65761,torch.utils._pytree -> stable,2021-09-28 19:15:51+00:00,,0,13,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""needs design"")]"
65760,Codegen issues with Tensor(a!)? arguments in native_functions.yaml schemas,2021-09-28 18:34:10+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
65753,[POC] Convolution-relu fusion via torch function and one-step lazy evaluation,2021-09-28 17:30:19+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: __torch_function__""), Label(name=""module: lazy"")]"
65752,Deprecate torch.cross with optional dim,2021-09-28 17:08:14+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: deprecation"")]"
65739,Sobol state API,2021-09-28 12:26:27+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: random"")]"
65734,pytorch mobile: some quant models on android cause memory leak,2021-09-28 05:53:19+00:00,,0,1,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
65718,Migrate current Windows CI scripts off of batch,2021-09-27 22:05:18+00:00,,1,6,"[Label(name=""module: windows""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""better-engineering"")]"
65702,Indicate support for more general use of `pos_weight` in binary cross entropy,2021-09-27 17:25:30+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
65698,torch.onnx.export error ,2021-09-27 16:43:13+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
65694,Plain Tensor serialization does not save the content of `__dict__`.,2021-09-27 15:12:30+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
65693,Add at least one config running GPU testing on sm_80+ cards,2021-09-27 14:47:01+00:00,,1,2,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement"")]"
65688,Parametrization silently disables RNN weight updates ,2021-09-27 11:41:57+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
65687,"repeat_interleave changes memory format from ""channels last"" to ""contiguous""",2021-09-27 11:33:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
65683,`torch.nn.functional.l1_loss` fails gradgradcheck for complex inputs,2021-09-27 09:45:27+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: complex"")]"
65673,[libtorch]incorrect sigmoid result on arm chip(rk3326),2021-09-27 02:28:17+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: arm"")]"
65670,Memory Leak in Distributed RPC nightly,2021-09-26 19:43:24+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
65665,Pipe method for torch tensors,2021-09-26 07:00:58+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
65664,C10dProcessGroupSerialization.test_process_group_as_module_member is flaky,2021-09-26 06:59:18+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
65663,Model Evaluation Returns Nan Values Sometimes for the Same Input,2021-09-26 06:29:48+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
65662,mobile deployment: optimized_for_mobile---wrap_cpp_module error,2021-09-26 03:19:14+00:00,,0,2,"[Label(name=""oncall: mobile""), Label(name=""mobile_perf"")]"
65661,[BUG] ConvTranspose with out_channels=1 ,2021-09-26 00:34:47+00:00,,0,2,"[Label(name=""module: convolution""), Label(name=""triaged"")]"
65660,[JIT] allow annotation with `nn.Module` for documentation purposes.,2021-09-25 20:38:55+00:00,,0,0,"[Label(name=""oncall: jit"")]"
65657,Transpose channels when exporting to ONNX,2021-09-25 16:05:47+00:00,,1,2,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
65653,[JIT] torch.load(model) fails for Unicode Variable Names.,2021-09-25 10:43:30+00:00,,0,2,"[Label(name=""oncall: jit"")]"
65650,Does ZeroRedundancyOptimizer support re-split partition on load_state_dict?,2021-09-25 04:49:19+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
65646,[LTC] Building unit tests on Debian results in double defined _GLIBCXX_USE_CXX11_ABI flag,2021-09-25 01:32:11+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
65643,[JIT] Start Using and Optimizing on Symbolic Shape Inference in Freezing,2021-09-24 23:40:22+00:00,,1,2,"[Label(name=""oncall: jit"")]"
65640,[LTC] Memory growing up during training until OOM,2021-09-24 22:39:27+00:00,,0,19,"[Label(name=""triaged""), Label(name=""lazy""), Label(name=""module: lazy"")]"
65637,Test ZeRO on gloo backend for GPU,2021-09-24 22:17:55+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
65630,Constants in torch.Jit.script,2021-09-24 20:50:20+00:00,,0,0,"[Label(name=""oncall: jit"")]"
65628,Add torch.distributed.shard package,2021-09-24 19:56:56+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""sharded_tensor"")]"
65622,Transformer modules should not hard-code the activation function,2021-09-24 18:48:27+00:00,,0,8,"[Label(name=""module: nn""), Label(name=""triaged"")]"
65619,Integration of __torch_dispatch__ with masked tensor semantics,2021-09-24 18:12:41+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
65617,Derivative not implemented for narrow_copy,2021-09-24 16:44:24+00:00,,1,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
65611,"`torch.jit.trace` fails claiming ""forward method already defined""",2021-09-24 14:01:41+00:00,,0,5,"[Label(name=""oncall: jit"")]"
65607,torch.dtype is int in JIT instead of torch.dtype,2021-09-24 09:10:55+00:00,,0,7,"[Label(name=""oncall: jit"")]"
65604,pytorch serializes entire tensor when you try to pickle a slice,2021-09-24 06:24:08+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
65588,Make torch.utils.tensorboard.add_scalar accepts float global_step ,2021-09-23 23:38:08+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
65577,Support cat() for meta tensors,2021-09-23 20:47:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: meta tensors"")]"
65576,[LTC] Code-gen IRs and TorchScript lowerings needed by running full TorchBench,2021-09-23 20:20:43+00:00,,1,12,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: lazy"")]"
65572,PyTorch setup.py should confirm with user if the user changes build flags,2021-09-23 20:09:30+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
65569,Support 'meta' device for 'shard_parameter' API,2021-09-23 19:56:51+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""sharded_tensor"")]"
65559,TestMultiprocessing.test_fs_sharing is flaky,2021-09-23 18:22:49+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
65536,Pass backward flags such as retain_graph to context of custom torch.autograd.Function,2021-09-23 14:53:38+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
65532,TorchScript can't handle super() in subclass of nn.Sequential,2021-09-23 13:40:39+00:00,,0,1,"[Label(name=""oncall: jit"")]"
65528,I cannot use x.to(GPU) or x.cuda(GPU),2021-09-23 11:05:50+00:00,,0,10,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
65526,[docs] Better explain signature of toch.randn,2021-09-23 10:19:50+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
65522,"pytorch framework tests using make_tensor hangs with pytest's boxed exec option ""--forked""",2021-09-23 07:38:46+00:00,,0,9,"[Label(name=""module: tests""), Label(name=""triaged"")]"
65521,DISABLED test_profiler (__main__.TestJit),2021-09-23 07:13:01+00:00,,0,10,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""module: tests""), Label(name=""skipped""), Label(name=""oncall: profiler"")]"
65520,Improve input checking for running_var of nn.functional.batch_norm on CPU/GPU,2021-09-23 05:41:38+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
65512, Performance problems of eigh operator on CPU,2021-09-23 02:07:25+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged"")]"
65510,nn.conv1d padding='same',2021-09-23 01:48:29+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: convolution""), Label(name=""triaged"")]"
65494,Feature request: add bool dtype support to CPU abs(),2021-09-22 20:58:27+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement"")]"
65490,optimize_for_mobile() assert fail: missing op for prepacked::conv2d_clamp_prepack,2021-09-22 19:20:49+00:00,,0,3,"[Label(name=""oncall: mobile""), Label(name=""mobile_perf"")]"
65475,building pytorch from source without conda,2021-09-22 17:00:16+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
65473,API torch.ops.image.read_file reports RuntimeError - No such operator image::read_file,2021-09-22 15:29:05+00:00,,0,17,"[Label(name=""high priority""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: custom-operators"")]"
65465,[LTC] Fail to run testcase of latest lazy_tensor_core branch,2021-09-22 13:40:12+00:00,,1,2,"[Label(name=""triaged""), Label(name=""lazy""), Label(name=""module: lazy"")]"
65464,linking error when building on Linux,2021-09-22 13:39:11+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
65462,"Why here save `store`, rather than `prefix_store`?",2021-09-22 13:19:29+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
65449,Make SummaryWriter.add_image supports PIL image directly ,2021-09-22 06:02:38+00:00,,0,1,"[Label(name=""oncall: visualization"")]"
65448,Magma : Intel MKL Errors,2021-09-22 04:44:45+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: intel""), Label(name=""module: magma"")]"
65447,No support for torch.trace on CPU for float16 tensors,2021-09-22 04:44:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: half"")]"
65446,libtorch compile problem. How to get the correct protobuf version? what PROTOBUF_VERSION <3011000 and 3011004 <PROTOBUF_MIN_PROTOC_VERSION?,2021-09-22 04:28:27+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: protobuf""), Label(name=""triaged"")]"
65436,Make DDP uneven inputs work with custom buffer reduction,2021-09-21 23:37:51+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
65428,module 'torch.distributed' has no attribute 'optim',2021-09-21 21:43:34+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
65426,Add a `__torch_pre_dispatch__` that will live at the top of the dispatcher,2021-09-21 20:23:01+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
65423,Enable is_contiguous slowpath for torch_dispatch,2021-09-21 18:50:41+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
65418,Sending tensors from short-lived multiprocessing process fails on Linux,2021-09-21 17:22:19+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
65400,torch.sparse.sum on scalar sparse tensor fails when dim is specified,2021-09-21 12:23:02+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
65398,[JIT] JIT does not support non-persistent buffers,2021-09-21 11:56:00+00:00,,0,0,"[Label(name=""oncall: jit"")]"
65397,Vague linkage when using libcxxabi built torch in torch_glow,2021-09-21 11:45:18+00:00,,0,2,"[Label(name=""oncall: jit"")]"
65393,PyTorch Profiler is not working with CUDA,2021-09-21 07:40:49+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: windows""), Label(name=""oncall: profiler"")]"
65392,torch.sparse.sum result has wrong dtype when reducing over all dimensions,2021-09-21 07:36:12+00:00,,0,11,"[Label(name=""high priority""), Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: correctness (silent)"")]"
65386,[LTC] Setup a subset of TorchBench for the current implementation,2021-09-21 01:41:55+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
65375,Make python_error use c10/util/Exception.h C++ backtrace machinery,2021-09-20 21:47:59+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""better-engineering"")]"
65366,Exception thrown in final autograd callback (queue_callback) not caught if not on CPU thread: terminate called after throwing an instance of 'python_error',2021-09-20 20:05:06+00:00,,0,7,"[Label(name=""module: crash""), Label(name=""module: bootcamp""), Label(name=""module: autograd""), Label(name=""triaged"")]"
65357,Improve DDP tutorial,2021-09-20 18:19:51+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: ddp"")]"
65342,Unexpected behaviour when resuming from checkpoint using CosineAnnealingLR,2021-09-20 15:43:40+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
65339,Make it easier to accurately reflect storage/view relationships in meta/wrapper tensors,2021-09-20 15:12:48+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: meta tensors""), Label(name=""module: __torch_dispatch__"")]"
65329,How can I re-weight a sample based on both class weights and instance weights?,2021-09-20 12:49:37+00:00,,0,1,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""enhancement"")]"
65325,ChannelShuffle: Missing CUDA implementation,2021-09-20 10:40:14+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
65313,openSUSE Build: CMake Generate step failed.  Build files cannot be regenerated correctly.,2021-09-19 15:31:00+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
65307,[numpy] Add torch.newdim/torch.newaxis,2021-09-19 05:37:25+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
65306,[numpy] Add `iscomplexobj` and `isrealobj`,2021-09-19 05:23:41+00:00,,1,6,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy"")]"
65305,Add support for HF NLP models in torch.package/deploy,2021-09-18 22:46:51+00:00,,0,1,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
65301,Anomaly detection: Error detected in CudnnRnnBackward0,2021-09-18 17:47:55+00:00,,0,18,"[Label(name=""module: cudnn""), Label(name=""module: rnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
65297,[JIT] TorchScript not works as expected when ModuleDict has modules with different signatures,2021-09-18 10:44:38+00:00,,0,0,"[Label(name=""oncall: jit"")]"
65261,Add an `all_paths` method to PackageExporter,2021-09-18 00:02:16+00:00,,1,0,"[Label(name=""triaged""), Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
65253,TestCppExtensionJit's test_crash_handler fails for force_on_cpu job on GHA,2021-09-17 22:40:36+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
65230,RuntimeError: Trying to create tensor with negative dimension -1741885395: [-1741885395],2021-09-17 17:03:19+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
65229,at::parallel_for created max_threads for inputs larger than GRAIN_SIZE,2021-09-17 17:01:29+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: openmp""), Label(name=""module: multithreading"")]"
65218,Indexing a tensor with a NumPy array sometimes works and sometimes doesn't,2021-09-17 14:52:16+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing"")]"
65216,Add function that retrieves a batch from a DataLoader,2021-09-17 14:48:27+00:00,,0,6,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
65215,_disabled_torch_function_impl should not be necessary for __torch_dispatch__,2021-09-17 14:40:06+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
65198,Multi-processing leaking file descriptors,2021-09-17 05:55:19+00:00,,0,12,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
65193,[Better Engineering] Generalize DDPSink and consolidate it with FSDP's pre-backward hooks,2021-09-17 03:08:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
65166,Review the Tensor and Operator Basics Onboarding page,2021-09-16 20:52:55+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
65163,Parametrization cannot be parametrized,2021-09-16 18:34:45+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
65161,error: ‘_mm512_set_epi8’ was not declared in this scope when build from source on AMD 3600 CPU,2021-09-16 18:28:22+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vectorization"")]"
65156,[feature request] Jagged / padding version of torch.stack / torch.cat + some general nested tensor discussion,2021-09-16 17:42:40+00:00,,0,33,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: nestedtensor""), Label(name=""module: padding"")]"
65153,Unification of model initialization methods / naming across domain libraries + support of skip_init,2021-09-16 17:19:34+00:00,,0,11,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: initialization"")]"
65151,Registering a global fallback for all operators that defaults us to assuming that autograd is not implemented,2021-09-16 16:41:15+00:00,,0,0,"[Label(name=""module: bc-breaking""), Label(name=""feature""), Label(name=""module: autograd""), Label(name=""module: molly-guard""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""topic: bc breaking"")]"
65144,jit.trace's returned module returns a tuple instead of a named tuple,2021-09-16 14:54:17+00:00,,0,0,"[Label(name=""oncall: jit"")]"
65140,profiler_legacy `_parse_legacy_records` deduplication logic has false-positive.,2021-09-16 11:04:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
65132,How to reference a tensor variable from a superclass of `torch.Tensor`?,2021-09-16 07:31:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: xla"")]"
65131,Adding a device variable to a `torch.Tensor` subclass fails,2021-09-16 07:27:35+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: xla"")]"
65117,[Comment] remove torch.cuda.synchronize() in state_dict(),2021-09-16 00:25:24+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: fsdp"")]"
65100,[Bug] [CUDA IPC] CUDA IPC memory cost,2021-09-15 21:36:14+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
65098,Bug: torch.jit.load cannot load from IOBuffer,2021-09-15 21:34:12+00:00,,0,1,"[Label(name=""oncall: jit"")]"
65096,[FX] `passes.split_module` doesn't have documentation,2021-09-15 20:48:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
65083,THPVariable_subclass_dealloc (i.e. tp_dealloc for torch.Tensor) should handle Python error state gracefully,2021-09-15 18:44:22+00:00,,0,3,"[Label(name=""high priority""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
65069,torch.linalg.cholesky does not raise a RuntimeError when the matrix is not symmetric,2021-09-15 16:13:26+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
65067,[DataPipe] Add Test Cases to Ensure Correct Behaviors When IterDataPipes Reset,2021-09-15 16:07:47+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: data"")]"
65062,Gloo and TensorPipe depend on different version of libuv,2021-09-15 15:06:49+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party""), Label(name=""module: tensorpipe"")]"
65058,Add nnapi serialization for module components in Wav2Vec2Model,2021-09-15 14:36:41+00:00,,0,3,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
65052,Use hyphens to separate long CLI parameters instead of underscores,2021-09-15 12:50:05+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""better-engineering"")]"
65051,deepcopy of Lazy modules returns an exception,2021-09-15 12:09:53+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: __torch_function__""), Label(name=""module: lazy"")]"
65050,torch.cross precision problem,2021-09-15 09:11:11+00:00,,0,0,"[Label(name=""module: numerical-stability""), Label(name=""triaged"")]"
65049,Setting a random seed or passing a generator to Modules for deterministic sampling.,2021-09-15 08:43:21+00:00,,0,12,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random""), Label(name=""module: determinism"")]"
65038,"[pytorch v1.9.0] for torch sync.pipeline in a single GPU, passing tensor layer by layer is better or using the skip-connection API is better?",2021-09-15 03:40:06+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""pipeline parallelism"")]"
65027,CUDA out of memory,2021-09-14 23:06:17+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
65022,"[AWS EC2 P3DN, EFA is enabled] Torch RPC tensorpipe/common/ibv.h:172 """": Operation not supported",2021-09-14 21:56:32+00:00,,0,12,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe""), Label(name=""pipeline parallelism"")]"
65002,Traceback tensor mode,2021-09-14 17:15:25+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""better-engineering"")]"
64997,FX failed to normalize op `block_diag` and `broadcast_tensors`,2021-09-14 16:16:15+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
64986,RandomSampler / DistributedSampler does not seem really random,2021-09-14 12:19:33+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader"")]"
64957,`INTERNAL ASSERT FAILED` after `torch.jit.freeze`,2021-09-13 22:22:57+00:00,,0,1,"[Label(name=""oncall: jit"")]"
64947,Quantile is limited to 16 million elements and have poor performance.,2021-09-13 19:14:20+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: sorting and selection"")]"
64939,BC CI error message should link to some information about how to squash the warning,2021-09-13 17:33:53+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""better-engineering"")]"
64936,[proposal] Let's unify the various gather/scatter ops.,2021-09-13 17:04:54+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""better-engineering""), Label(name=""module: scatter & gather ops"")]"
64932,[RFC] TorchStore - A Shared-Memory Tensor Store,2021-09-13 15:37:29+00:00,,1,44,"[Label(name=""feature""), Label(name=""triaged"")]"
64931,native functions should not be allowed to take in a `grad` argument,2021-09-13 15:29:38+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: codegen"")]"
64918,TorchScript error loading module with float literal default argument,2021-09-13 10:31:07+00:00,,0,0,"[Label(name=""oncall: jit"")]"
64905,[docs] [feature request] Tutorial on implementing correctly distributed dataset evaluators,2021-09-13 07:42:59+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
64897,Either support torch.mean on BoolTensors or fix the error message,2021-09-12 15:50:05+00:00,,0,6,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: boolean tensor""), Label(name=""module: reductions"")]"
64896,pytorch1.9.0 can not use torch.jit.load() to load model which save in pytorch1.3,2021-09-12 14:44:47+00:00,,0,2,"[Label(name=""oncall: jit"")]"
64889,"""RuntimeError: CUDA error: out of memory"" for no reason ",2021-09-12 06:11:15+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
64881,Add support for GPU based data loading and transformation,2021-09-11 08:06:11+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
64874,I am unable to detect torch.Tensor._version change during __torch_dispatch__ call,2021-09-11 02:25:54+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
64868,CMake outputs lots of warnings in CI,2021-09-11 00:14:44+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
64864,Base parallelism on CPU count available to process rather than system total,2021-09-10 23:24:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: multithreading"")]"
64845,Track Reliability of Test Reporting and Uploading,2021-09-10 21:07:57+00:00,,0,2,"[Label(name=""triaged"")]"
64818,Inconsistent NaN handling by cholesky between CPU and CUDA,2021-09-10 15:22:34+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: linear algebra"")]"
64812,PyTorch inference on tensors of a particular size cause Illegal Instruction (core dumped) on Jetson Nano,2021-09-10 13:06:55+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: arm""), Label(name=""module: jetson"")]"
64804,RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation,2021-09-10 07:35:45+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""triaged"")]"
64799,Add support to profile all RPC worker threads that are run on a process,2021-09-10 03:54:16+00:00,,0,5,"[Label(name=""oncall: distributed"")]"
64795,profiler crashes the program when trying to stop on different threads without context manager,2021-09-10 02:38:21+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: multithreading""), Label(name=""oncall: profiler"")]"
64794,linalg.lstsq out variant fails internal assert because it uses non-inplace view op for some inputs,2021-09-10 02:21:26+00:00,,0,2,"[Label(name=""high priority""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
64775,[JIT] Canonicalize aten::rsub ,2021-09-09 20:03:09+00:00,,0,0,"[Label(name=""oncall: jit"")]"
64772,[Efficiency] No shard + CPU offload in FSDP ,2021-09-09 19:04:39+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
64766,Ability to explicitly close/dispose a DataLoader,2021-09-09 18:39:29+00:00,,0,19,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: data"")]"
64745,Consolidate ProcessGroup allgather_coalesced and allgather,2021-09-09 14:57:08+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: c10d"")]"
64744,Consolidate ProcessGroup allreduce_coalesced and allreduce,2021-09-09 14:46:53+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: c10d"")]"
64743,Named Tensors to support custom unify functions,2021-09-09 13:44:57+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: named tensor"")]"
64730,Enable BatchNorm to use running mean/variance during train,2021-09-09 07:54:18+00:00,,0,7,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: norms and normalization"")]"
64711,Improve Docs builds to not have to push to a repository to update,2021-09-08 22:57:01+00:00,,1,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: doc infra"")]"
64709,Add out= resize warning to cat and maybe_native_stack,2021-09-08 22:50:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: viewing and reshaping"")]"
64700,Torchscript Variable Length Tuples,2021-09-08 21:25:46+00:00,,0,0,"[Label(name=""oncall: jit"")]"
64692,Remove the dependency with CUDA_LIBRARIES in TorchConfig.cmake,2021-09-08 20:14:44+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
64690,_disabled_torch_function_impl is unimplementable (must be special cased),2021-09-08 20:12:08+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
64688,Backend capability chart for nccl GPU send/recv may be stale,2021-09-08 20:00:39+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
64684,[Beta] Have a generic `no_sync` for all synchronized training features ,2021-09-08 19:21:32+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
64683,[Tools] Extend generic join to support FSDP,2021-09-08 19:19:23+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
64669,[Tools] Improve FSDP debuggability,2021-09-08 17:50:25+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
64667,[Tools] Add FSDP logging data,2021-09-08 17:47:44+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
64661,[Efficiency] Support optimizer overlap with backward pass in FSDP,2021-09-08 17:31:45+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
64657,[Beta] FSDP initialization redesign,2021-09-08 17:13:20+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
64645,Compilation from source fails,2021-09-08 12:53:07+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: protobuf""), Label(name=""module: abi""), Label(name=""triaged"")]"
64644,Improve meta tensor testing,2021-09-08 12:23:13+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: structured kernels"")]"
64637,Evaluating on single GPU (DDP),2021-09-08 08:57:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: ddp"")]"
64636,[docs or feature request] torchelastic: OOM recovery / skipping batches (e.g. if inf loss or nan gradients),2021-09-08 08:52:30+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: ddp""), Label(name=""oncall: r2p"")]"
64635,'LSTM' object has no attribute '_flat_weights_names',2021-09-08 08:40:03+00:00,,0,2,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
64628,[jit] cannot compile staticmethod of classes when they have a unscriptable __init__,2021-09-08 06:40:30+00:00,,0,0,"[Label(name=""oncall: jit"")]"
64560,Private bytes consumption exception,2021-09-07 02:08:38+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
64548,Interpreter initialized state changed by torch dispatch,2021-09-06 16:14:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: deploy""), Label(name=""module: __torch_dispatch__"")]"
64544,[Feature Request] Any plan to add 'Sparse Convolution' as default nn module?,2021-09-06 08:49:58+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""module: convolution""), Label(name=""triaged"")]"
64541,[docs] Version switcher to not reset home page unconditionally,2021-09-06 07:36:56+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
64539,[LTC][Documentation] Python examples in API_GUIDE.md don't work,2021-09-06 06:11:35+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""lazy""), Label(name=""module: lazy"")]"
64535,Memory Leak in MKL OpenMP on AVX2 machine,2021-09-06 03:00:39+00:00,,0,7,"[Label(name=""module: cpu""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: mkl""), Label(name=""module: multithreading""), Label(name=""module: intel"")]"
64532,Replace `clone.detach` with `detach.clone`,2021-09-06 00:31:54+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable"")]"
64527,"Asking for ""git submodule update"" when building a specific version",2021-09-05 09:32:10+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
64525,nn.TransformerEncoder - all nan values issues when src_key_padding_mask provided,2021-09-05 05:32:07+00:00,,0,11,"[Label(name=""module: NaNs and Infs""), Label(name=""oncall: transformer/mha"")]"
64518,TensorPipeDistAutogradTest is frequently failing,2021-09-05 02:32:02+00:00,,0,6,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
64509,Return attention weights in nn.Transformer,2021-09-04 18:00:59+00:00,,0,0,"[Label(name=""feature""), Label(name=""oncall: transformer/mha"")]"
64502,[numpy] torch.nonzero is similar to np.argwhere not np.nonzero,2021-09-04 07:25:54+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
64497,FX tracing on Fairseq-based roberta fails.,2021-09-03 15:57:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
64492,AttributeError: Can't pickle local object 'schedule.<locals>.schedule_fn',2021-09-03 13:29:08+00:00,,1,4,"[Label(name=""oncall: profiler"")]"
64491,TypeError when using torch.cuda.list_gpu_processes() on Windows with the WDDM driver,2021-09-03 12:45:51+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
64490,Load torchscript model with custom operators (GNN) on Windows,2021-09-03 12:38:36+00:00,,0,1,"[Label(name=""oncall: jit"")]"
64488,It' so strange!!!,2021-09-03 12:06:55+00:00,,0,3,"[Label(name=""module: serialization""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
64487,Error in torchScript based on Pytorch tutorial,2021-09-03 11:33:50+00:00,,0,0,"[Label(name=""oncall: jit"")]"
64477,torch.onnx.export crash while export quantized model,2021-09-03 06:39:31+00:00,,1,3,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
64462,torch.package: re-export docs suggestions don't work + other sharp edges,2021-09-02 23:34:02+00:00,,0,2,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
64458,Rename C++ Serialization APIs,2021-09-02 22:56:06+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
64426,Add support for ROCm MIOpen miopenConvolutionForwardBias and miopenConvolutionBackwardBias,2021-09-02 15:01:53+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
64419,Windows Torch.distributed Multi-GPU training with Gloo backend not working,2021-09-02 06:35:02+00:00,,0,4,"[Label(name=""oncall: distributed"")]"
64412,Memory leak in multi-thread inference,2021-09-02 01:43:33+00:00,,0,8,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
64407,Create a boxed/templated ADInplaceOrView kernel,2021-09-01 23:41:12+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
64394,[Prototype][RFC] PyTorch FullyShardedDataParallel(FSDP) API Proposal,2021-09-01 21:05:45+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: fsdp"")]"
64384,[doc] incomplete `get_num_interop_threads` doc,2021-09-01 17:51:11+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
64363,Add support for c++ Profiler APIs,2021-09-01 16:31:28+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""oncall: profiler"")]"
64359,[feature request] `numpy.append` / `numpy.insrt` / `numpy.delete` equivalents and implement dynamic arrays (reallocate storage with a surplus),2021-09-01 14:08:44+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: viewing and reshaping"")]"
64345,Profiler UTF-8 decode issue,2021-09-01 08:18:04+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: profiler"")]"
64334,How to add nan value judgment for variable t0_1 in fused_clamp kernel generated by torch/csrc/jit/tensorexpr/cuda_codegen.cpp.,2021-09-01 02:35:39+00:00,,0,0,"[Label(name=""oncall: jit"")]"
64333,When compiling TAG 1.9.0 or master for android，An error occurred and the compilation failed！ABIS_LIST=arm64-v8a,2021-09-01 02:26:00+00:00,,0,1,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
64327,RFC: multi-part `torch.load`/`torch.save` to support huge models and/or low CPU memory,2021-08-31 23:55:02+00:00,,0,29,"[Label(name=""module: nn""), Label(name=""module: serialization""), Label(name=""triaged"")]"
64311,issues flutter in android studio,2021-08-31 21:38:34+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
64308,Building from source results in no member named 'cerr' in namespace 'std',2021-08-31 21:10:20+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
64306,GradGrad of max_pool2d fails with empty batch dimension,2021-08-31 20:53:54+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
64292,torch.empty_like not taking None as layout?,2021-08-31 18:12:20+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
64284,FR: Record results of OpInfo reference tests and detect when numerics of an operator change,2021-08-31 17:00:32+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged"")]"
64260,Using Cloudpickle for pickling jitted functions,2021-08-31 11:33:42+00:00,,0,0,"[Label(name=""oncall: jit"")]"
64258,Incubation of Graphical Representation in TF2 of HParams,2021-08-31 11:13:26+00:00,,0,0,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
64254,[feature request] New copyseq_ method ,2021-08-31 07:30:19+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
64247,How to optimize jit-script model performance (backend device is gpu),2021-08-31 05:31:44+00:00,,0,0,"[Label(name=""oncall: jit"")]"
64225,"[clang-tidy] Errors aren't reported, runner fails if no ranges are found",2021-08-30 21:50:07+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
64208,"[feature request] ""Batched"" index_select (i.e. simplified torch.gather with not specifying full index)",2021-08-30 18:23:01+00:00,,0,21,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: scatter & gather ops"")]"
64206,Document how to generate Pybind bindings for C++ Autograd,2021-08-30 18:12:12+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
64187,Uniformly test that defaulted Tensor arguments appropriately handle __torch_function__,2021-08-30 15:35:50+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
64186, Complex recurrent layers produce NaN as grad ,2021-08-30 15:28:29+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: NaNs and Infs"")]"
64185,PyTorch public API cleanup,2021-08-30 15:26:25+00:00,,0,6,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""better-engineering"")]"
64162,[feature request] torch.Generator constructor to accept seed directly,2021-08-30 07:37:28+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random"")]"
64156,Get zero when using torch.matmul and torch.dot with 1-D tensor in torch-1.9.0-cp39-none-macosx_11_0_arm64.whl,2021-08-30 04:47:21+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: arm"")]"
64150,Enhance DDP doc to have a complete example including data loading,2021-08-29 22:40:18+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
64145,F.conv2d: confusing error message when using uint8 input instead of float32,2021-08-29 19:37:28+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement"")]"
64143,AttributeError: module 'torchvision.models' has no attribute 'load_model',2021-08-29 18:54:55+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: serialization""), Label(name=""triaged"")]"
64138,Longer int and normal Floats conversion to FloatTensor is strange,2021-08-28 19:20:01+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
64133,nn.MultiheadAttention does not belong to activation function,2021-08-28 03:44:21+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
64130,Every process takes a tiny memory on each nvidia GPU card when using DDP.,2021-08-28 02:28:12+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
64124,ciflow tracking meta issues,2021-08-27 23:37:43+00:00,,0,4,"[Label(name=""triaged"")]"
64119,Cleanup tests in rpc_test.py,2021-08-27 22:04:54+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: tests"")]"
64107,as_tensor and negative strided np arrays,2021-08-27 19:48:12+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: tensor creation"")]"
64106,modulefinder_determinator is incompatible with imports into the test/ directory,2021-08-27 19:16:14+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
64097,CUDA error: CUBLAS_STATUS_INVALID_VALUE,2021-08-27 17:01:08+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
64096,String frontend doesn't support tuple unpacking ,2021-08-27 15:40:10+00:00,,0,0,"[Label(name=""oncall: jit"")]"
64093,test_backward_accumulate_grads (__main__.TensorPipeDistAutogradTest) is flaky,2021-08-27 14:16:48+00:00,,2,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: rpc"")]"
64079,torch.equal does not support sparse tensors,2021-08-27 03:26:49+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
64067,Execute C++ based GTest unit tests from a python wrapper,2021-08-26 23:47:20+00:00,,1,15,"[Label(name=""good first issue""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement"")]"
64060,Consolidating NCCL version parsing functions,2021-08-26 22:25:53+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""module: c10d"")]"
64060,Consolidating NCCL version parsing functions,2021-08-26 22:25:53+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""module: c10d"")]"
64058,Some linalg operations are not taking advantage from batched computation,2021-08-26 21:51:25+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
64048,"Be able to use pytest to run a ""core"" set of tests",2021-08-26 19:40:17+00:00,,1,1,"[Label(name=""low priority""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""enhancement"")]"
64043,Uncleared memory use after torch.load(),2021-08-26 18:58:01+00:00,,0,4,"[Label(name=""module: memory usage""), Label(name=""module: serialization""), Label(name=""triaged"")]"
64041,torch.unique acting up for a binary tensor,2021-08-26 18:37:08+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: boolean tensor""), Label(name=""module: correctness (silent)""), Label(name=""module: sorting and selection"")]"
64038,torch.nn.functional.softmax _stacklevel undocumented,2021-08-26 17:39:49+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
64025,RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR,2021-08-26 16:14:08+00:00,,0,8,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
64023,A modest proposal: delete arithmetic overloads from c10::Half,2021-08-26 16:02:56+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: half"")]"
64006,Missing device and dtype description in torch.nn.MultiheadAttention,2021-08-26 06:25:40+00:00,,0,2,"[Label(name=""oncall: transformer/mha"")]"
64005,[LTC] Find a way to convert at::Generator into torch::jit::NamedValue,2021-08-26 06:09:09+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: lazy"")]"
63998,cat out= variant memory_format inconsistent for cpu and cuda,2021-08-26 02:29:36+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: memory format"")]"
63992,Direct inversion and linear systems solutions for small matrices,2021-08-25 22:54:35+00:00,,1,12,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
63972,bazel build warning: Artifact 'torch/csrc/api/include/torch/version.h' is duplicated,2021-08-25 18:32:37+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: build warnings""), Label(name=""module: bazel"")]"
63971,benchmark.Compare raises: TypeError: object of type 'NoneType' has no len(),2021-08-25 18:25:59+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: benchmark"")]"
63970,[LTC] Investigate a testing utility to make sure correct lowering has happened,2021-08-25 18:23:14+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
63958,torch.gather with sparse_grad=True does not work with SGD optimizer with momentum; gives bad error message,2021-08-25 15:50:10+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""module: optimizer""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""actionable"")]"
63935,Inconsistent behaviour of index put when assigning from other type,2021-08-25 08:09:46+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: advanced indexing"")]"
63929,[Poll] Support higher-order gradient computation in DDP,2021-08-25 05:56:09+00:00,,0,10,"[Label(name=""oncall: distributed""), Label(name=""module: c10d""), Label(name=""module: ddp"")]"
63921,More efficient colon backwards in advanced indexing,2021-08-25 03:10:59+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
63920,quicklint clang-tidy step fails with many unrelated errors,2021-08-25 02:54:24+00:00,,0,0,"[Label(name=""module: lint""), Label(name=""triaged"")]"
63919,quicklint mypy step fails with assertion,2021-08-25 02:52:24+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""module: lint""), Label(name=""triaged"")]"
63917,Add tests for DDP broadcast_buffers=True,2021-08-25 02:11:41+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
63911,Add efficient symmetric tensor representations,2021-08-25 00:48:38+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: __torch_function__"")]"
63897,Scalar construction in C++: PY`torch.tensor(7)` !~= C++`at::tensor(7)`,2021-08-24 22:50:42+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
63870,torch median / nanmedian w/ nans speed,2021-08-24 18:21:59+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: sorting and selection""), Label(name=""module: reductions"")]"
63855,Include tensor shape in its default print formatting,2021-08-24 11:12:44+00:00,,0,15,"[Label(name=""module: printing""), Label(name=""triaged""), Label(name=""enhancement"")]"
63849,"Installed successfully the torch-1.9 and torch_xla-1.9. RuntimeError requested XLA_GPU:0，but available devices are [CPU:0, XLA_CPU:0 ]",2021-08-24 09:08:29+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: xla"")]"
63847,RuntimError:CUDA error: an illegal memory access was encountered when copying data to CUDA,2021-08-24 08:46:15+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
63846,[torch.distributed] Make dynamic_rendezvous log handler configurable,2021-08-24 07:30:53+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: elastic""), Label(name=""oncall: r2p"")]"
63837,`torch.scatter` doesn't fail correctly on CUDA (memory overlap),2021-08-24 05:37:44+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: scatter & gather ops""), Label(name=""module: structured kernels"")]"
63832,[RFC] Add `torch.distributed.run` as a console script in pytorch's setup.py,2021-08-24 04:48:28+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: elastic"")]"
63815,[FX] Documentation for Graph.flatten_inps and Graph.unflatten_outs,2021-08-23 22:56:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
63812,Calling backward with create_graph on the output of a DistributedDataParallel throws error,2021-08-23 21:43:11+00:00,,1,14,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
63802,[torch.distributed.launch|run] Hangs on SIGINT when using a TCPStore backed rdzv_backend ,2021-08-23 20:46:07+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
63781,[rfc] Hardcoded Target Determination,2021-08-23 17:19:14+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged"")]"
63767,`__torch_function__` docs should use @classmethod,2021-08-23 15:16:00+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
63749,Segmentation fault when using C++/pybind11 module without also importing torch,2021-08-23 09:09:39+00:00,,1,1,"[Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""module: pybind""), Label(name=""module: regression"")]"
63740,DDP Gradient reduction is not triggered after calling autograd.backward(),2021-08-23 00:08:03+00:00,,0,6,"[Label(name=""oncall: distributed"")]"
63726,a problem happened in torch.randperm,2021-08-21 13:34:05+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: random"")]"
63725,[Feature Request] add graph to hparams for tensorboard,2021-08-21 11:57:54+00:00,,0,1,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
63720,Torch.save with zip serialization causes memory bloat,2021-08-21 00:47:17+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
63648,[JIT] Typing on math.ceil is inaccurate for Scalar input,2021-08-20 17:02:15+00:00,,1,3,"[Label(name=""oncall: jit"")]"
63645,Create a new OptionalArrayRef template class to replace Optional<ArrayRef>,2021-08-20 13:14:46+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
63644,LeakyReLU and Elu use more VRAM than needed,2021-08-20 12:36:02+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
63624,Raw saved tensors can survive the deletion of the underlying SavedVariable object,2021-08-20 02:40:50+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
63623,Expose a SavedTensorsHooks nn.Module for users to register saved tensors hooks,2021-08-20 01:57:03+00:00,,1,4,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
63618,C++ torch::cuda::synchronize speeds up training,2021-08-19 23:03:22+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
63610,Enable some amount of CI tests on lazy_tensor_staging branch,2021-08-19 21:45:09+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""module: lazy"")]"
63581,Java NVIDIA GPU Inference Support,2021-08-19 16:18:27+00:00,,1,8,"[Label(name=""triaged""), Label(name=""oncall: mobile"")]"
63574,compile_commands.json doesn't contain nvcc invocations,2021-08-19 15:27:25+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
63559,"Functional grid_sample: example of padding_mode=""reflection"" description error",2021-08-19 09:04:01+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
63558,universal binaries for libtorch on mac (x86_64+arm),2021-08-19 08:24:08+00:00,,0,30,"[Label(name=""module: binaries""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
63555,pytorch 1.8.1+cu111 used much more CPU RAM than pytorch 1.8.1 after run `import torch`,2021-08-19 07:38:32+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""module: cpu""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
63490,[FX] Data type of target should be validated on Node construction and lint,2021-08-18 17:44:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
63488,MultiStepLR with different gammas for each parameter group,2021-08-18 16:32:44+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
63486,Distributed / MPI / CUDA: Incorrect messages received from isend/irecv in PyTorch 1.9,2021-08-18 15:53:20+00:00,,0,5,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
63485,Preserve tensor subclasses when unpacking a SavedTensor,2021-08-18 15:27:54+00:00,,1,3,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
63479,Cannot include extension.h under Windows - linker error  THPVariable_Wrap,2021-08-18 12:41:38+00:00,,0,8,"[Label(name=""module: cpp-extensions""), Label(name=""module: cpp""), Label(name=""triaged"")]"
63477,Supporting Pytorch for Custom Compiler Backend,2021-08-18 12:32:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: backend"")]"
63476,Error loading Pytorch lite model in Android,2021-08-18 12:29:24+00:00,,2,1,"[Label(name=""oncall: mobile"")]"
63475,C++ Inference error causes Identity Module,2021-08-18 12:08:55+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
63466,Add a GitHub actions workflow for Macos,2021-08-18 07:33:32+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: infra"")]"
63455,distributed_error,2021-08-18 02:45:35+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
63445,"getNcclVersion() in NCCLUtils.cpp handles ""2.10.3"" incorrectly",2021-08-18 00:23:50+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""module: nccl""), Label(name=""module: ddp"")]"
63441,OpenCV causes backpropagation to get stuck,2021-08-17 23:19:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""module: multithreading"")]"
63405,torch.arange has issue tracing with bool input,2021-08-17 17:07:17+00:00,,0,1,"[Label(name=""oncall: jit"")]"
63403,Consolidate distributed benchmark folders,2021-08-17 16:28:07+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
63395,How to efficiently (without looping) get data from tensor predicted by a torchscript in C++?,2021-08-17 12:42:58+00:00,,0,1,"[Label(name=""oncall: jit"")]"
63356,[python codegen] correctly plumb TensorOptions defaults through the python binding layer.,2021-08-16 20:51:46+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
63337,Property based testing like AFL,2021-08-16 17:00:41+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
63322,lstm's input h0 and c0 bug,2021-08-16 14:44:42+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: NaNs and Infs"")]"
63313,Automatic mixed precision works worse for 3D neural networks.,2021-08-16 11:54:23+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
63305,Alternate Model Loading - Android,2021-08-16 08:11:33+00:00,,2,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
63299,Channels last mode doesn't work with inputs with 0 batch dimension,2021-08-16 01:36:51+00:00,,1,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: memory format"")]"
63297,Named tensor in tracer,2021-08-15 23:15:22+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
63295,pytorch 1.8.2  cuda test errors,2021-08-15 18:17:07+00:00,,0,6,"[Label(name=""module: build""), Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
63293,Support `torch.linalg.outer`,2021-08-15 13:44:09+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: python array api"")]"
63291,[typing] new_ones has wrong signature,2021-08-15 06:41:08+00:00,,1,3,"[Label(name=""module: bootcamp""), Label(name=""module: typing""), Label(name=""triaged"")]"
63290,DistributedDataParallel documentation,2021-08-15 05:16:41+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: ddp"")]"
63282,Serialising `torch.bool` generates a warning about `np.bool` being deprecated. ,2021-08-14 16:56:37+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: numpy"")]"
63265,torch.scatter_: support index.size(d) > src.size(d),2021-08-14 00:36:11+00:00,,0,26,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: scatter & gather ops"")]"
63257,`help(torch.finfo)` doesn't give useful information even though class has documentation,2021-08-13 21:29:38+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
63247,Add a timeout argument to RPC shutdown(),2021-08-13 18:49:59+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp"")]"
63226,"cuda.is_available returns True in pycharms python console, False in code",2021-08-13 12:24:41+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
63223,[bug] torch.distributed.elastic logging: Failed to print the first info statement,2021-08-13 10:16:55+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: elastic""), Label(name=""oncall: r2p"")]"
63217,Torch.nn.functional.interpolate() function memory release problem,2021-08-13 06:11:19+00:00,,0,1,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
63211,Memory leak in `ddp_zero_hook.py` hooks,2021-08-13 03:28:31+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: ddp"")]"
63207,"document our compatibility with upstream packages (e.g. languages, compilers, tools)",2021-08-13 01:58:27+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
63205,split up test/test_autograd.py,2021-08-13 01:27:03+00:00,,1,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""better-engineering"")]"
63188,ROCm build documentation lacks needed dependencies,2021-08-12 21:46:53+00:00,,0,10,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""actionable"")]"
63171,[BE] Clean up DDP Single-Program Multi-Device Vestige in reducer.cpp,2021-08-12 19:14:44+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp"")]"
63159,PyTorch Profiler,2021-08-12 17:58:31+00:00,,0,8,"[Label(name=""oncall: profiler""), Label(name=""mlops"")]"
63145,torch.jit.trace does not work if there is an autograd in the function,2021-08-12 11:50:10+00:00,,0,0,"[Label(name=""oncall: jit"")]"
63140,[documentation] torch.distributed.elastic: illustrate how to write load_checkpoint and save_checkpoint in Train Script ,2021-08-12 08:54:25+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: elastic""), Label(name=""oncall: r2p"")]"
63138,Sign in slogdet is set to requires_grad = False even when using complex numbers. ,2021-08-12 08:40:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: linear algebra""), Label(name=""complex_autograd"")]"
63124,torch.jit.trace quantized bigbird leads to 0INTERNAL ASSERT FAILED runtime error,2021-08-12 00:44:32+00:00,,0,3,"[Label(name=""oncall: jit"")]"
63113,Implement half_to_float flag for both _log_softmax and _softmax operators,2021-08-11 22:36:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
63085,Split up test_nn.py,2021-08-11 16:02:29+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""better-engineering"")]"
63082,script/build_android nn::Module support,2021-08-11 14:40:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
63079,"PyTorch 1.9.0, test_optim fails on Nvidia A10.",2021-08-11 13:15:51+00:00,,0,11,"[Label(name=""module: optimizer""), Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged"")]"
63078,torch.cuda.amp fails with torch.sparse.softmax,2021-08-11 12:44:50+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
63076,Tracing models all the way down to basic functions,2021-08-11 08:50:33+00:00,,0,15,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: fx"")]"
63069,CUDA error: invalid configuration argument for torch.sparse tensor backward,2021-08-11 04:17:29+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
63057,Find out why TestSparseCPU.test_softmax_cpu_float64 grad and input dtypes are different,2021-08-11 01:41:51+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: structured kernels"")]"
63041,[RFC] Should DDP support custom reduction logic for registered module buffers?,2021-08-10 19:37:24+00:00,,1,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
63038,Use pytorch-probot for PyTorch-specific stuff + MOTD in Dr. CI comment,2021-08-10 18:59:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: infra""), Label(name=""needs design"")]"
63034,[bug] nn.functional.pad (circular) ubsan failure,2021-08-10 18:36:57+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: padding"")]"
63023,[feature request] Type promotions for Boolean tensors with sub operation + Numpy compatability,2021-08-10 11:10:48+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: type promotion""), Label(name=""module: boolean tensor"")]"
63020,Update _symbolic_trace.py for proxy_placeholder function,2021-08-10 07:32:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
63016,grid_sample should not require grid to be the same dimension as input.,2021-08-10 05:18:11+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: interpolation"")]"
63004,ignore_index does not work as described with nn.CrossEntropyLoss,2021-08-09 22:54:26+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged"")]"
62998,Add nn.Module full pre-backward hooks,2021-08-09 21:32:21+00:00,,1,5,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
62989,Doc page for functions with overload is not properly indented,2021-08-09 19:53:42+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
62983,Implement `set_flush_denormal ` for ARM,2021-08-09 18:02:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: arm"")]"
62982,Don't use try-catch to handle overload resolution handling in torch.ops,2021-08-09 17:51:36+00:00,,1,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
62973,Audit use of `C10_UNUSED`,2021-08-09 16:06:31+00:00,,0,2,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
62962,[JIT] NVRTC unknown error ,2021-08-09 12:21:48+00:00,,0,7,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
62955,Make axes selection keyword arguments in torch.diagonal and torch.transpose consistent,2021-08-08 18:34:17+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: linear algebra""), Label(name=""module: python array api"")]"
62934,`tools/autograd/derivatives.yaml` doesn't support methods on optional tensor,2021-08-07 02:57:26+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: codegen"")]"
62933,Compilation error with gcc11 and libstdc++11 (thread_id != operator removed),2021-08-07 00:39:23+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: mkldnn"")]"
62931,GPU compatibility check without initializing CUDA,2021-08-06 22:56:36+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
62926,cudnn_convolution_add_relu fails under basic conditions,2021-08-06 21:37:36+00:00,,0,3,"[Label(name=""module: dependency bug""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
62925,[Testing] memory_format decorator,2021-08-06 20:47:15+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: memory format"")]"
62917,Use `linecache.lazycache` in torch.fx,2021-08-06 19:43:42+00:00,,0,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: fx"")]"
62902,distributed/elastic/multiprocessing/api_test is flaky on ROCm,2021-08-06 17:44:37+00:00,,0,2,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""needs research""), Label(name=""oncall: r2p"")]"
62888,Add a mechanism to not universally dispatch to python for all for all operations when using __torch_dispatch__ ,2021-08-06 14:29:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
62885,Type of first constructor parameter of ElasticDistributedSampler and DistributedSampler,2021-08-06 14:17:03+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader"")]"
62884,Conjugate fallback dispatch key should be per-backend,2021-08-06 13:56:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: dispatch"")]"
62876,Key already registered with the same priority: uv,2021-08-06 05:46:57+00:00,,0,5,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: tensorpipe"")]"
62865,Multiplication of non-int torch.tensor with string gives unexpected TypeError,2021-08-06 00:21:06+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
62862,Convert unset variables in `Reducer::Timer` to use c10::optional,2021-08-05 23:25:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
62854,"aten::pixel_shuffle(Tensor self, int upscale_factor) -> (Tensor): Argument self not provided.",2021-08-05 22:31:31+00:00,,0,1,"[Label(name=""oncall: jit"")]"
62849,"slice_embed, select_embed like diag_embed",2021-08-05 21:51:27+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
62845,allow specification of variadic arguments in native_functions.yaml,2021-08-05 21:06:24+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged"")]"
62821,Enable fft  support for mobile builds,2021-08-05 15:52:30+00:00,,0,5,"[Label(name=""enhancement""), Label(name=""module: android""), Label(name=""oncall: mobile""), Label(name=""module: arm""), Label(name=""module: fft"")]"
62812,Support `torch.linalg.einsum`,2021-08-05 10:10:59+00:00,,0,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
62790,Remove c10d::kDefaultFirstBucketBytes,2021-08-05 01:11:09+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
62788,PyTorch(with mkldnn) in inference mode using non-optimal prop_kind for convolution,2021-08-05 00:42:12+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mkldnn"")]"
62784,Runtime error when passing dim as None in torch.squeeze (and Tensor.squeeze),2021-08-05 00:14:28+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
62780,Seeing unit test failures for ProcessGroupShareTensorTest,2021-08-05 00:01:23+00:00,,0,3,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: nccl""), Label(name=""module: c10d"")]"
62775,[TorchScript] Support for registering builtin operators with control flow,2021-08-04 22:53:17+00:00,,0,2,"[Label(name=""oncall: jit"")]"
62742,Add a way to edit CI env variables from PRs,2021-08-04 18:44:02+00:00,,0,1,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""better-engineering"")]"
62699,Can not parse the caffe2 pretrain model. google.protobuf.message.DecodeError: Error parsing message,2021-08-04 02:45:34+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
62695,Use fast gpuAtomicAdd for FP16 data type in CUDA kernels,2021-08-04 00:06:54+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: half"")]"
62683,[FX] Support pytree `concrete_args` for *args,2021-08-03 21:57:59+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
62676,pytorch_mobile custom build Module.forward null reference. ,2021-08-03 20:35:09+00:00,,1,5,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
62675,dynamic shapes,2021-08-03 20:34:45+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: lazy"")]"
62673,Make printing to stdout / stderr in tests in CI an error,2021-08-03 20:20:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
62672,Add Convolution support for lazy tensor,2021-08-03 20:13:15+00:00,,1,0,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: lazy"")]"
62661,Rewrite PyTorch CUDA backend in Triton,2021-08-03 17:37:13+00:00,,0,22,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
62656,"Building pytorch from source results in ""an object with that name is already defined"" error on import",2021-08-03 17:19:19+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: pybind"")]"
62655,Make KernelFunction::makeFromUnboxedFunctor infer KernelFunctor from input argument,2021-08-03 17:16:27+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
62654,Checkpointing without re-entrant autograd,2021-08-03 17:15:10+00:00,,2,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
62650,Error while importing torch: libtorch_python.so: undefined symbol: PyThread_tss_alloc,2021-08-03 15:28:13+00:00,,0,0,"[Label(name=""module: abi""), Label(name=""triaged"")]"
62648,Feature request: Generate Sobol points directly on the GPU,2021-08-03 14:26:54+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
62644,waste too much time in first two pictures,2021-08-03 09:23:38+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
62640,add gamma to CosineAnnealingWarmRestarts so max lr can decrease in cycles,2021-08-03 07:51:49+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
62630,Instructions for CMAKE_PREFIX_PATH seem to be broken,2021-08-03 01:22:23+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged"")]"
62619,LazyTensor support for fuser integration investigation,2021-08-02 22:56:53+00:00,,0,4,"[Label(name=""triaged""), Label(name=""LazyTensor_nvfuser_integration""), Label(name=""module: lazy"")]"
62616,LazyTensor cuda fallback,2021-08-02 22:38:26+00:00,,0,14,"[Label(name=""triaged""), Label(name=""LazyTensor_nvfuser_integration""), Label(name=""module: lazy"")]"
62614,LazyTensor recomputes intermediate tensor in fragmented computation,2021-08-02 22:30:08+00:00,,1,5,"[Label(name=""triaged""), Label(name=""LazyTensor_nvfuser_integration""), Label(name=""module: lazy"")]"
62606,Guidance on where to add documentation,2021-08-02 20:40:17+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
62603,Unexpected `is_training` after using `train` in a JIT Module,2021-08-02 20:29:05+00:00,,0,0,"[Label(name=""oncall: jit"")]"
62602,"""test_events_wait"" is flaky on ROCm",2021-08-02 20:27:36+00:00,,0,3,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
62591,Unnecessary python bindings and documentation for internal functions/ops,2021-08-02 18:11:32+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
62588,static library kineto_LIBRARY-NOTFOUND not found.,2021-08-02 17:55:32+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: build warnings"")]"
62566,`c10::optional<T>` operators should delegate to corresponding operators on `T`,2021-08-02 14:10:56+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
62556,[TorchScript] Inconsistency between Python and PyTorch when raising 0 to a negative power,2021-08-02 05:40:05+00:00,,1,0,"[Label(name=""oncall: jit"")]"
62554,`torch.fx.node.normalized_arguments` does not pass `normalize_to_only_use_kwargs`,2021-08-02 04:22:52+00:00,,1,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: fx"")]"
62547,[FX] to_folder breaks when a directly-traced `nn.Sequential` is dumped,2021-08-01 13:16:09+00:00,,1,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: fx"")]"
62545,Incosistency with args for `nn.functional.max_poolNd` vs `nn.MaxPoolNd` functions,2021-08-01 07:31:00+00:00,,1,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling"")]"
62543,FAIL: test_threshold (test_jit_fuser.TestFuser),2021-08-01 06:15:28+00:00,,0,4,"[Label(name=""oncall: jit"")]"
62542,3 Times memory cost when loading the model to torch.nn.parallel.DistributedDataParallel,2021-08-01 05:20:26+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
62540,[Meta] Change default branch name to `main` for repos in `pytorch` project,2021-07-31 19:45:24+00:00,,0,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: infra"")]"
62530,[feature request] `torch.switch` (to mirror `lax.switch`) and `torch.cond` - with jax arithmetic coder as a case study,2021-07-31 08:26:01+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
62508,torch.prod internal asserts when passed a tensor that requires_grad (and a dtype),2021-07-30 21:41:32+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
62500,meta tensor `set_` seems fishy,2021-07-30 19:09:48+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: meta tensors"")]"
62475,Learning rate scheduler list index out of range,2021-07-30 13:25:23+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: LrScheduler"")]"
62474,Distributed: RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [2048]] is at version 4; expected version 3 instead ,2021-07-30 11:52:47+00:00,,0,6,"[Label(name=""oncall: distributed"")]"
62473,Sparse updates to logits in distributions.Categorical,2021-07-30 09:27:08+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""module: distributions""), Label(name=""module: autograd""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
62451,torch.Generator ignores the device argument?,2021-07-30 04:56:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random"")]"
62449,Review replacing test/test_namedtuple_return_api.py with an OpInfo-based test,2021-07-30 03:53:40+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged"")]"
62448,Dynamic tensor rematerialization,2021-07-30 03:48:12+00:00,,0,9,"[Label(name=""module: internals""), Label(name=""module: checkpoint""), Label(name=""feature""), Label(name=""triaged"")]"
62446,[docs] Can't get header links to h3 on docs pages,2021-07-30 00:35:10+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: doc infra"")]"
62403,DDP,2021-07-29 14:50:53+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
62399,Understatement about how running_var is computed in BatchNorm,2021-07-29 14:29:20+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
62396,"Make interpolation output size compatible with opencv, scikit-image and scipy for floating scale factor",2021-07-29 12:44:02+00:00,,1,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: interpolation"")]"
62395,[FX] Does PyTorch want to support for dynamic control flow for torch.fx?,2021-07-29 11:59:04+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
62394,crash in libtorch jit,2021-07-29 11:45:21+00:00,,0,6,"[Label(name=""oncall: jit"")]"
62390,Profiler reports profiling overhead & inaccurate numbers for last record_function,2021-07-29 09:15:03+00:00,,0,4,"[Label(name=""oncall: profiler"")]"
62387,Bad performance of stock model on Windows compared to Linux,2021-07-29 08:43:41+00:00,,0,23,"[Label(name=""module: performance""), Label(name=""module: windows""), Label(name=""module: cpu""), Label(name=""triaged"")]"
62381,torch.distributed and subprocess do not work together?,2021-07-29 06:12:04+00:00,,0,5,"[Label(name=""oncall: distributed"")]"
62371,libtorch on Apple m1,2021-07-29 00:13:38+00:00,,0,5,"[Label(name=""module: cpp""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""enhancement""), Label(name=""module: arm"")]"
62358,torch.cholesky_inverse supports tensors with more than 2 dimensions,2021-07-28 21:05:03+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
62354,Some way to specify expected failures for OpInfo-based tests,2021-07-28 20:24:34+00:00,,0,9,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""enhancement"")]"
62352,[feature request] Expand a given dim,2021-07-28 20:18:24+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: viewing and reshaping"")]"
62350,NotImplementedError: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend.,2021-07-28 19:23:38+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: vision"")]"
62343,maybe_wrap_dim should have an example attached to it,2021-07-28 18:33:35+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
62332,"How to Fix “AssertionError: CUDA unavailable, invalid device 0 requested”",2021-07-28 15:05:52+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
62331,broken pipe error ,2021-07-28 14:42:01+00:00,,0,0,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged"")]"
62330,Bus error (core dumped) when import torch,2021-07-28 14:04:16+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: build""), Label(name=""triaged"")]"
62325,[jit]][script] handling of 'void' returns,2021-07-28 12:56:20+00:00,,1,7,"[Label(name=""oncall: jit"")]"
62320,[JIT] Support JAX-style statically shaped nonzero to avoid host-device synchronization,2021-07-28 11:02:50+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""needs design"")]"
62314,dist.destroy_process_group() don't release master_port when there're at least 2 process groups,2021-07-28 08:23:11+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
62313,"On Triton inference server, the TorchScript .pt file, exported by 1.9.0, serves unsuccessfully",2021-07-28 07:27:23+00:00,,1,4,"[Label(name=""oncall: jit"")]"
62308,Error while running FINETUNING TORCHVISION MODELS,2021-07-28 05:42:46+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: vision"")]"
62300,ProcessGroupGloo CUDA Comm Synchronization Looks Wrong,2021-07-28 01:39:33+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
62283,c10d and discontiguous tensors with mismatch strides,2021-07-27 18:51:36+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
62273,Serialization map_location silently ignores xla/mlc/meta (any serialization mechanism that skips storage),2021-07-27 17:09:48+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
62271,Refactor serialization tests to use device parametrization,2021-07-27 17:09:11+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""module: serialization""), Label(name=""triaged"")]"
62265,`periodic-pytorch-linux-xenial-cuda11.3-cudnn8-py3.6-gcc7-build` started to fail ,2021-07-27 15:02:14+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
62258,Adding a new operator shouldn't need to trigger a rebuild of CUDA kernels,2021-07-27 13:03:54+00:00,,1,2,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
62255,Support `torch.linalg.trace`,2021-07-27 10:17:55+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: python array api"")]"
62221,Torchscript Optimize for Mobile RuntimeError: Can't deepcopy IValue with tag: Enum,2021-07-26 21:21:36+00:00,,0,5,"[Label(name=""oncall: jit"")]"
62182,Dispatch to Python with wrappers triggers Autograd view asserts,2021-07-26 13:42:32+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: __torch_dispatch__"")]"
62178,Wrong implementation of method log_prob in torch.distributions.negative_binomial,2021-07-26 09:28:24+00:00,,0,15,"[Label(name=""module: distributions""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy"")]"
62171,[feature request] torch.nn.Conv3d on tensors having more than 5 dimensions,2021-07-26 02:17:07+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
62168,Error installing from source,2021-07-26 00:39:34+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged"")]"
62165,"RuntimeError: xnn_status_success == run_status INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/native/xnnpack/Linear.cpp"":158",2021-07-25 16:44:02+00:00,,1,3,"[Label(name=""module: android""), Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
62162,Clarify sparse COO tensor coalesce behavior wrt overflow + how to binarize a sparse tensor,2021-07-25 12:37:49+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""module: docs""), Label(name=""triaged"")]"
62155,[docs] Change code snippet formatting to be directly copy-pasteable into REPL or into source files,2021-07-24 15:30:23+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs design"")]"
62154,AttributeError: module 'torch.jit' has no attribute '_script_if_tracing',2021-07-24 14:18:50+00:00,,0,4,"[Label(name=""oncall: jit"")]"
62153,cuSPARSELt Integration,2021-07-24 14:09:03+00:00,,1,10,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
62152,Runtime Error: Expected a 'cuda' device type for generator but found 'cpu' in google colab,2021-07-24 13:22:45+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
62148,[feature request] Function to broadcast right,2021-07-24 12:02:40+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs design""), Label(name=""module: viewing and reshaping"")]"
62147,Tensor subclassing does not support bool input,2021-07-24 09:48:36+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: boolean tensor""), Label(name=""module: tensor creation"")]"
62141,Dedupe code in functional optim classes,2021-07-23 23:42:59+00:00,,1,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
62130,"nn.DataParallel not working on A100 with nvidia-driver 470.42.01, Cuda 11.1, Debian 10",2021-07-23 21:40:01+00:00,,0,0,"[Label(name=""module: multi-gpu""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
62094,"[FR] Support for non-Parameter, non-Buffer objects in state_dict",2021-07-23 16:57:42+00:00,,0,20,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
62066,Memory Leak Found in Persistent DataLoader,2021-07-22 23:43:27+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
62034,cudnn_batch_norm_backward is extremely imprecise for some input shapes,2021-07-22 16:45:33+00:00,,0,2,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
62032,"Create a boxed fallback / template recipe for Autograd that forwards, but errors on backwards",2021-07-22 15:53:10+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
62031,Caffe2 tensor to ATen conversion doesn't initialize PyTorch CUDA state,2021-07-22 15:13:43+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""module: internals""), Label(name=""module: cuda""), Label(name=""triaged"")]"
62027,`x.to(memory_format=torch.contiguous_format)` does not always return a contiguous tensor,2021-07-22 13:12:23+00:00,,0,22,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""needs design"")]"
62026,Should we be upcasting integral types to int64 in torch.sum and torch.prod?,2021-07-22 12:44:28+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: reductions""), Label(name=""module: python array api"")]"
62021,[FX] Ability to provide autowrap function to Tracer init,2021-07-22 09:17:02+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
62016,ppc64le build fail: invalid conversion from Bfloat16 in functional_base.h:180,2021-07-22 06:56:02+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: POWER""), Label(name=""module: bfloat16"")]"
62011,Enable clang-tidy on all of master,2021-07-22 02:56:41+00:00,,2,0,"[Label(name=""triaged"")]"
62009,multi-input and multi-output support for nn.Module,2021-07-22 02:45:29+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
62007,Add Future return from default process group collective communications,2021-07-22 01:38:48+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
61970,FX incorrectly provides `int` instead of `float` for `value` kwarg of `nn.functional.pad`,2021-07-21 17:13:28+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: fx"")]"
61966,Bootcamp Task: Add `prim::to_mkldnn` to convert from aten's nchw to mkldnn's nChw8c directly,2021-07-21 16:39:41+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""jit-backlog"")]"
61951,Vulkan: error -5 when trying to use it with Nvidia card,2021-07-21 11:28:30+00:00,,1,1,"[Label(name=""module: android""), Label(name=""oncall: mobile""), Label(name=""module: vulkan"")]"
61930,NNAPI delegate library cannot be built on MacOS,2021-07-20 20:06:50+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
61923,Calling `torch.save()` twice writes a corrupted file,2021-07-20 18:02:02+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
61920,RPC memory leak for CPU,2021-07-20 17:20:46+00:00,,2,33,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed"")]"
61919,RuntimeError: !ref.requires_grad()INTERNAL ASSERT FAILED,2021-07-20 17:19:44+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
61909,Support matrix operations between complex and real tensors,2021-07-20 15:42:56+00:00,,0,18,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: type promotion""), Label(name=""module: linear algebra"")]"
61901,Reducing over empty dimensions for reductions without identity,2021-07-20 12:49:51+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""needs design""), Label(name=""module: reductions"")]"
61890,The matrix multiplication operator can't get correct results on 3090 !!,2021-07-20 05:00:28+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: tf32"")]"
61843,Investigate fairscale's use of storage APIs and find alternatives,2021-07-19 14:13:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""ezyang's list"")]"
61839,died with <Signals.SIGSEGV: 11>,2021-07-19 12:37:11+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
61835,Broadcasting documentation diverges from implementation,2021-07-19 10:35:37+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
61827, Bail out if `-std=c++` setting is detected during build,2021-07-19 06:20:35+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
61825,Improved OpInfo dtype testing,2021-07-19 05:46:50+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
61819,"[discussion] Support other index dtypes for scatter, scatter_reduce and other indexing functions in addition to int64: uint8, int16, int32 (without nya casting reallocations)",2021-07-18 19:41:32+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: type promotion""), Label(name=""module: advanced indexing""), Label(name=""actionable""), Label(name=""module: scatter & gather ops"")]"
61816,Better argument names for torch.atan2 and other math functions,2021-07-18 10:57:05+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
61781,Letting `_allgather_base` to support multiple tensors as inputs and outputs,2021-07-16 19:22:34+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
61772,Can I set the algorithm of torch.nn.Conv to CUDNN_CONVOLUTION FWD_ALGO_GEMM by myself?,2021-07-16 16:58:02+00:00,,0,1,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
61765,How to save tensors on mobile (lite interpreter)?,2021-07-16 09:43:03+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
61758,`make_tensor` tracking issue,2021-07-16 04:39:07+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: testing""), Label(name=""tracker"")]"
61730,"Can't specify compiler, leading to SUPPORT_GLIBCXX_USE_C99 failed",2021-07-15 20:29:59+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged"")]"
61727,```torch.distributions.Categorical``` unintended  ```log_prob``` gradient w.r.t ```probs```,2021-07-15 20:17:57+00:00,,0,3,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
61718,ATen codegen is always re-running for Makefile generator,2021-07-15 17:46:16+00:00,,2,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
61709,[pytorch android] use Vulkan backend crash,2021-07-15 09:46:58+00:00,,0,3,"[Label(name=""module: android""), Label(name=""oncall: mobile""), Label(name=""module: vulkan"")]"
61695,miss header file while using python setup.py install to install pytorch with anaconda env,2021-07-15 04:23:22+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
61693,"Pytorch Mobile on Android, LAPACK library not found in compilation",2021-07-15 04:18:41+00:00,,0,4,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
61686,[discussion] Remove the need of mandatory super() nn.Module's call,2021-07-15 00:47:37+00:00,,0,13,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
61671,TCPStoreTest.testWatchKeyCallback Timed Out,2021-07-14 19:11:46+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: c10d"")]"
61665,Default Collate doesn't work for subtypes of ndarray,2021-07-14 18:24:39+00:00,,1,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
61664,Support adding new keyword-only parameters without breaking FC,2021-07-14 17:09:39+00:00,,0,3,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: codegen""), Label(name=""needs design"")]"
61662,`super().__init__()` usage for `_Joinable`,2021-07-14 16:39:11+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
61661,Return `Future` instead of `Work` in `notify_join_context()`,2021-07-14 16:31:09+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
61660,Pytorch model load failure in Gunicorn with Gevent workers,2021-07-14 16:24:36+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: numpy"")]"
61659,Python program locks up when using some innocuous code inside mp.spawn(),2021-07-14 16:09:27+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
61658,Move `torch.cholesky_solve` into `torch.linalg`.,2021-07-14 15:55:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra"")]"
61654,Allow creation of pseudo devices for testing purposes,2021-07-14 15:17:37+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""triaged"")]"
61653,Move `lobpcg` into `torch.linalg`,2021-07-14 15:16:25+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra"")]"
61650,"Move `{svd,pca}_lowrank` into `torch.linalg`",2021-07-14 14:43:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra"")]"
61649,Move `tensordot` into `torch.linalg`,2021-07-14 14:34:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra""), Label(name=""module: python array api"")]"
61645,`channel_shuffle` output is sometimes aliased with its input,2021-07-14 13:41:16+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
61636,Enhance Distributed `get_future()` docs,2021-07-14 07:15:24+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup"")]"
61619,"When 'trapezoid' is called with an empty tensor input, it does not produce an output with requires_grad",2021-07-14 00:25:46+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
61614,Possibly flaky test: TestMultiprocessing.test_fd_sharing,2021-07-14 00:01:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
61591,Add `map_location` arg for c10d collective comms,2021-07-13 18:20:24+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
61585,"Proposal: allow using axis, axes, dim and dims interchangeably ",2021-07-13 17:23:07+00:00,,0,3,"[Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: ux""), Label(name=""module: python array api"")]"
61582,Many reduction operators do not support reducing over multiple dimensions,2021-07-13 15:44:56+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: reductions""), Label(name=""module: python array api"")]"
61574,[nn] Passing dtype to `_stacklevel` argument in `log_softmax` silently works,2021-07-13 07:00:18+00:00,,0,2,"[Label(name=""module: bc-breaking""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: functional UX""), Label(name=""topic: bc breaking"")]"
61544,`__torch_function__` always records default kwargs as kwargs,2021-07-12 17:56:04+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
61538,The use of epsilon in torch.nn.functional.pairwise_distance leads to incorrect minima of the distances,2021-07-12 16:25:32+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: distance functions"")]"
61528,Function Request: scipy.ndimage.map_coordinates ,2021-07-12 12:16:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: interpolation"")]"
61525,"I have graphic card of P4, but torch.cuda.is_available() always shows false",2021-07-12 08:22:53+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
61523,F.nll_loss with 16-bit CUDA tensors and reduction=mean produces NaNs,2021-07-12 07:32:06+00:00,,0,3,"[Label(name=""module: numerical-stability""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: reductions"")]"
61516,MemoryError with pip Install even with --no-cache-dir option,2021-07-11 13:10:28+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
61515,Buggy page with overlapped tabs,2021-07-11 11:11:44+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
61513,Adding 'differentiable' section to each function docstring,2021-07-11 09:21:12+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged"")]"
61510,What is find_package(Torch REQUIRED) doing that a manual include/glob doesnt?,2021-07-10 18:35:09+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
61509,[feature request] Exact euclidean distance transform,2021-07-10 11:47:19+00:00,,0,0,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: distance functions"")]"
61503,UCI Data Sets,2021-07-10 03:00:23+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
61492,Replace unbiased parameter in torch.(std|var|std_mean|var_mean) with correction=0,2021-07-09 22:47:32+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: reductions""), Label(name=""module: python array api"")]"
61490,Deprecate torch.(min|max|median|mode) to only return values and not indices,2021-07-09 22:41:18+00:00,,0,16,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation""), Label(name=""needs design""), Label(name=""module: reductions""), Label(name=""module: python array api"")]"
61486,Some reduction operators have double signatures,2021-07-09 22:17:33+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: reductions""), Label(name=""module: python array api"")]"
61485,CompositeImplicitAutograd ops should not call out= variants of operators,2021-07-09 21:51:08+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
61474,Implement missing torch.nan* operators,2021-07-09 19:40:33+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: NaNs and Infs""), Label(name=""module: reductions""), Label(name=""tracker"")]"
61470,torch.nn.utils.weight_norm fails with DDP,2021-07-09 18:57:01+00:00,,0,5,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
61468,Version is set to 1.8.0 in the torch tag v1.8.1,2021-07-09 18:19:56+00:00,,0,1,"[Label(name=""module: build""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
61464,Allow `ScriptModule`s to be symbolically traced,2021-07-09 16:57:31+00:00,,1,0,"[Label(name=""triaged""), Label(name=""FX-TorchScript Compatibility""), Label(name=""module: fx"")]"
61457,using DistributedSampler   occur RuntimeError: Expected a 'cuda:0' generator device but found 'cpu',2021-07-09 14:24:30+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
61453,"Reduce with any(), all(), median() over multiple dimensions",2021-07-09 13:19:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: reductions"")]"
61452,New module: Split log softmax with loss,2021-07-09 12:14:51+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
61417,Reductions tracking issue,2021-07-08 15:13:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: reductions""), Label(name=""tracker"")]"
61411,"I do have the GPU, but the print(torch.cuda.is_available()) always shows False",2021-07-08 13:59:14+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
61410,requires grad get lost during transform.,2021-07-08 12:48:17+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: tensor creation"")]"
61384,Merge fork of upload-artifact-s3 to a single commit,2021-07-07 23:04:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
61344,Get TensorType's device in python,2021-07-07 11:44:57+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp"")]"
61343,Feature Request: Remove Optimizer Lazy State Initialization,2021-07-07 11:38:42+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
61341,inerror: reference to ‘DeviceType’ is ambiguous,2021-07-07 09:58:54+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
61309,The class weights implementation is incorrect,2021-07-06 21:43:26+00:00,,0,14,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
61292,torch.linspace tensor support,2021-07-06 14:07:10+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
61289,Zero seed in DistributedSampler,2021-07-06 13:27:29+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
61281,DataLoader with IterativeDataset throws an error when providing a BatchSampler,2021-07-06 10:26:33+00:00,,0,5,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
61268,Unknown type name '__torch__.torch.classes.metal.Conv2dOpContext',2021-07-06 03:03:33+00:00,,0,1,"[Label(name=""module: convolution""), Label(name=""module: macos""), Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
61267,Incorrect trace with MKLDNN (adding scalar),2021-07-06 02:22:50+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: mkldnn"")]"
61261,libtorch_cpu.so is getting too large.,2021-07-05 17:20:56+00:00,,0,3,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
61260,libtorch_cpu.so: undefined symbol: _ZN3c1010ThreadPool3runESt8functionIFvvEE,2021-07-05 15:51:20+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: abi""), Label(name=""triaged"")]"
61246,"torch.quantization.fx.fuser forget to pass ""additional_fuser_method_mapping"" to fuse method",2021-07-05 07:20:34+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: fx"")]"
61244,error: invalid conversion in vec256_bfloat16.h,2021-07-05 03:57:22+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged"")]"
61243,Pytorch 1.5+ is slower than pytorch 1.3,2021-07-05 03:10:41+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""triaged"")]"
61233,[typing] ModuleDict ctor has wrong signature,2021-07-04 20:27:29+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged"")]"
61231,Document torch.Size and its methods (like torch.Size.numel),2021-07-04 19:01:55+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""triaged"")]"
61223,optimize_for_inference does not handle MKLDNN for BatchNorm1d,2021-07-04 13:52:57+00:00,,0,2,"[Label(name=""high priority""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
61222,The syncbatchnorm can not  be employed in the MODEL that the gradients including in the loss function,2021-07-04 13:21:59+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: derivatives""), Label(name=""module: norms and normalization"")]"
61221,Unable to add a scalar to an MKLDNN tensor,2021-07-04 12:43:05+00:00,,0,9,"[Label(name=""oncall: jit""), Label(name=""module: mkldnn""), Label(name=""module: intel"")]"
61213,[feature request] Low pass filtering of FFT results,2021-07-03 19:24:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: fft"")]"
61211,[feature request] Do zero-padding in high-frequency modes in `ifft`,2021-07-03 19:02:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: fft"")]"
61210,Jitted function cannot be pickled,2021-07-03 17:48:21+00:00,,1,9,"[Label(name=""oncall: jit""), Label(name=""good first issue""), Label(name=""OSS contribution wanted"")]"
61186,possible SummaryWriter memory leak,2021-07-02 22:35:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
61182,"Feature Request: torch.functional.interpolate to quietly ignore ""align_corners"" when mode is set to ""nearest""",2021-07-02 20:29:06+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: interpolation"")]"
61173, Increased memory usage with AMP ,2021-07-02 12:07:45+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
61167,Torch .pth model export to ONNX returned empty graph,2021-07-02 06:42:49+00:00,,1,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
61149,`pad(mode='reflect')` beyond `input.size`,2021-07-01 23:29:36+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: padding"")]"
61136,rename(**{}) should throw no error,2021-07-01 19:17:04+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
61122,Make copy_ use dispatcher,2021-07-01 14:21:15+00:00,,0,9,"[Label(name=""module: bootcamp""), Label(name=""triaged"")]"
61117,flatten renames in place,2021-07-01 14:05:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
61116,[custom op]RuntimeError: Error compiling objects for extension,2021-07-01 13:24:20+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
61110,Incorrect exponential calculation on Jetson devices with float32 dtype,2021-07-01 09:48:59+00:00,,0,12,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: arm""), Label(name=""module: jetson"")]"
61079,"[clang-tidy] Add a custom rule for AT_ERROR -> TORCH_CHECK(false, ...)",2021-06-30 23:26:48+00:00,,0,0,"[Label(name=""triaged"")]"
61046,Audit use of __ARM_NEON__ define,2021-06-30 16:19:25+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""enhancement"")]"
61041,Profile saving is slow,2021-06-30 13:34:34+00:00,,0,5,"[Label(name=""oncall: profiler"")]"
61030,[Docker] Incompatible torchvision for 1.9.0-cuda10.2-cudnn7-runtime tag.,2021-06-30 08:01:08+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: docker"")]"
60999,Merge seemethere/upload-artifact-s3 and driazati/upload-artifact-s3,2021-06-29 23:14:02+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
60997,Dispatcher doesn't handle ops with an empty list of tensors (e.g. `torch.cat()`),2021-06-29 22:10:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
60991,[NNC] APIs needed to bridge scheduling gap in reductions,2021-06-29 21:25:58+00:00,,1,0,"[Label(name=""NNC"")]"
60983,Automate bumping of `clang-tidy` docker image tag on CI,2021-06-29 20:23:44+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: infra"")]"
60977,[package] pattern usage can potentially create broken packages,2021-06-29 19:37:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
60971,jit scripting for the parametrizations,2021-06-29 18:48:11+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""module: nn.utils.parametrize"")]"
60956,Naming convention for variants of operations that never short circuit,2021-06-29 14:40:03+00:00,,0,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: ux"")]"
60953,Add support for Python's optimized mode to torchscript,2021-06-29 14:28:31+00:00,,0,3,"[Label(name=""oncall: jit"")]"
60950,Singular build setting CLANG_CXX_LANGUAGE_STANDARD has different values,2021-06-29 14:09:11+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
60941,Incorrect dtype cast for binary ops w/ mixed ComplexFloat + Double operands,2021-06-29 10:39:49+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: type promotion"")]"
60939,Functional multi_head_attention_forward softmax get nan for fp16 mode,2021-06-29 09:43:20+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
60937,[jit] About traced script module using in c++,2021-06-29 09:22:37+00:00,,0,9,"[Label(name=""oncall: jit"")]"
60936,The usage of get_stoi() in 0.10.0 and stoi[] in previous versions,2021-06-29 09:06:44+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
60933,jit.load error when changed Folder Name,2021-06-29 06:57:34+00:00,,0,3,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
60932,Is Python version of Docker image on DockerHub downgraded?,2021-06-29 06:12:59+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: docker"")]"
60930,error for using faster rcnn on c++ & GPU,2021-06-29 05:49:09+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""oncall: jit"")]"
60924,[rfc][local lint] Create lint runner as a setup.py target,2021-06-29 03:00:01+00:00,,0,1,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
60923,RuntimeError: derivative for im2col_backward is not implemented,2021-06-29 02:24:22+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
60916,Scipy 1.7.0 may cause some test failures,2021-06-28 23:31:17+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""module: tests""), Label(name=""triaged"")]"
60911,[elastic launcher] redirects/tee support for global rank,2021-06-28 22:12:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: elastic"")]"
60904,F.max_pool1d docs are really bad,2021-06-28 21:03:34+00:00,,1,4,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling"")]"
60858,Sparse CSR layout CPU backend tracking issue,2021-06-28 11:10:44+00:00,,1,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: mkl""), Label(name=""tracker"")]"
60854,Sparse CSR layout GPU backend tracking issue,2021-06-28 09:15:47+00:00,,1,7,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""tracker"")]"
60848,Fail to build with gcc11,2021-06-28 05:16:39+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: xnnpack"")]"
60847,How to release CPU memory cache in Libtorch JIT ?,2021-06-28 03:40:21+00:00,,0,2,"[Label(name=""oncall: jit"")]"
60844,DDP fails if you have multiple forward passes and a single backwards pass with `find_unused_parameters=True`,2021-06-28 02:54:54+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
60843,PyTorch's last 1 year update became unfriendly due to the lack of examples,2021-06-28 02:54:06+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
60835,"Pytorch V1.1 runs OK, but Pytorch v1.5 to 1.9 run wrong",2021-06-27 17:39:55+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: regression"")]"
60834,complie error when i use python setup.py build on arm computer,2021-06-27 12:33:42+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: arm"")]"
60832,State of Torch Named Tensors,2021-06-27 09:15:44+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
60825,Where OpInfo doesn't handle cases where one of the inputs is a scalar,2021-06-26 20:37:52+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
60802,Bug in `pytorch/benchmarks/tensorexpr/pt_engine.py`,2021-06-26 00:13:04+00:00,,0,1,"[Label(name=""triaged""), Label(name=""op-bench"")]"
60796,AccumulateGrad short circuits before calling variable hooks when the incoming grad is None,2021-06-25 23:33:27+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
60783,[torch.profiler] double counting CUDA wrapper self-cuda-time,2021-06-25 20:49:03+00:00,,0,6,"[Label(name=""oncall: profiler"")]"
60766,"_foreach_maximum returns ""incompatible type"" mypy error unexpectedly",2021-06-25 19:21:48+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged"")]"
60748,"Record file/line number when creating test data, and then report it in backtraces associated with this data",2021-06-25 15:44:37+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged"")]"
60732,Potential memory leaks reported by static analysis tool,2021-06-25 09:49:48+00:00,,0,1,"[Label(name=""oncall: jit"")]"
60727,[ONNX] export affine_grid_generator,2021-06-25 07:36:44+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""OSS contribution wanted""), Label(name=""function request""), Label(name=""onnx-needs-info"")]"
60724,bilinear interpolate is very slow under mixed precision training mode.,2021-06-25 06:26:54+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)""), Label(name=""module: interpolation"")]"
60674,Turn on -Winfinite-recursion in OSS CI,2021-06-24 18:55:47+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""better-engineering"")]"
60640,Building fails on a node with libibverbs installed with no Infiniband hardware present on RHEL8.,2021-06-24 09:21:26+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: tensorpipe"")]"
60628,pip install nightly torch torchaudio and torchvision together will install 0.3.0 version of torchvsion on Ubuntu,2021-06-24 05:27:43+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""triaged"")]"
60626,Impossible to raise the limit on number of shared memory tensors,2021-06-24 04:27:58+00:00,,0,11,"[Label(name=""high priority""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
60594,Install PyTorch on Windows with Conda and other Torch packages with cpuonly fails,2021-06-23 22:28:43+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
60561,nn.CrossMapLRN2d is missing from docs,2021-06-23 18:33:47+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
60548,Ensure warnings relate to user code with stacklevel,2021-06-23 16:02:08+00:00,,1,9,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: deprecation"")]"
60541,torch.cuda.Event(blocking=True) doesn't work,2021-06-23 14:08:20+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
60531,Enhanced torch.chunk and torch.split ,2021-06-23 11:33:26+00:00,,0,18,"[Label(name=""good first issue""), Label(name=""triaged""), Label(name=""enhancement"")]"
60520,[docs] torch.log_softmax is undocumented,2021-06-23 07:32:50+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
60518,different gpus to train,2021-06-23 07:15:53+00:00,,0,5,"[Label(name=""oncall: distributed"")]"
60477,ROCm miopenStatusInternalError /MIOpen/src/sqlite_db.cpp:109: open memvfs: unable to open database file,2021-06-22 18:18:02+00:00,,0,12,"[Label(name=""needs reproduction""), Label(name=""module: rocm""), Label(name=""triaged"")]"
60466,PyTorch unfold could be faster,2021-06-22 16:13:53+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged"")]"
60459,[Mkldnn] has_bf16 check only works on Linux for tests,2021-06-22 13:15:25+00:00,,0,4,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
60448,Enable large file support,2021-06-22 09:13:07+00:00,,0,0,"[Label(name=""module: build""), Label(name=""feature""), Label(name=""triaged"")]"
60440,DDP with cuda rpc failed with DistributedOptimizer Adagrad,2021-06-22 06:09:04+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""module: optimizer"")]"
60431,Implement simple view methods for TensorAccessor/PackedTensorAccessor,2021-06-22 02:40:43+00:00,,0,2,"[Label(name=""module: bootcamp""), Label(name=""triaged"")]"
60426,"Output of non-inplace, non-CompositeImplicitAutograd op has TensorImpl > 1 or StorageImpl use_count != 1",2021-06-22 00:58:00+00:00,,1,5,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
60401,Need workaround to support multiprocess CUDA tensor sharing on Jetson Platforms,2021-06-21 21:15:42+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""feature""), Label(name=""triaged"")]"
60400,Using inbuilt function name `input` as variable names in examples,2021-06-21 21:11:48+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
60381,broken source link / missing anchors,2021-06-21 17:39:41+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""triaged"")]"
60372,Docs for `Installing C++ Distributions of PyTorch` needs update,2021-06-21 15:47:30+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
60359,Expose the .pt model file path during TorchScript custom class Serialization/Deserialization,2021-06-21 10:35:37+00:00,,0,2,"[Label(name=""oncall: jit"")]"
60354,test_old_models_bc is flaky,2021-06-21 08:52:29+00:00,,1,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""module: flaky-tests"")]"
60343,What changes we need to make in metrics calculation and visualization part when we use Distributed Data Parallel for distributed training,2021-06-20 22:10:22+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
60341,C++ version 1.9.0 libtorch dynamic load fails -- GCC only,2021-06-20 15:43:09+00:00,,0,10,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""module: cpp""), Label(name=""module: abi""), Label(name=""triaged"")]"
60334,USE_SYSTEM_SLEEF: undefined reference to symbol 'Sleef_expd4_u10',2021-06-19 23:07:51+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: sleef"")]"
60333,Two-element ModuleList results in error in inference_mode when jit'ed,2021-06-19 22:36:00+00:00,,1,4,"[Label(name=""oncall: jit"")]"
60329,USE_SYSTEM_CPUINFO: internal symbol `clog_vlog_fatal' isn't defined,2021-06-19 16:35:48+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
60306,Divergent code is needed to record usage streams on different TensorImpl types,2021-06-18 22:07:42+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: vmap"")]"
60295,Optimize torch.einsum,2021-06-18 19:49:13+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
60294,Add a NumPy-like `pad` function,2021-06-18 19:43:44+00:00,,1,13,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: padding"")]"
60288,provide hashsum for downloads,2021-06-18 18:10:07+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
60277,Sparse CSR tensor should not accept equal column indices in the same row,2021-06-18 17:02:25+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""module: error checking""), Label(name=""triaged"")]"
60264,Subtensor operations like `tril/triu` to have an option to respect the strides of the input,2021-06-18 12:29:31+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: linear algebra"")]"
60261,Mixed logical indexing / numerical indexing fails.,2021-06-18 10:32:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
60252,UserWarning: Failed to initialize NumPy: No module named 'numpy',2021-06-18 06:42:41+00:00,,0,1,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
60234,Numerical-reproducibility issue in torch.matmul,2021-06-18 03:22:20+00:00,,0,15,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
60228,cannot build with tensorrt,2021-06-18 00:41:38+00:00,,0,4,"[Label(name=""module: build""), Label(name=""caffe2""), Label(name=""module: cuda""), Label(name=""triaged"")]"
60223,[testing] SkipInfo should error if `cls_name` and `test_name` combination is not valid,2021-06-17 23:11:26+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""needs design"")]"
60210,Quantized model using `boolean_dispatch` not picklable,2021-06-17 21:20:13+00:00,,1,6,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
60189,[package] Tutorial not accessible,2021-06-17 18:30:21+00:00,,0,1,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
60182,Improvement to CUDA mem leak check,2021-06-17 15:52:20+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
60172,[Android] Upgrading to 1.9.0 causes NNAPI model loading to fail,2021-06-17 09:11:41+00:00,,0,12,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
60165,torch.load non backwards compatible on Transformer between 1.8.1 and 1.9.0,2021-06-17 07:50:50+00:00,,0,7,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
60164,Training goes wrong with amp and no_grad since pytorch 1.8,2021-06-17 07:27:06+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
60159,Some ops throw runtime errors when called with complex tensors that require_grad but work when requires_grad=False,2021-06-17 06:12:10+00:00,,0,6,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""complex_autograd"")]"
60156,PEP-585 type annotations not supported for class-level annotations,2021-06-17 05:14:10+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
60153,[oneline docs] adding a source link for non-python functions,2021-06-17 04:47:54+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
60149,backward compatibility - need a way to find out when a certain API was added/modified/etc.,2021-06-17 04:43:48+00:00,,0,15,"[Label(name=""module: docs""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: doc infra""), Label(name=""better-engineering""), Label(name=""module: deprecation""), Label(name=""module: codegen"")]"
60146,[torch.profiler] enhancements + corrections,2021-06-17 02:49:22+00:00,,3,8,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: profiler"")]"
60143,"torch.jit.save gives error - RuntimeError: Could not export Python function call 'NMSop'. Remove calls to Python functions before export. Did you forget to add @script or @script_method annotation? If this is a nn.ModuleList, add it to __constants__",2021-06-17 01:17:19+00:00,,0,3,"[Label(name=""oncall: jit"")]"
60109,test_remote_module_py_pickle_not_supported_script is flaky,2021-06-16 17:44:11+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""module: rpc"")]"
60102,Allow packaging of classes defined in a notebook,2021-06-16 16:43:51+00:00,,0,1,"[Label(name=""triaged"")]"
60100,test_forward_async_script is flaky,2021-06-16 16:29:07+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""module: rpc"")]"
60096,Tutorials that require `pip install` not loading correctly in Colab,2021-06-16 14:44:09+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
60094,bundled libiomp5 causing segfaults in other libraries that use libomp,2021-06-16 14:20:56+00:00,,0,12,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: openmp"")]"
60092,`memory_format` flag for `tensor.new_empty()`. ,2021-06-16 14:17:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: memory format"")]"
60089,torch.package: TypeError: 'NoneType' object is not iterable,2021-06-16 09:26:44+00:00,,0,4,"[Label(name=""oncall: package/deploy""), Label(name=""imported"")]"
60084,Profiler does not contain NCCL kernel,2021-06-16 08:04:07+00:00,,3,3,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""oncall: profiler"")]"
60083,caffe_translator.py Unable to convert Power Layer,2021-06-16 07:46:33+00:00,,0,2,"[Label(name=""caffe2"")]"
60081,[Bug] numpy is no longer a required dependency,2021-06-16 07:32:19+00:00,,2,10,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: numpy"")]"
60069,Symbolic trace with *args,2021-06-16 04:05:13+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fx"")]"
60063,Replace native NHWC BN kernel,2021-06-16 02:07:27+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
60062,[c10d] Make `broadcast_object_list` accept a device parameter,2021-06-16 01:42:31+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp"")]"
60028,RReLU and PReLU do not propagate input strides to outputs,2021-06-15 17:33:09+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: memory format"")]"
60008,Dynamic quantized LSTM does not support output projection now.,2021-06-15 08:42:28+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
59936,Can't perform any operation on Vulkan device - macOS M1,2021-06-14 12:58:42+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm""), Label(name=""module: vulkan"")]"
59935,Error /usr/local/lib/libopenblas.so: error adding symbols: File in wrong format while building pytorch for ppc64le,2021-06-14 12:03:57+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER"")]"
59925,Implicit module registration permits silent programming errors in torch.nn.Module,2021-06-13 22:59:24+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
59923,Lazy modules should accept keyword arguments to forward method,2021-06-13 21:37:34+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
59905,[JIT] batch operators in training/inference ,2021-06-12 01:39:46+00:00,,0,2,"[Label(name=""oncall: jit"")]"
59896,Autograd engine current graph_task should be in the TLSState,2021-06-11 21:27:56+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
59883,"matmul causing cuDNN error: CUDNN_STATUS_INTERNAL_ERROR at future, unrelated Conv2d",2021-06-11 17:47:43+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
59875,[ROCm] test_gather_stress_cuda is flaky,2021-06-11 15:56:27+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
59868,Python scalars should be promoted to the same `dtype` as the respective tensor,2021-06-11 07:52:01+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""needs design""), Label(name=""module: python array api"")]"
59865,Custom build of c++ libtorch for Android program or dynamic so lib does not reduce program or lib size,2021-06-11 06:32:19+00:00,,0,2,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
59863,Sum issues with FP32,2021-06-11 05:14:44+00:00,,1,3,"[Label(name=""module: numerical-stability""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""module: reductions"")]"
59855,pytorch test failed,2021-06-11 01:20:34+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged"")]"
59854,Misreported linting messages,2021-06-11 01:07:12+00:00,,0,0,"[Label(name=""module: lint""), Label(name=""triaged"")]"
59823,print_regression should handle sharded test properly,2021-06-10 20:34:32+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""better-engineering"")]"
59822,TransformedDistribution's log_prob gradient is inconsistent w.r.t. cache_size,2021-06-10 20:24:03+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
59806,Context manager for torch.jit.ignore is not covered by test coverage ,2021-06-10 18:28:00+00:00,,1,1,"[Label(name=""oncall: jit"")]"
59787,Remove support for multiple ellipses in slicing,2021-06-10 11:48:40+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""module: deprecation""), Label(name=""needs design""), Label(name=""module: python array api"")]"
59786,Support negative step sizes for slicing,2021-06-10 11:44:07+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: python array api"")]"
59783,[Feature Request] Deterministic implementation for AdaptiveMaxpool1d.,2021-06-10 10:45:48+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: determinism""), Label(name=""module: pooling"")]"
59778,CUDA Memory Error: PyTorch doen't allocate memory even though it's available,2021-06-10 07:46:21+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
59745,[c10d] Work objects should have a general operator<< ,2021-06-09 21:10:09+00:00,,0,2,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: c10d"")]"
59743,m.fallback(torch::CppFunction::makeFromBoxedFunction<&my_fallback>) gives bad error message,2021-06-09 20:50:46+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
59730,Quantized conv2d with dilation and groups much slower than float32,2021-06-09 19:49:51+00:00,,1,10,"[Label(name=""module: performance""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""module: convolution""), Label(name=""triaged"")]"
59723,Segmentation fault when using CUDA with RNN,2021-06-09 18:20:47+00:00,,0,11,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: rnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
59692,"cuda streams run sequentially, expected to run parallel",2021-06-09 08:01:38+00:00,,0,18,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
59690,Inference ran on new thread leak memory on Android,2021-06-09 07:52:15+00:00,,0,7,"[Label(name=""module: memory usage""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
59682,Add a lint rule to recommend TORCH_CHECK(false) over throw std::runtime_error,2021-06-09 00:37:22+00:00,,0,1,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
59652,pin_memory mutates its input but this is not reflected in JIT schema,2021-06-08 19:57:47+00:00,,0,0,"[Label(name=""oncall: jit"")]"
59645,Tensor.type() does not work with meta tensors,2021-06-08 18:42:25+00:00,,0,4,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: meta tensors"")]"
59629,Potentially misleading note in documentation for PackedSequence,2021-06-08 12:49:37+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
59628,what():  result type Float can't be cast to the desired output type Long,2021-06-08 11:50:47+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: cpp""), Label(name=""triaged"")]"
59627,Example code for is_storage missing,2021-06-08 11:43:29+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
59626,multi scripted model on the same gpu on multi gpu machine,2021-06-08 11:24:47+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: multi-gpu""), Label(name=""triaged"")]"
59617,torch.split() infer -1 entry from the other split sizes,2021-06-08 07:08:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: viewing and reshaping"")]"
59612,Why Pytroch.distributed does not expose NCCL cuda stream?,2021-06-08 02:07:43+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: c10d"")]"
59592,Build failed with TBB,2021-06-07 21:39:39+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: tbb"")]"
59575,[clang-tidy] check for iteration over unordered data structures,2021-06-07 19:36:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
59566,[discussion] Make docs consistent for torch.nn Modules,2021-06-07 16:40:05+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
59552,test_batch_isend_irecv_nccl fails with NCCL 2.8.3,2021-06-07 11:41:52+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
59551,"error when trying to call ""torch::jit::load""method, use Metal backend in PyTorch Mobile",2021-06-07 11:24:04+00:00,,0,12,"[Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
59546,Multiprocessing model evaluation gets stuck,2021-06-07 09:13:30+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
59545,max-sum operation,2021-06-07 08:31:11+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: reductions"")]"
59542,Build Pytorch with Aten?,2021-06-07 07:19:21+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
59531,Failed to enable libuv,2021-06-07 02:26:09+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
59530,Batch size is hardcoded using torch.jit.trace with LSTMCell,2021-06-07 02:23:23+00:00,,0,11,"[Label(name=""oncall: jit"")]"
59528,AttributeError: module 'torch.jit' has no attribute '_script_if_tracing',2021-06-07 00:40:43+00:00,,0,2,"[Label(name=""oncall: jit"")]"
59526,Documentation for torch.finfo doesn't match implementation,2021-06-06 22:02:22+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy"")]"
59515,Conv1d with large batch size and half precision in cuda returns incorrect result,2021-06-05 17:21:40+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
59493,ctc loss bug,2021-06-05 00:08:15+00:00,,0,6,"[Label(name=""module: autograd""), Label(name=""module: loss""), Label(name=""triaged"")]"
59457,Error compiling PyTorch: `/usr/bin/ld: cannot find -lmagma /usr/bin/ld: cannot find -lnvToolsExt`,2021-06-04 16:38:10+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
59441,distributed/test_jit_c10d.py fails with RuntimeError: Address already in use,2021-06-04 12:05:43+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
59439,NaN values on torch.nn.functional.conv2d (aarch64),2021-06-04 11:29:14+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: arm""), Label(name=""module: jetson"")]"
59438," DataLoader worker (pid(s) 18056, 20540, 4512) exited unexpectedly",2021-06-04 11:14:45+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
59437,pytorch/manylinux-cuda102 support for aarch64,2021-06-04 09:08:05+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: docker""), Label(name=""module: arm"")]"
59436,Test timeout and assertion failure in distributed/rpc/test_tensorpipe_agent,2021-06-04 08:56:23+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""module: rpc"")]"
59418,Libtorch segfault in packed GRU evaluation with cuda batch_sizes,2021-06-03 22:15:39+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
59386,Energy-efficiency benchmarks?,2021-06-03 17:41:05+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged"")]"
59356,pytorch build failure on arm64,2021-06-03 01:45:28+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: arm""), Label(name=""module: jetson"")]"
59309,CUDA memory error when using torch.device('cpu') ,2021-06-02 16:08:55+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
59263,Ubuntu 20.04 GeForce RTX 3070  / NVIDIA-SMI 460.73.01 Driver Version: 460.73.01 /  GPU Visibility Issue,2021-06-01 21:13:23+00:00,,0,10,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
59262,"Possibly alignment issues on NEON vectorized ops, Jetson platforms",2021-06-01 21:05:29+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: arm""), Label(name=""module: jetson"")]"
59257,Optimizer step stuck during distributed training,2021-06-01 19:18:05+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: data parallel""), Label(name=""module: amp (automated mixed precision)"")]"
59256,ProcessGroupGloo creation crashes when world_size > 150,2021-06-01 19:04:38+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""module: c10d"")]"
59251,Ahead of time C++ Extensions should have an option to build with verbose=False,2021-06-01 15:40:27+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
59247,Support complex numbers in `at::nan_to_num`.,2021-06-01 14:36:40+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
59243,Can't install pytorch =1.7 with python 3.8.5 on Raspberry Pi ,2021-06-01 13:37:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: arm"")]"
59237,Multiplication of `torch.tensor` with `np.array` does the operation with numpy.,2021-06-01 08:11:45+00:00,,1,6,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: numpy"")]"
59218,Clarify BLAS configuration option,2021-05-31 14:07:16+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
59216,Add a BlendLoss class in torch.nn and a blend_loss function in torch.nn.functional to allow blending of a list of loss functions,2021-05-31 13:54:57+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""enhancement"")]"
59196,torch.zeros memory leak : cpu,2021-05-31 07:47:44+00:00,,1,3,"[Label(name=""high priority""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
59194,Add numerically-stable function for angle between vectors,2021-05-31 06:04:57+00:00,,0,2,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: distance functions"")]"
59185,Add supports_nnc metadata to OpInfos,2021-05-30 08:04:09+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""NNC"")]"
59174,[jit] Error: Results of original model and exported/imported version of model differed ,2021-05-29 11:12:29+00:00,,1,0,"[Label(name=""oncall: jit"")]"
59168,[CUDA] Add channels_last_3d support for commonly used modules,2021-05-29 00:31:20+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: memory format"")]"
59153,JIT compiling a ParameterList raises an unnecessary warning,2021-05-28 16:55:52+00:00,,1,7,"[Label(name=""oncall: jit"")]"
59140,No index type check of torch.tensor in array manner,2021-05-28 07:05:20+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
59137,[autograd] `fill_` gradgradcheck raises RuntimeError,2021-05-28 06:24:02+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
59114,[JIT] OpInfo / Autodiff tests dont seem to actually invoke symbolic backwards ,2021-05-27 23:18:12+00:00,,0,1,"[Label(name=""oncall: jit"")]"
59104,Data access pattern in the loop in add_out_dense_sparse_csr_cuda could be pretty bad,2021-05-27 20:46:30+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
59101,Use of storage_offset is not needed  in add_out_dense_sparse_csr_cuda,2021-05-27 20:28:57+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
59099,CSR: Relaxing constraints to s_addmm_out_sparse_dense_cuda_worker,2021-05-27 20:22:01+00:00,,1,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""open source"")]"
59098,`test_lstm` in `quantization.bc.test_backward_compatibility.TestSerialization` fails on Intel Cascade Lake machines,2021-05-27 19:55:17+00:00,,0,10,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
59074,c++ use pybind11 to import torch  free(): invalid pointer,2021-05-27 08:52:44+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: pybind"")]"
59071,test_bottleneck_cuda fails without error message,2021-05-27 06:42:11+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged"")]"
59058,Issue: support auto generation of device check for sparse tensors,2021-05-27 02:00:21+00:00,,0,6,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: codegen"")]"
58997,[discussion] Should Optimizers be also Modules?,2021-05-26 16:50:11+00:00,,0,8,"[Label(name=""module: nn""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
58983,Get stuck while using pytorch.profiler,2021-05-26 09:49:30+00:00,,3,2,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
58982,Can't re-init rpc with a different rank after rpc shutdown,2021-05-26 09:44:07+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""has workaround"")]"
58980,libtorch conflict with cxxopts and cause memery leak,2021-05-26 08:02:52+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
58979,gradient layout contract,2021-05-26 07:51:04+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
58973,First-class Java API,2021-05-26 04:40:03+00:00,,0,9,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: java"")]"
58969,Improper use of quantization API for MHA should fail fast,2021-05-26 02:46:10+00:00,,1,5,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
58962,Operating on a shared memory tensor with multiple threads hangs,2021-05-25 23:53:13+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
58944,Use PYTHONHASHSEED during pytorch build to avoid nondeterminism,2021-05-25 20:37:49+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: determinism""), Label(name=""module: codegen"")]"
58930,[local lint] Shellcheck quicklint file filter is incorrect,2021-05-25 18:42:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
58907,"JIT fails when calling an exported method inside another one, if kwargs with defaults are not passed",2021-05-25 08:54:27+00:00,,1,1,"[Label(name=""oncall: jit"")]"
58876,[deploy] Enable `torch.distributed.rpc` Python bindings in deploy,2021-05-24 20:22:39+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: deploy"")]"
58862,[cuDNN v8] Improve cuDNN convolution v8 API error reporting,2021-05-24 17:02:34+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
58860,[cuDNN v8] Extend current cuDNN convolution v8 API binding to support conv-bias-activation fusion,2021-05-24 16:58:01+00:00,,1,2,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
58859,[cuDNN v8] Extend current cuDNN convolution v8 API binding to support cuDNN benchmark,2021-05-24 16:56:43+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
58858,[cuDNN v8] Extend current cuDNN v8 API binding to support convolution backward and transposed convolution forward,2021-05-24 16:48:53+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
58857,Call non class methods from `torch::jit::Module` in C++,2021-05-24 16:32:38+00:00,,0,1,"[Label(name=""oncall: jit"")]"
58856,NCCL multi-gpu test intermittently failing after NCCL version upgrade,2021-05-24 16:26:44+00:00,,1,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: nccl"")]"
58847,Dataloader Rerunning with num_workers=0 may give better error trace,2021-05-24 14:21:12+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: ddp"")]"
58846,Simplification of pruned models,2021-05-24 12:58:20+00:00,,0,14,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
58845,Use jit in flask,2021-05-24 12:16:10+00:00,,0,7,"[Label(name=""oncall: jit"")]"
58841,[bug] torch.topk sometimes supports `float16` and sometimes doesn't,2021-05-24 08:50:13+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: half""), Label(name=""module: sorting and selection"")]"
58836,Latest nightly produces CUDA torchscript that cannot be run,2021-05-24 05:39:55+00:00,,1,2,"[Label(name=""oncall: jit"")]"
58833,Foreach Functions Tracking Issue,2021-05-24 03:29:33+00:00,,0,13,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""tracker""), Label(name=""module: mta"")]"
58828,[Feature Pitch] Fast extremal eigensolvers,2021-05-23 20:37:16+00:00,,0,15,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
58820,[docs] Tensor.bernoulli_ formatting is hard to read and UX inconsistent with the function variant,2021-05-23 09:55:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: ux"")]"
58814,TensorIterator for sparse layouts,2021-05-23 02:57:43+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
58813,Single-Process Multi-GPU is not the recommended mode for DDP,2021-05-23 02:40:08+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
58812,"Transferring tensor to the gpu and converting dtype in a single call to .to() is slower than first transferring, then converting.",2021-05-23 00:30:09+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
58804,A Null pointer dereference bug,2021-05-22 09:04:35+00:00,,0,1,"[Label(name=""oncall: jit"")]"
58791,[nnc] Add more optimization for conditional stmts in loopnest transformations,2021-05-22 01:02:51+00:00,,0,0,"[Label(name=""NNC"")]"
58789,Type annotations for torch.jit.* decorators,2021-05-22 00:38:10+00:00,,0,3,"[Label(name=""oncall: jit"")]"
58779,C++ Extensions that use ninja should enable colors by default,2021-05-21 22:05:07+00:00,,0,3,"[Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""enhancement"")]"
58772,NNC Lowering bugs found by new OpInfo tests,2021-05-21 19:38:28+00:00,,0,2,"[Label(name=""NNC"")]"
58770,MKL csr matmul issue,2021-05-21 19:16:21+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: mkl"")]"
58765,[codegen] generated inplace/out= wrappers don't have input checks,2021-05-21 18:01:59+00:00,,1,4,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: codegen"")]"
58758,precision/consistency issue in `linspace`,2021-05-21 16:32:01+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: numerical-reproducibility""), Label(name=""module: tensor creation"")]"
58745,"`torch.(min|max)(..., dim=...)` diverges from array API specification",2021-05-21 10:26:23+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: reductions""), Label(name=""module: python array api"")]"
58744,Using pytorch 1.1 model on pytorch 1.8 environment,2021-05-21 10:21:08+00:00,,0,4,"[Label(name=""oncall: jit"")]"
58743,Python Array API Compatibility Tracker,2021-05-21 10:08:45+00:00,,0,11,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: python array api""), Label(name=""tracker"")]"
58742,Python Array API New Operators Tracker,2021-05-21 10:02:37+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: python array api""), Label(name=""tracker"")]"
58741,`torch.size()` diverges from array API specification,2021-05-21 09:57:46+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: python array api"")]"
58736,type promotion with 0d-tensors diverges from array API specification,2021-05-21 07:41:26+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: python array api"")]"
58735,CSR construction: safe_get_attr_string suppresses real errors,2021-05-21 07:40:14+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""open source"")]"
58734,"Support for `uint16`, `uint32`, and `uint64`",2021-05-21 07:38:15+00:00,,0,16,"[Label(name=""triaged""), Label(name=""module: python array api""), Label(name=""oncall: pt2"")]"
58720,`pickle_save`/`pickle_load` are undocumented,2021-05-21 00:41:57+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
58681,Incorrect channel in installation command for stable (1.8.1)+windows+conda+python+cuda 11.1,2021-05-20 18:10:34+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""has workaround"")]"
58672,Werror should include -Wmissing-prototypes,2021-05-20 15:24:39+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: build warnings"")]"
58671,torch.load with dill is unable to unserialize from buffer,2021-05-20 15:13:47+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
58670,Ability to enabling/disabling cuDNN and cuBLAS API logging in PyTorch API directly,2021-05-20 15:09:44+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas"")]"
58657,"Improvement suggestions for the error message ""Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false""",2021-05-20 12:50:57+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
58628,[JIT] Concat QKV Linear Layers On Frozen Models,2021-05-20 00:51:09+00:00,,2,9,"[Label(name=""oncall: jit"")]"
58626,GPU 0 context created on GPU 1 worker when using pin_memory=True,2021-05-20 00:23:19+00:00,,0,7,"[Label(name=""module: dataloader""), Label(name=""module: cuda""), Label(name=""triaged"")]"
58617,[rfc] Bug developers about release notes for new APIs,2021-05-19 21:42:17+00:00,,0,3,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
58596,Some cuda objects take very long time to build,2021-05-19 20:02:30+00:00,,0,6,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
58591,"link error on BatchNormImplBase<D, Derived>::pretty_print  when using icpc ",2021-05-19 19:22:50+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: undefined reference"")]"
58585,Calling benchmark.Timer with default `num_threads=1` disables parallelism permanently,2021-05-19 18:34:50+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: multithreading"")]"
58567,ONNX exported EmbeddingBag fails for not strictly increasing offset.,2021-05-19 16:44:00+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
58555,fx: unable to symbolically trace model with torch.full(Proxy),2021-05-19 14:22:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
58548,Pixel shuffle support for PyTorch Mobile NN-API,2021-05-19 09:46:25+00:00,,1,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
58533,Migrate wheels to manylinux2010,2021-05-19 05:33:15+00:00,,1,2,"[Label(name=""oncall: releng""), Label(name=""triaged"")]"
58522,DDP grads dont have parity with local training when grads are undefined,2021-05-19 00:44:00+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
58516,Unhelpful error message when type annotation is violated.,2021-05-18 22:58:31+00:00,,0,0,"[Label(name=""oncall: jit"")]"
58507,OpInfo JIT tests do not work with Tensor kwarg arguments,2021-05-18 21:17:59+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: tests""), Label(name=""better-engineering"")]"
58489,Inter-category type promotion has undocumented behavior,2021-05-18 16:18:31+00:00,,0,8,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
58479,Make SavedVariables aware of pyobjects,2021-05-18 14:20:33+00:00,,2,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
58474,nn.Upsample result mismatch in 1.1.0a0+828a6a3 and 1.9.0,2021-05-18 09:59:18+00:00,,0,1,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
58471,Why the same training code running on different GPUs (V100 vs P100) brings a significiant difference in outputs and thus train loss / model accuracy?,2021-05-18 08:29:50+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: determinism"")]"
58466,`set_per_process_memory_fraction()` does not ensure max used GPU memory below fraction,2021-05-18 05:02:02+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
58456,TSAN issues in torch::jit::ProfilingRecord,2021-05-18 01:35:50+00:00,,0,2,"[Label(name=""oncall: jit"")]"
58452,Data race in RecordFunction::callbackShouldRun,2021-05-18 01:27:59+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
58447,TSAN issues in at::RecordFunction,2021-05-18 00:27:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
58442,TSAN issues in autograd,2021-05-17 23:59:53+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
58440,TSAN issues in libkineto,2021-05-17 23:44:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
58414,cuDNN v8 API tracking issue,2021-05-17 17:15:22+00:00,,1,0,"[Label(name=""high priority""), Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""tracker"")]"
58402,fx OpInfo tests don't work with nn.functional test names,2021-05-17 16:13:01+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
58395,[DOC] Add info about differentiability of functions,2021-05-17 15:23:28+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
58393,"In Android, the memory used by the tensor or model cannot be recycled. Is there any way to solve it?",2021-05-17 15:06:37+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
58392,torch.cuda.amp.autocast nan values when model.eval(),2021-05-17 14:03:41+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
58386,Better shared memory allocation under Docker,2021-05-17 11:17:53+00:00,,0,2,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: docker"")]"
58385,"A ""sanitizer"" mode for the CUDA caching allocator?",2021-05-17 11:07:42+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
58380,Clarity of error message in einsum regressed in performance improvements,2021-05-17 08:37:27+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
58371,Tests do not pass even though build successful,2021-05-16 22:14:47+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
58370,Add better python operators annotations for IDE type checking,2021-05-16 22:10:58+00:00,,1,5,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""module: typing""), Label(name=""triaged"")]"
58352,Broadcasting multiple tensors to all procs in distributed training,2021-05-15 16:28:40+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
58351,need  sampled softmax loss  function to train model to get user vector and item vector with a large dictionary,2021-05-15 14:25:40+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: loss""), Label(name=""triaged"")]"
58343,Add the features like Keras,2021-05-15 03:53:59+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: convolution""), Label(name=""triaged"")]"
58298,"[JIT] Can't handle creating new objects in compiled methods: ""Class does not have an __init__ function defined""",2021-05-14 10:15:39+00:00,,0,5,"[Label(name=""oncall: jit"")]"
58267,Pytorch build issues on PowerPC,2021-05-13 22:22:38+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER""), Label(name=""oncall: profiler"")]"
58238,torchdeploy doesn't prevent Obj from being used on wrong interpreter,2021-05-13 15:19:49+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: deploy"")]"
58228,"""_amp_foreach_non_finite_check_and_unscale_cuda"" not implemented for 'ComplexFloat'",2021-05-13 13:28:44+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""needs design""), Label(name=""module: amp (automated mixed precision)"")]"
58220,"After the Adam optimizer used weight_decay, the model became extremely slow when tested on the CPU.(Time from 7 seconds to 46 seconds)",2021-05-13 06:06:57+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
58218,"Torch.nn.DataParallel training model, the output of the model becomes list type, the number of lists is batch size",2021-05-13 05:41:53+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
58212,`torch.autograd.Function` subclasses *sometimes* throw away custom subclasses,2021-05-13 03:01:25+00:00,,1,10,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
58190,[FX] record_function tracing in FX,2021-05-12 22:00:10+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
58181,torch.split_with_sizes is not documented,2021-05-12 20:08:04+00:00,,1,10,"[Label(name=""module: docs""), Label(name=""triaged"")]"
58172,Mobile Android: Could not run 'aten::quantize_per_tensor' with arguments from the 'Vulkan' backend,2021-05-12 19:11:33+00:00,,1,7,"[Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
58171,"Error while converting model for NNAPI ""Unsupported node kind ('quantized::batch_norm2d')""",2021-05-12 19:03:57+00:00,,1,7,"[Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
58167,Allow `Union` as a `Dict` key,2021-05-12 18:29:56+00:00,,1,0,"[Label(name=""triaged""), Label(name=""TSRootCause:TypeRefinement"")]"
58155,"""uncorrectable NVLink error"" making the tests fail",2021-05-12 16:19:21+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: nccl"")]"
58139,[docs] Strange torch.unique function signature,2021-05-12 14:51:36+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
58136,scatter_add_ 6000-times slower with int64 compared to int32,2021-05-12 13:16:56+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
58135,Segmentation fault need help,2021-05-12 13:10:24+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
58128,the same input with different batchsize got different precision output,2021-05-12 08:30:44+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility""), Label(name=""module: batching"")]"
58127,Save checkpoint error,2021-05-12 08:10:12+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""module: serialization""), Label(name=""triaged"")]"
58124,Python API binding code generation does not need to pack TensorOptions for `xxx_like` generators,2021-05-12 06:33:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
58122,Generate special clear error messages for known common misuses in TorchScript,2021-05-12 06:11:02+00:00,,4,16,"[Label(name=""module: bootcamp""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""OSS contribution wanted"")]"
58119,[FX] Revise PyTree support in FX to move pytree logic out of `self.code`,2021-05-12 05:27:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
58111,Static graph training fails if forward is called multiple times before backward,2021-05-12 02:20:55+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
58109,torch.jit.trace memory leak,2021-05-12 02:03:52+00:00,,1,2,"[Label(name=""oncall: jit"")]"
58093,"TrilinearBackward takes 98.4% of total computational time, is this to be expected?",2021-05-11 22:18:26+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""triaged"")]"
58091,Follow-up updates to inference mode python bindings,2021-05-11 21:49:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""inference mode"")]"
58087,TensorList upfront checks parameter types in argument parsing and throws an error unexpectedly,2021-05-11 21:17:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
58054,PyTorch master failed to build with glog 0.5.0.,2021-05-11 16:15:41+00:00,,0,16,"[Label(name=""module: build""), Label(name=""triaged"")]"
58051,quantize_per_tensor not symbolically traceable with FX if scale+zp are proxied,2021-05-11 16:06:12+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
58037,linalg.eigh and linalg.cholesky UPLO flag breaks in backward,2021-05-11 11:05:55+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
58036,[feature request] torch.as_tensor to support any object that NumPy's asarray or array can consume (consume __array_interface__),2021-05-11 10:39:11+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
58034,Add a `descending` flag to `linalg.eigh` and `linalg.svd` ,2021-05-11 09:35:53+00:00,,0,10,"[Label(name=""module: docs""), Label(name=""feature""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
58016,Eliminate potential double device check,2021-05-11 05:32:53+00:00,,0,2,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
58015,Support a dist.group_like API,2021-05-11 05:05:49+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""pt_distributed_rampup""), Label(name=""module: c10d"")]"
58005,torch.distributed.nn.all_reduce incorrectly scales the gradient,2021-05-11 00:28:20+00:00,,0,27,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
57987,`type: ignore` everything,2021-05-10 21:30:54+00:00,,0,3,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
57960,Use the same CUDA stream for all RPCs within the same dist autograd context,2021-05-10 17:21:12+00:00,,0,13,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
57957,Add a few tests to make sure new dispatch keys for backends are added properly.,2021-05-10 16:56:51+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
57949,[structured] Clarify if NoNamesGuard is actually needed in impls or not,2021-05-10 14:28:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: structured kernels"")]"
57947,torch.lerp to support argument type promotion / broadcasting similar to torch.where,2021-05-10 13:30:41+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: interpolation"")]"
57929,[JIT] provide a pass for alias reduction,2021-05-10 02:30:47+00:00,,0,2,"[Label(name=""oncall: jit"")]"
57921,Backward pass for a nn.Conv2d with half-precision on Quadro RTX 8000 leads to CUDNN_STATUS_INTERNAL_ERROR,2021-05-09 18:04:38+00:00,,0,1,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
57911,Circular padding in Convolution layers should not only be wrap for once.,2021-05-09 02:21:19+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: padding"")]"
57894,"JIT ""optimizations"" take way too long ",2021-05-08 12:03:14+00:00,,0,2,"[Label(name=""oncall: jit"")]"
57893,Android API to run model on Vulkan backend,2021-05-08 10:54:57+00:00,,1,6,"[Label(name=""oncall: mobile"")]"
57887,[Mobile] Valid scale ratio with invalid error,2021-05-08 07:01:00+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
57843,Torch.save doesn't make new file,2021-05-07 20:08:08+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
57815,copy.deepcopy fails on spectral-norm layers after the first forward,2021-05-07 10:28:24+00:00,,0,11,"[Label(name=""module: nn""), Label(name=""triaged"")]"
57796,BatchNorm grad calculation is imprecise,2021-05-07 03:39:35+00:00,,2,10,"[Label(name=""needs reproduction""), Label(name=""module: numerical-stability""), Label(name=""module: autograd""), Label(name=""triaged"")]"
57794,CUDA error: an illegal memory access was encountered,2021-05-07 02:23:34+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
57793,"LibTorch inference script model is slower than PyTorch, and the speed is not stable. Why?",2021-05-07 02:14:20+00:00,,0,2,"[Label(name=""oncall: jit"")]"
57787,Add CI automation tests for Infiniband for DDP,2021-05-07 00:16:09+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
57776,[rfc] Build a debug tool to help users find which parameters are unused during DDP training,2021-05-06 22:11:24+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
57773,BFloat16 CUDA GEMM ops unsupported on Nvidia P100 (SM_60) on CUDA 11.3,2021-05-06 21:45:41+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas""), Label(name=""module: bfloat16"")]"
57759,Show commit hash for master branch docs on pytorch.org,2021-05-06 18:14:23+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: doc infra"")]"
57742,[structured] Meta-impl split implies redundant dtype tests,2021-05-06 15:28:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
57739,object with __torch_functon__ does not work with jit function ,2021-05-06 14:51:22+00:00,,0,1,"[Label(name=""oncall: jit"")]"
57724,Incorporate Posit Support,2021-05-06 11:55:32+00:00,,0,18,"[Label(name=""triaged""), Label(name=""needs research"")]"
57721,nn.TransformerEncoder cannot deal with large negative value even when this value is masked by src_key_padding_mask,2021-05-06 11:19:47+00:00,,0,1,"[Label(name=""oncall: transformer/mha"")]"
57717,TorchScript JIT Compiler Can't Recognize Repeated Branches (Scripting),2021-05-06 09:22:49+00:00,,0,6,"[Label(name=""oncall: jit"")]"
57716,Unknown builtin op: torchvision::nms in LibTorch,2021-05-06 08:53:26+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: serialization""), Label(name=""module: vision"")]"
57712,[Docs] nn.init._calculate_fan_in_and_fan_out(),2021-05-06 06:30:54+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""triaged"")]"
57691,Unify `std::getenv` usages,2021-05-05 23:04:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
57690,torch.cdist returns high diagonal values with CUDA,2021-05-05 22:26:00+00:00,,0,5,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: tf32"")]"
57646,"get_future() should be documented once it is enabled for gloo, mpi backends",2021-05-05 16:55:24+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
57639,"After tracing, the device of the named buffer is still `cuda` although it was moved to `cpu `",2021-05-05 15:08:37+00:00,,1,4,"[Label(name=""oncall: jit"")]"
57631,Pruners' compute_mask returns tensors with dtypes that are not consistent with each other,2021-05-05 14:23:15+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pruning"")]"
57617,complex128 autograd failures on PPC,2021-05-05 13:11:09+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: POWER""), Label(name=""complex_autograd"")]"
57611,[perf] 10x improvement on element-wise operations with manual broadcast,2021-05-05 08:03:00+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: TensorIterator"")]"
57610,[perf] 10x improvement when doing `x.sum(-1)` manually,2021-05-05 07:54:42+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: reductions"")]"
57593,[RFC] Provide an API for Structural Performance Tips in DDP,2021-05-05 06:18:57+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: ddp"")]"
57592,`jit.trace` fails to capture single-element tensor passed into op requiring scalar-type argument,2021-05-05 05:59:24+00:00,,0,0,"[Label(name=""oncall: jit"")]"
57559,[JIT] Investigate cloning/copying object before tracing it,2021-05-04 18:45:18+00:00,,0,2,"[Label(name=""oncall: jit"")]"
57554,Delete max_pool2d_with_indices_backward.grad_input?,2021-05-04 17:35:22+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: deprecation"")]"
57547,Add distributed testing for CUDA aware MPI,2021-05-04 15:22:57+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
57534,`torch.view_as_complex()` does not work when `storage_offset` is odd,2021-05-04 09:32:34+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: complex"")]"
57533,test_grid_sample (from TestNN) fails on POWER,2021-05-04 08:39:10+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: POWER"")]"
57507,Cleanup usage of IS_PYTHON_3_9_PLUS in autograd engine,2021-05-03 22:18:05+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: pybind"")]"
57503,[new feature] Adaptive gradient clipping,2021-05-03 22:10:09+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
57502,[structured] Fail if CompositeExplicitAutograd is in dispatch table of structured_delegate function,2021-05-03 21:59:11+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
57495,Please remove this assertion - it triggers on valid use cases,2021-05-03 21:25:01+00:00,,0,1,"[Label(name=""triaged"")]"
57491,setting  all seed still get different result. ,2021-05-03 20:44:54+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: determinism"")]"
57476,Profiler creates sequence numbers that are off by 1 between the forward and backwards pass,2021-05-03 17:50:04+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
57475,CUDA RPC stream synchronization does not work with @rpc.functions.async_execution,2021-05-03 17:39:34+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
57457,Valgrind Shows Potential Memory Leaks,2021-05-03 08:14:10+00:00,,0,12,"[Label(name=""oncall: jit""), Label(name=""module: autograd"")]"
57447,`torch._dirichlet_grad` returns `nan` value on cuda device,2021-05-02 21:55:18+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
57440,"I have just wasted 3 solid days trying to build PyTorch, without success",2021-05-02 17:06:40+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
57423,internal compiler error compiling PyTorch master on Fedora 33,2021-05-01 23:29:33+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""shadow review"")]"
57418,Poor torch.cat performance in the quantized Unet,2021-05-01 18:02:56+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
57415,torch 1.8.1+cuda crashes when setting breakpoints.,2021-05-01 10:49:29+00:00,,0,2,"[Label(name=""triaged"")]"
57406,nn.Module custom setattr leads very confusing behaviors,2021-05-01 01:29:23+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
57404,[lint] Make sure that all CMake options have a corresponding output in the summary,2021-05-01 00:04:04+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
57392,Simplified API for custom inplace & view kernel ,2021-04-30 21:50:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: custom-operators""), Label(name=""module: dispatch"")]"
57380,Asserts all tensor are defined in dispatch wrapper,2021-04-30 19:52:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
57370,gen_proto_typestubs_helper.py is slow,2021-04-30 17:41:15+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
57369,Delay errors of inference tensor to backward pass?,2021-04-30 17:19:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: dispatch""), Label(name=""inference mode"")]"
57359,torch.return_types does not exist,2021-04-30 15:20:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
57358,Missing complex autograd support for some operators,2021-04-30 14:55:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""complex_autograd"")]"
57326,Renaming Autograd dispatch keys to ADCreateGraph,2021-04-30 00:42:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: dispatch"")]"
57313,[jit] pickling custom classes may lead to invalid pickle files,2021-04-29 22:21:03+00:00,,0,2,"[Label(name=""oncall: jit"")]"
57301,Avoid code repeat in create sample inputs for sort/msort,2021-04-29 20:47:03+00:00,,1,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
57278,Attributes consistency in Sampler and DistributedSampler,2021-04-29 14:54:33+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
57272,Consistent treatment of non-differentiability in linear algebra operations,2021-04-29 10:03:49+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
57271,RuntimeError after optimize_for_mobile,2021-04-29 09:49:22+00:00,,0,10,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
57230,Implementation of Self Attention vs Encoder Decoder Attention Causing Early Evaluation for PyTorch/XLA,2021-04-29 02:32:48+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
57185,Segmentation fault with ITIMER_REAL,2021-04-28 20:46:01+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: macos"")]"
57178,MaxPool2D Returns Wrong Shape With Ceil_Mode,2021-04-28 19:35:05+00:00,,0,7,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: pooling"")]"
57163,Segmentation fault when using add_graph from tensorboard in combination with try except in forward pass ,2021-04-28 17:48:44+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
57158,Increasing RTT when using rpc_async in a PS architecture setup,2021-04-28 17:04:46+00:00,,1,7,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
57157,Using register_full_backward_hook with target module for intermediate activation,2021-04-28 17:03:36+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
57136,Intermittent segmentation fault when using rpc_async/rpc_sync with CUDA tensors,2021-04-28 15:06:00+00:00,,1,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
57128,test_eig_with_eigvec_cuda_float64 is flaky on ROCm,2021-04-28 14:29:23+00:00,,0,1,"[Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
57124,Allow `ScriptFunction`s to be symbolically traced,2021-04-28 12:55:24+00:00,,1,1,"[Label(name=""triaged""), Label(name=""FX-TorchScript Compatibility""), Label(name=""module: fx"")]"
57123,LibTorch ships with two identical library files: libdnnl and libmlkdnn,2021-04-28 12:55:21+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
57121,"einsum ""jk,ijkl->il"" is ~16x slower than numpy",2021-04-28 12:28:23+00:00,,0,15,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: linear algebra"")]"
57118,How to view VLOG information,2021-04-28 11:16:12+00:00,,0,7,"[Label(name=""module: logging""), Label(name=""triaged"")]"
57117,MultiheadAttention.out_proj.weight is not explicitly initialized,2021-04-28 10:53:38+00:00,,0,0,"[Label(name=""oncall: transformer/mha"")]"
57112,:attr: does not behave as expected.,2021-04-28 09:39:40+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
57108,Compilation failure in caffe2/core/plan_executor_test.cc with GCC 5.4,2021-04-28 08:04:40+00:00,,0,2,"[Label(name=""module: build""), Label(name=""caffe2""), Label(name=""triaged"")]"
57095,[FR] unflatten support empty shape if unflattened dim has size 1,2021-04-28 05:21:13+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
57065,Static Linking Pytorch,2021-04-27 21:38:28+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: static linking"")]"
57059,Get rid of weak_intrusive_ptr,2021-04-27 20:35:54+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged"")]"
57035,`typing.List` need to be on the same line as the variable declaration?,2021-04-27 16:49:17+00:00,,1,0,"[Label(name=""oncall: jit"")]"
57018,Attempting to concatenate scalar tensors throws a runtime error,2021-04-27 14:46:14+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
57005,about torch install,2021-04-27 10:48:38+00:00,,0,1,"[Label(name=""triaged"")]"
56979,"apex-0.1-py3.6-linux-x86_64.egg/apex/amp/wrap.py"", line 28, in wrapper     return orig_fn(*new_args, **kwargs) RuntimeError: CUDA error: an illegal memory access was encountered",2021-04-27 03:09:02+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
56978,Do padding of weight and activation tensors to match optimized backend implementation,2021-04-27 03:06:02+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
56975,scatter does not accept scalar src=,2021-04-27 02:21:25+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: scatter & gather ops"")]"
56969,[JIT / NNC] Incomplete Ops Coverage,2021-04-26 23:41:51+00:00,,0,5,"[Label(name=""oncall: jit"")]"
56938,remove the dependence on node names in fx graph mode quant ,2021-04-26 18:38:31+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
56928,torch-1.8.1 wheel verification fails with distlib,2021-04-26 17:52:39+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged"")]"
56926,CUDA 11 tracking issue,2021-04-26 17:24:26+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""tracker"")]"
56921,torch.multiprocessing implement SyncManager,2021-04-26 15:25:35+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
56901,Static prebuilt libraries contain shared libraries,2021-04-26 07:07:54+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: static linking"")]"
56896,masked_select is x3 slower than reshaping and index_select,2021-04-26 03:00:30+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""module: viewing and reshaping"")]"
56891,Batched SVD_LOWRANK being much slower than loop implementation (both CPU and GPU) ,2021-04-25 18:29:25+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
56881,[FR] integral discrete distributions should support dtype=int64,2021-04-25 07:34:24+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""enhancement"")]"
56862,Non-symbolic FX tracer,2021-04-24 14:16:50+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: fx"")]"
56843,Add clipnorm parameter to optimizers,2021-04-24 00:43:47+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
56838,Comprehensively test NCCL's `get_future()` API,2021-04-23 23:07:39+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup"")]"
56836,Remove single device constraint from ProcessGroupNCCL profiling ,2021-04-23 22:59:20+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup""), Label(name=""module: c10d"")]"
56809,Autograd engine worker thread initialization fails with python 3.9 debug build,2021-04-23 19:30:00+00:00,,0,3,"[Label(name=""triaged"")]"
56805,Implement random SeedSequence,2021-04-23 18:55:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: random"")]"
56794,No tensor operations allowed inside at::parallel_for,2021-04-23 17:55:24+00:00,,1,5,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
56781,Named Tensors in C++ Is Undocumented,2021-04-23 14:53:54+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: named tensor"")]"
56778,can't find user's fuser method in quantization.fx.fusion_patterns.py when run fx graph qat.,2021-04-23 14:09:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
56777,Error when building PyTorch from source in CentOS Linux 7,2021-04-23 13:36:28+00:00,,0,8,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: tensorpipe"")]"
56774,Support `expand_dims`,2021-04-23 10:06:03+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: python array api"")]"
56772,The multi-fc losses calculating in DistributedDataParallel.,2021-04-23 09:10:19+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
56771,Problems with initial communication between GPUs,2021-04-23 08:47:24+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
56764,Change make_reduction to reflect input resizing.,2021-04-23 05:29:08+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: reductions"")]"
56747,Matrix multiplication broken on PyTorch 1.8.1 with CUDA 11.1 and Nvidia GTX 1080 Ti,2021-04-22 23:17:56+00:00,,0,20,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: cublas"")]"
56710,Hard fail build when there is no CUDA but `USE_CUDA=1`,2021-04-22 17:40:14+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
56707,[TorchScript JIT] `dtype` propagation pass (meta-issue),2021-04-22 16:28:23+00:00,,1,0,"[Label(name=""triaged"")]"
56703,[Pytorch Mobile] Error running build_pytorch_android.sh,2021-04-22 15:33:19+00:00,,1,4,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
56698,Convolution2D may have a numerical error.,2021-04-22 14:46:32+00:00,,0,3,"[Label(name=""module: numerical-stability""), Label(name=""triaged"")]"
56697,Avoid no-op suggest_memory_format call in SparseCsrTensorImpl::resize_as_sparse_csr_tensor_,2021-04-22 14:25:28+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""open source""), Label(name=""better-engineering"")]"
56694,PyTorch 1.8.0 / 1.8.1 CUDA memory corruption on oddly sized tesnor sections of strided tensor,2021-04-22 14:08:24+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
56691,[structured] at::cpu_unchecked functions,2021-04-22 13:59:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: structured kernels"")]"
56688,Torch FX does not work with torchvision model,2021-04-22 11:07:39+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
56678,Segmentation fault on Pytorch 1.8.1 + cuda 11.1 on  GTX 1050 Ti ,2021-04-22 07:28:57+00:00,,1,4,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged"")]"
56671,{h / v / d}split methods are missing,2021-04-22 05:59:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
56660,consistency jit tests gives error for gradient operator,2021-04-22 02:44:39+00:00,,0,8,"[Label(name=""oncall: jit"")]"
56634,[package] Module name reported in error message does not always match what is needed to extern/mock it,2021-04-21 21:41:20+00:00,,0,0,"[Label(name=""triaged"")]"
56623,new torch.profiler slow for large number of events?,2021-04-21 20:46:58+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
56595,"TorchScript breaks (""internal assert failed"") on `torch.set_grad_enabled`",2021-04-21 17:20:45+00:00,,1,3,"[Label(name=""oncall: jit"")]"
56586,"Support multi-dim reductions for torch.prod, torch.all, torch.any",2021-04-21 14:47:02+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: reductions"")]"
56583,"All thread stack trace dumps interleave output in distributed tests, giving garbled output",2021-04-21 14:40:06+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
56571,Python static variable access for TorchScript's custom C++ classes,2021-04-21 07:50:08+00:00,,2,1,"[Label(name=""oncall: jit"")]"
56542,CrossEntropyLoss target shape expectation is inconsistent with BCEWithLogits,2021-04-20 21:49:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: shape checking"")]"
56525,Can't deepcopy memory format objects,2021-04-20 19:52:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
56522,[cpp op] TORCH_LIBRARY schema doesn't respect keyword only,2021-04-20 19:38:56+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""module: cpp""), Label(name=""triaged"")]"
56500,Marking variable not required in backward calculation if it is not needed,2021-04-20 17:49:45+00:00,,0,13,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
56489,[torchdeploy] ar: _bz2module.o: No such file or directory ,2021-04-20 16:29:19+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: deploy"")]"
56485, Sparse tensor CSR layout for CUDA,2021-04-20 15:29:06+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
56483,Add compute_residuals flag for torch.linalg.lstsq,2021-04-20 15:01:19+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: linear algebra"")]"
56482,unsafe_reclaim_from_nonowning is not that unsafe,2021-04-20 14:36:25+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
56480,shared torch.tensor with multiprocesses using python Queue cause coredump ,2021-04-20 13:49:51+00:00,,0,4,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""shadow review"")]"
56465,Provide a pkg-config file,2021-04-20 11:24:53+00:00,,0,0,"[Label(name=""module: build""), Label(name=""feature""), Label(name=""triaged"")]"
56464,Scatter tests missing when passing a reduction operation.,2021-04-20 10:31:20+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
56460,"I meet an error assert key in deserialized_objects when I torch.load(pthname),and pth file is trained on multi gpu",2021-04-20 08:32:57+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: ddp"")]"
56440,Raise exception when torch.clamp min value underflows the input tensor's dtype,2021-04-20 02:03:37+00:00,,0,3,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
56417,Building with USE_TENSORPIPE=0 causes errors on import torch for MacOS,2021-04-19 21:11:09+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: tensorpipe"")]"
56399,Figure out what mojo FB common/process/StackTrace.h has that we don't,2021-04-19 19:19:03+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""better-engineering"")]"
56397,Symbolicate crashes from releases,2021-04-19 18:48:29+00:00,,0,0,"[Label(name=""triaged"")]"
56396,Tests in CI are run from the test/ directory,2021-04-19 18:48:26+00:00,,1,2,"[Label(name=""module: docs""), Label(name=""module: tests""), Label(name=""triaged"")]"
56390,Distributed tests don't always check the exit code of worker processes,2021-04-19 18:22:48+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""module: flaky-tests""), Label(name=""module: ddp"")]"
56370,"Acquiring ""is_grad_enabled()"" inside an autograd function ",2021-04-19 11:11:59+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: custom-operators""), Label(name=""actionable"")]"
56360,Support for stereo audio data in from torch.utils.tensorboard.SummaryWriter,2021-04-19 07:50:15+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: tensorboard""), Label(name=""module: data"")]"
56357,[NNC] All NNC APIs should return bool flag,2021-04-19 06:58:31+00:00,,1,0,"[Label(name=""NNC"")]"
56356,"Resolved: Only add type promotion support to unary pwise, binary pwise, and reduction operations",2021-04-19 06:43:08+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: ux"")]"
56350,logcumsumexp (and maybe other cum* ops) has divergent CUDA and CPU out= behavior,2021-04-19 05:06:58+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: safe resize"")]"
56340,log_softmax(x) != x - logsumexp(x),2021-04-18 13:52:52+00:00,,0,2,"[Label(name=""module: numerical-stability""), Label(name=""triaged"")]"
56333,Unable to pip install PyTorch on M1 Mac - Errors,2021-04-18 00:15:45+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: arm"")]"
56330,Type checking doesn't match actual type in error message,2021-04-17 13:26:46+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
56329,Change `other` to `src` in torch.Tensor.scatter_add_,2021-04-17 09:33:08+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
56328,Why does output_padding have constraints in ConvTranspose1d?,2021-04-17 09:26:22+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
56314,test_variant_consistency_jit fails for torch.tensordot with dtype float32 with error INTERNAL ASSERT FAILED,2021-04-17 00:54:43+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: tests"")]"
56300,torch.where with input Tensor and other Scalar raises type mismatch error,2021-04-16 21:34:14+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: type promotion"")]"
56297,Audit destructors of classes bound using pybind11::class_ to see if they can block; such cases can deadlock,2021-04-16 20:57:38+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: pybind"")]"
56285,qnnpack uses deprecated pthreadpool APIs,2021-04-16 18:34:23+00:00,,0,0,"[Label(name=""triaged"")]"
56275,cumprod gradgradcheck fails in fast_mode=True,2021-04-16 16:14:41+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged"")]"
56263,Reflect padding_mode should be supported for Conv3d,2021-04-16 12:27:27+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: convolution""), Label(name=""triaged"")]"
56262,torch.nn.quantized.functional.conv_transpose1d/2d/3d support,2021-04-16 11:47:46+00:00,,1,2,"[Label(name=""module: docs""), Label(name=""oncall: quantization""), Label(name=""feature""), Label(name=""low priority""), Label(name=""triaged"")]"
56246,Silent incorrect running with zero padding for Conv1d,2021-04-16 09:48:13+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: padding"")]"
56244,Cuda RPC error when using then(),2021-04-16 08:34:10+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""module: tensorpipe"")]"
56237,optim.Adadelta: local variable 'lr' referenced before assignment,2021-04-16 06:21:31+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
56235,`test_cholesky_solve` gradgradcheck fails sometimes,2021-04-16 05:19:58+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: magma"")]"
56231,Half precision support for torch.sparse.mm,2021-04-16 04:33:30+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: half"")]"
56224,Error message regarding Padding of Conv2d needs improving,2021-04-16 02:55:21+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: padding"")]"
56202,Tolerance for non-determinism operators in gradcheck,2021-04-15 22:17:44+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: determinism"")]"
56191,[FX] Issues with names of functions in user packages,2021-04-15 21:09:07+00:00,,1,0,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: fx"")]"
56187,AVX512 and Vec512,2021-04-15 20:41:57+00:00,,0,94,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: vectorization"")]"
56183,"scripting LSTM module generates a script that has no .code, no .graph, and cannot be executed. ",2021-04-15 19:51:53+00:00,,1,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
56177,torch.gradient  not throwing error when spacing to be equal to 0,2021-04-15 18:43:40+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""low priority""), Label(name=""triaged"")]"
56161,"[rfc] Add a ""core only"" build flag",2021-04-15 17:54:24+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering"")]"
56159,Addition/subtraction/multiplication/division of bool variables are not supported in JIT,2021-04-15 17:29:31+00:00,,1,1,"[Label(name=""oncall: jit"")]"
56144,libtorch static linking results in undefined references to onnx_torch and caffe2::EmbeddingLookup,2021-04-15 13:56:50+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: undefined reference"")]"
56136,"Please add a tab of ""all"" packages in `Docs` option",2021-04-15 09:55:39+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
56127,torch.profiler does not work out of the box on nightly,2021-04-15 07:30:04+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
56126,AttributeError: module 'torch._C' has no attribute 'ComplexDoubleStorageBase',2021-04-15 07:15:52+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
56111,ProcessGroupGlooTest and other distributed tests don't capture stdout/stderr in test UI view,2021-04-15 03:14:12+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
56110,caffe2/utils/signal_handler.cc is failing to symbolize libtorch_cpu.so,2021-04-15 03:08:17+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
56100,[package] implicit externing can miss cases where the stdlib depends on further stdlib modules,2021-04-15 00:07:53+00:00,,0,3,"[Label(name=""triaged"")]"
56096,[JIT] Merge/reconcile `__jit_unused_properties` and `__jit_ignored_attributes__`,2021-04-14 23:39:15+00:00,,1,1,"[Label(name=""oncall: jit"")]"
56090,Converting float16->bool causes an internal compiler error with llvm,2021-04-14 23:04:03+00:00,,1,1,"[Label(name=""NNC"")]"
56067,A more flexible torch.hub search strategy,2021-04-14 21:22:38+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: hub"")]"
56064,Optionally include padding_idx items in the EmbeddingBag reduction,2021-04-14 20:59:48+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: embedding"")]"
56038,[Meta] PyTorch features build/test matrix,2021-04-14 18:05:23+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged"")]"
56030,Add Dirichlet Multinomial to PyTorch Distributions,2021-04-14 16:04:59+00:00,,0,3,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""function request"")]"
56027,Add an extensibility point for ThreadLocalState,2021-04-14 15:58:38+00:00,,0,3,"[Label(name=""triaged""), Label(name=""function request"")]"
56024,Support for mkldnn + ddp,2021-04-14 15:46:03+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: mkldnn"")]"
56023,[Opinfo] Better ErrorMsg for test_out with wrong shape,2021-04-14 15:39:22+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
56019,when building apk with libtorch,2021-04-14 15:14:48+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
56012,Failure in complex CUDA numerics tests for sigmoid,2021-04-14 12:06:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex"")]"
56010,[tensorboard] Expected data-type of images in tensorboard SummaryWriter,2021-04-14 11:34:15+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
56008,Segmentation fault when using torch.profiler,2021-04-14 10:07:36+00:00,,1,6,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
56007,NNAPI support for torch.cat([...]) when dim=-1,2021-04-14 10:02:23+00:00,,0,0,"[Label(name=""enhancement""), Label(name=""oncall: mobile"")]"
56006,Unable to get a Vulkan tensor using `to('vulkan')`,2021-04-14 09:21:56+00:00,,0,1,"[Label(name=""oncall: mobile""), Label(name=""module: vulkan"")]"
55999,[JIT][ProfilingExecutor] A reliable and consistent API/protocol to query & propagate profiling data,2021-04-14 07:04:41+00:00,,1,1,"[Label(name=""oncall: jit"")]"
55981,"LazyEmbedding, an embedding layer with a dynamically sized vocabulary",2021-04-14 01:40:36+00:00,,0,13,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: embedding"")]"
55967,"Cannot init, destroy, and then re-init process groups",2021-04-13 22:37:53+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
55964,Finish deprecating torch.range,2021-04-13 22:17:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: deprecation"")]"
55953,Deprecations tracking issue,2021-04-13 20:46:00+00:00,,1,2,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""tracker"")]"
55952,Compiler warnings tracking,2021-04-13 20:41:59+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: build warnings"")]"
55951,Update linspace and logspace to throw an error when steps is not provided,2021-04-13 20:40:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: tensor creation"")]"
55948,Deprecate torch.stft returning real-valued tensors and torch.istft accepting real-valued inputs,2021-04-13 20:31:09+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: fft"")]"
55945,Quantizable LSTMCell does not work correctly.,2021-04-13 19:58:01+00:00,,1,7,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
55944,Sparse-sparse matrix multiplication only works with torch.sparse.mm(),2021-04-13 19:54:49+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: ux"")]"
55941,[Tracking] Remove unneeded BC duplicates from native_functions.yaml,2021-04-13 19:03:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
55937,test_stream_event_nogil: Is the test making a wrong assumption?,2021-04-13 18:31:11+00:00,,0,4,"[Label(name=""in progress""), Label(name=""module: rocm""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""actionable"")]"
55933,[NNC] Replace ComputeAt,2021-04-13 17:53:42+00:00,,1,18,"[Label(name=""NNC"")]"
55912,Support float_qparams in quantized_clone,2021-04-13 15:37:21+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
55910,Allow variable intermediate hidden dimensions for stacked RNN/LSTM layers,2021-04-13 15:11:33+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""enhancement"")]"
55907,test_variant_consistency_eager_addbmm fails on both cpu and cuda,2021-04-13 14:55:21+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
55905,Attempt to use jited `torch.isnan` hit internal assert,2021-04-13 14:18:49+00:00,,1,5,"[Label(name=""oncall: jit""), Label(name=""module: crash""), Label(name=""module: ci"")]"
55902,Warn users when cross entropy is called after softmax,2021-04-13 13:48:28+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
55898,How should I warmup JIT properly ?,2021-04-13 13:14:14+00:00,,1,2,"[Label(name=""oncall: jit"")]"
55884,[Bug] RuntimeError: could not create a primitive on Xeon,2021-04-13 06:36:10+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: backend""), Label(name=""module: intel"")]"
55879,Vulkan backend on desktop platforms,2021-04-13 05:11:57+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: backend""), Label(name=""module: vulkan"")]"
55876,[rfc] Trigger callback when backwards begins for DDP with custom autograd function,2021-04-13 04:33:29+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
55869,We should perhaps prevent linking against LibTorch DLLs with the wrong configuration (debug vs release),2021-04-13 03:02:09+00:00,,0,4,"[Label(name=""module: windows""), Label(name=""triaged"")]"
55865,Don't define __assert_fail on systems using `musl-dev` headers,2021-04-13 02:09:59+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
55804,Add torch.nn.Conv2D correctness test,2021-04-12 17:19:11+00:00,,1,1,"[Label(name=""module: nn""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""enhancement"")]"
55790,Update contributing.md docs review guidelines,2021-04-12 15:45:15+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
55784,pybind11 Tensor type caster forces reference count bump,2021-04-12 14:25:51+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: pybind"")]"
55782,YoloV4 Pytorch model inference fails on NNAPI Android,2021-04-12 12:45:44+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
55779,Request setNumThreads API for Java,2021-04-12 09:10:17+00:00,,0,0,"[Label(name=""enhancement""), Label(name=""oncall: mobile"")]"
55777,torch.load is very slow with gzip.open,2021-04-12 08:52:13+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""has workaround"")]"
55764,clang format on OS X ssl verification failure,2021-04-12 00:52:35+00:00,,0,0,"[Label(name=""module: lint""), Label(name=""triaged"")]"
55757,Synchronize RRef.to_here() CUDA Streams properly when the profiler is enabled,2021-04-11 20:52:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
55756,Cuda OOM after several steps for DataParallel model,2021-04-11 19:16:53+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
55755,"Some float16 inputs to CPU matmul are supported, others aren't",2021-04-11 16:57:32+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: half""), Label(name=""module: linear algebra"")]"
55752,"[question] Influence of divisibility of B, C, T by 16 on Conv1d (and Conv2d perf) with CuDNN, including presence of padding",2021-04-11 15:24:29+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: docs""), Label(name=""triaged"")]"
55751,[docs] algolia docsearch in pytorch docs,2021-04-11 12:23:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: doc infra"")]"
55749,Fail to introduce torch::jit::Module as a parameter of a cusomized operator.,2021-04-11 09:39:15+00:00,,0,3,"[Label(name=""oncall: jit"")]"
55742,[JIT] TorchScript to represent typed tensor annotations in IR graph,2021-04-10 20:12:35+00:00,,1,5,"[Label(name=""oncall: jit"")]"
55736,RuntimeError: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasCreate(handle)`,2021-04-10 08:16:35+00:00,,0,11,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
55696,[TensorExpr] IRSimplifier fails to optimize useless stores,2021-04-09 18:29:25+00:00,,0,0,"[Label(name=""NNC"")]"
55694,symbolic tracing does not support patterns with multiple arguments?,2021-04-09 17:59:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
55669,Segmentation fault when loss.backward(),2021-04-09 10:33:20+00:00,,0,5,"[Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged"")]"
55668,GraphModule.to_folder generates code with syntax error (imports in the middle of a class) [torch.fx],2021-04-09 09:28:39+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: fx"")]"
55663,torch.nn.functional.log_softmax on Arm CPU gives partly NaN results,2021-04-09 07:48:46+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: arm"")]"
55661,"RuntimeError: ""max_cuda"" not implemented for 'ComplexFloat'",2021-04-09 07:33:20+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""enhancement"")]"
55655,Performance debugging / warning mode,2021-04-09 03:10:05+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""enhancement"")]"
55643,at::globalContext().hasCUDA()'s forked tongue tells lies,2021-04-08 21:39:18+00:00,,0,2,"[Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
55629,torch.arctanh not implemented for torch.float16,2021-04-08 18:25:41+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: half"")]"
55611,ATen/native/sparse headers not in LibTorch or pypi package,2021-04-08 14:11:29+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
55609,requires_grad does not get propagated properly when using the JIT compiler,2021-04-08 13:35:03+00:00,,1,8,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
55607,pytorch inference lead to memory leak in cpu,2021-04-08 12:08:04+00:00,,0,4,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
55603,Faster Inference time for first .pt model prediction,2021-04-08 08:39:20+00:00,,1,8,"[Label(name=""oncall: jit"")]"
55597,[ONNX] Incorrect handling of tuple multiplication with zero,2021-04-08 06:16:02+00:00,,0,4,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
55585,"[amp scaler] unable to prevent ""scheduler before optimizer step"" warning",2021-04-08 03:18:23+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
55583,Improve test runtime of distributed tests.,2021-04-08 02:54:06+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
55577,Source location range issue for dictionary ,2021-04-08 00:34:33+00:00,,1,29,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""good first issue""), Label(name=""OSS contribution wanted"")]"
55571,Update TCPStore.wait() error message to be more friendly,2021-04-07 23:20:46+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
55557,Gradcheck failure for `torchaudio.functional.phase_vocoder`,2021-04-07 20:42:51+00:00,,1,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
55549,`embedding_bag` has unexpected behavior when given `offsets` that are not monotonically increasing,2021-04-07 19:55:19+00:00,,1,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: embedding"")]"
55544,[FX] See if we can type-annotate attribute accesses on proxy,2021-04-07 19:44:08+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
55541,`torch.jit.interface` does not understand dunder methods (e.g. `__call__`),2021-04-07 19:39:02+00:00,,1,1,"[Label(name=""oncall: jit"")]"
55464,Support quantized functional linear/conv operators with 32b output,2021-04-07 15:46:10+00:00,,0,4,"[Label(name=""oncall: quantization""), Label(name=""feature""), Label(name=""low priority""), Label(name=""triaged"")]"
55461,Cross-compiling for cortexa9 processor,2021-04-07 14:54:33+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
55457,[feature request] TupleSequential module or an option for Sequential for unpacking tuples (i.e. support varargs),2021-04-07 13:19:09+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged"")]"
55454,Include the cuda headers in the libtorch pre-built packages,2021-04-07 10:50:45+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
55453,C++ sparse_coo_tensor ignores TensorOptions argument,2021-04-07 10:38:27+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
55450,[DOC] Incorrect image for the confusion matrix,2021-04-07 07:54:34+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: rnn""), Label(name=""triaged"")]"
55448,"Errors occur when operating broadcast with error log: Got completion with error 12, opcode 1, len 32547, vendor err 129",2021-04-07 06:48:02+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
55442,More AVX2 vectorization support for half (float16),2021-04-07 04:57:32+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: vectorization""), Label(name=""module: half"")]"
55440,Have the ability to disable `__torch_function__` dispatch for torch.nn.functional functions,2021-04-07 03:07:56+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
55437,Error building docker image: No module named 'typing_extensions',2021-04-07 00:34:19+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: docker"")]"
55401,[FX][testing] Add symbolic tracing tests for torchaudio,2021-04-06 18:17:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
55400,[FX][testing] Add symbolic tracing tests for torchtext,2021-04-06 18:16:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
55399,[FX][testing] Test symbolic tracing of detectron2,2021-04-06 18:13:34+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
55397,[FX][testing] Run symbolic tracing tests over torch benchmark in CI,2021-04-06 18:07:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
55395,[FX][testing] Test tracing into all the standard `torch.nn.functional` instances,2021-04-06 17:59:09+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
55394,[FX][testing] Test tracing into all the standard `nn.Module` instances,2021-04-06 17:58:00+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
55375,`DataParallel` (`broadcast_coalesced`) with complex tensors yield real views,2021-04-06 13:32:17+00:00,,0,11,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: data parallel"")]"
55374,[RFC] Extend Autocast to CPU/CUDA with BF16 data type,2021-04-06 12:12:38+00:00,,0,39,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: bfloat16""), Label(name=""module: amp (automated mixed precision)"")]"
55366,bool_tensor.sum(dtype=torch.int32) creates int32-copy of the original int8 tensor ,2021-04-06 10:00:00+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: boolean tensor""), Label(name=""module: reductions"")]"
55363,it is lack of compatibility of CUDA_HOME (or other env),2021-04-06 09:17:44+00:00,,0,5,"[Label(name=""module: cpp-extensions""), Label(name=""module: cuda""), Label(name=""triaged"")]"
55356,torch.allclose does not allow different types for comparison,2021-04-06 05:42:05+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: type promotion"")]"
55355,simple matrix multiplication yields wrong result on Ampere (3080),2021-04-06 04:18:53+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: cublas""), Label(name=""module: correctness (silent)""), Label(name=""module: tf32"")]"
55340,[RFC] Plan to deduplicate test_c10d and distributed_test ,2021-04-05 22:42:11+00:00,,1,6,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering"")]"
55331,Tests should be runnable without run_test.py,2021-04-05 21:49:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: testing"")]"
55330,CI not surfacing some failures (-Werror?) on PR,2021-04-05 21:42:16+00:00,,0,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
55329,Split test/cpp_extensions/setup.py per orthogonal extension module and/or do Python build from ninja too,2021-04-05 21:36:23+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
55304,nn.DataParallel should raise error when provided with list of tensors,2021-04-05 15:24:37+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
55299,[feature] `torch.polygamma` : Support Tensor for argument `n`,2021-04-05 10:29:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: special"")]"
55297,SIGSEGV at at::is_vulkan_available() invocation on Android,2021-04-05 06:54:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: android"")]"
55296,Build errors with USE_VULKAN=ON when cross-compiling for Android,2021-04-05 06:38:58+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: android"")]"
55289,Feature Request: Add a rounding mode to round,2021-04-04 17:22:32+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
55286,endpoint=False for torch.linspace and torch.logspace,2021-04-04 14:15:01+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: tensor creation"")]"
55282,Poor error message when trying to jit a function instead of a module (RuntimeError: Cannot insert a Tensor that requires grad as a constant.),2021-04-04 01:13:04+00:00,,1,0,"[Label(name=""oncall: jit"")]"
55279,[Feature Pitch] Full-batch optimization toolkit,2021-04-03 17:41:00+00:00,,0,8,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
55277,Small model occupies too much GPU in CUDA11.1 + Torch1.8.1 but is normal in Torch 1.6 + CUDA10.1,2021-04-03 16:34:50+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
55274,[Feature Request] PowerNorm,2021-04-03 10:20:30+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
55267,Improve CUDA extension building experience,2021-04-03 01:48:36+00:00,,1,26,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
55261,Batched multi_dot / chain_matmul + let it accept a tensor instead of tuple,2021-04-02 22:59:40+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra"")]"
55260,Cuda memory leak check is somehow unstable with repeat_test_for_types,2021-04-02 22:45:01+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: testing"")]"
55230,Profile Optionals and Optional[Tensor] specifically,2021-04-02 16:11:19+00:00,,0,7,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
55228,Requesting a feature to calculate attention weights.,2021-04-02 15:04:58+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
55211,[TorchScript] Can we support type refinement by Python type annotation?,2021-04-02 04:38:49+00:00,,1,3,"[Label(name=""oncall: jit"")]"
55207,[RFC] Model Sharding for distributed training,2021-04-02 03:33:51+00:00,,0,17,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
55198,[FX] to_folder breaks with qualified type name,2021-04-02 01:01:38+00:00,,1,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: fx"")]"
55194,Tracing `len(tensor)` gets static constant value in result graph,2021-04-02 00:03:04+00:00,,0,0,"[Label(name=""oncall: jit"")]"
55192,"Consider adding meta:1, meta:2 devices",2021-04-01 23:39:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: structured kernels""), Label(name=""module: meta tensors"")]"
55191,"`torch.tensor(..., device='meta')` doesn't work",2021-04-01 23:38:05+00:00,,0,5,"[Label(name=""module: bootcamp""), Label(name=""triaged"")]"
55174,Isolate CPU tests from GPU tests,2021-04-01 21:05:58+00:00,,0,7,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""actionable"")]"
55161,Internal assert failed: `iter.device(arg).is_cuda()`,2021-04-01 17:13:45+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
55159,Better syntax for OpInfo,2021-04-01 16:40:02+00:00,,0,4,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
55156,multiprocessing function cannot pass cuda objects use when calling inside from a DDP process,2021-04-01 16:21:19+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
55152,Better handling of OpInfo.sample_inputs,2021-04-01 15:42:10+00:00,,0,7,"[Label(name=""high priority""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""needs design""), Label(name=""ezyang's list"")]"
55144,Parameterless model still has extra inputs when exported to ONNX + insufficient checking of argument export_params,2021-04-01 12:50:45+00:00,,0,9,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
55143,Add suport to torch.gather for negative indices,2021-04-01 12:37:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: advanced indexing"")]"
55135,LR scheduler step() behaviour with and without epoch parameter ,2021-04-01 08:11:57+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
55122,Cusolver handle may decrease MAGMA performance on GPU,2021-04-01 02:45:10+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: magma"")]"
55120,Why isn't pip finding the correct pytorch dependency?,2021-04-01 01:25:59+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
55104,Alternative backend fallback like mechanism which has higher precedence than operator-specific composite implementations,2021-03-31 20:45:54+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
55095,Python dispatch key and backend fallback,2021-03-31 19:51:48+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
55093,Make it possible to skip only one hop of __torch_function__ override,2021-03-31 19:33:52+00:00,,1,21,"[Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
55083,[JIT][Testing] Split up test_jit.py and test_jit_py3.jit,2021-03-31 18:44:39+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
55072,[JIT][Testing] Replace use of `assertRaisesRegex` with `assertRaisesRegexWithHilight`,2021-03-31 18:30:04+00:00,,0,0,"[Label(name=""oncall: jit"")]"
55056,[FR] Safe softmax,2021-03-31 15:25:59+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
55045,16 bit accumulation for Convolution,2021-03-31 13:36:15+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement"")]"
55037,High CPU using torch.stack/torch.cat on Windows,2021-03-31 09:13:11+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""module: windows""), Label(name=""triaged"")]"
55035,DataLoader performance drop on 4-channel images?,2021-03-31 09:01:41+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
55030,Add Minimal Gated Unit (MGU),2021-03-31 07:42:08+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
55005,[TensorExpr] Provide a safe API to request the N-th loop for a given Buf.,2021-03-30 22:55:22+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""NNC"")]"
54983,Accept objects with `__float__` wherever regular `float`s are accepted,2021-03-30 19:44:51+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: half"")]"
54982,[RFC] A PyTorch Tensor Shape DSL For Symbolic Shape Inference,2021-03-30 19:12:47+00:00,,0,7,"[Label(name=""oncall: jit"")]"
54979,test_quantize_fx.py test_resnet_18_dpp test failure,2021-03-30 18:48:27+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: fx"")]"
54975,CUBLAS_STATUS_EXECUTION_FAILED error on torch >= 1.8.0 and CUDA 11.1,2021-03-30 18:36:12+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
54971,[1.8.x] Build from source with USE_VULKAN fails (requires C++20 instead of C++14),2021-03-30 17:53:25+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
54947,Results surprisingly differ on different backends,2021-03-30 09:15:33+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
54943,Structured kernels have increased TensorIterator overhead.,2021-03-30 07:00:58+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
54942,Optimizations to TORCH_CHECK change inlining behavior.,2021-03-30 07:00:54+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
54941,Regression in Python arg parser performance.,2021-03-30 07:00:51+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
54938,[tests] `cumprod` OpInfo tests take long time to run (around 1min),2021-03-30 06:12:03+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
54937,[JIT] export fast-transformer to TorchScript,2021-03-30 03:35:14+00:00,,0,1,"[Label(name=""oncall: jit"")]"
54913,FX tracer doesn't support returning a new instance of `object` subclass from module forward,2021-03-29 21:08:40+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: fx"")]"
54912,[autocast] DataParallel in a single process - possibly outdated docs,2021-03-29 20:45:22+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
54906,Out variants for Convolution ops,2021-03-29 19:47:51+00:00,,0,6,"[Label(name=""module: convolution""), Label(name=""triaged"")]"
54905,Allow CUDA build without requiring a physical GPU device.,2021-03-29 19:42:45+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
54899,[fx] forward references in annotations do not produce correct source code,2021-03-29 18:40:44+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: fx"")]"
54897,Default generated meta functions for inplace operations don't report errors,2021-03-29 18:31:12+00:00,,0,0,"[Label(name=""triaged"")]"
54881,Often the documentation does not match the actual signature of the function,2021-03-29 16:03:43+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
54874,Get a thread safe copy of torch::nn::Sequential object,2021-03-29 14:03:41+00:00,,0,6,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged"")]"
54871,Not possible to save dataloader in C++,2021-03-29 10:45:14+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
54861,Occured error in loss.backward() when using sparse=True in Embedding layer,2021-03-29 06:19:12+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: embedding"")]"
54843,Inconsistent behaviour with `weight` argument in CrossEntropyLoss and BCEWithLogitsLoss,2021-03-28 08:38:46+00:00,,0,0,"[Label(name=""module: loss""), Label(name=""triaged"")]"
54841,[testing] test_reference_numerics_extremal_clamp_cpu_bfloat16 fails on ci build with GCC5.4 and Python 3.6,2021-03-28 06:26:51+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: bfloat16"")]"
54829,c++ libtorch config mismatch with python version,2021-03-27 14:06:19+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
54827,Import error,2021-03-27 09:50:56+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
54823,"Fixing pytorch distributed training (DDP) code send a SIGKILL signal on its own on most version of pytorch 1.6.0, 1.7.0, 1.7.1?",2021-03-27 03:06:17+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
54821,Decouple TorchScript compiler from operator library,2021-03-27 02:30:20+00:00,,0,3,"[Label(name=""oncall: jit"")]"
54816,Per channel weight observer for ConvTranspose,2021-03-27 00:31:12+00:00,,1,12,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
54815,TensorExpr `LoopNest.get_loops_for` misbehaved after loop distribution transformation,2021-03-27 00:19:59+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
54802,[nnc] simplify is sometimes broken after computeAt,2021-03-26 22:19:51+00:00,,0,0,"[Label(name=""NNC"")]"
54800,[package] Detection of dependencies introduced by torch.ops.load_library ,2021-03-26 21:23:50+00:00,,1,1,"[Label(name=""triaged"")]"
54799,"Vertices=torch.matmul(vertices.unsqueeze(0), rotations_init), RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemmStridedBatched in CentOS",2021-03-26 21:21:37+00:00,,0,13,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: numpy"")]"
54785,[FX] Cannot symbolically trace class method,2021-03-26 17:54:44+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
54774,"RuntimeError: ""log2"" ""_vml_cpu"" not implemented for 'Half'",2021-03-26 16:04:49+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: half"")]"
54766,Add `start_dim` and `end_dim` functionality for common reduction operations.,2021-03-26 09:09:42+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: reductions"")]"
54757,[nnc] computeAt and index flatten broken in presence of if statements,2021-03-26 06:14:07+00:00,,0,1,"[Label(name=""NNC"")]"
54753,torch.sqrt for negative values should either return complex tensors or clearly throw a domain error/warning,2021-03-26 05:10:51+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy"")]"
54743,[Feature request] Add batched matrix support for torch.diag,2021-03-26 00:03:14+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: batching""), Label(name=""module: linear algebra"")]"
54728,JIT prim ops v.s. dispatcher,2021-03-25 20:43:42+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""module: dispatch""), Label(name=""oncall: mobile"")]"
54716,Segmentation fault in PyTorch dataloader,2021-03-25 18:44:25+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
54713,Test test_large_cumprod_cuda_float16 gets killed due to (probably) OOM ,2021-03-25 18:36:30+00:00,,0,2,"[Label(name=""module: memory usage""), Label(name=""module: tests""), Label(name=""triaged"")]"
54677,[docs] use sphinx link/reference checking features,2021-03-25 12:28:06+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra""), Label(name=""better-engineering"")]"
54655,qsize not implemented error,2021-03-25 04:23:33+00:00,,0,4,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: macos"")]"
54646,Optional enhanced logging for operator calls for backend implementor debugging,2021-03-25 00:58:34+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: backend"")]"
54638,torch.jit.trace() fails on a GCN with sparse inputs and dense layers,2021-03-25 00:03:12+00:00,,0,0,"[Label(name=""oncall: jit"")]"
54630,torch-tensor-repr gdb macro doesn't seem to work in opt mode,2021-03-24 22:19:22+00:00,,0,5,"[Label(name=""triaged"")]"
54629,"""Skipped!"" tests should have more descriptive skipped reason",2021-03-24 21:29:06+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""enhancement"")]"
54625,"[torchscript] nn.Embedding(_weight), tensor.masked_fill_, and torch.autograd.grad causes wrong gradient",2021-03-24 20:45:07+00:00,,0,1,"[Label(name=""oncall: jit"")]"
54622,torch.pow returns incorrect value for 0^0j,2021-03-24 20:26:21+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy"")]"
54620,"torch.pow(tensor, tensor) throws RuntimeError for dtype bool ",2021-03-24 20:05:41+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
54614,Dispatcher TLS to bypass loads of dispatch key from tensor arguments,2021-03-24 18:50:57+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: dispatch"")]"
54612,Exceptions thrown in JIT interpreter always are translated into RuntimeError,2021-03-24 18:36:59+00:00,,1,6,"[Label(name=""oncall: jit"")]"
54602,if cannot be symbolically traced,2021-03-24 17:20:25+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
54599,Better documentation for `torch.jit.isinstance`,2021-03-24 16:19:38+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""module: docs""), Label(name=""docs-hackathon"")]"
54598,Type refinement with `isinstance` only works with generics,2021-03-24 16:05:05+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""TSRootCause:TypeRefinement"")]"
54593,Multiple refinement with `isinstance` doesn't work,2021-03-24 15:28:14+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""TSRootCause:TypeRefinement"")]"
54591,Various issues in derivatives.yaml,2021-03-24 15:18:38+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
54588,Make searchsorted and bucketize API consistent,2021-03-24 12:48:12+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation""), Label(name=""module: ux"")]"
54578,cublasSgemmStridedBatched failure when calling grad of grad,2021-03-24 07:16:59+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged"")]"
54577,Question when I use Pytorch Mobile,2021-03-24 07:13:57+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""oncall: mobile"")]"
54574,"Add OpInfo metadata for ""is_torch_functional"" and a skip for these ops in TestOperatorSignatures.test_get_torch_func_signature_exhaustive",2021-03-24 05:57:03+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: fx"")]"
54566,Support docstring definition in torch/library.h operator definition,2021-03-24 03:24:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
54564,why single pytorch process is displayed on each GPUs with memory 0MB,2021-03-24 03:06:46+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
54546,Let backends specify a schema version when registering kernels,2021-03-23 21:42:19+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: backend""), Label(name=""module: codegen"")]"
54535,[ROCm] test failures during 4.1 upgrade,2021-03-23 19:59:50+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: dependency bug""), Label(name=""module: rocm""), Label(name=""triaged"")]"
54524,Store created by dist.new_group doesn't appear to respect timeout,2021-03-23 18:07:15+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering"")]"
54503,torch.fx may have problem for annotations,2021-03-23 14:33:38+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
54499,Caught an integer overflow or wraparound in torch.nn.MaxPool1d,2021-03-23 12:32:09+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: pooling"")]"
54497,Caffe2 has undeclared dependencies,2021-03-23 11:44:22+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
54487,"RuntimeError: iter.device(arg).is_cuda() INTERNAL ASSERT FAILED at ""/opt/conda/conda-bld/pytorch_1607370116979/work/aten/src/ATen/native/cuda/Loops.cuh"":94, please report a bug to PyTorch. ",2021-03-23 06:04:25+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: TensorIterator"")]"
54445,add tests to cover DDP on mixed dense-sparse models,2021-03-22 20:21:39+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
54440,BERT model from torchbenchmark fails inference after freezing.,2021-03-22 18:20:56+00:00,,1,0,"[Label(name=""triaged""), Label(name=""jit-backlog"")]"
54435,[JIT] prim::ModuleContainerIndex doesnt work with freezing,2021-03-22 17:25:56+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""days"")]"
54418,Some Numba tests are failing,2021-03-22 14:40:14+00:00,,0,2,"[Label(name=""high priority""), Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: numba"")]"
54408,It is strange that PyTorch is slow on RTX 3090,2021-03-22 09:57:25+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
54407,test_clamp fails on ppc64le,2021-03-22 09:47:15+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: POWER""), Label(name=""NNC"")]"
54394,Half Normal Log_Prob not defined for 0 ,2021-03-21 18:56:20+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: half"")]"
54393,[docs] torch.optim.lr_scheduler,2021-03-21 17:56:51+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
54389,"torch.lerp and torch._foreach_lerp should support uint8 inputs (for vision), int16 (for audio), int32/int64 (for generality)  without (up)casting to float for  and/or dtype argument ",2021-03-21 12:31:57+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: interpolation"")]"
54388,"in WINDOWS, CUDA Out of Memory error but CUDA memory is almost empty",2021-03-21 12:27:16+00:00,,0,2,"[Label(name=""module: windows""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
54387,[docs] torch.lerp has unmatching signature and explained parameter names,2021-03-21 12:24:41+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
54375,[proposal] Integrate autograd graph visualizer for displaying crashed locations during detect_anomaly,2021-03-20 19:59:52+00:00,,0,6,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
54368,RMSProp documentation is confusing,2021-03-20 03:53:07+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
54366,[package] Heuristics for extern-ing common dependencies,2021-03-20 01:06:46+00:00,,0,0,"[Label(name=""triaged"")]"
54365,Support `Generic` Type in TorchScript,2021-03-20 00:53:05+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
54364,[package] Clear and minimal interface for what a package provides,2021-03-20 00:52:50+00:00,,0,0,"[Label(name=""triaged"")]"
54362,[package] Buck integration for dependency analysis,2021-03-20 00:14:53+00:00,,0,0,"[Label(name=""triaged"")]"
54356,Generate delegates for all non-structured kernels,2021-03-19 22:26:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
54351,Numpy.float64 vs native python float breaks DDP,2021-03-19 20:53:18+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: ddp"")]"
54348,[JIT] TorchScript does not correctly handle `torch.` namespace functions called with `kwargs`,2021-03-19 20:06:21+00:00,,1,5,"[Label(name=""oncall: jit""), Label(name=""days"")]"
54346,Missing tests for gradcheck,2021-03-19 19:48:47+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged"")]"
54340,RuntimeError: polar does not support automatic differentiation for outputs with complex dtype.,2021-03-19 17:42:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""complex_autograd"")]"
54332,Unit testing failures when porting PyTorch wheel,2021-03-19 16:13:42+00:00,,0,19,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
54325,build broken when USE_TENSORPIPE=OFF and USE_DISTRIBUTED=ON,2021-03-19 15:26:01+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: tensorpipe"")]"
54309,[discussion] Support torch.matmul: strided x sparse in addition to sparse x strided,2021-03-19 08:42:38+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
54307,cuDNN error upon the backward method with a sliced tensor output from nn.GRU.,2021-03-19 05:36:13+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: rnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
54283,Split VariableTypeManual.cpp,2021-03-18 22:45:32+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
54282,test_randperm is failing on CPU-only build,2021-03-18 22:44:51+00:00,,0,3,"[Label(name=""module: tests""), Label(name=""triaged"")]"
54279,[Static Runtime] static_runtime_benchmark compile-time error,2021-03-18 22:09:27+00:00,,1,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
54278,[Static Runtime] StaticRuntime.EmbeddingBag test case broken,2021-03-18 22:05:14+00:00,,1,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
54269,SummaryWriter add_image() docs do not state that it is expecting images in a certain format,2021-03-18 19:53:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
54267,"Profiler with Kineto has ""orphan+childless"" function events (on P100)",2021-03-18 18:58:45+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
54232,DistributedDataParallel: `DDP(model)` hangs on non-master node,2021-03-18 02:52:50+00:00,,0,12,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
54216,Add inplace variant for torch.minimum / torch.maximum,2021-03-17 22:04:36+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""function request"")]"
54213,"[docs] torch.clamp / torch.clip do support None as placeholder of min/max, but this is not documented",2021-03-17 21:36:34+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
54209,[docs] Incomplete examples for torch.Generator,2021-03-17 21:18:52+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
54201,Provide half-away-from-zero rounding mode on Tensor::round,2021-03-17 20:05:00+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""function request"")]"
54192,OSS Mobile Errors Point to fburls,2021-03-17 17:51:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering"")]"
54149,OSS build doesn't hard fail on nodiscard,2021-03-17 14:36:02+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: build warnings""), Label(name=""better-engineering"")]"
54147,Implement Truly Parallel Ensemble Layers,2021-03-17 14:17:11+00:00,,0,10,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: batching"")]"
54146,Conversion of Pytorch model to Torchscript for model LaneATT(Lane Detection),2021-03-17 14:04:42+00:00,,0,1,"[Label(name=""oncall: jit"")]"
54140,[Torchscript] Error detected in torch::jit::(anonymous namespace)::DifferentiableGraphBackward on custom RNN model,2021-03-17 11:30:16+00:00,,1,7,"[Label(name=""oncall: jit"")]"
54139,as_tensor returns CPU copy of a CUDA buffer object implementing CUDA Array Interface,2021-03-17 11:11:38+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: numba"")]"
54138,Support Array Interface (__array_interface__ attribute),2021-03-17 10:39:49+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
54137,Add additive angular margin loss,2021-03-17 10:00:13+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: loss""), Label(name=""triaged"")]"
54135,torch.kron of a transposed input error,2021-03-17 09:35:10+00:00,,0,3,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""function request"")]"
54133,[TorchScript] kind_.is_prim() INTERNAL ASSERT FAILED,2021-03-17 08:27:34+00:00,,1,3,"[Label(name=""oncall: jit"")]"
54116,torch.put is divergent from np.put,2021-03-17 00:21:23+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
54104,TorchVision and TorchAudio wheels for AArch64 absent from https://download.pytorch.org/whl/torch_stable.html,2021-03-16 21:57:50+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: arm"")]"
54096,cdist skip for manual backward is kind of janky,2021-03-16 21:46:47+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""better-engineering""), Label(name=""module: distance functions"")]"
54082,Dispatch table for linalg_norm is fishy,2021-03-16 19:13:14+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""better-engineering""), Label(name=""module: norms and normalization"")]"
54077,[cuda extension] tutorial should mention device guard,2021-03-16 18:22:28+00:00,,0,1,"[Label(name=""module: cpp-extensions""), Label(name=""module: docs""), Label(name=""triaged"")]"
54071,[FX] Add guards in files in `test/fx` to make sure they're not run directly,2021-03-16 17:18:21+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
54062,Many advanced indexing operations have untested large tensor branches,2021-03-16 11:23:06+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
54058,c++ convert from std::vector<Tensor> to c10::List<optional<Tensor>>,2021-03-16 09:48:12+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged"")]"
54055,Wrong initialisation gain for SNNs/SELU,2021-03-16 09:08:41+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: initialization"")]"
54047,RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED in pytorch lightning,2021-03-16 03:25:29+00:00,,0,3,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
54035,Web support?,2021-03-15 22:34:47+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: language binding"")]"
54030,[FR] Configurable gain value for kaiming_normal_ / kaiming_uniform_ in torch.nn.init,2021-03-15 21:21:02+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: initialization"")]"
54021,Support scatter/gather for NCCL backend,2021-03-15 20:10:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: c10d"")]"
54006,enable parallel test execution for GPU tests,2021-03-15 16:08:17+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
54001,[codegen] Change public C++ to accept out/mut arguments by const&,2021-03-15 14:14:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
53983,"hope to support something like  ""torch::manual_seed_for_mulit_thread""",2021-03-14 14:42:49+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random"")]"
53982,[Feature Request] Optionally specify batch dimension in DataLoader and collate_fn,2021-03-14 09:52:26+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
53957,Is pytorch 1.8.0 incompatible with cuda 11.2 or what is the reason for this error?,2021-03-13 06:02:04+00:00,,0,10,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
53952,[Pipe] supporting None and non-Tensors in forward's input/output ,2021-03-13 03:51:50+00:00,,1,16,"[Label(name=""triaged""), Label(name=""pipeline parallelism"")]"
53937,Only tensor can be proxied in builtin operators with `__torch_function__`,2021-03-12 23:11:30+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: __torch_function__""), Label(name=""module: fx"")]"
53935,SubgraphRewriter doesn't handle tensor constants in replacement graph ,2021-03-12 23:10:42+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
53921,[JIT] TorchScript infers incorrect type for `or` in non-boolean context,2021-03-12 20:55:56+00:00,,1,2,"[Label(name=""oncall: jit"")]"
53910,There should be a CI build with OpenBLAS in addition to MKL,2021-03-12 18:12:12+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
53904,[JIT] Support `torch.ones([])`,2021-03-12 16:44:24+00:00,,2,2,"[Label(name=""oncall: jit"")]"
53903,[torch.vmap] Support second order grads,2021-03-12 16:33:02+00:00,,0,14,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: vmap"")]"
53900,Have the possibility to reduce a tensor with median on more than one specified dimension,2021-03-12 16:12:21+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""has workaround""), Label(name=""module: reductions"")]"
53895,"terminate called after throwing an instance of 'c10::Error'   what():  isTuple() INTERNAL ASSERT FAILED at ""/home/wenda/libtorch/include/ATen/core/ivalue_inl.h"":927, please report a bug to PyTorch. Expected Tuple but got GenericList",2021-03-12 14:30:10+00:00,,0,13,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: cpp""), Label(name=""triaged"")]"
53891,Check Archive.org for Failed Dataset Downloads,2021-03-12 12:59:16+00:00,,0,5,"[Label(name=""module: dependency bug""), Label(name=""triaged""), Label(name=""enhancement"")]"
53890,GoogleNet pretrained/scratch bug?,2021-03-12 11:52:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vision"")]"
53879,Linear algebra GPU library function bug tracking issue [magma/cusolver/cublas],2021-03-12 06:12:10+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
53878,[JIT] TorchScript errors out when assigning a value to an existing variable that's defined in outer block,2021-03-12 05:49:22+00:00,,1,1,"[Label(name=""oncall: jit"")]"
53877,[JIT] Bad interaction between if-else-style and assert-style type refinement,2021-03-12 05:37:25+00:00,,1,0,"[Label(name=""oncall: jit"")]"
53867,[JIT][Static Runtime] Memory optimization for output tensors,2021-03-12 02:17:32+00:00,,1,0,"[Label(name=""oncall: jit"")]"
53866,Add comprehensive subgroup testing to torch.distributed,2021-03-12 02:00:49+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""module: ddp"")]"
53862,"After the source code is compiled, an error will be reported fvcore",2021-03-12 01:36:01+00:00,,1,9,"[Label(name=""oncall: jit"")]"
53836,Lowering MHA C++/Python to ATen,2021-03-11 19:04:59+00:00,,0,1,"[Label(name=""triage review""), Label(name=""module: nn""), Label(name=""oncall: transformer/mha"")]"
53824,[JIT] torch.jit.optimized_execution(True) greatly slows down some operations in PyTorch 1.8.0 ,2021-03-11 16:41:53+00:00,,0,1,"[Label(name=""oncall: jit"")]"
53796,foreach ops in autograd ,2021-03-11 06:21:12+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""triaged"")]"
53794,[fx] GraphModule __init__ when provided a Module w/ inconsistent buffer handling,2021-03-11 06:02:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
53785,Support for one-hot of dtypes besides torch.int64,2021-03-11 03:15:37+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
53758,ZeroDivisionError: float division by zero in Adam (bias_correction1 is zero),2021-03-10 22:28:42+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
53753,TorchScript cannot handle declared module attributes of Python types,2021-03-10 21:51:50+00:00,,2,2,"[Label(name=""oncall: jit"")]"
53744,TorchScript divison by zero fails to error out ,2021-03-10 21:14:04+00:00,,1,8,"[Label(name=""oncall: jit"")]"
53732,[FX] Allow customizing code generation for certain Nodes,2021-03-10 19:19:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
53721,PyTorch on Embedded Hardware,2021-03-10 18:00:00+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
53712,Poor support of `Optimizer.add_param_group`,2021-03-10 14:38:24+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
53710,Ninja recompiles certain unchanged source files in cpp extension since torch 1.8.0,2021-03-10 14:15:39+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
53708,torch.load with Exception,2021-03-10 13:23:48+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
53707,[RFC] Add common device runtime abstraction,2021-03-10 10:24:32+00:00,,0,8,"[Label(name=""feature""), Label(name=""triaged"")]"
53704,`test_reductions` ignoring some tests,2021-03-10 09:51:17+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: reductions"")]"
53696,Support GPU/CPU communication in RPC,2021-03-10 08:12:00+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
53678,[FX] Regression from 1.8: FX can no longer trace functions where the first element of an int list is a Proxy,2021-03-10 02:13:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
53666,torch.autograd.functional.jacobian/hessian allow tensor in addition to function,2021-03-09 23:48:41+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
53658,torch.distributed with NCCL can hang if the first operation is a barrier,2021-03-09 22:20:50+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
53649,vmap gradgradcheck test fails for unfold operation,2021-03-09 21:14:21+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: vmap"")]"
53642,torch.unsafe_chunk and torch.unsafe_split 's documentation does not render on the website.,2021-03-09 20:39:56+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
53627,test_metal.py must skip when not compiled with metal support,2021-03-09 18:32:43+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
53625,torch.arange() issue,2021-03-09 18:27:35+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: regression"")]"
53623,test/distributed/test_c10d.py::DistributedDataParallelTest only passes if run before other test cases,2021-03-09 17:27:10+00:00,,1,6,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
53622,Properly design manual_cpp_binding (make it less error prone),2021-03-09 17:23:50+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: language binding"")]"
53584,How to delete Module from GPU? (libtorch C++),2021-03-09 02:55:03+00:00,,0,6,"[Label(name=""module: cpp-extensions""), Label(name=""module: cpp""), Label(name=""triaged"")]"
53534,[FX] Ability to wrap functions in other modules for symbolic tracing,2021-03-08 18:36:48+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: fx"")]"
53510,Improve memory format testing,2021-03-08 16:26:39+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: memory format"")]"
53491,Very slow backward speed when using gather with small-range indices,2021-03-08 04:00:05+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged"")]"
53477,Show methods of the class in the right sidebar,2021-03-07 16:20:56+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
53473,RuntimeError: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasCreate(handle)`,2021-03-07 10:32:07+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
53472,After upgrade to 1.8.0 memory leak in libTorch after using torch::jit::load(),2021-03-07 10:14:22+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""oncall: mobile"")]"
53464,libtorch reports bad_alloc when used together with darknet,2021-03-07 04:29:56+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
53463,[Feature Request] return type support for `torch.norm` and tensor iteration in for loop,2021-03-07 03:11:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
53462,Second order derivatives for F.grid_sample(),2021-03-06 22:45:05+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement"")]"
53451,Model loaded from full model state checkpoint does not run on multiple GPUs (device mismatch),2021-03-06 12:40:50+00:00,,0,9,"[Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""module: serialization"")]"
53442,IRSimplifier performs unsafe transformation on mod: m*n%m -> 0,2021-03-06 06:43:13+00:00,,0,7,"[Label(name=""triaged""), Label(name=""NNC"")]"
53441,"Conjugate gradient Descent, and Linear operator are not present in pytorch.",2021-03-06 05:26:41+00:00,,0,12,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: linear algebra""), Label(name=""complex_autograd""), Label(name=""function request""), Label(name=""module: lazy"")]"
53440,Add complex support for torch.unique,2021-03-06 03:49:24+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy""), Label(name=""complex_autograd""), Label(name=""function request""), Label(name=""module: python array api"")]"
53438,Pipe should automatically build appropriate partitions.,2021-03-06 02:49:46+00:00,,2,1,"[Label(name=""triaged""), Label(name=""pipeline parallelism"")]"
53427,Backward compute time in DDP logging may not be accurate ,2021-03-05 23:54:36+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
53421,[bug][JIT] Error when tracing model with partial hooks in PyTorch v1.8.0,2021-03-05 23:12:51+00:00,,0,5,"[Label(name=""oncall: jit"")]"
53414,[JIT] Metaprogram non-type based expression trees,2021-03-05 22:12:58+00:00,,1,0,"[Label(name=""oncall: jit"")]"
53407,"torch.matmul doesn't handle zero-sized inputs in some cases, leading to batched grad failures",2021-03-05 21:18:49+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: vmap"")]"
53405,When I ran the 'Get Started with Data Data Parallel' tutorial the code got 'RuntimeError '!There are no hints,2021-03-05 20:39:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
53392,[bug] GaussianNLLLoss: Variance not broadcast to input shape,2021-03-05 18:57:11+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
53391,torch.empty_strided doesn't test if strides are negative,2021-03-05 18:56:24+00:00,,0,0,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
53386,Default pytest is truncating stacktrace (somehow!!!),2021-03-05 18:19:19+00:00,,0,2,"[Label(name=""triaged"")]"
53365,Pytorch mobile Vulkan API usage,2021-03-05 15:48:55+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: mobile"")]"
53360,[bug] torch.cumsum: functional and method variant promotes all ints to Long but inplace don't,2021-03-05 14:00:45+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
53358,[bug] torch.cumsum: behaviour for `bool` input,2021-03-05 13:38:46+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: boolean tensor"")]"
53352,OpInfo mechanism to test for nondeterminism,2021-03-05 10:59:17+00:00,,1,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: determinism"")]"
53345,CUDA error: an illegal memory access was encountered when updating model weights using GradScaler,2021-03-05 06:54:30+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
53344,[JIT] raise unittest.SkipTest and self.skipTest cannot be used to skip tests in JitTestCase,2021-03-05 06:28:12+00:00,,0,0,"[Label(name=""oncall: jit"")]"
53337,Should we remind users not to use the dataset  on GPU when it's the argument of DataLoader?,2021-03-05 04:16:25+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
53284,Find a good namespace home for torch._assert_async,2021-03-04 18:57:18+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: testing"")]"
53264,How to load trained . torch from conversion to .mlmodel,2021-03-04 14:27:11+00:00,,0,4,"[Label(name=""oncall: mobile"")]"
53263,Different gradients in torch.matmul depending on input shape,2021-03-04 14:13:05+00:00,,0,9,"[Label(name=""module: numerical-stability""), Label(name=""triaged"")]"
53261,Dimension argument names in torch.diag_embed/diagonal vs. transpose/transpose_,2021-03-04 12:32:44+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy"")]"
53257,Inconsistent `out=` behaviour on advanced indexing operations.,2021-03-04 11:02:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""enhancement""), Label(name=""module: advanced indexing"")]"
53256,`index_copy_`  test fails on PyTorch/XLA,2021-03-04 10:36:48+00:00,,1,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: xla"")]"
53194,Relative performance of histc vs bincount,2021-03-03 18:03:12+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
53193,[nnc] Prevent user from scheduling after prepareForCodegen,2021-03-03 17:44:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""NNC"")]"
53191,RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR,2021-03-03 17:09:43+00:00,,0,6,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
53185,[NIT] Unpickler persistent_load monkey patch should fall back to original persistent_load,2021-03-03 15:14:06+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
53178,Exceedingly different F.conv2d outputs on cuda/cpu,2021-03-03 12:21:45+00:00,,0,9,"[Label(name=""high priority""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
53157,doxygen and pytorch documentation,2021-03-03 01:00:41+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged"")]"
53141,Structured kernels for operators that don't have out= variants,2021-03-02 21:46:46+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: structured kernels"")]"
53140,[JIT] Document __jit_ignored_attributes__,2021-03-02 20:57:53+00:00,,1,0,"[Label(name=""oncall: jit"")]"
53130,Lint rule to forbid bare assert() in cuda,2021-03-02 19:36:22+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: lint""), Label(name=""triaged"")]"
53124,Deprecate and remove torch.set_default_tensor_type,2021-03-02 18:29:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: deprecation"")]"
53121,[fx] Handle models with Optional inputs,2021-03-02 18:12:27+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
53103,ModuleList not recognised as reversible by mypy,2021-03-02 09:32:00+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""module: typing""), Label(name=""triaged"")]"
53095,Reset mask for torch.cumsum?,2021-03-02 07:25:10+00:00,,0,6,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: reductions"")]"
53094,group conv in amp too slower,2021-03-02 07:21:11+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
53090,'Tensor' object has no attribute 'astype',2021-03-02 06:05:08+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
53072,[NNC] Simplify after each transformation,2021-03-02 00:35:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""NNC"")]"
53026,Ensure that nn.MHA and functional multi-head attention is supported by FX graph mode quantization,2021-03-01 17:38:00+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: fx"")]"
53023,[codegen] Make it easier to codegen call to API,2021-03-01 16:41:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: codegen"")]"
53022,[TorchScript Usability] Instance attribute annotation does not seem to take effect,2021-03-01 15:55:19+00:00,,1,0,"[Label(name=""oncall: jit"")]"
53017,[TorchScript Usability] Optional type does not support `x != None`,2021-03-01 15:29:53+00:00,,1,0,"[Label(name=""oncall: jit"")]"
52989,lr_scheduler _triangular2_scale_fn calculation is overflowed,2021-03-01 01:17:58+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
52984,Tracker: pytest-related test improvements,2021-02-28 20:13:26+00:00,,1,12,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""tracker"")]"
52973,Add numerically stable methods to torch.distributions (e.g. logcdf),2021-02-27 17:50:54+00:00,,0,9,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
52970,Wrong link in readme for the android nightly version,2021-02-27 11:45:27+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
52940,[JIT] Provide a way to access a flattened optimized graph from Profiling Executor,2021-02-26 20:20:30+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
52936,profile pure C++ process ,2021-02-26 19:18:45+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: profiler"")]"
52920,[TorchScript Usability]  More intuitive error message when passing wrong types to `torch.jit.script()`,2021-02-26 16:52:56+00:00,,0,1,"[Label(name=""oncall: jit"")]"
52915,Broadcasting behaviour for linear algebra solvers,2021-02-26 14:59:44+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
52914,Export to ONNX with all tensor shapes included,2021-02-26 13:56:22+00:00,,0,10,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
52913,Create a standalone python execution viewer like livepython,2021-02-26 12:18:11+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: logging""), Label(name=""triaged"")]"
52911,LR Scheduler load_state_dict does not properly update scaling,2021-02-26 08:27:27+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
52851,"`embedding_bag(..., include_last_offset=True)` should always error if `offsets[-1] != input.size()`",2021-02-25 18:21:44+00:00,,1,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: embedding"")]"
52850,How to skip the images in a custom dataset and deal with None values?,2021-02-25 18:04:33+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
52845,[feature request] F.interpolate_as,2021-02-25 16:39:57+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request""), Label(name=""module: interpolation"")]"
52821,[nnc] Compute expressions with > 4 axes is pretty tedious,2021-02-25 05:00:04+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
52800,Create CI test checker to ensure # of test ran is the same as # of test reported in xmlrunner,2021-02-25 00:49:56+00:00,,1,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement"")]"
52795, Add format indexed argument support in JIT,2021-02-25 00:14:41+00:00,,1,0,"[Label(name=""oncall: jit"")]"
52788,distributed/optim/test_zero_redundancy_optimizer uses unittest.main() instead of common_utils.run_tests(),2021-02-24 23:08:20+00:00,,1,3,"[Label(name=""oncall: distributed"")]"
52777,[nnc] Placeholder::load braced init list fails to deduce,2021-02-24 22:11:07+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
52772,[nnc] Optimize 1x1 convolutions,2021-02-24 21:57:26+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
52768,[nnc] Optimize tiny convolutions,2021-02-24 21:50:34+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""NNC"")]"
52767,[nnc] Grouped convolutions,2021-02-24 21:43:27+00:00,,1,0,"[Label(name=""triaged""), Label(name=""NNC"")]"
52762,Basic feature missing,2021-02-24 19:07:50+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
52753,Enable support for dynamic shapes,2021-02-24 17:29:57+00:00,,2,1,"[Label(name=""oncall: jit"")]"
52747,[proposal] Make torchvision and other libraries' docs searchable via main docs search,2021-02-24 15:32:38+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
52745,Sort torch.topk() output following input index order,2021-02-24 13:53:38+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement"")]"
52744,Gradient checkpointing support in C++ API,2021-02-24 12:33:35+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""feature""), Label(name=""triaged""), Label(name=""enhancement"")]"
52743,torch.searchsorted issues,2021-02-24 12:26:21+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: sorting and selection"")]"
52741,torch.jit.script is swallowing a rfloordiv warning,2021-02-24 09:57:45+00:00,,1,5,"[Label(name=""oncall: jit"")]"
52738,[OpInfo] Improvements for sparse ops tests,2021-02-24 09:46:16+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""module: tests""), Label(name=""triaged"")]"
52722,Creating torch tensor as a function of index value,2021-02-24 03:55:59+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
52720,[JIT] Finish migrating torch._C._jit_ bindings to torch._C._jit,2021-02-24 03:02:04+00:00,,0,0,"[Label(name=""oncall: jit"")]"
52718,Discrepancy between CPU->GPU and GPU->CPU data transfer speeds,2021-02-24 02:26:28+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
52717,Fix `torch.norm`'s backward to match forward for ord=+/-inf,2021-02-24 01:51:16+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
52712,Refactor `torch.linalg.norm`,2021-02-24 01:35:53+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
52694,[TensorExpr] Loop Transformations: `compute_inline` should use `Let` for inlined expressions,2021-02-23 20:16:30+00:00,,2,0,"[Label(name=""triaged""), Label(name=""NNC"")]"
52688,[BE] Consolidating scripts/ and tools/ folder,2021-02-23 19:08:59+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
52680,Add Quantized{CPU|CUDA} support to Structured Kernels,2021-02-23 17:30:19+00:00,,0,2,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: structured kernels"")]"
52675,[feature request] Introduce TORCH_USE_CUDA=OFF runtime environment variable to faithfully/completely disable cuda (torch.cuda.is_available() <- False and torch.cuda.get_device_count() <- 0) and driver loading/interaction,2021-02-23 15:29:21+00:00,,0,15,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""small"")]"
52673,Add custom types to PyTorch,2021-02-23 14:57:21+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged"")]"
52668,Independent axis support for torch.trace,2021-02-23 13:55:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement"")]"
52666,caffe2 load onnx model error:IndexError: Input 475 is undefined!,2021-02-23 12:43:23+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""caffe2""), Label(name=""triaged"")]"
52663,code linking to libtorch cannot use thrust/cub functions,2021-02-23 09:58:32+00:00,,0,8,"[Label(name=""high priority""), Label(name=""module: cpp""), Label(name=""module: cuda""), Label(name=""triaged"")]"
52655,Optimize `einsum` in TorchScript profile guided optimization,2021-02-23 04:43:00+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""module: linear algebra"")]"
52648,Fix `torch.linalg.vector_norm`'s backward to avoid needing `at::abs()` call in forward for ord=+/-inf ,2021-02-23 01:51:26+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
52644,[FR] torch.load's map_location supports int ,2021-02-23 01:13:45+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
52633,CUDA `linalg.norm` matrix order +/-2 and nuclear norm for extreme values may be incorrect,2021-02-22 22:20:04+00:00,,1,4,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: linear algebra"")]"
52625,Add slicing to distributions,2021-02-22 21:50:25+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""enhancement"")]"
52611,[Profiler] LegacyEvent does not respect device,2021-02-22 19:21:18+00:00,,1,1,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
52607,Enable timed barrier in c10d,2021-02-22 18:44:49+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: c10d"")]"
52605,Torchaudio 0.8.0.dev nightly requires torch 1.9.0.dev which is missing,2021-02-22 17:50:06+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
52599,torch::jit::Node::isNondeterministic() does not include aten::feature_dropout or inline kinds,2021-02-22 14:47:13+00:00,,1,3,"[Label(name=""oncall: jit"")]"
52598,CUDA error: no kernel image is available for execution on the device When convert cpu tensor to gpu tensor,2021-02-22 12:14:04+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
52597,Custom scatter function for DataParallel,2021-02-22 10:37:07+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
52596,pickle is a security issue,2021-02-22 09:40:22+00:00,,1,10,"[Label(name=""module: pickle""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: hub""), Label(name=""topic: security"")]"
52589,[JIT-autodiff] batch_norm isn't differentiable,2021-02-22 05:41:42+00:00,,1,6,"[Label(name=""oncall: jit"")]"
52583,[TensorExpr] Add IR Verifier,2021-02-22 03:40:50+00:00,,0,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""NNC"")]"
52578,version1.7.0 is ~1.3x slower than 1.4.0 on ResNet18,2021-02-22 01:40:29+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""triaged"")]"
52575,Error: ‘str’ is not a member of ‘c10’; did you mean ‘c10::aten::str’? while using libtorch,2021-02-21 23:18:22+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
52570,"RTX 2080s performs better than RTX 3080 in Semantic Segmentation inference process(Libtorch,win10),why?",2021-02-21 14:22:39+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
52569,Omitting mutability annotations in op schemas can lead to subtle errors ,2021-02-21 10:19:15+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
52564,Submodules not rewritten during AST rewrite,2021-02-21 01:38:15+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
52553,Does pytorch have the inverse activation function of nn.LeakyReLU?,2021-02-20 14:12:49+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""function request"")]"
52552,Cumulative integration?,2021-02-20 12:16:27+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
52538,Helper methods not preserved during AST rewrite,2021-02-19 23:36:26+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
52517,[doc] JIT-compatible c++ custom ops,2021-02-19 20:04:09+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: docs""), Label(name=""docs-hackathon"")]"
52515,torch.bmm incorrect with pytorch 1.7.1 and cuda 11,2021-02-19 19:48:33+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas"")]"
52495,link failed when using custom build pytorch on Android,2021-02-19 08:52:27+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: undefined reference""), Label(name=""module: android""), Label(name=""module: arm"")]"
52485,Dispatcher documentation needs update,2021-02-19 05:33:23+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
52478,"Could you please increase the wheel compiled Linux (aarch64) GPU, thank you very much!",2021-02-19 02:18:17+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: arm"")]"
52471,all reduce hangs and does not throw exception when CUDA_VISIBLE_DEVICES is not set properly using the NCCL backend,2021-02-18 23:49:14+00:00,,0,10,"[Label(name=""oncall: distributed""), Label(name=""module: nccl"")]"
52465,[nnc][perf] Performance decrease with CPU fusion on `freeze(script(pytorch_mobilenet_v3))`,2021-02-18 21:44:32+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""NNC"")]"
52457,Add autograd tests to verify correctness for R -> C cases,2021-02-18 20:21:38+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""complex_autograd"")]"
52439,[proposal] Way to export/display the convolution algorithm found with cudnn.benchmark = True + allow to override algo choice with conv/matmul module/function algo/hint arguments,2021-02-18 15:01:34+00:00,,0,7,"[Label(name=""module: cudnn""), Label(name=""feature""), Label(name=""module: convolution""), Label(name=""triaged"")]"
52434,[NNC] NNC usability list,2021-02-18 09:14:21+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""NNC"")]"
52415,torch.autograd.Function doesn't support non-Tensor outputs,2021-02-18 01:35:26+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
52390,autograd.functional.vjp with function that mutates inputs in-place can cause confusion,2021-02-17 22:02:11+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
52363,RuntimeError: Can't redefine method: forward on class: __torch__.torch.nn.quantized.modules.conv.Conv1d (of Python compilation unit at: 0x5571a223a770),2021-02-17 18:23:56+00:00,,0,13,"[Label(name=""oncall: jit"")]"
52334,Normal_like operator,2021-02-17 00:21:31+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
52332,Reciprocals of complex tensors with infinities are different from NumPy.,2021-02-16 23:57:01+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy""), Label(name=""module: NaNs and Infs"")]"
52318,"TorchConfig.cmake entries of if(ON) are not accepted by CMake as ""true"", to be replaced by if(1)",2021-02-16 19:28:06+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
52312,TorchScript can't wrap Python constants in current module,2021-02-16 18:58:57+00:00,,1,4,"[Label(name=""oncall: jit"")]"
52310,Implementation of many complex functions is fast but inaccurate in libc++,2021-02-16 17:58:47+00:00,,0,1,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
52309,[JIT] __getitem__ on scripted ModuleDict returns unscripted module,2021-02-16 17:51:39+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""days"")]"
52307,Model produces same outputs for different inputs when using GPU,2021-02-16 17:31:02+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
52298,[FR} Implement Skellam distribution,2021-02-16 15:17:51+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
52295,Printing a Tensor that is being vmap'ed over in C++ raises an error,2021-02-16 11:45:37+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: vmap"")]"
52291,"""LayerNormKernelImpl"" not implemented for 'Half' - CPU",2021-02-16 06:45:17+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: half"")]"
52289,DataParallel module fails to handle data with size not divisible by number of GPUs,2021-02-16 01:40:55+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
52279,[docs] Official apex -> torch.cuda.amp migration guide,2021-02-15 19:16:22+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
52274,Port unary elementwise ops to structured kernels,2021-02-15 14:31:57+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: structured kernels"")]"
52271,torchscript should work with type: ignore comments from mypy even if they are not at the end of the line,2021-02-15 12:28:04+00:00,,1,9,"[Label(name=""oncall: jit""), Label(name=""days"")]"
52266,GPU (+CPU/RAM?) self-check script or instructions in core,2021-02-15 07:58:52+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
52265,'TypeError: expected CPU (got CUDA)' when placing a CUDA tensor on a class that is inheriting torch.Tensor,2021-02-14 21:19:17+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: tensor creation"")]"
52262,tolist called on torch scalar does not return a list => proposal to support new arg force = True to provide a work around,2021-02-14 10:14:41+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy"")]"
52260,Unlucky batch->device split by DataParallel causes an exception,2021-02-14 05:39:38+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
52256,[docs] Bad docs SEO,2021-02-13 22:48:26+00:00,,0,27,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
52241,CTCLoss gradient is incorrect,2021-02-12 21:55:23+00:00,,0,21,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""module: loss""), Label(name=""triaged"")]"
52236,CosineAnnealingWarmRestarts LR scheduler fails when lash_epoch != -1,2021-02-12 21:18:23+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
52230,Removing mutation on block input should print any meaning message.,2021-02-12 20:02:56+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
52214,`hasattr` check not supported on objects other than `self`,2021-02-12 17:15:16+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
52211,Conv3D error : CUDNN_STATUS_INTERNAL_ERROR,2021-02-12 16:32:59+00:00,,0,4,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
52208,C++ standard library confusion,2021-02-12 12:59:27+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
52207,Wasserstein metric,2021-02-12 12:15:51+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
52206,from_numpy function rounds float values on Jetson NX,2021-02-12 12:13:11+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: arm""), Label(name=""module: jetson"")]"
52205,Allow F.pad(mode = 'reflect') when shape == pad,2021-02-12 11:47:47+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: padding"")]"
52181,"`torch.load(..., weights_only=True)` currently raises a Deprecation warning + [proposal] `weights_only=True` should become default for safe legacy-loading pickles",2021-02-12 01:32:12+00:00,,1,57,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: hub""), Label(name=""topic: security"")]"
52168,CMake errors building project that uses PyTorch,2021-02-11 22:38:49+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
52147,Pointer passed where number is expected for PYTORCH_CUDA_FUSER_JIT_OPT_LEVEL leading to crash,2021-02-11 17:04:53+00:00,,0,0,"[Label(name=""oncall: jit"")]"
52145,Trying to initialise CUDA twice in a process with no visible devices hangs the process and terminal permanently,2021-02-11 16:10:23+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
52144,Concatenation of Java tensors (Android for mobile),2021-02-11 16:03:01+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
52143,[proposal] Parameter dim for F.linear (and maybe nn.Linear),2021-02-11 15:43:53+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
52134,Build using Py_LIMITED_API and then build wheels with the stable ABI abi3 tag,2021-02-11 10:59:53+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""module: performance""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
52096,"Unable to build: subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '-j', '4']' returned non-zero exit status 1.",2021-02-10 21:15:02+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
52058,at::numeric_limits is misleading,2021-02-10 16:39:46+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""actionable"")]"
52052,common_jit.check_against_reference() should check gradients w.r.t. weights,2021-02-10 16:02:21+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""days"")]"
52047,Detect OpenMP Loop and this application may hang warnings,2021-02-10 14:18:51+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: tests""), Label(name=""module: multithreading""), Label(name=""days"")]"
52041,device (+dtype) arguments for torch.stack / torch.cat,2021-02-10 12:02:19+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
52040,torch.distributed.TCPStore doesn't work with dual IPv4/IPv6 network interface,2021-02-10 11:29:18+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
52036,Automatic splitting of batch during model feed-forwarding to avoid memory errors caused by the too big batch_size,2021-02-10 10:09:23+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""needs research"")]"
52022,[FX] Interpreter doesn't GC values,2021-02-10 04:16:55+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
52011,CPU eval BatchNorm2d is not threaded,2021-02-10 00:31:32+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
52005,Implementation of Normalized Euclidean Distance (NED) in pytorch,2021-02-09 23:53:35+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request""), Label(name=""module: distance functions"")]"
51997,[FX] Modules called with constants should return constants and not proxies.,2021-02-09 22:21:31+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
51994,Allow Custom Classes to register a handler for .to operations ,2021-02-09 21:30:46+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""module: custom-operators""), Label(name=""weeks"")]"
51969,Support backward hooks in JIT ,2021-02-09 15:59:44+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
51965,Feature Request:Fast Cosine Transform,2021-02-09 14:52:01+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fft""), Label(name=""function request"")]"
51962,PyTorch for scientific computing,2021-02-09 13:44:25+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""needs design"")]"
51950,test_jit_cuda_archflags fails if current GPU is newer than nvcc,2021-02-09 08:52:33+00:00,,0,0,"[Label(name=""oncall: jit"")]"
51942,Overwritten method has wrong self when JIT'ed,2021-02-09 05:23:54+00:00,,1,4,"[Label(name=""oncall: jit"")]"
51941,RuntimeError: torch.dtype passed as int from JIT to ignored function,2021-02-09 05:10:35+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
51933,Performance bugs of transpose2d on A100,2021-02-09 02:49:54+00:00,,0,15,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
51932,[Pipe] Memory-Efficient Model Construction ,2021-02-09 02:45:11+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""pipeline parallelism"")]"
51931,[Pipe] Tied layers,2021-02-09 02:45:06+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""pipeline parallelism"")]"
51911,torch.nn.functional.grid_sample outputs NaN,2021-02-08 22:50:13+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
51906,torch.nn.functional.binary_cross_entropy(_with_logits) outputs NaN,2021-02-08 22:05:48+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
51896,Can't reassign a child module instance to a lambda,2021-02-08 20:07:01+00:00,,0,14,"[Label(name=""module: nn""), Label(name=""triaged"")]"
51892,[cuda jit extentions] global shared destination conflicts with virtual envs,2021-02-08 19:17:52+00:00,,0,2,"[Label(name=""oncall: jit"")]"
51885,JIT Module forward pre-hooks do not support default arguments,2021-02-08 17:53:29+00:00,,0,1,"[Label(name=""oncall: jit"")]"
51872,Tensor.nonzero tries to allocate huge amount of memory for tensors on GPU with num_elements close to INT_MAX,2021-02-08 14:17:19+00:00,,0,2,"[Label(name=""module: dependency bug""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
51871,Tensor.nonzero fails on GPU for tensors containing more than INT_MAX elements,2021-02-08 14:06:59+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
51868,discrepancies between TorchConfigVersion.cmake to git branch,2021-02-08 07:43:32+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
51863,TestVectorizedMemoryAccess.CopyKernel starting to fail after driver to 460.39,2021-02-07 17:26:32+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged"")]"
51856,Assignment target is transposed when using jit.script and avanced indexing,2021-02-07 11:13:42+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""good first issue""), Label(name=""OSS contribution wanted""), Label(name=""days"")]"
51855,"Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at /pytorch/caffe2/serialize/inline_container.cc:132)",2021-02-07 10:01:14+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: assert failure"")]"
51849,.numpy() array failes to keep original storage around,2021-02-07 04:38:39+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: tensor creation"")]"
51836,TypeError: can't pickle _thread.lock objects when using spawn / forkserver,2021-02-06 17:42:03+00:00,,0,1,"[Label(name=""module: pickle""), Label(name=""triaged""), Label(name=""better-engineering"")]"
51835,methods decorated with torch.jit._overload_method are not accessible,2021-02-06 17:28:35+00:00,,1,1,"[Label(name=""oncall: jit"")]"
51808,[jit] Keyword-arg expansion for constants,2021-02-05 21:55:02+00:00,,0,4,"[Label(name=""oncall: jit"")]"
51803,torch.fx.symbolic_trace fails on torch.arange with input-dependent size,2021-02-05 20:00:31+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: fx"")]"
51794,"optim.Optimizer should copy ""params"" before modifying them",2021-02-05 18:12:58+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
51782,[discussion] [python] Generic way for generating module-wrappers for stateless parametrized functions,2021-02-05 15:05:50+00:00,,0,6,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""better-engineering"")]"
51781,Libtorch lock thread,2021-02-05 13:08:37+00:00,,0,0,"[Label(name=""module: abi""), Label(name=""triaged"")]"
51780,Proposal for export TensorBoard tracing files,2021-02-05 11:54:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
51778,Assertion on the existence of RRef user-facing methods' docstrings,2021-02-05 11:01:50+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
51777,Analytical metric package,2021-02-05 10:54:14+00:00,,0,15,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: data"")]"
51776,BatchNorm3d error : CUDNN_STATUS_NOT_SUPPORTED,2021-02-05 09:38:51+00:00,,0,6,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
51732,torch.nn.functional.ctc_loss crash(segfault) ,2021-02-04 18:15:43+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
51720,Support for 64-bit (ILP64) LAPACK,2021-02-04 15:26:51+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
51714,Inconsistent result between NumPy and PyTorch for 0^(z) when Re(z) < 0,2021-02-04 09:21:51+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: NaNs and Infs"")]"
51711,Weird behavior in Conv2d padding when changed to 'reflect',2021-02-04 07:56:26+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: padding"")]"
51673,[JIT/Futures] Future callbacks/then() APIs should throw the correct exception,2021-02-03 22:37:00+00:00,,2,2,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""days"")]"
51663,Torch DataLoader fails to reraise error from sqlalchemy.,2021-02-03 19:50:36+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
51644,"Segmentation Fault: Garbage collector, cuda memory",2021-02-03 16:53:23+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
51623,[docs] FractionalMaxPool2d : _random_samples arg is present in signature but undocumented.,2021-02-03 07:16:33+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling"")]"
51622,"`fractional_max_pool{2, 3}d` inconsistent between CUDA and CPU",2021-02-03 07:10:28+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: pooling"")]"
51616,[RPC] rref.get_type() should have default return type of future,2021-02-03 05:31:32+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: rpc"")]"
51575,[doc] being able to switch version while keeping the same doc,2021-02-02 18:27:04+00:00,,1,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: doc infra""), Label(name=""better-engineering"")]"
51574,[Pipe] conversion to Sequential: various complex scenarios,2021-02-02 18:18:09+00:00,,0,10,"[Label(name=""oncall: distributed""), Label(name=""pipeline parallelism"")]"
51563,[TorchScript Usability] Type-checker too strict for Optional type initialization pattern,2021-02-02 15:29:24+00:00,,1,0,"[Label(name=""oncall: jit"")]"
51558,torch.reshape fails to keep the memory format,2021-02-02 13:44:49+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: viewing and reshaping"")]"
51553,ONNX export failed on ATen operator _thnn_fused_gru_cell,2021-02-02 10:45:52+00:00,,0,2,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
51535,Why isn't there a pip-installable PyTorch for Raspberry Pi?,2021-02-02 05:56:09+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: arm"")]"
51511,Python-3.9: Importing numba and torch triggers internal error,2021-02-02 00:51:12+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
51509,Massive Performance bottlenecks in some of the Reduce operations.,2021-02-02 00:26:33+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: TensorIterator""), Label(name=""module: reductions"")]"
51493,Add branch predictor hints to prefer `Context::deterministicAlgorithms() == false`,2021-02-01 20:55:13+00:00,,1,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: determinism"")]"
51471,Make TorchBind object appear in state_dict,2021-02-01 17:57:06+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: serialization""), Label(name=""triaged"")]"
51465,torch::jit::Module cannot be forward declared and used into a `unique_ptr` ,2021-02-01 17:23:45+00:00,,0,0,"[Label(name=""oncall: jit"")]"
51456,Optional tensor type,2021-02-01 15:26:58+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
51455,"[docs] Improve documentation for LayerNorm, GroupNorm, etc (+ add python reference impl)",2021-02-01 14:12:57+00:00,,0,11,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
51451,Add support for conan package manager,2021-02-01 12:49:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
51450,torch.median slower than torch.sort on cpu,2021-02-01 10:58:14+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: sorting and selection""), Label(name=""module: reductions"")]"
51445,Saving embedding vectors as TSV for Tensorboard is not efficient,2021-02-01 06:55:41+00:00,,0,2,"[Label(name=""oncall: visualization"")]"
51440,Support unity 3d,2021-02-01 02:48:09+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
51429,"dist.init_process_group('nccl', ...) hangs in some combinations of pytorch+python+cuda version",2021-01-31 14:09:09+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
51426,Different results on RTX 2060s vs GTX 1060 with gpt model,2021-01-31 05:39:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
51418,Pytorch num_worker>0 code worked first time and then it never worked with same setting again,2021-01-30 19:44:24+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
51410,Caffe2 RNN Cell Names not rectified,2021-01-30 12:17:05+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
51409,C++ load model error,2021-01-30 11:16:26+00:00,,0,1,"[Label(name=""oncall: jit"")]"
51407,Additon of levenberg-marquardt optimizer in TORCH.OPTIM,2021-01-30 10:20:47+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
51406,[numpy] `round` and `trunc` not supported for Integral Type while Python and NumPy supports them,2021-01-30 10:19:28+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
51393,max_pool2d CPU forward performance is poor,2021-01-30 01:04:04+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: pooling"")]"
51385,DataParallel copies the model onto GPUs sequentially,2021-01-29 23:03:17+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
51379,TorchScript class compilation failure with pybind11-2.6.2,2021-01-29 22:19:16+00:00,,0,6,"[Label(name=""oncall: jit"")]"
51376,Huggingface model not being torch scriptable,2021-01-29 22:00:10+00:00,,0,5,"[Label(name=""oncall: jit"")]"
51351,Run time error,2021-01-29 15:03:43+00:00,,1,11,"[Label(name=""module: dependency bug""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas""), Label(name=""module: wsl"")]"
51332,Cant compile from source 1.8.0a0 because 'magma_v2.h' file not found and undefined references to `magma_*',2021-01-29 05:01:26+00:00,,1,7,"[Label(name=""high priority""), Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: magma"")]"
51328,Support torch::jit::script::Module converting to torch::nn::Module.,2021-01-29 02:34:35+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
51320,"Pytorch not working properly (I don't know how to summarize it, see below)",2021-01-29 00:17:31+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged"")]"
51302,"""make install"" skips some required libraries for static build",2021-01-28 20:57:35+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
51284,result_type doesn't take dtypes and doesn't match numpy,2021-01-28 14:33:32+00:00,,0,20,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
51282,Bind tensor.unflatten to torch.unflatten namespace (torch.flatten exists but not torch.unflatten),2021-01-28 11:39:59+00:00,,0,1,"[Label(name=""triaged"")]"
51280,"[ux] Proposal to have t() === transpose(-1, -2), since batches are very frequent",2021-01-28 11:33:55+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: ux"")]"
51279,Profiler is stuck for DDP training,2021-01-28 11:17:18+00:00,,0,3,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
51275,Error of running,2021-01-28 08:58:45+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
51256,[search] duplicated entries in results,2021-01-28 01:06:40+00:00,,1,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
51231,macOS error building 1.7.1 from source on Catalina 10.15.7,2021-01-27 19:40:49+00:00,,0,16,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
51229,std::type_index doesn't provide reliable equality for getCustomClassTypeMap,2021-01-27 19:33:31+00:00,,0,2,"[Label(name=""module: internals""), Label(name=""triaged"")]"
51224,`torch.cuda.device` should look like it is inherited from `torch.device`,2021-01-27 18:49:02+00:00,,1,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
51210,"Complex->Real cast is a warning, calling `real` or `imag` on non-complex tensors is an Error.",2021-01-27 13:21:26+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: ux"")]"
51207,Initialize NCCL backend with MPI,2021-01-27 11:42:28+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: mpi""), Label(name=""enhancement""), Label(name=""module: nccl"")]"
51199,[numpy] torch.ceil and torch.floor don't support integer inputs while Numpy does,2021-01-27 09:25:17+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
51197,"[docs] use `versionadded`, `versionchanged` and `deprecated` directive",2021-01-27 09:09:40+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""feature""), Label(name=""triaged"")]"
51156,[Feature Request] Support tensor creation from objects that implement the __array__ interface,2021-01-26 23:40:14+00:00,,1,11,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""needs design""), Label(name=""function request"")]"
51154,[JIT] Rough edges found while exploring expressions supported by TorchScript,2021-01-26 23:39:19+00:00,,0,0,"[Label(name=""oncall: jit"")]"
51152,Make it clearer when a tensor was quantized symmetrically,2021-01-26 23:36:30+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
51151,-fno-omit-frame-pointer by default in our builds,2021-01-26 23:33:42+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement"")]"
51140,[TorchScript Usability] Non-intuitive error messages for user errors ,2021-01-26 20:40:27+00:00,,1,0,"[Label(name=""oncall: jit"")]"
51138,[TorchScript Usability] tensor printout format differs from eager mode,2021-01-26 20:33:49+00:00,,1,6,"[Label(name=""oncall: jit""), Label(name=""good first issue""), Label(name=""OSS contribution wanted""), Label(name=""TSUsability""), Label(name=""TSRootCause:PyTorchParityGap"")]"
51137,[TorchScript Usability] Earlier type checking needed for interface type,2021-01-26 20:29:23+00:00,,0,0,"[Label(name=""oncall: jit"")]"
51136,[TorchScript Usability] error message when invoking __init__ of module types inside TorchScript,2021-01-26 20:25:38+00:00,,1,1,"[Label(name=""oncall: jit"")]"
51135,[TorchScript Usability] Behaviors of used-defined subclasses of torch.tensor are silently ignored,2021-01-26 20:17:52+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""TSRootCause:InvalidCustomClass""), Label(name=""TSUsability"")]"
51134,segmentation fault in torch.nn.ReplicationPad3d/2d when padding is large,2021-01-26 20:14:42+00:00,,0,0,"[Label(name=""module: crash""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: padding"")]"
51117,TestLinalgCPU.test_cholesky_solve_autograd_cpu_float64 fails on different random seed,2021-01-26 17:40:05+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: correctness (silent)"")]"
51112,"torch.tensor(x) fails inconsistently, assumes 0 index exists in 'Series'",2021-01-26 16:58:18+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: tensor creation"")]"
51084,dyld: Symbol not found: _PyBaseObject_Type   Referenced from,2021-01-26 04:22:24+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: static linking"")]"
51083,apex internal assert failed,2021-01-26 04:19:58+00:00,,0,2,"[Label(name=""module: dependency bug""), Label(name=""triaged""), Label(name=""module: assert failure""), Label(name=""module: regression"")]"
51075,RFC: Private CUDA memory pools,2021-01-26 01:51:23+00:00,,1,13,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cuda graphs"")]"
51074, error: ‘PyFrameObject {aka struct _frame}’ has no member named ‘f_lasti’,2021-01-26 01:20:14+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
51062,test_profiler_with_remote_builtin (__main__.TensorPipeRpcTestWithSpawn) is flaky,2021-01-25 23:36:22+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: rpc"")]"
51055,Native code assert or hang on process exit with a torch.jit.script model on multi-GPU,2021-01-25 22:04:09+00:00,,0,14,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
51054,Class-based structured kernels instruction count regression,2021-01-25 21:06:27+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: structured kernels"")]"
51044,CuDNN 8 with benchmark=True takes minutes to execute for certain configurations,2021-01-25 17:35:33+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
51039,Status of pip wheels with _GLIBCXX_USE_CXX11_ABI=1,2021-01-25 16:24:49+00:00,,0,22,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""module: cpp""), Label(name=""module: abi""), Label(name=""triaged""), Label(name=""needs design"")]"
51038,The pooling code is ignoring sliding windows that start within the right padding,2021-01-25 16:17:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: pooling"")]"
51020,arm64-v8a not compiling due to libpytorch_jni.so,2021-01-25 01:33:54+00:00,,0,29,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: android""), Label(name=""module: arm"")]"
51018,len of ModuleList is incorrect for jitted models,2021-01-24 23:44:03+00:00,,0,3,"[Label(name=""oncall: jit"")]"
51015,/usr/local/include/google/protobuf/stubs/pbconfig.h:3:37: note: expanded from macro 'GOOGLE_PROTOBUF_HASH_MAP_H',2021-01-24 18:08:26+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
51014,[pipeline] gpu util + peak mem reporting to tune partitions and chunks ,2021-01-24 17:59:28+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""pipeline parallelism"")]"
51011,DataLoader is slow in spawned processes,2021-01-24 13:40:57+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
51008,Suggestion: Assimilate activation images to PyTorch brand color,2021-01-24 10:04:38+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
51003,Proposing new features: Developing Echo State Network layers,2021-01-24 05:42:44+00:00,,0,1,"[Label(name=""new-layer""), Label(name=""feature""), Label(name=""triaged""), Label(name=""shadow review""), Label(name=""module: embedding"")]"
51002,Consider adding context manager support for torch.set_printoptions,2021-01-24 05:41:50+00:00,,0,0,"[Label(name=""module: printing""), Label(name=""triaged""), Label(name=""enhancement"")]"
50987,Scalar/Tensor arg type for op schemas,2021-01-23 09:29:36+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
50971,Failing to trace Huggingface models using Trace API from Torchscript,2021-01-22 23:10:33+00:00,,0,5,"[Label(name=""oncall: jit"")]"
50962,Add option for Convolutions to operate over NTC and NHWC tensors,2021-01-22 21:22:13+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: memory format"")]"
50953,Dispatch-less structured wrapper / composite / alias kernels,2021-01-22 18:48:34+00:00,,0,22,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: structured kernels"")]"
50944,libpytorch macos build: static library eigen_blas_LIBRARY-NOTFOUND not found,2021-01-22 13:16:45+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
50943,Exporting opnames fails when using custom classes,2021-01-22 13:03:06+00:00,,0,3,"[Label(name=""oncall: mobile"")]"
50941,Questions about amp,2021-01-22 11:34:53+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
50940,SequentialSampler getting slower as time passing by,2021-01-22 11:28:07+00:00,,0,8,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
50939,dataloader bug need help,2021-01-22 10:41:54+00:00,,0,4,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
50933,[JIT] Type refinement failure in if-elif-else structure,2021-01-22 06:54:36+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""TSRootCause:TypeRefinement""), Label(name=""TSUsability"")]"
50925,THCCachingAllocator::cuda_free_mutex has no effect,2021-01-22 01:40:11+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: nccl"")]"
50890,"torch.unique(x, dim=1, return_inverse=True) returns inverse for only the last sub-tensor along dim",2021-01-21 17:55:54+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: sorting and selection"")]"
50888,Does pytorch support cuda 11.1,2021-01-21 16:35:38+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
50879,Unexpected slow dropout in stacked RNN/LSTM/GRU,2021-01-21 14:28:18+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: cudnn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
50873,Segmentation Fault when importing torch on macOS Big Sur,2021-01-21 10:01:41+00:00,,0,15,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: openmp"")]"
50853,[nnc][perf] CPU fuser needs to support intra-op parallelism,2021-01-20 23:22:19+00:00,,1,4,"[Label(name=""triaged""), Label(name=""NNC"")]"
50852,[TorchScript Performance Deep-dive] problems discovered in TS performance deep-dive,2021-01-20 23:20:01+00:00,,4,1,"[Label(name=""module: performance""), Label(name=""triaged"")]"
50835,Insufficient shared memory (shm) while training,2021-01-20 20:16:06+00:00,,0,2,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
50834,Precision of scalars is lost in script mode for binary operations with tensors,2021-01-20 20:11:12+00:00,,1,4,"[Label(name=""oncall: jit"")]"
50831,Dataloader Prefetch data to GPU by cudaMemPrefetchAsync,2021-01-20 19:50:12+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
50830,Pull upstream cmake's change in FindCUDA/select_compute_arch,2021-01-20 19:14:07+00:00,,1,0,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
50829,pin_memory leads to GPU memory being used but it doesn't initialize CUDA,2021-01-20 19:13:49+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
50820,NCCL_BLOCKING_WAIT=1 makes training extremely slow (but if not set then OOM on one device will hang training),2021-01-20 17:28:26+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
50804,Segmentation fault encountered when using nn.MultiheadAttention with v1.7.1,2021-01-20 11:43:49+00:00,,0,3,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""oncall: transformer/mha"")]"
50803,pytorch DDP hangs at .backward() call,2021-01-20 11:13:24+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""module: ddp"")]"
50802,Link to `torch.einsum` in `torch.tensordot`,2021-01-20 11:02:32+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
50789,Implement torch.pow for float16 and bfloat16 on CPU,2021-01-20 03:30:51+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: half""), Label(name=""function request"")]"
50779,pytorch is built without _GLIBCXX_USE_CXX11_ABI and can cause std::regex crashes (probably),2021-01-20 01:25:27+00:00,,0,9,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
50772,[TorchScript Usability] Incorrect default types,2021-01-19 22:26:05+00:00,,1,0,"[Label(name=""oncall: jit"")]"
50758,"Improve error message for ""Could not run 'aten::record_stream' with arguments from the 'CPU' backend. "" ",2021-01-19 20:05:38+00:00,,1,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: dispatch"")]"
50743,Batched grad coverage rollup,2021-01-19 17:31:07+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: vmap"")]"
50737,Adding visualizations for indexing and other functions,2021-01-19 16:47:25+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""module: scatter & gather ops"")]"
50734,[TorchScript] Document TorchScript IR,2021-01-19 15:40:07+00:00,,2,1,"[Label(name=""oncall: jit"")]"
50723,[PyTorch Mobile] Can't use Vulkan backend,2021-01-19 13:06:30+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile""), Label(name=""module: vulkan"")]"
50718,dependency_links is deprecated ,2021-01-19 10:17:45+00:00,,0,8,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged"")]"
50714,[PyTorch Mobile] Android speed benchmark binary crashes when using vulkan,2021-01-19 07:54:48+00:00,,0,7,"[Label(name=""oncall: mobile"")]"
50712,ignore_index for nn_mse_loss,2021-01-19 06:40:31+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""function request"")]"
50701,Multiple ProcessGroup C++ Tests are flaky,2021-01-18 21:15:53+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: c10d"")]"
50694,CosineAnnealingWarmRestarts lacks verbose functionality,2021-01-18 20:04:54+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
50689,RandomSampler is very slow with huge dataset,2021-01-18 15:15:41+00:00,,0,13,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
50688,[feature request] `torch.scan` (also port `lax.fori_loop` / `lax.while_loop` / `lax.associative_scan` and hopefully parallelized associative scans),2021-01-18 14:21:46+00:00,,1,38,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""needs design""), Label(name=""module: functional UX""), Label(name=""oncall: pt2""), Label(name=""module: functorch""), Label(name=""module: pt2-dispatcher"")]"
50678,[PyTorch Mobile] NNAPI prototype installer no longer available,2021-01-18 07:19:11+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
50669,Launching two processes causes hanging,2021-01-17 19:58:43+00:00,,0,9,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
50650,build from source fail in jeston tx2 Python3.8,2021-01-16 06:17:58+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: arm"")]"
50636,Training slowdown from 1.6 to 1.7.1,2021-01-16 00:20:31+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
50616,Use unified type for distributions.constraint API,2021-01-15 21:58:12+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
50613,Discourage slow gradchecks,2021-01-15 21:16:12+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged"")]"
50566,Enhance supported fill value type for constant pad in functional.pad,2021-01-15 03:14:30+00:00,,0,13,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs design""), Label(name=""module: padding"")]"
50552,test_fn_grad_fft_fftn_cpu_complex128 and test_fn_grad_fft_rfftn_cpu_float64 are failing under TSAN,2021-01-14 21:13:02+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: sanitizers""), Label(name=""module: fft"")]"
50549,Channels last doesn't improve speed when using SyncBatchNorm,2021-01-14 20:24:55+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: memory format"")]"
50533,Non-avairable nightly version for converting models to NNAPI,2021-01-14 11:41:27+00:00,,0,13,"[Label(name=""oncall: mobile"")]"
50531,"PyTorch mobile perf recipes, fails when building android ",2021-01-14 10:45:44+00:00,,0,1,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
50530,Unable to compile CUDAExtension with Pytorch 1.5 or above,2021-01-14 09:07:31+00:00,,0,3,"[Label(name=""module: bc-breaking""), Label(name=""module: cpp-extensions""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""topic: bc breaking"")]"
50503,Huge file sizes for libtorch and dependencies?,2021-01-13 21:45:27+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
50473,Make use of eps for numerical stability more consistent,2021-01-13 13:08:25+00:00,,0,0,"[Label(name=""module: numerical-stability""), Label(name=""triaged"")]"
50471,linker error when trying to use Metal backend in PyTorch Mobile,2021-01-13 12:10:19+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: arm"")]"
50468,[RFC] Make RRef proxy APIs non-blocking,2021-01-13 10:10:17+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
50463,creating a dummy_input param for Pytorch model to Onnx conversion,2021-01-13 07:24:36+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
50462,Standalone OSS RPC benchmark,2021-01-13 07:00:47+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
50444,[TorchScript] Rough edges discovered during type system rewrite,2021-01-12 20:20:11+00:00,,1,0,"[Label(name=""oncall: jit"")]"
50425,libtorch gpu set id bug,2021-01-12 09:22:48+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""module: cuda""), Label(name=""triaged"")]"
50402,ValueError: optimizer got an empty parameter list,2021-01-11 23:09:39+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
50384,Static hooks serialization: moving the hook definitions outside of module definitions in the archive,2021-01-11 19:03:12+00:00,,0,0,"[Label(name=""oncall: jit"")]"
50382,out variant of many loss functions are not consistent with non-out variant when reduction is not none,2021-01-11 18:36:39+00:00,,1,3,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: reductions"")]"
50375,Provide a set of C++ foreach APIs that will take tensor pointers as an input,2021-01-11 16:07:11+00:00,,1,3,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
50366,Optimizer Closure: Enable skip by returning None loss.,2021-01-11 10:13:36+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
50360,error: conversion from ‘std::vector<at::Tensor>’ to non-scalar type ‘at::Tensor’ requested,2021-01-11 04:01:33+00:00,,0,19,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
50354,for CNN in fp16 execution time depends on input scale,2021-01-10 18:58:05+00:00,,0,13,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: half"")]"
50352,torch.tril_indices is incompatible with np.tril_indices,2021-01-10 15:21:11+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation""), Label(name=""module: ux"")]"
50346,how to save weights when using RPC framework,2021-01-10 08:26:37+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
50345,torch.special tracking issue,2021-01-10 08:02:14+00:00,,1,15,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: special""), Label(name=""tracker"")]"
50344,NumPy Compatibility tracking issue,2021-01-10 07:45:08+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""tracker"")]"
50343,RFC: identify analogous NumPy operators when documenting PyTorch operators,2021-01-10 07:44:49+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy"")]"
50342,torch.any and torch.all map uint8 -> uint8 but should map uint8 -> bool,2021-01-10 07:41:01+00:00,,0,0,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: reductions""), Label(name=""topic: bc breaking"")]"
50341,Interpolation tracking issue,2021-01-10 07:17:12+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: interpolation""), Label(name=""tracker"")]"
50340,Function request: scipy.interpolate.InterpolatedUnivariateSpline,2021-01-10 07:01:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: interpolation"")]"
50339,Function request: scipy.interpolate.griddata,2021-01-10 06:59:07+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: interpolation"")]"
50338,Function request: scipy.interpolate.RegularGridInterpolator,2021-01-10 06:57:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: interpolation"")]"
50337,Function request: scipy.interpolate.RectBivariateSpline,2021-01-10 06:55:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: interpolation"")]"
50336,Function Request: scipy.ndimage.zoom,2021-01-10 06:53:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: interpolation"")]"
50335,Function Request: scipy.interpolate.interp1d,2021-01-10 06:51:48+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: interpolation"")]"
50334,Function Request: np.interp,2021-01-10 06:49:49+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: interpolation"")]"
50333,Function Request: scipy.stats.pearsonr,2021-01-10 06:26:32+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
50332,torch.Tensor.random_ is divergent from NumPy's np.random.random,2021-01-10 06:12:24+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: random""), Label(name=""module: deprecation"")]"
50328,RTX3090 performs no better than 1080ti,2021-01-10 02:26:44+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""triaged"")]"
50323,running a job on multiple gpus with qsub ,2021-01-09 16:10:12+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
50303,Way to solve GPU Host Thread Contention?,2021-01-09 00:19:11+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
50292,Implement dunder getattribute instead of dunder getattr for nn.Module,2021-01-08 21:55:56+00:00,,0,2,"[Label(name=""module: bc-breaking""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""topic: bc breaking"")]"
50282,Add MultiScheduler,2021-01-08 16:27:28+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
50276,torch.meshgrid is divergent from np.meshgrid,2021-01-08 14:41:14+00:00,,0,21,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation"")]"
50275,torch.transpose is divergent from np.transpose,2021-01-08 14:27:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation"")]"
50274,torch.equal is divergent from np.equal,2021-01-08 14:19:33+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation""), Label(name=""module: testing"")]"
50273,torch.cross is divergent from np.cross,2021-01-08 14:11:48+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation"")]"
50268,CUDA error when using `binary_cross_entropy_with_logits`,2021-01-08 10:16:12+00:00,,0,10,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
50261,ModuleNotFoundError: No module named '__torch__',2021-01-08 09:05:01+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: multiprocessing""), Label(name=""module: serialization""), Label(name=""triaged"")]"
50260,FusedKernelCPU failed to delete generated dll files on Windows ,2021-01-08 08:42:13+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""module: windows"")]"
50258,More general MultiHeadAttention and Transformer modules,2021-01-08 07:38:44+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: transformer/mha"")]"
50231,"Tracing with autocast failed with error: ""Cannot insert a Tensor that requires grad as a constant""",2021-01-07 21:31:21+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: amp (automated mixed precision)"")]"
50219,`requires_grad_` in `no_grad` context returns incorrect value with tensor subclasses,2021-01-07 19:03:46+00:00,,0,10,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
50213,torch.float_power out= and inplace variant errors on non-matching output dtype instead of casting,2021-01-07 17:32:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: type promotion"")]"
50210,"Pytorch 1.7.1 hangs with multi-gpu, while Pytorch 1.6.0 works correctly",2021-01-07 16:03:35+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""module: data parallel"")]"
50206,Build Fail with vulkan on ARM64 and wayland drivers,2021-01-07 15:53:33+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
50204,Find the joint eigenvalue of two matrices. ,2021-01-07 15:46:07+00:00,,0,8,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: linear algebra"")]"
50201,Excessive memory usage caused by Samplers storing lists of indices,2021-01-07 14:22:19+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
50198,deterministic implementation for adaptive_avg_pool2d_backward_cuda ,2021-01-07 11:22:49+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""module: pooling""), Label(name=""function request"")]"
50192,GRU and LSTM fail for seq_len = 0,2021-01-07 06:55:58+00:00,,1,12,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
50190,Calling emptyCache in Conv_v7.cpp causes performance degradation,2021-01-07 05:32:21+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
50185,CUDACachingAllocator is not GC-aware,2021-01-07 02:27:46+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
50177,[FX] Static specialization of callsites (e.g. chunk),2021-01-07 00:37:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
50170,Automated Mixed Precision not documented to work with nn.DataParallel,2021-01-06 23:33:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
50143,FX call_function does not work if target is a class member function,2021-01-06 15:49:35+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fx"")]"
50136,Inconsistent Variable Naming in FindTorch.cmake,2021-01-06 09:42:01+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
50134,"nn.InstanceNorm should warn user if input channel is inconsistent with num_features, even when affine=False",2021-01-06 09:02:40+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: norms and normalization"")]"
50127,JIT does not correctly compile custom classes derived from torch.Tensor,2021-01-06 05:21:18+00:00,,0,0,"[Label(name=""oncall: jit"")]"
50122,[proposal] Pseudo-functions to support common gradient patch use-cases like replacing inf / nan or clipping / gradient reversal,2021-01-05 23:26:30+00:00,,0,6,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""needs design"")]"
50118,torch.where scalar/tensor documentation is unclear and not formatted,2021-01-05 22:52:49+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
50112,need a clear guide for when and how to use torch.cuda.set_device(),2021-01-05 22:11:26+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""needs design"")]"
50098,Errors when coercing complex numbers of various sizes,2021-01-05 16:13:31+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: half"")]"
50097,Cannot print 32-bit complex tensors,2021-01-05 15:46:38+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: printing""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: half"")]"
50094,Broken LAPACK links in the documentation,2021-01-05 14:15:48+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
50092,batch_isend_irecv: the receiving end cannot receive large tensors from the sending end correctly,2021-01-05 10:26:28+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
50090,Torch native_layer_norm OP out-of-bounds access,2021-01-05 08:19:35+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
50076,resize_ documentation does not match implementation when memory_format is given,2021-01-04 23:29:10+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""triaged"")]"
50068,Magma functions that don't have queue argument create cublas handles for each call,2021-01-04 21:38:25+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
50051,pytorch_windows_vs2019_py36_cuda11.1_test1 intermittently fails,2021-01-04 18:43:08+00:00,,1,7,"[Label(name=""high priority""), Label(name=""module: windows""), Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged"")]"
50038,Torch  _remove_batch_dim OP out-of-bounds access,2021-01-04 11:46:43+00:00,,0,5,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: vmap"")]"
50037,Torch quantized_lstm_cell op out-of-bounds access,2021-01-04 10:35:26+00:00,,1,3,"[Label(name=""module: crash""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
50036,channels_last format convolution is slower than normal NCHW,2021-01-04 08:18:14+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: memory format"")]"
50034,Multinomial without replacement produces samples that have zero probability,2021-01-04 07:05:29+00:00,,0,8,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: random""), Label(name=""module: ux"")]"
50031,Inconsistent function name between stub and implementation in `torch.optim.swa_utils`,2021-01-04 04:48:50+00:00,,0,1,"[Label(name=""module: typing""), Label(name=""triaged"")]"
50013,torch.Tensor.repeat is divergent from np.repeat,2021-01-03 12:04:06+00:00,,0,3,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation"")]"
50012,torch.split is divergent from np.split,2021-01-03 11:53:42+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation"")]"
50010,torch.var and torch.std are not compatible with np.var and np.std,2021-01-03 10:46:29+00:00,,1,7,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation""), Label(name=""module: reductions"")]"
49992,"[docs] nn.modules pages should mention corresponding functional versions, e.g. for nn.Hardshrink",2021-01-01 13:06:22+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""small"")]"
49961,rfc: automating the switching of inputs to the device of the params,2020-12-30 03:40:54+00:00,,0,18,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""module: rpc""), Label(name=""needs design""), Label(name=""module: ux"")]"
49949,"RFC: Add a ""see also"" section to operators' documentation",2020-12-29 21:16:42+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
49935,[FX] intermediate types of empty lists/dicts not preserved during torch.fx tracing,2020-12-29 19:55:30+00:00,,1,5,"[Label(name=""oncall: jit""), Label(name=""TSRootCause:DefaultTypes""), Label(name=""TSUsability"")]"
49911,[RFC] Speed up python function and arg serialization in RPC APIs,2020-12-29 01:02:54+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
49909,Test functionality to detect extra cross device synchronizations,2020-12-29 00:04:29+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged"")]"
49900,A significant overhead when running fastrnns with autograd.profiler,2020-12-28 21:02:06+00:00,,1,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
49891,Support DDP find_unused_parameters=True mode when combined with Pipe,2020-12-28 16:19:06+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: ddp"")]"
49890,GEMM with int8 datatype throws RuntimeError on GPU,2020-12-28 15:23:18+00:00,,0,13,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""needs design""), Label(name=""function request"")]"
49885,LR scheduler `get_lr()` bug,2020-12-28 10:39:19+00:00,,0,4,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
49882,nll_loss2d: t >= 0 && t < n_classes assertion is not checked when using GPU tensors and reduction='none',2020-12-28 08:19:21+00:00,,0,7,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""good first issue""), Label(name=""module: error checking""), Label(name=""triaged"")]"
49877,The same tensor requires more memory on RTX3090,2020-12-27 14:11:09+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
49874,Accessibility Coding Needed,2020-12-27 07:14:05+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
49874,Accessibility Coding Needed,2020-12-27 07:14:05+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
49873,Accessibility of Website for Low Vision Users,2020-12-27 07:13:09+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
49870,Tensorboard Error,2020-12-26 20:37:41+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
49865,torch.solve on Jetson is slower than humans,2020-12-26 08:05:45+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
49856,Pytorch1.7.1 Dataloader bugs on win10,2020-12-25 18:08:05+00:00,,1,11,"[Label(name=""module: windows""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
49852,Advanced Indexing does not trace correctly for tensor shape that has leading 1s,2020-12-25 12:35:03+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""module: advanced indexing""), Label(name=""days"")]"
49851,[Feature Request] SuperLoss (NeurIPS 2020),2020-12-25 12:30:19+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""function request"")]"
49849,[dataloader] RuntimeError: Too many open files when yielding integers,2020-12-25 09:38:50+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
49846,torch init_process_group always hangs,2020-12-25 07:11:07+00:00,,0,2,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
49844,BCEWithLogitsLoss gives out nan with -inf logits,2020-12-25 05:31:00+00:00,,0,8,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
49832,RuntimeError: CUDA error: unspecified launch failure,2020-12-24 14:09:44+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
49825,Ensure inplace views are properly handled,2020-12-24 09:49:24+00:00,,0,6,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""better-engineering"")]"
49823,Why trace method used insted of script method in graph creation?,2020-12-24 08:35:06+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
49820,[JIT] Don't support math.exp and math.log in the Script,2020-12-24 05:27:10+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""days""), Label(name=""TSRootCause:TypeChecking""), Label(name=""TSUsability"")]"
49814,from_blob segfaults when given CUDA pointer,2020-12-24 00:49:50+00:00,,0,4,"[Label(name=""module: crash""), Label(name=""module: cpp""), Label(name=""module: cuda""), Label(name=""triaged"")]"
49810,Undefined reference to `cv::imread`,2020-12-23 19:00:12+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""has workaround"")]"
49795,ninja: build stopped: subcommand failed.,2020-12-23 09:37:15+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
49791,Caching for autoregressive decoding of Transformer,2020-12-23 07:54:46+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
49784,Compatibility with Raspberry Pi,2020-12-23 03:29:03+00:00,,0,0,"[Label(name=""module: build""), Label(name=""feature""), Label(name=""triaged"")]"
49782,TorchScript model's output different on Mobile and PC,2020-12-23 03:20:30+00:00,,0,6,"[Label(name=""oncall: mobile"")]"
49764,Second order derivative errors with torch.jit.script decorator after a few iterations,2020-12-22 22:55:42+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
49758,c10::scalar_to_tensor(...) uses should be audited for performance and type promotion impact,2020-12-22 22:13:56+00:00,,1,6,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
49752,IndexError: Input _features.0.weight is undefined!,2020-12-22 20:39:24+00:00,,0,3,"[Label(name=""caffe2""), Label(name=""triaged""), Label(name=""module: vision"")]"
49727,RandomSampler generator created in every iteration,2020-12-22 07:26:40+00:00,,1,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
49726,Wrong error is raised for property of nn.Module (again),2020-12-22 06:34:15+00:00,,0,10,"[Label(name=""module: nn""), Label(name=""triaged"")]"
49724,cure unnecessary NaN values that arise from ±∞ arguments,2020-12-22 05:24:51+00:00,,0,25,"[Label(name=""module: numerical-stability""), Label(name=""module: bootcamp""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
49723,Flattening nn.Parameters while maintaining gradients from neural network forward pass,2020-12-22 04:07:24+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
49716,Two independent future chains in PowerSGD cannot be kicked off asynchronously,2020-12-22 00:23:55+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
49678,That define multiple models can influence the convolution parameter update.,2020-12-21 13:01:37+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""triaged"")]"
49677,"File ""setup.py"", line 773:subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '-j', '8']' returned non-zero exit status 2",2020-12-21 11:39:08+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
49673,Is there any upper-level API to disable the detection of the weight’s version,2020-12-21 10:01:53+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
49672,Model passed through queue hangs while loading in sub process ,2020-12-21 09:39:33+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
49669,"While training the model, GPU util reaches 100% but no progress happends.",2020-12-21 08:40:55+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
49666,Use rlibm for faster and more accurate floating point operations,2020-12-21 04:42:14+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: bfloat16"")]"
49653,"torch.cuda.amp, example with 20% memory increase compared to apex/amp",2020-12-20 11:58:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
49650,Annotating submodule with correct type fails scripting,2020-12-20 05:38:34+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""TSRootCause:InvalidCustomClass""), Label(name=""TSUsability"")]"
49643,Tracing doesn't work with spectral normalization,2020-12-19 14:16:38+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
49642,Turn deprecation warnings into errors in CI,2020-12-19 13:34:03+00:00,,0,4,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
49630,Bug in CosineAnnealingWarmRestarts,2020-12-19 03:06:04+00:00,,0,5,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
49618,Support scope in fx Node,2020-12-18 22:49:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
49614,Improve error on missing/problematic Module member type annotation,2020-12-18 20:08:13+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""days""), Label(name=""TSRootCause:TypeChecking""), Label(name=""TSUsability"")]"
49585,[JIT] Serialization forward compatibility tests,2020-12-18 04:05:19+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
49569,Update jit/OVERVIEW.md,2020-12-17 22:07:13+00:00,,2,1,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
49562,"Batched gradient computation w/ vmap, feature rollup",2020-12-17 20:05:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""actionable""), Label(name=""module: vmap"")]"
49555,Gunicorn preload flag not working with PyTorch library,2020-12-17 18:50:55+00:00,,0,5,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
49539,Improve AssertionError for torch.nn.functional.pad 'replicate',2020-12-17 15:14:59+00:00,,0,3,"[Label(name=""module: bootcamp""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering"")]"
49538,jit tracer doesn't work with unflatten layer,2020-12-17 14:48:46+00:00,,1,17,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
49536,Pytorch mobile Vulkan API bug during call to ReLU,2020-12-17 09:46:39+00:00,,0,1,"[Label(name=""oncall: mobile""), Label(name=""oncall: java"")]"
49520,Segfault in torch.bincount,2020-12-17 00:50:14+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""triaged"")]"
49503,Enable torch.nn.modules.pooling typechecks during CI,2020-12-16 21:53:56+00:00,,1,0,"[Label(name=""module: typing""), Label(name=""triaged"")]"
49491,Bug report: INTERNAL ASSERT FAILED,2020-12-16 20:56:53+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
49481,rank-0 gpu consume too high memory,2020-12-16 19:14:25+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
49480,Internal symbols are leaking from torch.nn.functional,2020-12-16 19:11:44+00:00,,0,8,"[Label(name=""triaged"")]"
49477,Callbacks may not be automatically synchronized in a single NCCL future chain,2020-12-16 18:56:18+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
49476,Use METH_FASTCALL protocol in Python bindings,2020-12-16 18:29:47+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: pybind"")]"
49475,Write link in README.md,2020-12-16 18:22:41+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
49473,Pytorch 1.5+: Kernel dies / Segmentation Fault with torch.cuda.mermory_allocated() and torch.cuda.mermory_reserved(),2020-12-16 18:00:17+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: regression"")]"
49460,Libtorch: Segmentation fault when running torch::jit::load,2020-12-16 15:17:05+00:00,,0,24,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
49459, This error occurs occasionally during the run,2020-12-16 13:42:46+00:00,,0,5,"[Label(name=""module: crash""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
49456,Impossible to run tests target with LibTorch as dependency inside a cocoapods.,2020-12-16 10:15:05+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: ios"")]"
49445,[doc] how to prevent pytorch-nightly from being replaced by a released version on pip install,2020-12-16 02:42:27+00:00,,0,8,"[Label(name=""module: binaries""), Label(name=""module: docs""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
49444,[RFC] Add JIT graph fuser for oneDNN Graph API,2020-12-16 02:06:08+00:00,,1,12,"[Label(name=""oncall: jit"")]"
49440,[RFC] DataLoader architecture updates and TarDataset implementation,2020-12-16 00:34:47+00:00,,0,50,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
49431,clip_grad_norm_ performance regression,2020-12-15 22:09:04+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
49427,Inserting named tensor into other fails,2020-12-15 21:21:30+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: named tensor"")]"
49426,[doc] missing torch.pdist entry,2020-12-15 20:43:57+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""small""), Label(name=""module: distance functions"")]"
49416,A few years after #701 and PyTorch is still using implicit __all__ imports.,2020-12-15 19:06:05+00:00,,0,13,"[Label(name=""module: typing""), Label(name=""triaged""), Label(name=""module: pybind""), Label(name=""better-engineering""), Label(name=""module: codegen"")]"
49409,Add global gradcheck setting,2020-12-15 17:48:57+00:00,,1,8,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""better-engineering"")]"
49406,Bitcode enable for iOS,2020-12-15 16:02:51+00:00,,1,13,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: ios"")]"
49405,PyTorch 1.7.1 on (macOS/python 3.9/conda) links libtorch_global_deps.dylib with libomp.dylib instead of libiomp5.dylib,2020-12-15 15:57:37+00:00,,1,6,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
49398,Can we add try-except for list/slice indices even when auto_collation is True?,2020-12-15 07:31:12+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data"")]"
49394,Apparent Memory Leak with torch.as_tensor,2020-12-15 06:19:09+00:00,,0,23,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""quansight-nack""), Label(name=""module: tensor creation"")]"
49392,Uninitialized variable was not detected in ASAN CI config,2020-12-15 05:44:50+00:00,,0,0,"[Label(name=""high priority""), Label(name=""module: ci""), Label(name=""triaged"")]"
49377,[JIT-DEBUG] Suppress GRAPH dump in profile-graph-executor,2020-12-15 00:22:50+00:00,,1,0,"[Label(name=""oncall: jit"")]"
49372,[jit] Support `torch.Tensor.numel()` and `torch.Size.numel()` properly in tracing,2020-12-14 23:12:22+00:00,,1,5,"[Label(name=""oncall: jit"")]"
49370,"PyEval_SaveThread: the function must be called with the GIL held, but the GIL is released",2020-12-14 23:01:28+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: pybind"")]"
49347,[pre-commit hook] fails on `BLK100 Black would make changes.`,2020-12-14 19:24:23+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
49338,a time series library ,2020-12-14 17:43:45+00:00,,0,6,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research"")]"
49332,global_pruning costs memory after model is trained,2020-12-14 15:47:04+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: pruning"")]"
49321,Backward hangs with DDP during training.,2020-12-14 10:17:27+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: ddp"")]"
49320,how could I print the log in source code,2020-12-14 10:15:03+00:00,,0,5,"[Label(name=""module: cpp""), Label(name=""module: logging""), Label(name=""triaged"")]"
49300,is this a typo in optimizer.pyi ? it says `statue` instead of `state`,2020-12-13 19:25:21+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
49298,[question] How hard would it be to implement 4-bit precision training?,2020-12-13 18:04:02+00:00,,0,5,"[Label(name=""module: internals""), Label(name=""triaged"")]"
49291,add inverse cdf for Chi-square Distribution ,2020-12-13 09:19:34+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
49284,TensorBoard SummaryWriter to remote storage unreasonably slow,2020-12-12 14:43:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
49282,Bug when combining AMP with channels_last memory format,2020-12-12 10:20:39+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: amp (automated mixed precision)"")]"
49278,Does Pytorch have the function that can obtain sub-matrix according to index? ,2020-12-12 05:57:27+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
49265,[FX] Update `placeholder` docs to better reflect the role of `node` and `target`,2020-12-11 21:56:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
49261,[TorchScipt] Custom Objects C++ API,2020-12-11 21:35:52+00:00,,0,1,"[Label(name=""oncall: jit"")]"
49253,Differentiate between objects with a true `Tensor` type and objects with a default `Tensor` type,2020-12-11 19:36:04+00:00,,1,2,"[Label(name=""oncall: jit"")]"
49252,Methods that solve systems of linear equations are memory-inefficient (batch-wise broadcasting),2020-12-11 19:34:31+00:00,,0,3,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
49227,Looking for a more convenient way to getter value of the upper/lower triangular matrix into 1D,2020-12-11 10:03:48+00:00,,0,6,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""needs design""), Label(name=""topic: bc breaking"")]"
49224,Torch abs op crashes on -128 int8 tensor with ASAN,2020-12-11 09:18:37+00:00,,0,2,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
49217,Bug in profiler on CI machines when profiling NCCL distributed calls,2020-12-11 04:42:27+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
49207,Provide a mechanism to limit the workspace size of cudnn convolution,2020-12-11 00:36:01+00:00,,0,3,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
49180,torch.utils.data.DistributedSampler allow uneven inputs,2020-12-10 19:30:34+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data"")]"
49178,[NNC] Some ops have type promotion logic which adds extra casts & does compute in different dtype than eager,2020-12-10 19:05:59+00:00,,0,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""NNC"")]"
49177,Investigate `torch.linalg.norm` performance,2020-12-10 18:29:22+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
49166,Implement fill_out on complex,2020-12-10 15:37:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
49157,softmax fail,2020-12-10 10:38:54+00:00,,1,4,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""module: viewing and reshaping"")]"
49139,"Hello everyone, why does libtorch half precision float 16 leak memory?大家好，为什么libtorch半精度float16会内存泄漏？",2020-12-10 04:00:45+00:00,,0,11,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
49133,Unknown failure for test_reference_numerics_sinc_cpu_complex64 ,2020-12-10 01:37:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: trigonometric functions"")]"
49110,[RFC] Integrate DeepSpeed CUDA kernels,2020-12-09 20:52:17+00:00,,1,0,"[Label(name=""feature""), Label(name=""triaged"")]"
49101,[RFC] RemoteTensor: Use Remote Devices as Local Devices,2020-12-09 18:52:11+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
49095,NCCL Error when training with 2x 3090s.,2020-12-09 16:30:12+00:00,,0,27,"[Label(name=""module: multi-gpu""), Label(name=""module: cuda""), Label(name=""triaged"")]"
49082,swa_utils.bn_update is too opinionated in how it calls the model,2020-12-09 11:54:17+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
49076,Add List Type Data through add_hparam method in torch.utils.tensorboard.SummaryWriter,2020-12-09 08:50:16+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
49038,Make the  forward function of a nn.Module and/or a certain function to work with only float32 when used with autocast,2020-12-08 20:53:59+00:00,,0,8,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
49023,Automatically rerun tests with CUDA_LAUNCH_BLOCKING=1 when they fail with CUDA errors in CI,2020-12-08 16:01:20+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged"")]"
49016,Discrete Cosine Transform,2020-12-08 13:09:19+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged"")]"
48998,Torch1.2 can't be downloaded!,2020-12-08 03:49:01+00:00,,0,1,"[Label(name=""triaged"")]"
48984,Scripting silently ignores methods of class derived from `NamedTuple`,2020-12-08 01:21:36+00:00,,1,5,"[Label(name=""oncall: jit"")]"
48972,non-negative least squares solver feature request,2020-12-08 00:16:57+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
48959,[Poll] Support DistributedDataParallel (DDP) in PyTorch C++ API (libtorch),2020-12-07 23:01:32+00:00,,0,21,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: ddp"")]"
48945,CUDA error: illegal memory access Conv3d,2020-12-07 20:07:54+00:00,,0,1,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
48932,Unknown builtin op: torchvision::nms when loading scripted FasterRCNN,2020-12-07 15:17:27+00:00,,0,11,"[Label(name=""oncall: jit"")]"
48929,Domain Specific Batch Normalization,2020-12-07 13:32:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
48928,"When multiple GPUs run multiple processes, it is found that any process not running in GPU 0 will have some more memory (such as 200m) in GPU 0. What is the cause of this?（多个GPU跑多进程时候，发现只要不在0号GPU跑的进程都会在0号GPU多出一些内存(如200M)，请问这是什么情况导致的？）",2020-12-07 11:28:55+00:00,,0,8,"[Label(name=""oncall: distributed"")]"
48900,addmm with out= argument returns incorrect result,2020-12-06 17:36:49+00:00,,0,9,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: partial aliasing""), Label(name=""module: linear algebra""), Label(name=""module: correctness (silent)""), Label(name=""module: structured kernels"")]"
48892,is_non_overlapping_and_dense() does not error out for sparse tensors ,2020-12-05 21:58:24+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
48878,Libtorch:  nvrtc: error: invalid value for --gpu-architecture (-arch),2020-12-05 05:46:54+00:00,,0,2,"[Label(name=""triaged"")]"
48869,Tracing fails sanity check ,2020-12-04 23:14:25+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""days"")]"
48845,memory_format kwarg doesn't work on most factory functions,2020-12-04 18:05:39+00:00,,0,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: memory format"")]"
48832,cudnn cannot be pickled by cloudpickle,2020-12-04 10:36:35+00:00,,0,7,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: serialization""), Label(name=""triaged"")]"
48830,"Please add ""dim"" feature for function ""torch.masked_select""",2020-12-04 09:13:17+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""needs design""), Label(name=""module: sorting and selection""), Label(name=""function request"")]"
48813,inception_v3 is not symbolically traceable,2020-12-03 23:26:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
48793,Weight_decay in torch.Adam,2020-12-03 17:06:20+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
48747,[bug][libtorch] torch::load seeks to the start of the input stream before reading,2020-12-02 21:51:43+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""needs design"")]"
48714,RTX 3090 setup vs 2x RTX 2080TI setup slower? Help..,2020-12-02 15:02:35+00:00,,0,17,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
48710,RuntimeError: CUDNN_STATUS_BAD_PARAM when testing environment,2020-12-02 12:17:48+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
48706,test_inverse setup is flaky using MKL>=2020.1 on certain CPUs and fails on CUDA,2020-12-02 10:57:28+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: mkl""), Label(name=""shadow review"")]"
48703,Caffe2 upsample do not support float times output_size,2020-12-02 08:59:53+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
48702,provide example for distributed training with iterative dataloaders ,2020-12-02 08:17:04+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
48684,Remove remaining native:: references from non-native ATen,2020-12-02 01:49:36+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
48667,Operator registration doesn't work with noexcept functions on some compilers (c10::guts::is_function_type rejects noexcept),2020-12-01 20:44:53+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
48650,[feature request] Keyword-only device argument (and maybe dtype) for torch.meshgrid,2020-12-01 13:17:40+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""feature""), Label(name=""triaged"")]"
48649,[docs] A single additional summary page for diag* methods,2020-12-01 11:59:14+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
48648,Confused on project website pointer.,2020-12-01 11:11:02+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
48645,Can sublist a nn.Sequential subclass,2020-12-01 08:20:22+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged"")]"
48641,"[bug] `torch.{sinh, cosh}`: Incorrect values for vectorized path",2020-12-01 06:27:32+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: sleef""), Label(name=""module: NaNs and Infs""), Label(name=""module: vectorization""), Label(name=""module: trigonometric functions"")]"
48628,Add docs on PyTorch - NumPy interaction,2020-12-01 00:04:53+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy"")]"
48626,Missing super().__init__() call in nn.Module,2020-11-30 23:28:24+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged"")]"
48621,[FR] loss reduction argument accepts None,2020-11-30 22:26:38+00:00,,0,0,"[Label(name=""module: loss""), Label(name=""triaged"")]"
48605,[NNC] Bugs Exposed in Binary Op Testing,2020-11-30 19:24:27+00:00,,2,3,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""NNC"")]"
48587,[feature request] Give `torch.cholesky` an optional fallback to test whether the tensor is positive definite,2020-11-30 15:13:56+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
48580,torch.save() fails when attempting to save to mounted drives,2020-11-30 13:25:57+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""module: serialization""), Label(name=""triaged"")]"
48579,test_fs_pool fails,2020-11-30 12:37:24+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: multiprocessing""), Label(name=""module: tests""), Label(name=""triaged"")]"
48559,[FR] torch.load should support loading directly to pinned/shared memory,2020-11-29 16:46:07+00:00,,0,2,"[Label(name=""high priority""), Label(name=""module: multiprocessing""), Label(name=""feature""), Label(name=""module: serialization""), Label(name=""triaged"")]"
48558,[FR] tensor ctors should support directly creating in shared memory,2020-11-29 16:41:33+00:00,,0,3,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
48555,segment fault for Image model training by four GPUs,2020-11-29 10:22:48+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
48549,JIT script has wrong signature for .norm,2020-11-29 06:57:42+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""days""), Label(name=""TSUsability""), Label(name=""TSRootCause:PyTorchParityGap"")]"
48548,at::size documentation conflict,2020-11-29 04:13:14+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged"")]"
48526,CARU: A Content-Adaptive Recurrent Unit for the Transition of Hidden State in NLP,2020-11-28 04:04:11+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
48525,TorchScript input tensor size,2020-11-28 03:03:46+00:00,,2,1,"[Label(name=""oncall: jit"")]"
48518,C++ optimizer check for duplicate parameters,2020-11-27 14:57:55+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
48511,Ambiguous RuntimeError raised when device of input PackedSequence does not match with nn.LSTM's device,2020-11-27 06:50:36+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
48494,Inconsistent type of property stride of Conv1d and MaxPool1d,2020-11-26 17:21:49+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""module: ux"")]"
48491,SegmentationFault when pytorch is installed from source.,2020-11-26 15:55:55+00:00,,0,4,"[Label(name=""module: crash""), Label(name=""module: build""), Label(name=""triaged"")]"
48486,[complex] torch.abs: does not match numpy ,2020-11-26 10:34:18+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy""), Label(name=""module: NaNs and Infs"")]"
48485,Add wheels for all cuda versions on pypi,2020-11-26 10:34:15+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
48483,Vulkan Api Backend Build Error with GCC,2020-11-26 09:47:47+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
48478,Callbacks of Futures shouldn't wait inline on another future,2020-11-26 08:50:00+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: ddp"")]"
48466,[master] new default signature: op=<ReduceOp.SUM: 0>from `op=<ReduceOp.SUM>,2020-11-26 00:12:30+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged"")]"
48465,anchored direct links to functions disappeared in 1.7.0 docs,2020-11-25 23:58:54+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
48457,compile error immintrin.h,2020-11-25 17:34:00+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
48452,After updating to Xcode 12 and LibTorch to 1.7.0. Facing issue when running unit test.,2020-11-25 12:34:16+00:00,,1,8,"[Label(name=""oncall: jit""), Label(name=""oncall: mobile""), Label(name=""module: ios""), Label(name=""module: arm"")]"
48450,"Qt 5.14.2, libtorch1.7.0 cuda10.2，Error after using header file",2020-11-25 11:25:42+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: static linking"")]"
48439,cudnn convolution modifies the input Tensor metadata inplace when it tries to `.resize_()` it,2020-11-25 07:16:16+00:00,,1,10,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: memory format"")]"
48419,pin_memory=True in DataLoader converts a tuple to list automatically,2020-11-24 13:08:51+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
48410,PyTorch Mobile speed_benchmark_torch crashes on mobile optimized model,2020-11-24 04:33:08+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
48408,TorchScript: Optional sized lists cannot be called with optional scalar values,2020-11-24 01:40:47+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""days"")]"
48400,conv_transpose3d returns different result when the input and kernel are mkldnn tensors,2020-11-23 19:00:17+00:00,,1,2,"[Label(name=""high priority""), Label(name=""module: dependency bug""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
48389,"Add parameter ""half_pixel_center =False"" to the Bilinear function",2020-11-23 11:49:35+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: interpolation"")]"
48387,"Error occurred when trying to call ""torch::jit::load""method for loading "".pt"" file on IOS",2020-11-23 10:55:55+00:00,,0,8,"[Label(name=""oncall: jit""), Label(name=""oncall: mobile"")]"
48382,hangs indefinitely at os.waitpid(),2020-11-23 02:25:34+00:00,,0,8,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""module: multiprocessing""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
48377,Management of Gpu memory to avoid memory errors,2020-11-22 16:18:06+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
48366,Add Go to high level interface,2020-11-21 19:39:21+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
48365,Custom exception for out of memory,2020-11-21 16:40:09+00:00,,1,7,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""triaged""), Label(name=""better-engineering"")]"
48353,[FR] bool tensor should support basic arithmetics,2020-11-21 02:37:10+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: type promotion""), Label(name=""module: boolean tensor"")]"
48338,torch.float128 datatype,2020-11-20 22:35:44+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
48325,[JIT] Constant Propagation Shouldn't Run on Values that Escape the Graph,2020-11-20 19:16:22+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""days"")]"
48307,Provide torchscript support for staticmethods for classes derived from Enum,2020-11-20 13:18:00+00:00,,1,1,"[Label(name=""oncall: jit"")]"
48306,[doc] example for pairwise distance matrix,2020-11-20 11:33:27+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: distance functions"")]"
48305,[RFC] CUDA-aware future for distributed,2020-11-20 10:00:06+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: c10d"")]"
48291,pytorch is not linked with support for cuda devices,2020-11-20 02:45:08+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
48287,"[doc] Error ""You've reached a dead end"" when opening torch.__config__ in the docs",2020-11-20 01:18:54+00:00,,0,9,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
48281,Batched inplace mm changes stride when out size is correct,2020-11-20 00:00:59+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: linear algebra""), Label(name=""module: correctness (silent)"")]"
48279,"Pytorch streams API don't execute concurrently, However Same code in CUDA does. ",2020-11-19 23:55:16+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
48273,torch.multinomial example is incorrect,2020-11-19 21:01:12+00:00,,0,5,"[Label(name=""module: distributions""), Label(name=""module: docs""), Label(name=""triaged"")]"
48251,torch.eye(d) is slow and hogs cpu for d >= 182,2020-11-19 10:34:50+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""good first issue""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
48246,[RFC] XPU device for PyTorch,2020-11-19 08:36:34+00:00,,0,16,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: intel"")]"
48245,"RuntimeError: ""threshold_cpu"" not implemented for 'Half'",2020-11-19 08:32:51+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: half"")]"
48243,torch.save writes file even when pickle fails,2020-11-19 07:14:06+00:00,,0,3,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
48235,Softplus differs depending on number of elements in tensor,2020-11-19 04:33:32+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
48227,Modifying values() tensor of COO tensor requiring grad throws an odd error message,2020-11-19 00:35:46+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
48209,[FX] Write an inference optimization pass,2020-11-18 22:30:07+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
48203,Document torch.distributed.destroy_process_group(),2020-11-18 21:27:45+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: c10d"")]"
48202,"""Found no NVIDIA driver"" produces too much log",2020-11-18 21:13:13+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
48191,[JIT] Contained Module Attributes should be recursively compiled,2020-11-18 18:32:10+00:00,,1,1,"[Label(name=""oncall: jit"")]"
48177,Support for oneDNN / MKL-DNN on AArch64,2020-11-18 15:06:02+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: arm"")]"
48167,[libtorch] Build shared library with libtorch and compile a static library,2020-11-18 09:04:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: static linking"")]"
48163,nn.functional.interpolate backward in fp16 is extremely slow,2020-11-18 07:04:32+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""module: interpolation"")]"
48153,More robust list comprehension ,2020-11-18 03:47:32+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""weeks"")]"
48108,JIT should not force users to write ugly code,2020-11-17 18:12:42+00:00,,0,12,"[Label(name=""oncall: jit""), Label(name=""TSUsability"")]"
48106,quantization - document get_default_qconfig,2020-11-17 17:28:06+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
48094,[JIT][PE] Profiling Executor should re-profile `DifferentiableGraph`,2020-11-17 13:37:36+00:00,,0,0,"[Label(name=""oncall: jit"")]"
48090,[JIT] Constant folding on no-op `aten::mul`,2020-11-17 12:47:02+00:00,,0,0,"[Label(name=""oncall: jit"")]"
48089,[JIT] Optimization pass in profiling executor to fold away conditional branches,2020-11-17 12:22:31+00:00,,0,0,"[Label(name=""oncall: jit"")]"
48088,[dataloader] Worker threads to print the signal they received before they die,2020-11-17 11:11:08+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
48083,CPU Tensor with Python MP Freezing in Docker Container,2020-11-17 08:12:36+00:00,,0,2,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: docker"")]"
48082,Microsoft C++ exception: torch::jit::ErrorReport at memory location 0x0000001C0C3BBB40.,2020-11-17 06:51:03+00:00,,0,13,"[Label(name=""oncall: jit"")]"
48066,[JIT] Saving and Loading JIT Model Does Not Preserve __dir__,2020-11-17 00:11:20+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""days"")]"
48064,FAILED: test_api/CMakeFiles/test_api.dir/dataloader.cpp.o ,2020-11-17 00:06:34+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
48054,RuntimeError: NYI: Named tensors are not supported with the tracer,2020-11-16 22:34:04+00:00,,0,1,"[Label(name=""oncall: jit"")]"
48045,"[NNC] Improve ""UNSUPPORTED DTYPE"" error messages ",2020-11-16 21:23:55+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""NNC"")]"
48033,Missing -fopenmp when used in torchvision,2020-11-16 19:57:36+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cpp-extensions""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: build warnings""), Label(name=""module: openmp"")]"
48010,[complex] torch.{exp}: does not match numpy,2020-11-16 09:22:17+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy""), Label(name=""module: correctness (silent)"")]"
48000,Inconsistent complex results with NumPy when computing non-positive power of 0,2020-11-16 06:19:48+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy""), Label(name=""module: NaNs and Infs"")]"
47999,Torch DDP seems not prefer IPv6 over IPv4?,2020-11-16 05:21:11+00:00,,1,6,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
47996,GPU Vendor-Agnosticism via Vulkan,2020-11-16 03:19:15+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: vulkan"")]"
47993,"build pytorch from source on ubuntu, building error from fbgemm::SparseAdaGradSignature",2020-11-16 01:00:12+00:00,,0,31,"[Label(name=""module: build""), Label(name=""module: collect_env.py""), Label(name=""triaged"")]"
47990,Is nn.Conv2d equivalent with Unfold + Matrix Multiplication + Fold ?,2020-11-15 22:12:00+00:00,,0,10,"[Label(name=""needs reproduction""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
47988,Support calls to super().function() by implementing (poor man's) inheritance ,2020-11-15 21:19:58+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""TSRootCause:DynamicBehaviors"")]"
47964,TorchScript is unable to distinguish int and ScalarType,2020-11-14 06:29:32+00:00,,1,14,"[Label(name=""oncall: jit""), Label(name=""weeks""), Label(name=""TSRootCause:DefaultTypes""), Label(name=""TSUsability"")]"
47954,[Feature] torch.bitwise_where,2020-11-14 01:10:29+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""shadow review"")]"
47953,Linear algebra GPU backend tracking issue [magma/cusolver/cublas],2020-11-14 00:51:02+00:00,,0,9,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
47931,Unknown DispatchKey when indexing tensor with named dimensions,2020-11-13 19:52:22+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""module: named tensor"")]"
47918,Function request: Sparse matrix inverse,2020-11-13 16:22:49+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""function request"")]"
47917,LibTorch cannot load PyTorch exported model,2020-11-13 15:45:40+00:00,,0,15,"[Label(name=""module: docs""), Label(name=""module: serialization""), Label(name=""triaged"")]"
47916,Hash mismatch for METADATA file,2020-11-13 15:36:05+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
47915,sparse filter layers (more specifically convolutions),2020-11-13 15:17:20+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""function request"")]"
47912,Code becomes more than x20 slower after upgrading torch version,2020-11-13 14:18:50+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""triaged"")]"
47908,The speed of pytorch with cudatoolkit 11.0 is slower than cudatoolkit 10.2,2020-11-13 08:38:08+00:00,,0,54,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
47906,amp for custom op,2020-11-13 07:32:15+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: custom-operators""), Label(name=""module: amp (automated mixed precision)"")]"
47904,Memory leak in nn.MaxPool2d layer when run on iOS,2020-11-13 06:34:39+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: ios"")]"
47901,"Get forward output, grad, hessian all at once",2020-11-13 06:22:02+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement"")]"
47887,"ONNX export of a scripted submodule fails with ""Modules that are called during a trace must be registered as submodules of the thing being traced""",2020-11-13 01:09:04+00:00,,0,19,"[Label(name=""oncall: jit""), Label(name=""module: onnx""), Label(name=""onnx-triaged"")]"
47885,NCCL 2.7.8 errors on PyTorch distributed process group creation,2020-11-12 22:40:55+00:00,,0,23,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
47883,`.modules()` is not callable in TorchScript when any submodule is a module interface type (i.e. a class decorated by `@torch.jit.interface`),2020-11-12 22:23:32+00:00,,0,2,"[Label(name=""oncall: jit"")]"
47857,QAT with DDP should have documentation,2020-11-12 16:29:12+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
47844,Incorrect output loss value under specific CUDA version,2020-11-12 09:32:46+00:00,,0,10,"[Label(name=""high priority""), Label(name=""module: dependency bug""), Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: tf32"")]"
47841,Factorial & Binomial Coefficient,2020-11-12 08:37:37+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
47832,Error during distributed training,2020-11-12 06:02:33+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
47824,"DDP error, when I use ""if"" branch in forward function.",2020-11-12 03:30:26+00:00,,0,3,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: ddp"")]"
47778,Eliminate redundant device guards in generic dispatch key kernel wrappers,2020-11-11 20:33:22+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
47753," Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2",2020-11-11 15:09:41+00:00,,0,9,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
47751,Make libtorch modular,2020-11-11 13:52:28+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: selective build"")]"
47743,Cudnn header files should be copied into build package as well ,2020-11-11 09:44:45+00:00,,0,27,"[Label(name=""module: windows""), Label(name=""triaged""), Label(name=""windows-triaged"")]"
47739,Conda package should install libtorch in the standard location,2020-11-11 08:44:30+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
47702,GPU acceleration for Apple's M1 chip?,2020-11-10 22:05:54+00:00,,0,183,"[Label(name=""module: performance""), Label(name=""triaged"")]"
47699,DCNv2 Layers,2020-11-10 20:44:45+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request"")]"
47692,pyre not able to infer the type of torch.jit.script,2020-11-10 19:32:04+00:00,,1,2,"[Label(name=""oncall: jit"")]"
47688,ARM Mac 16-core Neural Engine,2020-11-10 19:00:32+00:00,,0,18,"[Label(name=""feature""), Label(name=""triaged"")]"
47682,Common dunder methods fail when called directly,2020-11-10 17:07:35+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""days"")]"
47681,How to install Pytorch on AIX7.2 without internet access?,2020-11-10 17:02:24+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
47669,Pytorch 1.7.0 with cuda 11.1.1 and cudnn 8.0.5,2020-11-10 12:23:20+00:00,,0,20,"[Label(name=""module: cuda""), Label(name=""oncall: releng""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement"")]"
47650,DataParallel support for scripted modules in C++,2020-11-10 04:46:46+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
47649,error: reference to __host__ function 'parallel_for<thrust::cuda_cub::for_each_f...' in __host__ __device__ function,2020-11-10 03:50:43+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
47627,Allow add_embedding to have dict for metadata,2020-11-09 21:44:09+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
47610,Input dimension check for `torch.gather`,2020-11-09 18:15:47+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
47609,Error while trying to load a pretrained ResNet34 VTN (Video Transformer Network) model in Android,2020-11-09 17:45:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: mobile"")]"
47591,PyTorch1.3.1 Can not using namespace torch::indexing,2020-11-09 06:42:52+00:00,,0,4,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
47588,Can we apply Weight normalization hook to a method other than `forward`?,2020-11-09 03:14:04+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: norms and normalization"")]"
47582,torch.nn.Module.apply cyclical references unbounded,2020-11-08 20:08:21+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged"")]"
47568,Failed to get generated_cpp list,2020-11-08 07:59:23+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
47565,Keyword-only function not allowed with TorchScript,2020-11-08 01:32:45+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""OSS contribution wanted""), Label(name=""days"")]"
47563,Handling multiple large-scale datasets efficiently ,2020-11-07 18:58:00+00:00,,0,5,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
47560,Minumul LR is never reached in ,2020-11-07 15:39:37+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
47557,Ninja-built CUDAExtension build process ignores changed #include dependencies,2020-11-07 12:53:22+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
47546,Whats Pytorch's policy on adding support for a wider range of hardwares for training and inference? ,2020-11-07 04:39:28+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: backend"")]"
47535,per channel observer to work for weights of groupwise conv transpose,2020-11-06 23:32:41+00:00,,0,4,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
47513,ReduceLROnPlateau fails for negative input,2020-11-06 19:35:25+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
47502,Hackable python-only autograd engine,2020-11-06 16:33:23+00:00,,0,6,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
47481,[fx] scripting a model with tensor list as input fails,2020-11-06 00:55:11+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
47476,Reciprocal and reciprocal square root instructions are too inaccurate on ARM64,2020-11-06 00:20:41+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: correctness (silent)""), Label(name=""module: arm"")]"
47447,"thread blocked when moving a tensor from GPU to CPU, by calling the function .cpu() in pytorch. This kind of block can be stop by any window event like mouse moving/clicking or keyboard pressing.",2020-11-05 16:46:46+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: cpu""), Label(name=""triaged"")]"
47439,how to use torch.utils.checkpoint + gru with variable length sequence?,2020-11-05 13:25:06+00:00,,0,3,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
47433,unbalanced gpu memory when using DistributedDataParallel,2020-11-05 08:22:38+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
47422,[Discussion] Use the unicode variant of the Windows API,2020-11-05 04:11:50+00:00,,0,21,"[Label(name=""module: windows""), Label(name=""module: internals""), Label(name=""triaged"")]"
47378,torch.vmap giving INTERNAL ASSERT FAILED error,2020-11-04 19:08:19+00:00,,0,13,"[Label(name=""triaged""), Label(name=""module: vmap"")]"
47363,FX quantization: we should preserve original model class name through the quantization passes,2020-11-04 17:20:27+00:00,,1,7,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
47357,Conv1D formula in docs is wrong,2020-11-04 14:01:40+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
47351,no member named 'beta1' in 'torch::optim::AdamOptions',2020-11-04 09:32:49+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""actionable"")]"
47342,My demo app uses other package name will crash but org.pytorch.demo,2020-11-04 06:47:05+00:00,,0,2,"[Label(name=""oncall: mobile"")]"
47341,ConvTranspose1d groups=channels is very slow!!!,2020-11-04 06:41:49+00:00,,0,5,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
47336,[jit] Properly support slicing of ModuleList,2020-11-04 03:42:11+00:00,,0,2,"[Label(name=""oncall: jit"")]"
47335,[jit] support length inference for list comprehension,2020-11-04 03:36:34+00:00,,0,2,"[Label(name=""oncall: jit"")]"
47311,Quantized modules should properly implement __getstate__ and __setstate__ (copy.deepcopy doesn't work on quantized model),2020-11-03 20:30:45+00:00,,0,5,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
47307,[Feature request] Stochastic Frank-Wolfe optimizer,2020-11-03 20:05:00+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
47291,ProcessGroupNCCL NCCL lib version mismatch,2020-11-03 17:09:47+00:00,,0,7,"[Label(name=""module: binaries""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
47281,Error: invalid use of register,2020-11-03 15:18:51+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
47265,[Feature Request] tensorboard add_graph support for multiple method,2020-11-03 07:13:10+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
47260,DDP doesn't work with retain_graph = True,2020-11-03 04:03:44+00:00,,1,6,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
47218,[JIT] Alias Annotations for Native Schema List Ops Is Subtly Wrong,2020-11-02 19:52:37+00:00,,0,2,"[Label(name=""high priority""), Label(name=""oncall: jit""), Label(name=""days""), Label(name=""weeks"")]"
47217,RuntimeError: Exporting the operator quantize_per_tensor to ONNX opset version 10 is not supported.,2020-11-02 19:50:31+00:00,,0,33,"[Label(name=""module: onnx""), Label(name=""feature""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""onnx-needs-info"")]"
47208,[RFC] Add test execution time analysis CI workflow,2020-11-02 18:39:18+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
47201,torch.save has a maximum size regardless of RAM,2020-11-02 17:49:56+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""function request"")]"
47177,LayerNorm on Android will cause very high cpu usage,2020-11-02 02:05:37+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
47175,[feature request] Show warning if optimizer.zero_grad() was not called before optimizer.step(),2020-11-01 21:00:24+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: ux"")]"
47163,Grad strides do not match bucket view strides.,2020-11-01 09:48:49+00:00,,0,14,"[Label(name=""oncall: distributed""), Label(name=""module: memory format""), Label(name=""module: ddp"")]"
47162,Custon C++ classes are not traceable ,2020-11-01 05:57:41+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
47161,segfault during shutdown with torch1.7,2020-10-31 21:50:33+00:00,,0,3,"[Label(name=""module: dependency bug""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: pybind""), Label(name=""module: third_party"")]"
47149,Allow all torch.nn modules to accept arbitrary batch dimensions,2020-10-31 07:41:52+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: batching""), Label(name=""module: ux"")]"
47128,AMP doesn't gracefully handle optimizers for disabled regions,2020-10-30 18:38:28+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
47117,ctx.save_for_backward doesn't save torch.Tensor subclasses fully,2020-10-30 14:43:00+00:00,,0,26,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs design""), Label(name=""module: __torch_function__"")]"
47116,trying to Installing pytorch on python3.9 via pip results in an non-descript error,2020-10-30 13:04:51+00:00,,0,13,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
47111,THCudaShutdown should be called before THCState_free,2020-10-30 09:25:13+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
47109,Pytorch 1.7/Cuda 11.1 binaries,2020-10-30 08:43:01+00:00,,0,22,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
47056,Training slows down and memory usage increases when upgrading from PyTorch 1.6 to 1.7,2020-10-29 15:55:44+00:00,,0,15,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: amp (automated mixed precision)"")]"
47055,"[types] torch.utils.data.{Dataset, Sampler} are not Sized",2020-10-29 15:27:53+00:00,,0,18,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research""), Label(name=""module: data"")]"
47052,Activation functions for complex tensors,2020-10-29 14:55:35+00:00,,0,20,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""function request"")]"
47051,Tensor subclasses lose type when pickling,2020-10-29 13:45:54+00:00,,0,7,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: __torch_function__"")]"
47037,"Change ""_next_index()"" in DataLoader to a public and stable API",2020-10-29 02:39:22+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""needs research"")]"
47028,torch.autograd.backward() fails to sync with other stream,2020-10-28 22:51:49+00:00,,1,7,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
47027,Fix the way imports are done to be more correct for static type checkers,2020-10-28 22:43:42+00:00,,1,31,"[Label(name=""module: typing""), Label(name=""triaged""), Label(name=""enhancement"")]"
47010,[JIT] Tracing turns None Device Input into a Constant,2020-10-28 19:42:15+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
46999,"torch.sum(tensor(2.), dim=0) (and probably other reduction functions) doesn't make sense",2020-10-28 17:26:03+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: reductions"")]"
46995,max_pool2d always fails on native Android app,2020-10-28 16:56:08+00:00,,0,7,"[Label(name=""oncall: mobile"")]"
46980,torch.acos not supported for sparse layout,2020-10-28 10:41:48+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""function request"")]"
46979,[JIT] scripting torchaudio.transforms.MFCC() error ,2020-10-28 09:58:07+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
46971,Yolov5 detect.py(ingerence) Error:Torch.nn.modules.module.ModuleAttributeError: 'Hardswish' object has no attribute 'inplace',2020-10-28 07:15:10+00:00,,0,12,"[Label(name=""module: nn""), Label(name=""module: pickle""), Label(name=""triaged"")]"
46948,Record shaping assertions and use them for tracing / scripting optimization and codegen,2020-10-27 22:03:28+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: codegen"")]"
46947,Add Optimistic Mirror Descent (OMD),2020-10-27 21:51:11+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
46946,Changing order of field assignments breaks TorchScript classes,2020-10-27 21:31:07+00:00,,1,2,"[Label(name=""oncall: jit"")]"
46944,Export TorchScript Classes as TorchScript code,2020-10-27 21:23:33+00:00,,1,3,"[Label(name=""oncall: jit"")]"
46929,Pooling code does not allow sliding window starting in right padded region,2020-10-27 17:38:33+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: pooling"")]"
46918,Jacobians computed by autograd.functional.jacobian with compute_graph sometimes set requires_grad True,2020-10-27 15:08:15+00:00,,0,9,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
46907,SummaryWriter deletes data automatically when there are too many,2020-10-27 11:07:01+00:00,,0,5,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
46904,Authentication for RPC,2020-10-27 08:54:48+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
46902,How to use clang as a cuda compiler instead of nvcc?,2020-10-27 05:52:23+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement"")]"
46899,CUDA out of memory when using torch.load,2020-10-27 03:03:27+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
46886,Support deleting a parameter/buffer by name,2020-10-26 23:12:05+00:00,,0,6,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: ux"")]"
46869,[META] DO NOT DELETE THIS LABEL,2020-10-26 19:33:36+00:00,,0,1,"[Label(name=""triaged""), Label(name=""open source""), Label(name=""fb-exported""), Label(name=""Merged"")]"
46829,Mixing Numpy's arrays and PyTorch tensors,2020-10-26 00:39:36+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""needs design""), Label(name=""module: ux"")]"
46822,C++ Optimizer: remove warning on Optimizer::size method,2020-10-25 14:27:18+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""better-engineering"")]"
46820,simple v *=  v_scale error,2020-10-25 13:29:37+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
46819,Specify input dimensions where they are not obvious,2020-10-25 13:24:35+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
46809,Including AdaBound in the list of Optimizers. ,2020-10-24 08:19:12+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
46807,[cudatoolkit 11.0] segfaults,2020-10-24 06:37:02+00:00,,0,17,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
46806,Compile Pytorch with MAGMA Issue,2020-10-24 06:01:35+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
46803,About 2 minor bug fixes on CUDA macOSX 10.13.6,2020-10-24 04:33:25+00:00,,0,6,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: nnpack"")]"
46802,"DataLoader gives ""Broken pipe"" error on Linux platform",2020-10-24 04:13:24+00:00,,0,6,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
46787,Clearer error messages for 'different devices' error in the RNN module,2020-10-23 21:17:48+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
46766,Unable to compile from code v1.6.0,2020-10-23 14:40:13+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
46760,How to define a new data type in  native_functions.yaml?,2020-10-23 09:04:27+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged"")]"
46753,Memory leak when creating new tensors inside nn.DataParallel on multiple GPUs,2020-10-23 02:12:05+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
46749,Quantization - we need a better solution for tracking quantization backend settings in a model,2020-10-23 00:41:49+00:00,,1,33,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
46739,torch.utils.tensorboard.SummaryWriter.add_embedding fails for some label_img sizes,2020-10-22 20:54:22+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
46724,PROBLEM WITH INSTALLATION PYTORCH FROM SOURCE,2020-10-22 17:44:07+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
46712,The documentation for c10::Dict is completely empty.,2020-10-22 14:55:18+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: internals""), Label(name=""module: cpp""), Label(name=""triaged"")]"
46711,A random split function that return the datasets following specific target (label) distribution.,2020-10-22 13:41:52+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: data"")]"
46705,torch.eye not supported for sparse layout,2020-10-22 10:13:50+00:00,,1,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""function request"")]"
46659,Excluding image processing operators due to no opencv,2020-10-21 17:26:54+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
46654,Converting object detector model to TorchScript,2020-10-21 14:53:48+00:00,,0,1,"[Label(name=""oncall: jit"")]"
46653,Future returned by RPC should print a warning message on destruction if it's not waited,2020-10-21 14:52:32+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: rpc"")]"
46644,Trying to compile PyTorch for sm_30 fails with `error: identifier “__ldg” is undefined`,2020-10-21 07:05:31+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
46643,Autograd support for the tensor multiplication of sparse tensors,2020-10-21 06:41:31+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""function request"")]"
46642,Loss functions for complex tensors ,2020-10-21 05:19:31+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""complex_autograd"")]"
46631,error in bazel build //...,2020-10-21 00:53:12+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: bazel"")]"
46604,torch.concat doesn't raise an error in a quantized model,2020-10-20 18:52:05+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
46597,Suggestion: link individual APIs in docs with tutorials that use them,2020-10-20 17:24:15+00:00,,2,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
46574,Mismatch between the documentation and implementation of caffe2 PReLU operator,2020-10-20 05:57:08+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""module: docs"")]"
46564,Clean up request_callback_no_python.cpp,2020-10-19 22:36:14+00:00,,2,5,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
46559,Exception raised in rpc_async context is silently handled,2020-10-19 20:33:47+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
46544,PyTorch NaN behavior and API design,2020-10-19 17:44:02+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: NaNs and Infs""), Label(name=""needs design""), Label(name=""module: ux"")]"
46531,`torch.igamma` error and gives wrong results on float64 ROCm,2020-10-19 10:07:13+00:00,,0,0,"[Label(name=""high priority""), Label(name=""module: rocm""), Label(name=""triaged""), Label(name=""module: correctness (silent)"")]"
46530,[Request] Batched Dataset->DataLoader interface,2020-10-19 09:39:36+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
46522,ModuleNotFoundError when installing PyTorch via pip on aarch64 environment,2020-10-18 15:46:02+00:00,,0,14,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: arm"")]"
46516,Batchnorm support for tracking buffer statistics when using gradient accumulation ,2020-10-17 15:13:11+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research""), Label(name=""module: norms and normalization"")]"
46505,Cannot script when a static method or cross module function calls custom op,2020-10-17 01:27:27+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""module: cpp-extensions""), Label(name=""internals""), Label(name=""module: torchbind"")]"
46491,cannot call rpc.init_rpc twice within a single process,2020-10-16 21:00:28+00:00,,0,6,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
46468,Advanced indexing: allow combining Boolean & integer index,2020-10-16 14:33:11+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing""), Label(name=""function request"")]"
46464,[META] Assert that expected libraries appear in libtorch,2020-10-16 14:09:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: static linking""), Label(name=""enhancement"")]"
46460,C++ API: Training and inference of torchscript modules on multiple GPU,2020-10-16 13:18:51+00:00,,1,0,"[Label(name=""oncall: jit"")]"
46428,send_object/recv_object APIs for c10d,2020-10-15 22:01:35+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d"")]"
46409,Custom ops get stuck in multiprocess data loader under certain environments,2020-10-15 18:51:50+00:00,,0,10,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""module: custom-operators"")]"
46400,Make Undefined reprensentable in DispatchKeySet. ,2020-10-15 16:31:52+00:00,,1,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
46386,"GPU memory leak when registering a forward hook with ""self"" access",2020-10-15 09:19:34+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""has workaround"")]"
46382,"Code asserts when register new aten operations' implementation thru ""c10::RegisterOperators::op"" API. ",2020-10-15 07:24:21+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""triaged"")]"
46381,[Feature] Imbalanced batch scattering in th.nn.DataParallel,2020-10-15 07:23:10+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
46379,"Reduce ""reserved"" memory by PyTorch.",2020-10-15 06:44:31+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
46375,JIT: error in LSTM with `flatten_parameters`,2020-10-15 02:54:19+00:00,,0,4,"[Label(name=""oncall: jit"")]"
46374,Complex Number support for torch.nn modules,2020-10-15 02:45:45+00:00,,0,13,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: complex"")]"
46368,[JIT] Inconsistent behavior of torchScript parser in python and c++,2020-10-15 01:04:32+00:00,,1,1,"[Label(name=""oncall: jit"")]"
46367,[chore] Test pybind11 2.6.0 (RC 2?),2020-10-15 00:23:41+00:00,,0,20,"[Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement"")]"
46350,torch.distributions.half_normal.HalfNormal.cdf returns negative values,2020-10-14 22:14:34+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
46334,A race problem of JIT cpp extensions in distributed setting,2020-10-14 19:09:00+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""days"")]"
46321,Add distributed examples into PyTorch CI tests,2020-10-14 16:08:28+00:00,,1,3,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""module: tests""), Label(name=""triaged"")]"
46319,Remove header declarations for CPUType/TypeDefault,2020-10-14 14:33:27+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
46311,"Compile error when use c10::RegisterOperators::Options::kernel with the return type ""std::tuple<Tensor&, Tensor&>""",2020-10-14 07:22:35+00:00,,1,2,"[Label(name=""module: internals""), Label(name=""triaged"")]"
46291,ProcessGroup::Work API changes,2020-10-13 22:18:10+00:00,,0,0,"[Label(name=""module: bc-breaking""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""topic: bc breaking"")]"
46276,test_distributed_* does not show error details from the subprocess,2020-10-13 20:13:40+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup"")]"
46272,test_distributed_* does not work with run_test.py -i option,2020-10-13 19:53:35+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""pt_distributed_rampup"")]"
46254,Enable named tensor inputs to `torch.linalg.norm`,2020-10-13 16:51:58+00:00,,1,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: named tensor"")]"
46253,Add short guide for updating `torch.norm` calls to `torch.linalg.norm`,2020-10-13 16:49:40+00:00,,1,16,"[Label(name=""module: docs""), Label(name=""triaged"")]"
46248,"""distributed"" NCCL tests fail when having more than 3 GPUs",2020-10-13 14:41:51+00:00,,0,12,"[Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""module: ddp"")]"
46241,ubuntu16.04+vscode compile libtorch error,2020-10-13 12:01:44+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
46240,"Support ""symmetric"" reflection padding",2020-10-13 11:55:07+00:00,,0,11,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: padding""), Label(name=""module: tensorflow"")]"
46225,torch.mode when input has nans,2020-10-13 00:20:33+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: NaNs and Infs""), Label(name=""module: sorting and selection""), Label(name=""module: reductions"")]"
46222,Use better tempfile creation mechanism to avoid skip windows test,2020-10-12 22:52:13+00:00,,0,8,"[Label(name=""module: tests""), Label(name=""triaged"")]"
46210,[FX]Add support for len() on Proxy,2020-10-12 20:03:53+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: fx"")]"
46202,pytorch not uploading data to tensorboard page,2020-10-12 18:03:00+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
46187,Better support for operators that return (named) tuples of tensors,2020-10-12 16:00:46+00:00,,0,34,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation""), Label(name=""module: ux"")]"
46184,redesign of Dropout,2020-10-12 15:21:17+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
46178,"torch.cuda.amp!  when I use @autocast() on DCN(DeformConv), the error ""RuntimeError:expect scalar type Float but Half """,2020-10-12 11:12:06+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
46176,BucketSampler for easy variable-length input batching,2020-10-12 09:00:26+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
46169,Squared 2-norm pdist (as available in SciPy / Faiss),2020-10-11 21:57:52+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: norms and normalization""), Label(name=""module: distance functions"")]"
46168,[discussion] In-place gradient (grad_input) computation for better memory utilisation,2020-10-11 21:25:43+00:00,,0,18,"[Label(name=""module: autograd""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""needs research"")]"
46166,Error with DistributedDataParallel with specific model,2020-10-11 19:39:39+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
46164,Deprecate spmm and dsmm functions,2020-10-11 17:06:07+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""open source""), Label(name=""module: linear algebra""), Label(name=""module: deprecation"")]"
46158,No improvement gain between sm_86 (cuda 11.1) and sm_80 (cuda 11.0) on 3090 or 3080 GPUs.,2020-10-11 11:24:16+00:00,,0,35,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
46157,Ability to disable cusolver,2020-10-11 10:47:25+00:00,,0,6,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
46155,Complex backward returns NaN values,2020-10-11 10:05:13+00:00,,0,16,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""complex_autograd"")]"
46153,Getting this error while installing torch and torchvision!,2020-10-11 07:11:35+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
46149,seeding does not work when I initialize a linear model even if I do not use it in the code,2020-10-10 22:06:53+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
46139,"Policy CMP0012   is not set, CMake, Building For C++ With PyTorch CUDA",2020-10-10 10:54:48+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""better-engineering"")]"
46102,test_cat_cuda (__main__.TestTensorExprFuser) fails,2020-10-09 18:36:59+00:00,,1,8,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""shadow review"")]"
46093,"Spawn wrapper should catch BaseException, not Exception",2020-10-09 15:50:51+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""better-engineering"")]"
46084,"In PyTorch Tutorials, RuntimeError: CUDA error: out of memory happen",2020-10-09 08:17:58+00:00,,0,2,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
46076,NCCL watchdog thread should log warnings about long-running GPU operations instead of silently hanging,2020-10-09 02:23:07+00:00,,1,1,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""pt_distributed_rampup""), Label(name=""module: c10d"")]"
46066,TestXNNPACKConv1dTransformPass.test_conv1d_with_relu_fc takes 2+ min to finsh,2020-10-08 23:37:58+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
46065,TestDataLoader.test_proper_exit takes 2.5min to finish,2020-10-08 23:34:26+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
46061,Support undispatched ops in codegen,2020-10-08 22:41:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
46035,"Error installing on source: ""src.cxx:1:10: fatal error: glog/stl_logging.h: No such file or directory""",2020-10-08 15:52:10+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
46031,Custom attention,2020-10-08 10:26:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
46027,Padding mode for ConvTransposeNd,2020-10-08 09:24:50+00:00,,0,2,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""function request"")]"
46024,Reproducibility breaks down with weighted Cross Entropy loss,2020-10-08 07:38:58+00:00,,0,11,"[Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility""), Label(name=""module: determinism"")]"
45996,Backpropagation for sparse matrix indexing is problematic (colab provided),2020-10-07 21:50:59+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
45943,Improve distributed documentation for NCCL_BLOCKING_WAIT ,2020-10-07 01:59:07+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""pt_distributed_rampup""), Label(name=""module: ddp"")]"
45910,with torch.cuda.amp.autocast() get out of memory error when using with torch.no_grad() during validation,2020-10-06 17:29:48+00:00,,1,7,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
45901,Add support for reading the whole file in from_file,2020-10-06 15:22:57+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
45897,Unify matrix multiplications operations,2020-10-06 13:31:48+00:00,,0,13,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""open source""), Label(name=""module: linear algebra"")]"
45855,Do we have plan to offer C++ binding for prune related features. ,2020-10-05 18:00:44+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: pruning"")]"
45851,The same function can have different signatures in  the torch and torch.nn.functional namespaces,2020-10-05 17:25:04+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
45840,Error with DataParallel and dataclass,2020-10-05 14:46:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
45833,Support torch.mean for BoolTensors and other integer tensor inputs (without manual upcasting and hopefully without hidden upcasting),2020-10-05 11:23:56+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: type promotion""), Label(name=""module: reductions"")]"
45823,"Traceback for ""Warning: Mixed memory format inputs detected while calling the operator.""",2020-10-04 19:32:31+00:00,,1,7,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
45808,Support for Locality Sensitive Hashing Optimizations,2020-10-03 19:30:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""needs research"")]"
45769,F.conv2d() causes RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR ,2020-10-02 20:30:31+00:00,,0,15,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
45767,`defineMethodsInModule` no longer exists,2020-10-02 20:17:16+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
45764,resize_(0) is very expensive,2020-10-02 19:51:26+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""triaged"")]"
45760,Complex Number support for distributed,2020-10-02 18:57:52+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""pt_distributed_rampup""), Label(name=""module: c10d"")]"
45745,Native CUDA-Aware MPI support for MVAPICH2 and other MPI libraries,2020-10-02 16:59:47+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""needs research"")]"
45728,Low shared memory,2020-10-02 07:26:50+00:00,,0,5,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
45717,Better documentation of vec256 API,2020-10-02 02:47:54+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: vectorization""), Label(name=""internals"")]"
45690,Complex and real results do not agree when computing reciprocal or pow(-1) of 0,2020-10-01 20:00:14+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: complex"")]"
45685,"[fx] symbolic trace ""is None"" and ""is not None"" checks",2020-10-01 18:42:28+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: fx"")]"
45683,[FX] Configurability of nested module representation,2020-10-01 18:22:54+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
45682,[FX] Allow customization of the behavior of Proxy,2020-10-01 17:53:04+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
45635,fx graph mode quantization tutorials,2020-10-01 00:29:25+00:00,,1,5,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
45578,Why is RTX3080 slower than RTX2020-Ti?,2020-09-30 16:53:50+00:00,,0,16,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
45573,Build Failed Ubuntu Cuda. CUDAHooks.cpp:97:15: error: ‘struct cudaPointerAttributes’ has no member named ‘type’ return attr.type == cudaMemoryTypeHost;,2020-09-30 15:57:43+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
45569,Distutils Error in torch.hub Load(),2020-09-30 14:06:55+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: hub"")]"
45565,Resolving overloads and default arguments from within __torch_function__,2020-09-30 10:48:28+00:00,,1,9,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
45560,Android: allow preallocation of output buffers,2020-09-30 07:34:41+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
45549,Can't initialize NCCL/GLOO process group if default process group is MPI,2020-09-30 01:56:09+00:00,,1,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""pt_distributed_rampup"")]"
45540,Why does NLLLoss and CrossEntropyLoss require type long?,2020-09-29 23:27:14+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
45534,"[FX] Make tracer return a Graph, not a GraphModule",2020-09-29 21:40:55+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
45524,[JIT] JIT Autograd is saving more results than are necessary for bprop like the result of RELU when it is an intermediate,2020-09-29 19:27:32+00:00,,1,5,"[Label(name=""oncall: jit"")]"
45503,Tensorboard makes logger handlers (except the 1st one) DISAPPEAR !,2020-09-29 14:56:13+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
45499,"torch.nonzero(t, as_tuple=...) does not work with the JIT because the as_tuple signatures are not exposed properly",2020-09-29 10:45:15+00:00,,0,20,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: python array api"")]"
45493,Build LibTorch for cpu using OpenBLAS: Had to manually remove a path in Caffe2Targets.cmake,2020-09-29 08:57:12+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
45483,Extra arguments included in the doc where they are not actually presented in the source code,2020-09-29 04:25:41+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
45481,Combining add_scalar with add_hparams with different frequencey ,2020-09-29 03:33:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
45465,torchscript model size increases when loading and saving it again,2020-09-28 21:42:36+00:00,,0,3,"[Label(name=""oncall: jit"")]"
45459,Backward for sparse tensor item select does not work,2020-09-28 20:37:38+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
45448,CuDNN version not found,2020-09-28 18:50:41+00:00,,0,2,"[Label(name=""module: build""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
45447,Retire usages of CUDA_tensor_apply helpers in ATen,2020-09-28 18:19:10+00:00,,0,3,"[Label(name=""module: internals""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""better-engineering"")]"
45444,Using operator[] in GenericPackedTensorAccessor impossible in cpu code in .cu files (tensor on cpu),2020-09-28 16:34:39+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
45428,Use libtorch for online inference: an illegal memory access was encountered,2020-09-28 12:17:55+00:00,,0,2,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""module: cuda""), Label(name=""triaged"")]"
45414,Module __call__ typing,2020-09-28 04:15:09+00:00,,0,2,"[Label(name=""module: typing""), Label(name=""triaged"")]"
45412,Autocast but there are no kernels registered for this dispatch key. The operator is p�8ߎU Aborted (core dumped),2020-09-28 04:12:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
45399,Load ExtraFilesMap with Java library ,2020-09-27 19:46:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: java"")]"
45398,build_android.sh,2020-09-27 19:32:04+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
45352,torch.nn.functional.one_hot should gracefully skip negative and out-of-range indices,2020-09-25 19:09:10+00:00,,0,8,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
45327,Tensorboard summary_iterator,2020-09-25 05:30:33+00:00,,0,1,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
45321,Memory leak when using share_memory_ on cuda device,2020-09-25 01:08:45+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
45308,Blocked version of Cholesky backward,2020-09-24 21:38:02+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
45295,Adaptive usage of memory during training inference,2020-09-24 19:51:41+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""needs research"")]"
45273,"Training fast with small dataset, slow with large dataset",2020-09-24 15:33:50+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""module: amp (automated mixed precision)"")]"
45242,Functional interface for optimizers,2020-09-23 23:30:01+00:00,,0,6,"[Label(name=""module: cpp""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
45220,FX should preserve type annotations and not break TorchScript-ability,2020-09-23 19:07:35+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: fx"")]"
45208,Adding @torch.no_grad() to forward () causes undefined value in torch.jit.script() ,2020-09-23 17:12:30+00:00,,0,3,"[Label(name=""oncall: jit"")]"
45203,Staged backend boxed fallback (per-operator precomputation / precompute),2020-09-23 14:48:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
45199,JIT doesn't support rfloordiv with scalars correctly,2020-09-23 11:10:35+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""days""), Label(name=""TSUsability""), Label(name=""TSRootCause:PyTorchParityGap"")]"
45198,DataLoader with cv2 and some numpy/cv2 import order causes workers to not work,2020-09-23 10:58:16+00:00,,0,12,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""module: regression"")]"
45160,"In profiler, record_function event's total CPU time can be less than the contained ops",2020-09-22 20:29:33+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: profiler""), Label(name=""module: correctness (silent)"")]"
45139,Mention accessor/data_ptr for raw memory access in Libtorch index API document and discuss performance implications,2020-09-22 17:04:32+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""module: cpp""), Label(name=""triaged"")]"
45136,Multiple torch.load in one file,2020-09-22 16:23:53+00:00,,0,13,"[Label(name=""high priority""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: regression"")]"
45133,[Feature Request] Add support for Hidden Markov Models in torch.distributions,2020-09-22 15:28:25+00:00,,0,4,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research"")]"
45129,Inconsistent wheel name in https://download.pytorch.org/whl/torch_stable.html,2020-09-22 14:37:37+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
45125,Boolean indexing of an ndarray with a torch.tensor mask breaks for size=1 ,2020-09-22 14:03:32+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing"")]"
45115,Standardized Distributions,2020-09-22 11:23:30+00:00,,0,11,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
45111,(prototype) Graph Mode Dynamic Quantization on BERT failure on quantize_dynamic_jit(...) call,2020-09-22 08:13:24+00:00,,0,7,"[Label(name=""triaged""), Label(name=""oncall: mobile"")]"
45100,Pytorch report INTERNAL ASSERT FAILED at ..\\torch\\csrc\\jit\\ir.cpp:1529 when use torch.jit.script to convert to model,2020-09-22 01:40:19+00:00,,0,3,"[Label(name=""oncall: jit"")]"
45073,Compilation errors on power-pc,2020-09-21 17:33:25+00:00,,0,10,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER"")]"
45053,about benchmark issue,2020-09-21 03:59:56+00:00,,0,5,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
45051,Custom Datatypes in Tensors,2020-09-21 00:06:41+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""needs research"")]"
45044,torch rpc cannot handle UnsupportedNodeError exception,2020-09-20 07:09:51+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
45042,"torch.distributed launch.py is hanged.  (pid, sts) = os.waitpid(self.pid, wait_flags)",2020-09-20 03:40:08+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
45012,torch.jit saves nonpersistent buffers,2020-09-19 03:01:25+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""days"")]"
45009,Median / quantile / mode / rank / percentile pooling,2020-09-19 01:48:47+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: sorting and selection""), Label(name=""module: pooling"")]"
44992,[jit] cann't pass class objects across boundary of tracing/scripting,2020-09-18 22:42:52+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
44991,"Unite/unify tensor.unfold with F.unfold and make them more performant (zero-copy or little-copy with stride tricks, as in NumPy)",2020-09-18 22:26:44+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: ux"")]"
44989,"Support unfold for integral types (long, byte etc) tensors",2020-09-18 22:18:23+00:00,,0,9,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable"")]"
44969,Tensordot does not support Bool,2020-09-18 19:44:22+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: boolean tensor"")]"
44968,[feature request] dtype argument for torch.sign,2020-09-18 19:35:48+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
44954,Optimization with constraints for torch.optim,2020-09-18 16:10:14+00:00,,1,4,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
44951,copy.deepcopy not working properly for jit.TopLevelTracedModule,2020-09-18 14:57:30+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""days"")]"
44948,Clarify use of GLog/GFlags,2020-09-18 12:06:35+00:00,,0,2,"[Label(name=""module: dependency bug""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""small""), Label(name=""module: build warnings""), Label(name=""better-engineering"")]"
44945,Fuse softmax and masking in MultiheadAttention,2020-09-18 10:27:35+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""oncall: transformer/mha"")]"
44943,In pytorch 1.6。Run model with input no contiguous tensor will become very slow.,2020-09-18 09:32:27+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
44938,DataParallel on CPU,2020-09-18 07:44:03+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
44931,Issue while writing scalars o tensorboard using writer.add_scalars(....),2020-09-18 03:47:48+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
44917,Incorrect documentation of SGD momentum,2020-09-17 23:09:20+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
44901,for loop can't be symbolically traced,2020-09-17 19:10:36+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
44898,Don't query current device on stream construction,2020-09-17 18:13:58+00:00,,0,1,"[Label(name=""module: bootcamp""), Label(name=""triaged"")]"
44878,"[ONNX] Support Tuple(List(Tensors),...) in input/ouput",2020-09-17 14:42:13+00:00,,0,8,"[Label(name=""module: onnx""), Label(name=""feature""), Label(name=""triaged"")]"
44869,Incorrect processing of autograd profiler outputs in torch.utils.bottleneck,2020-09-17 08:08:01+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
44855,RuntimeError: Caught RuntimeError in replica 1 on device 1.,2020-09-17 01:31:16+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
44851,fx: Python range function used on tensor shape is not symbolically traceable,2020-09-17 00:05:52+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fx"")]"
44827,[RFC] Pipeline Parallelism in PyTorch,2020-09-16 21:29:08+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: rpc"")]"
44822,ONNX export failed on ATen operator rfft because torch.onnx.symbolic_opset9.rfft does not exist,2020-09-16 20:53:11+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement"")]"
44817,ComplexHelper.h contains non-inline functions,2020-09-16 20:33:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex"")]"
44814,LNK2019 error after static compilation of Libtorch,2020-09-16 20:23:32+00:00,,0,13,"[Label(name=""module: build""), Label(name=""triaged"")]"
44809,Simple functions shouldn't go through dispatcher,2020-09-16 19:48:56+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""better-engineering"")]"
44800,torchscript continue training,2020-09-16 17:59:57+00:00,,0,1,"[Label(name=""oncall: jit"")]"
44784,Unreliable CPU times in torch.autograd.profiler.profile(use_cuda=True) when using CUDA,2020-09-16 14:14:45+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
44777,Hybrid Memory,2020-09-16 07:29:27+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""needs research"")]"
44771,Timed out RRef can still be used in subsequent RPCs,2020-09-16 03:09:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
44768,[JIT] function decorated with @torch.no_grad() can not be exported when another function is called inside it.,2020-09-16 01:54:02+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""days"")]"
44741,cblas_gemv is not being used for gemv on complex on CPU,2020-09-15 22:07:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex"")]"
44738,[tools.codegen] Remove byte-for-byte compatibility code,2020-09-15 21:23:38+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
44726,Pytorch Installation from source fails (GCC-8.4/CUDA-10.2/RHEL7) and (GCC-7.5/CUDA-10.2/RHEL7),2020-09-15 18:29:02+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
44724,16-bit input + AMP breaks AdaptiveLogSoftmaxWithLoss,2020-09-15 18:06:47+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
44721,Get rid of copy_from,2020-09-15 17:19:31+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
44719,404 Page not found - inference_api.md & management_api.md,2020-09-15 16:43:52+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: doc infra"")]"
44710,AMP support for libtorch/c++,2020-09-15 14:17:17+00:00,,1,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: amp (automated mixed precision)"")]"
44704,Error message concerning dtype GRU not identical between devices,2020-09-15 10:10:00+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
44676,Make quantized::prepack_fp16 op just do prepacking,2020-09-15 00:21:36+00:00,,0,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
44673,[RFC] Integrate profiler with torch.distributed APIs for profiling of distributed models,2020-09-14 23:33:22+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
44657,Use macro to define `DispatchKey::toString` method,2020-09-14 21:07:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
44634,torch.sparse improvements - tracking issue,2020-09-14 13:03:14+00:00,,1,7,"[Label(name=""high priority""), Label(name=""module: sparse""), Label(name=""triaged"")]"
44631,Multi-process Dataloader and multi-parameter exceptions,2020-09-14 09:14:46+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
44630,No pytorch_jni in StartLocal's zip,2020-09-14 09:03:15+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
44624,CUDA RuntimeError unrecoverably bricks session,2020-09-14 01:56:57+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
44611,MacOS CPU torch.tan and torch.tanh do not compute some values properly,2020-09-13 10:18:19+00:00,,0,4,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: macos"")]"
44608,building torchscript extension results in INVALID TYPE: Only int64_t and bool are supported as an integral argument type  custom_class,2020-09-13 06:29:21+00:00,,0,3,"[Label(name=""oncall: jit"")]"
44593,Docs include the verbose arg of `CosineAnnealingWarmRestarts` but the actual docstring in code doesn't,2020-09-12 15:10:39+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
44591,[Feature] Fused Matmul & Min/Max/Sum/Prod,2020-09-12 09:30:49+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research""), Label(name=""module: linear algebra"")]"
44552,torch.norm does not broadcast for dim > 2,2020-09-11 14:53:08+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""triaged"")]"
44551,PyTorch 1.6 DataParallel causes CUDNN_STATUS_BAD_PARAM in backward pass,2020-09-11 14:20:19+00:00,,0,11,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
44547, floating point exception (core dumped) in training 10^4 steps,2020-09-11 10:49:52+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
44545,too large data in Queue cause dead lock in Multiprocessing ,2020-09-11 09:02:56+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
44544,torch.distributed server back-connects to clients on random ports leading to firewall problems,2020-09-11 08:39:43+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
44533,“doxygenfunction: Unable to resolve multiple matches for function ...” in C++ documentation,2020-09-11 03:05:28+00:00,,1,2,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged"")]"
44528,DataLoader consumes extremely large shared memory (shm) in its initialization.,2020-09-11 02:08:56+00:00,,1,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
44511,"LR scheduler throws warning when using scaler.step instead of optimizer.step, and when saving optimizer state",2020-09-10 22:11:30+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
44504,FP16 inference latency after sleeping,2020-09-10 21:16:05+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""triaged"")]"
44503,TestJitGeneratedModule.test_nn_CTCLoss_lengths_intlists fails if not skipped,2020-09-10 21:12:26+00:00,,1,2,"[Label(name=""oncall: jit"")]"
44489,for_each doesn't support integer input to float output type promotion,2020-09-10 18:38:10+00:00,,0,2,"[Label(name=""triaged"")]"
44473,RuntimeError: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.,2020-09-10 15:41:48+00:00,,0,10,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
44469,Error in the converting to pytorch mobile..,2020-09-10 13:48:08+00:00,,0,5,"[Label(name=""oncall: mobile"")]"
44446,[jit] class type optional type annotation not working properly ,2020-09-10 01:30:00+00:00,,1,0,"[Label(name=""oncall: jit"")]"
44428,Support for CUDA matrix multiplication on long (and other integer) tensors,2020-09-09 21:30:32+00:00,,0,16,"[Label(name=""high priority""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas""), Label(name=""module: linear algebra""), Label(name=""needs design""), Label(name=""function request"")]"
44421,[tools.codegen] Rename api.legacy_dispatcher to api.native,2020-09-09 20:46:17+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
44415,Batchnorm2d in PT1.6 couldn't turn off track_running_stats,2020-09-09 19:59:16+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
44403,Investigate SyncBatchNorm cleanup with NCCL Async Error Handling,2020-09-09 18:14:06+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering"")]"
44380,Support for NVIDIA UVM technology,2020-09-09 14:10:49+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
44362,Libtorch CMakeList.txt config help,2020-09-09 05:15:41+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
44343,Asynchronous Execution on CPU,2020-09-08 23:15:41+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: cpu""), Label(name=""triaged"")]"
44341,Consider cache effects in Timer,2020-09-08 23:01:22+00:00,,1,4,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement"")]"
44316,[FX] Schema normalization tooling ,2020-09-08 18:23:21+00:00,,0,5,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: fx"")]"
44313,`Undefined symbol: torch::kNearest` when building App iOS,2020-09-08 17:55:49+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""module: ios"")]"
44295,Request: Add PyTorch version to state dicts,2020-09-08 04:25:05+00:00,,0,3,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""enhancement"")]"
44282,PyTorch wheel's own OpenMP library clashing with system-wide OpenMP library at runtime,2020-09-07 15:38:54+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: openmp"")]"
44279,How to use CUDA Dynamic Parallelism in PyTorch CPP extension?,2020-09-07 10:55:28+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
44274,Slower speeds when using half().,2020-09-07 07:33:38+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged"")]"
44255,Allow to use system zstd,2020-09-06 00:13:15+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
44248,Additional clutter memory allocated on GPU 0 when training on GPU 1+,2020-09-05 09:46:19+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
44245,torch.mv with sparse matrix gives internal assert on cuda,2020-09-05 08:46:16+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
44185,caffe2: Python 3 deprecation warnings about inspect.getargspec,2020-09-04 08:46:37+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
44182,Support keep stride for neg with requires_grad=False,2020-09-04 07:55:08+00:00,,0,6,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
44179,REINFORCEMENT LEARNING (DQN) TUTORIAL is not working anymore due to matplotlib.pyplot.imshow(),2020-09-04 07:33:31+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
44172,build from scratch failed because of the expansion of macro,2020-09-04 03:12:54+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
44169,Deadlock with RPC and dist.barrier() for TensorPipeAgent and NCCL.,2020-09-04 02:23:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
44159,"[Feature Request] Add an option to run GPU tests only, and skip all CPU tests",2020-09-03 22:46:17+00:00,,0,6,"[Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged"")]"
44156,CUDA memory leak in multi-processing,2020-09-03 22:27:43+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
44103,Item seems to affect the backward process of DataParallel,2020-09-03 08:28:00+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
44084,[RFC] Manage CUDA Stream in TensorPipe RPC Agent,2020-09-03 01:00:23+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
44077,[jit] Better type refinement for class attributes which are class types,2020-09-02 23:30:24+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""weeks""), Label(name=""months""), Label(name=""TSRootCause:TypeRefinement""), Label(name=""TSUsability"")]"
44049,[FX] Can't symbolically trace callsites to ScriptFunction,2020-09-02 19:11:30+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: fx"")]"
44027,Immutable (read-only) tensors,2020-09-02 15:18:46+00:00,,0,9,"[Label(name=""triaged"")]"
44026,[Feature] Einsum like ShapeGuard,2020-09-02 14:11:36+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""shadow review"")]"
44024,"When the pytorch training data reaches a certain epoch, the memory remains unchanged?",2020-09-02 09:13:44+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
43964,Make it so that leading underscore operators are truly private and can be changed without worry for BC,2020-09-01 17:42:20+00:00,,0,0,"[Label(name=""triaged"")]"
43949,bytes(byte_tensor) gives strange error + [feature request] support memoryview(tensor),2020-09-01 10:49:49+00:00,,0,10,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
43947,torch.cuda.synchronize Influence distributed training,2020-09-01 10:20:15+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
43904,Documentation and `torch.sparse` alias for `torch.bmm` sparse-dense,2020-08-31 20:15:08+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
43876,Insert at specific index/key in nn.Sequential,2020-08-31 08:49:16+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
43873,PackedSequence objects that are created within jit.script are not PackedSequence,2020-08-31 07:11:04+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""TSRootCause:InvalidCustomClass""), Label(name=""TSUsability"")]"
43869,"In profiler, calling `key_averages()` unexpectedly changes CPU time returned for profiled events",2020-08-31 02:21:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
43868,"In profiler, recorded block's total time can be less than the operators within the block",2020-08-31 01:54:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
43867,torch.bincount beyond 1d arrays,2020-08-30 23:49:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement"")]"
43865,"Allow custom kwargs for forward method of nn.TransformerEncoderLayer, nn.TransformerDecoderLayer.",2020-08-30 22:30:45+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
43859,Multi-machine multi-gpu training won't start on CNGrid,2020-08-30 14:46:16+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
43816,Move randperm() to DistributionTemplates,2020-08-29 00:16:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""csprng"")]"
43815,Buffers are moved to another device by copy and not in-place,2020-08-29 00:14:24+00:00,,1,5,"[Label(name=""triaged"")]"
43795,[ONNX] shape node constant folded tensor with dynamic shape,2020-08-28 19:48:36+00:00,,0,8,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
43765,JIT fails sanity checks during tracing torch.rand_like,2020-08-28 13:02:52+00:00,,0,1,"[Label(name=""oncall: jit"")]"
43760,Error : lib/libstdc++.so.6: version `CXXABI_1.3.11 not found,2020-08-28 09:30:57+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
43758,OSError: /lib64/libc.so.6: version `GLIBC_2.14' not found ,2020-08-28 07:41:48+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
43754,"Using Dataparallel with multi input error.  Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at cuda:0",2020-08-28 00:54:00+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
43707,torch.optim mentions legacy Variable,2020-08-27 15:36:02+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
43706,checkpoint restore of optimizers changes dtype of Floating-point state,2020-08-27 15:29:57+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
43692,named tensor INTERNAL ASSERT FAILED when indexing with a list.,2020-08-27 07:16:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
43686,Static Linking of PyTorch didn't statically link CUDA,2020-08-27 03:12:27+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: static linking"")]"
43685,Syncbatchnorm and DDP ,2020-08-27 02:33:59+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""triaged"")]"
43679,[FX] List unpacking is broken,2020-08-27 00:44:24+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: fx"")]"
43677,"Some largeCUDATensorTest fails with OOM when running with the entire test suit, but not when running standalone",2020-08-27 00:01:59+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
43672,Make `torch.Generator` picklable,2020-08-26 23:07:02+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: serialization""), Label(name=""triaged"")]"
43663,test_doc_template is not working correctly,2020-08-26 21:50:27+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
43659,Exploring supporting some cases of `__bool__` on Proxy,2020-08-26 21:11:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: fx"")]"
43646,c10::string_view pybind11 custom type caster.,2020-08-26 19:14:56+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: pybind"")]"
43638,[FR] hub uses default github branch,2020-08-26 18:00:07+00:00,,0,7,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: hub"")]"
43623,[FR] Raise an exception when constructing non-empty index and empty values sparse tensor,2020-08-26 11:17:03+00:00,,1,2,"[Label(name=""module: sparse""), Label(name=""module: cuda""), Label(name=""triaged"")]"
43617,Type hints from _VariableFunctions and elsewhere clash,2020-08-26 07:46:48+00:00,,0,1,"[Label(name=""module: typing""), Label(name=""triaged"")]"
43604,ImportError: libtorch_cpu.so: cannot open shared object file: No such file or directory,2020-08-26 01:10:07+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
43579,"For the same complex dtype and same value, comparing a PyTorch tensor with a NumPy array results in False",2020-08-25 21:57:44+00:00,,1,8,"[Label(name=""triaged""), Label(name=""module: complex"")]"
43567,`torch.svd()` CUDA gives incorrect results when input contains `nan`,2020-08-25 19:14:15+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: linear algebra"")]"
43561,[RFC] RPC BENCHMARK,2020-08-25 18:14:14+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
43556,FP16 gives NaN loss when using pre-trained model,2020-08-25 16:37:14+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
43548,JIT tracing incorrectly records some slice bounds,2020-08-25 11:32:31+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit"")]"
43546,"NCCL WARN Your program may be hanging, this may be caused by a collective mismatch around rank 2. Please check your collective calls at and around this rank. You can use NCCL_DEBUG=INFO and NCCL_DEBUG_SUBSYS=COLL to see the collective logs",2020-08-25 10:34:29+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: nccl"")]"
43544,AMP much worse performance with groupped Conv2d than fp32 ,2020-08-25 09:33:13+00:00,,0,10,"[Label(name=""module: dependency bug""), Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
43536,"How do I debug ""RuntimeError: trying to initialize the default process group twice!""",2020-08-25 02:55:51+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
43520,[jit] cannot use functools.partial with TorchScript,2020-08-24 21:41:17+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""months"")]"
43510,Make busy waiting time in DDP (kSynchronizeBusyWaitMillis) a configurable environment variable,2020-08-24 19:23:10+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
43503,torch.quantization.quantize_dynamic document refers `module` as a parameter ,2020-08-24 16:35:45+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
43502,Useless Exception traces when DataSet timing out,2020-08-24 16:23:12+00:00,,0,6,"[Label(name=""module: bootcamp""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
43501,[jit] Shape hints for TorchScript,2020-08-24 16:10:41+00:00,,1,5,"[Label(name=""oncall: jit"")]"
43490,Implement a set_printoptions method in libtorch ,2020-08-24 12:43:13+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement"")]"
43488,"c10::Error: Couldn’t find an operator for aten::dropout(Tensor input, float p, bool train)",2020-08-24 08:54:38+00:00,,0,4,"[Label(name=""oncall: mobile"")]"
43486,scatter not place inputs into every device ,2020-08-24 07:43:44+00:00,,0,2,"[Label(name=""triaged"")]"
43484,pybind11_object_dealloc error,2020-08-24 03:13:11+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: pybind"")]"
43467,Data loader struct pack issue(overflow)?,2020-08-23 07:16:55+00:00,,0,5,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
43465,Memory Profiler: Not profiled memory deallocation in outside of an autograd function,2020-08-23 06:15:18+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
43459,Trying to build PyTorch from source with LLD 8 fails,2020-08-23 00:11:57+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: static linking"")]"
43453,CUDAGuard might not create CUcontext,2020-08-22 12:14:11+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
43450,Training Large Neural Networks with Constant Memory using a New Execution Algorithm,2020-08-22 07:39:36+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""needs research"")]"
43429,Inference performance regression caused by hacky_wrapper_for_legacy_signatures,2020-08-21 20:54:42+00:00,,0,14,"[Label(name=""module: performance""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
43411,Add support of random state generator objects to nn.init module,2020-08-21 18:13:46+00:00,,1,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: initialization"")]"
43409,Switch C10_EXPORT_CAFFE2_OP_TO_C10 to new operator registration API,2020-08-21 18:01:24+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""module: bootcamp"")]"
43402,ModuleDict does not preserve order of initializing dictionary,2020-08-21 12:31:13+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
43388,"Abort message: ‘terminating with uncaught exception of type c10::Error: _ivalue_ INTERNAL ASSERT FAILED at ../torch/csrc/jit/api/object.cpp:19, please report a bug to PyTorch. (_ivalue at ../torch/csrc/jit/api/object.cpp:19)",2020-08-21 02:50:40+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""oncall: mobile"")]"
43385,OffsetCalculator.cuh(and THCIntegerDivider.cuh) should be available with PyTorch cpu-only binaries,2020-08-21 01:49:43+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""csprng"")]"
43378,[JIT] Using Any type variable inside can produce incorrect results due to type unification problems,2020-08-21 00:50:06+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
43369,"torch.load(.., map_location='cpu') fails when unserializing cuda tensors on a cpu-only device serialized with pickle",2020-08-20 23:46:01+00:00,,0,4,"[Label(name=""module: pickle""), Label(name=""module: serialization""), Label(name=""triaged"")]"
43352,"Remove warning, and update documentation.",2020-08-20 20:28:09+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
43347,backward for dense+sparse does not work,2020-08-20 19:01:16+00:00,,0,6,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
43328,torch.utils.tensorboard.SummaryWriter.add_histogram() execution time explodes with each epoch.,2020-08-20 11:33:49+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
43325,CUDA error: an illegal memory access was encountered (laugh_kernel at ...../cuda/CUDALoops.cuh:112),2020-08-20 09:20:48+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas"")]"
43323,Set SummaryWriter step globally,2020-08-20 08:08:48+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
43281,Cannot find CUDA devices when the machine stays idle for a while,2020-08-19 19:07:10+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
43261,OSError: could not find class definition when export torchscript module,2020-08-19 09:18:52+00:00,,0,2,"[Label(name=""oncall: jit"")]"
43259,RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one.,2020-08-19 08:52:26+00:00,,0,31,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
43255,Adding entropy function analogous to SciPy,2020-08-19 05:42:54+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
43254,Vec256<int64_t> does not handle LONG_MAX on minimum,2020-08-19 04:58:44+00:00,,0,3,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: vectorization""), Label(name=""module: reductions"")]"
43253,Reduce number of stack frames used up by dispatcher,2020-08-19 04:43:40+00:00,,0,3,"[Label(name=""module: internals""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
43250,Support for Multi-Categorical in torch.distributions,2020-08-19 03:16:27+00:00,,0,6,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
43249,[JIT] Cannot iterate over nn.ModuleList in JITted code when accessed through one level of indirection,2020-08-19 02:48:15+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""days"")]"
43245,mp.spawn 'args' are not clear,2020-08-19 01:56:59+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
43238,Expose counters for torch.distributed to report communication overhead within a block.,2020-08-19 00:28:24+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
43237,[jit] remove shape/device specialization from tracing after ONNX done with its own shape inference,2020-08-18 23:52:57+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
43200,Support controlling output delay for CTC loss.,2020-08-18 09:53:46+00:00,,0,1,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""enhancement"")]"
43196,model trace error,2020-08-18 09:22:56+00:00,,0,3,"[Label(name=""caffe2""), Label(name=""triaged"")]"
43195,one_hot tensors are channels_last but marked as contiguous,2020-08-18 09:11:11+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
43166,Do not call nullptr deleter in at::fromDLPack (dlpack),2020-08-17 22:08:26+00:00,,0,4,"[Label(name=""module: cpp""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
43140,"Pytorch ""Import torch"" lead to ""core dump""",2020-08-17 11:12:35+00:00,,0,32,"[Label(name=""module: binaries""), Label(name=""module: protobuf""), Label(name=""triaged"")]"
43134,[jit] need a better way to handle mix CPU/GPU (Inference/Training) for tracing,2020-08-17 06:27:49+00:00,,0,2,"[Label(name=""oncall: jit"")]"
43128,Accessing elements of tensor with multi-dimensional index results `IndexError`,2020-08-16 15:18:18+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing"")]"
43127,`onnxifi_load` symbol undefined in `libtorch_cpu.a` library built from source,2020-08-16 13:38:57+00:00,,0,2,"[Label(name=""triaged"")]"
43125,"Non-conforming variable identifiers in JIT code errors / printouts: e.g. ""Tensor 0""",2020-08-16 09:46:13+00:00,,1,4,"[Label(name=""oncall: jit"")]"
43123,Add CutMix transform to torchvision.transforms,2020-08-16 06:46:48+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: vision"")]"
43120,"When modified the model python file, the pytorch will raise the KeyError of this file",2020-08-16 04:16:47+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
43119,Tracing can leak CUDA memory when using tensor constants,2020-08-16 03:40:07+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""months"")]"
43116,Accessing tensor by element is super slow,2020-08-15 23:41:52+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""triaged"")]"
43115,torch.multinomial with replacement=True produces inaccurate results for large number of categories,2020-08-15 22:38:22+00:00,,0,0,"[Label(name=""module: numerical-stability""), Label(name=""module: distributions""), Label(name=""triaged"")]"
43114,"out kwargs are sometimes inconsistent with returned named tuple field name (and in some cases, cannot be made consistent)",2020-08-15 22:17:51+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
43113,Missing caffe2_pybind11_state in pip install after cmake.,2020-08-15 21:59:48+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: pybind"")]"
43109,[docs] LR schedulers' get_last_lr missing in docs online,2020-08-15 16:50:13+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
43101,New function for CTC decoding,2020-08-15 07:45:23+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs design"")]"
43091,Enable torch.optim typechecks during CI ,2020-08-15 00:22:05+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged"")]"
43072,LSTM::permute_hidden breaks Liskov substitution principle,2020-08-14 20:24:09+00:00,,0,1,"[Label(name=""module: rnn""), Label(name=""module: typing""), Label(name=""triaged"")]"
43064,torch.dot throws an error for input tensors of different dtypes,2020-08-14 17:09:05+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: type promotion"")]"
43040,undefined symbol: FLAGS_caffe2_keep_on_shrink,2020-08-14 01:03:25+00:00,,0,2,"[Label(name=""caffe2""), Label(name=""triaged"")]"
43033,No vectorization for int8 and uint8,2020-08-13 22:32:06+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: vectorization""), Label(name=""better-engineering"")]"
43030,BUILD_PYTHON switched to OFF at second run of CMake,2020-08-13 21:31:38+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
43012,Implement map-style caching DataSet as PyTorch build-in DataSet.,2020-08-13 14:45:21+00:00,,0,5,"[Label(name=""module: bootcamp""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
43005,`torch.distributions.Categorical` crashes with illegal instruction,2020-08-13 13:00:24+00:00,,0,6,"[Label(name=""module: crash""), Label(name=""module: distributions""), Label(name=""triaged"")]"
42971,Enable torch.quantization.fuse_modules typechecks during CI ,2020-08-13 04:56:32+00:00,,0,0,"[Label(name=""module: typing""), Label(name=""triaged"")]"
42969,Enable torch.testing._internal typechecks during CI ,2020-08-13 04:54:56+00:00,,1,2,"[Label(name=""module: typing""), Label(name=""triaged"")]"
42959,[feature request] Faster specialized int16->float32 conversions to match speed with NumPy,2020-08-13 01:17:10+00:00,,0,23,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
42950,TorchBind C++ Enum Class,2020-08-12 22:55:27+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: torchbind"")]"
42949,Verify TorchBind works with nested class type,2020-08-12 22:54:19+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: torchbind"")]"
42948,[jit] TorchBind std::chrono::milliseconds ,2020-08-12 22:51:57+00:00,,0,1,"[Label(name=""oncall: jit"")]"
42947,[jit] std::exception_ptr can't be torchbind/convert to ivalue,2020-08-12 22:50:43+00:00,,0,3,"[Label(name=""oncall: jit"")]"
42919,Legacy Python2 and early Python3 leftovers,2020-08-12 15:41:44+00:00,,0,4,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""shadow review""), Label(name=""OSS contribution wanted"")]"
42916,Build problems caffe2 -- pytorch from source & CUDA 11.0,2020-08-12 14:16:39+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
42912,"Add typing information into variable declarations for JIT script "".code"" output",2020-08-12 13:17:08+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""triaged""), Label(name=""days"")]"
42911,Converting from .pth to .onnx failed on 3d-input. Support 3d-conv?,2020-08-12 13:14:35+00:00,,0,6,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
42902,Avoid dynamic isCustomClassRegistered() checks in kernel call paths,2020-08-12 06:32:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
42885,Unable to call `super` method with TorchScript,2020-08-11 22:24:54+00:00,,0,8,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""TSRootCause:DynamicBehaviors""), Label(name=""TSUsability""), Label(name=""TSRootCause:ModuleInheritance"")]"
42882,Support for defining/saving custom operators with dynamic schema,2020-08-11 22:14:11+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
42879,Tensorpipe requires setting both GLOO_SOCKET_IFNAME and TP_SOCKET_IFNAME,2020-08-11 20:31:44+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
42863,TensorOptions extensibility has rusted shut,2020-08-11 16:28:04+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
42861,Can not get pytorch working with tensorboard,2020-08-11 16:09:45+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
42858,"prelu_backward, hardshrink_backward shouldn't be a method",2020-08-11 15:17:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
42849,[RFC] DeepSpeed + PT Distributed Integration,2020-08-11 03:24:09+00:00,,0,20,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
42848,Add support for user defined types in serialization in libtorch,2020-08-11 02:14:34+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""feature""), Label(name=""module: serialization""), Label(name=""triaged"")]"
42847,Get test_jit.py below 10k lines,2020-08-11 01:54:13+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""module: tests""), Label(name=""enhancement""), Label(name=""better-engineering"")]"
42843,Documentation mistake of Adam in v1.6.0?,2020-08-11 01:17:41+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
42838,"RuntimeError: ""triangular_solve_cuda"" not implemented for 'Half'",2020-08-11 00:02:09+00:00,,1,5,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""module: amp (automated mixed precision)"")]"
42830,Undocumented parameters in the Variables section of the recurrent bidirectional layers regarding the backward pass,2020-08-10 20:36:01+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
42829,torch/library.h doc rendering issue,2020-08-10 20:22:42+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
42818,Can't registered boxed kernel for operator that doesn't support boxing,2020-08-10 18:08:14+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
42815,Add a guide for what to do when you think there's a memory leak,2020-08-10 17:19:13+00:00,,0,1,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
42812,checkpoint_sequential breaks backpropagation,2020-08-10 16:52:11+00:00,,0,2,"[Label(name=""module: checkpoint""), Label(name=""module: autograd""), Label(name=""triaged"")]"
42807,build error redefinition of ‘struct c10::complex<T>’ with release v1.6.0,2020-08-10 12:08:17+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
42805,Unbuffered operation,2020-08-10 09:41:13+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""function request"")]"
42800,RuntimeError: cublas runtime error : the GPU program failed to execute at /pytorch/aten/src/THC/THCBlas.cu:27 for spectral norm,2020-08-10 08:01:39+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
42793,distributed training with c10d does not work with layerdrop in pytorch > 1.4,2020-08-09 23:09:21+00:00,,1,14,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
42791,Build fail on Ubuntu 18.04: caffe2/CMakeFiles/init_test.dir/build.make:106: recipe for target 'bin/init_test' failed,2020-08-09 12:56:00+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
42784,libtorch 1.5 crashes when used on macs when using torch::max without AVX support,2020-08-08 20:19:35+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: macos"")]"
42779,[quant] Quantized AdaptivePool3d is much slower for ChannelsLast3d.,2020-08-08 14:19:05+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: memory format"")]"
42774,Missing API reference for SWALR and AveragedModel,2020-08-08 05:35:15+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
42729,Mismatch in docs and behavior of align_corners for nn.functional.interpolate,2020-08-07 10:47:19+00:00,,1,5,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
42722,How to build libtorch static libraries on Windows?,2020-08-07 02:37:24+00:00,,0,13,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged""), Label(name=""windows-triaged"")]"
42705,torch.distributed.rpc package not work well with generator and lambda,2020-08-06 22:08:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
42689,How can I specify NumPy while building PyTorch?,2020-08-06 18:31:24+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
42673,"Unexpected behavior of ""to"" method inside a torch.jit.script decorated function",2020-08-06 16:05:41+00:00,,2,7,"[Label(name=""oncall: jit""), Label(name=""days""), Label(name=""TSRootCause:DefaultTypes""), Label(name=""TSUsability"")]"
42671,[discussion] Support __round__ magic,2020-08-06 15:58:41+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
42665,Optimizer support via Libtorch C++ on Android,2020-08-06 11:06:22+00:00,,0,7,"[Label(name=""module: cpp""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""oncall: mobile"")]"
42663,Why Conv3D is slower than Conv2D when its flops is smaller than Conv2D,2020-08-06 07:42:11+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
42655,"When one distributed test fails in CI, the next one can fail spuriously",2020-08-06 03:56:10+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
42654,RuntimeError: each element in list of batch should be of equal size ,2020-08-06 03:10:56+00:00,,0,25,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
42653,onnx export failed when output size are not factor of input size for adaptive_avg_pool2d,2020-08-06 03:09:38+00:00,,0,27,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
42652,Add non_blocking=True copy of torch.Storage,2020-08-06 02:41:13+00:00,,0,5,"[Label(name=""triaged""), Label(name=""needs research"")]"
42625,F.grid_sample produces weird results on single-pixel images,2020-08-05 19:47:01+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
42597,Logsigmoid as chaining operation,2020-08-05 12:50:47+00:00,,0,6,"[Label(name=""triaged""), Label(name=""function request"")]"
42594,support LSTM for quantization aware training,2020-08-05 11:24:40+00:00,,0,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
42592,Lower performance when forwarding JIT model with libTorch 1.6 compared with 1.5,2020-08-05 10:15:18+00:00,,0,2,"[Label(name=""oncall: jit"")]"
42581,Build script complains that gcc is < 6 even though gcc version is 8,2020-08-05 03:37:51+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
42545,CuDNN RNN bindings are basically all deprecated in cudnn 8,2020-08-04 17:04:19+00:00,,0,2,"[Label(name=""module: cudnn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: deprecation"")]"
42544,torch rpc lose device information between rpc calls,2020-08-04 16:53:56+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
42539,Docs for Tensor.copy_ non_blocking should mention pinned memory,2020-08-04 15:15:12+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
42529,renorm dim argument is extremely confusing,2020-08-04 14:24:37+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: ux"")]"
42526,Python3 segfaults or doesn't load torch after installation,2020-08-04 12:24:04+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
42502,[proposal] batch mode for randperm,2020-08-04 02:09:34+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random"")]"
42498,pytorch tests failed,2020-08-03 23:26:13+00:00,,0,3,"[Label(name=""module: tests""), Label(name=""triaged"")]"
42487,Support recursive data type in TorchScript,2020-08-03 21:07:35+00:00,,1,2,"[Label(name=""high priority""), Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""weeks"")]"
42481,[Macos][CircleCI] Test failed in test_dataloader.py,2020-08-03 20:20:03+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: macos"")]"
42478,Using hooks with `DataParallel` gets `autograd` error,2020-08-03 19:12:54+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
42460,Training with AMP gives overflow warning,2020-08-03 15:49:26+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
42459,[JIT] Runtime error when backpropagating through input gradient,2020-08-03 15:40:02+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
42452,`device-side assert triggered` - when probability > 1.0,2020-08-03 13:05:45+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""better-engineering"")]"
42447,OneCycleLR argument `pct_start` used as a proportion not percentage,2020-08-03 10:36:52+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
42444,torch.random.randperm stuck in multiprocess,2020-08-03 09:47:52+00:00,,0,7,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: random"")]"
42440,[feature request].Time Series Algorithms,2020-08-03 08:51:40+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
42439,How to use libtorch on Jetson TX2,2020-08-03 06:14:11+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: arm"")]"
42428,KeyError: xxxxxxxxxx when calling optimizer.state_dict(),2020-08-02 20:25:21+00:00,,0,6,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
42427,./scripts/build_android.sh need support nn::module nn::Functional nn::Linear,2020-08-02 19:48:49+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
42407,torch.distributions.multinomial.Multinomial cannot be used in batch,2020-08-01 13:51:03+00:00,,0,11,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
42405,slow data loading in VisionDataset  - need to allow batch loading.,2020-08-01 12:33:07+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: vision"")]"
42402,Reading data speed slower than tensorflow,2020-08-01 06:50:18+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
42379,TensorBoard Summaries Written with `SummaryWriter.add_scalars()` are not Purged ,2020-07-31 19:32:33+00:00,,0,0,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
42368,RFC: torch.vmap,2020-07-31 15:53:04+00:00,,1,41,"[Label(name=""triaged""), Label(name=""module: vmap"")]"
42366,Stop implementing JIT stack as a std::vector,2020-07-31 15:27:20+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""weeks"")]"
42362,libpytorch_jni is not provided in conda builds,2020-07-31 12:14:54+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
42355,nn::Sequential Link error in Android version,2020-07-31 07:38:44+00:00,,0,1,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
42350,An error occurred deploying CRNN using libtorch,2020-07-31 02:07:42+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""module: rnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
42345,Generate unique `worker_id` for each node in the RPC framework for the store.,2020-07-31 00:37:58+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
42336,Audit quantization functions to ensure proper argument sizes,2020-07-30 22:35:13+00:00,,0,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
42332,RuntimeError: ProcessGroupNCCL does not support recv (torch-nightly),2020-07-30 20:47:31+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: nccl"")]"
42317,Instance norm annotation is incorrect,2020-07-30 16:34:16+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""days"")]"
42316,Proper testing of `nn.Module` loading backward compatibility,2020-07-30 16:06:23+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: tests""), Label(name=""module: serialization""), Label(name=""triaged"")]"
42311,Inconsistent results when trying to enable Tensor Cores on NVIDIA T4,2020-07-30 15:25:19+00:00,,0,8,"[Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: amp (automated mixed precision)"")]"
42308,Not able to run quantized model on android,2020-07-30 14:31:45+00:00,,0,3,"[Label(name=""oncall: mobile"")]"
42303,frame_length reference in pytorch.stft documentation,2020-07-30 12:44:30+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
42301,Is it possible that one-version pytorch supports two gpu (GTX TITAN X and TITAN) using at the same time?,2020-07-30 12:23:49+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
42295,KeyError: 'track_running_stats' in batchnorm.extra_repr,2020-07-30 07:43:22+00:00,,0,1,"[Label(name=""module: printing""), Label(name=""module: serialization""), Label(name=""triaged"")]"
42267,assertRaisesRegxWithHighlight isn't triggered correctly,2020-07-30 00:25:50+00:00,,1,0,"[Label(name=""oncall: jit"")]"
42258,Cannot load certain function from dumped Torchscript file,2020-07-29 22:11:06+00:00,,1,11,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""days"")]"
42246,"`torch.tensor([1, 2], dtype=torch.int).fmod(torch.tensor(0, dtype=torch.float))` leads to ""RuntimeError: result type Float can't be cast to the desired output type Int""",2020-07-29 19:33:56+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: type promotion"")]"
42228,[docs] Bitwise ops miss arguments,2020-07-29 09:03:12+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
42223,Implementing packbits,2020-07-29 05:48:09+00:00,,0,20,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
42207,torchscript does not support unicode strings,2020-07-29 00:43:09+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""months"")]"
42188,Eliminate warning when cloning a tensor using `torch.tensor(x)`,2020-07-28 20:25:23+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""triaged"")]"
42183,Skip all reduce globally unused parameters in DDP,2020-07-28 19:11:48+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
42177,record_function no longer appears in the docs,2020-07-28 17:33:56+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
42173,Exclusive flag in torch.cumsum,2020-07-28 15:50:32+00:00,,0,1,"[Label(name=""triaged""), Label(name=""function request"")]"
42170,Tracing a[b] records converting b to fixed device type of a,2020-07-28 14:24:26+00:00,,0,6,"[Label(name=""oncall: jit"")]"
42159,[docs] Add example of interop with DLPack created in plain C,2020-07-28 12:24:28+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
42156,"RuntimeError: test_autograd failed! Build success, test failed on IBM POWER9",2020-07-28 11:34:41+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: POWER"")]"
42155,BusError memory-mapped tensor,2020-07-28 07:50:50+00:00,,0,13,"[Label(name=""module: internals""), Label(name=""triaged"")]"
42145,Support Python type() in TorchScript,2020-07-28 00:11:31+00:00,,0,3,"[Label(name=""oncall: jit"")]"
42112,Function names in title should not be capitalized in documentation,2020-07-27 16:12:50+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
42109,Slow `index_add_` on `torch.long` tensors ,2020-07-27 15:21:53+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
42095,[RFC] Add Windows support to torch.distributed package,2020-07-27 04:51:00+00:00,,1,23,"[Label(name=""oncall: distributed""), Label(name=""module: windows""), Label(name=""triaged""), Label(name=""windows-triaged"")]"
42094,Setting threads number to the number of default by torch.set_num_threads is faster than not setting it,2020-07-27 04:04:58+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: multithreading"")]"
42081,Document optimizations enabled by JIT scripting and tracing (TorchScript),2020-07-26 12:55:01+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""days"")]"
42080,To have single cuda context across multiple processes,2020-07-26 11:24:27+00:00,,0,17,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
42074,Memory usage of torch.nn.functional.interpolate increased with v1.5.0 when run on numpy input,2020-07-26 01:48:59+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: numpy"")]"
42053,Function request: np.copy (alias of clone?),2020-07-25 07:15:16+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
42049,"Code hangs when using `set_start_method('spawn', force=True)` in `torch.multiprocessing.pool`",2020-07-25 05:42:09+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
42039,Segmentation fault (core dumped) when running optimize_for_mobile,2020-07-24 22:01:24+00:00,,0,3,"[Label(name=""oncall: mobile"")]"
42015,Support additional arguments in nn.Identity.forward,2020-07-24 16:03:01+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged"")]"
42012,EMNIST looks different to MNIST,2020-07-24 15:15:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: vision"")]"
41999,PyBind11 submodule required even when pybind11_PREFER_third_party=OFF,2020-07-24 10:14:18+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
41970,torch.random.fork tries to initialize cuda even when no cuda devices are available,2020-07-24 02:32:16+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: random"")]"
41955,can not use nn::Functional(torch::softmax(-1)) in Sequential,2020-07-23 22:41:09+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged"")]"
41950,[docs] Clarify behavior of torch.cuda.device_count() when torch compiled without CUDA (cpu-only) or when CUDA is not available,2020-07-23 21:50:59+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
41938,Installing pytorch from source on Power9 (PPC64LE) + CUDA 10.2 + RHLE7 ,2020-07-23 19:29:47+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER"")]"
41926,torch.exp() cannot be modified by an inplace operation,2020-07-23 14:51:17+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged"")]"
41921,Failure to compile Eigen on Power with clang,2020-07-23 13:15:14+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
41920,Compilation on Power fails with clang due to vec_xl,2020-07-23 13:03:09+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER"")]"
41918,ASAN build breaks when using third_party/protobuf,2020-07-23 12:07:37+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: protobuf""), Label(name=""triaged""), Label(name=""module: POWER"")]"
41916,ASAN build broken when using USE_ASAN=1,2020-07-23 12:02:49+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER"")]"
41915,Automating the various Installation processes for Linux,2020-07-23 11:18:53+00:00,,0,0,"[Label(name=""module: build""), Label(name=""feature""), Label(name=""triaged"")]"
41909,Dropout in TorchScript under torch.no_grad() produces incoherent results,2020-07-23 05:43:16+00:00,,1,0,"[Label(name=""oncall: jit"")]"
41904,Inconsistencies on ModelLayer,2020-07-23 03:47:40+00:00,,0,2,"[Label(name=""caffe2-op""), Label(name=""triaged""), Label(name=""better-engineering"")]"
41903,[C++] adding type checking or type casting to torch::PackedTensorAccessor indexing,2020-07-23 03:47:01+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement"")]"
41869,TorchScript pack_padded_sequence and  pad_packed_sequence run time error,2020-07-22 20:29:37+00:00,,0,13,"[Label(name=""oncall: jit"")]"
41852,Difference in inference time between CUDA 10.0 & 10.2,2020-07-22 14:21:46+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
41844,test_bottleneck_cuda fails on Power,2020-07-22 07:52:58+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: POWER"")]"
41839,"[Feature Request] Add `to`, `cpu`, and `cuda` method to optimizer",2020-07-22 06:00:16+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
41833,"Error occurs when adding ""max_unpool2d"" to onnx",2020-07-22 01:51:56+00:00,,0,10,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement"")]"
41823,bitwise_or / bitwise_and /... reductions across dim (+ multidim / keepdim for consistency),2020-07-21 22:40:49+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement"")]"
41816,install path can set prefix install dir ,2020-07-21 21:27:17+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
41803,out-variant for tensor.bitwise_and (exists for torch.bitwise_and) + bitwise_friends,2020-07-21 16:18:10+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""needs research""), Label(name=""module: ux""), Label(name=""function request"")]"
41801,Caffe2 GPU Inference not working on pytorch nightly version,2020-07-21 16:01:24+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
41797,[C++] Libtorch error in Release build only ,2020-07-21 13:09:13+00:00,,0,6,"[Label(name=""module: abi""), Label(name=""triaged"")]"
41793,General reduction mode selection for in-place and out-variants for wider range (hopefully all) of ops,2020-07-21 09:36:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: reductions"")]"
41695,Improve overload resolution order rules for `invokeOperatorFromPython`,2020-07-20 21:28:43+00:00,,1,1,"[Label(name=""high priority""), Label(name=""oncall: jit"")]"
41694,Torch.multiprocessing.spawn can deadlock,2020-07-20 21:21:17+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
41683,'torch::jit::script::ErrorReport' from 'torch::jit::load('modelpath') in Visual Studio 2017,2020-07-20 16:24:36+00:00,,1,5,"[Label(name=""oncall: jit"")]"
41681,TypeError: cannot create 'generator' instances,2020-07-20 16:00:41+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
41673,"../caffe2/perfkernels/common_avx2.cc:17:2: error: #error ( ""You found a build system error: __AVX2__ is defined (via e.g. -mavx2) "" ""but CAFFE2_PERF_WITH_AVX2 is not defined."");",2020-07-20 13:46:40+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
41667,[Feature Request] named tensor support for `tensordot`(tensor contract),2020-07-20 08:18:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: named tensor"")]"
41661,libgcc_s.so.1 must be installed for pthread_cancel to work,2020-07-20 03:36:31+00:00,,0,40,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""triaged"")]"
41660,Potential bug in net_printer,2020-07-20 02:36:37+00:00,,0,0,"[Label(name=""caffe2"")]"
41653,Enable and disable autograd profiler without context manager mechanics,2020-07-19 16:14:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: profiler"")]"
41639,Error with minimal hogwild test (multiprocessing shared memory),2020-07-18 23:51:31+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
41625,Bring Python torch.slice bindings back or add step argument to torch.narrow,2020-07-18 11:20:14+00:00,,0,9,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research""), Label(name=""function request"")]"
41623,Can we have a way to reset a scheduler back to epoch -1,2020-07-18 09:08:53+00:00,,1,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
41622,New Feature : A very fast algorithm for computing matrix rank,2020-07-18 06:01:23+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: linear algebra"")]"
41571,"torch.cuda.BoolTensor uses 8 bits per element, not 1 bit as reported by element_size()",2020-07-17 01:18:54+00:00,,0,11,"[Label(name=""module: docs""), Label(name=""triaged"")]"
41561,[RPC] Should we support users _not_ calling rpc.shutdown()?,2020-07-16 21:10:54+00:00,,0,13,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
41559,momentum in BatchNorm,2020-07-16 21:06:22+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
41556,Implement LSH Optimizations for Enhanced CPU-Only Performance,2020-07-16 20:45:28+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""needs research"")]"
41531,Test failure in test_shared_allgather_nccl: NCCL error in: ../torch/lib/c10d/ProcessGroupNCCL.cpp:537,2020-07-16 13:12:18+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: POWER"")]"
41530,Parallel computation of the diagonal of a Jacobian,2020-07-16 12:35:57+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
41528,"torch.nn.functional.grid_sample()is doing bilinear interpolation when the input is 5D, i think the mode should add 'trilinear'",2020-07-16 08:12:57+00:00,,0,9,"[Label(name=""module: nn""), Label(name=""triaged"")]"
41525,c++ indexing vs python,2020-07-16 06:47:50+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
41513,Python object None check not supported,2020-07-16 00:46:00+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""days""), Label(name=""TSUsability""), Label(name=""TSRootCause:UnsupportedConstructs"")]"
41512,Tensor.new_tensor is not supported,2020-07-16 00:42:51+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""days""), Label(name=""TSUsability""), Label(name=""TSRootCause:BetterEngineering"")]"
41508,nn.MultiheadAttention causes gradients to become NaN under some use cases,2020-07-16 00:03:06+00:00,,0,69,"[Label(name=""high priority""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""oncall: transformer/mha"")]"
41499,Helping test example code blocks in the docs,2020-07-15 21:39:01+00:00,,1,9,"[Label(name=""module: docs""), Label(name=""feature""), Label(name=""module: tests""), Label(name=""triaged"")]"
41492,Make torch.iinfo/torch.finfo torchscriptable,2020-07-15 19:20:30+00:00,,0,1,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""days"")]"
41486,"LSTMs leak memory in CPU PyTorch 1.5.1, 1.6, and 1.7 on Linux",2020-07-15 18:02:16+00:00,,0,33,"[Label(name=""high priority""), Label(name=""module: rnn""), Label(name=""module: cpu""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
41485,GLOO infiniband with PyTorch,2020-07-15 17:42:06+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
41478,Implement backend fallback for Tracer,2020-07-15 16:32:17+00:00,,0,2,"[Label(name=""module: internals""), Label(name=""triaged"")]"
41433,[JIT][to-backend] `selective_to_backend` infra,2020-07-14 23:31:43+00:00,,0,0,"[Label(name=""oncall: jit"")]"
41428,Add a done() API to torch.futures.Future and ProcessGroup::Work,2020-07-14 21:25:45+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
41419,[jit] Support NamedTuple in tracing,2020-07-14 17:46:42+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""days"")]"
41418,[jit] support `rpc_remote` and `rpc_sync`,2020-07-14 17:45:13+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""days"")]"
41417,[jit] support class polymorphism,2020-07-14 17:42:31+00:00,,1,6,"[Label(name=""oncall: jit""), Label(name=""months""), Label(name=""TSRootCause:DynamicBehaviors""), Label(name=""TSUsability""), Label(name=""TSRootCause:UnsupportedConstructs"")]"
41416,[jit] support for generators and `yield`,2020-07-14 17:40:49+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""months""), Label(name=""TSUsability""), Label(name=""TSRootCause:UnsupportedConstructs"")]"
41415,[jit] `set` builtin support,2020-07-14 17:37:40+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""weeks""), Label(name=""TSUsability""), Label(name=""TSRootCause:UnsupportedConstructs"")]"
41400,test_jit.py fails on Power,2020-07-14 13:43:04+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
41399,Bottleneck when publishing the model using flask about 3 times slower.,2020-07-14 12:45:47+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
41392,"About the description of the mathematical formula of nn.RNN, I think it is wrong",2020-07-14 09:25:12+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
41383,Large overhead (7 microseconds) for PyTorch operation,2020-07-14 03:57:35+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""triaged"")]"
41369,[RFC] Device Placement API for RPC ,2020-07-13 22:32:07+00:00,,0,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
41353,[jit] support for torch.distributed primitives,2020-07-13 17:58:01+00:00,,0,13,"[Label(name=""oncall: jit""), Label(name=""weeks"")]"
41337,Distributed tests fail with pytest,2020-07-13 13:24:18+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
41329,Reference the randomness issue in DataLoader & Dataset documentation.,2020-07-13 06:16:24+00:00,,1,4,"[Label(name=""module: docs""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
41327,torch.nn.parallel.scatter_gather.gather can't gather outputs that are dataclasses,2020-07-13 06:15:32+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
41325,torch.combinations() - Tried to allocate 7869836414.81 GiB,2020-07-12 22:44:50+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
41323,[discussion] Comparison operator chaining,2020-07-12 14:41:50+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: boolean tensor"")]"
41322,SGD documentatiuon detail on g_{t+1},2020-07-12 14:23:22+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
41311,ConvTranspose1d layer behaviour under different channel numbers,2020-07-11 19:55:54+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: convolution""), Label(name=""triaged"")]"
41292,"[RFC, Tracker] DataLoader improvements",2020-07-11 00:23:22+00:00,,0,19,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
41291,Return list of tuples from custom operator,2020-07-11 00:15:54+00:00,,1,1,"[Label(name=""oncall: jit"")]"
41289,List[Any] support in TorchScript,2020-07-11 00:09:39+00:00,,0,5,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""weeks"")]"
41284,add a reparameterized version of inverse Gaussian distribution,2020-07-10 23:06:11+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""enhancement"")]"
41282,[docs] Strange arg names of torch.bmm/mm and tensor.bmm/mm,2020-07-10 22:25:06+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
41256,Add nn.functional.swish alias for nn.functional.silu,2020-07-10 15:43:44+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged"")]"
41246,torch.abs(complex) is divergent from NumPy on vectorized NaN values ,2020-07-10 12:23:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: NaNs and Infs"")]"
41245,torch.sign is divergent from numpy.sign on NaN,2020-07-10 12:04:57+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
41244,torch.tan(complex) on CUDA doesn't handle nonfinite values properly,2020-07-10 12:00:25+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: complex"")]"
41243,[discussion] Unite nn modules nn.Something*d to just nn.Something with appropriate options,2020-07-10 11:43:10+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged"")]"
41242,"test_backward_deadlock fails with ""Directory not empty""",2020-07-10 11:14:54+00:00,,1,8,"[Label(name=""oncall: jit""), Label(name=""module: POWER"")]"
41236,"""out of scope"" variable `cmd` used",2020-07-10 09:27:14+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering"")]"
41232,Cleanup git branches,2020-07-10 07:49:48+00:00,,1,15,"[Label(name=""triaged""), Label(name=""small""), Label(name=""better-engineering""), Label(name=""actionable"")]"
41226,"The name ""Contiguous"" in `torch::MemoryFormat::Contiguous` can mislead users into assuming contiguous memory",2020-07-10 04:42:09+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: memory format"")]"
41213,libTorch cpp docs missing for Tensor::item(),2020-07-09 23:24:12+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged"")]"
41187,test_upsampling_not_recompute_scale_factor fails with Eigen/OpenBLAS,2020-07-09 16:00:18+00:00,,0,4,"[Label(name=""module: tests""), Label(name=""triaged"")]"
41186,test_autograd failures on Power,2020-07-09 15:51:18+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: POWER""), Label(name=""module: linear algebra"")]"
41182,DLPack cannot accept empty CUDA tensor,2020-07-09 13:23:11+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
41178,Failure to build on Power9 due to FXDIV_SOURCE_DIR not being set,2020-07-09 07:37:01+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: POWER"")]"
41177,The new version of the libtorch become slow,2020-07-09 07:22:45+00:00,,0,24,"[Label(name=""module: performance""), Label(name=""oncall: jit""), Label(name=""module: cpp""), Label(name=""triaged"")]"
41164,Pytorch.js would be nice!,2020-07-08 23:58:31+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged"")]"
41162,Advanced indexing gradient is extremely slow when there are many duplicate indices,2020-07-08 23:55:07+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""has workaround"")]"
41149,eager mode quantization should remove qconfig in the (non-leaf module of) quantized model,2020-07-08 21:51:37+00:00,,1,1,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
41148,Source code for some /_modules/.../.../ not displaying on https://pytorch.org/docs/master/_modules/,2020-07-08 21:48:30+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
41142,Support for More Loss Functions,2020-07-08 20:46:42+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: loss""), Label(name=""triaged"")]"
41141,Sum of two tuples becomes a list in torchscript,2020-07-08 19:47:52+00:00,,0,1,"[Label(name=""oncall: jit"")]"
41135,libtorch cmake should PUBLIC ally advertise it as requiring C++14,2020-07-08 18:27:09+00:00,,1,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
41128,Memory bug for backward on torch.sparse.mm? ,2020-07-08 17:23:27+00:00,,0,10,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
41119,TORCH_CUDA_ARCH_LIST deprecation warning,2020-07-08 14:37:10+00:00,,1,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement"")]"
41106,Missing Code for Audio Classification Tutorial,2020-07-08 00:00:29+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
41101,DDP should provide an option for not touching grad of locally unused params,2020-07-07 23:00:40+00:00,,1,26,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
41099,max_pool2d always compute indices even when it's not required,2020-07-07 22:50:44+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: pooling"")]"
41081,Add a function to convert SyncBatchNorm layers back to BatchNorm Layers,2020-07-07 18:39:22+00:00,,0,9,"[Label(name=""module: bootcamp""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
41070,Cannot define v_dim in MultiheadAttention,2020-07-07 12:12:33+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
41046,Human-readable names and operations for TorchScript model graphs,2020-07-06 22:52:57+00:00,,0,0,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""TSUsability""), Label(name=""TSRootCause:PoorIRVisibility"")]"
41027,out= resizing (and restriding) behavior is confusing,2020-07-06 18:59:19+00:00,,0,16,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: safe resize""), Label(name=""topic: bc breaking"")]"
41006,Simplify Adam Optimizer,2020-07-06 10:58:04+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
40997,Is this a bug? The values calculated according to the document isn't equal to the values calculated by framework,2020-07-06 02:16:27+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
40989,Difference between allocated and reserved CUDA memory,2020-07-05 15:26:40+00:00,,0,2,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
40988,'_mm256_extract_epi64' was not declared in this scope when compiling on Debian 32-bit,2020-07-05 14:34:55+00:00,,0,8,"[Label(name=""module: build""), Label(name=""triaged"")]"
40978,[FR] NCCL and bool type,2020-07-04 06:00:29+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""small""), Label(name=""module: data parallel"")]"
40974,Add a launching script for RPC,2020-07-04 01:13:51+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
40972,len of dataloader when using iterable dataset does not reflect batch size,2020-07-03 18:29:33+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
40971,The values calculated according to the document isn't equal to the values calculated by framework,2020-07-03 17:36:40+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
40969,Regarding graphs page on site,2020-07-03 16:27:00+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
40968,Pytorch 1.4 compilation hangs on AMD Epyc,2020-07-03 15:30:26+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vectorization"")]"
40967,Inconsistent behaviour when parameter appears multiple times in parameter list,2020-07-03 15:06:49+00:00,,0,12,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
40959,Will the model run slower when deployed using libtorch ?,2020-07-03 02:20:48+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cpp""), Label(name=""triaged"")]"
40936,[RFC] [RPC] Automatic retries of all requests in TensorPipe agent,2020-07-02 19:34:34+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
40932,MultiheadAttention set(-inf) cause 'Nan' in loss computing,2020-07-02 18:57:50+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""oncall: transformer/mha"")]"
40916,Vectorized torch.eig(),2020-07-02 14:17:01+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: vectorization"")]"
40914,Inconsistent handling of torch.Size.__add__,2020-07-02 13:33:28+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""weeks""), Label(name=""TSUsability""), Label(name=""TSRootCause:PyTorchParityGap"")]"
40906,will you support SRU on mobile?,2020-07-02 09:29:33+00:00,,0,1,"[Label(name=""module: android""), Label(name=""oncall: mobile"")]"
40891,[FR] torch.floor/ceil should support output int dtype,2020-07-02 00:07:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: type promotion"")]"
40886,Improve error messaging when using dictionaries as inputs to a trace,2020-07-01 21:38:19+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement"")]"
40882,JIT fuser result of dropout doesn't fully match eager mode ,2020-07-01 20:35:47+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
40880,Allow TLS to keep distributed autograd context alive,2020-07-01 19:21:12+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
40870,[JIT] cannot statically infer the expected size of a list in this context for positional arguments to Tensor.view(),2020-07-01 17:55:43+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""weeks""), Label(name=""TSUsability""), Label(name=""TSRootCause:UnsupportedConstructs"")]"
40867,[JIT] Infer type of argument foo = None to be Optional[Tensor],2020-07-01 17:25:54+00:00,,0,4,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit"")]"
40859,Option to allow loading state dict with mismatching shapes.,2020-07-01 13:37:31+00:00,,0,35,"[Label(name=""module: nn""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""enhancement"")]"
40854,Build pytorch with cuda11,2020-07-01 07:42:43+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
40843,emit_nvtx context manager is very slow,2020-07-01 00:55:27+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
40790,Encoding dimension argument for F.one_hot,2020-06-30 17:01:52+00:00,,0,2,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: memory format"")]"
40770,Incremental version of pca_lowrank,2020-06-30 12:56:44+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""function request"")]"
40763,Enhance supported types of functional.pad ,2020-06-30 09:26:56+00:00,,1,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
40761,Sparse Convolutional support,2020-06-30 06:45:06+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
40759,Quantization support for F.Softmax,2020-06-30 04:37:19+00:00,,0,6,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
40756,RuntimeError: rois.device().is_cpu() ASSERT FAILED at /vision/torchvision/csrc/cpu/ROIAlign_cpu.cpp:386,2020-06-30 02:13:28+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: vision"")]"
40736,torch::autograd::Function should set AutoNonVariableTypeMode when running forward,2020-06-29 22:37:05+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
40729,Custom c++ extension build process doesn't preserve color from compiler,2020-06-29 21:46:04+00:00,,0,2,"[Label(name=""module: cpp-extensions""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""better-engineering"")]"
40696,"Trace model with floor, Inconsistent performance",2020-06-29 11:57:21+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""days"")]"
40687,libtorch: macros in logging_is_not_google_glog.h have very common names like CHECK or LOG,2020-06-28 21:47:38+00:00,,1,5,"[Label(name=""module: logging""), Label(name=""triaged""), Label(name=""better-engineering"")]"
40679,[JIT] Tracing BCE loss throws error when using weight,2020-06-28 10:36:17+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
40667,Segmentation fault in forward pass using DataParallel and multiple GPUs,2020-06-27 22:16:07+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
40659,[typing] overly restrictive List[int],2020-06-27 05:01:39+00:00,,0,7,"[Label(name=""module: typing""), Label(name=""triaged"")]"
40635,[JIT] Recursive compilation doesn't apply for types used in type expressions but not value expressions,2020-06-26 19:01:01+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
40633,RuntimeError: broken pipe from NCCL,2020-06-26 18:20:09+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl"")]"
40613,Suppress scientific notation in libtorch,2020-06-26 08:16:27+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""feature""), Label(name=""triaged"")]"
40590,Inconsistent behavior between numpy.exp and torch.exp on CPU for complex numbers,2020-06-25 21:43:54+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy"")]"
40581,Libtorch C++ multiple GPU performance slower than single GPU,2020-06-25 19:45:20+00:00,,0,19,"[Label(name=""module: performance""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
40570,Generalized CPU vector reductions,2020-06-25 17:31:52+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: reductions"")]"
40568,Converting NumPy dtype to Torch dtype when using `as_tensor`,2020-06-25 17:20:20+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
40566,"If all parameters are unused by forward pass in a process, backward will not work with DDP.",2020-06-25 16:53:44+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
40564,Stop registering kernels that use DispatchStub as catch all,2020-06-25 16:30:16+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
40563,"Compiling PyTorch with 11.0, V11.0.167",2020-06-25 15:52:00+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
40561,Cannot manually assign a tensor to .grad from TorchScript,2020-06-25 14:26:57+00:00,,0,7,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""days"")]"
40550,RemoteModule enhancements,2020-06-25 02:46:09+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: rpc""), Label(name=""pt_distributed_rampup"")]"
40548,"Embedding with DataParallel can return ""incomplete"" results",2020-06-25 01:30:14+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
40507,SyncBatchNorm for JIT and a list of not supported operations,2020-06-24 15:21:39+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement"")]"
40500,Not able to launch tensorboard using pytorch ,2020-06-24 11:21:08+00:00,,0,8,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
40497,Mixed precision causes NaN loss,2020-06-24 09:33:21+00:00,,0,87,"[Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: amp (automated mixed precision)"")]"
40492,Learning rate change is not applied at designated iteration with a scheduler,2020-06-24 05:31:33+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
40480,torch.autograd.functional.* for models,2020-06-24 01:36:53+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement"")]"
40471,please add 'tensor.astype(dtype_string)' syntax for numpy interoperability,2020-06-23 22:54:15+00:00,,0,7,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
40470,jit's default dtype is different in sandcastle and test_jit.py,2020-06-23 22:53:19+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: tests""), Label(name=""triaged"")]"
40457,DataParallel with Torch 1.5,2020-06-23 19:39:01+00:00,,0,10,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: regression""), Label(name=""module: data parallel"")]"
40456,Print values (but not strings) when STRIP_ERROR_MESSAGES is defined,2020-06-23 19:20:23+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
40441,"[feature request] batch_apply, a general-purpose device-agnostic batch iterator",2020-06-23 17:16:32+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: batching"")]"
40427,"Can we make torch.inverse FP16? - RuntimeError: ""inverse_cuda"" not implemented for 'Half'",2020-06-23 10:09:51+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""has workaround""), Label(name=""module: linear algebra""), Label(name=""module: amp (automated mixed precision)"")]"
40425,Segment Fault after use cusolverDnDestroy() with torch1.5,2020-06-23 08:46:41+00:00,,0,9,"[Label(name=""module: dependency bug""), Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged"")]"
40419,Add a `like` argument to creation ops,2020-06-23 05:15:17+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: tensor creation""), Label(name=""function request"")]"
40417,Missing explanation in torch.utils.tensorboard.add_histogram(),2020-06-23 04:18:26+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: tensorboard"")]"
40403,Cannot re-initialize CUDA in forked subprocess,2020-06-22 22:57:44+00:00,,0,39,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader""), Label(name=""module: cuda""), Label(name=""triaged"")]"
40400,New ProcessGroups created with dist.new_group may leak memory,2020-06-22 22:13:07+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""better-engineering"")]"
40375,Add batched torch.combinations,2020-06-22 16:43:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: batching""), Label(name=""function request"")]"
40373,[discussion] Expressing tensor dimension semantics / constraints through typing / constraints blocks. Constraints block could be scripted/traced and help for tracing/script execution and codegen,2020-06-22 12:26:39+00:00,,0,27,"[Label(name=""module: internals""), Label(name=""feature""), Label(name=""triaged"")]"
40355,Tracking output dimensions of the convolutional layers,2020-06-21 15:47:03+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""triaged"")]"
40319,Too many labels in the repo,2020-06-19 23:12:16+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: infra"")]"
40316,Refactor the adaptive avg pool code,2020-06-19 23:10:35+00:00,,1,15,"[Label(name=""oncall: quantization""), Label(name=""good first issue""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: pooling"")]"
40295,from torch._C import default_generator ImportError: cannot import name 'default_generator',2020-06-19 19:24:20+00:00,,0,7,"[Label(name=""module: build""), Label(name=""module: rocm""), Label(name=""triaged"")]"
40278,Observer in Quantization throws Warning,2020-06-19 09:20:59+00:00,,1,7,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
40275,Conv3d with specific kernel size outputs inconsistent results between FP16 and FP32 in V100 GPU,2020-06-19 09:09:06+00:00,,0,12,"[Label(name=""module: dependency bug""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
40269,caffe2 error during compilation of PyTorch with ROCm on Archlinux,2020-06-19 05:10:22+00:00,,0,3,"[Label(name=""caffe2"")]"
40266,CUDA error: out of memory when running tensorpipe test_cuda,2020-06-19 02:38:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
40250,Include expanded TensorOptions version of op in at:: namespace,2020-06-18 22:32:05+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
40237,Move torch cpp Errors to c10::Error,2020-06-18 20:23:54+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering"")]"
40215,Move all torch.Tensor methods to codegen,2020-06-18 09:19:42+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: pybind"")]"
40208,C++ API for torch.autograd.functional.jacobian,2020-06-18 01:59:46+00:00,,0,18,"[Label(name=""module: cpp""), Label(name=""module: autograd""), Label(name=""triaged"")]"
40147,SyncBatchNorm doesn't work when I set track_running_stats False,2020-06-17 04:35:50+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
40137,Improve RPC test debugability,2020-06-17 02:46:59+00:00,,0,7,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
40134,About torch.backends.cudnn.deterministic issue,2020-06-17 02:05:50+00:00,,0,8,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
40133,Why does Libtorch use more memory than Pytorch does in Python？,2020-06-17 01:20:43+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
40114,ppc64le: test cpp_extensions/rng_extension.cpp failure (without altivec override),2020-06-16 19:44:50+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: POWER"")]"
40107,[RFC] Add a RPC context manager that collects/waits for all RPC futures created in scope,2020-06-16 18:46:22+00:00,,1,6,"[Label(name=""module: bootcamp""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
40098,Updating learning rate with Libtorch 1.5 and optimiser options,2020-06-16 15:53:58+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
40095,Bump up NCCL to 2.7.3,2020-06-16 15:09:00+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl"")]"
40087,Make Scaling in BatchNorm optional ,2020-06-16 10:22:47+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement"")]"
40086,TestListwiseL2rOps::test_lambda_rank_loss fails,2020-06-16 10:20:51+00:00,,0,3,"[Label(name=""caffe2""), Label(name=""module: tests""), Label(name=""triaged"")]"
40071,[JIT][to-backend] Finalize the PyTorchBackendInterface API/naming for external sharing,2020-06-16 01:23:41+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
40070,[JIT][to-backend] Support type refinement for container types in the generated code,2020-06-16 01:19:44+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
40052,Simplify checks that generator has next normal sample cache methods in normal_distribution,2020-06-15 20:31:02+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: random"")]"
40034,Doing optimizing compilations in a separate thread,2020-06-15 17:35:17+00:00,,1,0,"[Label(name=""triaged""), Label(name=""jit-backlog"")]"
40030,matchTensor tests. Add tests to make sure that `isSubtypeOf` and `matchTensor` return equivalent results,2020-06-15 16:06:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""jit-backlog"")]"
40027,[Android Pytorch] TorchScript traced model returns inconsistent output tensors on each run,2020-06-15 15:10:38+00:00,,0,17,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""oncall: mobile"")]"
40024,torch::jit::load -> Unhandled exception ,2020-06-15 14:11:21+00:00,,0,9,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
40020,Caffe2 operation switches current CUDA stream,2020-06-15 08:55:23+00:00,,0,2,"[Label(name=""caffe2""), Label(name=""module: cuda""), Label(name=""triaged"")]"
39993,How do I derive weights for CrossEntropy Loss on my custom dataset?,2020-06-13 15:47:15+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vision"")]"
39990,libtorch 1.5 macos crash when loading on some mac,2020-06-13 10:37:50+00:00,,1,5,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
39972,Port old registration API to new one,2020-06-12 23:38:26+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
39959,Different max_pool2d cpp signatures due to indices. ,2020-06-12 20:19:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: pooling"")]"
39947,[Caffe2]  compilation in c++ undefined reference to `caffe2,2020-06-12 16:08:57+00:00,,0,4,"[Label(name=""module: build""), Label(name=""caffe2""), Label(name=""triaged"")]"
39917, build QT program use libtorch-cxx11-abi-shared-with-deps-1.5.0+cu101 ok with CPU but error with cuda GPU,2020-06-12 02:21:58+00:00,,0,8,"[Label(name=""module: build""), Label(name=""triaged"")]"
39864,Parallelize arguments serde for RPC with TorchScript functions. ,2020-06-11 16:13:51+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: rpc"")]"
39852,Shared file-system initialization in pytorch distributed is slow ,2020-06-11 11:47:28+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
39836,Feedback to split certain doc pages into sub-topics,2020-06-11 00:43:58+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
39832,Torch Distributed Asynch docs with invalid ENV args,2020-06-11 00:28:44+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: rpc"")]"
39820,I would like to install pytorch-nightly from requirements.txt,2020-06-10 22:26:45+00:00,,0,6,"[Label(name=""triaged""), Label(name=""has workaround"")]"
39806,Simplify layers of optionals in `VaryingShape` and `Stride`,2020-06-10 21:30:51+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
39799,Tensor.size() API not correctly documented?,2020-06-10 19:32:42+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
39780,LRP-based explainability,2020-06-10 14:01:22+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research"")]"
39765,Support mainstream pruning techniques ,2020-06-10 01:01:44+00:00,,0,11,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""needs research""), Label(name=""module: pruning"")]"
39757,max_unpool2d and max_unpool3d cpp signature should be similar,2020-06-09 21:32:33+00:00,,1,10,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: pooling"")]"
39745,[JIT] exported dunder methods are ignored,2020-06-09 18:40:14+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
39724,pickle_save on mobile (no longer works with 1.5.0 release),2020-06-09 13:58:37+00:00,,0,2,"[Label(name=""oncall: mobile"")]"
39719,User Objects aren't recursively scripted as nn.Module attributes,2020-06-09 09:26:17+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
39716,Do not modify global random state,2020-06-09 08:20:01+00:00,,0,11,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: random"")]"
39706,[distributed] calling nccl reduce with inconsistent dst hangs,2020-06-09 05:18:22+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""module: deadlock"")]"
39705,[doc] [distributed] example of specifying url etc in url,2020-06-09 05:14:45+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged"")]"
39690,[Quantization] Output tensor type is lost after serializing and loading back a quantized model,2020-06-09 01:16:29+00:00,,0,9,"[Label(name=""oncall: jit"")]"
39682,Run `clang-tidy` on the `aten` folder?,2020-06-08 22:38:25+00:00,,0,0,"[Label(name=""module: lint""), Label(name=""triaged""), Label(name=""module: build warnings""), Label(name=""better-engineering"")]"
39680,CUDA cannot be found,2020-06-08 21:48:03+00:00,,0,13,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: arm"")]"
39674,[BatchNorm] Add boolean flags to choose the stats for normalization,2020-06-08 20:09:30+00:00,,0,22,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request""), Label(name=""module: norms and normalization"")]"
39671,TestTorchDeviceTypeCPU.test_float_to_int_conversion_finite_cpu_uint8 is broken on PowerPC,2020-06-08 19:01:25+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: POWER"")]"
39670,Force JIT to do type inference even when mypy annotated,2020-06-08 18:56:15+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""module: typing""), Label(name=""triaged"")]"
39665,Better err msg for tensor ctor from sequence,2020-06-08 16:50:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering"")]"
39662,[RFC][distributed] RFC: c10d ProcessGroup extension and C++ API change,2020-06-08 16:12:49+00:00,,1,6,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
39656,Broadcasting for torch.cross,2020-06-08 13:53:48+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
39634,Installation from source fails on macOS (No CUDA),2020-06-07 05:06:48+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: macos"")]"
39632,F.affine_grid dispatch async issue,2020-06-07 00:14:15+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
39625,All keys matched successfully missing when loading state dict on optimizers,2020-06-06 09:56:56+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
39619,Switching from CPU build to CUDA build in conda environments is a bit tricky,2020-06-06 06:18:17+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
39603,friend constexpr in templated struct loses constexpr-ness in nvcc,2020-06-05 21:34:12+00:00,,0,2,"[Label(name=""triaged"")]"
39570,Dataloader._shutdown_workers hangs,2020-06-05 10:19:29+00:00,,0,14,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
39569,[JIT] OrderedDict doesn't support custom objects,2020-06-05 10:09:38+00:00,,0,1,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
39539,[JIT] Print out mutation in IR Dumps,2020-06-04 21:38:47+00:00,,0,0,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
39537,Segfault = docker + tensorboard + pytorch,2020-06-04 21:24:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
39524,test_nn_module_tests should run less tests,2020-06-04 15:59:40+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: tests""), Label(name=""triaged"")]"
39522,Valgrind leak checking flags losses in libtorch,2020-06-04 15:10:38+00:00,,0,7,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
39503,pytest suppresses stderr from Python startup by default,2020-06-04 01:36:40+00:00,,0,2,"[Label(name=""module: logging""), Label(name=""module: tests""), Label(name=""triaged"")]"
39495,Misannotation of layer_norm parameters causes internal assert failure,2020-06-04 00:19:14+00:00,,0,4,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
39463,JIT test suite has dependencies across tests,2020-06-03 19:12:25+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
39444,Torch hub: object has no attribute nms,2020-06-03 12:43:24+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: docker"")]"
39443,PyTorch multiprocessing.spawn seems slow with list of tensors,2020-06-03 12:07:26+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
39437,error when specifying sparse=True in embedding,2020-06-03 08:32:56+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
39435,BCEWithLogitsLoss() not equal to BCELoss() with sigmoid(),2020-06-03 07:19:59+00:00,,0,3,"[Label(name=""module: loss""), Label(name=""triaged"")]"
39426,Format issue in `torch.quantization.add_quant_dequant`  documentation parameter section,2020-06-03 02:00:45+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
39421,torch::jit::script::Module::to(torch::kDouble) also casts buffers,2020-06-02 23:40:10+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
39411,Allow to_here to interrupt blocking wait in the case of rpc.remote timeout,2020-06-02 20:34:14+00:00,,1,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""pt_distributed_rampup"")]"
39399,Update RPC doc  to recommend async user functions for non-blocking server execution,2020-06-02 15:05:02+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: rpc"")]"
39395,Morphological operations,2020-06-02 11:12:37+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
39388,"RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:514, unhandled system error, NCCL version 2.4.8",2020-06-02 03:09:13+00:00,,0,11,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: nccl"")]"
39383,Pickling a Tensor or a Storage is not deterministic,2020-06-02 01:26:29+00:00,,0,1,"[Label(name=""module: pickle""), Label(name=""triaged"")]"
39370,Draw quantized tensors in tensorboard,2020-06-01 23:37:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: tensorboard"")]"
39365,Attributes not removed by freeze module,2020-06-01 22:51:15+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
39362,"The conversion of Inplace aten::append to outplace is incomplete, creating incorrect subgraphs",2020-06-01 22:42:39+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
39358,SyncBatchNorm doesn't scale well across multiple nodes on large data sizes,2020-06-01 21:58:10+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
39357,Enable scripting modules with recursive functions,2020-06-01 21:55:35+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""triaged"")]"
39356,Torch script to support dictionary with keys of type tuple,2020-06-01 21:49:32+00:00,,0,8,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
39355,Clean up GIL that used to guard deleted RRef destructions ,2020-06-01 21:37:06+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
39351,Clean up RPC request callback implementation,2020-06-01 20:34:00+00:00,,0,4,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
39317,send a Tensor to Cuda very slow,2020-06-01 04:50:33+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
39310,Make torch.cross `dim` parameter work intuitively,2020-05-31 14:34:21+00:00,,0,4,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""topic: bc breaking"")]"
39309,[JIT] nn.ModuleList loses None objects inside it after scripting,2020-05-31 13:09:53+00:00,,0,1,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
39305,Compilation errors,2020-05-30 23:19:03+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
39298,Caffe 2 android app not working with proguard and minifyEnabled,2020-05-30 06:23:36+00:00,,0,1,"[Label(name=""caffe2"")]"
39292,Tensorboard，graph in pytorch 1.4 is more complicated than pytorch 1.1？,2020-05-30 02:42:03+00:00,,0,0,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
39280,Let future.wait() take in an optional timeout,2020-05-29 23:09:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: rpc"")]"
39279,Differentiable Optimizers,2020-05-29 23:08:25+00:00,,0,10,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
39270,Current implementation of c10::complex does not support being used in shared memory,2020-05-29 20:07:09+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: complex"")]"
39260,Naming inconsistency: padding_mode vs pad_mode + F.conv* docs ops miss padding_mode arg at all,2020-05-29 18:15:23+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: ux"")]"
39250,SummaryWriter `add_hparams` should support adding new hyperparameters ,2020-05-29 15:46:17+00:00,,0,7,"[Label(name=""enhancement""), Label(name=""oncall: visualization"")]"
39245,pytorch-crf model to onnx conversion,2020-05-29 14:26:26+00:00,,0,10,"[Label(name=""module: onnx""), Label(name=""triaged"")]"
39242,Add numerically stable log1mexp = log(1 - exp(-|x|)) function,2020-05-29 13:30:02+00:00,,0,5,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""function request"")]"
39240,[mobile] Running on armeabi-v7a is inconsistent with arm64-v8a,2020-05-29 11:50:01+00:00,,0,2,"[Label(name=""oncall: mobile"")]"
39226,Try Address Sanitizer in MSVC builds,2020-05-29 07:27:06+00:00,,1,7,"[Label(name=""module: windows""), Label(name=""triaged"")]"
39224,Negative stride values in `as_strided`,2020-05-29 05:45:00+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: memory format"")]"
39178,Add support for rsample to MixtureSameFamily Distribution,2020-05-28 17:02:44+00:00,,0,9,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""enhancement"")]"
39134,Crossentropy inconsistent results depending on tensor order,2020-05-28 08:13:28+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: determinism"")]"
39130,`torch.backends` undocumented,2020-05-28 06:13:46+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
39128,"Problems implementing complex support for acosh, asinh, tanh",2020-05-28 04:47:38+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: complex"")]"
39124,[TensorPipe] Errors in pipeWrite should clear out the future in pendingResponseMessage,2020-05-28 02:05:21+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
39123,The MacOS compiler is generating illegal instruction for the division of c10::complex,2020-05-28 02:03:20+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: complex"")]"
39101,Build issue when installing pytorch with USE_FFMPEG=1 USE_OPENCV=1 ,2020-05-27 21:48:38+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
39082,[TensorPipe] Avoid wrapping the future message in order to do atomic test-and-set,2020-05-27 19:26:03+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: tensorpipe"")]"
39064,Add cpack support to CMakeLists.txt,2020-05-27 13:33:26+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
39061,Some @slowtests are never run in CI,2020-05-27 10:27:22+00:00,,0,2,"[Label(name=""high priority""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
39058,Failure when loading quantized pre-trained weights partially,2020-05-27 09:26:49+00:00,,0,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
39050,PyTorch Issue w/ GPU,2020-05-27 05:43:36+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
39022,Cap DDP total number of buckets,2020-05-26 19:01:19+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
39009,Missing OneCycleLR and MultiplicativeLR in lr_scheduler.pyi,2020-05-26 15:45:47+00:00,,1,5,"[Label(name=""module: typing""), Label(name=""triaged"")]"
38997,[doc] document cuda.nccl,2020-05-26 03:54:45+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: nccl"")]"
38996,[FR] API consistency for cuda.comm and distributed,2020-05-26 03:53:38+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
38995,[FR] [distributed] coalesced primitives,2020-05-26 03:48:18+00:00,,0,11,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
38980,runtime error while using default arguments in add_graph() function,2020-05-25 11:31:58+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
38975,Use general ATen dispatch mechanism,2020-05-25 07:45:12+00:00,,0,4,"[Label(name=""module: internals""), Label(name=""triaged"")]"
38974,ATen registrable operator list,2020-05-25 07:31:10+00:00,,0,12,"[Label(name=""module: internals""), Label(name=""triaged"")]"
38973,ATen operator API versioning,2020-05-25 06:54:33+00:00,,0,10,"[Label(name=""module: internals""), Label(name=""triaged"")]"
38964,[JIT] jit can not recognize the imported function,2020-05-24 15:09:23+00:00,,1,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
38955,fold variation,2020-05-23 14:15:18+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request"")]"
38948,torch.lobpcg always breaks for autograd,2020-05-23 04:38:20+00:00,,1,67,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
38940,[FR] Support SyncBatchNorm in DataParallel,2020-05-22 20:32:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: nccl""), Label(name=""module: data parallel"")]"
38936,[FR] DataParallel arg rename device_ids->devices,2020-05-22 18:20:03+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
38911,[FR] cuda.comm.broadcast/reduce_add support `out=`,2020-05-22 05:35:55+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
38910,Memory Leak with Docker GPU,2020-05-22 04:27:09+00:00,,0,13,"[Label(name=""high priority""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: regression"")]"
38876,Override `__call__` instead of `forward`,2020-05-21 16:20:15+00:00,,0,1,"[Label(name=""module: typing""), Label(name=""triaged"")]"
38863,[JIT] named_(parameters | buffers) do not support recursive iteration. ,2020-05-21 09:20:33+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
38855,Can not compile GridSamplerKernel.cpp with gcc-9.3,2020-05-21 03:55:06+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
38854,Can't compile QuantizedOpKernels.cpp using gcc-9.3,2020-05-21 03:52:43+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
38853,Weight decay in AdamW,2020-05-21 03:50:44+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
38788,Convergence issues when using pytorch's native AMP,2020-05-20 16:35:33+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: amp (automated mixed precision)"")]"
38782,SPMG in DDP does not have gradient computation and communication overlap?,2020-05-20 15:10:15+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
38767,weight_decay in Adam is not an L2 Penalty,2020-05-20 08:45:01+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
38765,LibTorch 1.5.0 not supporting GLIBC < 2.23,2020-05-20 07:34:44+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
38752,test_float_to_int_conversion_finite_cpu_int16 is failing on MacOS,2020-05-20 01:59:53+00:00,,1,3,"[Label(name=""high priority""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: numpy"")]"
38744,[jit] `jit.annotate` and multiple compilation of functions with different types,2020-05-19 23:20:54+00:00,,0,1,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
38737,equivalent of tensorflow's embedding_lookup_sparse,2020-05-19 20:46:47+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged"")]"
38720,DOC: add documentation for undocumented classes and methods,2020-05-19 14:17:03+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
38719,Building NVCC (Device) failed when building from source,2020-05-19 13:13:59+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
38709,NaN Loss for FasterRCNN on Multiclass Object Detection on Custom Dataset COCO,2020-05-19 05:51:10+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vision"")]"
38703,torch.as_tensor(np_array) is sometimes much faster than torch.tensor(np_array),2020-05-19 03:59:28+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: numpy"")]"
38684,Add Plackett-Luce distribution,2020-05-18 22:40:07+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged"")]"
38677,TestCase.assertEqual does not distinguish Python builtin types and single-element Tensor,2020-05-18 21:23:32+00:00,,1,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
38671,Add CUDA callback to Python API,2020-05-18 18:38:43+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: rpc"")]"
38662,Unify CPU/CUDA exponential transformation formula,2020-05-18 17:06:07+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random"")]"
38650,Implement torch.erf for complex dtypes,2020-05-18 15:02:09+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex"")]"
38643,torch while loading weighs found runtime error on storage has wrong size: expected 4254413747647032608 got 1024 ,2020-05-18 10:24:13+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
38642,Synchronization problem in torch.distributed with MPI on CUDA ,2020-05-18 10:19:20+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
38640,Maxunpool seems to give a weird error message,2020-05-18 09:51:46+00:00,,0,1,"[Label(name=""triaged"")]"
38639,Difference between using a python list and nn.ModuleList,2020-05-18 09:43:44+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
38630,Torchvision error TypeError: _resolve_type_from_object(),2020-05-17 20:22:23+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: vision"")]"
38624,Wheels not manylinux1 compliant,2020-05-17 14:49:48+00:00,,0,6,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
38623,Providing CUDA tensor to model on CPU causes a crash,2020-05-17 11:17:35+00:00,,0,6,"[Label(name=""module: crash""), Label(name=""module: rnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
38622,Clarification for usage of negative loss with optim.lr_scheduler.ReduceLROnPlateau,2020-05-17 10:44:53+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
38619,"Can you add NMS,RoIAlign,RoIPool for libtorch?",2020-05-17 03:52:57+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: vision"")]"
38616,RuntimeError: num_gpus <= 16 INTERNAL ASSERT FAILED ,2020-05-17 02:09:59+00:00,,0,19,"[Label(name=""module: multi-gpu""), Label(name=""module: cuda""), Label(name=""triaged"")]"
38614,`SummaryWriter.add_graph` borks with simple example,2020-05-16 21:43:51+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
38613,Investigate using log1p instead of log in transformation functions(TransformationHelper.h),2020-05-16 21:08:16+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: random"")]"
38612,Investigate exponential distribution improvements,2020-05-16 21:04:54+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: random"")]"
38611,Investigate using -cospi(u) / sinpi(u) instead of tan(pi * (u - 0.5)) in transformation::cauchy,2020-05-16 21:00:18+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: random"")]"
38595,torch.norm p/ord parameter documentation is wrong,2020-05-16 05:55:22+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
38569,[quantization] Version support for quantization BC tests,2020-05-15 19:36:21+00:00,,1,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
38564,tensorboard projector mode with custom metadata_header with only one label name,2020-05-15 18:27:22+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
38553,"When I use cuda(), wg = th.matmul(extra_obs, extra_obs.transpose(-2, -1)) take a mistake",2020-05-15 16:43:26+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
38550,Returning a tensor instead of a list in split and chunk,2020-05-15 14:55:02+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""shadow review"")]"
38548,Add Distributed LR Scheduler to RPC,2020-05-15 14:34:33+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
38543,Make rebuildBucket() to be async in c10d reducer,2020-05-15 07:55:38+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
38541,Doc update regarding predictability of experiments using Seeds and Workers,2020-05-15 06:39:59+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: determinism"")]"
38536,"build libtorch problem: Configuring incomplete, errors occurred!  _mm256_abs_epi16",2020-05-15 03:51:10+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
38510,[DISCUSSION] RPC server-side ThreadLocalState,2020-05-14 22:07:02+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""module: rpc"")]"
38487,expected scalar type Half but found Float with torch.cuda.amp and torch.nn.DataParallel,2020-05-14 17:07:09+00:00,,0,13,"[Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""module: amp (automated mixed precision)"")]"
38475,TopK implementation slower than a custom divide and conquer implementation,2020-05-14 13:57:43+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""good first issue""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
38474,Scale parameter downcasted and rounded down in pytorch.distributions.Normal,2020-05-14 13:45:00+00:00,,0,5,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
38473,Python builtin function next() is currently not supported in Torchscript,2020-05-14 12:38:36+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
38472,[torch.jit.trace] torch.jit.trace fixed batch size CNN ,2020-05-14 12:03:33+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
38471,Immediate mode API (with functional flavor) for optimizers,2020-05-14 11:33:26+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
38470,[Feature] Option to have zeros/ones/full output tensor with zero strides,2020-05-14 10:47:18+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: tensor creation""), Label(name=""function request"")]"
38457,Named Tensor and Indexing,2020-05-14 05:58:30+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
38443,JitTest.testAutogradProfiler is broken in test_misc.cpp,2020-05-13 22:08:11+00:00,,0,8,"[Label(name=""oncall: jit""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
38437,[JIT] torch.tensor needs a Tensor overload,2020-05-13 21:37:27+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""small"")]"
38419,[RFC] Add tar-based IterableDataset implementation to PyTorch,2020-05-13 18:54:24+00:00,,1,31,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
38412,No MKL Compatible Conda installation for PyTorch 1.5,2020-05-13 18:17:34+00:00,,0,27,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""module: mkl"")]"
38394,4D tensor support for torch.nn.functionnal.fold() (col2im),2020-05-13 12:30:16+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request"")]"
38354,"Can I add more ""Project Documentation"" on the PYPI webpage? ",2020-05-12 21:06:32+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""small"")]"
38337,"Clicking ""Click here to view docs for latest stable release."" on some pages leads to nowhere",2020-05-12 17:59:11+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
38328,Provide an issubdtype API,2020-05-12 15:33:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: type promotion"")]"
38323,Support alternate casting rules,2020-05-12 15:02:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: type promotion"")]"
38319,c10/macros/cmake_macros.h not exists,2020-05-12 14:12:42+00:00,,0,1,"[Label(name=""triaged""), Label(name=""oncall: mobile"")]"
38312,Status of support for training on mobile,2020-05-12 09:49:17+00:00,,0,5,"[Label(name=""oncall: mobile"")]"
38310,Compiling errors when trying to cross-compile the C++ API for RTOS (QNX),2020-05-12 09:12:52+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
38273,Adding model metadata in TorchScript model file,2020-05-11 21:49:34+00:00,,0,1,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""module: serialization"")]"
38272,"PyTorch's rot90 returns a new tensor, inconsistent with NumPy's returning a view",2020-05-11 21:31:54+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
38271,"PyTorch's flip returns a new tensor, but NumPy's flip returns a view",2020-05-11 21:30:57+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
38245,Make torch.rpc accept store as optional parameter,2020-05-11 17:19:30+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
38241,SIGXCPU at test_cholesky_solve with AMD EPYC 7742 64-Core Processor,2020-05-11 17:01:15+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
38240,RuntimeError: arg_types.size() == param_names.size() - (moduleSelf_ ? 1 : 0) INTERNAL ASSERT FAILED,2020-05-11 16:22:59+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""module: typing""), Label(name=""triaged"")]"
38239,Failed to link torch_library using cmake,2020-05-11 16:21:32+00:00,,0,6,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
38233,When TorchScripted module has bad type annotation you get bad error message,2020-05-11 15:14:57+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
38231,Python autograd engine threads never terminate in Python 3.5-3.8,2020-05-11 14:50:41+00:00,,1,4,"[Label(name=""module: crash""), Label(name=""module: autograd""), Label(name=""module: ci""), Label(name=""triaged"")]"
38228,pybind11::gil_scoped_release: crash on exit with daemon threads,2020-05-11 14:38:29+00:00,,1,13,"[Label(name=""high priority""), Label(name=""module: dependency bug""), Label(name=""module: crash""), Label(name=""triaged"")]"
38212,"Please help, building failing with MAGMA support",2020-05-11 05:47:47+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
38208,nn.Module Abstract Class attribute overrides Child.,2020-05-10 17:32:58+00:00,,0,2,"[Label(name=""triaged"")]"
38206,Loops are very slow compared to tensorflow,2020-05-10 12:32:50+00:00,,1,6,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
38205,RESOLVED: Disable zero-dim CUDA tensors interacting with CUDA tensors on other devices,2020-05-10 09:51:21+00:00,,0,2,"[Label(name=""module: bc-breaking""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
38204,missing dependency `protobuf` for caffe2,2020-05-10 08:10:15+00:00,,0,10,"[Label(name=""module: build""), Label(name=""triaged"")]"
38202,IndexError reports the wrong dimension when fancy indexing,2020-05-10 00:39:49+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
38197,Why no `torch.randperm_like`?,2020-05-09 17:27:17+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: tensor creation"")]"
38193,Can't Build Pytorch0.4.1 From Source,2020-05-09 11:52:35+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
38190,test_ReplicationPad3d (test_nn.TestNN) takes too long to run,2020-05-09 07:45:20+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
38189,test_LocalResponseNorm_3d_custom_params (test_nn.TestNN) takes too long to run,2020-05-09 07:44:44+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
38188,test_interpolate_nearest_scale_3d in test_nn takes too long to run,2020-05-09 07:43:56+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
38185,Feature Request: Sampled softmax loss,2020-05-09 06:20:47+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
38184,Feature Request: Log uniform candidate sampler,2020-05-09 06:18:25+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
38177,valgrind says libtorch has memory leak,2020-05-09 02:36:58+00:00,,0,1,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
38170,"OneCycleLR  raises ""Tried to step { step_num + 1 } times"" after the value is more than expected.",2020-05-08 23:40:59+00:00,,0,1,"[Label(name=""triaged"")]"
38155,"Python script name with ""profile.py"" will run twice",2020-05-08 21:32:59+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
38142,[JIT] Aliased Python references to script::Object escape IValue reference counting,2020-05-08 19:05:26+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
38138,"TorchScript to support == None, != None",2020-05-08 18:48:44+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
38135,test_cpp_warnings_have_python_context_cpu fails under some build configurations,2020-05-08 18:33:34+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged"")]"
38122,Pybind11 cpp extensions broken with pytorch v1.5.0,2020-05-08 15:56:21+00:00,,1,21,"[Label(name=""high priority""), Label(name=""module: build""), Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: regression"")]"
38118,Add helpers to save/load RPC-based models,2020-05-08 14:35:34+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
38090,ImportError: libtorch_cpu.so: cannot open shared object file: No such file or directory,2020-05-08 00:24:05+00:00,,0,12,"[Label(name=""module: build""), Label(name=""triaged"")]"
38057,DNNL's backward pass much slower when using nn.grad.conv2d_input and nn.grad.conv2d_weight,2020-05-07 21:42:49+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
38051,Div by zero error not triggered and inf not returned when dividing by 0 for some dtypes,2020-05-07 21:21:02+00:00,,1,8,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
38035,Quantile Regression Loss,2020-05-07 19:06:44+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""OSS contribution wanted"")]"
38034,Support Slicing of ModuleList during JIT model tracing/scripting ,2020-05-07 19:04:37+00:00,,1,5,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""large""), Label(name=""medium"")]"
38019,"torch.cuda.nccl.init_rank does not handle ""uid"" properly, causing runtime error",2020-05-07 16:22:44+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: nccl"")]"
38012,Formatting of topic and sub-topic pages,2020-05-07 12:32:19+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
38010,Split more pages into sub-topics,2020-05-07 12:22:01+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra""), Label(name=""open source"")]"
38009,Resnet Model always predicting same label,2020-05-07 11:40:55+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: vision"")]"
38006,Inconsistent Documentation about Optimizer.step(closure),2020-05-07 09:30:27+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
38000,"New padding size format for F.pad, allowing named tensors and more clear syntax overall",2020-05-07 05:59:42+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
37995,unsqueeze support for named tensors,2020-05-07 04:48:08+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: named tensor"")]"
37988,JIT compilation of NamedTuple Containing a NamedTuple fails,2020-05-07 01:22:56+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
37987,Special methods on torchscript custom class,2020-05-07 01:20:42+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
37985,torch.save incompatible with lzma file,2020-05-07 00:20:17+00:00,,0,9,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
37928,CUDA sources are not cached with sccache,2020-05-06 14:43:04+00:00,,1,13,"[Label(name=""module: build""), Label(name=""module: windows""), Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: regression"")]"
37895,torch.addmv can't take as input tensors with different dtypes,2020-05-06 00:24:14+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: type promotion"")]"
37883,Support @property decorator in TorchScript,2020-05-05 21:27:07+00:00,,0,6,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
37880,"[RFC] Don't install CI dependencies in build scripts, install them in underlying docker images",2020-05-05 21:19:49+00:00,,0,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
37863,Deprecate type() and type_as() call,2020-05-05 19:30:58+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: ux"")]"
37860,autograd engine callbacks don't respect non-default cuda streams,2020-05-05 19:25:45+00:00,,0,13,"[Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""triaged"")]"
37847,llvmlite version issue when upgrading CI docker image to python 3.8,2020-05-05 18:35:05+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
37837,[DRAFT] Channels Last + AMP support plan for 1.6 release,2020-05-05 17:00:59+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
37814,DistributedDataParallel does not support Modules that take no inputs.,2020-05-05 06:02:18+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
37809,"Add Numpy-like ""order"" argument to reshape",2020-05-05 03:42:25+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""has workaround"")]"
37782,Guard Gloo and TensorPipe related code in RPC with #ifdef,2020-05-04 18:46:29+00:00,,0,0,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""module: tensorpipe"")]"
37766,CMake Documentation Issue,2020-05-04 15:19:11+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""triaged"")]"
37762,Add docstring to `torch/__init__.pyi`?,2020-05-04 11:27:13+00:00,,0,10,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: doc infra"")]"
37751,Documentation of _CtxMethodMixin: must be tensors?,2020-05-04 07:31:07+00:00,,1,5,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged"")]"
37740,torch Summary writer does not display torchvision.io.read_video output,2020-05-03 19:44:12+00:00,,0,0,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
37734,torch.cdist returns inconsistent result,2020-05-03 15:37:48+00:00,,0,16,"[Label(name=""module: numerical-stability""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: distance functions"")]"
37731,Variational Dropout In RNN,2020-05-03 10:54:27+00:00,,0,0,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""enhancement"")]"
37713,Builtin FusedLayerNorm is slower than apex one,2020-05-02 07:52:25+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
37684,"Add Compound key, make custom ops default to it (but keep internal users using CatchAll)",2020-05-01 19:08:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""internals"")]"
37682,LSTMCell consumes x1.5 more memory on CUDA on pytorch >=1.3 comparing to pytorch 1.2,2020-05-01 18:58:30+00:00,,0,2,"[Label(name=""module: rnn""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
37664,Remove everything from a GPU (including drivers),2020-05-01 14:38:14+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
37629,logging_is_not_google_glog.h:24:11: error: 'const int ERROR' redeclared as different kind of symbol  (v1.3.0),2020-04-30 23:24:22+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
37598,NCCL fails to find cuda include dir,2020-04-30 18:56:47+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl"")]"
37588,"test_qnnpack_sigmoid failing on old CPU, built pytorch 1.5.0",2020-04-30 17:19:25+00:00,,0,8,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
37585,Unable to use torch.det() inside nn.DataParallel with multiple gpus,2020-04-30 16:31:35+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""module: linear algebra"")]"
37556,"torch.cartesian_prod(*tensors) error when you have tensors with [x,y]",2020-04-30 02:05:20+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
37554,Add name to Class Parameter(),2020-04-30 01:28:30+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: rpc"")]"
37549,Are there any differences in kernel memory between RX2080's and Quadro RTX4000?  ,2020-04-29 23:58:39+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
37529,Implement generic function scheduler in c10/util,2020-04-29 20:37:33+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
37512,Improve visibility in test suite timings,2020-04-29 18:45:32+00:00,,0,5,"[Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
37510,"Cannot build pytorch with linker arguments in C{,XX}FLAGS",2020-04-29 17:18:35+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
37488,undefined reference to pthreadpool_compute*,2020-04-29 06:22:37+00:00,,0,8,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: xnnpack"")]"
37487,Log-linear version of cumsum and cumprod,2020-04-29 06:12:10+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""triaged"")]"
37484,No speedup from channels_last with DataParallel,2020-04-29 04:53:59+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""module: memory format"")]"
37457,[RuntimeError] Tensor creation using storage fails,2020-04-28 20:44:39+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
37449,RuntimeError: CUDA error: an illegal memory access was encountered with channels_last,2020-04-28 19:35:49+00:00,,0,12,"[Label(name=""high priority""), Label(name=""module: dependency bug""), Label(name=""module: binaries""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
37444,Multi-Process Single-GPU is bad,2020-04-28 18:54:57+00:00,,0,10,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
37443,torch.clamp_max clamp_min shouldn't be there,2020-04-28 18:54:53+00:00,,0,2,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
37442,Tensor.is_distributed not documented,2020-04-28 18:52:14+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: docs"")]"
37441,Tensor.as_strided_ is not documented,2020-04-28 18:51:18+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
37440,Tensor.is_same_size not documented,2020-04-28 18:49:30+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
37434,rsub incorrectly exposed in torch,2020-04-28 18:35:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
37416,[docs] Unclear return type of torch.randint and extra comma in arg spec,2020-04-28 15:30:25+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
37411,"Questions about ""torch.utils.tensorboard.add_graph"": Could I use it to see network graph's compute time and memory? ",2020-04-28 10:18:31+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: tensorboard"")]"
37410,Reset a `torch.optim.Optimizer`,2020-04-28 09:35:50+00:00,,0,11,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
37409,Compatibility of subset dataset with disabled batch sampling,2020-04-28 09:32:27+00:00,,0,4,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
37408,torch.cdist() implementation without using contiguous() calls,2020-04-28 09:31:22+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: distance functions"")]"
37406,3D grouped & depthwise convolution very slow on backward pass,2020-04-28 08:13:45+00:00,,0,1,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
37387,The pytorch's graph is lack of common names for nodes,2020-04-28 02:44:47+00:00,,2,3,"[Label(name=""module: bootcamp""), Label(name=""feature""), Label(name=""module: tensorboard""), Label(name=""oncall: visualization""), Label(name=""days"")]"
37386,Add BufferDict container,2020-04-28 01:14:36+00:00,,0,12,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
37384,Error running trace on Pytorch Crowd Counting model,2020-04-28 00:46:25+00:00,,0,15,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
37373,Move bernoulli_() to DistributionTemplates,2020-04-27 21:56:24+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: random"")]"
37363,"cdist docs imply only one batch dimension is possible, but actually arbitrarily many are allowed",2020-04-27 21:14:26+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: distance functions"")]"
37354,Efficient handling special gradient values in the autograd,2020-04-27 18:59:45+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
37344,[JIT] Not support for MaskRCNNPredictor,2020-04-27 14:38:15+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
37343,qnnpack's quantized-add gives wrong result,2020-04-27 12:40:40+00:00,,2,4,"[Label(name=""oncall: quantization""), Label(name=""triaged""), Label(name=""oncall: mobile"")]"
37334,Why do we not use TorchScript to build graph for tensorboard,2020-04-27 03:39:57+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
37332,Concerning default confiugration for distribution packages,2020-04-27 03:20:39+00:00,,0,8,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
37324,Multiprocessing: model shared between processes hangs during copy.deepcopy,2020-04-26 21:17:55+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
37314,equal_nan keyword not implemented for complex torch.isclose,2020-04-26 08:43:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy"")]"
37300,Data caching module a la `Sampler`,2020-04-25 13:20:08+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
37282,python setup.py install error,2020-04-25 04:35:59+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
37261,"intermittent failures of ""test_remote_script_module""",2020-04-24 21:31:06+00:00,,0,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""module: flaky-tests"")]"
37250,Inconsistency between GPU memory usage in torch.cuda.memory_summary and nvidia-smi,2020-04-24 19:36:57+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
37246,`max_norm` parameter on nn.Embedding will fail inside nn.DataParallel,2020-04-24 18:32:03+00:00,,0,7,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
37208,RuntimeError: Tried to instantiate class __file__.__file__ but it does not exist! Ensure that it is registered via torch::jit::class_,2020-04-24 03:19:23+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
37204,Make it harder to make SIOF bugs for torchbind classes referenced by schemas,2020-04-24 02:49:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
37162,torch.distributions bug in RelaxedOneHotCategorical.log_prob ,2020-04-23 18:30:26+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
37160,Enhanced operator context when reporting errors,2020-04-23 18:17:50+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: shape checking"")]"
37155,Per-cluster biases in AdaptiveLogSoftmaxWithLoss,2020-04-23 17:22:06+00:00,,1,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs research"")]"
37153,CPU out of bound memory access in CUDA reduction kernel config,2020-04-23 17:04:23+00:00,,0,7,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: TensorIterator"")]"
37149,Cuda profiler + DataParallel + manual profiling start = strange profiling overhead pattern,2020-04-23 14:39:38+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
37142,Propagation of channels-last layout leads to massive slowdowns in 1.5 compared to 1.4,2020-04-23 12:02:14+00:00,,2,13,"[Label(name=""module: performance""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: memory format"")]"
37136,[Design][RFC] RemoteModule API Design,2020-04-23 08:03:15+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: rpc"")]"
37113,pip install torch==1.4.0 is broken when using CUDA 10.1,2020-04-22 23:01:17+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
37104,[JIT] Use of global value creates confusing error message,2020-04-22 21:17:04+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""small"")]"
37103,Legacy fuser doesn't do remainder consistently with `aten::remainder`,2020-04-22 21:07:18+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
37092,nn.Bilinear cannot be used inside nn.Sequential,2020-04-22 18:29:31+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
37079,Result parameters from Single-Process Multi-GPU DDP training on RNN do not match local training,2020-04-22 15:57:16+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
37067,can't wrap two models in the same class,2020-04-22 13:00:28+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
37066,Saved model behaves differently on same data,2020-04-22 12:59:46+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: serialization""), Label(name=""triaged"")]"
37065,Deprecated mask fill mask type can causes pages and pages of repeated messages,2020-04-22 12:54:12+00:00,,1,1,"[Label(name=""triaged"")]"
37063,Misleading documentation in torch.nn.functional.fold,2020-04-22 10:53:54+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
37057,CUDA error: device-side assert triggered @ model.cuda(),2020-04-22 06:12:04+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
37048,copy_ slowness,2020-04-22 03:05:40+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
37016,Guidance on implementing a new backend,2020-04-21 18:30:20+00:00,,0,7,"[Label(name=""oncall: mobile"")]"
37015,Converting to Torch Script: cpp_module does not match nn_module,2020-04-21 18:27:03+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
37010,Make it an error to def() an operator multiple times,2020-04-21 17:34:20+00:00,,0,2,"[Label(name=""module: bootcamp""), Label(name=""triaged"")]"
37004,"RuntimeError: NCCL error in ProcessGroupNCCL.cpp:290, unhandled system error",2020-04-21 16:24:25+00:00,,0,2,"[Label(name=""module: dependency bug""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl"")]"
37002,[RFC] Modularize DistributedDataParallel,2020-04-21 16:09:12+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
36999,Add a CI configuration to test USE_DISTRIBUTED=0,2020-04-21 14:08:13+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
36990,[docs] Explain active_bytes in torch.cuda.memory_stats and Cuda Memory Management,2020-04-21 08:28:28+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
36989,pytorch latest update(1.4) broke CosineAnnealingWarmRestarts: T_cur is not define,2020-04-21 08:04:37+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
36931,Pull hacked twins out of prim ops,2020-04-20 16:09:10+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
36926,JIT string ops and other miscellaneous ops probably shouldn't be in aten namespace,2020-04-20 15:01:58+00:00,,0,2,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
36922,Multiprocess DataLoader with DLPack conversion sometimes corrupts memory,2020-04-20 14:49:48+00:00,,0,6,"[Label(name=""module: multiprocessing""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: xnnpack"")]"
36917,"jit trace failed due to ""failed to differentiate `prim::ListConstruct`""",2020-04-20 08:18:10+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
36914,Problem with c10/utils/variant.h,2020-04-20 06:58:10+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
36910,jit.script leads to RuntimeError: attribute lookup is not defined on python value of type in some cases,2020-04-20 02:39:08+00:00,,0,4,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""small"")]"
36891,pytorch and c++ inference disagree,2020-04-19 07:53:47+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
36874,Memory leak upon exception for interactive consoles,2020-04-18 18:49:43+00:00,,0,2,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
36871,Stochasticity for DistributedDataParallel on CPU but not on GPU,2020-04-18 17:31:21+00:00,,0,31,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""module: data parallel"")]"
36804,c++: error: unrecognized command line option '-Wthread-safety',2020-04-17 15:49:49+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
36754,Clearer guidance on when to define an operator as a method on torchbind'ed class versus standalone function,2020-04-16 22:14:53+00:00,,0,5,"[Label(name=""triaged"")]"
36753,When you try to register a kernel that make boxed from unboxed functor doesn't support you get a horrible error message,2020-04-16 21:57:04+00:00,,0,0,"[Label(name=""triaged"")]"
36748,return_index option for torch.unique,2020-04-16 20:07:43+00:00,,0,23,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""function request"")]"
36739,Custom class type name is very wordy,2020-04-16 19:16:54+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
36733,Custom Generators don't work in JIT,2020-04-16 18:35:54+00:00,,0,0,"[Label(name=""triaged"")]"
36721,[1.4.1] Cuda build fails,2020-04-16 12:11:50+00:00,,0,10,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
36718,Support alpha channel in tensorboard.add_figure,2020-04-16 08:10:54+00:00,,0,5,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
36713,variable name N_ conflicts with an internationalization macro in glib,2020-04-16 04:32:34+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: build""), Label(name=""triaged"")]"
36706,Reduction for `torch.int8` is super slow on CUDA,2020-04-16 02:41:52+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: TensorIterator"")]"
36650,state_dict and load_state_dict methods for DataLoader and Sampler to continue training at specific epoch and batch,2020-04-15 11:22:04+00:00,,0,15,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
36649,"RuntimeError: Expected cuda::check_device({sparse_, r_, t, dense}) to be true, but got false.  ",2020-04-15 09:25:11+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
36638,Poor elmenetwise_kernel performance becomes critical on small mini-batch sizes,2020-04-15 02:57:18+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: TensorIterator"")]"
36603,TorchScript Support for Named Tensors,2020-04-14 19:59:18+00:00,,0,0,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
36577,Add load_state_dict and state_dict() in C++,2020-04-14 11:52:24+00:00,,0,7,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
36575,One confusion about the CompilationUnit destructuring process in torch/jit/__init__.py ,2020-04-14 11:25:41+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
36572,[1.4.1] cmake3 not found,2020-04-14 09:45:06+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
36570,Libtorch build error when setting both `USE_GLOO` and `USE_SYSTEM_NCCL` to `ON`,2020-04-14 08:54:00+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: nccl"")]"
36560,Allow `__array__` to automatically detach and move to CPU,2020-04-14 05:03:29+00:00,,0,15,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: numpy"")]"
36553,Typecasting issue in MSELoss,2020-04-14 02:06:07+00:00,,0,1,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
36524,"Drop _stacklevel from argspecs of F.softmax, F.softmin, F.log_softmax (for implicit dim has been long deprecated)",2020-04-13 22:21:54+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
36519,Restructure test_c10d.py and test_distributed.py,2020-04-13 21:33:05+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering"")]"
36517,XNNPACK operators are not actually registered under xnnpack namespace,2020-04-13 21:30:58+00:00,,1,4,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: xnnpack"")]"
36516,DDP should divide bucket contents by the number of global replicas instead of world size,2020-04-13 21:30:40+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
36508,Quantized _out functions don't follow same conventions as other out functions in the codebase,2020-04-13 20:31:56+00:00,,1,6,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""better-engineering"")]"
36469,Wrong results for multiplication of non-finite complex numbers with real numbers,2020-04-13 01:54:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy"")]"
36444,Comparison ops for Complex Tensors,2020-04-12 00:12:51+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: numpy"")]"
36437,Issue when linking C++ code with libtorch_cpu: cuda not detected,2020-04-11 16:20:57+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
36436,"After `create_graph=True`, calculating `backward()` on sparse Tensor fails",2020-04-11 15:44:36+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
36426,Any reference to LPPool2d,2020-04-11 04:59:51+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
36407,Unable to build wheel from RC3,2020-04-10 19:48:57+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
36386,Docs of distributed module do not include the full documentation for torch.distributed.launch,2020-04-10 13:50:06+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
36380,Population Count Op,2020-04-10 09:42:48+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
36378,CMake targets wrongly forward unknown options to NVCC (v1.5+),2020-04-10 08:59:16+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
36370,Jit doesn't match schema like eager mode does,2020-04-10 06:48:32+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
36356,Memory leak issue still exists in CI ,2020-04-10 01:06:01+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged"")]"
36333,Illegal memory access / CUDNN_STATUS_MAPPING_ERROR on Quadro 8000,2020-04-09 19:46:10+00:00,,0,13,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
36317,Updating a ModelDict instance with another ModelDict instance generates error.,2020-04-09 14:58:20+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
36314,[discussion] Refactor spectral_norm to use the newly merged lowrank solvers and proposal for Linear Algebra Cookbook page,2020-04-09 13:55:14+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
36309,"torch.ceil, torch.floor should accept a dtype argument",2020-04-09 11:38:07+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: ux"")]"
36307,[docs] Matrix transpose missing in formula in nn.functional.bilinear docs,2020-04-09 11:10:45+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
36217, Rectify docs for MultiLabelSoftMarginLoss,2020-04-08 09:57:32+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
36211,[JIT] support self.named_buffers and self.named_parameters in TorchScript,2020-04-08 05:31:14+00:00,,1,5,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement"")]"
36182,## 🐛 Bug: QNNPACK tests failing on master on Nexus 6,2020-04-07 23:33:04+00:00,,0,0,"[Label(name=""oncall: mobile"")]"
36175,New dtype ComplexPolarFloat (phasor),2020-04-07 21:54:35+00:00,,0,7,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""enhancement"")]"
36160,Decouple DDP from CUDA,2020-04-07 20:03:05+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
36152,Seg Fault: import vaex with torch,2020-04-07 17:37:19+00:00,,0,5,"[Label(name=""module: binaries""), Label(name=""module: crash""), Label(name=""triaged"")]"
36140,Inconsistent ProcessGroupMPI work data structure for send/recv and collectives,2020-04-07 14:28:12+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering"")]"
36125,build Pytorch-1.5.0-rc1 from source fail,2020-04-07 03:28:51+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
36108,Add a flow_sample function to sample optical flows and displacement fields,2020-04-06 22:46:15+00:00,,1,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
36107,Allow grid_sample to accept pixel units (absolute coordinates),2020-04-06 22:43:55+00:00,,1,2,"[Label(name=""proposal accepted""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: vision"")]"
36099,"In AutogradContext, get_saved_variables() should be renamed to get_saved_tensors()",2020-04-06 20:57:46+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
36091,[quantization] torch.quantized_lstm and torch.quantized_gru not documented,2020-04-06 19:43:14+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
36066,Add Specific Warning/Error For Unsupported GPU or Systems,2020-04-06 14:48:56+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
36062,RuntimeError CUDA error despite CUDA available and GPU supported,2020-04-06 14:11:07+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
36061,[JIT] support list of nn.Module in torchscript,2020-04-06 13:56:16+00:00,,0,16,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement"")]"
36059,Some tutorials cannot be found from both side panel and tutorial welcome page,2020-04-06 07:21:37+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
36058,Half type promotion with Numpy arrays is incorrect,2020-04-06 06:31:56+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
36041,[DISCUSSION] Better user experience for debugging on Windows,2020-04-05 13:35:32+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged"")]"
36040,[JIT] Huge delay (1274s vs 0.031s) when running scripted model,2020-04-05 13:28:02+00:00,,1,5,"[Label(name=""high priority""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
36036,torch.multinomial is misnamed. ,2020-04-05 05:28:33+00:00,,0,4,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: ux"")]"
36028,About tensorboard in pytorch record graph in different state,2020-04-04 14:54:19+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: visualization"")]"
36004,C++ tensor print doesn't show requires_grad and grad_fn like Python tensor print,2020-04-04 00:33:37+00:00,,0,2,"[Label(name=""module: printing""), Label(name=""module: cpp""), Label(name=""triaged"")]"
35998,JITed GRU too slow,2020-04-03 22:56:33+00:00,,2,7,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
35990,"[JIT] Tensor method API behavior discrepancy, Tensor.detach(..)",2020-04-03 22:10:48+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
35964,TensorOptions shouldn't provide default values,2020-04-03 18:56:20+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
35944,"Copy activations from one parts to another part in tensor, but report error",2020-04-03 09:51:33+00:00,,0,1,"[Label(name=""triaged"")]"
35942,Build PyTorch-1.4.0 from source failed,2020-04-03 09:26:00+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged"")]"
35937,MKLDNN_conv2d 2X slower than the native TH implementation,2020-04-03 06:15:17+00:00,,2,10,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
35881,Error when loading jit traced FasterRCNN model in C++,2020-04-02 14:51:04+00:00,,1,23,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
35872,torch.autograd.set_detect_anomaly(True) does not exist in C++?,2020-04-02 09:01:18+00:00,,1,3,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
35870,CUDNN_STATUS_INTERNAL_ERROR with GPU RTX 8000,2020-04-02 07:27:23+00:00,,0,17,"[Label(name=""needs reproduction""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
35832,Linking error after marking an op `manual_kernel_registration: True`,2020-04-01 19:48:59+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
35820,[JIT] Tracer bakes List[Tensor] attribute as constant,2020-04-01 17:58:40+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
35802,Hook on input tensor not called when using autograd.grad(),2020-04-01 10:58:46+00:00,,1,2,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
35801,Add KFAC optimizer,2020-04-01 10:08:56+00:00,,1,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
35798,Dropout on sparse tensors,2020-04-01 06:25:00+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
35797,Backward function causes device error in C++ when changing module's device repeatly.,2020-04-01 06:20:40+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""module: autograd""), Label(name=""triaged"")]"
35792,Python 3 build PyTorch got core dump,2020-04-01 03:31:06+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
35788,[jit] Structural typing shouldn't work,2020-04-01 00:22:11+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
35775,Unexpected behaviour for affine_grid and grid_sample with 3D inputs,2020-03-31 20:44:46+00:00,,0,6,"[Label(name=""module: numerical-stability""), Label(name=""module: nn""), Label(name=""triaged"")]"
35770,BatchNormFuncOptions object cant be printed in C++,2020-03-31 18:34:26+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged"")]"
35766,Clarify tensor storage communication behavior in RPC,2020-03-31 17:44:48+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
35759,how to do 3d data augmentation in parallel on the gpu?,2020-03-31 15:25:22+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""module: cuda""), Label(name=""triaged"")]"
35758,UserRRef should store error if it sees any and prevent subsequent usage,2020-03-31 14:58:46+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
35755,Expected object of scalar type Double but got scalar type Float for argument #2 'mat2' in call to _th_mm,2020-03-31 09:21:17+00:00,,0,1,"[Label(name=""triaged"")]"
35754,pytorch 1.4.0 hangs when using with CUDA   >=  10.1,2020-03-31 08:41:19+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
35749,Cannot JIT functions with custom backwards (e.g. swish),2020-03-31 05:54:16+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""module: autograd""), Label(name=""triaged"")]"
35736,"Simple C++ custom autograd function code throws error ""CUDA error: driver shutting down""",2020-03-31 01:36:48+00:00,,0,12,"[Label(name=""module: cpp""), Label(name=""module: autograd""), Label(name=""triaged"")]"
35723,LibTorch API on Mobile,2020-03-30 22:32:06+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""oncall: mobile"")]"
35713,libtorch for Windows. MNIST example does no work.,2020-03-30 21:50:41+00:00,,0,13,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
35681,TensorBoard add_scalars throws error when dict has keys of type int,2020-03-30 16:46:21+00:00,,0,1,"[Label(name=""triaged"")]"
35678,USE_AVX/USE_AVX2 does not affect __AVX2__ macro defition,2020-03-30 16:04:40+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: build warnings""), Label(name=""internals"")]"
35671,allgather_coalesced for tensors of different types seems to be broken,2020-03-30 13:35:00+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
35666,[discussion] Generic solutions for too-small-epsilon in FP16 training,2020-03-30 10:46:09+00:00,,0,9,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: half"")]"
35661,"nn.LSTM gives nondeterministic results with dropout and multiple layers, OR cuDNN version mismatch",2020-03-30 10:16:24+00:00,,0,6,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: determinism"")]"
35655,Wrong conv2d output on GPU when kernel has many zeros,2020-03-30 04:23:05+00:00,,0,3,"[Label(name=""module: dependency bug""), Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
35651,Caffe2 utility_ops_gpu_test fails on Windows,2020-03-30 01:19:25+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
35648,Caffe2 ReshapeOpGPUTest crashes on Windows,2020-03-29 21:19:58+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
35642,Caching Support for class Dataset,2020-03-29 15:22:43+00:00,,0,8,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
35641,"Dimension reducing variants of bitwise operations (bitwise_or, bitwise_and, bitwise_xor)",2020-03-29 08:48:25+00:00,,0,7,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: reductions"")]"
35640,How do you change Adam learning rate since the latest commits ?,2020-03-29 08:45:52+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
35636,Caffe2 generate_proposals_op_gpu_test crashes on Windows,2020-03-29 06:01:40+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
35633,Integration of Large Model Support in PyTorch,2020-03-29 03:13:38+00:00,,0,20,"[Label(name=""module: internals""), Label(name=""feature""), Label(name=""low priority""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
35609,Randomly error reports,2020-03-28 18:42:18+00:00,,0,1,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""triaged"")]"
35606,"Could not find any similar ops to ""foo..."" in the `Libtorch`",2020-03-28 17:27:32+00:00,,0,1,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
35603,Performance bug with convolutions with weights and inputs of similar spatial size,2020-03-28 15:36:32+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
35600,Increased memory usage in repetitive torch.jit.trace calls,2020-03-28 10:47:19+00:00,,1,9,"[Label(name=""high priority""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
35597,libtorch_global_deps.so not found.,2020-03-28 06:32:27+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: regression"")]"
35553,caffe2 `DEPTHWISE3x3.Conv` test is broken,2020-03-27 17:49:02+00:00,,0,1,"[Label(name=""caffe2""), Label(name=""module: tests""), Label(name=""triaged"")]"
35535,Apple Review Rejected. ITMS-90338: Non-public API usage In Pytorch For iOS,2020-03-27 13:09:37+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: ios"")]"
35534,Fail to load torch script model,2020-03-27 13:06:30+00:00,,0,11,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
35529,Support bool input tensors for argmax / argmin / sort / topk and other functions,2020-03-27 11:38:50+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: reductions"")]"
35527,torch.bernoulli and torch.rand and torch.randint to support dtype=torch.bool kwarg (and operation of tensor.uniform_ / tensor.random_ on bool tensors),2020-03-27 11:34:13+00:00,,0,13,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
35526,RuntimeError during converting Reformer model to TorchScript,2020-03-27 11:19:34+00:00,,1,2,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
35520,TorchScript can't use lists in conditionals,2020-03-27 02:11:09+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement"")]"
35499,Support tensor.cumsum() for 1-dim tensors,2020-03-26 21:00:30+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
35472,Multiprocessing map gets stuck if doing inference on loaded model,2020-03-26 17:23:13+00:00,,0,17,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
35458,Shared-QK transformer for the transformer (nn.activation.MultiheadAttention) module in PyTorch?,2020-03-26 06:18:28+00:00,,1,7,"[Label(name=""triaged""), Label(name=""needs research""), Label(name=""oncall: transformer/mha"")]"
35446,[JIT] dropout fails on legacy mode,2020-03-26 02:04:16+00:00,,0,10,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
35441,"torch::normal only supports (double, double), but at::normal supports (double, double) / (double, Tensor) / (Tensor, double) / (Tensor, Tensor)",2020-03-26 01:00:45+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
35418,PyTorch / libtorch executables fail when built against libcuda stub library,2020-03-25 20:48:04+00:00,,0,8,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
35414,"MacOS Error: subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '-j', '12']' returned non-zero exit status 1.",2020-03-25 20:40:16+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: macos"")]"
35408,torch.jit.script works for x*sigmoid(x) but not for x*sin(x),2020-03-25 19:57:31+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
35381,runtime error when loding heavy dataset,2020-03-25 15:31:19+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
35372,How to support single-process-multiple-devices in DistributedDataParallel other than CUDA device,2020-03-25 08:52:08+00:00,,0,2,"[Label(name=""oncall: distributed"")]"
35363,NCCL version upgrade for PyTorch,2020-03-25 05:01:58+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
35312,Method/constructor which takes as input angle and magnitude and returns a complex tensor,2020-03-24 18:40:16+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: complex"")]"
35294,ONNX export support for sparse tensors,2020-03-24 13:26:20+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
35290,Why C++ version libtorch so slow,2020-03-24 11:45:35+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
35266,Using profiler to profile distributed autograd code can lead to misleading results,2020-03-24 01:18:05+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc""), Label(name=""oncall: profiler"")]"
35234,Raspberry Pi Zero build fails,2020-03-23 20:50:13+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
35215,Get hold of Backward graph from a C++ module.,2020-03-23 16:41:23+00:00,,0,11,"[Label(name=""oncall: jit"")]"
35208,The BatchNorm error in `DataParallel`,2020-03-23 12:57:42+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
35180,hasSpecialCase INTERNAL ASSERT FAILED: We don't have an op for aten::to but it isn't a special case.,2020-03-22 09:03:11+00:00,,0,9,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
35160,Documentation doesn't cover MWE using launch.py script,2020-03-21 17:20:31+00:00,,1,4,"[Label(name=""todo""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
35151,Segfault when using misaligned data pointer (from joblib),2020-03-21 05:14:01+00:00,,0,3,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: numpy"")]"
35128,Autograd Engine leaks reentrant threadpool threads on deletion,2020-03-20 22:28:55+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""better-engineering"")]"
35118,Customize batch size based on  gpu id,2020-03-20 20:53:27+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
35116,JIT does not support class instance attribute type annotation,2020-03-20 19:36:42+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""days"")]"
35108,"zip(list, tuple) throws an non-actionable error message",2020-03-20 18:33:30+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""days""), Label(name=""TSRootCause:TypeChecking""), Label(name=""TSUsability"")]"
35097,undefined symbols when using  libtorch and ITK,2020-03-20 09:42:58+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
35095,"tensorboard add_graph 's ""operator_export_type""",2020-03-20 08:35:26+00:00,,0,1,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
35078,Generator C++ API should match Python API,2020-03-20 00:26:56+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: random"")]"
35074,"[JIT] If a python function type comment is referring to a wrong type, JIT frontend gives a not helpful error message",2020-03-19 23:51:47+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
35071,Options for printing the shape with print(tensor),2020-03-19 22:57:10+00:00,,0,1,"[Label(name=""module: printing""), Label(name=""triaged"")]"
35041,Make operator registrations truly commutative using priority,2020-03-19 16:37:00+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
35040,Deprecate and remove RegisterOperators,2020-03-19 16:33:16+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
35038,Rename Dispatcher::findSchema to Dispatcher::findOperator,2020-03-19 16:23:37+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
35035,How install old version pytorch 1.2.0 from source?,2020-03-19 15:11:42+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
35026,Refactor record_function_ops.cpp to not use cpp_custom_type_hack,2020-03-19 05:13:48+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""oncall: profiler"")]"
34998,Better examples in functional autograd functions,2020-03-18 22:22:02+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged"")]"
34977,`conv2d` is slow with specific shapes of channels_last tensors,2020-03-18 20:27:27+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""module: memory format"")]"
34953,Graphic tool to view the backward(Gradient Graph) and forward graph in Pytorch ,2020-03-18 14:06:45+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: visualization"")]"
34951,"[feature request] Sparse (hybrid sparse-dense) output option for topk, min, max",2020-03-18 12:22:26+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
34949,Equality operator for torch.distribution.*,2020-03-18 08:37:24+00:00,,0,9,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""enhancement"")]"
34948,TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function,2020-03-18 08:14:53+00:00,,0,16,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
34941,Issues with DataParallel on Multiple GPUs,2020-03-18 03:45:46+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
34939,Enable OpaqueTensor to possess Storage then allow it to view from CPUTensor,2020-03-18 02:54:14+00:00,,0,27,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
34937,[JIT]torch.jit.export invaild for pytorch1.4,2020-03-18 02:13:18+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
34881,libtorch memory leak,2020-03-17 13:38:47+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
34880,Expanded tensors don't work as registered buffers,2020-03-17 12:37:26+00:00,,0,8,"[Label(name=""module: nn""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: partial aliasing"")]"
34879,Addition of Siamese loss or contrastive loss function,2020-03-17 10:50:58+00:00,,0,11,"[Label(name=""feature""), Label(name=""module: loss""), Label(name=""triaged"")]"
34878,Set the number of CUDAStream,2020-03-17 10:07:15+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
34874,Extend nn.functional.softmax for arbitrary dimensions,2020-03-17 09:02:12+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request"")]"
34870,Flaky test test_ctc_loss_cuda on Windows,2020-03-17 08:19:59+00:00,,0,2,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
34851,[jit] `__hash__` magic method is missing,2020-03-17 00:41:28+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""low priority"")]"
34839,[torch.jit.script] Allow `range` to index into Tensor,2020-03-16 21:34:39+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement"")]"
34837,[torch.jit.script] Support tensor indexing after an Ellipsis,2020-03-16 21:24:23+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement"")]"
34833,NO_CUDA and NO_DISTRIBUTED referenced in docs,2020-03-16 20:09:48+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
34814,[JIT] Tensor.add_ incorrect schema matching on overloads,2020-03-16 17:01:46+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
34812,"Semantic differences between forward and backward of upsampling2d/3d in channels last (NHWC, NDHWC) format.",2020-03-16 16:48:44+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
34799,Is it possible to run an object detection android app by using Pytorch Mobile?,2020-03-16 08:03:12+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: android"")]"
34788,keepdim for Tensor.select?,2020-03-15 20:08:25+00:00,,0,1,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: viewing and reshaping"")]"
34772,"Unsupported ONNX op (Upsample 3D, bicubic) contrary to documentation",2020-03-15 00:56:40+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: vision"")]"
34765,Add ability to return a copy to Module's state_dict member function.,2020-03-14 14:51:54+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
34760,incomplete implementation doubt,2020-03-14 04:29:08+00:00,,0,6,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
34754,General Purpose Faulty RPC Agent,2020-03-14 01:13:48+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
34731,Small output value mismatch after convert to onnx model,2020-03-13 19:21:44+00:00,,0,1,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
34728,CPU softmax performance poor when dim is not the last dimension,2020-03-13 19:18:18+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
34715,Maybe gpu_kernel shouldn't ASSERT_HOST_DEVICE_LAMBDA,2020-03-13 13:53:08+00:00,,0,10,"[Label(name=""triaged"")]"
34713,torch.jit.script report error when using index to subscript nn.ModuleList,2020-03-13 12:16:53+00:00,,0,2,"[Label(name=""triage review""), Label(name=""oncall: jit"")]"
34707,Pytorch report INTERNAL ASSERT FAILED at ..\\torch\\csrc\\jit\\ir.cpp:1529 when use torch.jit.script to convert to model,2020-03-13 08:36:22+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
34704,RuntimeError: derivative for grid_sampler_2d_backward is not implemented,2020-03-13 06:42:12+00:00,,0,38,"[Label(name=""triaged""), Label(name=""module: interpolation"")]"
34682,Pytorch not compatible with react native android,2020-03-12 21:58:03+00:00,,0,4,"[Label(name=""oncall: mobile"")]"
34675,[feature request]Support dilation parameter for unfold2d_* function (slow cpu maxpool2d #28733),2020-03-12 20:48:32+00:00,,0,10,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: pooling""), Label(name=""function request"")]"
34660,"Add ""strict"" flag to ignore missing parameters in Optimizer.load_state_dict",2020-03-12 18:05:52+00:00,,1,5,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
34651,Support passing memoryview to torch.as_tensor,2020-03-12 16:55:07+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement"")]"
34649,Confusing error message of tensor constructor when passing a storage,2020-03-12 16:25:54+00:00,,0,3,"[Label(name=""triaged"")]"
34646,"Support creating a CPU tensor from ctypes pointer in Python / from_blob(ptr, shape, strides, dtype)",2020-03-12 12:40:46+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
34621,A better way to show users all build options,2020-03-11 21:37:34+00:00,,1,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
34611,Eigen version for PyTorch ?,2020-03-11 20:18:09+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged"")]"
34606,Multiple CMake target errors ever since commit 0e52627358,2020-03-11 19:53:04+00:00,,0,18,"[Label(name=""module: build""), Label(name=""triaged"")]"
34576,Significant speed difference between P100 and V100,2020-03-11 03:38:02+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: cublas"")]"
34573,Restructure `multi_head_attention_forward`,2020-03-11 02:50:20+00:00,,0,31,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
34565,Backward operations not decorated with stashed seq marker,2020-03-11 00:13:12+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
34544,Strange behaviour of F.interpolate with bicubic mode.,2020-03-10 18:24:57+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged"")]"
34516,Expose chunk_sizes for DataParallel,2020-03-09 23:48:04+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
34483,JIT: Tracing faster than scripting,2020-03-09 14:40:01+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
34453,[Feature request] Query padding mask for nn.MultiheadAttention,2020-03-08 15:15:38+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
34451,Mac build from source error ,2020-03-08 12:00:40+00:00,,0,12,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""module: xnnpack"")]"
34412,error in pytorch Docs: https://pytorch.org/docs/stable/distributions.html,2020-03-07 04:02:18+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
34409,PyTorch build with Ideep support?,2020-03-07 01:07:38+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
34397,TorchScript docs have broken links,2020-03-06 21:49:07+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
34375,.detach() behaves differently for dense tensors vs sparse tensors,2020-03-06 17:28:16+00:00,,1,8,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
34367,Better testing of the autograd engine,2020-03-06 15:10:08+00:00,,4,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""better-engineering"")]"
34361,[JIT legacy executor] device propagation regression,2020-03-06 08:32:32+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
34329,[jit] Hook support tracking,2020-03-05 23:55:37+00:00,,1,3,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
34323,PyTorch GPU memory allocation,2020-03-05 22:23:01+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
34306,[docs] Missing docs online for conv_tbc,2020-03-05 15:47:07+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
34300,Inconsistent semantics of converting inf/-inf to long,2020-03-05 12:40:53+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
34279,`torch.norm` is 113x slower than `torch.sqrt(a**2 + b**2)`,2020-03-05 00:43:09+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
34257,CustomFromMask pruning stores a copy of the user-provided mask,2020-03-04 20:20:54+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pruning"")]"
34242,RuntimeError with torch.unique: radix_sort: failed on 2nd step: invalid argument,2020-03-04 19:00:26+00:00,,0,14,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
34210,[docs] Unclear arg spec for torch.full,2020-03-04 12:02:23+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: numpy"")]"
34207,Support vars/__dict__ on torch.return_types tuples e.g. topk,2020-03-04 09:53:42+00:00,,0,7,"[Label(name=""triaged""), Label(name=""enhancement"")]"
34172,END_HANDLE_TH_ERRORS_PYBIND prevents pybind11 Exception translation,2020-03-03 23:21:23+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: pybind"")]"
34130,ExceptionWrapper cannot handle exceptions with more than one argument,2020-03-03 14:09:24+00:00,,0,5,"[Label(name=""module: dataloader""), Label(name=""module: error checking""), Label(name=""triaged"")]"
34126,torch::jit::script::Object::attr should throw AttributeError instead of RuntimeError,2020-03-03 10:47:22+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
34116,autograd with TorchScript does not match finite differences,2020-03-03 02:58:03+00:00,,0,1,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit"")]"
34086,Enable profiler tracing tests on windows,2020-03-02 20:47:38+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
34082,Autograd deep copy avoidance optimization unsound in the presence of views,2020-03-02 20:29:46+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
34080,RPC API Changes for TensorPipes,2020-03-02 20:21:19+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
34068,[C++ API Parity] Incorrect documentation for optim initialization in serialization docs,2020-03-02 17:29:14+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
34064,pip --requirement installs incorrect CUDA version,2020-03-02 14:49:18+00:00,,0,4,"[Label(name=""module: dependency bug""), Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
34063,[docs] Unclear description of indices arg in torch.index_put_,2020-03-02 14:27:59+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
34058,libtorch.so file size is very large,2020-03-02 10:19:16+00:00,,0,17,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""oncall: mobile""), Label(name=""quansight-nack"")]"
34052,Model loaded in C++ runtime is not thread safe,2020-03-02 06:01:34+00:00,,0,4,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: sanitizers"")]"
34044,Torchscript Inference with DLL Creation,2020-03-01 15:35:23+00:00,,0,1,"[Label(name=""oncall: jit"")]"
34001,_broadcast_coalesced_reshape doesn't respect zero-size tensor,2020-02-29 04:49:26+00:00,,0,0,"[Label(name=""triaged""), Label(name=""small""), Label(name=""module: data parallel"")]"
33993,ModuleList doesn't support slicing in TorchScript,2020-02-29 01:24:43+00:00,,0,0,"[Label(name=""oncall: jit"")]"
33991,TensorPipes RPC Agent Default Args/Result Device Mapping,2020-02-29 00:30:07+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
33990,TensorPipes RPC Agent Multiple Placement Retries,2020-02-29 00:28:00+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
33989,TensorPipes RPC Agent Message Acknowledgements,2020-02-29 00:06:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
33983,TensorPipes RPC Agent Listener shortcut,2020-02-28 23:23:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
33982,Initialize TensorPipe RPC Agent Transport,2020-02-28 23:21:30+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
33979,TensorPipes RPC Agent CUDA Support,2020-02-28 23:13:54+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: rpc"")]"
33898,Docs for uniform_ don't make any sense,2020-02-27 20:55:53+00:00,,0,8,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
33890,Libtorch segfault when used with libqpOASES ,2020-02-27 18:58:37+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
33887,[jit] Python arg parser / TorchScript incompatibilities,2020-02-27 18:47:17+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33876,Torchscript incompatible with torch.cat for tensor lists,2020-02-27 16:39:30+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33867,cuDNN batchnorm with non-contiguous running mean silently discards updates,2020-02-27 15:21:43+00:00,,1,5,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
33864,Memory leak in embedding layer and LSTM,2020-02-27 13:03:11+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
33859,Possibility to support int4 data type,2020-02-27 05:33:36+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
33855,Unclear output for Pytorch Profiler,2020-02-27 03:53:47+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged"")]"
33844,[jit] Returning different types with `Any` segfaults,2020-02-26 23:44:04+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33811,"Models saved in C++ LibTorch with torch::save, cannot be loaded in python using torch.load",2020-02-26 11:52:16+00:00,,0,7,"[Label(name=""module: cpp""), Label(name=""module: serialization""), Label(name=""triaged"")]"
33810,Wrongly detected: Division of ints in TorchScript uses Python 3 true division semantics,2020-02-26 11:32:04+00:00,,0,0,"[Label(name=""oncall: jit"")]"
33800,Can't get module gradient in autograd.Function's custom backward when DataParallel is used,2020-02-26 02:31:06+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
33799,Add `start_process_in_context` to `torch.multiprocessing`,2020-02-26 01:51:28+00:00,,0,4,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""enhancement"")]"
33787,MSE Loss Implementation,2020-02-25 22:58:43+00:00,,0,4,"[Label(name=""triaged"")]"
33785,Deepcopy fails with nn.parallel.replicate,2020-02-25 22:30:02+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
33782,[JIT] BroadcastingList annotations don't work with ignore'd functions,2020-02-25 22:08:37+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33738,Support pipelining the backward pass and optimizer.step() for distributed autograd.,2020-02-25 01:45:57+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
33725,Tensor.random_ is not implemented for bfloat16 on CPU(but implemented on CUDA),2020-02-24 22:12:38+00:00,,1,0,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: random"")]"
33692,JIT tracing check fails with boolean tensor modifications,2020-02-24 13:12:27+00:00,,0,3,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""actionable"")]"
33691,Some module has incorrect scope in complex naming situations in tensorboard graph export,2020-02-24 10:39:07+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
33684,Decouple Lifetime of Local RRef and RPC,2020-02-24 02:32:51+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
33672,[dev] `RecursiveScriptModule` does not expose `jit.ignore`d methods,2020-02-23 14:16:25+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33670,Some module info is missing in nested graph for tensorboard,2020-02-23 10:54:11+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
33668,"/usr/bin/x86_64-linux-gnu-ld: warning: libcusparse.so.10.0, needed by /pytorch_master/build/lib/libtorch_cuda.so, not found (try using -rpath or -rpath-link)",2020-02-23 02:02:07+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
33664,torch.rand() not having same values on using torch.manual_seed(0),2020-02-22 17:51:03+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random"")]"
33653,master build error,2020-02-22 07:33:34+00:00,,0,0,"[Label(name=""caffe2"")]"
33631,bitmapToFloat32Tensor() 1 channel Tensor [feature] [mobile],2020-02-21 20:58:12+00:00,,0,2,"[Label(name=""oncall: mobile""), Label(name=""oncall: java"")]"
33628,Remove .data subset1 for fixathon,2020-02-21 19:59:53+00:00,,0,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering""), Label(name=""actionable""), Label(name=""fixathon"")]"
33611,Resnet 32x32 in caffe2 generates ResNet with wrong number of layers,2020-02-21 05:05:14+00:00,,0,0,"[Label(name=""caffe2"")]"
33571,empty_sparse shouldn't be called with memory layout but is,2020-02-20 19:48:11+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""module: tensor creation"")]"
33520,Reverse Cumulative Sum,2020-02-19 22:40:22+00:00,,0,5,"[Label(name=""triaged""), Label(name=""function request"")]"
33514,"Make setter non-optional, e.g., TensorOptions::device(optional<Device>) -> device(Device), and add a device_opt setter",2020-02-19 20:34:13+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
33501,"When a Node fails to resolve to an Operator, print out the types of arguments, and all ""close matches"" in known operators",2020-02-19 18:12:02+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33491,jit.trace checker fails for LSTM ,2020-02-19 11:56:49+00:00,,0,1,"[Label(name=""oncall: jit"")]"
33482,Distributed Data Parallel for computation graphs that make RPCs in forward(),2020-02-19 05:28:17+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
33477,"Add 32-bit CI (e.g., Raspberry PI CI)",2020-02-19 02:09:08+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
33476,Make ArrayRef::size() return int64_t rather than size_t,2020-02-19 02:05:51+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
33463,torch._C.Node.scopeName() missing in pytorch 1.4,2020-02-18 21:44:40+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33436,It seems nn.Sequential.add_module() could take duplicate names,2020-02-18 08:20:19+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
33413,IterableDataset with num_workers > 0 and drop_last=True drops more instances than expected,2020-02-17 06:21:31+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
33396,PyTorch 1.4.0 does not support using `Module` or `ModuleList` in attribute annotations in ScriptModule,2020-02-16 09:12:42+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33390,It is not good to separate the steps of modules making and forward computation,2020-02-16 02:40:14+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
33388,Sobol engine generates out-of-bounds samples after drawing too many samples,2020-02-16 01:19:41+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: random"")]"
33385,Illegal instruction: 4 - OSX 10.13.6 install from source,2020-02-15 20:53:32+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
33373,torch.clamp_ not inplace during backward,2020-02-15 08:25:37+00:00,,0,6,"[Label(name=""module: autograd""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
33367,Expose `internal::GRAIN_SIZE` through Python API.,2020-02-15 00:23:14+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: multithreading"")]"
33363,Make it easier to add new messages in RPC layer,2020-02-14 23:26:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
33360,Dropout of attention weights in function F.multi_head_attention_forward() breaks sum-to-1 constraint,2020-02-14 22:04:12+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
33354,Long torchscript warmup times can be problematic for production serving,2020-02-14 19:37:23+00:00,,0,11,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33353,[jit] `Node` callstack is incorrect,2020-02-14 19:32:34+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33342, malloc(): memory corruption (fast),2020-02-14 12:15:44+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
33341,how-to-adjust-learning-rate using libtorch,2020-02-14 11:25:57+00:00,,0,0,"[Label(name=""triaged"")]"
33327,Creating Torch tensors slows OpenCV video reading a lot,2020-02-14 01:28:48+00:00,,1,4,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
33303,torch::var_out and dimnames,2020-02-13 18:09:13+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: named tensor"")]"
33301,Don't take TensorOptions by reference,2020-02-13 17:53:34+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
33298,[feature request] torch.expand to not require unsqueeze and match -1 to existing dimensions if tensor.shape.count(-1) == tensor.ndim,2020-02-13 17:01:10+00:00,,0,8,"[Label(name=""triaged""), Label(name=""enhancement"")]"
33296,Training got stuck due to timeout from dataloader,2020-02-13 16:38:03+00:00,,1,26,"[Label(name=""module: performance""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
33285,iOS libtorch superpoint model bug,2020-02-13 08:12:35+00:00,,1,0,"[Label(name=""module: macos""), Label(name=""oncall: mobile""), Label(name=""module: ios""), Label(name=""shadow review"")]"
33281,"Uninitialised value was created by a stack allocation, reported by valgrind",2020-02-13 03:41:44+00:00,,0,2,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
33249,Core dumps being created when running test_c10d.py and test_multiprocessing_spawn.py,2020-02-12 20:54:47+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged"")]"
33248,PyTorch 1.4.0 CUDA initialization error with CPU-only (multiprocessing) on Python 3.7.5,2020-02-12 19:42:13+00:00,,0,11,"[Label(name=""module: autograd""), Label(name=""module: cuda""), Label(name=""triaged"")]"
33241,"[feature request] Add ""groups"" argument to nn.Fold and nn.Unfold",2020-02-12 17:06:39+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
33227,[v1.5] Python/C++ API parity master tracking task,2020-02-12 03:39:46+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
33181,[feature request] [dataloader] Introduce Dataset.__collate__,2020-02-11 11:35:55+00:00,,0,20,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research"")]"
33180,Loading pretrained model,2020-02-11 09:42:22+00:00,,0,1,"[Label(name=""caffe2"")]"
33166,TensorIterator does not work with different input/output types,2020-02-11 00:46:52+00:00,,1,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: vectorization""), Label(name=""module: TensorIterator"")]"
33132,Support multiple-build-type generators for CMake,2020-02-09 19:21:58+00:00,,1,4,"[Label(name=""module: windows""), Label(name=""triaged"")]"
33129,Python package using CMake,2020-02-09 07:36:38+00:00,,1,5,"[Label(name=""module: build""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""enhancement"")]"
33124,QNNPACK: GNU aarch64 assembler does not support 4s on neon mov,2020-02-08 20:40:15+00:00,,0,3,"[Label(name=""oncall: mobile"")]"
33122,[feature request] make torch.multinomial behaviour compliant with rnn output dimension,2020-02-08 11:25:37+00:00,,0,3,"[Label(name=""module: distributions""), Label(name=""module: bc-breaking""), Label(name=""feature""), Label(name=""triaged"")]"
33115,[RFC] Add ability to get all remote parameters when constructing DistributedOptimizer.,2020-02-07 23:37:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
33114,Move the custom pass execution back to the beginning of runNondiffOptimization,2020-02-07 22:47:30+00:00,,1,8,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33110,InlineAutodiffSubgraphs in JIT inlines non-differentiable custom groups unexpectedly.,2020-02-07 22:29:30+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""module: custom-operators""), Label(name=""actionable"")]"
33089,test_baddbmm_cpu_float32 fails locally for me when built with DEBUG=1,2020-02-07 15:35:38+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""small"")]"
33086,F.max_pool*d/F.min_pool*d should support integer dtypes and bool tensors,2020-02-07 13:52:24+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: pooling""), Label(name=""function request"")]"
33085,not able to import *  from fastai.vision  in Google collab,2020-02-07 10:03:08+00:00,,1,9,"[Label(name=""triaged"")]"
33081,DataParallel gives different gradients when using LSTMs,2020-02-07 05:39:20+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""module: data parallel"")]"
33055,[docs] Strange order of items in docs contents in left pane,2020-02-06 19:46:50+00:00,,3,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
33051,Recover from CUDA runtime error,2020-02-06 17:33:57+00:00,,1,2,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: third_party"")]"
33049,Warning when link libtorch and opencv4.2.0 together,2020-02-06 16:21:22+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""better-engineering"")]"
33047,torch.nn.functional import grid_sample,2020-02-06 15:35:41+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
33041,bytearray(tensor) behaves very differently from bytearray(tensor.numpy()),2020-02-06 11:33:03+00:00,,0,3,"[Label(name=""module: printing""), Label(name=""triaged""), Label(name=""module: numpy"")]"
33040,[debatable] Better infer dtype in torch.as_tensor,2020-02-06 11:23:24+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: tensor creation"")]"
33035,Support batch linear transformation,2020-02-06 00:47:48+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: batching""), Label(name=""function request"")]"
33034,Scripting fails to preserve attribute aliasing,2020-02-06 00:43:02+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
33029,Torch not compiled with CUDA enabled,2020-02-05 23:16:40+00:00,,0,1,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""module: binaries""), Label(name=""module: cuda""), Label(name=""triaged"")]"
33007,Upper/Lower attributes for named dimensions for proper Ricci notation and to generalize matrix operations,2020-02-05 14:18:57+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
33006,matmul: no warning when contracting differently named dimensions,2020-02-05 13:46:55+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
32998,torch batchwise max with indices,2020-02-05 01:57:32+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: batching""), Label(name=""function request""), Label(name=""module: reductions"")]"
32988,[jit] Dict set item type mismatch error doesn't say the type was inferred,2020-02-04 23:06:40+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32976,[JIT] pytorch 1.4 breaks torch.jit.script(LSTM/GRU),2020-02-04 17:41:29+00:00,,0,7,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""has workaround"")]"
32972,"which pytorch do i install for running this project in my windows.link for this is ::  https://github.com/xiaojunxu/SQLNet  .IN this they have used python 2.7 ,but i am unable to install pytorch on python 2.7 environment .help me with this",2020-02-04 14:07:15+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
32937,Operation Registration Error,2020-02-03 19:12:27+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
32924,Connect timeout feature do not work in DDP with TCPStore,2020-02-03 02:34:23+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
32919,"Torchscript used to work, but now it fails with VariableTensorId error",2020-02-03 00:46:13+00:00,,1,6,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
32918,Interpolate in the “bicubic” mode with the same shape outputs zeros from second sample onwards,2020-02-02 17:26:01+00:00,,1,1,"[Label(name=""high priority""), Label(name=""triaged"")]"
32916, from torch._C import * (ImportError: DLL load failed),2020-02-02 13:51:15+00:00,,0,15,"[Label(name=""triaged"")]"
32912,Optional seq_len argument to torch.nn.utils.rnn.pad_sequence,2020-02-01 19:24:29+00:00,,1,1,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: padding"")]"
32909,Some questions Concerning Intel's DNNL(MKLDNN) support in Pytorch (adding support for Intel Processors GPUs) by transitioning to DNNL,2020-02-01 11:09:18+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: mkldnn"")]"
32901,QNNPACK linear doesn't preserve dimensions,2020-02-01 04:18:54+00:00,,0,1,"[Label(name=""oncall: mobile"")]"
32884,[RFC] Nested scopes in autograd profiler should support RPC calls properly.,2020-01-31 22:47:17+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: rpc"")]"
32881,CUDNN_STATUS_EXECUTION_FAILED,2020-01-31 22:32:06+00:00,,0,13,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
32872,Confusing error messages of tensor.scatter_ on both CPU and CUDA,2020-01-31 18:22:55+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
32868,__cuda_array_interface__ conversion does not support readonly arrays,2020-01-31 15:10:04+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: numba"")]"
32867,"[feature request] np.packbits / np.unpackbits, general BitTensors (maybe can be just tensors with dtype torch.bits8 or have a new dtype torch.bits introduced) and bit packed tensors utilities for saving memory / accesses, support for BitTensors wherever BoolTensors are used",2020-01-31 14:35:47+00:00,,0,60,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: boolean tensor"")]"
32864,[docs] Missing docs for torch.__version__ and torch.version,2020-01-31 10:46:50+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""small"")]"
32851,Silent failing of batch_sampler when the data points are lists of tensors.,2020-01-31 01:15:02+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
32840,Can we add support for Enum in scripted models?,2020-01-30 21:28:06+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32826,MKLDNN doesnt work and is slower than normal cpu mode,2020-01-30 13:17:16+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: mkldnn"")]"
32822,Error tracing custom autograd.Function,2020-01-30 07:54:17+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32784,Implement Backend-Agnostic RPC functionality in RpcAgent,2020-01-29 20:03:05+00:00,,1,1,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
32783,Comments Separating Class Methods from Different Classes in C++ Files,2020-01-29 19:53:57+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
32770,Error while trying to build pytorch from source in conda environment,2020-01-29 14:35:47+00:00,,1,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
32767,Documentation is not loaded by IDEs,2020-01-29 11:41:29+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
32754,JIT performance discrepancies,2020-01-29 01:51:54+00:00,,1,1,"[Label(name=""module: performance""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
32752,RPC mock mode for unit tests.,2020-01-29 01:29:43+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
32751,PyTorch freezes on second call to scripted densenet model from torchvision,2020-01-29 01:10:53+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: vision"")]"
32706,Torch serialization does not restore tensors properly when custom __reduce__ is defined,2020-01-28 18:18:31+00:00,,0,3,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
32698,Add Julia Bindings to Torch backend ,2020-01-28 13:05:13+00:00,,0,6,"[Label(name=""feature""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: language binding"")]"
32695,torch.tensordot has inconsistent signature with torch script,2020-01-28 12:44:05+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32694,ninja: build stopped: subcommand failed.,2020-01-28 12:35:08+00:00,,0,11,"[Label(name=""module: build""), Label(name=""triaged"")]"
32690,How to customize build torchscript model to be used in end devices codebase,2020-01-28 10:11:07+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""oncall: mobile"")]"
32687,Building PyTorch ignores my current Python version,2020-01-28 04:50:53+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
32662,Second-order gradient cause segfault over time,2020-01-27 20:00:35+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
32651,[Tensorboard] Problem with subfolders from SummaryWriter,2020-01-27 15:35:42+00:00,,0,19,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
32641,changed format of trace graph in torch 1.4.0,2020-01-27 04:53:21+00:00,,0,18,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32638,TORCH_CUDA_API export failure on torch::cuda::nccl::detail::throw_nccl_error(ncclResult_t),2020-01-27 00:44:24+00:00,,0,6,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""quansight-nack"")]"
32614,Logical AND and OR for Tensors in C++ API.,2020-01-25 08:15:31+00:00,,1,3,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""function request"")]"
32590,[FYI] MultiheadAttention / Transformer,2020-01-24 20:06:25+00:00,,1,17,"[Label(name=""proposal accepted""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
32589,User-friendly handling of types and devices,2020-01-24 19:08:16+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: ux"")]"
32584,Segmentation Fault (core dumped) with 1.4.0,2020-01-24 17:10:13+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
32580,SGD optimizer with deprecation warning,2020-01-24 16:48:32+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""module: deprecation"")]"
32576,Document different gradient wrt to jax when nesting,2020-01-24 11:32:41+00:00,,0,13,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged"")]"
32575,Interrupting a DDP worker while using the CUDA MPS server causes CUDA to hang until reboot,2020-01-24 10:00:47+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""triaged"")]"
32570,[feature request] Out-variant and dtype argument for torch.argmax / torch.argmin / torch.argsort (and friends),2020-01-24 03:07:30+00:00,,0,5,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: sorting and selection""), Label(name=""function request""), Label(name=""module: reductions"")]"
32565,Reduce RPC branches for Python/Built-inOp/TorchScript,2020-01-24 00:09:08+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: rpc"")]"
32552,MultivariateNormal.rsample: use eigen-decomposition when Cholesky fails,2020-01-23 21:02:58+00:00,,0,5,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra"")]"
32549,"""Tried to register multiple operators with the same name and the same overload name"" error is confusing",2020-01-23 20:01:37+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: dispatch""), Label(name=""better-engineering"")]"
32544,[jit] Use `typing.get_type_hints` instead of parsing types manually,2020-01-23 19:02:19+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32531,Batched torch.eig() and gradient of torch.eig() for real eigenvalues,2020-01-23 14:15:45+00:00,,1,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: batching""), Label(name=""module: linear algebra"")]"
32529,addition of attention based techniques to pytorch,2020-01-23 09:12:57+00:00,,1,3,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""function request"")]"
32528,Bug in add_param - functionality for tensorboard (scatter matrix view),2020-01-23 08:09:50+00:00,,0,1,"[Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
32524,Pytorch 1.4 does not detect gpu,2020-01-23 04:59:56+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
32511,TorchScript C++ API Tracking Issue,2020-01-22 21:41:31+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32510,Tensor.random_ is not implemented for bool on CUDA(but implemented on CPU),2020-01-22 21:27:40+00:00,,1,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: random"")]"
32504,LibTorch operates very slowly on data blobs from GPU,2020-01-22 20:23:52+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
32497,Don't unnecesarily send cleanup dist autograd context RPCs to other nodes,2020-01-22 18:22:55+00:00,,1,0,"[Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
32490,"RuntimeError: has_marked_unused_parameters_ INTERNAL ASSERT FAILED at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:290, please report a bug to PyTorch.",2020-01-22 14:09:01+00:00,,1,2,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
32488,TracerWarning When Using Tensor Size in Torchscript Trace,2020-01-22 12:25:25+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32463,[JIT] Make `torch.jit.script` work on all objects which we can represent as IValues,2020-01-21 22:59:21+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32452,Numba Enhancement Proposal (NBEP) 7: External Memory Management Plugins,2020-01-21 20:35:02+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
32444,DataParallel does not work with sparse parameters,2020-01-21 18:07:19+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
32443,Segmentation fault in lazyInitCUDA -> CUDAHooks::initCUDA -> THCMagma_init -> magma_init,2020-01-21 18:04:34+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: third_party"")]"
32427,[C++] Don't use DeprecatedTypeProperties in torch::utils::reorder_tensors_like,2020-01-20 19:02:32+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
32421,Segmentation fault in C++ API torch::from_blob(...).clone(),2020-01-20 13:07:41+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
32419,MAGMA libraries,2020-01-20 06:39:00+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
32416,Is there a way to use SYSTEM_INSTALLED 3rdparty libraries?,2020-01-20 04:22:09+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
32415,DistributedStreamSampler: support stream sampler in distributed setting,2020-01-20 03:05:10+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: cpp""), Label(name=""triaged"")]"
32407,Build without MKL is not possible when MKL is installed,2020-01-19 18:32:01+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkl"")]"
32406,KL divergence for diagonal Gaussian distributions,2020-01-19 15:47:51+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
32403,How to accelerate the compiling of pytorch ,2020-01-19 13:42:14+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
32402,torchvision,2020-01-19 08:05:32+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vision"")]"
32390,[JIT] Compile group of functions/modules,2020-01-18 13:47:07+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32375,Make _rpc_sync_torchscript and _rpc_async_torchscript work with autograd profiler,2020-01-17 22:34:48+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32372,Migrate processGroup::async_work to use Future,2020-01-17 21:24:05+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
32370,Backward `Functional.conv3d` is slow when cuDNN is enabled,2020-01-17 20:23:34+00:00,,0,3,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
32365,[jit] Calling `torch.jit.script` on `@staticmethod`s which in turn call other `@staticmethod`s results in a `TypeError`,2020-01-17 19:10:13+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32363,Possible ProcessGroup::Work::abort correctness issue,2020-01-17 18:50:56+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: rpc"")]"
32358,torch.bartlett_window not jitable,2020-01-17 17:15:39+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32357,Pytorch JIT Compilation Does Not Finish (Infinite Loop?) for Deeper Models,2020-01-17 16:57:38+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32351,"Problem with multiprocessing, custom __getstate__ with Tensors and forkserver",2020-01-17 14:32:43+00:00,,0,4,"[Label(name=""module: multiprocessing""), Label(name=""module: serialization""), Label(name=""triaged"")]"
32337,Save LocalResponceNorm as a single aten node when convert a pytorch model to jit model,2020-01-17 02:41:46+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32322,deadlock when using mp.spawn multiprocessing,2020-01-16 21:55:31+00:00,,0,13,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
32306,[FR] bincount along arbitrary dimension,2020-01-16 18:15:14+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: sorting and selection""), Label(name=""function request"")]"
32305,[FR] histc should (optionally) return a long tensor,2020-01-16 18:14:36+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: sorting and selection""), Label(name=""function request"")]"
32300,[jit] Various problems calling `@staticmethod`s in 1.4.0,2020-01-16 17:38:12+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32293,Truncated normal distribution,2020-01-16 15:39:20+00:00,,0,14,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
32288,Allow range in dim argument of reducing operations such as sum,2020-01-16 13:41:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: ux""), Label(name=""function request""), Label(name=""module: reductions"")]"
32287,Python 3.8 Windows JIT test failure,2020-01-16 13:24:42+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32269,Support strategy to train large model that exceeds GPU mem and DRAM mem,2020-01-16 05:11:49+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
32268,Numpy array functionality in torchscript.,2020-01-16 04:45:31+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32267,the results when using opset10 and when using opset11 are different.,2020-01-16 04:07:22+00:00,,0,9,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-needs-info"")]"
32264,torch.nn.functional.threshold not work with LongTensor,2020-01-16 03:18:14+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
32262,models after prepare/prepare_qat contains `qconfig` which prevents pickling,2020-01-16 02:16:12+00:00,,1,3,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
32253,[TorchScript] Device comparison implemented in eq but not ne,2020-01-16 00:25:05+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32237,PyTorch C++ API docs only tracks master branch,2020-01-15 20:13:22+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
32227," 0 INTERNAL ASSERT FAILED at /pytorch/c10/util/intrusive_ptr.h:348, please report a bug to PyTorch.",2020-01-15 16:18:21+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: assert failure"")]"
32219,[Feature proposal] improved algorithms for checkpointing,2020-01-15 11:03:50+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
32214,Pytorch compilation error,2020-01-15 08:36:37+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
32210,"dist.send/recv ""IndexError: map::at"" error when bool tensors are used with mpi backend",2020-01-15 07:28:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: boolean tensor"")]"
32196,pytorch_linux_xenial_cuda10_1_cudnn7_py3_slow_test triggered on all PRs,2020-01-14 23:43:20+00:00,,0,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
32186,Can't import torch on latest master,2020-01-14 22:14:00+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
32167,Support in-place pinning of memory,2020-01-14 12:50:18+00:00,,0,3,"[Label(name=""triaged"")]"
32166,"C++ randint returns float32, python returns int64",2020-01-14 10:42:49+00:00,,0,4,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
32165,Serialization inconsistency with pickling tensors breaks caching,2020-01-14 10:17:59+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
32162,Using Tensor.to(device) after distributed all_reduce intermittently causes deadlock with NCCL ,2020-01-14 08:10:42+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl"")]"
32150,pin_memory may change the type of instance returned by collate_fn.,2020-01-14 01:33:24+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
32141,We should change DeprecationWarnings to UserWarnings in 27361,2020-01-13 23:36:16+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
32137,torch.nn.functional.normalize epsilon too small for half precision,2020-01-13 22:26:48+00:00,,0,2,"[Label(name=""module: numerical-stability""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""module: norms and normalization"")]"
32132,Slighty out of tolerance for `test_mv` and `test_cholesky_solve_batched_cuda_float64`,2020-01-13 21:57:47+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged"")]"
32130,Idempotency Keys for RPC Retry,2020-01-13 21:36:09+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
32113,Inconsistent linking flags result in error when building lib/libc10_cuda.so,2020-01-13 19:24:19+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
32105,TensorRT: CheckDims() need adjustment for EXPLICIT_BATCH?,2020-01-13 16:54:20+00:00,,0,1,"[Label(name=""caffe2""), Label(name=""triaged"")]"
32101,Improve cuda OOM message,2020-01-13 15:06:16+00:00,,0,11,"[Label(name=""module: docs""), Label(name=""module: bootcamp""), Label(name=""module: cuda""), Label(name=""triaged"")]"
32098,torch.gt ge lt le,2020-01-13 08:26:15+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: type promotion"")]"
32097,logsumexp with subtraction,2020-01-13 06:50:18+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: reductions"")]"
32094,logical_not for Boolean tensor has peculiar behavior,2020-01-13 05:24:56+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: boolean tensor"")]"
32088,Batch convolutional layer with 5d weight tensor that is not contiguous,2020-01-12 13:45:02+00:00,,0,0,"[Label(name=""feature""), Label(name=""triaged"")]"
32087,Out-of-date link to pytorch ci dockerfiles in jenkins readme,2020-01-12 04:06:45+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
32083,build pytorch from source fauled: undefined reference to `cusparseGetErrorString(cusparseStatus_t)',2020-01-11 11:24:38+00:00,,0,15,"[Label(name=""module: build""), Label(name=""triaged"")]"
32078,Reduce degrees of freedom in strides so that they unambiguously specify layout permutation,2020-01-10 23:15:16+00:00,,1,6,"[Label(name=""triaged""), Label(name=""enhancement"")]"
32047,Sobol point implementation,2020-01-10 17:06:56+00:00,,0,16,"[Label(name=""triaged""), Label(name=""module: random"")]"
32039,Internal assert failure for user IValue unwrapping,2020-01-10 13:34:42+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
32036,Internal assert failed using multiple GPUs with DataParallel,2020-01-10 12:06:48+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: assert failure""), Label(name=""module: data parallel"")]"
32034,Extend `ConcatDataset` to return dataset index,2020-01-10 10:15:44+00:00,,0,9,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""small"")]"
32033,run detectron test test_spatial_narrow_as_op.py fails,2020-01-10 10:06:29+00:00,,0,0,"[Label(name=""caffe2"")]"
32030,Dockerfile for people to quick-start contributing,2020-01-10 06:34:16+00:00,,1,16,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: docker"")]"
32023,Inaccurate batched GRU results on CPU,2020-01-10 01:36:50+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
32021,[discussion] Relax optimizer constructor constraints for simplicity,2020-01-10 00:45:46+00:00,,0,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
32018,DistributedDataParallel non-floating point dtype parameter with requires_grad=False,2020-01-10 00:17:11+00:00,,0,9,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
32005,gradients inside gradient checkpoint,2020-01-09 20:38:00+00:00,,0,2,"[Label(name=""module: checkpoint""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement"")]"
31994,Trying to disable cuda to run torch on OSX run it on CPU,2020-01-09 17:10:40+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
31980,repeat_interleave Performance Issue,2020-01-09 04:57:29+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
31979,Reuse spawned subprocesses in RPC tests,2020-01-09 04:24:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
31953,JIT tests are linked directly into libtorch and register operators even when unused,2020-01-08 18:36:10+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31945,"Function request: logerfc, logerfcx special functions",2020-01-08 16:09:34+00:00,,0,8,"[Label(name=""module: numerical-stability""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: special"")]"
31943,error when building pytorch 1.1.0 from source,2020-01-08 09:31:32+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
31942,Support sparse inputs for torch.block_diag,2020-01-08 09:19:02+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: tensor creation""), Label(name=""function request"")]"
31937,RPC and dist_autograd should respect no_grad mode,2020-01-08 02:56:34+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
31916,I'm not able to build pytorch with tensorrt (current master),2020-01-07 17:41:49+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
31913,`index_add_` with multidimensional index,2020-01-07 08:12:52+00:00,,1,5,"[Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""function request"")]"
31907,Compile libtorch by source code failed.,2020-01-07 02:04:13+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: cpp""), Label(name=""triaged"")]"
31895,"torch.masked_select out argument can easily be misused, because output shape is dynamically computed",2020-01-06 21:19:00+00:00,,0,11,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: safe resize"")]"
31883,"The dependency target ""nccl_external"" of target ""gloo_cuda"" does not exist.",2020-01-06 13:09:38+00:00,,0,14,"[Label(name=""oncall: distributed""), Label(name=""module: build""), Label(name=""triaged"")]"
31882,Example cmakelists for custom cuda operator?,2020-01-06 06:20:56+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31881,[Feature Request] reduce CUDA runtime size by selectively compiling PyTorch GPU kernels,2020-01-06 03:14:37+00:00,,0,10,"[Label(name=""high priority""), Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
31867,The model training time is increasing between runs if the same DataLoader reused to train multiple models.,2020-01-05 05:35:10+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
31866,Negative indices in chunk could cause Out of Range access on loss.backward in JIT,2020-01-05 03:52:10+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31856,Fix softplus clampling issues using logsigmoid,2020-01-04 16:20:14+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
31842,Support rpc/remote torch script call with script class/module name and class/module method name,2020-01-03 20:11:52+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: rpc"")]"
31837,logsumexp: two little-impact perf suggestions,2020-01-03 19:44:59+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: reductions"")]"
31822,Libtorch's files conflict with glog's file?,2020-01-03 08:56:13+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
31818,How to distinguish different layers in hook？,2020-01-03 03:48:13+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
31815,ImportError: /home/xx/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_python.so: undefined symbol: _ZNK5torch3jit5Graph8toStringE,2020-01-03 01:20:47+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31799,Inaccurate ValueError reporting in nn/functional.py,2020-01-02 22:30:10+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
31788,CI test should use PR commit instead of pulling the latest master,2020-01-02 18:32:00+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
31779,torch.poisson returns floating point tensor,2020-01-02 17:25:49+00:00,,1,8,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
31776,Documentation for `scatter` incorrectly states that index values must be unique,2020-01-02 16:23:17+00:00,,0,6,"[Label(name=""module: bc-breaking""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
31772,Support Python builtins on iterators in JIT,2020-01-02 14:18:09+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31759,Allow using digits in names of named tensors,2020-01-01 12:22:24+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: named tensor"")]"
31758,DataLoader: Segmentation Fault (core dumped),2020-01-01 12:15:03+00:00,,0,31,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
31752,Need a launch utility for Distributed RPC framework.,2019-12-31 21:39:06+00:00,,0,2,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
31742,sparse tensor eliminate_zeros,2019-12-31 02:28:56+00:00,,0,11,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
31710,AttributeError: module 'torch.distributed' has no attribute 'init_process_group' on torch 1.3 aarch64,2019-12-30 19:50:33+00:00,,0,14,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
31708,Computing dot product of columns sliced from large matrix causes illegal memory access in CUDA,2019-12-30 17:36:42+00:00,,1,14,"[Label(name=""module: dependency bug""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: 64-bit""), Label(name=""module: cublas"")]"
31697,the cmake problem with build from source ?,2019-12-30 07:18:03+00:00,,0,1,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
31689,DataLoader does not consider default floating point type,2019-12-29 11:23:32+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
31688,Parallelization: more balanced work distribution among workers,2019-12-29 09:24:06+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
31685,What is the significance of torchvision._is_tracing()? ,2019-12-29 04:07:08+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vision"")]"
31679,broadcast randperm with dim specification,2019-12-28 19:35:58+00:00,,0,0,"[Label(name=""triaged""), Label(name=""function request"")]"
31660,Cuda error 59 : device-side assert triggered,2019-12-27 18:14:45+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
31657,Use of Sequence collections for abstract classes in Dataset,2019-12-27 14:41:25+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
31655,pytorch out of memory when calculation squared difference of unfold,2019-12-27 11:20:37+00:00,,0,1,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
31651,"update embedding at indices, other than those passed as input, in the case of sparse tensors",2019-12-27 07:19:42+00:00,,0,5,"[Label(name=""module: sparse""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
31615,'torch.load' report 'bad pickle data',2019-12-26 02:02:43+00:00,,0,14,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
31606,No auto-suggest capacity for Transformer,2019-12-25 08:04:39+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement"")]"
31603,Typo in `torch.utils.tensorboard.add_image`,2019-12-25 07:44:16+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
31598,ATen not compiled with MKL support,2019-12-24 16:12:55+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkl"")]"
31596,pytorch forward hangs in multiprocess environment,2019-12-24 12:55:25+00:00,,0,0,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
31579,Option to apply weights to gradients when using DistributedDataParallel,2019-12-23 21:22:14+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
31574,attribute and register_buffer are not the same on gpu ,2019-12-23 16:52:15+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31571,Bug in ForkingPickler for multiprocessing spawn context for shared storages on Linux,2019-12-23 14:44:33+00:00,,0,3,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
31570,Can't pin storage memory,2019-12-23 14:31:06+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
31565,Force libtorch to use CUDA context,2019-12-23 09:23:57+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31558,More dynamic PyTorch APIs,2019-12-22 17:57:37+00:00,,1,15,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: ux"")]"
31557,[docs] F.ctc_loss docs to warn clearly about invalid inf-causing inputs; zero_infinity to become enabled by default,2019-12-22 15:28:23+00:00,,0,13,"[Label(name=""module: docs""), Label(name=""triaged"")]"
31553,allow setting different batch size splits for data_parallel.py and distributed.py,2019-12-22 00:02:27+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
31551,TorchBind broken on rocm,2019-12-21 21:33:37+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31548,"c++ PReLUFuncOptions declared, not used or valid",2019-12-21 19:53:41+00:00,,0,1,"[Label(name=""triaged"")]"
31546,[Feature Request] Make torch.solve output NaN for singular matrix,2019-12-21 17:09:48+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
31545,IndexExpressions (or slice) for jit.script functions,2019-12-21 16:29:52+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31528,cuCtxGetDevice error and seg fault with DDP and OpenMPI,2019-12-20 22:17:22+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""module: cuda""), Label(name=""triaged"")]"
31487,Disable PSIMD? Why Pytorch is trying to download PSimd when PSIMD_SOURCE_DIR is defined?,2019-12-19 18:32:39+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
31478,DataParallel has different tensor copy behavior if batch size = 1,2019-12-19 17:10:03+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
31474,Slow clip_grad_norm_ because of .item() calls when run on device,2019-12-19 16:06:23+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
31471,Mnasnet0_5 first layer shape incorrect,2019-12-19 15:01:56+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: vision"")]"
31467,Distributed hangs on process termination with world_size=1,2019-12-19 10:46:36+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
31461,Make RRef.to_here() non-blocking,2019-12-19 05:56:28+00:00,,1,2,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
31460,DataParallel doesn't properly handle kwargs,2019-12-19 05:14:24+00:00,,0,17,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
31458,Integrate `torch.xxx` and `Tensor.xxx`,2019-12-19 03:07:22+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: ux"")]"
31430,[jit] `del` with slices doesn't work,2019-12-18 18:59:30+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31425,cuDNN convolution does not handle empty input tensor,2019-12-18 18:14:11+00:00,,0,4,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""small"")]"
31423,Add option in LSTM layer to access all cell states of all time steps,2019-12-18 16:21:39+00:00,,0,7,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
31422,Support DataParallel with PackedSequence,2019-12-18 14:17:35+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
31394,torch.scatter_logsumexp,2019-12-17 23:44:25+00:00,,0,4,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: scatter & gather ops"")]"
31391,"Error ""builtin cannot be used as a value"" when add Python snippets in C++",2019-12-17 22:59:23+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""low priority""), Label(name=""triaged"")]"
31386,[jit] Python type hints in TorchScript classes don't work,2019-12-17 21:38:16+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31368,TestMomentumSGD.test_fp16momentum_sgd (caffe2) is flaky,2019-12-17 16:53:12+00:00,,0,0,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""caffe2""), Label(name=""module: flaky-tests"")]"
31367,`clip_grad_norm` allows negative `max_norm` values,2019-12-17 16:51:10+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
31362,sklearn and pytorch incompatibility issue,2019-12-17 14:04:27+00:00,,0,12,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
31360,DDP/MP not yielding nontrivial speedup,2019-12-17 12:50:43+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
31356,Optimizing DLRM for CPU,2019-12-17 04:46:48+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""module: cpu""), Label(name=""triaged"")]"
31353,Memory management is inefficient which limits performance,2019-12-17 03:29:09+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
31321,Ability to download docs HTML for offline use,2019-12-16 18:45:39+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
31316,quantization - Missing operations needed for object detection,2019-12-16 15:13:17+00:00,,0,8,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
31311,Why Keras behave better and faster than Pytorch under the same network configuration?,2019-12-16 11:26:17+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: windows""), Label(name=""triaged"")]"
31308,[mac] Failure to import torch,2019-12-16 06:40:50+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: macos"")]"
31300,torch runtime error when manual link libmkldnn.so,2019-12-15 07:43:19+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
31289,Intel OMP multiprocessing assertion failure: Assertion failure at z_Linux_util.cpp(2338),2019-12-14 15:37:57+00:00,,0,2,"[Label(name=""module: dependency bug""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
31277,nn.MultiHeadAttention with different similarity measures,2019-12-14 01:30:32+00:00,,0,2,"[Label(name=""triaged""), Label(name=""oncall: transformer/mha""), Label(name=""function request"")]"
31264,Failed to config caffe2_rocksdb in cmake,2019-12-13 21:09:02+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
31261,pinned memory requires DeviceGuard in multi-process envs,2019-12-13 19:22:36+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
31259,Script method can't call a scripted function when it is decorated with `@torch.no_grad`,2019-12-13 19:04:53+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31252,[feature request] Better handling for CUDA Out of Memory,2019-12-13 14:16:43+00:00,,0,9,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
31232,Default shuffle behavior of DistributedSampler,2019-12-13 03:21:19+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
31228,[RPC] Support nn.Module pickling with share memory,2019-12-13 02:05:30+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
31202,Request for Lint Pass to Detect Modification on Parameters/Attributes during TorchScript Inference,2019-12-12 18:51:33+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""triaged"")]"
31191,[JIT] Slice with optional not supported,2019-12-12 16:02:54+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31185,Retain Subgraph or Save Intermediate Grad support?,2019-12-12 13:13:23+00:00,,0,5,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
31178,torch::nn::functional::interpolate crash,2019-12-12 07:45:53+00:00,,0,5,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
31141,[JIT] tensor(device=...) and tensor.to(device = ...) does not work properly in traced functions and modules,2019-12-11 22:50:28+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
31129,[jit] Python objects as arguments are not mutated,2019-12-11 19:08:20+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""low priority""), Label(name=""triaged"")]"
31110,torch.nn.Softplus threshold argument bug?,2019-12-11 13:17:48+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged"")]"
31107,Add torch.version.nccl,2019-12-11 11:47:38+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: nccl"")]"
31085,Common lookup of generic types across full script and mobile parsers,2019-12-11 00:43:07+00:00,,1,0,"[Label(name=""feature""), Label(name=""triaged"")]"
31050,float[] unsupported in native_functions.yaml,2019-12-10 16:16:40+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
31048,MathJax too small in Firefox,2019-12-10 15:37:41+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
31038,Pytorch 1.3.0 on RTX cards: CUDA error: an illegal memory access was encountered,2019-12-10 07:59:39+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
31007,"GPU version of minimal example for libtorch fails with ""no kernel image is available...""",2019-12-09 22:50:12+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
31004,The inference speed of the torch compiled manually is slower than the torch build from official binaries?,2019-12-09 22:29:20+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: binaries""), Label(name=""module: performance""), Label(name=""triaged"")]"
30987,Remove `.data`,2019-12-09 19:47:58+00:00,,0,20,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering""), Label(name=""actionable"")]"
30968,Categorical.sample too slow,2019-12-09 17:01:02+00:00,,0,4,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
30965,JIT breaks with postponed annotations,2019-12-09 14:54:56+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
30962,How can I add masks to parameters,2019-12-09 12:50:11+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
30955,error C3203: “templated_iterator”: 未专用化的 类 模板 不能用作 模板 变量，该变量属于 模板 参数“_Ty1”，应为 real 类型,2019-12-09 06:08:50+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: internals""), Label(name=""triaged"")]"
30953,false CHECK FAILED at ../aten/src/ATen/core/function_schema_inl.h,2019-12-09 05:41:05+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
30947,Wrong initialization with kaiming_uniform_,2019-12-09 00:02:52+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
30934,Spurious negative output in convolution of positive tensors,2019-12-07 16:11:34+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: convolution""), Label(name=""triaged"")]"
30929,How to set not to build libtorch_cpu.so and libmkl_*.so dependencies?,2019-12-07 04:08:13+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkl"")]"
30903,Don't ship protoc in wheels,2019-12-06 20:27:22+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
30900,CUDA error: initialization error (multiprocessing) with Python 3.7 ,2019-12-06 20:04:52+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
30899,Adding max_norm constraint to an Embedding layer leads to an error,2019-12-06 20:00:51+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged"")]"
30896,"FATAL_ERROR ""Failed to determine the source files for the regular expression backend""",2019-12-06 19:42:00+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
30873,ReduceLROnPlateau detects a plateau during a steady decrease after a spike,2019-12-06 16:54:35+00:00,,0,5,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
30867,save model definition file,2019-12-06 10:58:58+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: serialization""), Label(name=""triaged"")]"
30863,"[TensorBoard] Installed tensorboard 1.14.0, TestTensorBoardWriter.test_writer failed.",2019-12-06 08:26:08+00:00,,0,0,"[Label(name=""oncall: visualization"")]"
30830,Torch getting stuck transfering model to GPU in multiple GPU setting,2019-12-05 18:26:46+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
30812,Tensorboard graph failing to nest modules,2019-12-05 09:56:07+00:00,,0,5,"[Label(name=""oncall: visualization"")]"
30807,Sending sparse tensors over RPC not yet supported,2019-12-05 07:26:12+00:00,,1,10,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: rpc"")]"
30803,Pytorch openmp thread number tuning option for CPU trainning,2019-12-05 06:39:28+00:00,,2,4,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: multithreading"")]"
30788,Master Task: JIT/C++ Parity With Pytorch Python API,2019-12-05 02:29:23+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
30786,C++ / JIT Parity for ops in `torch/functional.py` and `torch/tensor.py`,2019-12-05 02:21:18+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""TSUsability""), Label(name=""TSRootCause:PyTorchParityGap"")]"
30780,Remove Ops bound in Python Layer for Legacy Reasons,2019-12-05 00:33:25+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: pybind"")]"
30774,Natively Declarable Fast-path Functions ,2019-12-05 00:08:10+00:00,,0,12,"[Label(name=""high priority""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
30762,Page for `torch.__config__` 404s,2019-12-04 23:03:04+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
30759,`TestDocCoverage.test_torch` error messages could be clearer,2019-12-04 22:51:46+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
30754,"JIT, nn.utils.weight_norm and {save,load}_state_dict produce wrong results",2019-12-04 21:29:41+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
30744,Issues in linking libtorch c++ ,2019-12-04 18:59:03+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
30723,Distributed Package asynchronous send/receive not working as expected (Gloo),2019-12-04 11:02:01+00:00,,0,11,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
30718,Method to broadcast parameters/buffers of DDP model,2019-12-04 07:37:50+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""enhancement"")]"
30711,Sorting in embedding_dense_backward_cuda takes very long time,2019-12-04 03:15:07+00:00,,0,10,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: embedding"")]"
30702,[FR] multidim squeeze and flatten,2019-12-04 00:27:32+00:00,,0,6,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: viewing and reshaping"")]"
30658,"Dedicated inverse AdaptiveMaxPool1d operation (e.g., AdaptiveMaxUnpool1d)",2019-12-03 13:33:42+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: pooling""), Label(name=""function request"")]"
30651,[TensorBoard] The different order of import SummaryWriter may cause Segmentation fault,2019-12-03 06:44:03+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""oncall: visualization"")]"
30635,Cannot use torch.jit.script with nn.DataParallel,2019-12-02 23:58:59+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
30633,Remove RPC internal helper that overrides the default pickler,2019-12-02 23:12:14+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
30611,Refactor/consolidate code for generating test tensors,2019-12-02 16:40:43+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
30596,Overlapping strides not supported by cublas,2019-12-02 01:45:59+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
30589,weight norm missing p=,2019-12-01 18:36:40+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
30586,"run ./android/run_tests.sh --warning-mode all   ,  show error.",2019-12-01 12:01:11+00:00,,1,4,"[Label(name=""triaged""), Label(name=""module: android""), Label(name=""oncall: mobile"")]"
30574,`index_select` with multidimensional `index`,2019-11-29 22:10:42+00:00,,0,9,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
30569,"Assertion `index >= -sizes[i] && index < sizes[i] && ""index out of bounds""` failed.",2019-11-29 14:11:05+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
30565,`F.interpolate` returns unexpected result when dealing with output size `1`,2019-11-29 07:44:21+00:00,,0,13,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: interpolation"")]"
30563,[ONNX] Support affine_grid_generator,2019-11-29 02:21:18+00:00,,1,13,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""onnx-triaged"")]"
30535,[FR] nn.init.* accept None as input tensor,2019-11-27 21:30:23+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
30533,Document memory characteristics of in-place ops,2019-11-27 20:42:52+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: type promotion"")]"
30532,Version 1.3 no longer supporting Tesla K40m?,2019-11-27 20:31:28+00:00,,0,78,"[Label(name=""module: binaries""), Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
30528,Warn about driver CUDA mismatch in torch.cuda.is_available(),2019-11-27 19:21:09+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
30525,[Tensorboard] nothing appears in the projector tab,2019-11-27 19:06:03+00:00,,0,12,"[Label(name=""needs reproduction""), Label(name=""module: tensorboard""), Label(name=""oncall: visualization"")]"
30507,"LibTorch, Error in 'xxx': free(): invalid pointer",2019-11-27 09:13:41+00:00,,0,12,"[Label(name=""needs reproduction""), Label(name=""module: cpp""), Label(name=""triaged"")]"
30505,Adding a function to change the process_group in DistributedDataParallel,2019-11-27 08:08:52+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
30489,Torchscript Precision Issue with PyTorch/vision pretrained model inception v3,2019-11-26 22:43:09+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
30469,Add single input/output tensor scatter/gather to ProcessGroup base class,2019-11-26 18:22:22+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""enhancement"")]"
30463,cuda support,2019-11-26 14:28:48+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
30461,`torch.multiprocessing.spawn` fails when `join=False`,2019-11-26 11:27:46+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
30459,[TensorBoard] Graph with objects other than torch.nn.Module can not be visualized.,2019-11-26 09:08:34+00:00,,0,28,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
30458,add method to make tensor constant for debug purposes,2019-11-26 09:03:23+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
30443,Expose bhistc to python,2019-11-26 02:19:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
30440,Redundant counter in batchnorm impl,2019-11-26 01:12:17+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
30421,[jit] Module references aren't preserved,2019-11-25 21:48:38+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
30418,More detailed information about TensorType in error messages,2019-11-25 21:34:09+00:00,,1,0,"[Label(name=""triaged""), Label(name=""enhancement"")]"
30413,nn.functional should maintain API parity with nn where possible,2019-11-25 19:33:58+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
30405,Codegen refactoring master task,2019-11-25 15:20:59+00:00,,1,10,"[Label(name=""triaged"")]"
30404,affine_grid CUDA / cuDNN support for Half removed in 1.3.x,2019-11-25 14:39:55+00:00,,0,7,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
30403,last updated timestamp,2019-11-25 14:37:24+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
30402,There is no support for `weight_decay`/`momentum` in SGD for sparse tensors.,2019-11-25 13:56:06+00:00,,0,7,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""enhancement"")]"
30401,Unexpected difference torch.multiprocessing.manager.queue and torch.multiprocessing.queue,2019-11-25 12:17:08+00:00,,0,5,"[Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
30399,Conv2d: Inconsistent results on Raspberry Pi 3B ,2019-11-25 09:59:45+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged"")]"
30388,Increasing memory usage on CPU,2019-11-24 18:34:50+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
30387,[docs] Missing docs for Storage.from_buffer,2019-11-24 17:27:26+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""triaged"")]"
30386,Exponentiated gradient descent,2019-11-24 17:20:07+00:00,,1,4,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
30384,Docs missing link to torch.__config__,2019-11-24 11:19:21+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
30380,Add Google Colab as an option on the 'Get Started' page.,2019-11-24 07:09:19+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
30373,Refactor (a bit) `torch.hub(.load)`,2019-11-23 17:39:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: hub"")]"
30365,TorchScript Performance: 150x gap between TorchScript and Native Python,2019-11-23 02:36:50+00:00,,0,13,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
30291,[feature request] A way to restore/assign tensor _version,2019-11-22 04:33:27+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
30263,pairwise_dist eps argument is confusing,2019-11-21 21:38:08+00:00,,0,4,"[Label(name=""module: numerical-stability""), Label(name=""module: bc-breaking""), Label(name=""module: docs""), Label(name=""triaged"")]"
30248,Add scripts for comprehensive benchmark TensorIterator,2019-11-21 19:46:05+00:00,,1,0,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""triaged"")]"
30246,CUDA masked_select uses way too much memory,2019-11-21 19:22:26+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
30226,Wrong substitution of aten::to ,2019-11-21 08:49:48+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""oncall: mobile"")]"
30225,c10:Error: could not unlink the shared memory file,2019-11-21 08:04:28+00:00,,1,1,"[Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""better-engineering"")]"
30214,Add support for fusion of relu6 with conv and bn for quantization,2019-11-21 03:20:35+00:00,,1,4,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
30182,[quantization][graph mode] SubgraphRewriter discards SourceRanges,2019-11-20 21:12:23+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
30162,[docs] Newline / whitespace / comma missing in formula for PoissonNLLLoss,2019-11-20 17:24:46+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
30161,Support struct that is initializable / mutable in CPP,2019-11-20 17:17:58+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
30155,Transform caffe2 to trt failed,2019-11-20 13:38:10+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""caffe2-op""), Label(name=""triaged"")]"
30150,I have  reconstructed LSTM model and tested by mnist data but the loss is not changed (loss=2.3),2019-11-20 09:07:19+00:00,,1,5,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
30138,Unable to register custom JIT Operator with AliasAnalysisKind::CONSERVATIVE ,2019-11-20 02:40:36+00:00,,1,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
30049,CPU Memory Leak for JIT ScriptModule on DataParallel,2019-11-18 22:51:58+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29987,Move the attributes of a module to the given device,2019-11-18 04:17:53+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29981,[feature request] Multivariate normal CDF,2019-11-17 10:30:43+00:00,,0,5,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
29973,Indexing into tensor order of magnitude slower than numpy,2019-11-16 19:52:58+00:00,,0,36,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
29961,Add support for integer matrix multiplication (particularly for dtype = torch.int8 ),2019-11-16 05:29:36+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
29891,Get wrong precision when multi nodes run in docker,2019-11-15 06:58:10+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
29863, n-dimensional non-constant padding functional,2019-11-15 00:37:23+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: padding"")]"
29860,torch.save/load shows raw path on the pickle_module arg,2019-11-15 00:16:23+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: serialization""), Label(name=""triaged"")]"
29844,Fold DispatchStub into c10 dispatcher,2019-11-14 21:44:46+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
29843,torch.distributions.normal.Normal is not JIT supported,2019-11-14 21:44:09+00:00,,0,19,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""triaged"")]"
29822,[jit] Traced `cat` on GPU doesn't support negative indexing,2019-11-14 17:52:49+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29816,AdamSparse fails to run,2019-11-14 15:53:27+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
29814,SGD fails on sparse matrix,2019-11-14 15:40:01+00:00,,0,11,"[Label(name=""module: sparse""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
29804,Parallel data loader performance degradation for IterableDataset with num_workers > 1 (but not for Dataset).,2019-11-14 11:52:21+00:00,,1,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
29800,unsqueeze has 'out=' option documented but not implemented(?),2019-11-14 10:28:06+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
29799,android run build_pytorch_android.sh error,2019-11-14 10:18:57+00:00,,1,4,"[Label(name=""triaged""), Label(name=""oncall: mobile"")]"
29763,Add doc coverage testing for quantization.rst,2019-11-13 22:58:27+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""oncall: quantization""), Label(name=""triaged"")]"
29758,[doc] Tensor.mean: dtype kwarg is not documented,2019-11-13 22:01:16+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: reductions"")]"
29754,[FR] general nll_loss and cross_entropy along arbitrary dimension,2019-11-13 21:37:35+00:00,,0,1,"[Label(name=""module: loss""), Label(name=""triaged"")]"
29750,[jit] Printing the graph doesn't include function calls,2019-11-13 21:21:51+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29739,"[build] gcc 7.4 needs CMAKE_CXX_FLAGS=""-std=gnu++11""",2019-11-13 18:39:19+00:00,,0,1,"[Label(name=""module: dependency bug""), Label(name=""module: build""), Label(name=""triaged"")]"
29734,Tensor.nbytes() returns itemsize * numel for sparse tensors,2019-11-13 17:57:40+00:00,,1,4,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""fixathon"")]"
29722,Slow (20-50x) RNN tutorial/example when torch is installed using pip comp. to conda installation,2019-11-13 10:45:36+00:00,,0,17,"[Label(name=""module: binaries""), Label(name=""module: performance""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: mkl"")]"
29720,Provide a mechanism to set global state per test in thread-safe manner,2019-11-13 09:03:33+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""enhancement"")]"
29717,CPU and CUDA error messages are divergent in type promotion,2019-11-13 08:56:09+00:00,,0,1,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: type promotion"")]"
29713,[FR] F.pad support syntax sugars for specifying the padding amount,2019-11-13 08:13:14+00:00,,0,0,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement"")]"
29710,Reliable way to identify RuntimeErrors (CUDA),2019-11-13 06:29:54+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
29697,MultiStepLR does not return good lr after load_state_dict,2019-11-13 01:23:40+00:00,,0,32,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
29692,[FR] add generator= kwarg support for torch.randn and torch.rand,2019-11-13 00:21:50+00:00,,0,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random"")]"
29662,[jit] Dict construction fails at runtime,2019-11-12 19:28:20+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29657,Improved detection of repeated observers,2019-11-12 17:54:32+00:00,,0,0,"[Label(name=""oncall: quantization""), Label(name=""low priority""), Label(name=""triaged"")]"
29647,[ONNX] Exported ONNX module with for loop + scatter operation on tensor seems to be incorrect,2019-11-12 11:31:55+00:00,,0,5,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
29642,error: ‘struct torch::jit::RegisterOperators’ has no member named ‘op’,2019-11-12 10:14:14+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29637,Compiled functions can't take variable number of arguments,2019-11-12 06:04:23+00:00,,0,10,"[Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""triaged"")]"
29597,[jit] Script class attributes aren't automatically added,2019-11-11 22:55:42+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29554,[feature request] Print some measure of fragmentation at CUDA out-of-memory,2019-11-11 17:45:56+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
29553,`print` uses lots of GPU memory,2019-11-11 17:42:08+00:00,,0,1,"[Label(name=""module: printing""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
29548,Dispatch key reorganization,2019-11-11 15:51:33+00:00,,0,5,"[Label(name=""module: internals""), Label(name=""triaged"")]"
29545,Tensorboard GPU Problems,2019-11-11 11:27:05+00:00,,1,3,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: tensorboard"")]"
29528,Half precision cdist,2019-11-10 20:45:10+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: half""), Label(name=""function request""), Label(name=""module: distance functions"")]"
29522,Indexing with torch tensors and NumPy arrays is different,2019-11-10 12:02:06+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
29516,RuntimeError: CUDA error: invalid device ordinal,2019-11-10 07:02:38+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
29510,torch.stack: bad shape error message,2019-11-09 21:34:26+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""module: error checking""), Label(name=""triaged"")]"
29498,"""malloc(): memory corruption (fast)"", action=3) at malloc.c",2019-11-09 01:40:22+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged"")]"
29429,NLLLoss reduce=True returning nan in float16,2019-11-08 01:10:37+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
29419,"IValue can't be constructed from one of `int`, `long`, or `long long`.",2019-11-07 23:25:08+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29402,[RFC] RPC timeout,2019-11-07 19:42:26+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
29398,[feature request] torch.kthvalue to support a new argument largest,2019-11-07 19:01:05+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
29378,Support out= parameters with autograd,2019-11-07 17:01:21+00:00,,0,16,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
29377,[jit] Saving a `ScriptFunction` to a buffer doesn't work,2019-11-07 16:58:19+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29373,backward_compatibility_check_test doesn't play well with reverts,2019-11-07 14:42:23+00:00,,2,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
29372,torch.std() returns nan for single item tensors.,2019-11-07 13:52:19+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""small"")]"
29369,nn.Conv(n)d constructor doesn't check for the number of kernel dimensions,2019-11-07 12:00:03+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
29254,Add support for ivalue float scalars,2019-11-06 00:34:25+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29235,Redo our library structure,2019-11-05 20:11:26+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged"")]"
29202,Add instructions for building torch.distributed on macOS,2019-11-05 15:58:24+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged"")]"
29198,RuntimeError: CUDA out of memory with available GPU memory,2019-11-05 14:33:30+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
29190,How to run two different jit models in two GPUs respectively in one scrip?,2019-11-05 10:09:34+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29177,[FR] trace_module traces both eval and train graph,2019-11-05 03:04:56+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement"")]"
29172,Modules without copying  in multiprocess,2019-11-05 01:59:16+00:00,,0,3,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
29137,"torch.sum(tensor, dim=()) is different from np.sum(arr, axis=())",2019-11-04 18:37:41+00:00,,1,37,"[Label(name=""high priority""), Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: TensorIterator""), Label(name=""module: deprecation""), Label(name=""module: reductions"")]"
29128,JIT should respect SKIP_PYTHON_BINDINGS and SKIP_PYTHON_BINDINGS_SIGNATURES,2019-11-04 16:45:45+00:00,,1,1,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
29125,_compared_saved_loaded doesn't work with torch.tensor constants,2019-11-04 16:20:09+00:00,,0,0,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
29116,torch.masked_fill missing out argument,2019-11-04 14:21:53+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: ux"")]"
29115,"crash when call dist.new_group(ranks=local_ranks, backend='gloo')",2019-11-04 13:48:49+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
29111,First element in data passed to `torch.*Tensor` constructors cannot be a tensor,2019-11-04 10:07:11+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
29108,a retrained and saved  jit module could not be reload.,2019-11-04 06:44:47+00:00,,1,8,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29094,"""Unknown type constructor"" error in TorchScript",2019-11-02 20:32:17+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
29093,error: 'SO_REUSEPORT' was not declared in this scope,2019-11-02 19:26:51+00:00,,0,16,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
29092,[FR] script returns subclass of the original module class,2019-11-02 15:25:12+00:00,,0,3,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""TSUsability""), Label(name=""TSRootCause:ModuleInheritance"")]"
29063,Trace of torch.tensor is impressively convoluted,2019-11-01 21:23:21+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
29057,Docker issue for Pytorch 1.3 ,2019-11-01 19:33:30+00:00,,0,0,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: docker"")]"
29044,Add Wishart and inverse-Wishart distributions,2019-11-01 17:47:04+00:00,,0,13,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
29042,Support clang+cuda builds,2019-11-01 17:15:46+00:00,,0,7,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement"")]"
29033,Move allgather_coalesced functionality to comm.cpp.,2019-11-01 14:48:14+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
29028,Inconsistent documentation for in-place functions at https://pytorch.org/docs/stable/torch.html,2019-11-01 13:43:34+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""triaged"")]"
29026,RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at /pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp:591,2019-11-01 09:25:10+00:00,,0,3,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
29023,Named Tensors: Slicing based on name,2019-11-01 08:00:15+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""module: named tensor"")]"
29021,Named Tensors: size of a named dimension,2019-11-01 07:56:00+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: named tensor"")]"
29010,torch.stack does not yet support named tensors ,2019-10-31 23:47:18+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: named tensor"")]"
28993,"torch.mean(x, dims=[]) has incorrect gradient in 1.2",2019-10-31 20:58:17+00:00,,0,13,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""quansight-nack""), Label(name=""module: reductions"")]"
28980,Unsafe use of `at::parallel_for` in current codebase,2019-10-31 19:36:42+00:00,,1,9,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""module: internals""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
28962,[feature request] Some activations modules missing inplace argument,2019-10-31 15:21:52+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
28956,RuntimeError: CUDA error: unknown error,2019-10-31 10:20:20+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
28950,ConnectionResetError when using dataLoader with pin_memory=True,2019-10-31 05:46:53+00:00,,0,12,"[Label(name=""needs reproduction""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
28943,The `@` operation uses too much memory on GPU,2019-10-31 02:57:16+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
28938,Cannot select version in the tutorials page,2019-10-30 23:45:18+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
28930,Add support for multidimensional input to `at::tensor`,2019-10-30 22:07:58+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
28929,torch::tensor(scalar) behaves differently from at::tensor(scalar),2019-10-30 22:04:47+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: pybind"")]"
28925,"Provide rpc, remote and dist autograd C++ APIs and register them as Prim::ops",2019-10-30 21:44:25+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: rpc"")]"
28906,Font used in documentation is not always sharp,2019-10-30 19:57:30+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
28884,Why attn_mask is not 3D tensor in nn.MultiheadAttention?,2019-10-30 15:39:18+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""oncall: transformer/mha"")]"
28882,Support RRef[T].__call__(*args) which invokes T.__call__(*args) on owner,2019-10-30 15:29:49+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
28863,Command for downloading torch 1.12.0 CUDA 10 linked to cu92 version,2019-10-30 01:10:38+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
28859,Remove bce_with_logits in derivatives.yaml,2019-10-29 22:54:46+00:00,,1,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering"")]"
28845,Implement operator<< for bfloat16,2019-10-29 19:57:57+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: bfloat16"")]"
28829,torch.cuda.close request to be able to reset communications,2019-10-29 11:14:17+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
28794,torch.from_file not documented,2019-10-28 17:20:40+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
28791,[CUDA-MEMCHECK] TestTorchDeviceTypeCUDA.test_pin_memory_from_constructor_cuda fails,2019-10-28 17:06:02+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
28786,RPC couldn't match torch.ones with requires_grad=True,2019-10-28 16:24:28+00:00,,1,2,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: distributed""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
28780,'import torch` fails with Illegal instruction,2019-10-28 05:37:18+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
28777,cudnn.determinstic=True causes dilated convolution to be >10x slower,2019-10-28 04:34:16+00:00,,0,9,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
28761,torch.tensor() is very slow when it is passed an h5py Dataset.,2019-10-27 19:25:05+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
28757,[feature request] Docs for fuse_conv_bn_eval,2019-10-27 16:59:33+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
28756,cmake allows both MKL and MKLDNN to be OFF;  aten/src/ATen/CMakeLists.txt then ignores c++ sources,2019-10-27 16:24:00+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
28754,ABI backwards compatibility,2019-10-27 13:31:34+00:00,,0,3,"[Label(name=""module: abi""), Label(name=""triaged"")]"
28746,super().__init__() not called in torch.nn.Module.__init__,2019-10-26 15:03:24+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
28745,Problem when installing Pytorch from source on CentOS 7.4,2019-10-26 14:49:12+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
28743,Sampler for IterableDataset,2019-10-26 12:50:25+00:00,,0,10,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
28742,torch.as_tensor fails to create named tensors,2019-10-26 09:22:53+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: named tensor""), Label(name=""module: tensor creation"")]"
28733,CPU MaxPool2d is very slow,2019-10-26 01:21:36+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: bootcamp""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: pooling"")]"
28721,[docs] Improve docs of nn.MultiheadAttention,2019-10-25 23:20:53+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
28657,[docs] Unclear input/output format for TransformerEncoderLayer,2019-10-25 16:15:30+00:00,,0,9,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
28655,Cmake fails due to bad python call,2019-10-25 15:25:20+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
28648,Can't successfully install pytorch with python3.6 on my pi 4 ,2019-10-25 11:05:42+00:00,,0,14,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""has workaround"")]"
28619,Channels Last (NHWC) support plan.,2019-10-24 21:21:22+00:00,,2,11,"[Label(name=""triaged""), Label(name=""module: memory format"")]"
28594,[BUG] Can't Deepcopy module with weightnorm,2019-10-24 15:30:23+00:00,,0,12,"[Label(name=""module: nn""), Label(name=""triaged"")]"
28577,`Tensor.__reversed__` breaks protocol for reversible objects,2019-10-24 10:39:31+00:00,,0,2,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: pybind"")]"
28558,We should suggest using as_strided_ instead of set_,2019-10-23 23:05:04+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
28552,Doing rendezvous twice can cause hangs,2019-10-23 21:50:59+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
28549,Expose DifferentiableGraphBackward to python,2019-10-23 21:27:50+00:00,,1,6,"[Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
28532,TestTorch.test_c10_layer_norm fails if you run it on a build of PyTorch with BUILD_CAFFE2_OPS=0,2019-10-23 18:41:57+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
28520,Unified management of thread local variables,2019-10-23 17:36:04+00:00,,0,12,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""module: internals""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
28519,[jit] C++ Documentation,2019-10-23 17:20:07+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
28517,[JIT] __repr__ support for ScriptModules,2019-10-23 17:07:57+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
28515,Get rid of libc10.so,2019-10-23 16:48:56+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
28497,Problem when installing pytorch 1.4 from source on Centos 6.3,2019-10-23 10:05:04+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
28444,Problem installing from source on CentOS 6.5,2019-10-22 20:21:48+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: nccl"")]"
28441,gradient of Dirichlet.log_prob gives nan,2019-10-22 19:58:52+00:00,,0,5,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
28440,Python/C++ API Parity: torch.optim optimizers,2019-10-22 19:29:29+00:00,,1,7,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
28417,Patch: Fix for using `clang` to compile CUDA,2019-10-22 09:26:59+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
28390,torch.multinominal ignores elements from cumulative distribution,2019-10-21 22:17:27+00:00,,0,0,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: random"")]"
28341,LinearOperator Abstraction / Structure-Exploiting LazyTensors for Linear Algebra,2019-10-20 00:00:23+00:00,,0,7,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: lazy"")]"
28329,No in-place version of where(),2019-10-19 06:00:04+00:00,,0,15,"[Label(name=""triaged""), Label(name=""OSS contribution wanted""), Label(name=""actionable""), Label(name=""module: sorting and selection""), Label(name=""function request"")]"
28320,Unable to install pytorch with cuda 10.0 using conda,2019-10-18 22:51:31+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged"")]"
28319,Seg-fault in LayerNormKernelImpl,2019-10-18 22:35:06+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged"")]"
28318,`torch.nn.Module._load_state_dict` catch-all error message can be misleading,2019-10-18 22:21:00+00:00,,0,2,"[Label(name=""triaged"")]"
28308,jit script fails with `AttributeError: 'str' object has no attribute 'lineno'`,2019-10-18 21:00:21+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
28307,[jit] scripted module and user defined methods,2019-10-18 20:33:44+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
28275,nn.parallel.replicate in v1.1+ is much slower than v1.0,2019-10-18 04:59:48+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
28267,Problem with jit TorchScript while copying data between GRUs,2019-10-18 00:41:01+00:00,,0,4,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
28258,[jit] TorchScript classes don't work in notebooks,2019-10-17 22:38:27+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
28249,Add scopes to autograd profiler,2019-10-17 20:53:02+00:00,,0,10,"[Label(name=""triaged"")]"
28245,PyTorch RPC should expose critical metrics to the application.,2019-10-17 20:38:42+00:00,,1,5,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
28244,ProcessGroupMPI reports incorrect world size,2019-10-17 20:26:05+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
28239,support class annotations in __init__,2019-10-17 19:07:37+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
28233,torch native functions cannot be used with inspect.signature,2019-10-17 17:40:37+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: pybind""), Label(name=""module: language binding"")]"
28224,Allow to disable polling for CUDA synchronization,2019-10-17 15:51:42+00:00,,0,19,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
28223,Convert manually bound `cuda` `cpu` `byte` `float` operators to native_functions,2019-10-17 15:09:45+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: ux"")]"
28221,TorchScript doesn't support torch.channels_last or any other memory format constants,2019-10-17 15:05:17+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: memory format"")]"
28220,TorchScript custom ops like `cuda` `byte` etc. doesn't support memory_format argument,2019-10-17 15:04:18+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
28218,"index_sub, index_mul and index_div",2019-10-17 14:07:55+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""OSS contribution wanted"")]"
28214,reflective padding for 5D tensor,2019-10-17 12:42:14+00:00,,0,0,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: padding"")]"
28206,torch.utils.tensorboard.SummaryWriter.add_graph do not support non-tensor inputs,2019-10-17 05:24:14+00:00,,0,7,"[Label(name=""oncall: visualization"")]"
28194,New Stochastic Optimization Algorithms in Pytorch,2019-10-17 01:52:03+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
28191,[JIT] Allow user to provide aliasing information on input tensors and model parameters,2019-10-17 01:30:37+00:00,,0,2,"[Label(name=""triage review""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
28146,Named tensor: align_to align_as  error messages,2019-10-16 21:34:00+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
28142,Named Tensor: Support -1 in `unflatten`.,2019-10-16 21:29:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: named tensor"")]"
28119,Provide function similar to cdist that returns dist_p^p,2019-10-16 18:39:10+00:00,,0,11,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: distance functions"")]"
28110,Stable docs show dead __config__ section link,2019-10-16 16:50:01+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
28093,Move options logic in _like functions from parsing layer to implementations,2019-10-16 15:54:09+00:00,,1,3,"[Label(name=""triaged"")]"
28090,[discussion] Smarter version of torch.reshape (can avoid realloc in some cases),2019-10-16 15:07:09+00:00,,0,8,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: viewing and reshaping"")]"
28055,Traced resnet101 leaks memory during `forward`,2019-10-15 23:56:09+00:00,,0,3,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
28035,Easy way to create previews of the docs website after any changes,2019-10-15 20:54:56+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: doc infra"")]"
28033,TestTorch.test_doc should be in TestDocCoverage,2019-10-15 20:50:04+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
27975,"Sending CUDA tensors via queue between processes, memory of Consumer process grows infinitely ",2019-10-15 13:16:52+00:00,,0,1,"[Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
27970,can't load model on cuda after call cudaDeviceReset functions,2019-10-15 09:47:22+00:00,,0,9,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
27958,how to use libtorch library in cuda file with nvcc compiler(c++)?,2019-10-15 03:35:07+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
27955,Expand Pytorch C10D backend to dynamic load third party communication library,2019-10-15 02:34:23+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
27936,Specifying `pos_weight` in F.binary_cross_entropy_with_logits leads to RuntimeError: class size not match,2019-10-14 21:28:35+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: error checking""), Label(name=""triaged"")]"
27926,`num_batches_tracked` update in `_BatchNorm` forward should be a single scalar update on host regardless of the residence of the layer,2019-10-14 20:46:36+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement"")]"
27843,Be able to build torch.distributed documentation easier,2019-10-14 14:04:28+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
27840,caffe2 install VS2019 CUDA 10.1 lib\\torch.lib : fatal error LNK1248: image size (10028FA9F) exceeds maximum allowable size (FFFFFFFF) ,2019-10-14 10:55:22+00:00,,0,35,"[Label(name=""caffe2"")]"
27839,RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 24 and 195 in dimension 0 at /opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/TH/generic/THTensor.cpp:689,2019-10-14 10:21:36+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""module: nn""), Label(name=""triaged"")]"
27815,Improve the error message when trying to install in a 32-bit Python environment,2019-10-12 19:35:01+00:00,,0,15,"[Label(name=""triaged""), Label(name=""enhancement"")]"
27785,docs for torch.cuda.reset_max_memory_reserved don't exist,2019-10-11 22:05:55+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
27780,torch.cuda.default_generators documentation referenced but don't exist.,2019-10-11 21:18:46+00:00,,1,5,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
27766,Test `make html-stable` target in CI,2019-10-11 18:54:35+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: doc infra"")]"
27752,Version number is still duplicated in a bunch of places,2019-10-11 17:11:34+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""better-engineering"")]"
27740,Scripting torchvision.models.detection.maskrcnn_resnet50_fpn,2019-10-11 10:28:58+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: vision"")]"
27708,Documentation makefile should include torchvision,2019-10-10 17:41:47+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
27694,Deployment training model at C + + end,2019-10-10 10:47:43+00:00,,1,5,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged"")]"
27687,`nn.Sequential.__setattr__` appends to the execution list,2019-10-10 07:55:04+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""low priority""), Label(name=""triaged"")]"
27682,I can't set gpu is 1 it always use gpu 0,2019-10-10 06:16:32+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""module: cpp""), Label(name=""module: cuda""), Label(name=""low priority""), Label(name=""triaged"")]"
27671,Avoid RTTI in DistEngine,2019-10-10 00:37:00+00:00,,1,4,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
27647,🚀 Graceful RPCAgent termination in multi-driver scenario,2019-10-09 23:16:24+00:00,,1,4,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
27642,Test re-entrant backward works with torch.distributed.autograd.backward(),2019-10-09 23:05:11+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: rpc"")]"
27641,torch.distributed.autograd.backward() should populate .grad field on Tensors by default.,2019-10-09 23:03:31+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: rpc"")]"
27617,[feature request] [dataloader] Pad variable-sized tensors in default_collate,2019-10-09 17:54:23+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
27614,scatter_add allows index tensor that doesn't match input size in forward pass but fails on backward pass,2019-10-09 17:31:01+00:00,,1,29,"[Label(name=""high priority""), Label(name=""module: crash""), Label(name=""triaged"")]"
27610,[FR][RFC] Build a serving framework to host and serve trained PyTorch models,2019-10-09 16:29:17+00:00,,0,27,"[Label(name=""feature""), Label(name=""triaged"")]"
27608,Unify warning logging mechanism,2019-10-09 16:21:05+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""better-engineering"")]"
27588,RuntimeError: cuDNN error: CUDNN_STATUS_MAPPING_ERROR,2019-10-09 02:34:40+00:00,,0,27,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
27579,Support Anomaly detection for distributed autograd.,2019-10-08 22:59:41+00:00,,1,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: rpc"")]"
27542,Make topk sort stable,2019-10-08 13:47:15+00:00,,0,18,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: determinism""), Label(name=""OSS contribution wanted""), Label(name=""module: sorting and selection"")]"
27540,CTCLoss cuda backend large batch handling takes up to 1.8x more memory,2019-10-08 12:52:52+00:00,,0,1,"[Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""enhancement"")]"
27522,[feature request] Reduction (torch.add / torch.logaddexp / torch.max / torch.min / torch.mean) of several tensors without extra copies/allocations / memory accesses } TensorList inputs support,2019-10-08 03:11:57+00:00,,0,41,"[Label(name=""triaged""), Label(name=""function request"")]"
27517,Allow explicit gradients in torch.distributed.autograd.backward() API,2019-10-08 00:52:31+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
27505,[JIT] ndimension not supported,2019-10-07 22:04:31+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
27504,[JIT] List Comprehensions With Ifs not Supported ,2019-10-07 21:57:43+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
27497,TSAN failure related to mkldnn,2019-10-07 21:18:15+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
27479,[JIT] Figure out how to easily investigate memory usage issues issues,2019-10-07 18:24:08+00:00,,2,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
27475,[JIT] script::Module API parity with nnmodule,2019-10-07 18:05:54+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
27466,batch_norm_elemt_cuda_template does not use its argument epsilon,2019-10-07 17:23:09+00:00,,0,7,"[Label(name=""module: bc-breaking""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
27421,[dataloader] Sampler abstract constructor API minor proposal,2019-10-05 11:51:39+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
27409,Installer not setting rpath for MAGMA (OS X w/ GPU),2019-10-04 22:53:19+00:00,,0,19,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: macos"")]"
27406,[jit] String frontend doesn't support default arg values,2019-10-04 21:36:31+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
27394,Re-enable test_EmbeddingBag_per_sample_weights_and_no_offsets_cuda,2019-10-04 19:29:14+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
27376,[ONNX export] UpSample with scale_factor should map to UpSample op with scale ,2019-10-04 17:33:06+00:00,,0,16,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""onnx-triaged"")]"
27343,[jit] `ScriptFunction`s are loaded as `ScriptModule`s,2019-10-03 23:20:40+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
27336,Allow one inferred axis in torch.split ,2019-10-03 22:34:02+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement"")]"
27312,torch.Tensor.mean erroneously documented as sometimes returning a tuple,2019-10-03 19:56:10+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: reductions"")]"
27300,"Tensorboard add image with boxes, labels, and confidence scores.",2019-10-03 18:20:23+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
27297,CUDA error: device-side assert triggered(insert_events at /pytorch/c10/cuda/CUDACachingAllocator.cpp:569),2019-10-03 16:31:03+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
27276,Add in-place view (view_),2019-10-03 04:40:16+00:00,,0,1,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: viewing and reshaping"")]"
27218,pytorch data_parallel oom on gpu:0,2019-10-02 15:44:14+00:00,,0,1,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
27175,Easier way to create tensors with names,2019-10-01 21:56:35+00:00,,0,12,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: named tensor"")]"
27147,Stop binding in-place methods to `torch.*`,2019-10-01 17:57:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: ux"")]"
27144,torch::jit::script::Module has no zero_grad(),2019-10-01 17:22:48+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
27138,CUDAPytorchToCaffe2.MutualResizes is flaky,2019-10-01 15:48:48+00:00,,0,0,"[Label(name=""caffe2-op""), Label(name=""module: cuda""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
27099,Support implicit RRef type conversion,2019-09-30 21:19:22+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
27097,[c10] c10 dispatch doesn't support tracing of scalars,2019-09-30 21:10:15+00:00,,0,19,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: dispatch"")]"
27094,[jit] Document what types can be traced,2019-09-30 20:32:43+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
27072,RNG for torch.randn_like,2019-09-30 17:54:41+00:00,,0,9,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random"")]"
27055,torch::NoGradGuard no_grad get wrong  when I use batchsize!=1,2019-09-30 08:16:01+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
27046,The Gather problem in DataParallel: dimension are not matched.,2019-09-30 04:01:04+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
27034,RuntimeError:[enforce fail at context.h:48] option.device_type() ==PROTO_CPU. 1vs0,2019-09-29 13:12:45+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
27030,Tensorboard logging image WITH LABEL,2019-09-29 07:08:45+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
27024,Is it an incompleted dst tensor synchronization in CUDA device to device copy ?,2019-09-29 02:24:09+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
27021,Cmake warnings during build,2019-09-28 21:52:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: build warnings"")]"
27015,Missing bin and include when building with torchvision on CentOS,2019-09-28 08:16:04+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: vision"")]"
27003,[JIT] Script doesn't preserve builtin torch named tuples upon python return,2019-09-27 22:37:02+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
26990,torch.quantized.modules.floatFunctional -- add a little color commentary to the doc,2019-09-27 20:35:57+00:00,,2,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""quantization_release_1.3"")]"
26967,Lint rule to test for creation of tensor in native/ without options(),2019-09-27 14:25:47+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: lint""), Label(name=""triaged""), Label(name=""better-engineering"")]"
26964,AnyValueTest.CorrectlyAccessesIntWhenCorrectType UBSAN failure: owncast of address 0x60300105d750 which does not point to an object of type 'Holder<const int>' Sep 27 00:01:03 0x60300105d750: note: object is of type 'torch::nn::AnyModule::Value::Holder<int>',2019-09-27 13:34:59+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
26957,Batched Dataloader,2019-09-27 05:54:56+00:00,,0,9,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
26950,conv2d Memory usage is too large； pytorch 1.1.0,2019-09-27 03:23:44+00:00,,0,1,"[Label(name=""module: dependency bug""), Label(name=""module: cudnn""), Label(name=""module: memory usage""), Label(name=""module: convolution""), Label(name=""triaged"")]"
26889,Statically checked tensor shapes,2019-09-26 12:41:48+00:00,,0,27,"[Label(name=""module: internals""), Label(name=""feature""), Label(name=""triaged"")]"
26863,[BUG Report]Integrate libtorch to ffmpeg but memory leak happened!,2019-09-26 03:01:14+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: vision"")]"
26802,Google Summer of Code,2019-09-25 14:06:32+00:00,,0,1,"[Label(name=""triaged"")]"
26796,setup.py install error,2019-09-25 11:13:25+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
26790,Importing tensorboard jams CUDA device selection,2019-09-25 07:37:27+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
26781,Matrix corresponding to convolution by a 2D kernel (convmtx2),2019-09-25 05:28:53+00:00,,0,15,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
26759,[RFC] RRef Protocol,2019-09-24 22:09:15+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
26744,[jit] Default args don't work with TorchScript classes,2019-09-24 20:05:14+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
26730,[jit] Bad error when instantiating TorchScript class with incorrect types,2019-09-24 17:35:46+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
26691,Support FPGA Xilinx,2019-09-23 23:59:28+00:00,,0,11,"[Label(name=""triaged""), Label(name=""module: backend"")]"
26659,torch::nn::Sequential not compatible with torch::nn::RNN,2019-09-23 20:24:45+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged"")]"
26567,Make `torch.save` serialize a zip file,2019-09-20 21:20:08+00:00,,0,4,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""enhancement"")]"
26551,No way to disable mse_loss broadcasting warning,2019-09-20 17:39:30+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
26534,MKLDNN+AMD BLIS path for PyTorch ,2019-09-20 09:01:12+00:00,,0,13,"[Label(name=""feature""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
26527,Multilinear map,2019-09-20 06:29:35+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request"")]"
26456,[libtorch]Same model in CUDA and CPU got different result?,2019-09-19 07:04:18+00:00,,0,17,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged"")]"
26447,parallel_for may hang when called in main process and then on daemon process,2019-09-19 01:25:13+00:00,,0,12,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
26446,Avoid sending zero grads over the wire in distributed autograd backward pass,2019-09-19 00:24:47+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: rpc"")]"
26428,Remove TensorOptions logic from generated code,2019-09-18 20:58:43+00:00,,1,24,"[Label(name=""module: internals""), Label(name=""triaged"")]"
26409,Generated file not getting cleaned up by clean,2019-09-18 16:37:49+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
26400,RuntimeError: tensor.ndimension() == static_cast<int64_t>(expected_size.size()) INTERNAL ASSERT FAILED,2019-09-18 09:04:58+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""module: multi-gpu""), Label(name=""module: cuda""), Label(name=""triaged"")]"
26396,NNPACK condition should be changed (ARM processors),2019-09-18 07:51:33+00:00,,0,1,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: nnpack"")]"
26379,DistAutogradContext should be cleaned up in case of node failures.,2019-09-18 00:04:00+00:00,,1,0,"[Label(name=""module: autograd""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: rpc"")]"
26354,torch.tensor / torch.as_tensor not working with list of tensors,2019-09-17 18:13:17+00:00,,0,10,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: tensor creation"")]"
26345,The performance of multiplication of two matrices is different between window and linux,2019-09-17 12:24:33+00:00,,1,2,"[Label(name=""module: performance""), Label(name=""module: windows""), Label(name=""triaged"")]"
26344,How to get rid of zombie processes using torch.multiprocessing.Pool?,2019-09-17 11:55:41+00:00,,0,3,"[Label(name=""module: dependency bug""), Label(name=""oncall: distributed""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
26340,CPU version of PyTorch on PyPI,2019-09-17 08:10:19+00:00,,0,58,"[Label(name=""module: build""), Label(name=""feature""), Label(name=""oncall: releng""), Label(name=""module: cpu""), Label(name=""triaged"")]"
26338,Behavior of F.dropout in eval mode,2019-09-17 06:57:22+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""low priority""), Label(name=""triaged"")]"
26334,"Supporting ""cdf"" for Student-T distribution",2019-09-17 04:09:00+00:00,,0,7,"[Label(name=""module: distributions""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""enhancement"")]"
26288,Inplace and out arguments for BatchNorm (and other norm layers: InstanceNorm / LayerNorm / GroupNorm ...),2019-09-16 15:46:26+00:00,,0,57,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""function request""), Label(name=""module: norms and normalization"")]"
26258,"""git describe"" shows incorrect version 1.0 instead of 1.2",2019-09-15 22:12:29+00:00,,1,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
26228,Higher dimension support for `MultiLableSoftMarginLoss`,2019-09-14 02:33:49+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""enhancement"")]"
26218,Default adam epsilon to 1e-7 when on fp16,2019-09-13 23:02:07+00:00,,0,11,"[Label(name=""module: numerical-stability""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: half"")]"
26207,Dispatch Tracing/Debugging,2019-09-13 21:50:23+00:00,,1,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""internals""), Label(name=""module: dispatch"")]"
26165,Memory leak in multithreading environment when loading checkpoint,2019-09-13 12:52:11+00:00,,1,7,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: multiprocessing""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
26157,Tests for pytorch_macos_10_13_cuda9_2_cudnn7_py3_build fail,2019-09-13 07:45:36+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: macos"")]"
26139,c10 List API hard to use,2019-09-12 23:07:21+00:00,,0,4,"[Label(name=""module: internals""), Label(name=""triaged"")]"
26136,There should be gating around BFloat16,2019-09-12 22:37:02+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: bfloat16"")]"
26120,Process fails with assertion error in magma-cuda100,2019-09-12 20:29:33+00:00,,0,22,"[Label(name=""module: dependency bug""), Label(name=""needs reproduction""), Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
26119,Make GloballyUniqueId a common type for both rpc and dist autograd,2019-09-12 20:24:09+00:00,,1,3,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
26117,Tracing non-constant shapes is broken,2019-09-12 20:17:41+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
26110,Access data_ptr in RNN.cpp,2019-09-12 18:30:32+00:00,,0,9,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
26109,Support the AVX512 runtime dispatch,2019-09-12 18:24:12+00:00,,1,6,"[Label(name=""feature""), Label(name=""low priority""), Label(name=""triaged"")]"
26097,[RFC] TensorBoard extensions and improvements for PyTorch,2019-09-12 15:13:16+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
26086,[Feature Request] Trace / Script C++ models,2019-09-12 06:43:45+00:00,,0,7,"[Label(name=""oncall: jit""), Label(name=""module: cpp""), Label(name=""triaged"")]"
26072,DataLoader workers fail to die,2019-09-12 00:15:49+00:00,,0,5,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
26058,sccache stats can cause whole build to fail,2019-09-11 22:06:27+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
25991,Why doc building isn't failing us for referring to a non-existent method?,2019-09-11 12:39:23+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
25979,[C++] `Module::pretty_print` is broken,2019-09-11 05:13:23+00:00,,0,7,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged"")]"
25978,Provide a way to select SVD algorithm in PyTorch?,2019-09-11 05:04:10+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""function request"")]"
25941,TestAutograd.test_deep_reentrant fails with SIGBUS on macOS,2019-09-10 20:05:52+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: macos"")]"
25904,Python hang after using torch.exp(),2019-09-10 07:50:40+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
25892,load_state_dict on CPU first,2019-09-10 02:47:12+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
25888,Forward/backward hooks for C++ torch::nn modules,2019-09-10 00:31:38+00:00,,0,29,"[Label(name=""module: cpp""), Label(name=""module: autograd""), Label(name=""triaged"")]"
25883,Python/C++ API Parity: torch.nn modules and functional,2019-09-09 22:35:40+00:00,,1,109,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""good first issue""), Label(name=""triaged"")]"
25880,Incorrect lable read with ImageInput Op of Caffe2,2019-09-09 22:09:18+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
25821,Conv2D 2x~20x slower than Tensorflow when channel count is small,2019-09-07 15:53:03+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
25820,Pytorch master can not build with computer capability 3.0 under Mac OS X 10.13.16 with Nvidia GT 750m,2019-09-07 13:39:26+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: macos"")]"
25814,(PyTorch1.1 and 1.2) RuntimeError: Can't detach views in-place. Use detach() instead,2019-09-07 06:42:08+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
25803,[jit] `random` module support,2019-09-06 21:16:10+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
25785,[Feature request] modified Cholesky decomposition,2019-09-06 17:50:47+00:00,,1,10,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra"")]"
25783,Detaching a distribution's `log_prob` to block gradients only w.r.t its parameters,2019-09-06 17:36:14+00:00,,0,13,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
25767,"Model parallel with DDP get `Socket Timeout` error when using NCCL, while GLOO works fine",2019-09-06 13:40:15+00:00,,0,27,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
25752,torch.cuda.empty_cache() write data to gpu0,2019-09-06 03:30:48+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
25747,Int32 overflow in bincount indexing,2019-09-06 00:54:15+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: 64-bit"")]"
25743,Custom sampler for Seq2Seq models to avoid padding,2019-09-06 00:11:08+00:00,,0,6,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
25714,Backtrace prints many <unknown function>,2019-09-05 16:48:01+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""better-engineering"")]"
25691,[dataloader] Hang because of too many open files (and probably some process dead),2019-09-05 06:22:42+00:00,,0,4,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
25661,finfo operator not bound into JIT,2019-09-04 18:59:35+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
25648,"Torch.jit.trace unexpected error with `torch.cat(…, dim=-1)` ",2019-09-04 15:03:55+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
25646,libtorch forward memory leak,2019-09-04 14:30:47+00:00,,0,9,"[Label(name=""module: cpp""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
25641,[distributed] all_gather on a List of Tensors directly,2019-09-04 07:48:53+00:00,,1,5,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement"")]"
25635,[C++] Support negative index in `torch::TensorAccessor::size()`,2019-09-04 05:42:45+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
25601,Avoid non-POD data in thread_local,2019-09-03 20:53:09+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: multithreading""), Label(name=""better-engineering"")]"
25591,IValue pickle does not work properly if an empty tensor table is not provided,2019-09-03 17:49:40+00:00,,0,7,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
25570,Remote memory access similar to MPI one-sided in pytorch,2019-09-03 03:30:46+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: mpi"")]"
25552,Usage of DDP on a module that doesn't require gradients,2019-09-02 12:13:28+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""enhancement"")]"
25548,The inference speed of the torch c++ dynamic library compiled manually is slower than the torch library officially provided,2019-09-02 06:48:52+00:00,,0,13,"[Label(name=""module: binaries""), Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
25535,[Proposal] Pin Windows SDK and MSVC compiler versions in LibTorch,2019-09-01 11:14:53+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged""), Label(name=""enhancement"")]"
25522,[dataloader] Problem in exception reraise mechanism,2019-08-31 12:51:36+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
25520,pytorch c++ api cannot call operator() on torch::nn::Sequential,2019-08-31 08:50:33+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged"")]"
25518,Assign torch.cuda.FloatTensor to List tensor,2019-08-31 05:28:20+00:00,,0,3,"[Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""has workaround"")]"
25514,Multithreaded backpropagation with custom autograd.Functions,2019-08-31 00:53:30+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
25492,clang-tidy job merges with master which can lead to hard to understand errors,2019-08-30 20:14:52+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
25481,[feature request] symmetric matrix square root,2019-08-30 18:19:26+00:00,,0,44,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""function request"")]"
25480,Vectorize bool operations,2019-08-30 17:37:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: boolean tensor"")]"
25478,Delete TensorOptions::operator==,2019-08-30 16:16:06+00:00,,1,3,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""small"")]"
25460,Build link not right,2019-08-30 10:03:29+00:00,,0,11,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
25417,Add a mode to check input tensor sizes in allreduce_coalesced,2019-08-29 19:33:42+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
25416,Add GPU support to c10d allreduce_coalesced ,2019-08-29 19:28:14+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
25410,[jit] NamedTuples don't respect `__new__`,2019-08-29 18:33:48+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
25387,[DRAFT] Auto-casting in JIT - Automatic mixed precision,2019-08-29 12:08:22+00:00,,0,17,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
25381,regarding builtin_function_or_method,2019-08-29 08:11:08+00:00,,0,1,"[Label(name=""feature""), Label(name=""low priority""), Label(name=""triaged"")]"
25329,[jit] Bad error for incorrect container type,2019-08-28 17:57:35+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
25314,ConstQuantizerPtr is misnamed,2019-08-28 15:33:34+00:00,,1,2,"[Label(name=""oncall: quantization""), Label(name=""triaged"")]"
25310,Handling of packed_sequence by activation functions and linear layers,2019-08-28 14:47:28+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
25297,torch.as_tensor(bytearray(...)) seems to leak memory,2019-08-28 08:37:57+00:00,,0,9,"[Label(name=""module: dataloader""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
25267,JIT leaks memory when I change the max sequence length,2019-08-27 19:56:39+00:00,,0,17,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""has workaround"")]"
25206,Ability to tell whether a tensor might be changed in TH/Aten impl,2019-08-26 23:13:41+00:00,,1,8,"[Label(name=""high priority""), Label(name=""module: internals""), Label(name=""triaged"")]"
25190,Error in python3: double free or corruption (fasttop),2019-08-26 19:00:55+00:00,,0,13,"[Label(name=""needs reproduction""), Label(name=""module: cudnn""), Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
25174,BCEWithLogitsLoss expects wrong shape of weight (#classes instead of batch size),2019-08-26 11:57:29+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
25162,Incorrect Validation Accuracy Due to Distributed Sampler,2019-08-25 16:45:10+00:00,,1,10,"[Label(name=""oncall: distributed""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
25156,euclidean distance between two tensors,2019-08-25 05:57:18+00:00,,0,6,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: distance functions"")]"
25150,Problems with install python from source,2019-08-24 19:19:17+00:00,,0,10,"[Label(name=""module: build""), Label(name=""triaged"")]"
25137,Serialization does not work for quantized modules,2019-08-24 01:25:57+00:00,,0,1,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""quantization_release_1.3"")]"
25132,Feature request: Fix dimension convention for masks in transformer,2019-08-23 22:12:29+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
25112,[RFC] NestedTensor - 0.0.2,2019-08-23 18:52:25+00:00,,0,0,"[Label(name=""triaged"")]"
25104,[FR] Dropout modules/functions should take in generator=,2019-08-23 16:36:37+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random"")]"
25092,No way to correctly reset weights of a model with spectral norm,2019-08-23 10:30:36+00:00,,0,9,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""has workaround"")]"
25091,JavaScript (Web Assembly) target for trained models,2019-08-23 10:07:34+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement"")]"
25071,Generator objects should not always use the same seed,2019-08-23 01:24:45+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: random"")]"
25070,[FR] torch.(Generator|random).seed allows specifying the seed value,2019-08-23 01:17:28+00:00,,0,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: random"")]"
25066,[FR][jit] torch.jit.script as a class decorator,2019-08-23 00:39:29+00:00,,0,12,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
25057,ctc_loss computes different losses and gradients on batched utterances vs. individual utterances,2019-08-22 23:33:23+00:00,,0,0,"[Label(name=""module: loss""), Label(name=""triaged"")]"
25047,ScriptModule and nn.Module parameter ordering difference,2019-08-22 21:27:58+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
25045,[Distance functions] F.pdist backward CUDA invalid configuration,2019-08-22 21:11:15+00:00,,0,11,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: distance functions"")]"
25039,Add new interpolation modes to `grid_sample`,2019-08-22 18:56:24+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request""), Label(name=""module: interpolation"")]"
25034,"make add_module accept tuples as well or change containers(ModuleList, Sequential, etc) to allow this",2019-08-22 17:30:29+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
25032,[FYI] NestedTensor Project Progress,2019-08-22 17:11:28+00:00,,0,16,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
25014,Benchmark cuDNN affine_grid_generator vs native,2019-08-22 06:58:11+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
25004,[C++] Call find_package(Torch REQUIRED) more than one time in downstream project causes CMake configuration error,2019-08-22 00:47:44+00:00,,0,10,"[Label(name=""module: build""), Label(name=""triaged"")]"
24985,Data worker should fetch a sample instead of a batch.,2019-08-21 20:33:16+00:00,,0,6,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
24984,DataLoader slow down when `pin_memory=False`,2019-08-21 20:10:00+00:00,,1,5,"[Label(name=""module: performance""), Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
24963,torch.cuda.synchronize blocks CUDA execution on other threads using other devices.,2019-08-21 14:58:56+00:00,,0,8,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
24956,[RPC] Fix logging initialization warning in ProcessGroupAgent,2019-08-21 07:04:16+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
24946,[RPC] Make ProcessGroupAgent send task non-blocking,2019-08-21 02:33:51+00:00,,1,7,"[Label(name=""todo""), Label(name=""triaged""), Label(name=""module: rpc"")]"
24931,"Consider not checking in autogenerated core/{Tensor.h,TensorMethods.h}",2019-08-20 21:15:14+00:00,,0,7,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
24930,Successive Layer Normalization in nn.Transformer,2019-08-20 21:12:42+00:00,,0,9,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
24915,Shared Dataset Functionality,2019-08-20 17:22:07+00:00,,0,8,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""better-engineering"")]"
24904,tensorboard add_graph error,2019-08-20 13:01:43+00:00,,0,28,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
24899,Export torch.cat to ONNX with Dynamic shape does not work on GPU,2019-08-20 09:58:16+00:00,,0,9,"[Label(name=""caffe2""), Label(name=""triaged"")]"
24891,RuntimeError on PyTorch 1.2 under NVIDIA Nsight Systems,2019-08-20 05:10:36+00:00,,0,14,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: third_party"")]"
24870,Recommendations for Grid Sample/Affine Grid/Displacement Fields/Optical Flow,2019-08-19 22:22:03+00:00,,0,16,"[Label(name=""proposal accepted""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
24859,Improve binary release for PyTorch domain library,2019-08-19 20:14:18+00:00,,0,27,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""better-engineering"")]"
24836,Gloo scatter gives wrong result for stride != 1,2019-08-19 07:57:51+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged"")]"
24835,NetworkX's Version,2019-08-19 04:18:21+00:00,,0,2,"[Label(name=""caffe2"")]"
24834,PyTorch 1.2 'module' object has no attribute 'BFloat16StorageBase',2019-08-19 04:03:19+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: undefined reference""), Label(name=""module: vision"")]"
24831,subprocess.CalledProcessError: Compile source in NVIDIA TX2,2019-08-19 03:09:43+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
24826,Transformer Lack of Embedding Layer and Positional Encodings,2019-08-18 22:46:01+00:00,,0,18,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""oncall: transformer/mha"")]"
24823,"Problematic handling of NaN and inf in grid_sample, causing segfaults, corrupted CUDA memory, and incorrect results",2019-08-18 21:55:41+00:00,,1,3,"[Label(name=""high priority""), Label(name=""module: crash""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
24810,"Doesn't install the python module ""torch""",2019-08-18 01:31:26+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged"")]"
24798,Installs empty directories under Python's sitelibdir,2019-08-17 00:14:45+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
24786,[jit] Dict iterator invalidation doesn't match Python,2019-08-16 19:52:37+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
24500,Failed to compile PyTorch on IBM Power 9 architecture with CUDA 10,2019-08-16 17:31:43+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
24498,Migrate CPU_tensor_apply to TensorIterator in aten/src/ATen/native/TensorCompare.cpp:30,2019-08-16 17:27:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: CPU_tensor_apply"")]"
24478,Port CPU_tensor_apply functions to TensorIterator (umbrella issue),2019-08-16 17:17:41+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: CPU_tensor_apply"")]"
24470,Benchmark cudnn version of grid sampler,2019-08-16 15:45:43+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
24468,[Tensorboard] Write summaries to S3 or GCS bucket,2019-08-16 15:24:05+00:00,,1,16,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: tensorboard"")]"
24463,Crashes on torch.cuda.memory_allocated(device),2019-08-16 11:28:27+00:00,,0,3,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
24456,Build PyTorch 1.2.0 occur `recipe for target bin/test_parallel' failed,2019-08-16 04:01:50+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
24432,Use a ScriptModule on GPU that was saved from CPU,2019-08-15 20:06:06+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""module: serialization""), Label(name=""triaged"")]"
24422,Label tracking meta-issue (edit me to get automatically CC'ed on issues! cc bot),2019-08-15 18:28:22+00:00,,0,36,"[Label(name=""triaged"")]"
24419,Building Python bits separate from C++ bits and making one play well with the other,2019-08-15 18:20:11+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement"")]"
24417,1.0rc0-6216 installs empty directories under include and duplicates under /,2019-08-15 17:59:52+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
24401,"When running model forward with large batch size, it reports the error: THCudaTensor sizes too large for THCDeviceTensor conversion",2019-08-15 10:52:58+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
24398,Significantly slower in latest version than in 0.4.0,2019-08-15 08:41:33+00:00,,0,10,"[Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
24397,SyncBatchNorm error when using model.eval() with DistributedDataParallel,2019-08-15 08:41:19+00:00,,0,6,"[Label(name=""needs reproduction""), Label(name=""oncall: distributed""), Label(name=""module: autograd""), Label(name=""triaged"")]"
24354,Default warning handler in C++ doesn't seem to unique warnings,2019-08-14 19:42:47+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
24353,Visual Studio Code not providing autosuggestions for submodules,2019-08-14 19:34:03+00:00,,0,3,"[Label(name=""triaged"")]"
24344,CI Standardization for Domain APIs,2019-08-14 18:12:13+00:00,,1,4,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""better-engineering"")]"
24343,Unified representation for enum types,2019-08-14 18:12:09+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
24338,Consider changing the behavior of Tensor.__contains__(Tensor) to make more sense,2019-08-14 16:59:03+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: ux"")]"
24336,Auto tuner takes too much time in serialized model,2019-08-14 16:55:11+00:00,,1,13,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
24313,Value_select to perform region-wise selection,2019-08-14 07:34:07+00:00,,0,0,"[Label(name=""triaged""), Label(name=""function request"")]"
24303,Port `masked_fill` operator from the TH code to Aten,2019-08-14 02:15:22+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: porting""), Label(name=""better-engineering"")]"
24273,Check PyTorch version when initializing process groups,2019-08-13 21:02:02+00:00,,0,1,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement"")]"
24264,"TensorIterator ""builder"" options should be documented.",2019-08-13 19:21:42+00:00,,1,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
24261,"""PyTorch core"" thread local flag",2019-08-13 18:51:21+00:00,,0,3,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""enhancement"")]"
24248,Loading custom Torchscript C++ operators in python segfaults due to ABI compatibility issue between pytorch and libtorch,2019-08-13 17:28:28+00:00,,1,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
24243,hasSideEffects INTERNAL ASSERT FAILED when using .split method with JIT,2019-08-13 16:31:39+00:00,,0,7,"[Label(name=""high priority""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
24236,Tensorboard: Add disable flag for debugging,2019-08-13 09:35:14+00:00,,0,2,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: tensorboard"")]"
24234,torch.utils.tensorboard.SummaryWriter fails to flush at program exit,2019-08-13 07:56:36+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
24229,Confusing error message for Custom Class type mismatch,2019-08-13 05:04:37+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
24225,Allow forward method to be defined with .define() in new TorchScript API,2019-08-13 03:13:22+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
24205,deprecate cuda arch 3.5/3.7 in nightlies,2019-08-12 22:19:59+00:00,,0,11,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
24193,TensorIterator stubs are designed for merge conflicts.,2019-08-12 18:21:19+00:00,,1,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
24188,Pin flake8 version in CI,2019-08-12 17:16:47+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
24185,[feature request] Subset of eigenvalues/eigenvectors ,2019-08-12 15:31:15+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""module: cpu""), Label(name=""triaged"")]"
24176,torch.fft crash when used with nn.DataParallel,2019-08-12 12:09:49+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
24168,torch.unique is inconsistent with NumPy's unique,2019-08-12 04:47:02+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: correctness (silent)"")]"
24167,Failed to build pytorch with NanoPi M4,2019-08-12 02:31:09+00:00,,0,3,"[Label(name=""module: build""), Label(name=""low priority""), Label(name=""triaged"")]"
24155,"""To compact weights again call flatten_parameters()"" is printed every step for every GPU",2019-08-11 05:52:46+00:00,,1,15,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
24145,sccache crashes when building `Distribution.cu` on Windows,2019-08-10 09:29:26+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: build warnings"")]"
24139,Allow incompatible shapes in load_state_dict(strict=False),2019-08-10 00:45:35+00:00,,0,7,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""enhancement"")]"
24130,[RPC] Add type annotations for RPC-related Python files,2019-08-09 21:40:15+00:00,,1,0,"[Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: rpc"")]"
24102,[JIT] script doesn't convert dtypes back to torch.dtype from long,2019-08-09 18:19:46+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
24090,`suggest_memory_format` has ambiguity & cannot represent intended layout format for corner cases,2019-08-09 17:04:14+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""triaged"")]"
24089,torch.nn.functional.grid_sample with 'circular' border conditions,2019-08-09 16:42:33+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
24081,Multi-gpu example freeze and is not killable,2019-08-09 13:27:51+00:00,,0,54,"[Label(name=""module: dependency bug""), Label(name=""module: multi-gpu""), Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: deadlock""), Label(name=""has workaround""), Label(name=""module: data parallel""), Label(name=""quansight-nack"")]"
24079,[Caffe2] build android in v1.1.0 with headfile error,2019-08-09 07:02:03+00:00,,0,2,"[Label(name=""caffe2""), Label(name=""triaged"")]"
24045,"torch.{save,load} data corruption when serializing a Module with __{get,set}state__",2019-08-08 22:09:49+00:00,,0,5,"[Label(name=""high priority""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
24041,tensor.var_mean variant for existing torch.var_mean (and same for std_mean),2019-08-08 21:56:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: reductions"")]"
24037,Tests do not pass with the latest protobuf,2019-08-08 21:39:31+00:00,,0,2,"[Label(name=""module: protobuf""), Label(name=""caffe2""), Label(name=""triaged"")]"
24031,fractional_max_pool2d_with_indices silently ignores output_ratio if output_size is provided,2019-08-08 20:29:22+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: pooling"")]"
24025,Refactor CircleCI config for version 2.1,2019-08-08 18:19:51+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""better-engineering"")]"
24016,Multiplying a very large CUDA tensor with another tensor yields unexpected result,2019-08-08 16:31:10+00:00,,0,9,"[Label(name=""module: dependency bug""), Label(name=""module: cuda""), Label(name=""triaged"")]"
24005,Using  `torch.utils.checkpoint.checkpoint_sequential` and `torch.autograd.grad` breaks when used in combination with `DistributedDataParallel`,2019-08-08 06:27:44+00:00,,1,32,"[Label(name=""oncall: distributed""), Label(name=""module: checkpoint""), Label(name=""feature""), Label(name=""triaged"")]"
23966,Error out during compilation if USE_FBGEMM=1 is ignored,2019-08-07 19:55:22+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: cpu""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""better-engineering"")]"
23958,[jit] Python @property's not supported in TorchScript,2019-08-07 18:25:32+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""quantization_release_1.3""), Label(name=""jit-backlog"")]"
23946,We should run clang-tidy on all of master,2019-08-07 15:48:59+00:00,,0,4,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""better-engineering"")]"
23940,Improve the performance of linear algebra operations in CUDA for small problem sizes,2019-08-07 12:16:02+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
23938,torch.nn.DataParallel causes incorrect gradients,2019-08-07 11:22:51+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: autograd""), Label(name=""triaged"")]"
23896,Remove USE_C10D flag,2019-08-06 20:48:04+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: build""), Label(name=""triaged"")]"
23890,[JIT] Can't use ndim in script,2019-08-06 19:53:28+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
23865,model->to(device) costs over a millisecond when doing nothing,2019-08-06 11:09:38+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged"")]"
23859,CUDA: THTensor code complains about devices not matching when creating tensor from blob,2019-08-06 05:36:18+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
23854,Fan out calculation broken for group (depthwise) convolution,2019-08-06 02:15:41+00:00,,1,5,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: initialization"")]"
23850,[quantization] jit::class_ for packed weights,2019-08-06 01:45:46+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""quantization_release_1.3""), Label(name=""jit-backlog"")]"
23849,Make MultiProcessTestCase pickable,2019-08-06 01:21:48+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
23787,Better version of chrome://tracing,2019-08-05 14:33:21+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""small"")]"
23780,Construction of MultivariateNormal much slower on GPU than CPU,2019-08-05 07:32:03+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: distributions""), Label(name=""module: cuda""), Label(name=""triaged"")]"
23771,SummaryWriter doesn't read comment if log_dir precised,2019-08-04 22:14:31+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
23768,Better documentation about PyTorch's dependencies,2019-08-04 13:30:53+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: third_party"")]"
23756,[feature request] Core API for invertible/inplace and flow-like ops + memory-saving (hookless?) reversible sequential container for RevNets to allow for much larger batch-sizes in academic setting,2019-08-03 14:02:58+00:00,,0,66,"[Label(name=""high priority""), Label(name=""module: distributions""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs design"")]"
23749,Wrong device in graph - Tensorboard SummaryWriter ,2019-08-02 21:31:06+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: tensorboard"")]"
23732,nn.Module.forward signature with **kwargs,2019-08-02 09:55:17+00:00,,0,5,"[Label(name=""module: checkpoint""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
23730,Failed to build pytorch ...,2019-08-02 09:25:46+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged"")]"
23721,Using PyTorch on AWS EFA network,2019-08-02 04:48:55+00:00,,0,1,"[Label(name=""module: dependency bug""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
23720,segmentation faults when using multiprocessing_context='spawn' with large number of processes,2019-08-02 04:46:05+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
23676,"Bogus ""Your compiler (clang++) is not compatible"" message",2019-08-01 19:53:15+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
23657,Accelerate PyTorch just-in-time compilation using MKL-DNN,2019-08-01 16:41:56+00:00,,4,15,"[Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
23655,TorchScript GPU Fuser Doesn't Handle In-Place Operations,2019-08-01 14:51:56+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
23547,model use dilated conv backward in v1.1.0 is ~3x slower than in v0.4.1 on 1080Ti ,2019-07-30 05:16:01+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
23540,Error from PyTorch when finalizing Python embedded in C++,2019-07-30 00:32:43+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: pybind"")]"
23525,MultiheadAttention output changes if input order is not exactly same,2019-07-29 21:05:16+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: nn""), Label(name=""triaged"")]"
23512,Build reconfiguration should consistently honor env variables,2019-07-29 18:17:01+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
23509,Enable PyTorch Bfloat16 for CPU and add MKL-DNN bfloat16 optimization for Cooper Lake,2019-07-29 17:03:59+00:00,,5,6,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
23490,upcoming PEP 554: how much effort we need to support sub-interpreter,2019-07-28 16:19:53+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged"")]"
23482,Build error due to unintended include path /usr/include,2019-07-27 20:50:21+00:00,,0,43,"[Label(name=""module: build""), Label(name=""triaged"")]"
23434,einsum equation with conditional mask works in numpy but not in PyTorch,2019-07-26 17:14:38+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: linear algebra""), Label(name=""function request"")]"
23430,[Feature request] Let DistributedSampler take a Sampler as input,2019-07-26 14:01:32+00:00,,0,21,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""has workaround"")]"
23429,Unreachable code in tanh,2019-07-26 12:35:34+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
23425,Hanging on when one gpu node return zero as loss in the context of distributed data parallel training,2019-07-26 10:09:21+00:00,,0,11,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
23382,Tensor from mmaped storage loads the entire file into memory,2019-07-25 17:24:04+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
23364,dyndep function not working ,2019-07-25 03:31:47+00:00,,0,0,"[Label(name=""caffe2"")]"
23355,[jit] add named tuple as output type to the tracer,2019-07-25 00:46:28+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
23342,QNNpack tests should be skipped on ppc64le (not enabled there),2019-07-24 21:36:41+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
23305,make torch.utils._download_url_from_file public and add a docstring,2019-07-24 15:30:37+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: hub""), Label(name=""module: ux"")]"
23301,Error while using Libtorch + OpenCV + Qt Creator,2019-07-24 13:51:08+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
23299,Add gatherv/allgatherv primitives to support non-equal contribution,2019-07-24 09:30:26+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: bootcamp""), Label(name=""feature""), Label(name=""triaged"")]"
23240,UBSAN failure in test_simple_model (__main__.TestTensorBoardNumpy): runtime error: call to function pybind11::class_<caffe2::GradientWrapper>::dealloc(pybind11::detail::value_and_holder&) through pointer to incorrect function type 'void (*)(pybind11::detail::value_and_holder &)',2019-07-23 17:49:34+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
23233,"Unofficial ARMv6, ARMv7, ARMv8 builds",2019-07-23 16:35:47+00:00,,0,21,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""triaged"")]"
23230,Consolidate multiprocessing helpers in distributed tests,2019-07-23 15:05:54+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
23217,Libtorch with deeplabv3_resnet101 will not forward.,2019-07-23 06:32:45+00:00,,0,14,"[Label(name=""module: crash""), Label(name=""module: cpp""), Label(name=""triaged"")]"
23159,"Can't `torch.sum(tensor, dim)` where `dim >= 64`",2019-07-22 13:31:52+00:00,,1,1,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: TensorIterator""), Label(name=""module: reductions"")]"
23151,Deterministic mode for scatter_add operation,2019-07-22 04:51:45+00:00,,1,1,"[Label(name=""triaged""), Label(name=""module: determinism""), Label(name=""function request""), Label(name=""module: scatter & gather ops"")]"
23110,[RFC] RPC Based Distributed Model Parallel,2019-07-19 21:33:47+00:00,,0,21,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: rpc"")]"
23103,Test utility for non-contiguous tensors,2019-07-19 20:02:54+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""enhancement"")]"
23094,Versioning for libtorch nightlies,2019-07-19 18:46:46+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""better-engineering"")]"
23079,update docs that sorting is not needed in ,2019-07-19 15:25:25+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: rnn""), Label(name=""triaged"")]"
23072,Inconsistent axis argument names in torch.diagonal and torch.transpose,2019-07-19 13:36:34+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""low priority""), Label(name=""triaged"")]"
23068,[c++] torch::conv2d() expected output_padding to be a single integer value or a list of 3 values ,2019-07-19 10:15:05+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""low priority""), Label(name=""module: convolution""), Label(name=""triaged"")]"
23067,creation of a tensor from a numba.cuda array,2019-07-19 10:10:24+00:00,,0,4,"[Label(name=""feature""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: numba"")]"
23061,The speed of `torch.einsum` and `torch.matmul` when using `fp16` is slow,2019-07-19 06:25:28+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
23054,ConcatDataset returns different error messages setting out of range plus index and minus index.,2019-07-19 02:57:09+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""low priority""), Label(name=""triaged"")]"
23048,Add automatic tuning flags to utils.data.dataloader,2019-07-18 23:21:48+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""low priority""), Label(name=""triaged"")]"
23032,Proposal: Optional AutogradMeta for Variable,2019-07-18 19:26:09+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
23026,BatchNorm1d fails on first run through GPU,2019-07-18 17:20:19+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
22961,performance much worse on 2080ti than 1080ti,2019-07-17 08:00:22+00:00,,0,37,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
22954,Support serializing IValue to bytes (and deserialize from bytes),2019-07-17 02:05:41+00:00,,0,10,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
22924,[data loader] Graceful data loader threads exit on KeyboardInterrupt,2019-07-16 20:14:52+00:00,,0,10,"[Label(name=""needs reproduction""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
22919,Unify tensor shape formatting in shape checks,2019-07-16 19:32:40+00:00,,0,4,"[Label(name=""module: error checking""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement"")]"
22911,JIT trace parameter sharing error if Module attributes happen to be the same,2019-07-16 16:21:37+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
22879,Difference between dropout2d and dropout3d,2019-07-15 20:28:54+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
22868,Make it easier to bisect on PyTorch,2019-07-15 17:30:51+00:00,,0,2,"[Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""better-engineering"")]"
22859,CRITICAL:root:Cannot load caffe2.python. Error: DLL load failed: The specified module could not be found.,2019-07-15 09:46:17+00:00,,0,13,"[Label(name=""caffe2"")]"
22848,[feature request] Log-determinant for symmetric positive definite matrices,2019-07-14 15:10:11+00:00,,0,17,"[Label(name=""triaged""), Label(name=""has workaround""), Label(name=""module: linear algebra""), Label(name=""function request"")]"
22815,TensorImpl de-virtualization,2019-07-12 19:12:40+00:00,,0,11,"[Label(name=""high priority""), Label(name=""module: dependency bug""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
22803,Port `fmod` operator from the TH code to Aten,2019-07-12 15:55:55+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: porting""), Label(name=""better-engineering"")]"
22791,How to use mpi backend without CUDA_aware,2019-07-12 08:09:15+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: mpi"")]"
22788,Pytorch deadlock from distributed multiprocessing,2019-07-12 05:54:23+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
22785,Getting cuda runtime error (48) with Jetson TX2 when running simple program,2019-07-12 02:12:06+00:00,,0,2,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
22778,In-place updating the original value tensor should also update version counter of sparse tensor's values_ tensor,2019-07-11 22:57:03+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""module: autograd""), Label(name=""triaged"")]"
22766,assert_no_internal_overlap should pass const char*,2019-07-11 21:10:19+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
22755,[RFC] InstanceNorm default affine value,2019-07-11 18:41:37+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
22707,torch.fill_() exists and modifies the input tensor: Expected or bug?,2019-07-10 21:59:18+00:00,,0,9,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: ux"")]"
22687,DispatchStub should report what operator it failed to find kernel for,2019-07-10 15:56:18+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""module: cpu""), Label(name=""triaged"")]"
22682,CMAKE_PARSE_IMPLICIT_LINK_INFO Function invoked with incorrect arguments,2019-07-10 13:50:43+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""has workaround"")]"
22671,The training always freezes after some epochs.,2019-07-10 04:00:14+00:00,,0,18,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: deadlock"")]"
22669,BFloat16 numeric limits should contain more info,2019-07-10 00:56:41+00:00,,1,0,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: bfloat16"")]"
22609,caffe_translator TranslateCrop fails when more than one dimensions is cropped,2019-07-09 04:42:11+00:00,,0,0,"[Label(name=""caffe2"")]"
22604,"""CrossEntropyLoss"" should mention in its name that it takes softmax for target",2019-07-09 00:27:27+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
22597,Autograd profiler memory leak when use_cuda=True,2019-07-08 21:04:34+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: autograd""), Label(name=""triaged"")]"
22585,[dataloader] Mysterious error when using spawn start_method ,2019-07-08 12:26:42+00:00,,0,4,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
22580,Pytorch compilation error on Mac OS,2019-07-08 02:02:07+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
22578,torch.gels runs 100 time slower on gpu than on cpu,2019-07-07 21:31:39+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""triaged"")]"
22577,Double backward 3 times slower for conv2d with padding = 1,2019-07-07 19:56:35+00:00,,0,14,"[Label(name=""module: dependency bug""), Label(name=""module: performance""), Label(name=""module: double backwards""), Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""has workaround""), Label(name=""quansight-nack"")]"
22573,Batched symeig and qr are very slow on GPU,2019-07-07 13:18:26+00:00,,0,15,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
22557,CPU torch.exponential_ function may generate 0 which can cause downstream NaN,2019-07-05 20:07:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: random"")]"
22550,Eigen Tensor library for convolutions on CPU,2019-07-05 15:14:30+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: arm""), Label(name=""function request"")]"
22541,make[2]: *** No rule to make target 'libtorch/lib/libc10.so',2019-07-04 17:51:38+00:00,,0,5,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
22536,libtorch new op,2019-07-04 10:01:10+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""module: custom-operators"")]"
22532,Know which function is used by conv and force to use a function,2019-07-04 08:40:46+00:00,,0,8,"[Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
22513,No assertion when using scatter_ on a non-contiguous tensor,2019-07-03 22:11:41+00:00,,0,5,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: partial aliasing""), Label(name=""module: scatter & gather ops"")]"
22495,`binary_linux_libtorch_2.7m_cu100_devtoolset3_build` times out after running for 5 hours,2019-07-03 18:03:32+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""better-engineering"")]"
22494,Error in equation,2019-07-03 17:58:52+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
22487,"""Floating point exception"" after trying the method from the issue #22382",2019-07-03 09:56:06+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
22455,"Move csrc/distributed/c10d/{comm,reducer} to libtorch.so",2019-07-02 17:39:28+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
22454,Tracing an RNN does not support torch.nn.utils.rnn.PackedSequence as input,2019-07-02 16:31:00+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
22447,Weak Symbols Resolution Causes Segmentation Fault in External Libraries,2019-07-02 12:16:09+00:00,,0,3,"[Label(name=""triaged"")]"
22415,Add support for serializing Mkldnn Tensor,2019-07-01 22:01:07+00:00,,0,2,"[Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
22414,CPU random number generator is slow,2019-07-01 21:43:34+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: random"")]"
22406,Build failure with setup.py,2019-07-01 20:40:50+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
22402,PyTorch Tensor subclasses and protocols for NumPy interoperability,2019-07-01 19:29:23+00:00,,1,26,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
22400,Sparse allreduce for ProcessGroupNCCL,2019-07-01 17:49:35+00:00,,1,5,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
22383,Storage operation failing on second GPU,2019-06-30 22:31:26+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
22378,scatter_ supporting different reduction modes,2019-06-30 06:14:30+00:00,,0,37,"[Label(name=""high priority""), Label(name=""module: sparse""), Label(name=""module: internals""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: scatter & gather ops"")]"
22375,Label.dim Enforcement Check in AccuracyOp,2019-06-29 22:15:24+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
22370,returned non-zero exit status 2.,2019-06-29 11:53:12+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
22358,"When I run python setup.py install to install Caffe2, I have an error: ""No such file or directory: 'nvcc': 'nvcc'""",2019-06-28 22:59:49+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
22343,New Weight Scheduler Concept for Weight Decay,2019-06-28 16:36:20+00:00,,0,6,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
22340,Reducer bucketing based on autograd profile ,2019-06-28 14:03:57+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
22338,Illegal instruction (core dumped) when running in qemu,2019-06-28 13:53:30+00:00,,0,19,"[Label(name=""high priority""), Label(name=""module: crash""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: vectorization"")]"
22331,Integer division by Zero giving large number results instead of NaN/inf on Windows,2019-06-28 04:10:49+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged"")]"
22330,Training CNNs with deconvolution,2019-06-28 03:32:49+00:00,,0,5,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: vision""), Label(name=""function request"")]"
22281,Box constraints for optimizers,2019-06-26 21:48:53+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged"")]"
22277,Handle all IntArrayRef expansions in ATen,2019-06-26 20:26:08+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
22274,second derivatives of unfold,2019-06-26 19:57:52+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: derivatives"")]"
22259,using multi thread lead to gpu stuck with GPU-util 100%,2019-06-26 11:18:51+00:00,,0,36,"[Label(name=""high priority""), Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
22252,[libtorch] header warning suppression,2019-06-26 06:15:06+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: build warnings"")]"
22232,[FYI] Introducing Quantized Tensor,2019-06-25 21:28:10+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
22220,[doc] nn.Module.forward documentation unclear,2019-06-25 19:18:34+00:00,,0,6,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
22169,[RFC] NestedTensor - 0.0.1,2019-06-24 23:48:43+00:00,,0,44,"[Label(name=""triaged""), Label(name=""module: batching"")]"
22155,[jit] Optional type refinement on non-named expressions,2019-06-24 19:13:35+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""TSRootCause:TypeRefinement""), Label(name=""TSUsability"")]"
22136,[dataloader] SIGCHLD handler should poll the queue for exception first,2019-06-24 16:13:22+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
22128,Automatic rank selection when using file:// initialization method,2019-06-24 09:26:01+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""enhancement"")]"
22122,ASSERT FAILED at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:12721,2019-06-23 19:37:35+00:00,,1,3,"[Label(name=""triaged""), Label(name=""module: assert failure"")]"
22083,Pytorch is slower on windows than on linux,2019-06-21 19:28:51+00:00,,0,9,"[Label(name=""module: windows""), Label(name=""feature""), Label(name=""triaged"")]"
22070,[ONNX] BUG for Upsample operator export re-used by caffe2,2019-06-21 11:31:09+00:00,,0,1,"[Label(name=""caffe2"")]"
22049,Cannot update part of the parameters in DistributedDataParallel.,2019-06-20 23:06:50+00:00,,0,14,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
22040,SigAbort while running the Caffe2 unit test - thread_init_test - built on Clang7 +glibc 2.23,2019-06-20 21:05:37+00:00,,0,1,"[Label(name=""caffe2"")]"
22035,Have a different way to check if gradient was computed in the optimizer (not checking for None),2019-06-20 19:33:24+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
22024,Consolidate definition of operators/gradients where possible,2019-06-20 17:01:53+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""better-engineering"")]"
22022,nn.modules.functional.h does not support optional arguments,2019-06-20 14:52:37+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged"")]"
22013,Mysterious Tensor Indexing Problem,2019-06-20 06:13:38+00:00,,0,8,"[Label(name=""high priority""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing""), Label(name=""module: ux"")]"
21956,nn.init.orthogonal_ doesn't work with multiprocessing,2019-06-19 05:55:38+00:00,,0,18,"[Label(name=""module: dependency bug""), Label(name=""module: multiprocessing""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: initialization"")]"
21902,contradictory output values,2019-06-18 10:18:28+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
21899,Crash when using tensor.set_data() function in libtorch on windows,2019-06-18 07:24:52+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
21876,nn.TransformerLayer,2019-06-17 22:02:34+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
21856,Batch Normalization axis,2019-06-17 12:44:14+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: batching""), Label(name=""function request""), Label(name=""module: norms and normalization"")]"
21847,Logging mode for saying when tensor broadcast occurs,2019-06-16 18:36:06+00:00,,0,2,"[Label(name=""module: internals""), Label(name=""feature""), Label(name=""module: molly-guard""), Label(name=""triaged"")]"
21843,[Caffe2/ONNX] ONNX LSTM Loading,2019-06-16 09:44:14+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
21828,torch::zeros is slow for small tensors (C++),2019-06-15 18:44:56+00:00,,1,11,"[Label(name=""module: performance""), Label(name=""module: cpp""), Label(name=""triaged"")]"
21824,How about add torch::end for slicing in c++ frontend,2019-06-15 16:12:06+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""feature""), Label(name=""triaged"")]"
21818,C++ ABI - Coupling different libraries issue,2019-06-15 06:49:07+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged"")]"
21794,Linker errors when building project with OpenCV,2019-06-14 18:05:56+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
21780,cumsum cuda numerical instability,2019-06-14 14:58:28+00:00,,0,2,"[Label(name=""module: numerical-stability""), Label(name=""module: cuda""), Label(name=""triaged"")]"
21779,"Use of word ""elements"" in `torch.utils.data` samplers",2019-06-14 13:51:54+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
21777,typo and missing return statements,2019-06-14 09:53:48+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
21766,Missing header files for prebuilt libtorch,2019-06-14 00:46:55+00:00,,0,2,"[Label(name=""caffe2"")]"
21760,[FR] faster reduce sum on expanded/unfolded tensors,2019-06-13 22:59:08+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""function request"")]"
21745,torch.save also saves docstrings into pickle for some reason,2019-06-13 17:41:57+00:00,,0,14,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
21738,symbol lookup error: libmkl_intel_lp64.so: undefined  symbol: mkl_blas_dsyrk (binaries built with static linking -DBUILD_SHARED_LIBS=OFF fail due to dynamic linker problem),2019-06-13 16:00:15+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: static linking""), Label(name=""module: third_party""), Label(name=""has workaround"")]"
21731,Improve multithreaded random number generation (RNG),2019-06-13 13:17:02+00:00,,0,2,"[Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: random""), Label(name=""module: multithreading"")]"
21700,(LLD 8.0.0) ld: error: can't create dynamic relocation R_X86_64_DTPOFF32 against symbol: ideep::utils::computation_cache,2019-06-12 20:35:23+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: static linking""), Label(name=""module: mkldnn"")]"
21688,Batched Conv2d for sequence data,2019-06-12 16:28:50+00:00,,0,3,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: batching""), Label(name=""function request"")]"
21684,The cuda problem in caffe2,2019-06-12 14:41:10+00:00,,0,1,"[Label(name=""caffe2"")]"
21682,C++ module API footgun: assigning to parameter doesn't update `parameters()` list,2019-06-12 13:42:10+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
21673,[FR] Diagonal Transform for Distributions,2019-06-12 06:18:01+00:00,,0,3,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
21645,Batch Dataloader and Dataset,2019-06-11 18:35:25+00:00,,0,12,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
21602,Strange latency overhead of F.conv2d,2019-06-10 20:16:05+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
21587,RuntimeError: cublas runtime error ,2019-06-10 13:43:19+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
21567,torch.bernoulli's parameter generator not documented,2019-06-08 17:14:06+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: random"")]"
21554,Pytorch hangs when dataloader multiprocessing workers are killed,2019-06-08 00:49:55+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
21553,Feature Request: beta cdf,2019-06-08 00:37:05+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
21544,"[jit] In pickler, don't memoize if not necessary",2019-06-07 21:43:51+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
21518,`attn_mask` in nn.MultiheadAttention is additive,2019-06-07 13:35:35+00:00,,1,8,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""oncall: transformer/mha"")]"
21477,Not obvious how to install torchvision with PyTorch source build,2019-06-06 18:04:12+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: vision"")]"
21467,No continuous integration coverage for Python 2 CUDA,2019-06-06 14:36:31+00:00,,0,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
21462,"Slow convolution with large kernels, should be using FFT",2019-06-06 13:57:02+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: fft"")]"
21459,RuntimeError: cublas runtime error ,2019-06-06 12:18:45+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: cublas"")]"
21457,downsampling with grid_sample doesn't match interpolate,2019-06-06 11:46:04+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: interpolation"")]"
21454,[JIT] Memory Leak during tracing?,2019-06-06 09:57:57+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
21442,[JIT] kwarg with default doesn't work for class instantiation,2019-06-06 00:24:50+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
21411,Implementation of Group equivariant convolutions,2019-06-05 13:12:52+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""low priority""), Label(name=""triaged"")]"
21405,how libtorch can work with  tensor data as same as  pytorch,2019-06-05 09:49:17+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""low priority""), Label(name=""triaged"")]"
21399,collect_env ignores conda environment,2019-06-05 04:53:56+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: docs""), Label(name=""low priority""), Label(name=""module: collect_env.py""), Label(name=""triaged"")]"
21318,"Undefined symbols for architecture x86_64: ""testing::internal::UntypedFunctionMockerBase::UntypedInvokeWith(void const*)"" on Mac OS X",2019-06-04 00:07:32+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: internals""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""module: macos"")]"
21290,"Title of docs page includes ""PyTorch master documentation"" even for non-master branches.",2019-06-03 16:59:19+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
21277,[caffe2] check Range Operator inputs with bug,2019-06-03 10:15:27+00:00,,0,1,"[Label(name=""caffe2"")]"
21275,weight_norm is not supported in TorchScript,2019-06-03 07:23:06+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
21255,IsType<T>() ASSERT FAILED [Detectron e2e_mask_rcnn_R-50-C4_1x.yaml],2019-06-01 20:46:09+00:00,,0,1,"[Label(name=""caffe2""), Label(name=""module: assert failure"")]"
21179,Failed to install pytorch from source on ubuntu.,2019-05-30 23:20:42+00:00,,0,4,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
21176,Adding a method called `T` in native_functions causes undefined behavior on Windows,2019-05-30 22:28:47+00:00,,0,7,"[Label(name=""module: windows""), Label(name=""triaged"")]"
21165,Getting Access to Blob/Tensor reference in jit::script::Module,2019-05-30 20:16:21+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
21144,Data Parallel Implementation Improvements,2019-05-30 15:09:02+00:00,,1,1,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
21135,[cmake build] can't build pytorch with install mkl library ,2019-05-30 07:32:31+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
21120,[RFC] Adding MKL-DNN Int8 functions to PyTorch/Aten/JIT backend,2019-05-30 05:08:47+00:00,,1,5,"[Label(name=""oncall: jit""), Label(name=""oncall: quantization""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
21064,[JIT] Expose subgraph execution for intermediate output extraction,2019-05-29 15:04:15+00:00,,0,9,"[Label(name=""oncall: jit""), Label(name=""enhancement""), Label(name=""TSUsability""), Label(name=""TSRootCause:PoorIRVisibility"")]"
21061,Misleading Error when doing Large Batch Matrix Multiplication,2019-05-29 12:11:46+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
21050,output values not same and much slower than Python API,2019-05-29 01:49:11+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
21028,Zero-dim Tensors (scalars) should be printed at full precision,2019-05-28 18:42:31+00:00,,0,4,"[Label(name=""module: printing""), Label(name=""triaged"")]"
21018,free(): invalid pointer Aborted (core dumped),2019-05-28 14:18:38+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""triaged"")]"
21017,"Stop using ""AAA"" prefix for builds",2019-05-28 13:25:30+00:00,,0,3,"[Label(name=""module: ci""), Label(name=""triaged"")]"
21016,[utils.bottleneck] throws initialization error for cuda profiling,2019-05-28 13:00:58+00:00,,0,8,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
21015,How to use Infiniband for cpu-cluster with backend gloo?,2019-05-28 11:41:53+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
21012,"Error when creating new caffe2::Predictor(_initNet, _predictNet)",2019-05-28 08:20:30+00:00,,0,0,"[Label(name=""caffe2"")]"
20997,ReduceLROnPlateau will fail when add new parameter group to the optimizer,2019-05-28 01:33:31+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
20975,"build caffe2 operators failed, 'sorry, unimplemented: non-trivial designated initializers not supported'",2019-05-27 03:07:39+00:00,,0,0,"[Label(name=""caffe2"")]"
20967,Track running stats regardless of track_running_stats=False,2019-05-26 14:59:54+00:00,,0,10,"[Label(name=""module: nn""), Label(name=""triaged"")]"
20963,official libtorch static build zip file error,2019-05-26 06:36:35+00:00,,0,2,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
20935,torch.full_like missing documentation for out input variable,2019-05-24 21:14:34+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
20864,Import warning when using the wrong version of CUDA,2019-05-23 16:05:30+00:00,,0,3,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
20858,convert Onnx Slice operator to caffe2 failed,2019-05-23 09:11:49+00:00,,0,1,"[Label(name=""caffe2""), Label(name=""triaged"")]"
20822,"[Proposal] Data reading framework for PyTorch (Hive, MySQL, S3 etc.) ",2019-05-22 19:36:25+00:00,,1,45,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""needs research"")]"
20805,LibTorch :About torch.jit.trace generate model.pt,2019-05-22 11:11:10+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""triaged"")]"
20777,"Caffe2: operator_test/instance_norm_test.py::TestInstanceNorm::test_instance_norm_gradients test case fails with ""RuntimeError: dim() called on undefined TensorError from operator""",2019-05-21 21:44:07+00:00,,0,0,"[Label(name=""caffe2"")]"
20776,Caffe2: executor_test.py::ExecutorGPUResNetTest fails with an AssertionError,2019-05-21 21:32:10+00:00,,0,0,"[Label(name=""caffe2"")]"
20769,[JIT] Better Python String Support,2019-05-21 18:36:17+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""jit-backlog"")]"
20753,cmake for Torch unusable in archlinux,2019-05-21 12:49:29+00:00,,0,2,"[Label(name=""module: dependency bug""), Label(name=""module: build""), Label(name=""triaged"")]"
20748,Segmentation fault when use torch::from_blob,2019-05-21 08:09:28+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""module: cpp""), Label(name=""module: abi""), Label(name=""triaged"")]"
20734,[jit] set up views for Autodiff and autograd hooks ,2019-05-20 23:08:58+00:00,,0,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
20704,Remove unpack() in torch/csrc/nn/type_checks.h and its caller functions in the codebase,2019-05-20 16:34:38+00:00,,0,7,"[Label(name=""module: internals""), Label(name=""module: nn""), Label(name=""good first issue""), Label(name=""triaged"")]"
20686,In-source build causes repeating filename annotations (Windows doesn't support out-of-source build),2019-05-19 03:07:09+00:00,,1,23,"[Label(name=""module: build""), Label(name=""module: windows""), Label(name=""triaged"")]"
20682,[distribution] Support for various domain for AffineTransform,2019-05-18 14:49:12+00:00,,0,4,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
20664,[JIT] List python builtin has wrong casting behavior,2019-05-17 22:43:32+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
20655,nn.Embedding backwards slow under high row contention,2019-05-17 19:13:30+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
20641,Main page broadcasting (?) example image bug,2019-05-17 11:57:15+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
20629,profiler seems not print all op calls,2019-05-17 06:45:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
20613,groupby function,2019-05-16 22:34:16+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
20591,@ignore annotation for user defined type,2019-05-16 16:55:45+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
20576,NVRTC_ERROR unknown when using self-built libtorch,2019-05-16 06:57:47+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
20562,Performance issue when accessing an extremely large (10GB) longtensor,2019-05-15 22:54:57+00:00,,1,3,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
20551,torch.norm produces incorrect results,2019-05-15 21:28:51+00:00,,0,8,"[Label(name=""triaged""), Label(name=""module: numerical-reproducibility""), Label(name=""module: norms and normalization"")]"
20531,c++ torch::nn::Sequential increments count on name errors,2019-05-15 14:43:41+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
20497,Statically make `__setstate__` set all attributes/parameters ,2019-05-14 19:07:32+00:00,,0,4,"[Label(name=""high priority""), Label(name=""module: serialization""), Label(name=""triaged"")]"
20488,RoiAlignTest.CheckCPUGPUEqual is still flaky,2019-05-14 15:05:25+00:00,,0,1,"[Label(name=""caffe2""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""better-engineering"")]"
20481,[docs] Automatically detect docs missing in rst,2019-05-14 08:50:32+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""enhancement"")]"
20466,Lint rule to prevent direct use of #pragma omp,2019-05-14 00:52:28+00:00,,0,2,"[Label(name=""module: lint""), Label(name=""triaged"")]"
20433,Dataloader's memory usage keeps increasing during one single epoch.,2019-05-13 15:09:37+00:00,,1,5,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
20424,pos_weight argument in torch.nn.BCELoss,2019-05-13 12:55:38+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
20416,Class based Sampler for Class Incremental/Continual Learning research,2019-05-13 00:43:02+00:00,,0,7,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
20412,String in tensor,2019-05-12 16:21:20+00:00,,0,2,"[Label(name=""module: internals""), Label(name=""triaged"")]"
20405,CosineAnnealingLR has unexpected behavior with large step,2019-05-12 02:55:07+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
20375,Better documentation / molly-guards around use of multiprocessing with spawn in Jupyter/ipython notebooks,2019-05-10 18:23:26+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
20367,Overhead performance regression over time umbrella issue.,2019-05-10 16:12:20+00:00,,0,0,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""module: internals""), Label(name=""module: cuda""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
20363,"Define portable M_PI replacement, use it instead of non-standard M_PI in math.h",2019-05-10 13:57:33+00:00,,0,4,"[Label(name=""module: internals""), Label(name=""triaged"")]"
20359,[feature request] Run examples from docs as tests,2019-05-10 12:16:33+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""feature""), Label(name=""triaged"")]"
20343,torch.distributions.Binomial.sample() uses a massive amount of memory,2019-05-10 00:28:15+00:00,,0,13,"[Label(name=""module: distributions""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
20342,TensorIterator resizes output to a scalar if there are no inputs,2019-05-10 00:10:32+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
20323,Support size to `torch.normal`,2019-05-09 14:56:03+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
20315,libtorch+opencv Mat result error: different from the python ones,2019-05-09 11:46:24+00:00,,0,2,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
20273,Linker errors when linking statically (avx perfkernels) [Caffe2],2019-05-08 14:26:39+00:00,,1,4,"[Label(name=""caffe2"")]"
20272,Redundantly saving sizes of SavedVariables in autograd Function,2019-05-08 14:06:56+00:00,,0,2,"[Label(name=""module: bootcamp""), Label(name=""module: autograd""), Label(name=""low priority""), Label(name=""triaged"")]"
20268,[Caffe2] Convert caffe to caffe2 with solverstate,2019-05-08 11:35:21+00:00,,0,0,"[Label(name=""caffe2"")]"
20248,Sparse tensors can't be used in DataLoader running many workers,2019-05-07 22:33:43+00:00,,0,11,"[Label(name=""module: sparse""), Label(name=""module: multiprocessing""), Label(name=""feature""), Label(name=""triaged"")]"
20245,ProcessGroupMPI tests in test_c10d.py,2019-05-07 20:24:08+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged"")]"
20230,[jit] torch.tensor doesn't support list of tuples,2019-05-07 18:10:08+00:00,,1,1,"[Label(name=""oncall: jit""), Label(name=""low priority""), Label(name=""triaged"")]"
20206,Failed to build with system protobuf,2019-05-07 12:43:06+00:00,,0,8,"[Label(name=""module: build""), Label(name=""module: protobuf""), Label(name=""triaged"")]"
20204,"SyncBatchNorm should support 2D input (B, C)",2019-05-07 10:03:39+00:00,,0,8,"[Label(name=""oncall: distributed""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
20189,Unify Caffe2 and PyTorch OpenMP initialization,2019-05-06 23:12:28+00:00,,1,0,"[Label(name=""triaged""), Label(name=""module: multithreading"")]"
20183,Latex Errors when Compiling documentation to latexpdf,2019-05-06 21:59:45+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
20165,torch.nn.threshold cannot accept tensor as a threshold,2019-05-06 16:18:13+00:00,,0,12,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
20154,"convert the model from pytorch to onnx to caffe2, but get a lower accuracy than before",2019-05-06 08:14:10+00:00,,0,2,"[Label(name=""caffe2""), Label(name=""triaged"")]"
20151,RuntimeError: Given input size: (2048x1x1). Calculated output size: (2048x-5x-5). Output size is too small at /pytorch/aten/src/THNN/generic/SpatialAveragePooling.c:48,2019-05-06 05:48:24+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: tensorboard""), Label(name=""has workaround"")]"
20149,Advanced indexing with uint8 tensor versus int64 tensor is inconsistent,2019-05-06 04:33:39+00:00,,0,4,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: advanced indexing""), Label(name=""module: boolean tensor"")]"
20138,Inconsistant values of lr_scheduler.get_lr and lr in optimizer.param_groups,2019-05-05 09:13:24+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
20134,"ERROR: Command ""python setup.py egg_info"" when dockerfile build",2019-05-05 04:00:55+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged"")]"
20119,[JIT] Source highlighting doesn't line up when tabs are used for indentation,2019-05-04 00:10:36+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""jit-backlog"")]"
20117,[FR] [RFC] add Sequential.append & .extend,2019-05-03 22:17:40+00:00,,0,11,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
20111,Split libtorch binary build CI job into separate variants,2019-05-03 20:46:41+00:00,,1,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
20102,LSTM forget bias must be initialized properly,2019-05-03 14:31:09+00:00,,0,6,"[Label(name=""module: bc-breaking""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: initialization"")]"
20086,CosineAnnealingLR giving unexpected learning rates on PyTorch 1.1.,2019-05-02 22:50:33+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
20066,Change devtoolset7 CUDA 9.0 nightlies to use a lower devtoolset,2019-05-02 16:27:53+00:00,,1,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
20058,Implement noise_shape keyword for Dropout layers,2019-05-02 12:11:20+00:00,,0,7,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
20056,Creation of too big multidimensional array returns empty tensor.,2019-05-02 08:38:45+00:00,,0,19,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
20022,Precision of sparse float embeddings differs from dense embeddings on CPU,2019-05-01 18:01:51+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
20006,"RuntimeError: invalid argument 10: ldb should be at least max(1, 0), but have 0 at ../aten/src/TH/generic/THBlas.cpp:36",2019-05-01 11:52:32+00:00,,0,6,"[Label(name=""module: internals""), Label(name=""triaged"")]"
20005,install error from source,2019-05-01 11:31:32+00:00,,0,10,"[Label(name=""proposal accepted""), Label(name=""module: internals""), Label(name=""triaged"")]"
19978,[JIT] traced model with optimization shows no performance improvement,2019-04-30 22:17:45+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
19960,"On first construction, CUDAContext changes default CPU allocator behavior",2019-04-30 11:21:02+00:00,,0,0,"[Label(name=""caffe2"")]"
19953,Performance difference between 0.4.1 and 1.1.0,2019-04-30 08:27:07+00:00,,0,8,"[Label(name=""module: performance""), Label(name=""triaged"")]"
19930,caffe2/resnet50 assert in fetch_blob() when base_learning_rate = 0,2019-04-29 21:28:47+00:00,,0,0,"[Label(name=""caffe2"")]"
19911,"BatchNorm1d does not support batchsize>65535 in eval mode with 3 dimension (NxCxL), raise CUDNN_STATUS_NOT_SUPPORTED",2019-04-29 10:04:08+00:00,,0,10,"[Label(name=""module: dependency bug""), Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""small"")]"
19826,vectorized convert_to_int_of_same_size <int64_t> can't handle nan,2019-04-27 20:17:25+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
19825,Performance issue master (a25b79531),2019-04-27 20:01:03+00:00,,1,11,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
19739,Importing open3d after PyTorch causes free(): invalid pointer,2019-04-25 12:33:53+00:00,,0,21,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: pybind"")]"
19708,Test failure for depthwise3x3_conv,2019-04-25 01:27:17+00:00,,0,0,"[Label(name=""caffe2"")]"
19685,Bad overload order for zeros_like,2019-04-24 18:33:22+00:00,,0,5,"[Label(name=""triaged""), Label(name=""module: pybind""), Label(name=""module: tensor creation"")]"
19682,View in Sequential - reasoned case for it,2019-04-24 18:09:39+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
19672,torch.set_flush_denormal not working on some (old) OSX machines,2019-04-24 15:05:01+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: macos"")]"
19668,Importing matlab.engine after torch causes bad_alloc,2019-04-24 10:46:16+00:00,,0,5,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
19652,[docs] torch.set_flush_denormal(...) to mention default mode,2019-04-24 02:00:44+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
19637,"[jit] Traced {zeros,empty}()/{zeros,empty}_like() calls do not respect device args.",2019-04-23 22:11:16+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
19628,[jit] nn.LSTM errors in nn.ScriptModule,2019-04-23 19:56:28+00:00,,0,3,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
19599,cudnn conv doesn't check batch_size > 0,2019-04-23 02:32:40+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
19581,[jit] Do aten::values dispatch at build time instead of runtime,2019-04-22 21:31:12+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
19571,[doc] Document general guidelines to work with CUDA async copying and streams,2019-04-22 19:13:08+00:00,,0,4,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""better-engineering"")]"
19563,why my personal compiled libtorch is so slow?  2~3 times slower than caffe,2019-04-22 13:33:09+00:00,,0,13,"[Label(name=""module: performance""), Label(name=""module: windows""), Label(name=""triaged"")]"
19529,failed to load model which is saved as text format(pickle_protocol=0) instead of binary format,2019-04-20 01:06:00+00:00,,0,1,"[Label(name=""module: pickle""), Label(name=""module: serialization""), Label(name=""triaged"")]"
19504,[jit] Bad error when calling `ScriptModule`s with attributes/parameters,2019-04-19 19:19:04+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
19499,C++ API 'nn::Sequential' has inconsistent behavior with python conterpart,2019-04-19 17:46:30+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
19453,How to load PyTorch model with LSTM using C++ api,2019-04-19 02:11:06+00:00,,1,26,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
19437,The `unary_kernel` call should be pushed into CopyKernel.cpp and it should completely replace the current `copy_kernel`.,2019-04-18 21:53:59+00:00,,1,0,"[Label(name=""module: cpu""), Label(name=""triaged"")]"
19416,[caffe2]Reloading model gives segmentation fault,2019-04-18 18:20:00+00:00,,0,0,"[Label(name=""caffe2"")]"
19408,Massive memory overhead over NumPy,2019-04-18 14:28:30+00:00,,0,7,"[Label(name=""module: internals""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
19393,[jit] requires_grad in JIT constructor/factories,2019-04-18 04:58:52+00:00,,0,9,"[Label(name=""high priority""), Label(name=""triage review""), Label(name=""oncall: jit"")]"
19349,Different behavior when trace model.,2019-04-17 10:49:22+00:00,,0,10,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
19335,CUDA optimization: using `__restrict__` whenever possible,2019-04-17 02:32:43+00:00,,0,8,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
19330,Multiprocessing on distributed Multi-nodes shutdown error: ‘spawn’ on slave node leads to semaphore_tracker leaked,2019-04-17 01:39:27+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
19267,torch.distributed.broadcast should default to current stream,2019-04-15 18:35:38+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
19263,GCP Base Image Wrong CUDA Version,2019-04-15 16:19:54+00:00,,1,6,"[Label(name=""triaged""), Label(name=""module: doc infra"")]"
19248,add stable distribution in torch.distributions,2019-04-14 10:48:32+00:00,,0,5,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""low priority""), Label(name=""triaged"")]"
19244,[Caffe2] Retraining saved model,2019-04-13 16:52:03+00:00,,0,0,"[Label(name=""caffe2"")]"
19229,Different behavior of torch.nn.MultiMarginLoss on CPU/GPU Tensors,2019-04-13 04:36:41+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
19200,"Deprecate torch.add(tensor, value, other)",2019-04-12 17:12:28+00:00,,0,3,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: deprecation""), Label(name=""module: ux"")]"
19197,index_put_ take min when there are repeated indices,2019-04-12 14:59:17+00:00,,0,2,"[Label(name=""low priority""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: advanced indexing"")]"
19177,8 tests in test_c10d fail when running all tests in one command,2019-04-11 22:40:46+00:00,,1,4,"[Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged"")]"
19172,[Feature Request] Common constants in the torch.* namespace,2019-04-11 18:19:47+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy"")]"
19163,LayerNorm is very slow (almost frozen) in CPU of multiprocessing,2019-04-11 12:53:55+00:00,,0,5,"[Label(name=""module: cpu""), Label(name=""triaged"")]"
19160,Suggest model.eval() in torch.no_grad (and vice versa),2019-04-11 09:37:42+00:00,,0,11,"[Label(name=""module: docs""), Label(name=""triaged"")]"
19150,Improve unit test coverage of torch.unique,2019-04-11 05:53:02+00:00,,1,0,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
19149,Make operators like logsumexp and cumsum operate over dimension 0 by default (or at least for 1D arrays),2019-04-11 05:43:44+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""module: reductions"")]"
19143,Support memoryview() method on torch.Tensor,2019-04-11 02:47:17+00:00,,0,12,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
19128,pytorch.version.cuda is None when compiling with CUDA support,2019-04-10 21:08:40+00:00,,0,9,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
19126,weight_norm doesn't support eta and returns nan for zero weights,2019-04-10 20:07:33+00:00,,0,8,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""module: norms and normalization"")]"
19125,Multi-gpu via torch::nn::parallel::data_parallel,2019-04-10 19:30:00+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""module: cpp""), Label(name=""feature""), Label(name=""triaged"")]"
19120,Embedding layer does not check input range,2019-04-10 17:57:30+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
19117,[jit] Can't `torch.jit.script` a lambda,2019-04-10 17:15:46+00:00,,0,1,"[Label(name=""oncall: jit""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
19107,pytorch/caffe2/onnx/backend.cc:1668:57: error: invalid conversion from ‘google::protobuf::int32 {aka int}’ to ‘onnx_torch::TensorProto::DataType {aka onnx_torch::TensorProto_DataType}’ [-fpermissive],2019-04-10 11:23:56+00:00,,0,0,"[Label(name=""caffe2"")]"
19106,"Performance issue with torch.jit.trace(), slow prediction in C++ (CPU)",2019-04-10 10:49:01+00:00,,0,40,"[Label(name=""triage review""), Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""oncall: jit""), Label(name=""module: cpp"")]"
19092,[RFC] Memory format (aka layout aka NHWC) support,2019-04-10 00:44:37+00:00,,1,73,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: mkldnn"")]"
19053,RNN module weights not compacted,2019-04-09 02:45:16+00:00,,0,14,"[Label(name=""oncall: jit"")]"
19029,C++ custom module not thread safe,2019-04-08 17:56:44+00:00,,0,2,"[Label(name=""needs reproduction""), Label(name=""module: cpp""), Label(name=""triaged"")]"
19026,Python math module support,2019-04-08 17:14:23+00:00,,0,13,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""jit-backlog"")]"
19016,Clean up and consolidate DDP tests,2019-04-08 15:35:27+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""module: tests""), Label(name=""triaged"")]"
18998,torch.from_PIL() Request ?,2019-04-07 14:59:56+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: vision"")]"
18993,ninja: build stopped: subcommand failed.,2019-04-07 02:21:58+00:00,,0,13,"[Label(name=""module: build""), Label(name=""triaged"")]"
18987,Performance issue of unique on CPU,2019-04-06 15:02:09+00:00,,1,0,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
18975,Tracing and Scripting nn.Conv2d shows different op in the graph,2019-04-06 00:03:11+00:00,,0,4,"[Label(name=""oncall: jit"")]"
18944,Caffe2 on google colab: ,2019-04-05 09:40:31+00:00,,0,2,"[Label(name=""caffe2"")]"
18933,Completion of error handling,2019-04-05 07:27:57+00:00,,0,5,"[Label(name=""module: internals""), Label(name=""low priority""), Label(name=""module: error checking""), Label(name=""triaged"")]"
18920,[c10d] CUDA tests for C++ reducer,2019-04-05 06:05:35+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
18906,Provide option to use alias method in Categorical.sample(),2019-04-04 23:46:13+00:00,,1,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
18904,[FR] torch.dist along a dimension,2019-04-04 22:59:45+00:00,,0,0,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: reductions"")]"
18856,CI with >8G CUDA memory,2019-04-04 16:57:32+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: 64-bit"")]"
18850,Allow tracing of models which output `None`,2019-04-04 14:03:43+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""feature""), Label(name=""triaged"")]"
18849,More efficient STFT on CUDA,2019-04-04 09:39:31+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
18805,Running custom operator tests manually is too difficult,2019-04-03 16:46:28+00:00,,1,1,"[Label(name=""module: cpp-extensions""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""enhancement"")]"
18796,[Feature Request] Flattened indices option for max pooling,2019-04-03 11:49:49+00:00,,1,2,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: pooling"")]"
18776,Value of torch.backends.cudnn.benchmark Baked into JIT-Traced Modules ( 150x slowdown on ConvTranspose2d() ) [jit] [libtorch] [cudnn] ,2019-04-02 22:47:54+00:00,,1,7,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
18730,Numerical instability KL divergence RelaxedOneHotCategorical,2019-04-02 15:05:13+00:00,,0,8,"[Label(name=""module: numerical-stability""), Label(name=""module: distributions""), Label(name=""triaged"")]"
18728,MaxPool with n-dimensional tensors,2019-04-02 14:39:45+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: pooling"")]"
18692,Add build tests for feature environment vars,2019-04-01 16:15:53+00:00,,0,0,"[Label(name=""todo""), Label(name=""module: ci""), Label(name=""triaged"")]"
18677,How to compile/install caffe2 with cuda 9.0?,2019-04-01 06:54:50+00:00,,0,2,"[Label(name=""caffe2"")]"
18660,[FR] Warn in cuda init if cuda < 10 is used with RTX cards,2019-03-30 22:38:58+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""module: molly-guard""), Label(name=""triaged"")]"
18658,[FR] add CPU information in collect_env.py,2019-03-30 20:17:23+00:00,,0,0,"[Label(name=""module: collect_env.py""), Label(name=""triaged""), Label(name=""enhancement"")]"
18643,Memory not being deallocated in backward(),2019-03-30 00:44:22+00:00,,0,17,"[Label(name=""module: autograd""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
18634,Speed-up torch.cat on CPU,2019-03-29 20:57:01+00:00,,0,18,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
18631,FP32 depthwise convolution is slow in GPU,2019-03-29 20:29:29+00:00,,0,66,"[Label(name=""high priority""), Label(name=""module: dependency bug""), Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""module: convolution""), Label(name=""triaged"")]"
18630,documentation for C++ / libtorch autograd profiler,2019-03-29 20:16:01+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged"")]"
18536,Make it easier to figure out what CuDNN convolution algorithm we actually chose,2019-03-27 19:24:46+00:00,,0,8,"[Label(name=""module: cudnn""), Label(name=""module: logging""), Label(name=""triaged"")]"
18524,[Caffe2] Missing CMAKE_CUDA_COMPILE_WHOLE_COMPILATION,2019-03-27 13:37:16+00:00,,0,11,"[Label(name=""caffe2"")]"
18520,Jit fail with TracingCheckError with tracing model with layers created after init.,2019-03-27 08:59:44+00:00,,0,2,"[Label(name=""oncall: jit"")]"
18476,[CPP] Allow binding config structs into the Python front end,2019-03-26 14:21:38+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""module: cpp"")]"
18475,The latest version of onnx-caffe2 does not support  “pow” ？,2019-03-26 13:59:58+00:00,,0,10,"[Label(name=""caffe2""), Label(name=""triaged"")]"
18451,download_mnist.py causes flaky tests,2019-03-25 20:51:38+00:00,,0,4,"[Label(name=""oncall: releng""), Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""better-engineering"")]"
18447,Tests on CI are not printing exceptions as they occur,2019-03-25 20:24:28+00:00,,0,2,"[Label(name=""low priority""), Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged"")]"
18436,UnpicklingError when trying to load multiple objects from a file,2019-03-25 18:06:05+00:00,,0,1,"[Label(name=""module: pickle""), Label(name=""module: serialization""), Label(name=""triaged"")]"
18434,improve jit error message for legacy constructor,2019-03-25 16:32:39+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
18414,Add layer-wise adaptive rate scaling (LARS) optimizer,2019-03-25 01:55:59+00:00,,0,16,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
18380,"C++ inference (CPU-only) stalls in Android, and crashes on Mac/Linux",2019-03-23 05:36:54+00:00,,0,2,"[Label(name=""caffe2""), Label(name=""module: android"")]"
18376,Cleanup code in register_c10_ops.cpp,2019-03-23 00:11:01+00:00,,1,1,"[Label(name=""oncall: jit"")]"
18351,Port SpatialConvolutionMM and VolumetricConvolutionMM to ATen,2019-03-22 20:04:46+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: porting"")]"
18317,Add a RandomBatchSampler ?,2019-03-22 03:48:52+00:00,,0,4,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
18315,[FR] support default size (scalar) in torch.randint,2019-03-22 02:41:41+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: tensor creation""), Label(name=""function request"")]"
18312,[jit] Trace perform weirdly on BatchNorm,2019-03-22 01:59:23+00:00,,1,2,"[Label(name=""oncall: jit"")]"
18300,NCCL backend fails when calling broadcast from different threads,2019-03-22 00:09:44+00:00,,1,25,"[Label(name=""high priority""), Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl"")]"
18283,Doubly freed pointer in torch::cat error handling when called via pybind11.,2019-03-21 18:06:31+00:00,,0,18,"[Label(name=""module: cpp""), Label(name=""module: error checking""), Label(name=""triaged"")]"
18273,[caffe2] Broken Operators Catalog,2019-03-21 10:53:49+00:00,,0,1,"[Label(name=""caffe2"")]"
18229,Add support for tuple type deduction in C++ custom operators,2019-03-20 17:42:28+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""enhancement"")]"
18220,Context Manager that disables training mode with in a nn.Module.,2019-03-20 14:12:23+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
18212,[JIT] bitwise NOT does not handle tensor shapes correctly under JIT,2019-03-20 06:55:45+00:00,,0,4,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
18206,Rename ignore_index to ignore_target in CrossEntropyLoss,2019-03-20 02:43:08+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""small"")]"
18182,Update weight initialisations to current best practices,2019-03-19 17:34:38+00:00,,0,46,"[Label(name=""high priority""), Label(name=""module: bc-breaking""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
18173,[docs] How to achieve high-order derivation in my .cpp?,2019-03-19 08:34:46+00:00,,1,3,"[Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
18157,JIT does not batch linear layers in an ensemble,2019-03-19 01:48:55+00:00,,0,11,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
18106,copy.copy not working for ScriptModule,2019-03-16 19:24:49+00:00,,0,15,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
18101,Android NNAPI support of Caffe2,2019-03-16 10:16:04+00:00,,0,1,"[Label(name=""caffe2"")]"
18095,torch.flip is inconsistent with np.flip and also uses `dims` arg instead of `dim`,2019-03-16 02:19:33+00:00,,0,12,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request"")]"
18094,[JIT Script] Need support on distributions.Categorical.,2019-03-16 00:40:30+00:00,,1,5,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
18053,cuDNN error when using 3d convolutions,2019-03-15 08:56:39+00:00,,0,8,"[Label(name=""module: dependency bug""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
18011,caffe2 Segmentation fault (core dumped),2019-03-14 09:14:20+00:00,,0,1,"[Label(name=""caffe2"")]"
18005,Support 'bytes' type in torchscript,2019-03-14 01:42:26+00:00,,2,5,"[Label(name=""oncall: jit""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
18000,Unsupported type of tensor c10::half when running resnet50_trainer.py in Caffe2 ,2019-03-13 22:36:23+00:00,,0,3,"[Label(name=""caffe2"")]"
17984,"""unknown builtin op"" error with static library",2019-03-13 17:34:43+00:00,,1,3,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
17970,Binary not operator causes crash when Jit module is executed on different device,2019-03-13 11:11:40+00:00,,1,7,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
17966,torch.cuda.is_available()  returns misleading value,2019-03-13 08:10:53+00:00,,0,1,"[Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: ux"")]"
17936,[caffe2] resize_op_test.py::TestResize::test_nearest FAILED,2019-03-12 20:52:12+00:00,,0,1,"[Label(name=""caffe2"")]"
17932,JIT torch.ones_like with dtype starts failing on master,2019-03-12 19:15:01+00:00,,0,1,"[Label(name=""oncall: jit"")]"
17920,Build compact libtorch from source with cmake ,2019-03-12 16:08:31+00:00,,0,18,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
17907,"[caffe2] resnet_trainer example fails with MNIST dataset, when parameter num_channels=1 is provided",2019-03-12 08:18:27+00:00,,0,0,"[Label(name=""caffe2"")]"
17902,Conjugate gradient method,2019-03-12 03:42:35+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: derivatives""), Label(name=""function request"")]"
17901,should disable AVX on 32bit x86 / refine AVX availability tests,2019-03-12 03:36:46+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
17897,CUDA large matrix-vector product (torch.mv) causes illegal memory access,2019-03-11 23:37:44+00:00,,0,3,"[Label(name=""module: dependency bug""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: 64-bit""), Label(name=""module: cublas"")]"
17887,Caffe2 building failure,2019-03-11 21:31:14+00:00,,0,0,"[Label(name=""caffe2"")]"
17879,C++ nn::Sequential push_back() copies module if the module is concrete type,2019-03-11 20:15:25+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: nn""), Label(name=""triaged"")]"
17872,Linking Caffe2 with sequential MKL but still calling multi-threaded mkl,2019-03-11 16:48:22+00:00,,0,0,"[Label(name=""caffe2"")]"
17869,[C++ Frontend] ONNX export,2019-03-11 15:23:25+00:00,,0,15,"[Label(name=""module: onnx""), Label(name=""triaged""), Label(name=""onnx-triaged"")]"
17853,Caffe2 building failure when turning off USE_OPENMP,2019-03-11 02:21:39+00:00,,0,2,"[Label(name=""caffe2"")]"
17850,Build fails for caffe2/CMakeFiles/caffe2.dir/__/aten/src/ATen/native/mkldnn/Conv.cpp.o; possibly MKL-DNN issue,2019-03-10 16:50:52+00:00,,0,0,"[Label(name=""caffe2"")]"
17849,Tensor::options() returns false for requires_grad when it is true,2019-03-10 11:21:02+00:00,,0,14,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
17835,PyPy support,2019-03-09 08:30:14+00:00,,0,20,"[Label(name=""module: binaries""), Label(name=""feature""), Label(name=""triaged"")]"
17800,[Caffe2] cudnn mismatch ,2019-03-08 14:28:50+00:00,,0,7,"[Label(name=""caffe2"")]"
17798,Feature Request: deterministic CUDA torch.nn.CTCLoss,2019-03-08 13:52:12+00:00,,0,8,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: determinism"")]"
17797,Non-coherent result for C++ with multithreading and GPU,2019-03-08 08:48:25+00:00,,1,4,"[Label(name=""oncall: jit""), Label(name=""module: cpp""), Label(name=""triaged"")]"
17796,[Caffe2] install error,2019-03-08 08:39:23+00:00,,0,5,"[Label(name=""caffe2"")]"
17774,RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED when batch size is too large,2019-03-07 20:53:27+00:00,,0,7,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
17745,"distributed data parallel, gloo backend works, but nccl deadlock",2019-03-07 13:37:26+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""module: deadlock"")]"
17716,"collate_fn returns subclass of torch.Tensor, but DataLoader transforms back to torch.Tensor",2019-03-06 15:06:33+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: __torch_function__"")]"
17712,Can we to build Caffe2 custom ops independently from a Caffe2 build ?,2019-03-06 10:46:35+00:00,,0,1,"[Label(name=""caffe2"")]"
17703,Training hangs when using DistributedDataParallel in two pod on two nodes ,2019-03-06 03:25:16+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
17688,Improve save() method in torch.jit.ScriptModule,2019-03-05 18:17:01+00:00,,0,5,"[Label(name=""oncall: jit""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""jit-backlog"")]"
17666,Building pytorch on ARM failed,2019-03-04 22:13:31+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
17658,C++ API: Crash in cudnnDestroy() when deconstructing,2019-03-04 15:08:14+00:00,,0,19,"[Label(name=""module: cudnn""), Label(name=""module: cpp""), Label(name=""module: abi""), Label(name=""triaged"")]"
17655,TracedModule 'to' attribute doesn't work for tensors created on forward.,2019-03-04 13:23:09+00:00,,0,2,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
17644,"Not depend on third_party submodules, but self-built libraries?",2019-03-03 13:36:50+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
17634,[Caffe2] android app crashed while linked with libcaffe2_detectron_ops.so,2019-03-02 10:36:15+00:00,,0,0,"[Label(name=""caffe2"")]"
17632,Caffe2 C++ script for classification/object_detection with CMakeLists.txt ,2019-03-02 05:06:30+00:00,,0,0,"[Label(name=""caffe2"")]"
17614,Document whether it is possible to train TorchScript modules,2019-03-01 13:02:44+00:00,,1,19,"[Label(name=""oncall: jit""), Label(name=""module: docs""), Label(name=""module: cpp""), Label(name=""triaged"")]"
17612,The documentation to Module._version isn't visible.,2019-03-01 10:32:16+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: serialization""), Label(name=""triaged"")]"
17554,Add ASSERT for calling accessor on a GPU tensor,2019-02-27 20:44:41+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""module: molly-guard""), Label(name=""triaged"")]"
17553,"torch.Tensor.cpu talks about the object being ""on the correct device""",2019-02-27 20:08:30+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: bootcamp""), Label(name=""triaged""), Label(name=""small"")]"
17538,ONNX->TensorRT parser library duplicated,2019-02-27 06:57:38+00:00,,3,4,"[Label(name=""triaged"")]"
17525,cmake fails with -DBUILD_PYTHON=OFF -DUSE_NNPACK=OFF,2019-02-27 00:46:12+00:00,,0,4,"[Label(name=""module: build""), Label(name=""oncall: releng""), Label(name=""triaged"")]"
17495,RuntimeError: storage_.IsType<T>() ASSERT FAILED,2019-02-26 07:34:56+00:00,,0,2,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""caffe2""), Label(name=""triaged"")]"
17458,Overflow in fbgemm,2019-02-25 02:56:12+00:00,,0,4,"[Label(name=""caffe2"")]"
17437,Automatic aggregation of a mix of sparse and dense gradients is not supported yet,2019-02-24 01:26:58+00:00,,0,0,"[Label(name=""caffe2"")]"
17425,"improved assert message in the case of ""CUDA error: device-side assert triggered""",2019-02-23 00:03:24+00:00,,1,1,"[Label(name=""module: bootcamp""), Label(name=""module: cuda""), Label(name=""module: molly-guard""), Label(name=""triaged"")]"
17354,testConvnetBenchmarks intermittently segfaults,2019-02-21 15:07:15+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""better-engineering"")]"
17350,"torch.nn.CrossEntropyLoss with ""reduction"" sum/mean is not deterministic on segmentation outputs / labels",2019-02-21 12:45:43+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
17342,Code review on .circleci/,2019-02-21 04:31:33+00:00,,1,1,"[Label(name=""module: ci""), Label(name=""triaged"")]"
17313,Implement Adaptive Input Representations for Neural Language Modeling,2019-02-20 20:44:25+00:00,,0,16,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
17286,Use standard docker image for XLA build,2019-02-20 01:16:00+00:00,,0,0,"[Label(name=""oncall: releng""), Label(name=""triaged""), Label(name=""module: xla""), Label(name=""module: docker"")]"
17268,Generic object to tensor dispatching,2019-02-19 18:59:03+00:00,,0,9,"[Label(name=""feature""), Label(name=""triaged"")]"
17257,Generated `__init__.pyi` contains invalid default values,2019-02-19 17:01:17+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
17249,Proposal: Add __tensor_wrap__ method similar to numpy __array_wrap__,2019-02-19 09:15:41+00:00,,0,33,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: numpy"")]"
17234,[feature request] build and move distributions w/ device and/or dtype,2019-02-18 22:23:34+00:00,,0,2,"[Label(name=""module: build""), Label(name=""module: distributions""), Label(name=""triaged"")]"
17216,Group Norm Error When using FP16,2019-02-17 04:55:40+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""triaged""), Label(name=""module: type promotion""), Label(name=""module: half""), Label(name=""module: norms and normalization"")]"
17199,Deadlock with multiprocessing (using fork) and OpenMP / PyTorch should warn after OMP and fork that multithreading may be broken,2019-02-16 10:52:06+00:00,,0,23,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
17169,Global Second Order Pooling,2019-02-15 19:11:16+00:00,,0,5,"[Label(name=""todo""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: pooling"")]"
17165,Better API / conversion for c++ objects to correct IValue objects,2019-02-15 17:39:47+00:00,,0,6,"[Label(name=""oncall: jit""), Label(name=""low priority""), Label(name=""jit-backlog"")]"
17154,Error in converting pytorch model to caffe2 using onnx framework ,2019-02-15 07:23:48+00:00,,0,1,"[Label(name=""caffe2"")]"
17150,Conv2d layers should accept 4-tuple for padding argument,2019-02-15 03:38:18+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement"")]"
17126,Support callables in scripted functions,2019-02-14 20:38:10+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""jit-backlog"")]"
17113,Distributed training jobs do not terminate properly if there is a crash,2019-02-14 13:20:11+00:00,,1,13,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
17057,"Be able to use ""@pytorchbot retest this please"" to re-run both CircleCI and Jenkins jobs",2019-02-13 17:00:02+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: ci""), Label(name=""triaged"")]"
17041,Errors running distributed example,2019-02-13 01:28:26+00:00,,1,9,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
17023,Download speed issues with the pytorch conda channel,2019-02-12 20:29:14+00:00,,0,91,"[Label(name=""module: dependency bug""), Label(name=""triaged"")]"
16991,"[Caffe2] Dropout modules exported from PyTorch with ONNX: BlobIsTensorType(*blob, CPU). Blob is not a CPU Tensor: [BlobNumber]",2019-02-12 02:48:38+00:00,,0,0,"[Label(name=""caffe2"")]"
16956,Hardshrink for Sparse Tensors,2019-02-11 15:15:29+00:00,,1,2,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
16954,torch.multiprocessing.pool.Pool broken,2019-02-11 14:10:33+00:00,,1,12,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""small"")]"
16953,Seg fault with test_rnn_retain_variables on ppc64le,2019-02-11 10:25:40+00:00,,0,1,"[Label(name=""module: crash""), Label(name=""triaged""), Label(name=""module: POWER"")]"
16943,Multiple CPU processes using same GPU model for inference,2019-02-10 21:27:08+00:00,,1,32,"[Label(name=""module: windows""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
16940,Allow positional arguments to be passed as kwargs for autograd custom Function,2019-02-10 20:23:52+00:00,,0,6,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""actionable"")]"
16901,Issue with dataloader using pin_memory = True,2019-02-08 18:50:59+00:00,,0,9,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
16899,"Give clearer guidance about multithreading in PyTorch, and how to disable it",2019-02-08 17:00:39+00:00,,0,5,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
16897,Implement `numpy.random.choice` equivalent,2019-02-08 15:33:11+00:00,,0,29,"[Label(name=""high priority""), Label(name=""module: bootcamp""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
16896,`nn.Linear` allows 1d input tensors,2019-02-08 13:53:09+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
16873,Allow building C++ custom ops that imports another custom ops,2019-02-07 23:31:32+00:00,,0,0,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
16843,Allow to build pytorch for a *specific* architecture,2019-02-07 14:01:01+00:00,,0,19,"[Label(name=""module: build""), Label(name=""triaged"")]"
16805,cstddef not found when compiling C++ Extension - macOS,2019-02-06 15:48:57+00:00,,1,9,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
16804,Wrong description of positive class weight in BCEWithLogitsLoss,2019-02-06 15:31:05+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
16797,"Should be a way to unpickle an object with a torch cuda tensor on a CPU-only machine when using plain ""pickle""",2019-02-06 10:08:13+00:00,,0,9,"[Label(name=""todo""), Label(name=""feature""), Label(name=""module: serialization""), Label(name=""triaged"")]"
16737,torch.save overwrite,2019-02-04 23:14:36+00:00,,1,5,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
16717,Performance regression on CPU from 0.4.1 to 1.0.0 on ResNet inference,2019-02-04 15:01:18+00:00,,1,14,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: single threaded"")]"
16710,culibos linker errors on binary_linux_conda_3.6_cu90_build,2019-02-04 03:37:48+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
16708,Better include path when compiling mkldnn,2019-02-04 02:42:41+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
16706,Very poor Uniform() sampling near floating 0.0,2019-02-03 23:45:40+00:00,,0,29,"[Label(name=""triaged""), Label(name=""module: random"")]"
16703,split_with_sizes should accept a LongTensor as the split_sizes parameter,2019-02-03 10:23:22+00:00,,0,13,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
16700,[feature request] Store accumulated gradients in separate GPU or on CPU memory,2019-02-03 06:31:26+00:00,,1,9,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
16695,Check whether _cudnn_rnn_flatten_weight can avoid changing the TensorImpl or Storage pointer of tensors in `weight_arr`,2019-02-02 20:00:26+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
16668,Reduce fragmentation with CUDA caching allocator when using many streams,2019-02-01 20:27:30+00:00,,0,0,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
16666,numa_test.py fails with AssertionError,2019-02-01 19:35:09+00:00,,0,1,"[Label(name=""caffe2"")]"
16663,new_zeros is not traced correctly,2019-02-01 18:43:07+00:00,,0,12,"[Label(name=""oncall: jit""), Label(name=""good first issue""), Label(name=""triaged"")]"
16661,ROCm 2.1: test_gamma_gpu_sample test fails,2019-02-01 17:44:53+00:00,,0,0,"[Label(name=""module: rocm""), Label(name=""triaged"")]"
16655,"CUDA cache doubles on the second batch and causes OOM, `empty_cache` doesn't empty it",2019-02-01 11:11:51+00:00,,0,13,"[Label(name=""module: dependency bug""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
16654,pytorch was blocked at loss.backward,2019-02-01 10:57:10+00:00,,0,7,"[Label(name=""needs reproduction""), Label(name=""oncall: distributed""), Label(name=""triaged"")]"
16602,Error while installing pytorch,2019-01-31 06:24:02+00:00,,0,14,"[Label(name=""module: build""), Label(name=""caffe2"")]"
16599,Feature Request: Earth Mover's Distance Loss,2019-01-31 04:58:16+00:00,,0,6,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""function request"")]"
16592,[JIT] NVRTC unknown error,2019-01-31 03:07:29+00:00,,0,25,"[Label(name=""needs reproduction""), Label(name=""oncall: jit""), Label(name=""has workaround"")]"
16590,Benchmarking pre-trained model in Caffe2,2019-01-31 02:52:52+00:00,,0,0,"[Label(name=""caffe2"")]"
16589,Make sure `data_ptr` for non-zero-size input tensors stays the same after the VariableType dispatch,2019-01-31 02:37:34+00:00,,0,2,"[Label(name=""module: autograd""), Label(name=""module: molly-guard""), Label(name=""triaged""), Label(name=""module: assert failure"")]"
16556,"KeyError: 'No translator registered for layer: name: ""res3b_relu_norm""\\ntype: ""Normalize""\\nbottom: ""res3b""\\ntop: ""res3b_relu_norm""\\nnorm_param",2019-01-30 10:02:57+00:00,,0,0,"[Label(name=""caffe2"")]"
16542,Error with setting tensors to use cpu in packed_padded_sequence when CUDA tensor is set as default,2019-01-30 03:47:54+00:00,,0,15,"[Label(name=""module: rnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
16523,"The word ""ints"" is not rendered correclty in docs.",2019-01-29 20:54:01+00:00,,0,1,"[Label(name=""todo""), Label(name=""module: docs""), Label(name=""triaged"")]"
16500,Undefined GPU Reference when importing torch with caffe2.onnx.backend for cpu-only pytorch,2019-01-29 14:04:03+00:00,,0,1,"[Label(name=""caffe2"")]"
16499,TorchConfig.cmake always sets _GLIBCXX_USE_CXX11_ABI,2019-01-29 13:51:40+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
16494,caffe2 softmaxwithloss problem,2019-01-29 08:34:53+00:00,,0,1,"[Label(name=""caffe2"")]"
16458,TensorRTOpTest.test_vgg19 is flaky,2019-01-28 20:04:39+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
16436,How to retrain the modelzoo model in Caffe2? ,2019-01-28 09:02:59+00:00,,0,0,"[Label(name=""caffe2"")]"
16432,A bug in parallel.data_parallel when module_kwargs is not None,2019-01-28 05:48:16+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: batching""), Label(name=""module: data parallel"")]"
16424,Flip is much slower than advanced indexing,2019-01-27 22:52:34+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
16405,error on cmake_version from tools/build_pytorch_libs.py,2019-01-26 14:27:44+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
16402,error with nccl when distributed training on caffe2,2019-01-26 10:46:15+00:00,,0,0,"[Label(name=""caffe2"")]"
16385,Adding new module to caffe2,2019-01-25 22:33:49+00:00,,0,1,"[Label(name=""caffe2"")]"
16375,Python-bound C++ frontend modules don't handle attributes well,2019-01-25 19:09:45+00:00,,1,3,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
16363,No Schema registered for ConstantOfShape with domain_version of 9,2019-01-25 10:18:03+00:00,,0,0,"[Label(name=""caffe2"")]"
16330,support `unique_indices` option for `unique`,2019-01-24 19:03:01+00:00,,1,11,"[Label(name=""todo""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
16328,Should torch.arange take a layout parameter?,2019-01-24 18:49:14+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""module: tensor creation""), Label(name=""module: ux"")]"
16322,We're binding a bunch of crap to 'torch' namespace which shouldn't be there,2019-01-24 16:52:26+00:00,,0,8,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
16318,Pytorch with CUDA aware OpenMPI for Infiniband not working with HCOLL and MXM,2019-01-24 14:14:28+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""distributed-backlog"")]"
16299,caffe2::CudnnConvOp::RunOnDevice() fails on Squeezenet,2019-01-24 03:27:17+00:00,,0,1,"[Label(name=""caffe2"")]"
16298,caffe2::onnx::OnnxExporter::Caffe2OpToOnnxNodes failure,2019-01-24 03:19:18+00:00,,0,0,"[Label(name=""caffe2"")]"
16296,caffe2::onnx::OnnxExporter::CreateGemmNodes fails on bvlc_alexnet,2019-01-24 02:55:30+00:00,,0,0,"[Label(name=""caffe2"")]"
16295,ProcessGroupGlooTest.test_gather_stress is flaky,2019-01-24 02:16:50+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: c10d"")]"
16293,Unexpected behavior of jit.trace when PYTORCH_JIT=0,2019-01-24 01:43:08+00:00,,1,3,"[Label(name=""oncall: jit""), Label(name=""low priority"")]"
16291,Confusing documentation with distributions.Categorical about logits,2019-01-24 01:25:05+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""module: docs""), Label(name=""triaged"")]"
16280,caffe2: cudaHostRegister() and mbind()-related test failures on ppc64le,2019-01-23 22:10:12+00:00,,0,2,"[Label(name=""caffe2"")]"
16268,Complete dtype support for torch.norm,2019-01-23 18:41:57+00:00,,0,2,"[Label(name=""module: docs""), Label(name=""triaged"")]"
16266,support for multiple torch.cuda.max_memory_allocated() counters,2019-01-23 18:18:48+00:00,,0,7,"[Label(name=""todo""), Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
16263,[JIT] Support C++ front end module and JIT interop,2019-01-23 17:42:57+00:00,,2,9,"[Label(name=""oncall: jit"")]"
16257,why check ArgumentInfo is_pod? suffer bugs,2019-01-23 14:19:36+00:00,,0,9,"[Label(name=""module: docs""), Label(name=""low priority""), Label(name=""triaged"")]"
16254,I hope Caffe2's python interface add DataLoader Module Similar to pytorch's DataSet and DataLoader,2019-01-23 09:13:44+00:00,,0,0,"[Label(name=""caffe2"")]"
16248,Assert In function importUnsqueeze,2019-01-23 03:26:15+00:00,,0,1,"[Label(name=""caffe2"")]"
16195,how to implement crf predict for segmentation task in Caffe2?,2019-01-20 03:02:20+00:00,,0,0,"[Label(name=""caffe2"")]"
16187,Sparse matrix multiplication is too slow,2019-01-19 15:54:07+00:00,,0,18,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
16148,CategoricalCrossEntropy Loss runs with wrong tag,2019-01-18 09:43:26+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
16138,[Caffe2] resize5d stride/dim issue,2019-01-18 04:45:16+00:00,,0,0,"[Label(name=""caffe2"")]"
16090,build failure with NNAPI enabled (Caffe2 path but under pytorch umbrella),2019-01-16 22:29:09+00:00,,1,2,"[Label(name=""module: build""), Label(name=""caffe2""), Label(name=""triaged"")]"
16014,[docs] Missing argument description (value) in scatter_   function documentation,2019-01-14 15:49:44+00:00,,0,4,"[Label(name=""todo""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
15998,[Caffe2] Failed to load ONNX model with python 3.6,2019-01-13 11:05:05+00:00,,0,0,"[Label(name=""caffe2"")]"
15994,More data type support for gather_map,2019-01-12 21:10:52+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
15963,ProcessGroupGlooTest.test_scatter_stress_cuda is flaky,2019-01-11 17:25:25+00:00,,0,6,"[Label(name=""oncall: distributed""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""module: c10d"")]"
15918,Broadcasting and Additional Dimensions for pairwise_distance,2019-01-10 07:36:34+00:00,,0,7,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request""), Label(name=""module: distance functions"")]"
15869,RuntimeError: [enforce fail at pybind_state.cc:1111] success. Error running net train,2019-01-09 09:15:59+00:00,,0,0,"[Label(name=""caffe2"")]"
15864,Deformable Convolution,2019-01-09 07:05:36+00:00,,0,11,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: vision"")]"
15849,DataLoader with option to re-use worker processes,2019-01-09 00:21:24+00:00,,1,59,"[Label(name=""high priority""), Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
15829,computing  entropy of a tensor ,2019-01-08 16:27:09+00:00,,0,21,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""function request"")]"
15822,AvgPool2d doesn't test if kernel is smaller than input size,2019-01-08 08:29:56+00:00,,0,5,"[Label(name=""module: bootcamp""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""better-engineering""), Label(name=""module: pooling"")]"
15821,No test coverage for kwargs of AvgPool2d and AvgPool3d,2019-01-08 08:14:54+00:00,,0,2,"[Label(name=""module: bootcamp""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: pooling"")]"
15812,Possible regression in incremental build,2019-01-08 00:15:15+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
15771,Implicit conversion error in caffe2,2019-01-06 08:55:43+00:00,,1,2,"[Label(name=""caffe2"")]"
15738,Beta Distribution values wrong for a=b---> 0,2019-01-04 17:33:11+00:00,,0,14,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
15716,"Nn.dataparallel with multiple output, weird gradient result None",2019-01-03 23:18:11+00:00,,1,6,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
15630,[Caffe2] Internal compiler error for CUDA.,2018-12-30 13:33:36+00:00,,0,14,"[Label(name=""caffe2"")]"
15617,Feature request: transposed locally connected layer,2018-12-29 18:16:23+00:00,,0,0,"[Label(name=""todo""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
15608,[Caffe2] How to switch to test phase?,2018-12-29 09:33:55+00:00,,0,2,"[Label(name=""caffe2"")]"
15607,documentation for adding a new type via C++ extensions,2018-12-29 07:32:25+00:00,,0,13,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: complex""), Label(name=""module: bfloat16"")]"
15491,LibTorch: include cmake files for all distributed headers,2018-12-21 20:27:12+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
15465,Transplant caffe2 on my DNN-accelerator,2018-12-21 02:35:55+00:00,,0,1,"[Label(name=""caffe2"")]"
15457,Improve one_hot,2018-12-21 00:16:40+00:00,,0,9,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request"")]"
15432,caffe2: multi-thread(or multi-instance) predict is much slower than the single thread or single instance,2018-12-20 09:16:52+00:00,,0,13,"[Label(name=""caffe2"")]"
15431,IDEEP error:could not initialize a memory descriptor,2018-12-20 08:59:39+00:00,,0,2,"[Label(name=""caffe2"")]"
15421,JIT is not compatible with data parallel,2018-12-20 02:37:12+00:00,,1,13,"[Label(name=""oncall: jit"")]"
15386,F.grid_sample doesn't respect padding_mode when height of inputs is 1,2018-12-19 05:38:31+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
15378,Projective Transformation grid generator,2018-12-19 02:46:21+00:00,,0,5,"[Label(name=""todo""), Label(name=""triaged""), Label(name=""enhancement"")]"
15350,Proposal for build system under many system configuration testing,2018-12-18 17:05:17+00:00,,0,4,"[Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged"")]"
15342,[JIT] Batch op. batch_sum return a mask which is on cpu,2018-12-18 13:43:52+00:00,,0,3,"[Label(name=""needs reproduction""), Label(name=""oncall: jit"")]"
15313,AttributeError: module 'caffe2.python._import_c_extension' has no attribute 'get_cudnn_version' when Caffe2 is not built with CuDNN,2018-12-17 22:10:24+00:00,,0,0,"[Label(name=""caffe2"")]"
15309,libtorch without cmake ,2018-12-17 20:32:29+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
15303,CMake Error at CMakeLists.txt:10 (find_package) in C++,2018-12-17 18:42:22+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
15298,Momentum problem (1-momentum is correct?) in BatchNorm2d,2018-12-17 11:44:47+00:00,,0,2,"[Label(name=""todo""), Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
15294,manylinux2014 compatible wheels,2018-12-17 06:26:09+00:00,,0,6,"[Label(name=""module: build""), Label(name=""triaged"")]"
15291,linked error of Pytorch 1.0 release ,2018-12-17 02:22:38+00:00,,0,16,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
15290,[caffe2] Installation problem on OSX,2018-12-17 02:10:32+00:00,,0,1,"[Label(name=""caffe2"")]"
15288,possible unsafety in torch.distributions.kl_divergence for Bernoullis,2018-12-16 22:05:10+00:00,,0,2,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""module: NaNs and Infs"")]"
15284,index_add_ with scalar values instead of tensors,2018-12-16 15:54:08+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: advanced indexing"")]"
15260,MultiGPU for gru,2018-12-15 08:04:30+00:00,,0,4,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
15259,err:torch.nn.CrossEntropyLoss,2018-12-15 07:33:51+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
15253,[Feature Request] cdist: pairwise distances between two sets of tensors with batch mode,2018-12-15 04:56:44+00:00,,0,15,"[Label(name=""triaged""), Label(name=""module: batching""), Label(name=""function request""), Label(name=""module: distance functions"")]"
15249,[caffe2] controlled forward pass,2018-12-15 01:33:52+00:00,,0,2,"[Label(name=""caffe2"")]"
15245,Gather backward is faster than integer indexing on GPU,2018-12-15 00:08:44+00:00,,0,13,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: determinism"")]"
15167,cudnn not found,2018-12-13 11:47:09+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""actionable"")]"
15161,Maybe a bug when using DataParallel,2018-12-13 07:58:46+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
15149,Use std::variant to represent C++ side enumerations (with binding support),2018-12-13 00:25:17+00:00,,0,5,"[Label(name=""module: cpp""), Label(name=""triaged"")]"
15142,Update third_party/googletest - Ability to skip tests in GTEST,2018-12-12 22:54:49+00:00,,0,3,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""module: third_party"")]"
15120,Different implementations of upsampleBilinear between pytorch and caffe2,2018-12-12 13:42:15+00:00,,1,4,"[Label(name=""caffe2"")]"
15116,torch.save does not work if nn.Module has partial JIT.,2018-12-12 09:05:18+00:00,,1,3,"[Label(name=""oncall: jit"")]"
15070,In-place operations on `.data` or `.detach()` of sparse tensor doesn't update the original tensor,2018-12-11 20:03:50+00:00,,0,1,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
15043,[JIT] jit.trace fails with custom GRUs and CUDA when the sequence is longer,2018-12-11 04:24:48+00:00,,1,9,"[Label(name=""oncall: jit"")]"
15009,[Caffe2] Caffe2Config.cmake,2018-12-10 19:58:47+00:00,,0,1,"[Label(name=""caffe2"")]"
15004,[Caffe2] How to link Caffe2 in cmake file for C++ compilation?,2018-12-10 18:37:18+00:00,,0,4,"[Label(name=""caffe2"")]"
14996,as_tensor does not use the device of the default tensor type,2018-12-10 16:47:15+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged"")]"
14989,[Caffe2] CNN Training on CPU is faster than GPU,2018-12-10 13:01:32+00:00,,0,1,"[Label(name=""caffe2"")]"
14970,"[Caffe2] ""Same"" padding ",2018-12-09 23:01:31+00:00,,0,0,"[Label(name=""caffe2"")]"
14963,PyTorch 1.0 source build fails (error in caffe2/utils/fatal_signal_asan_no_sig_test.cc),2018-12-09 15:32:33+00:00,,0,2,"[Label(name=""caffe2"")]"
14959,get/set device in c++,2018-12-09 13:43:16+00:00,,0,9,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""small"")]"
14945,[Feature request] create sparse coo matrix w/o index check,2018-12-08 23:12:21+00:00,,0,23,"[Label(name=""module: performance""), Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""enhancement"")]"
14940,caffe2::Predictor: Cannot find operator schema for GivenTensorFill. Will skip schema checking.,2018-12-08 19:38:50+00:00,,0,3,"[Label(name=""caffe2"")]"
14939,caffe2/predictor missing from libtorch,2018-12-08 17:56:58+00:00,,0,1,"[Label(name=""caffe2"")]"
14925,Am I able to run caffe2 and gloo example: resnet50_trainer.py using pytorch v1.0rc1?,2018-12-08 03:54:29+00:00,,0,1,"[Label(name=""caffe2"")]"
14907,Missing dilation from several pooling modules (AvgPool),2018-12-07 20:31:05+00:00,,0,1,"[Label(name=""hackamonth""), Label(name=""triaged""), Label(name=""module: pooling""), Label(name=""function request"")]"
14867,[C++/Pytorch] Get input shapes,2018-12-07 01:02:50+00:00,,0,6,"[Label(name=""oncall: jit"")]"
14864,[discussion] Recommend a different file extension for models (.PTH is a special extension for Python),2018-12-07 00:47:56+00:00,,1,17,"[Label(name=""triaged"")]"
14844,Negative indexing for nn.Embedding inputs,2018-12-06 08:05:58+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""needs design""), Label(name=""function request"")]"
14839,Test OpenCV4 in CI,2018-12-06 05:35:24+00:00,,0,0,"[Label(name=""module: ci""), Label(name=""triaged"")]"
14799,which operator of caffe2  have the same function as torch.nn.Parameter,2018-12-05 10:36:47+00:00,,0,0,"[Label(name=""caffe2"")]"
14797,Modern interface for Storage,2018-12-05 06:14:19+00:00,,0,2,"[Label(name=""module: internals""), Label(name=""triaged"")]"
14796,Cannot build Caffe2 with TensorRT,2018-12-05 06:08:05+00:00,,1,1,"[Label(name=""caffe2"")]"
14790,Tensor.copy_() seems to work improperly with numpy/list indices,2018-12-05 04:41:03+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
14788,[caffe2] [NNPACK] how to set thread pool for NNPACK?,2018-12-05 03:35:28+00:00,,0,0,"[Label(name=""caffe2"")]"
14750,[caffe2] ConvTranspose with group attribute,2018-12-04 11:33:49+00:00,,0,1,"[Label(name=""caffe2""), Label(name=""module: op-unification"")]"
14731,Caffe2 C++ runs single threaded,2018-12-04 02:25:50+00:00,,0,3,"[Label(name=""caffe2"")]"
14726,[caffe2] Corresponding C++ API for prepare_prediction_net,2018-12-04 01:02:52+00:00,,0,0,"[Label(name=""caffe2"")]"
14702,pytorch_doc_push is racing with itself,2018-12-03 15:22:11+00:00,,0,4,"[Label(name=""triaged"")]"
14701,CI: Flaky download from download.pytorch.org,2018-12-03 15:17:26+00:00,,0,11,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""better-engineering"")]"
14699,[Feature Request] linux distribution friendly build system,2018-12-03 14:11:30+00:00,,0,10,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""enhancement"")]"
14687,Advanced indexing slower than numpy,2018-12-03 00:39:03+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: advanced indexing"")]"
14685,[Caffe2] Exception when creating gradient for [Cast] SquaredL2Distance as output layer of CNN network,2018-12-02 21:40:44+00:00,,0,1,"[Label(name=""caffe2"")]"
14670,[ONNX CI] TestCaffe2End2End.test_squeezenet occasional error,2018-12-01 16:12:39+00:00,,0,1,"[Label(name=""caffe2"")]"
14652,fc_without_bias / FCWithoutBias,2018-11-30 23:46:24+00:00,,0,0,"[Label(name=""caffe2"")]"
14632,[c10d] Check that allgather/gather output tensors point to different storage,2018-11-30 19:09:34+00:00,,0,2,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
14573,libtorch exports protobuf symbols,2018-11-29 22:05:44+00:00,,1,14,"[Label(name=""high priority""), Label(name=""module: build""), Label(name=""module: protobuf""), Label(name=""module: cpp""), Label(name=""module: abi""), Label(name=""triaged"")]"
14560,pin_memory/is_pinned API is too CUDA-centric,2018-11-29 19:30:01+00:00,,1,5,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: memory format""), Label(name=""needs design"")]"
14538,[Caffe2] How to fetch trainable parameters? ,2018-11-29 15:33:34+00:00,,0,0,"[Label(name=""caffe2"")]"
14508,[Caffe2] GPU test passed. Cannot see on nvidia-smi,2018-11-28 23:12:30+00:00,,0,1,"[Label(name=""caffe2"")]"
14489,"Batch matmul with sparse matrix, dense vector",2018-11-28 19:33:21+00:00,,1,16,"[Label(name=""todo""), Label(name=""module: sparse""), Label(name=""triaged"")]"
14487,TestAdagrad.test_row_wise_sparse_adagrad intermittently fails health check,2018-11-28 18:39:41+00:00,,0,1,"[Label(name=""caffe2"")]"
14486,"building bundled nccl fails in (caffe2, cuda 8, cudnn 7) CI environment",2018-11-28 18:35:28+00:00,,0,2,"[Label(name=""caffe2"")]"
14484,prim::ConstantChunk derivative formula doesn't handle undefined inputs,2018-11-28 18:20:39+00:00,,0,0,"[Label(name=""oncall: jit"")]"
14478,Flaky download from files.pythonhosted.org when installing botocore,2018-11-28 17:06:10+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: flaky-tests""), Label(name=""better-engineering"")]"
14477,"Add a debug mode which is -O0 for framework code, but -O for kernels",2018-11-28 16:25:15+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
14467,"Optimizer warning when parameters ""change""",2018-11-28 10:45:44+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
14461,The speed of scatter is influenced by the data size while using nn.DataParallel,2018-11-28 08:41:53+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
14459,[Caffe2] Error protos.protos_size() == OutputSize() when loading dataset created by regular Caffe (datum),2018-11-28 07:49:59+00:00,,0,1,"[Label(name=""caffe2"")]"
14455,[JIT] Tracing a script function/module where not all args are Tensors,2018-11-28 06:36:53+00:00,,0,14,"[Label(name=""oncall: jit"")]"
14436,Use of STL templates in cpu/ directory (compiling with different AVX settings) is silently hazardous,2018-11-27 23:17:28+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
14431,BUILD_CAFFE2_OPS=OFF is not tested in CI,2018-11-27 22:28:21+00:00,,0,0,"[Label(name=""caffe2"")]"
14408,DeviceOption::set_device_type() doesn't accept caffe2::CPU anymore,2018-11-27 11:04:47+00:00,,0,2,"[Label(name=""caffe2"")]"
14380,[caffe2] Caffe2 GlobalInit should be run before any other API calls,2018-11-26 19:15:08+00:00,,0,0,"[Label(name=""caffe2"")]"
14372,[c10d] Configurable timeout per operation for MPI backend,2018-11-26 17:00:45+00:00,,1,0,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""distributed-backlog"")]"
14370,[Caffe2] Check failed: output->size() == values_.size() output size: 1 given size: 1563551,2018-11-26 16:45:06+00:00,,0,3,"[Label(name=""caffe2"")]"
14367,Error: DeviceGuardImpl for cpu is not available (static linking PyTorch),2018-11-26 11:02:24+00:00,,0,32,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: static linking""), Label(name=""has workaround"")]"
14366,How to use model.net.Clip?,2018-11-26 10:58:50+00:00,,0,0,"[Label(name=""caffe2"")]"
14352,[libtorch] Catkin_make compilation error,2018-11-25 09:12:13+00:00,,0,8,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""has workaround"")]"
14348,[Caffe2] Error when loading a leveldb dataset using brew.db_input (Error protos.protos_size() == OutputSize().),2018-11-24 13:10:09+00:00,,0,1,"[Label(name=""caffe2"")]"
14337,Caffe2 C++ tutorial is not working,2018-11-23 15:37:13+00:00,,0,1,"[Label(name=""caffe2"")]"
14332,[jit][script] support slicing with tensor literals,2018-11-23 06:26:38+00:00,,0,0,"[Label(name=""oncall: jit"")]"
14328,[Caffe2] How to use the euclidean loss (L2) as output of a CNN model?,2018-11-22 23:49:23+00:00,,0,0,"[Label(name=""caffe2"")]"
14320,[caffe2] Fails to build with fbgemm enabled,2018-11-22 13:12:06+00:00,,0,0,"[Label(name=""caffe2"")]"
14318,No code example for AdaptiveLogSoftmaxWithLoss,2018-11-22 12:14:38+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
14312,[Caffe2] Cannot get repeated argument in custom operator in CUDA context,2018-11-22 06:55:39+00:00,,0,0,"[Label(name=""caffe2"")]"
14277,Provide Protobuf library if libtorch was built with included version,2018-11-21 15:09:50+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: protobuf""), Label(name=""module: cpp""), Label(name=""triaged"")]"
14270,Pytorch C++ API with cuda : Expected object of backend CPU but got backend CUDA for sequence element 1 in sequence argument at position #1 'tensors' ,2018-11-21 09:34:03+00:00,,0,6,"[Label(name=""oncall: jit"")]"
14262,[Caffe2] How can I use detectron with pytorch?,2018-11-21 02:59:06+00:00,,0,3,"[Label(name=""caffe2"")]"
14227,[bug] inconsistent behavior of indexing ,2018-11-20 12:41:09+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
14222,Caffe2->ONNX conversion issue due to spatial-bn,2018-11-20 09:04:27+00:00,,0,0,"[Label(name=""caffe2"")]"
14219,C++ model load error,2018-11-20 06:53:28+00:00,,0,17,"[Label(name=""oncall: jit""), Label(name=""triaged"")]"
14200,Failed to run 'bash ../tools/build_pytorch_libs.sh --use-nnpack --use-mkldnn --use-qnnpack caffe2',2018-11-19 21:11:15+00:00,,0,11,"[Label(name=""module: build""), Label(name=""triaged"")]"
14185,[Caffe2] Non-spatial batchnorm optimization,2018-11-19 10:27:12+00:00,,2,0,"[Label(name=""caffe2"")]"
14152,Failed to run 'bash ../tools/build_pytorch_libs.sh --use-cuda --use-nnpack --use-mkldnn --use-qnnpack caffe2',2018-11-17 21:59:13+00:00,,0,23,"[Label(name=""module: build""), Label(name=""triaged"")]"
14131,running caffe2 float16 tensors results in aten runtime error,2018-11-16 23:53:34+00:00,,0,1,"[Label(name=""caffe2"")]"
14112,[sparse] add descriptions and examples for methods at torch.sparse doc page,2018-11-16 19:35:25+00:00,,0,2,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
14095,[feature request] bincount along specified dimension(s),2018-11-16 10:39:49+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: sorting and selection""), Label(name=""function request"")]"
14047,Make torch.multiprocessing.SpawnContext usable,2018-11-15 22:51:59+00:00,,1,0,"[Label(name=""module: multiprocessing""), Label(name=""feature""), Label(name=""triaged"")]"
14030,Cannot import caffe2_pybind11_state_gpu,2018-11-15 14:16:09+00:00,,0,1,"[Label(name=""caffe2"")]"
13993,[tracking task] FBGEMM guarding AVX2 properly,2018-11-14 22:21:13+00:00,,0,17,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
13918,Pytorch very slow to convert list of numpy arrays into tensors,2018-11-13 19:52:33+00:00,,1,14,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: numpy""), Label(name=""has workaround"")]"
13865,[c10d] Coordinated file truncation for FileStore,2018-11-12 22:18:53+00:00,,2,5,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged""), Label(name=""distributed-backlog"")]"
13836,"Pytorch-Caffe2 export: ""Arrays are not almost equal to 3 decimals""",2018-11-12 10:32:06+00:00,,0,7,"[Label(name=""caffe2"")]"
13818,test_spectral_norm: Backward is not reentrant,2018-11-11 03:11:32+00:00,,0,6,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: data parallel""), Label(name=""module: norms and normalization"")]"
13811,Feature request: von Mises-Fisher distribution,2018-11-10 19:31:29+00:00,,0,8,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
13786,PyTorch streams are not cuda-memcheck clean,2018-11-09 20:48:28+00:00,,0,4,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
13782,torch.linspace does not check for infinity and nan,2018-11-09 18:58:46+00:00,,0,4,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: tensor creation"")]"
13772,Error in building Caffe2 on Windows (experimental operators),2018-11-09 12:43:04+00:00,,0,7,"[Label(name=""caffe2"")]"
13746,[caffe2] test depthwise3x3_conv_op_test fails to run,2018-11-08 20:39:17+00:00,,0,1,"[Label(name=""caffe2"")]"
13726,"onnx_graph_to_caffe2_net takes a model, not a graph",2018-11-08 17:43:33+00:00,,0,3,"[Label(name=""caffe2"")]"
13716,depthwise convolution are slow on cpu ,2018-11-08 09:50:30+00:00,,0,6,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""module: convolution""), Label(name=""triaged"")]"
13715,caffe2 c++ load pb model fail,2018-11-08 09:32:48+00:00,,0,1,"[Label(name=""caffe2"")]"
13684,[caffe2] Adding CUDA operators for generate proposals and NMS layers,2018-11-07 22:08:29+00:00,,0,0,"[Label(name=""caffe2"")]"
13671,Caffe2 Build Static,2018-11-07 15:19:24+00:00,,0,0,"[Label(name=""caffe2"")]"
13667,[caffe2] Modify models in model zoo,2018-11-07 13:42:02+00:00,,0,0,"[Label(name=""caffe2"")]"
13664,Caffe2 install,2018-11-07 10:24:13+00:00,,0,2,"[Label(name=""caffe2"")]"
13655,[caffe2] How to export onnx model trained on Detectron in Caffe2?,2018-11-07 02:04:40+00:00,,0,0,"[Label(name=""caffe2"")]"
13598,caffe2: RuntimeError: [enforce fail at reshape_op.h:110]  with Alexnet onnx test with cuda,2018-11-05 23:55:36+00:00,,0,8,"[Label(name=""caffe2"")]"
13565,Unicode support for the MS Windows platform,2018-11-05 11:08:24+00:00,,0,1,"[Label(name=""module: windows""), Label(name=""caffe2"")]"
13508,OpenCL support for smartphones,2018-11-02 14:08:55+00:00,,0,3,"[Label(name=""triaged"")]"
13505,[feature request] Singular values and spectral norm for convolutional layers ,2018-11-02 12:48:03+00:00,,0,8,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""module: fft""), Label(name=""function request"")]"
13498,Caffe2 missing headers in docker/conda,2018-11-02 04:28:33+00:00,,0,0,"[Label(name=""caffe2"")]"
13493,How to do inference with float16 (or half) in caffe2?,2018-11-02 00:52:25+00:00,,0,2,"[Label(name=""caffe2"")]"
13477,[jit] restrict promotion of single-element arguments to lists,2018-11-01 20:57:14+00:00,,0,0,"[Label(name=""oncall: jit"")]"
13447,Support gathering nested lists in DataParallel ,2018-11-01 13:29:38+00:00,,0,3,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
13405,[caffe2] How to use Split operator?,2018-10-31 18:41:37+00:00,,0,0,"[Label(name=""caffe2"")]"
13402,batch_norm doesn't bump version counter of running stats,2018-10-31 18:12:32+00:00,,1,21,"[Label(name=""high priority""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""actionable""), Label(name=""fixathon"")]"
13373,cannot run mobilenet_v2_quantized on pytorch/caffe2,2018-10-31 05:59:13+00:00,,1,2,"[Label(name=""caffe2"")]"
13304,ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79,2018-10-30 10:02:12+00:00,,0,8,"[Label(name=""caffe2"")]"
13300,Use a dill-based multiprocessing library and serialization,2018-10-30 07:51:01+00:00,,0,5,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
13297,[Caffe2]How to accelerate group convolution in Caffe2?,2018-10-30 07:17:31+00:00,,0,0,"[Label(name=""caffe2"")]"
13268,Non-Zero Padding in Convolution Module,2018-10-29 21:23:48+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
13246,DataLoader num_workers > 0 causes CPU memory from parent process to be replicated in all worker processes,2018-10-29 13:23:59+00:00,,0,132,"[Label(name=""high priority""), Label(name=""module: dependency bug""), Label(name=""module: multiprocessing""), Label(name=""module: dataloader""), Label(name=""module: molly-guard""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
13234,torch.utils.checkpoint is not compatible with nn.DataParallel,2018-10-29 03:03:08+00:00,,0,4,"[Label(name=""module: checkpoint""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
13226,[Caffe2] cmake3 detection error?,2018-10-28 14:12:52+00:00,,0,1,"[Label(name=""caffe2"")]"
13224,Caffe2: Causes error when using flag remove_legacy_pad while converting from caffe to caffe2,2018-10-28 10:18:58+00:00,,0,2,"[Label(name=""caffe2"")]"
13222,Memory inefficient in batched matmul when requiring gradients,2018-10-28 07:27:00+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: linear algebra"")]"
13218,Support for integer interpolation (torch.nn.functional.interpolate),2018-10-27 23:56:45+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request"")]"
13208,[caffe2] How to use the operators that are not included in brew through the python API?,2018-10-27 14:49:21+00:00,,0,1,"[Label(name=""caffe2"")]"
13207,[pytorch] [feature request] Error out if the needed GPU device capability is absent in runtime,2018-10-27 14:12:23+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
13188,cudnn explicit paths and GCC multilib suffixes prevents detection of good cudnn headers,2018-10-26 21:41:54+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
13170,Allow traced modules to return dictionaries,2018-10-26 18:18:35+00:00,,0,0,"[Label(name=""oncall: jit"")]"
13164,Tracing custom ops,2018-10-26 10:17:02+00:00,,0,1,"[Label(name=""oncall: jit"")]"
13162,circular module reference raises RecursionError,2018-10-26 08:37:54+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
13130,"arm64 port for PyTorch, libtorch",2018-10-25 17:38:07+00:00,,0,14,"[Label(name=""module: ci""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: arm"")]"
13122,[onnx][caffe2] Is there schedule to support onnxwhile in onnx exporter?,2018-10-25 15:04:54+00:00,,0,0,"[Label(name=""caffe2"")]"
13120,[caffe2]  incompatible constructor arguments,2018-10-25 14:37:58+00:00,,0,0,"[Label(name=""caffe2"")]"
13118,"warning: attribute namespace ""clang"" is unrecognized; High Sierra / Fedora compilation with clang results in spurious clang errors in nvcc",2018-10-25 13:33:27+00:00,,1,18,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: build warnings"")]"
13079,Tests that download from internet should retry on failure ,2018-10-24 22:11:16+00:00,,0,2,"[Label(name=""module: ci""), Label(name=""triaged"")]"
13058,Backward pass over torch.nn.functional.pad is extremely slow with half tensors,2018-10-24 17:38:46+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: half"")]"
13053,Generalized Data Class,2018-10-24 15:53:20+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: data"")]"
13041,[caffe2] How to handle multiple inputs and multiple outputs in the network architecture?,2018-10-24 09:44:02+00:00,,0,2,"[Label(name=""caffe2"")]"
13034,[caffe2]How can I export init_net.pb and predict_net.pb files on my own?,2018-10-24 03:03:13+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
13023,Python dataloader Improvements,2018-10-23 23:36:40+00:00,,1,6,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
13018,Improved performance for torch.multinomial with small batches,2018-10-23 23:23:33+00:00,,0,4,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged"")]"
12983,Fail to Run Caffe2 with Successful Build: This caffe2 python run does not have GPU support,2018-10-23 12:36:09+00:00,,0,5,"[Label(name=""caffe2"")]"
12980,Installing pytorch from source on labs.cognitiveclass.ai,2018-10-23 07:26:42+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: POWER"")]"
12962,Come up with a better strategy for noticing BC-breaking attribute additions to serializable classes,2018-10-23 00:49:15+00:00,,0,0,"[Label(name=""module: bc-breaking""), Label(name=""module: molly-guard""), Label(name=""triaged"")]"
12931,USE_OPENMP=OFF is ignored [Caffe2],2018-10-22 13:55:14+00:00,,0,1,"[Label(name=""caffe2"")]"
12913,ubuntu16.04 build from source caffe2,2018-10-21 14:26:53+00:00,,0,10,"[Label(name=""caffe2"")]"
12895,RelaxedOneHotCategorical not implementing entropy (and other abstract methods),2018-10-20 00:04:04+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""enhancement"")]"
12879,Eigen in Caffe2 doesn't produce vectorized instructions,2018-10-19 17:13:13+00:00,,2,2,"[Label(name=""caffe2"")]"
12873,Massive initial memory overhead GPU,2018-10-19 14:34:09+00:00,,0,48,"[Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
12869,caffe2: Unsupported type of tensor: nullptr (uninitialized),2018-10-19 11:23:25+00:00,,0,2,"[Label(name=""caffe2"")]"
12868,[CAPI] Increase of memory usage when exporting a Adam optimzer,2018-10-19 09:27:02+00:00,,0,0,"[Label(name=""module: cpp""), Label(name=""module: optimizer""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
12855,Model with Caffe2 runs much slower than it with pytorch in GPU mode !!!!,2018-10-19 02:28:13+00:00,,0,5,"[Label(name=""caffe2"")]"
12851,TestAdadelta.test_adadelta flaky on CI,2018-10-19 00:51:01+00:00,,0,2,"[Label(name=""caffe2""), Label(name=""module: flaky-tests""), Label(name=""better-engineering"")]"
12830,Test that (cd build && ninja) immediately after build is no-op in CI,2018-10-18 18:54:22+00:00,,0,0,"[Label(name=""module: build""), Label(name=""module: ci""), Label(name=""triaged"")]"
12828,BUILD_BINARY is a lie,2018-10-18 18:00:40+00:00,,0,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
12819,Initialization error when moving data to the GPU,2018-10-18 12:08:33+00:00,,0,8,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
12812,Pytorch BatchNorm2D Unstable,2018-10-18 08:34:41+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
12808,tutorial_blob ERROR,2018-10-18 07:03:23+00:00,,0,1,"[Label(name=""caffe2"")]"
12797,Port dragon4_scientific for pretty float tensor print.,2018-10-17 23:52:08+00:00,,0,1,"[Label(name=""module: printing""), Label(name=""triaged""), Label(name=""enhancement"")]"
12795,C++ frontend: how to debug nan gradients,2018-10-17 23:22:57+00:00,,0,3,"[Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement"")]"
12773,"Build the docker image from source, but torch.cuda.is_available()==false",2018-10-17 16:50:51+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: docker"")]"
12764,[feature request] Operator Overloading,2018-10-17 12:17:06+00:00,,0,2,"[Label(name=""todo""), Label(name=""feature""), Label(name=""triaged"")]"
12763,"Caffe2: Two entries of external_input ""data_0"" in mnist_predict_net.pbtxt file",2018-10-17 12:15:45+00:00,,0,0,"[Label(name=""caffe2"")]"
12760,[feature request] Spectral norm support in torch.norm or factor out Power Iteration from spectralnormalization in some other place and orthogonalization from PowerSGD hook,2018-10-17 10:28:48+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
12755,caffe2 python custom operator could not update parameters,2018-10-17 07:36:43+00:00,,0,0,"[Label(name=""caffe2"")]"
12716,cdf in torch.distributions.bernoulli throws NotImplementedError,2018-10-16 17:18:50+00:00,,0,3,"[Label(name=""todo""), Label(name=""module: distributions""), Label(name=""triaged"")]"
12715,pack_padded_sequence throws IndexError when only kwargs are specified,2018-10-16 16:55:41+00:00,,0,1,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
12704,Error occuring while converting mnist or cifar model from caffe2 to onnx,2018-10-16 08:49:35+00:00,,0,0,"[Label(name=""caffe2"")]"
12702,How to run a pytorch-onnx-caffe2 model on GPU?,2018-10-16 07:58:19+00:00,,0,5,"[Label(name=""caffe2""), Label(name=""triaged"")]"
12690,How can I build caffe2_gtest_main under pytorch/caffe2/test/ folder?,2018-10-15 23:10:17+00:00,,0,2,"[Label(name=""caffe2""), Label(name=""triaged"")]"
12675,[feature request] ignore_index and size_average in nn.AdaptiveLogSoftMaxWithLoss,2018-10-15 20:47:37+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""triaged"")]"
12672,Move collate_fn functionality / responsibility into Dataset object,2018-10-15 20:23:09+00:00,,0,5,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
12659,Differentiation through Module parameters updates,2018-10-15 16:23:37+00:00,,2,12,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
12658,Move BigTensorSerialization tests out of default caffe2_cpu_tests,2018-10-15 16:17:51+00:00,,0,0,"[Label(name=""caffe2"")]"
12650,"pytorch/torch/utils/cpp_extension.py ignores compiler setting, ",2018-10-15 13:39:31+00:00,,0,2,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
12646,Caffe2 Installation inside Pytorch,2018-10-15 10:52:28+00:00,,0,8,"[Label(name=""caffe2"")]"
12642,fail to visualize caffe2 model,2018-10-15 03:31:39+00:00,,0,4,"[Label(name=""caffe2"")]"
12641,Install Jetson TX2 Max Regcount Error,2018-10-15 01:15:52+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: jetson"")]"
12640,how to store a bounding box in Tensor?,2018-10-15 00:36:34+00:00,,0,0,"[Label(name=""caffe2"")]"
12609,Request for stripped down / inference only pytorch wheels,2018-10-12 16:33:17+00:00,,1,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
12576,[feature request] `ignore_label` argument in Caffe2 `SoftmaxWithLoss`,2018-10-11 18:42:56+00:00,,0,1,"[Label(name=""caffe2"")]"
12535,[CMake] Linking against Intel OpenMP,2018-10-10 15:26:46+00:00,,1,8,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: openmp"")]"
12532,Provide better documentation for torch.Size,2018-10-10 14:12:04+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""triaged"")]"
12530,[caffe2] Memory usage,2018-10-10 12:03:51+00:00,,0,1,"[Label(name=""caffe2"")]"
12515,how to use mask-rcnn in caffe2 c++ gpu,2018-10-10 03:14:40+00:00,,0,2,"[Label(name=""caffe2"")]"
12509,"The text design (color, type) makes it hard to read",2018-10-10 00:31:43+00:00,,0,2,"[Label(name=""todo""), Label(name=""triaged"")]"
12501,C++: Calling Workspace::RunNet for a prediction on a different thread each time causes a GPU memory leak,2018-10-09 20:56:01+00:00,,0,5,"[Label(name=""caffe2"")]"
12498,Support calculating grad for dense in sparse @ dense ,2018-10-09 20:42:53+00:00,,1,6,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
12484,CuDNN convolution on some CUDA devices will not preserve NaN weights (upstream bug),2018-10-09 15:50:30+00:00,,0,14,"[Label(name=""module: dependency bug""), Label(name=""module: cudnn""), Label(name=""low priority""), Label(name=""triaged"")]"
12482,[Feature request]:  add `LayerNormLSTMCell`,2018-10-09 12:27:01+00:00,,0,4,"[Label(name=""module: rnn""), Label(name=""triaged"")]"
12461,Certain operations cause implicity sync-points,2018-10-08 18:44:14+00:00,,0,5,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
12460,"input_device, output_device, devices_used properties",2018-10-08 18:32:05+00:00,,0,2,"[Label(name=""module: nn""), Label(name=""triaged"")]"
12449,"Could not find a package configuration file provided by ""Torch"" with any of   the following names:",2018-10-08 08:15:55+00:00,,0,36,"[Label(name=""module: cpp-extensions""), Label(name=""triaged"")]"
12435,`pstrf` on positive semi-definite matrices,2018-10-07 14:28:37+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""function request"")]"
12401,AttributeError: Method VideoInput is not a registered operator,2018-10-05 21:37:35+00:00,,0,4,"[Label(name=""caffe2"")]"
12322,[Caffe2] Segmentation fault (core dumped) while import caffe2.python.core,2018-10-04 12:39:39+00:00,,0,2,"[Label(name=""caffe2"")]"
12308,nn.functional.linear() for sparse tensor,2018-10-04 00:00:54+00:00,,0,9,"[Label(name=""module: sparse""), Label(name=""module: nn""), Label(name=""triaged"")]"
12297,[caffe2] Inference using multiple GPU,2018-10-03 21:34:49+00:00,,0,0,"[Label(name=""caffe2"")]"
12280,`GLIBC_2.23' not found on Ubuntu14.04.,2018-10-03 10:44:20+00:00,,0,0,"[Label(name=""caffe2"")]"
12257,[Caffe2] Relink error after installing Caffe2 from conda,2018-10-02 09:01:03+00:00,,0,0,"[Label(name=""caffe2"")]"
12248,.cuda() changes a module's behavior when there are registered buffers with requires_grad=True,2018-10-02 03:21:12+00:00,,0,8,"[Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
12189,[Feature] Support Adaptive Max Gradient Norm / Clipping,2018-09-29 00:11:13+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: norms and normalization"")]"
12181,Network surgery for transfer fails,2018-09-28 20:37:56+00:00,,0,0,"[Label(name=""caffe2"")]"
12159,clip_grad_norm_ does not work on grads of different types,2018-09-28 05:41:02+00:00,,0,0,"[Label(name=""todo""), Label(name=""module: nn""), Label(name=""triaged"")]"
12146,Misleading step method in lr_scheduler.ReduceLROnPlateau,2018-09-27 21:46:48+00:00,,0,1,"[Label(name=""todo""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
12136,[Caffe2] GAN No Gradients in Generator,2018-09-27 13:08:25+00:00,,0,1,"[Label(name=""caffe2"")]"
12134,[caffe2] How to set different learning rates for different layers?,2018-09-27 12:18:43+00:00,,0,0,"[Label(name=""caffe2"")]"
12117,"Error: Internal Compiler Error (codegen): ""there was an error in verifying the lgenfe output!""",2018-09-26 21:00:05+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""internals"")]"
12086,Caffe2 issues with using Glog without GFlags,2018-09-26 14:31:27+00:00,,0,0,"[Label(name=""caffe2"")]"
12069,Stop using make_intrusive directly; provide some make_tensor,2018-09-25 21:10:21+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""triaged"")]"
12060,cuda test hangs if GPUs in Exclusive Process mode,2018-09-25 18:47:26+00:00,,0,0,"[Label(name=""todo""), Label(name=""module: cuda""), Label(name=""triaged"")]"
12045,Create a custom function using the functions from math_cpu.cc source code in Caffe2?,2018-09-25 11:33:44+00:00,,0,4,"[Label(name=""caffe2"")]"
12010,Caffe2 compiled with MKLDNN doesn't have device_type = MKLDNN,2018-09-24 11:58:10+00:00,,0,0,"[Label(name=""caffe2"")]"
12007,caffe2's installation is still problematic...,2018-09-24 09:34:16+00:00,,0,3,"[Label(name=""caffe2"")]"
11996,Test the Caffe2 Installation with GPU erro,2018-09-23 15:30:59+00:00,,0,0,"[Label(name=""caffe2"")]"
11982,[feature request] Publish wheels with debug symbols,2018-09-22 19:43:08+00:00,,0,12,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
11980,[Enhancement] Increase user-friendliness of dataset.random_split,2018-09-22 18:36:55+00:00,,0,6,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data"")]"
11978,[Caffe2] Attempting to install Caffe2 in Google Colab,2018-09-22 17:43:12+00:00,,0,7,"[Label(name=""caffe2"")]"
11976,[caffe2] Documentation of Optimizers (Python API),2018-09-22 15:57:13+00:00,,0,0,"[Label(name=""caffe2"")]"
11974,Specify out= argument to convolution,2018-09-22 13:56:42+00:00,,0,5,"[Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement"")]"
11967,Jit cannot trace autograd for certain operator,2018-09-22 05:53:14+00:00,,0,1,"[Label(name=""oncall: jit"")]"
11951,dtype mismatch error messages can be misleading,2018-09-21 21:33:38+00:00,,0,4,"[Label(name=""todo""), Label(name=""module: error checking""), Label(name=""module: molly-guard""), Label(name=""triaged"")]"
11937,[feature request] Kumaraswamy distribution,2018-09-21 15:57:18+00:00,,0,4,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
11936,torch.bmm doesn't support CUDA uint8 (byte) tensor,2018-09-21 15:49:16+00:00,,0,9,"[Label(name=""todo""), Label(name=""module: bootcamp""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: linear algebra"")]"
11890,caffe2 argmax and argmin documentation incorrect for output type,2018-09-20 15:23:31+00:00,,0,0,"[Label(name=""caffe2"")]"
11885,[caffe2] Bug for softmaxwithloss operator,2018-09-20 06:28:12+00:00,,0,0,"[Label(name=""caffe2"")]"
11869,[caffe2] Unaligned AVX instruction operands in LayerNorm implementation in OSS build,2018-09-19 18:09:49+00:00,,0,0,"[Label(name=""caffe2"")]"
11865,[Caffe2] Errors occured when running Cpp Predictor,2018-09-19 17:42:36+00:00,,0,5,"[Label(name=""caffe2"")]"
11861,[Caffe2 installation problem],2018-09-19 12:30:42+00:00,,0,4,"[Label(name=""caffe2"")]"
11854,error: ‘array_size’ is not a class template,2018-09-19 08:22:42+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cpp""), Label(name=""triaged"")]"
11850,[Caffe2/Bug] Cannot enable MKL-DNN,2018-09-19 02:00:52+00:00,,0,5,"[Label(name=""caffe2"")]"
11793,DataParallel: Parallel_apply assert len(modules) == len(inputs) AssertionError,2018-09-18 08:16:58+00:00,,0,5,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
11791,[caffe2]Can i build caffe2 library only for cpu inference purpose and reduce the binary size?,2018-09-18 07:28:40+00:00,,0,1,"[Label(name=""caffe2"")]"
11790,set num_workers on the dataloader make the jupyter kernel crash at the almost end of the epoch ,2018-09-18 07:10:15+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
11786,Mysterious error due to num_workers: 1,2018-09-18 04:39:45+00:00,,0,6,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
11735,Caffe2 installation:  libcaffe2_gpu.so: undefined reference to `caffe2::ClipTransformRGB,2018-09-16 01:34:53+00:00,,1,5,"[Label(name=""caffe2"")]"
11727,Semaphore leaks in dataloader,2018-09-15 03:07:32+00:00,,0,8,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
11678,[caffe2] adam_op implementation is incorrect.,2018-09-14 00:32:47+00:00,,0,0,"[Label(name=""caffe2"")]"
11645,One GPU is more memory efficient than Multiple GPUs,2018-09-13 16:38:37+00:00,,0,1,"[Label(name=""module: multi-gpu""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
11636,undefined reference to caffe2,2018-09-13 13:40:07+00:00,,0,1,"[Label(name=""caffe2"")]"
11635,[Feature request] Advanced indexing in functions like `expand`,2018-09-13 12:59:37+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: advanced indexing"")]"
11633,DataLoader: Could not wrapper a exception in threads,2018-09-13 12:26:29+00:00,,0,2,"[Label(name=""module: dataloader""), Label(name=""module: error checking""), Label(name=""triaged"")]"
11624,Add min mode to embedding bags,2018-09-13 03:50:48+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
11612,[feature request] Triangular Matrix Representation,2018-09-13 00:08:09+00:00,,0,4,"[Label(name=""feature""), Label(name=""triaged"")]"
11578,Request to import pytest in test/*.py,2018-09-12 16:50:40+00:00,,1,22,"[Label(name=""module: tests""), Label(name=""triaged"")]"
11551,"CrossEntropyLoss, ignore_index does not prevent back-prop if the logits are -inf",2018-09-11 21:29:27+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
11537,"[CLEANUP] Context functions should return TypeExtendedInterface, not Type",2018-09-11 19:54:31+00:00,,0,0,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
11532,[JIT][tracer] Slicing shape is specialized to tensor rank,2018-09-11 18:24:52+00:00,,0,0,"[Label(name=""oncall: jit"")]"
11516,at::Device makes it very easy to write buggy code,2018-09-11 15:16:58+00:00,,0,4,"[Label(name=""triaged""), Label(name=""better-engineering"")]"
11514,[feature request] - Allow sequences lengths to be 0 in PackSequence,2018-09-11 10:00:49+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""enhancement"")]"
11496,"Tests with ""."" in the name cannot be run standalone",2018-09-11 00:13:42+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
11451,[caffe2] caffe2 openmp linking error with xcode 9.0(AppleClang 9.0) on mac,2018-09-10 09:27:55+00:00,,0,2,"[Label(name=""caffe2"")]"
11439,High leverage TH operations to port to ATen,2018-09-09 17:33:25+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: porting""), Label(name=""better-engineering""), Label(name=""module: tensor creation"")]"
11433,Assorted issues in Caffe2's Metal ops,2018-09-09 07:19:18+00:00,,0,0,"[Label(name=""caffe2"")]"
11426,[Feature request] Intuitive error message when input to Linear is not cudarized,2018-09-08 15:54:26+00:00,,0,1,"[Label(name=""module: error checking""), Label(name=""triaged"")]"
11390,Views created in no_grad block still have requires_grad=True,2018-09-07 18:23:56+00:00,,1,21,"[Label(name=""high priority""), Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged"")]"
11389,[distributions] Torch distribution samplers slow on expanded parameters,2018-09-07 18:08:15+00:00,,0,0,"[Label(name=""todo""), Label(name=""module: distributions""), Label(name=""triaged"")]"
11372,Suggest: DataLoader add device parameter ,2018-09-07 07:47:04+00:00,,0,8,"[Label(name=""todo""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
11363,Hypothesis operator tests in Caffe2 generate too many warnings,2018-09-07 02:22:20+00:00,,0,1,"[Label(name=""caffe2"")]"
11354,caffe2 failed to build from source,2018-09-07 00:02:09+00:00,,0,8,"[Label(name=""caffe2"")]"
11340,Better user experience for using Generator object,2018-09-06 18:27:52+00:00,,1,16,"[Label(name=""todo""), Label(name=""module: docs""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: random"")]"
11324,Why does DistributedDataSampler not use default RNG?,2018-09-06 06:13:36+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
11268,How to re-shuffle lmdb per epoch in the caffe2 training process,2018-09-05 06:19:01+00:00,,0,0,"[Label(name=""caffe2"")]"
11267,How to simulate multi-node using single-node with 8 GPUs,2018-09-05 06:18:21+00:00,,0,0,"[Label(name=""caffe2"")]"
11213,Ubuntu 16.04 setup.py error - undefined reference to elfLink_Get_FatBinary_From_Object' /usr/lib/x86_64-linux-gnu/libcuda.so: undefined reference to elf32_section_header',2018-09-04 12:41:16+00:00,,0,23,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: undefined reference"")]"
11202,[pytorch][feature request] Cosine distance / simialrity between samples of own tensor or two tensors,2018-09-03 14:40:43+00:00,,0,21,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""function request""), Label(name=""module: distance functions"")]"
11197,[Caffe2] How to correctly add Caffe2 libraries to Visual Studio to write C++ programs?,2018-09-03 08:02:17+00:00,,0,0,"[Label(name=""caffe2"")]"
11180,A Caffe2 Implementation of Pose Estimation,2018-09-01 22:47:51+00:00,,0,0,"[Label(name=""caffe2"")]"
11119,[Caffe2] Error C2492: data with thread storage duration may not have dll interface,2018-08-30 23:44:06+00:00,,0,0,"[Label(name=""caffe2"")]"
11113,use_system_nccl flag does not work?,2018-08-30 22:09:37+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
11072,[...] operator for masked select does not broadcast anymore,2018-08-30 09:28:13+00:00,,0,1,"[Label(name=""todo""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
11071,undefined reference to 'caffe2::Caffe2FlagsRegistry[abi:cxx11]()',2018-08-30 08:29:35+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
11062,"non-shuffling data loaders can affect random states, thus the results of shuffling data loaders.",2018-08-30 02:56:33+00:00,,0,3,"[Label(name=""todo""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
11058, A bug in roi_align.cc? [Caffe2],2018-08-30 02:27:45+00:00,,0,1,"[Label(name=""caffe2"")]"
10996,Multiprocess Deadlock when using np.transpose and torch.stack ,2018-08-29 12:46:09+00:00,,0,12,"[Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
10991,Error when building ,2018-08-29 08:12:00+00:00,,0,4,"[Label(name=""caffe2"")]"
10990,[Caffe2] [Question] How to disable the bias parameter?,2018-08-29 07:33:20+00:00,,0,0,"[Label(name=""caffe2"")]"
10985,Where could I see all of the caffe2 operators and their arguments in python API?,2018-08-29 03:00:38+00:00,,0,2,"[Label(name=""caffe2"")]"
10984,[caffe2] Implement Gather for any value of `axis`,2018-08-29 02:57:33+00:00,,0,0,"[Label(name=""caffe2"")]"
10978,[feature request] padding for torch.cat ,2018-08-28 22:01:36+00:00,,1,10,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: viewing and reshaping"")]"
10956,Better dev docs for writing native CPU kernels with Vec256,2018-08-28 16:50:38+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vectorization"")]"
10950,Cannot run torch in different sub-interpreters,2018-08-28 15:59:18+00:00,,0,0,"[Label(name=""todo""), Label(name=""needs reproduction""), Label(name=""module: cpp""), Label(name=""triaged"")]"
10940,[Caffe2] Model work Alright in Python but Failed in C++,2018-08-28 10:09:21+00:00,,0,2,"[Label(name=""caffe2"")]"
10913,Cannot find operator schema for 'ATen' Caffe2 Ios,2018-08-27 20:35:24+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""triaged"")]"
10902,LNK2019 error when linking with MSVC [Caffe2],2018-08-27 14:51:00+00:00,,0,4,"[Label(name=""caffe2"")]"
10875,how can i run two model in a simple project?,2018-08-25 09:06:04+00:00,,0,3,"[Label(name=""caffe2"")]"
10818,[Caffe2] Can't load pretrained model,2018-08-23 11:06:29+00:00,,0,0,"[Label(name=""caffe2"")]"
10808,[Feature Request] Crop op or ConvTranspose with output_shape,2018-08-23 02:47:57+00:00,,0,2,"[Label(name=""caffe2"")]"
10800,[distributed] Synchronization on CUDA side with MPI backend,2018-08-22 22:41:41+00:00,,0,0,"[Label(name=""oncall: distributed""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: c10d""), Label(name=""distributed-backlog"")]"
10756,Unexpected Behavior when Pointwise Operations Write to Expanded Tensors,2018-08-21 23:10:22+00:00,,0,8,"[Label(name=""module: internals""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: partial aliasing"")]"
10746,[Caffe2] Failed to build dispatch_test. Error LNK2001: unresolved external symbol,2018-08-21 19:11:09+00:00,,0,0,"[Label(name=""caffe2"")]"
10738,[caffe2] the caffe2 operators document is too old,2018-08-21 17:24:18+00:00,,0,0,"[Label(name=""caffe2"")]"
10735,Have all C++ modules expose a __file__ attribute,2018-08-21 17:11:23+00:00,,0,8,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""enhancement"")]"
10719,size mismatch when trying to reconstruct predifined network,2018-08-21 03:26:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: vision"")]"
10714,[feature request][caffe2] extend FC/FCTranspose op to handle 2d bias.,2018-08-21 01:33:09+00:00,,0,2,"[Label(name=""caffe2"")]"
10691,Build system doesn't prevent ATen/core from including non-core files,2018-08-20 18:05:58+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
10685,[feature request] convtbc with group convolution,2018-08-20 14:44:06+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: convolution""), Label(name=""triaged"")]"
10684,make install error： [third_party/gloo/gloo/CMakeFiles/gloo.dir/all] Error 2,2018-08-20 14:22:27+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: third_party"")]"
10683,Tensor.register_hook is not passing the tensor object to the hook function,2018-08-20 14:03:44+00:00,,0,3,"[Label(name=""module: bc-breaking""), Label(name=""triaged""), Label(name=""enhancement"")]"
10675,GenerateProposals CUDA implementation,2018-08-20 02:17:58+00:00,,0,4,"[Label(name=""caffe2"")]"
10667,[Caffe2] Error importing ConvTranspose2d to Caffe2 with ONNX,2018-08-19 18:11:12+00:00,,0,2,"[Label(name=""caffe2"")]"
10615,Request for better memory management,2018-08-17 10:38:47+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
10604,"Bilinear interpolation behavior inconsistent with TF, CoreML and Caffe",2018-08-17 00:45:34+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: interpolation"")]"
10582,[Caffe2] Unable to use MPI rendezvous in Caffe2,2018-08-16 14:50:46+00:00,,0,3,"[Label(name=""caffe2"")]"
10577,[BUG]: unstable happend in saving model.,2018-08-16 04:48:09+00:00,,0,13,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
10573,[Caffe2] Error C2375 when building DLL. ,2018-08-16 03:18:19+00:00,,0,0,"[Label(name=""caffe2"")]"
10536,[feature request] Adding Pre and Post padding functionalities to pad_sequence function,2018-08-15 10:00:24+00:00,,0,6,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: padding"")]"
10515,[Caffe2] Segmentation faults in multithreading Caffe2,2018-08-14 20:40:06+00:00,,0,7,"[Label(name=""caffe2"")]"
10482,Reduce code duplication in interpolate and make it more generic,2018-08-13 19:34:03+00:00,,1,15,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: interpolation"")]"
10471,[Caffe2] Multithreading in Caffe2,2018-08-13 17:27:05+00:00,,0,4,"[Label(name=""caffe2"")]"
10464,caffe2 CI does not test header install,2018-08-13 15:42:10+00:00,,0,0,"[Label(name=""caffe2"")]"
10461,Key already registered. Offending key: caffe2_print_stacktraces.,2018-08-13 15:01:55+00:00,,0,0,"[Label(name=""caffe2"")]"
10460,Type name float registered twice. This should not happen. Do you have duplicated CAFFE_KNOWN_TYPE?,2018-08-13 14:42:04+00:00,,0,0,"[Label(name=""caffe2"")]"
10454,[feature request] Rank-Revealing QR - Adding dgeqp3 support to torch.qr,2018-08-13 08:48:59+00:00,,0,4,"[Label(name=""todo""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""actionable"")]"
10440,"[caffe2] enforce fail at context_gpu.cu:285, cannot get GPU memory usage statistics",2018-08-11 20:44:09+00:00,,0,0,"[Label(name=""caffe2"")]"
10396,"[feature request] Provide a way to redirect shared memory prefix ""/torch_""",2018-08-10 07:13:32+00:00,,0,5,"[Label(name=""triaged""), Label(name=""enhancement"")]"
10386,[feature request] batch_first option in torch.utils.data,2018-08-09 21:23:11+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
10377,[Docs] Update broadcasting documentation for scalars / n-dimensional empty tensors,2018-08-09 14:08:34+00:00,,0,3,"[Label(name=""todo""), Label(name=""module: docs""), Label(name=""triaged"")]"
10375,"Sending CUDA tensor to process, and then back, does not work",2018-08-09 13:17:34+00:00,,0,10,"[Label(name=""module: bootcamp""), Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged"")]"
10342,[Caffe2] which kind of database can I read from caffe2,2018-08-08 03:29:32+00:00,,0,0,"[Label(name=""caffe2"")]"
10341,[Caffe2] Which document should we follow to install caffe2?,2018-08-08 03:01:19+00:00,,0,1,"[Label(name=""caffe2"")]"
10314,[Caffe2] ConvPoolOpBase operator,2018-08-07 17:04:25+00:00,,0,0,"[Label(name=""caffe2"")]"
10298,[feature request] Runtime warning for inappropriate labels (among others),2018-08-07 12:38:14+00:00,,1,5,"[Label(name=""module: loss""), Label(name=""module: error checking""), Label(name=""triaged"")]"
10256,[Caffe 2] How to access/remove Blobs from Workspace?,2018-08-06 08:48:38+00:00,,0,0,"[Label(name=""caffe2"")]"
10254,"[Caffe2] I don't knw whether GPU support is right, is there something wrong with Hypothesis?",2018-08-06 07:57:13+00:00,,0,4,"[Label(name=""caffe2"")]"
10249,pytorch does not compatible with caffe2,2018-08-06 03:36:14+00:00,,0,10,"[Label(name=""caffe2"")]"
10232,[Caffe2] AVX not enabled for pytorch/caffe2,2018-08-04 05:39:36+00:00,,0,3,"[Label(name=""caffe2"")]"
10215,[Caffe2] Build failure on Ubuntu 16.04,2018-08-03 19:15:45+00:00,,0,7,"[Label(name=""caffe2"")]"
10176,[Caffe2] Modelling using Ops instead of Helper Functions,2018-08-02 19:46:49+00:00,,0,0,"[Label(name=""caffe2"")]"
10172,"[Feature request] Batch eig/symeig functions (for small matrices, with CUDA)",2018-08-02 18:38:23+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: batching""), Label(name=""module: linear algebra""), Label(name=""function request"")]"
10170,build error,2018-08-02 18:14:45+00:00,,0,0,"[Label(name=""caffe2"")]"
10165,torch.utils.data.random_split() returns dataset index as tensor,2018-08-02 15:24:20+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
10161,error when building caffe2 from source with gcc 7 & cuda gcc 5.5,2018-08-02 08:42:21+00:00,,0,3,"[Label(name=""caffe2"")]"
10155,"""No module named 'tools.setup_helpers'"" when use pip install caffe2",2018-08-02 03:42:59+00:00,,0,4,"[Label(name=""caffe2"")]"
10119,"[Caffe2] MNIST Tutorial LMDB Error ""Cannot open db"" ",2018-08-01 14:41:50+00:00,,0,21,"[Label(name=""caffe2"")]"
10088,[Caffe2]  Implementing CoordConv layer,2018-07-31 20:23:21+00:00,,0,3,"[Label(name=""caffe2"")]"
10070,UnicodeDecodeError while loading caffe2 model,2018-07-31 13:31:00+00:00,,0,3,"[Label(name=""caffe2"")]"
10062,Does this mean onnx do not support spatialBN operator?,2018-07-31 08:32:32+00:00,,0,8,"[Label(name=""caffe2"")]"
10043,Sparse tensor use cases,2018-07-31 01:06:25+00:00,,0,83,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
10007,Upgrade Caffe2 Hypothesis,2018-07-30 15:35:10+00:00,,0,1,"[Label(name=""caffe2"")]"
10006,RNN gradients in eval mode in pytorch 0.4,2018-07-30 14:42:09+00:00,,0,10,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
9983,[feature request] Add matrix functions,2018-07-29 03:25:01+00:00,,1,85,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: linear algebra""), Label(name=""function request"")]"
9975,python caffe2/python/operator_test/activation_ops_test.py  Segmentation fault (core dumped),2018-07-28 14:38:48+00:00,,0,2,"[Label(name=""caffe2"")]"
9952,[feature request] Add COCOB Optimizer,2018-07-27 20:47:25+00:00,,0,4,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""function request"")]"
9950,Stop passing inplace/out arguments as (non-const) Tensor& to functions,2018-07-27 20:03:20+00:00,,0,0,"[Label(name=""module: internals""), Label(name=""module: cpp""), Label(name=""triaged""), Label(name=""enhancement"")]"
9945,WERROR=1 doesn't work with FULL_CAFFE2,2018-07-27 19:01:16+00:00,,0,0,"[Label(name=""caffe2"")]"
9921,A serious problem when installing caffe2. Can anyone  help me?,2018-07-27 05:58:10+00:00,,0,7,"[Label(name=""caffe2"")]"
9912,Stop ifdef'ing out scatter/gather (comm) in libtorch,2018-07-26 23:46:30+00:00,,0,1,"[Label(name=""module: cpp""), Label(name=""module: cuda""), Label(name=""triaged"")]"
9910,CRITICAL:root:Cannot load caffe2.python. Error: DLL load failed: A dynamic link library (DLL) initialization routine failed.,2018-07-26 23:04:26+00:00,,0,0,"[Label(name=""caffe2"")]"
9898,[Feature Request] Checkpoint manager,2018-07-26 19:43:40+00:00,,1,3,"[Label(name=""feature""), Label(name=""triaged"")]"
9894,[docs] Script for releasing new versions of the docs,2018-07-26 18:57:52+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""triaged"")]"
9893,interaction with FindCUDA causes spurious re-cmakes,2018-07-26 18:31:21+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
9886,[doc] functionalities not documented,2018-07-26 17:41:35+00:00,,0,20,"[Label(name=""module: docs""), Label(name=""good first issue""), Label(name=""triaged"")]"
9883,NetTest.OperatorWithExecutorHelper intermittently hangs,2018-07-26 17:08:48+00:00,,0,0,"[Label(name=""caffe2"")]"
9882,Unintuitive reduction of mini-batch loss for NLLLoss,2018-07-26 16:47:03+00:00,,1,1,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
9881,cannot open caffe2.lib in VS2015 debug mode,2018-07-26 15:20:53+00:00,,0,0,"[Label(name=""caffe2"")]"
9875,onnx to caffe2 err,2018-07-26 12:08:54+00:00,,0,0,"[Label(name=""caffe2"")]"
9873,"Pytorch is slow when only using CPU, and cannot utilize multicore of CPU",2018-07-26 10:52:00+00:00,,0,24,"[Label(name=""module: performance""), Label(name=""module: cpu""), Label(name=""triaged""), Label(name=""module: multithreading"")]"
9867,How can I sure that I run caffe2 with GPU,2018-07-26 07:24:39+00:00,,0,1,"[Label(name=""caffe2"")]"
9854,TestConvolution.test_conv_separate_stride_pad_gradients failing,2018-07-26 00:40:42+00:00,,0,1,"[Label(name=""caffe2"")]"
9853,TestSequenceOps.test_gather_padding failing,2018-07-26 00:39:07+00:00,,0,1,"[Label(name=""caffe2"")]"
9833,RecurrentNetworkTest.test_sum_mul flaky on master,2018-07-25 18:37:47+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""module: flaky-tests""), Label(name=""better-engineering"")]"
9832,TestReduceFrontSum.test_col2im_gradients flaky,2018-07-25 18:31:35+00:00,,0,1,"[Label(name=""caffe2""), Label(name=""module: flaky-tests""), Label(name=""better-engineering"")]"
9797,Build torch as a submodule with static linking doesn't work (CAFFE2_PERF_WITH_AVX2 is not defined),2018-07-25 00:14:16+00:00,,1,4,"[Label(name=""caffe2""), Label(name=""module: static linking"")]"
9761,[caffe2] Questions about conv_transpose && ConvTranspose,2018-07-24 14:31:44+00:00,,0,10,"[Label(name=""caffe2"")]"
9753,dataloader stuck at sched_yield =0,2018-07-24 09:11:48+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
9708,"[caffe2]mpirun multi-node multi GPU in Distributed mode ,run resnet50_trainer.py get RuntimeError",2018-07-23 13:19:10+00:00,,0,6,"[Label(name=""caffe2"")]"
9707,"[caffe2]mpirun multi-node multi GPU in Distributed mode ,run resnet50_trainer.py get RuntimeError",2018-07-23 13:18:38+00:00,,0,0,"[Label(name=""caffe2"")]"
9704,"A newer protobuf should be used, so that cmake install will work when building for mobile",2018-07-23 04:52:19+00:00,,1,4,"[Label(name=""caffe2"")]"
9701,[request] speed-up multidim slicing backward,2018-07-23 04:20:40+00:00,,0,5,"[Label(name=""todo""), Label(name=""module: performance""), Label(name=""module: autograd""), Label(name=""triaged"")]"
9699,[Build error] libcudnn.so: error adding symbols: File in wrong format,2018-07-23 02:22:25+00:00,,0,6,"[Label(name=""caffe2"")]"
9681,[feature request] Support for 0-length sequences in packed_sequences,2018-07-21 18:26:23+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
9678,Remove BatchNorm layers once the training is completed.,2018-07-21 12:29:41+00:00,,0,5,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
9676,"[caffe2]running problem,  No module named caffe2_pybind11_state_hip",2018-07-21 07:10:55+00:00,,1,2,"[Label(name=""caffe2"")]"
9674,The state of sparse Tensors,2018-07-21 04:03:19+00:00,,0,37,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
9624,Request: Pycuda interoperability,2018-07-20 13:40:42+00:00,,0,5,"[Label(name=""feature""), Label(name=""triaged"")]"
9604,WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode. CRITICAL:root:Cannot load caffe2.python. Error: libcaffe2.so: cannot open shared object file: No such file or directory,2018-07-19 21:20:38+00:00,,1,7,"[Label(name=""caffe2"")]"
9595,[JIT] Unify python -> SugaredValue construction + fix inlining of graphs with Tuple-typed inputs,2018-07-19 18:49:28+00:00,,0,0,"[Label(name=""oncall: jit"")]"
9570,[feature request] More options for Fractional Max Pooling,2018-07-18 22:21:27+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: pooling"")]"
9563,batch_sampler/test_worker_seed intermittently fails with address already in use on OS X,2018-07-18 20:57:32+00:00,,0,2,"[Label(name=""todo""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
9560,Incorrect term in _LRScheduler.,2018-07-18 20:18:51+00:00,,0,5,"[Label(name=""todo""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
9559,[feature request] Rename `Subset` -> `Resample` to reflect wider use,2018-07-18 20:16:46+00:00,,0,2,"[Label(name=""todo""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
9531,[caffe2]train on GPU and test on cpu failed,2018-07-18 11:52:22+00:00,,0,1,"[Label(name=""caffe2"")]"
9484,WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode. WARNING:root:Debug message: libcurand.so.9.0: cannot open shared object file: No such file or directory Segmentation fault (core dumped),2018-07-17 05:58:23+00:00,,0,5,"[Label(name=""caffe2"")]"
9461,Windows CPU version much slower than Unix versions,2018-07-16 01:13:57+00:00,,0,17,"[Label(name=""module: windows""), Label(name=""triaged"")]"
9449,PredictorTest.SimpleBatchSizedMapInput intermittently hangs,2018-07-14 18:50:22+00:00,,0,3,"[Label(name=""caffe2"")]"
9445,Build error: flat_hash_map.h(226) C2133,2018-07-14 15:37:06+00:00,,0,4,"[Label(name=""caffe2"")]"
9381,[doc] many losses still mention size_average in formula,2018-07-12 11:47:05+00:00,,1,0,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""module: deprecation"")]"
9375,[Caffe2] Not handle attribute 'spatial' of ONNX operator 'BatchNormalization',2018-07-12 04:12:05+00:00,,0,3,"[Label(name=""caffe2"")]"
9349,[Caffe2] Can't find Caffe2<->ONNX conversion tools,2018-07-11 16:57:39+00:00,,0,0,"[Label(name=""caffe2"")]"
9310,/usr/bin/ld: cannot find -lpthreads,2018-07-10 17:23:58+00:00,,0,8,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""has workaround"")]"
9286,Accumulate into accreal instead of real for CPU loss functions,2018-07-09 21:08:59+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
9282,[gradcheck] warn about the case that mulitple inputs share storage,2018-07-09 19:56:27+00:00,,1,1,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
9250,[feature request] SSIM-based cost function as part of the standard set of loss functions,2018-07-09 02:59:11+00:00,,0,6,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""enhancement"")]"
9222,[feature request] Implementing Block Sparse Operations,2018-07-06 21:59:51+00:00,,0,20,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
9218,[Caffe2] Cannot load caffe2.python. Error: libcaffe2.so: cannot open shared object file: No such file or directory,2018-07-06 21:11:29+00:00,,1,5,"[Label(name=""caffe2"")]"
9208,[Caffe2] compiling error with gcc-6,2018-07-06 14:53:18+00:00,,0,4,"[Label(name=""caffe2"")]"
9207,Where is the include and lib path for caffe2?,2018-07-06 14:44:20+00:00,,1,2,"[Label(name=""caffe2"")]"
9204,/usr/bin/ld: cannot find -lpthreads,2018-07-06 09:17:34+00:00,,1,2,"[Label(name=""caffe2"")]"
9193,[Feature Request] Additional torch.nn.LSTM functionality,2018-07-05 21:18:55+00:00,,0,3,"[Label(name=""todo""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""enhancement"")]"
9186,[pytorch] Make dtype second positional argument of tensor factory methods,2018-07-05 15:09:42+00:00,,0,4,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: pybind""), Label(name=""module: ux"")]"
9174,[Caffe2] build_ios.sh => 'is only available on iOS 11 or newer',2018-07-05 01:03:44+00:00,,0,1,"[Label(name=""caffe2"")]"
9171,Mismatch in behaviour of WeightedRandomSampler and other samplers,2018-07-04 20:55:46+00:00,,0,3,"[Label(name=""todo""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
9166,nvcc fatal : A single input file is required for a non-link phase when an outputfile is specified,2018-07-04 11:04:33+00:00,,1,1,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""caffe2"")]"
9150,[caffe2] Drop connections,2018-07-03 22:53:32+00:00,,0,0,"[Label(name=""caffe2"")]"
9137,ObserverTest.TestMultipleNetBase intermittently segfaults,2018-07-03 14:21:44+00:00,,1,1,"[Label(name=""caffe2"")]"
9133,[Caffe2] Error running net train when running resnet50,2018-07-03 13:30:27+00:00,,0,0,"[Label(name=""caffe2"")]"
9098,[caffe2] how to substract the mean value ?,2018-07-02 08:16:53+00:00,,0,0,"[Label(name=""caffe2"")]"
9068,Deployment for ios for 1.0,2018-06-30 17:57:28+00:00,,0,3,"[Label(name=""caffe2"")]"
9046,[feature request] freeze() for nn.Module,2018-06-29 20:51:14+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""enhancement"")]"
9032,Lint check for non-Unicode characters in diffs / Unicode characters without coding,2018-06-29 14:47:12+00:00,,0,0,"[Label(name=""module: lint""), Label(name=""triaged""), Label(name=""better-engineering"")]"
9029,DataWorkersTest::testRNNInput timeout,2018-06-29 13:46:54+00:00,,0,1,"[Label(name=""caffe2"")]"
9028,"[caffe2]build problem, can not find caffe2_pybind11_state_hip",2018-06-29 13:35:25+00:00,,1,9,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""caffe2"")]"
9026,(CAFFE_ENFORCE_EQ_WITH_CALLER tensor.h) caffe2 C++ windows10  runtime error! ,2018-06-29 11:36:05+00:00,,0,5,"[Label(name=""caffe2"")]"
9024,cmake error:Could NOT find IDEEP (missing:  /usr/local/include) ,2018-06-29 10:08:03+00:00,,2,6,"[Label(name=""caffe2"")]"
9016,SimpleMetaNetDefInitializer intermittently hangs,2018-06-29 04:10:43+00:00,,0,4,"[Label(name=""caffe2"")]"
9003,cmake error,2018-06-28 21:54:45+00:00,,1,1,"[Label(name=""caffe2"")]"
8984,[Caffe2] segmentation fault,2018-06-28 14:49:16+00:00,,1,1,"[Label(name=""caffe2"")]"
8982,parallelize_bmuf_distributed_test intermittently hangs,2018-06-28 13:32:26+00:00,,0,3,"[Label(name=""caffe2"")]"
8979,Check failed: error == cudaSuccess unspecified launch failure [caffe2],2018-06-28 07:45:15+00:00,,0,0,"[Label(name=""caffe2"")]"
8944,[caffe2] UnicodeDecodeError when running LeNet,2018-06-27 17:09:24+00:00,,1,3,"[Label(name=""caffe2"")]"
8937,[caffe2] Is there any method to implement learning rate scheduler?,2018-06-27 13:31:51+00:00,,0,0,"[Label(name=""caffe2"")]"
8921,[feature request] More methods for PackedSequence,2018-06-26 22:32:21+00:00,,0,7,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
8913,Multiprocessing Self Test Error,2018-06-26 20:59:55+00:00,,0,3,"[Label(name=""todo""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
8902,[Caffe 2] Does caffe2 support Galaxy 5S with Android 6? ,2018-06-26 17:56:12+00:00,,0,0,"[Label(name=""caffe2"")]"
8886,[Caffe2] Dose caffe2 support the function similar to itersize of caffe ,2018-06-26 02:10:01+00:00,,0,3,"[Label(name=""caffe2"")]"
8874,Issues with dynamically created grad_fn for views,2018-06-25 22:22:41+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: viewing and reshaping"")]"
8871,Use target_compile_options to set warning flags,2018-06-25 21:47:30+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
8853,Todo functions and autograd supports for Sparse Tensor,2018-06-25 17:23:07+00:00,,1,21,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
8837,Inconsistency in implementation of _LRScheduler ,2018-06-25 02:11:05+00:00,,0,0,"[Label(name=""module: nn""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
8821,Storages still use legacy printing,2018-06-23 14:15:08+00:00,,0,2,"[Label(name=""module: printing""), Label(name=""triaged"")]"
8818,MPI causing job to hang --- unresponsive to external (termination) signals,2018-06-23 02:32:03+00:00,,0,1,"[Label(name=""oncall: distributed"")]"
8760,[JIT] Add peephole to delete unnecessary type_as.,2018-06-21 20:06:26+00:00,,0,0,"[Label(name=""oncall: jit"")]"
8741,[Feature Request] Add to() method for optimizers/schedulers,2018-06-21 08:21:29+00:00,,1,6,"[Label(name=""todo""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
8730,[caffe2] AffineChannelOp,2018-06-21 03:13:06+00:00,,0,1,"[Label(name=""caffe2"")]"
8650,Cannot use IterOp at runtime CUDA&CPU,2018-06-19 11:07:43+00:00,,0,1,"[Label(name=""caffe2"")]"
8648,Cannot allocate memory Error from operator,2018-06-19 08:00:28+00:00,,0,0,"[Label(name=""caffe2"")]"
8607,[Caffe2] Wrong prediction with simple FF,2018-06-18 16:31:04+00:00,,0,0,"[Label(name=""caffe2"")]"
8602,Come with a better strategy for TensorArg (error reporting),2018-06-18 14:38:37+00:00,,0,1,"[Label(name=""module: performance""), Label(name=""module: internals""), Label(name=""triaged"")]"
8595,[Caffe2] How to build caffe2/mobile/ulp2/ulp_test?,2018-06-18 04:37:07+00:00,,0,0,"[Label(name=""caffe2"")]"
8577,Update tests to no longer spew debug info,2018-06-16 00:14:18+00:00,,0,8,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
8561,cleanup BLAS detection,2018-06-15 18:33:21+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
8556,[JIT] Interleaved C++-Python execution loses inner Python stacks,2018-06-15 15:35:11+00:00,,0,0,"[Label(name=""oncall: jit"")]"
8550,caffe2: Does caffe support the model running on different device (CPU and GPU) same time ?,2018-06-15 11:54:01+00:00,,0,1,"[Label(name=""caffe2"")]"
8548,[caffe2] [feature request]Doese caffe2 support conv_nd with group?,2018-06-15 10:00:50+00:00,,0,0,"[Label(name=""caffe2"")]"
8546,Q: how to generate my own pb files to C++ Predictor,2018-06-15 04:59:41+00:00,,0,0,"[Label(name=""caffe2"")]"
8533,[Caffe2] Runtime error while using a pre-trained style_transfer model,2018-06-14 22:04:26+00:00,,0,0,"[Label(name=""caffe2"")]"
8479,An error occurred while creating a new notebook. ,2018-06-14 09:09:36+00:00,,0,0,"[Label(name=""caffe2"")]"
8473,RuntimeError: /pytorch/torch/csrc/jit/tracer.h:117: getTracingState: Assertion `var_state == state` failed.,2018-06-14 04:11:10+00:00,,0,14,"[Label(name=""oncall: jit"")]"
8471,Does the caffe2 have the depthwise separable convolution oprater  ?,2018-06-14 03:19:07+00:00,,0,2,"[Label(name=""caffe2"")]"
8453,"[JIT] Generalize checkTrace() to also compare gradients of parameters, not just inputs",2018-06-13 21:43:47+00:00,,0,0,"[Label(name=""oncall: jit"")]"
8442,[caffe2] Why the GPU memory consumption has no change after enable optimize_gradient_memory?,2018-06-13 19:25:52+00:00,,0,0,"[Label(name=""caffe2"")]"
8433,Use CMAKE_<LANG>_COMPILER_LAUNCHER,2018-06-13 17:26:05+00:00,,0,2,"[Label(name=""module: build""), Label(name=""triaged"")]"
8430,batchnorm2d  track_running_stats,2018-06-13 15:57:45+00:00,,1,10,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
8386,Properly release NCCL resources,2018-06-12 17:49:50+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: nccl"")]"
8374,[Feature request] Add torch.multiprocessing.Pipe,2018-06-12 13:23:59+00:00,,0,3,"[Label(name=""module: bootcamp""), Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""small"")]"
8328,how can I fetch the result of output's Blobs_namet after  I sum two numpy array via brew.sum,2018-06-11 09:17:28+00:00,,0,0,"[Label(name=""caffe2"")]"
8290,[feature request] MPI init_method for torch.distributed,2018-06-08 20:44:15+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
8276,[Installation]: Support conda/pip install with ppc64le(power8),2018-06-08 07:18:52+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: POWER"")]"
8242,Different behavior of LSTM and LSTMCell implementation ,2018-06-07 15:55:01+00:00,,0,9,"[Label(name=""module: numerical-stability""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""module: numerical-reproducibility"")]"
8191,error when import caffe2.python.onnx.backend,2018-06-06 09:15:10+00:00,,1,1,"[Label(name=""caffe2"")]"
8186,[Caffe2] Successive in-place operators cause RuntimeError of gradient operator versions,2018-06-06 05:02:17+00:00,,0,0,"[Label(name=""caffe2"")]"
8153,GRU is implementation of GRU v1 draft rather than final GRU paper algo,2018-06-05 06:38:02+00:00,,0,11,"[Label(name=""module: docs""), Label(name=""module: rnn""), Label(name=""triaged"")]"
8128,Cmake is getting permission denied when installed system wide,2018-06-04 19:38:32+00:00,,1,8,"[Label(name=""caffe2"")]"
8126,PyTorch multiprocessing using single CPU core,2018-06-04 19:27:05+00:00,,0,7,"[Label(name=""todo""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
8107,Export CC is ignored when I build pytorch,2018-06-04 07:49:10+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
8104,load_state_dict unexpectedly does not load Tensor to buffers that currently have None value,2018-06-04 04:35:01+00:00,,0,9,"[Label(name=""module: bc-breaking""), Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""triaged"")]"
8098, Please provide wheel package for windows on PyPI,2018-06-04 02:04:45+00:00,,0,3,"[Label(name=""module: binaries""), Label(name=""triaged"")]"
8097,manager.cpp:64: undefined reference to `shm_open (when building with GCC 5.x (sic)),2018-06-04 00:36:03+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
8069,Document torch.acos() behavior near -1 and 1,2018-06-02 10:46:06+00:00,,0,12,"[Label(name=""module: docs""), Label(name=""triaged"")]"
8066,import problem,2018-06-02 03:25:11+00:00,,1,1,"[Label(name=""caffe2"")]"
8062,CrossEntropyLoss mishandles weights,2018-06-02 00:28:04+00:00,,1,5,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
8044,[PyTorch] Windows CI CUDA mem leak check on BN tests are flaky,2018-06-01 20:07:52+00:00,,0,4,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""module: flaky-tests"")]"
8035,[PyTorch] EmbeddingBag comparison vs Embedding fails w/ small max_norm on CUDA,2018-06-01 18:12:34+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
8028,Build error : mpi/mpi_gpu_test.cc.o:  undefined reference to symbol '_ZN3MPI8Datatype4FreeEv',2018-06-01 09:59:02+00:00,,1,9,"[Label(name=""caffe2"")]"
8012,[Caffe2] VideoInput/LMDB Reader to Standalone Predictor Question,2018-06-01 00:01:35+00:00,,0,2,"[Label(name=""caffe2"")]"
7986,[Caffe2] place some nodes of the same network on GPU and others on CPU?,2018-05-31 12:56:54+00:00,,0,2,"[Label(name=""caffe2"")]"
7946,how to use Softmax when do segmentation,2018-05-30 06:16:40+00:00,,0,2,"[Label(name=""caffe2"")]"
7945,[Caffe2]How to convert Caffe's mean file to Caffe2's ?,2018-05-30 05:16:39+00:00,,0,0,"[Label(name=""caffe2"")]"
7944,Better error message in DataChannelTCP::_receive,2018-05-30 04:21:34+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: backend"")]"
7912,[Caffe2] Operators of Detectron module not registered/compiled when built on windows,2018-05-29 08:54:40+00:00,,0,3,"[Label(name=""caffe2"")]"
7904,TracedModules don't support parameter sharing between modules,2018-05-29 02:23:17+00:00,,0,13,"[Label(name=""oncall: jit"")]"
7900,Deprecate torch.Tensor,2018-05-28 20:09:07+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: tensor creation"")]"
7897,"[caffe2] build from source, cannot find my cudnn7.1",2018-05-28 13:42:00+00:00,,1,3,"[Label(name=""caffe2"")]"
7890,[feature request] batch_first of RNN hidden weight for Multi GPU training,2018-05-28 03:09:16+00:00,,0,8,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
7887,[Caffe2] convert ONNX to caffe2,2018-05-28 00:20:35+00:00,,0,2,"[Label(name=""caffe2"")]"
7865,[PyTorch] weight tensor dimension assumption,2018-05-25 22:38:53+00:00,,1,5,"[Label(name=""module: nn""), Label(name=""triaged"")]"
7857,Feature Request: Logistic Distribution,2018-05-25 19:51:39+00:00,,0,11,"[Label(name=""module: distributions""), Label(name=""feature""), Label(name=""triaged"")]"
7835,[caffe2] how to using the Mul operator to mul the input vetor,2018-05-25 03:19:09+00:00,,0,0,"[Label(name=""caffe2"")]"
7834,torch.Tensor.new() disappeared in 0.4 doc,2018-05-25 03:03:41+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: deprecation""), Label(name=""module: tensor creation"")]"
7807,LMDB read error for Mnist,2018-05-24 11:12:47+00:00,,0,4,"[Label(name=""caffe2"")]"
7806,OOM Exception when using torch.nn.grad.conv2d_weight (apparently because CuDNN backwards is not used),2018-05-24 08:29:20+00:00,,0,7,"[Label(name=""module: performance""), Label(name=""module: cudnn""), Label(name=""module: memory usage""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""has workaround"")]"
7801,Checkpointing is slow on nn.DataParallel models,2018-05-23 22:50:53+00:00,,0,10,"[Label(name=""module: performance""), Label(name=""module: checkpoint""), Label(name=""triaged"")]"
7795,[feature request] Add cudaification API for distributions,2018-05-23 20:25:49+00:00,,0,18,"[Label(name=""module: distributions""), Label(name=""triaged""), Label(name=""enhancement"")]"
7789,detectron net create error,2018-05-23 11:58:23+00:00,,0,1,"[Label(name=""caffe2"")]"
7786,[feature request] Simple and Efficient way to get gradients of each element of a sum,2018-05-23 07:56:00+00:00,,0,26,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
7781,[Caffe2] Fail to build after upgrading to cuda 9.2,2018-05-23 02:44:49+00:00,,0,3,"[Label(name=""caffe2"")]"
7773,[feature request] Add Local Contrast Normalization ,2018-05-22 21:43:59+00:00,,0,4,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
7745,[Caffe2] Align Element-Wise Ops Broadcasting to Numpy,2018-05-21 23:07:15+00:00,,2,1,"[Label(name=""caffe2"")]"
7740,Conv3D can be optimized for cases when kernel is spatial (probably),2018-05-21 18:58:52+00:00,,0,0,"[Label(name=""module: performance""), Label(name=""module: convolution""), Label(name=""triaged"")]"
7733,Inserting a tensor into a python dict causes strange behavior,2018-05-21 16:26:35+00:00,,0,28,"[Label(name=""todo""), Label(name=""module: nn""), Label(name=""triaged"")]"
7729,[Caffe2][Caffe] Caffe to Caffe2 ParseError,2018-05-21 07:37:29+00:00,,0,0,"[Label(name=""caffe2"")]"
7686,Only one thread is used on macOS (super slow on CPU),2018-05-18 19:15:44+00:00,,0,20,"[Label(name=""triaged""), Label(name=""module: macos""), Label(name=""module: multithreading"")]"
7667,Caffe2 network exported from ONNX does not initialize the model inputs,2018-05-18 08:26:50+00:00,,0,1,"[Label(name=""caffe2"")]"
7617,"checkpoint(function, *args) should have the same requires_grad as function(*args)",2018-05-16 18:02:54+00:00,,0,20,"[Label(name=""module: checkpoint""), Label(name=""module: autograd""), Label(name=""triaged"")]"
7614,[Caffe2] modify op in the net from init and predict files,2018-05-16 13:29:53+00:00,,0,0,"[Label(name=""caffe2"")]"
7610,Inconsistent interactions of PyTorch tensors and NumPy ops,2018-05-16 11:21:27+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
7610,Inconsistent interactions of PyTorch tensors and NumPy ops,2018-05-16 11:21:27+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
7571,"the latest version of caffe2,  Which file is  the function loadToNCHW() ",2018-05-15 10:09:20+00:00,,0,1,"[Label(name=""caffe2"")]"
7569,[Caffe2]How to set lr_mult and decay_mult in Conv layer?,2018-05-15 08:52:19+00:00,,0,0,"[Label(name=""caffe2"")]"
7546,[Caffe2] Build broken on macOS High Sierra: can't find sys headers in /usr/local/include.,2018-05-14 04:28:32+00:00,,1,2,"[Label(name=""caffe2"")]"
7541,[Bug] Dilated max-pooling fails due to padding check,2018-05-13 23:51:03+00:00,,0,4,"[Label(name=""todo""), Label(name=""triaged""), Label(name=""module: pooling"")]"
7535,[feature request] Global GPU Flag,2018-05-13 13:07:06+00:00,,0,12,"[Label(name=""feature""), Label(name=""module: cuda""), Label(name=""triaged"")]"
7493,Build from source with anaconda [caffe2],2018-05-11 05:58:48+00:00,,1,1,"[Label(name=""caffe2"")]"
7491,[caffe2] How to know the input shape for certain pre-trained network,2018-05-11 03:57:20+00:00,,0,0,"[Label(name=""caffe2"")]"
7490,"[Caffe2]: caffe2.python.caffe_translator.py script doesn't convert ""Split"" and ""Slice"" Layer",2018-05-11 03:02:49+00:00,,0,0,"[Label(name=""caffe2"")]"
7480,[caffe2] How to use multiple CPUs?,2018-05-10 19:20:55+00:00,,0,0,"[Label(name=""caffe2"")]"
7471,Make c10d/FileStore cache file descriptor,2018-05-10 16:16:11+00:00,,1,0,"[Label(name=""newcomer""), Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""triaged"")]"
7457,[feature request] torch.nn.DataParallel should work nicely both for cpu and gpu devices,2018-05-10 08:26:17+00:00,,2,3,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: data parallel"")]"
7423,Multi queue for dataloader when workers > 1,2018-05-09 14:13:20+00:00,,0,1,"[Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""enhancement"")]"
7414,[Caffe2] Negative export to ONNX fails,2018-05-09 07:52:04+00:00,,0,1,"[Label(name=""caffe2"")]"
7374,[Caffe2] Can't use resnet50_trainer.py through redis.,2018-05-08 15:20:45+00:00,,0,0,"[Label(name=""caffe2"")]"
7365,nn.DataParallel fills None grads with 0,2018-05-08 03:42:16+00:00,,0,7,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
7362,[caffe2] Can I load the gpu data to cpu in .cu file?,2018-05-08 02:01:09+00:00,,0,0,"[Label(name=""caffe2"")]"
7359,[feature request] [PyTorch] Dynamic Samplers.,2018-05-08 01:24:25+00:00,,0,10,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
7358,DataParallel on list inputs,2018-05-08 00:18:52+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: data parallel"")]"
7353,"Windows MAGMA binary requires explicit linking against MKL LAPACK, or it will silently give  incorrect results",2018-05-07 20:54:07+00:00,,0,1,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
7352,Check for F2C convention (for blas) at runtime,2018-05-07 20:47:23+00:00,,0,1,"[Label(name=""module: build""), Label(name=""triaged"")]"
7343,[memory leak] [PyTorch] .backward(create_graph=True),2018-05-07 17:57:29+00:00,,0,10,"[Label(name=""module: autograd""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
7342,[feature request] [PyTorch] More flexible optimizer API,2018-05-07 17:52:11+00:00,,0,6,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
7330,Issue when importing both retro (from OpenAI) and torch,2018-05-06 16:03:18+00:00,,0,10,"[Label(name=""triaged""), Label(name=""module: pybind"")]"
7316,"Optional modifiers (e.g., Tensor?) are not checked for non-dispatched native functions",2018-05-05 03:25:50+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: dispatch"")]"
7313,[proposal] [discussion] Refactor pruning/weight_norm using new Reparametrization functionality + actually deprecate old impl of SpectralNorm,2018-05-04 23:03:28+00:00,,0,70,"[Label(name=""module: nn""), Label(name=""triaged"")]"
7250,feature request: support for new/future hardware accelerators,2018-05-03 18:02:37+00:00,,0,3,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""shadow review"")]"
7227,[Caffe2]Install problem,2018-05-03 04:52:22+00:00,,1,1,"[Label(name=""caffe2"")]"
7214,Do not put system paths in RPATH,2018-05-03 01:50:21+00:00,,1,3,"[Label(name=""module: build""), Label(name=""triaged"")]"
7180,[Caffe2 Bug] Windows timer is not accurate,2018-05-02 17:37:39+00:00,,0,0,"[Label(name=""caffe2"")]"
7179,[caffe2]when i do CMAKE,2018-05-02 14:57:07+00:00,,1,1,"[Label(name=""caffe2"")]"
7133,[Caffe2 warpctc] How to use the offered warpctc?,2018-05-01 14:08:44+00:00,,1,4,"[Label(name=""caffe2"")]"
7127,how can i use openMP for caffe2? why caffe2 not work in multi-threads mode?,2018-05-01 03:22:36+00:00,,0,2,"[Label(name=""caffe2"")]"
7078,Fail to import Caffe2Backend,2018-04-29 06:25:54+00:00,,0,5,"[Label(name=""caffe2"")]"
7066,LBFGS contribution ,2018-04-28 06:18:44+00:00,,0,7,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
7060,[feature request] Provide Caffe2 CUDA dockerfile with USE_REDIS=ON,2018-04-28 01:07:00+00:00,,0,0,"[Label(name=""caffe2"")]"
7047,"""Undefined symbols for architecture arm64"" when linking libcaffe2.a for iOS",2018-04-27 19:51:19+00:00,,0,5,"[Label(name=""caffe2"")]"
7043,CuDNN version not supported,2018-04-27 17:55:01+00:00,,0,0,"[Label(name=""todo""), Label(name=""module: build""), Label(name=""module: cudnn""), Label(name=""module: cuda""), Label(name=""triaged"")]"
7036,[Caffe2] compilation linker error `libtbb.so.2: undefined reference to std::__exception_ptr`,2018-04-27 12:46:30+00:00,,1,0,"[Label(name=""module: crash""), Label(name=""module: build""), Label(name=""caffe2"")]"
7035,[Compilation] how to disable caffe2? ,2018-04-27 11:28:22+00:00,,0,9,"[Label(name=""module: build""), Label(name=""triaged"")]"
7032,[feature request] norm argument for RNNCells,2018-04-27 09:16:45+00:00,,0,2,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""enhancement"")]"
7020,[Caffe2] LT and GT cannot be exported to ONNX,2018-04-27 01:31:55+00:00,,0,4,"[Label(name=""caffe2"")]"
6998,[pytorch] Not handling python reload properly,2018-04-26 16:25:46+00:00,,1,4,"[Label(name=""todo""), Label(name=""module: crash""), Label(name=""triaged"")]"
6979,[Caffe2] Is there any way to load custom operators in c++?,2018-04-26 03:35:15+00:00,,0,0,"[Label(name=""caffe2"")]"
6934,Feature request: SSIM/MS-SSIM,2018-04-25 06:09:34+00:00,,0,43,"[Label(name=""triaged""), Label(name=""module: vision""), Label(name=""function request"")]"
6902,[Caffe2] Flatten Layer in caffe2,2018-04-24 15:28:40+00:00,,0,1,"[Label(name=""caffe2"")]"
6901,[Caffe2] [feature request] Dilations in grouped convolutons,2018-04-24 14:52:13+00:00,,0,1,"[Label(name=""caffe2"")]"
6898,[Caffe2] cudnn versions compatibility issue.,2018-04-24 12:44:51+00:00,,1,1,"[Label(name=""module: cudnn""), Label(name=""caffe2"")]"
6875,[Bug] VS reports unresolved external symbol from caffe2 observer,2018-04-23 19:18:11+00:00,,0,1,"[Label(name=""caffe2"")]"
6868,[Caffe2] Android NNApi integration bugs.,2018-04-23 17:30:04+00:00,,0,1,"[Label(name=""caffe2"")]"
6857,[caffe2] Understanding WorkFlow for Training and Testing,2018-04-23 09:07:14+00:00,,0,11,"[Label(name=""caffe2"")]"
6850,[feature request] More `index_*_` functionality and/or lambda functionality,2018-04-23 00:21:20+00:00,,0,9,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
6846,Jetson TX1 Caffe2 installation fails on latest JetPack release,2018-04-22 11:46:42+00:00,,0,2,"[Label(name=""caffe2"")]"
6845,[caffe2] global average pool in caffe2,2018-04-22 07:33:42+00:00,,0,0,"[Label(name=""caffe2"")]"
6794,[Caffe2] TensorProtosDBInput AttributeError,2018-04-20 03:53:44+00:00,,0,10,"[Label(name=""caffe2"")]"
6785,[caffe2] Training and inference,2018-04-19 23:34:39+00:00,,0,0,"[Label(name=""caffe2"")]"
6783,[caffe2] IfOp,2018-04-19 23:03:59+00:00,,0,0,"[Label(name=""caffe2"")]"
6760,[Feature request] LayerNormLSTMCell and LayerNormLSTM,2018-04-19 13:52:16+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement"")]"
6662,Autogenerate code example / tutorial outputs in documentation,2018-04-17 15:23:03+00:00,,0,15,"[Label(name=""todo""), Label(name=""module: docs""), Label(name=""good first issue""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
6660,[caffe2] GANs,2018-04-17 14:23:48+00:00,,1,5,"[Label(name=""caffe2"")]"
6657,[feature request] Stochastic Variance Reduced Gradient (SVRG) optimizer,2018-04-17 13:28:46+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
6618,[Caffe2] CUDNN_STATUS_BAD_PARAM Error with the LRN layer while trying to run the code using CUDA. The training works fine on CPU,2018-04-16 08:53:51+00:00,,0,1,"[Label(name=""caffe2"")]"
6613,[caffe2] benchmark performance for different operators ,2018-04-15 13:53:18+00:00,,0,1,"[Label(name=""caffe2"")]"
6581,[Caffe2] [feature request] How to freeze a layer ? (Selective Backward Propagation),2018-04-13 04:51:29+00:00,,0,1,"[Label(name=""caffe2"")]"
6564,[Feature Request] Optimization with constraint (L-BFGS-B),2018-04-12 20:23:58+00:00,,0,4,"[Label(name=""proposal accepted""), Label(name=""todo""), Label(name=""triaged"")]"
6552,[Caffe2] - Run on different Cuda streams,2018-04-12 15:07:43+00:00,,0,2,"[Label(name=""caffe2"")]"
6549,caffe2/cuda_rtc can throw during the destructor,2018-04-12 13:00:10+00:00,,0,0,"[Label(name=""caffe2"")]"
6542,"【Train issue with caffe2 detectron】Aborted at 1523501813 (unix time) try ""date -d @1523501813"" if you are using GNU date *** PC: @     0x7fa35103733a (unknown)",2018-04-12 05:39:28+00:00,,0,3,"[Label(name=""caffe2"")]"
6505,[Caffe2] Onnx to Caffe2 Blob error,2018-04-11 14:21:35+00:00,,0,5,"[Label(name=""caffe2"")]"
6502,[Caffe2] Boolean Tensor not supported for mobile_exporter.Export,2018-04-11 08:24:20+00:00,,0,0,"[Label(name=""caffe2"")]"
6465,[caffe2] ChannelShuffle example,2018-04-10 14:30:08+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""module: docs"")]"
6442,[feature request] dropout1d,2018-04-09 22:07:23+00:00,,0,6,"[Label(name=""todo""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
6437,[caffe2] Double precision for operators?,2018-04-09 20:53:15+00:00,,0,0,"[Label(name=""caffe2"")]"
6431,Examine contiguity requirements for gradInput,2018-04-09 19:00:44+00:00,,0,9,"[Label(name=""triaged"")]"
6424,[utils.bottleneck] List of improvements,2018-04-09 16:18:08+00:00,,0,2,"[Label(name=""todo""), Label(name=""triaged""), Label(name=""module: bottleneck"")]"
6422,[caffe2] Run resnet50_trainer.py error between 2 machines using GLOO/Redis and ibverbs,2018-04-09 14:24:27+00:00,,0,5,"[Label(name=""caffe2"")]"
6408,[caffe2] Prefetching blobs for memory optimization,2018-04-08 17:41:23+00:00,,0,3,"[Label(name=""caffe2"")]"
6402,[caffe2] How to freeze a layer?,2018-04-08 10:13:46+00:00,,0,10,"[Label(name=""caffe2"")]"
6357,[feature request] Unpooling layer in Caffe2,2018-04-06 18:02:50+00:00,,0,0,"[Label(name=""caffe2""), Label(name=""feature"")]"
6350,worker assignments in torch.utils.dataloader.py,2018-04-06 15:07:39+00:00,,0,3,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
6328,[feature request] Include libomp support (macOS),2018-04-05 23:16:56+00:00,,0,5,"[Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: macos"")]"
6273,Multithreading Scaling Issue with MKL,2018-04-04 15:30:22+00:00,,0,10,"[Label(name=""caffe2"")]"
6265,[Caffe2] mobile_exporter init_net has code calling information,2018-04-04 07:54:53+00:00,,1,1,"[Label(name=""caffe2"")]"
6257,"[feature request] adding a nonzero element ""in-place"" in sparse tensor",2018-04-04 00:41:04+00:00,,1,3,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
6165,Note about unusual stride situations in dev docs / make it easier to test for this in the library,2018-04-01 02:31:35+00:00,,0,0,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: memory format"")]"
6138,[feature request] SIGNUM an optimizer that takes the sign of gradient or momentum.,2018-03-30 16:18:00+00:00,,0,1,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
6135,Test suite should test implementations,2018-03-30 15:43:29+00:00,,0,0,"[Label(name=""module: tests""), Label(name=""triaged"")]"
6107,"Well documented, safe method to deserialize model parameters from untrusted sources",2018-03-29 11:22:37+00:00,,0,9,"[Label(name=""feature""), Label(name=""module: pickle""), Label(name=""module: serialization""), Label(name=""triaged""), Label(name=""onnx-triaged""), Label(name=""topic: security"")]"
6083,[feature request] DC-ASGD (Delay Compensated Asynchronous Stochastic Gradient Descent),2018-03-28 21:23:08+00:00,,0,3,"[Label(name=""oncall: distributed""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
6071,Repeated 'python setup.py install' with clang leads to -lcpuinfo not found,2018-03-28 15:54:58+00:00,,0,4,"[Label(name=""module: build""), Label(name=""triaged"")]"
6010,Develop a strategy for writing leak tests for pytorch. ,2018-03-26 19:23:32+00:00,,0,1,"[Label(name=""oncall: jit"")]"
6007, Clean up the extra copies that occur in the execution engine and other places,2018-03-26 19:21:07+00:00,,0,0,"[Label(name=""oncall: jit"")]"
5953,"LBFGS always give nan results, why",2018-03-23 01:26:27+00:00,,1,15,"[Label(name=""needs reproduction""), Label(name=""module: numerical-stability""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
5924,Install doesn't work with spaces in directory,2018-03-21 17:56:20+00:00,,0,6,"[Label(name=""todo""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""has workaround"")]"
5912,Conv-RNN combination slow in backward pass,2018-03-20 20:22:47+00:00,,0,9,"[Label(name=""module: performance""), Label(name=""module: nn""), Label(name=""triaged"")]"
5900,"Build Fails on Gentoo with CUDA 9.1, GCC 6.4, Python 3.5",2018-03-20 10:58:04+00:00,,1,7,"[Label(name=""module: build""), Label(name=""triaged"")]"
5857,Change THCudaCheck to suggest that device-side asserts likely mean that you have out of bound indices,2018-03-17 19:46:48+00:00,,0,6,"[Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: assert failure""), Label(name=""small"")]"
5790,Add hookable weights,2018-03-14 20:50:43+00:00,,0,14,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement"")]"
5740,[feature request] scalar input to scatter_add_ like scatter_,2018-03-13 14:27:07+00:00,,0,10,"[Label(name=""triaged""), Label(name=""function request""), Label(name=""module: scatter & gather ops"")]"
5737,[feature request] Callback on learning rate drop in torch.optim.lr_scheduler.ReduceLROnPlateau,2018-03-13 11:35:29+00:00,,0,4,"[Label(name=""todo""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
5580,"[feature request] F.interpolate to support integral data types: bool, int8, int32, int16, int64 ||| support uint8 on CUDA",2018-03-05 23:30:28+00:00,,1,15,"[Label(name=""todo""), Label(name=""triaged"")]"
5565,[feature request] Different interpolation algos for 'grid_sample' function,2018-03-05 08:44:01+00:00,,0,19,"[Label(name=""hackamonth""), Label(name=""module: docs""), Label(name=""triaged""), Label(name=""function request""), Label(name=""module: interpolation"")]"
5528,TestNN.test_data_parallel takes 10G of memory,2018-03-02 17:08:56+00:00,,0,0,"[Label(name=""module: memory usage""), Label(name=""module: tests""), Label(name=""triaged"")]"
5524,Redo torch.nn.functional docstring strategy,2018-03-02 15:05:38+00:00,,0,1,"[Label(name=""module: docs""), Label(name=""triaged"")]"
5489,"torch.jit.trace(network, data) fails if data is an OrderedDict",2018-03-01 09:37:39+00:00,,1,0,"[Label(name=""oncall: jit""), Label(name=""module: bootcamp""), Label(name=""days"")]"
5435,Gaussian Sampling,2018-02-27 16:00:19+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
5434,RuntimeError: $ Torch: not enough memory: you tried to allocate 72GB. Buy new RAM!,2018-02-27 15:16:02+00:00,,0,15,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
5405,scatter_add_ should support scalar source (including Python scalar),2018-02-25 23:09:42+00:00,,1,9,"[Label(name=""triaged""), Label(name=""module: scatter & gather ops"")]"
5388,Perf regression: indexing 1-d tensor,2018-02-23 21:28:23+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""in progress""), Label(name=""triaged"")]"
5385,Handle python_arg_parser dtype constants better,2018-02-23 20:18:59+00:00,,0,1,"[Label(name=""todo""), Label(name=""feature""), Label(name=""triaged"")]"
5353,Bugs: Score Function approach in REINFORCE for PONG,2018-02-22 18:35:59+00:00,,0,1,"[Label(name=""todo""), Label(name=""module: crash""), Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
5326,TestMultiprocessing.test_fd_sharing hangs with ASAN,2018-02-21 05:29:07+00:00,,0,2,"[Label(name=""module: tests""), Label(name=""triaged"")]"
5280,BatchNorm1d raises RuntimeError (CUDNN_STATUS_BAD_PARAM) on 3D input.,2018-02-17 00:50:35+00:00,,0,1,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
5272,Unsafe out= keyword argument with tensors sharing storage,2018-02-16 07:41:38+00:00,,0,6,"[Label(name=""triaged""), Label(name=""module: numpy""), Label(name=""module: safe resize""), Label(name=""module: correctness (silent)"")]"
5266,[feature request] warnings for functions with unspecified dim arguments,2018-02-15 20:50:22+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement"")]"
5231,[feature request] Stratified splits in random_split function,2018-02-14 01:19:06+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
5212,Weird error message in torch.split_size_or_sections,2018-02-13 13:16:40+00:00,,0,9,"[Label(name=""triaged""), Label(name=""module: numpy"")]"
5161,ASAN detected leaks on python -c 'import torch',2018-02-09 17:53:05+00:00,,0,3,"[Label(name=""module: memory usage""), Label(name=""triaged"")]"
5159,TakeBackward taking a significant portion of backward time,2018-02-09 17:03:48+00:00,,0,5,"[Label(name=""module: performance""), Label(name=""module: autograd""), Label(name=""triaged"")]"
5157,BCELoss - weight parameter shape incorrect,2018-02-09 16:03:39+00:00,,0,6,"[Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged"")]"
5106,Saving model with runtime code changes,2018-02-07 11:40:37+00:00,,0,0,"[Label(name=""module: serialization""), Label(name=""triaged"")]"
5096,[feature request]Add an env variable to cover different pathes when testing code with openmp,2018-02-07 02:23:19+00:00,,0,4,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""better-engineering"")]"
5070,NVIDIA_DRIVER_CAPABILITIES env variable is missing in pytorch docker images,2018-02-06 03:48:20+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: docker"")]"
5063,Delete obsolete `THCDeviceTensor::downcastOuter` / `THCDeviceTensor::downcastInner` functions,2018-02-05 22:28:57+00:00,,0,1,"[Label(name=""module: bootcamp""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""small""), Label(name=""better-engineering"")]"
5013,[Feature Request] Calculating FLOPs for computational graph operations,2018-02-02 16:08:57+00:00,,0,25,"[Label(name=""high priority""), Label(name=""module: performance""), Label(name=""feature""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
4987,MultiGPU hangs Titan Xp in multiprocessing/queue.py,2018-02-01 15:57:30+00:00,,0,15,"[Label(name=""module: multiprocessing""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: macos"")]"
4959,Speed up data loading for `TensorDataset` if the underlying dataset supports index by a list of indices,2018-01-31 15:40:23+00:00,,0,3,"[Label(name=""module: performance""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
4958,[Feature Request] Extract glimpses from a batch of images (as in tf.image.extract_glimpse),2018-01-31 09:09:59+00:00,,0,1,"[Label(name=""triaged""), Label(name=""module: vision""), Label(name=""function request"")]"
4954,[docs] Docs website search finds duplicates and produces bad snippets,2018-01-31 01:32:39+00:00,,0,7,"[Label(name=""module: docs""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
4952,[Feature request] Optimize autograd/ATen when a gradient is clearly zero,2018-01-30 23:09:18+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
4930,[feature request] Type-1 Multi-layer bidirectional RNN,2018-01-30 09:22:10+00:00,,1,29,"[Label(name=""module: cudnn""), Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""function request"")]"
4927,[Feature Request]would PackedSequence support unsorted sequences?,2018-01-30 07:33:37+00:00,,0,0,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
4906,"Rebuild from no-CUDA to CUDA leads to: error: #error ""Expected GLOO_USE_CUDA to be defined""",2018-01-29 14:24:59+00:00,,0,9,"[Label(name=""module: build""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""has workaround"")]"
4829, [Feature Request] clip_grad_norm for sparse gradients,2018-01-24 12:34:07+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
4825,[feature request]Support AVX512F intrinstics to vectorize operations,2018-01-24 00:59:23+00:00,,0,9,"[Label(name=""feature""), Label(name=""module: cpu""), Label(name=""triaged"")]"
4758,Clang color diagnostics don't work with ninja,2018-01-20 19:36:47+00:00,,0,0,"[Label(name=""module: build""), Label(name=""triaged"")]"
4731,Consider disallowing Variables that require grad in NCCL/comm functions,2018-01-18 21:32:53+00:00,,0,1,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: nccl""), Label(name=""actionable"")]"
4716,Compilation issue: problem with GPU capability check,2018-01-18 00:47:08+00:00,,0,3,"[Label(name=""module: build""), Label(name=""module: cuda""), Label(name=""triaged"")]"
4703,Very slow on CPU,2018-01-17 08:05:34+00:00,,0,23,"[Label(name=""module: performance""), Label(name=""module: rnn""), Label(name=""module: cpu""), Label(name=""triaged"")]"
4660,[Feature proposal] Add MC-derived optimizers,2018-01-14 02:26:56+00:00,,1,0,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""needs research"")]"
4636,Better header hygiene in ATen,2018-01-12 15:51:40+00:00,,0,2,"[Label(name=""module: internals""), Label(name=""triaged"")]"
4632,CUDNN_STATUS_INTERNAL_ERROR when training with conv3d,2018-01-12 08:47:38+00:00,,0,7,"[Label(name=""module: cudnn""), Label(name=""module: convolution""), Label(name=""triaged"")]"
4622,Protect user from No module named _C import error,2018-01-12 01:27:30+00:00,,0,4,"[Label(name=""module: error checking""), Label(name=""triaged""), Label(name=""module: pybind"")]"
4574,`from` keyword in `random_` gives error,2018-01-10 05:14:47+00:00,,0,0,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
4564,Mixed Tensor/TensorList arguments in ATen functions with explicit derivatives,2018-01-09 20:07:29+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""enhancement"")]"
4551,Met 'cudnnDestroyDropoutDescriptor' while run multiply gpu-based models in multiply processes,2018-01-09 03:18:00+00:00,,0,1,"[Label(name=""module: multi-gpu""), Label(name=""module: cudnn""), Label(name=""triaged"")]"
4542,Carefully audit contiguity requirements of code,2018-01-08 21:55:10+00:00,,0,0,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
4530,descriptor 'add' of 'torch._C._VariableBase' object needs an argument,2018-01-08 10:15:40+00:00,,0,3,"[Label(name=""module: docs""), Label(name=""triaged"")]"
4501,Bind in Python _backward ATen functions,2018-01-05 22:20:09+00:00,,0,4,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
4474,[docs] Return value type hint to be specified in docs for torch.is_grad_enabled (i.e. -> bool),2018-01-04 14:47:52+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
4440,Assert that some tests must not be skipped under certain CI configurations,2018-01-02 17:21:04+00:00,,0,8,"[Label(name=""high priority""), Label(name=""module: ci""), Label(name=""module: tests""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
4406,DistributedDataParallel doesn't converge well when using MPI,2017-12-29 10:42:38+00:00,,0,7,"[Label(name=""oncall: distributed""), Label(name=""triaged"")]"
4400,Installation Optimise For Chinese Users Who Behind the Wall,2017-12-29 01:43:37+00:00,,0,4,"[Label(name=""module: docs""), Label(name=""triaged"")]"
4392,"Cache CuDNN benchmark selection, turn it on by default, use it across PyTorch runs",2017-12-28 21:39:31+00:00,,0,5,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
4358,Invoking MKL in multiprocessing with importing torch causes blocking,2017-12-27 04:07:21+00:00,,0,3,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: mkldnn""), Label(name=""module: mkl"")]"
4334,torch.cuda.device_count() returns 1 using 4 TitanX setup.,2017-12-23 14:43:27+00:00,,0,1,"[Label(name=""needs reproduction""), Label(name=""module: cuda""), Label(name=""triaged"")]"
4247,Feature request: sparse matrix max(axis),2017-12-19 11:31:20+00:00,,1,6,"[Label(name=""module: sparse""), Label(name=""triaged""), Label(name=""enhancement"")]"
4241,single-gpu works but multi-gpu hangs,2017-12-18 22:19:08+00:00,,0,2,"[Label(name=""module: cudnn""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
4186,Feature Request: CPU performance optimization with MKL-DNN,2017-12-15 01:58:51+00:00,,0,27,"[Label(name=""triaged""), Label(name=""module: mkldnn"")]"
4181,Fused RNN refactor plan,2017-12-14 22:50:03+00:00,,0,6,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
4159,Variable outputs of stochastic functions should never require grad,2017-12-13 20:50:43+00:00,,0,1,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
4148,ATen explicitly differentiated native function resolution hazard (call is ambiguous),2017-12-13 14:41:33+00:00,,0,1,"[Label(name=""module: internals""), Label(name=""triaged"")]"
4145,[Proposal] Consistent `batch_first` effect for RNN modules,2017-12-13 08:02:47+00:00,,0,11,"[Label(name=""module: docs""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
4132,x.grad should be 0 but get NaN after x/0,2017-12-12 16:44:52+00:00,,0,16,"[Label(name=""module: docs""), Label(name=""module: autograd""), Label(name=""triaged""), Label(name=""module: NaNs and Infs""), Label(name=""has workaround""), Label(name=""needs design"")]"
4123,Use the int64 version of MKL calls,2017-12-11 20:35:48+00:00,,0,3,"[Label(name=""module: internals""), Label(name=""triaged""), Label(name=""module: mkl"")]"
4102,Make the generator tools data model more explicit,2017-12-10 05:41:18+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: codegen"")]"
4085,GridSampler behaviours,2017-12-08 11:03:36+00:00,,0,5,"[Label(name=""module: cudnn""), Label(name=""triaged"")]"
4073,Feature request: Correlation module,2017-12-07 16:10:31+00:00,,0,11,"[Label(name=""triaged"")]"
3990,Raise an error when using magma built against wrong version of cuda,2017-12-03 23:54:52+00:00,,0,4,"[Label(name=""module: binaries""), Label(name=""module: build""), Label(name=""triaged"")]"
3931,Suppress hidden state output of RNNs?,2017-11-28 23:52:16+00:00,,0,5,"[Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""enhancement"")]"
3920,[docs] Tensor.new is not documented,2017-11-28 11:51:31+00:00,,1,7,"[Label(name=""module: docs""), Label(name=""triaged"")]"
3904,Implement DE in pytorch.optim,2017-11-27 18:06:14+00:00,,1,3,"[Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs research"")]"
3898,Sparse matrices in dataloader error,2017-11-27 11:32:13+00:00,,1,11,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
3877,Wrap Cephes library for mathematical special functions,2017-11-25 18:40:37+00:00,,0,18,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: numpy"")]"
3867,"[Feature Request] Implement ""same"" padding for convolution operations?",2017-11-25 07:52:39+00:00,,1,84,"[Label(name=""high priority""), Label(name=""module: nn""), Label(name=""module: convolution""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""needs design"")]"
3863,Considerable slowdown in Adam.step after a number of epochs with multiple losses,2017-11-24 20:53:31+00:00,,0,4,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""needs reproduction""), Label(name=""module: performance""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
3823,Fuse bias to CuDNN convolution,2017-11-22 01:14:27+00:00,,0,4,"[Label(name=""triaged""), Label(name=""enhancement"")]"
3818,Memory leak when doing backward with grad as yourself,2017-11-21 20:50:43+00:00,,0,24,"[Label(name=""module: autograd""), Label(name=""module: memory usage""), Label(name=""triaged""), Label(name=""quansight-nack"")]"
3791,Make pytest stop printing docstrings in its default diagnostic output,2017-11-20 12:54:51+00:00,,0,6,"[Label(name=""module: tests""), Label(name=""triaged""), Label(name=""enhancement"")]"
3790,"Add SGDR, SGDW, AdamW and AdamWR",2017-11-20 09:20:23+00:00,,0,11,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
3697,Deprecate inplace argument in torch.nn.functional,2017-11-14 17:50:55+00:00,,0,1,"[Label(name=""module: bc-breaking""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: deprecation"")]"
3667,Exposing CuDNN benchmark strategy selection ,2017-11-13 15:02:46+00:00,,0,7,"[Label(name=""module: cudnn""), Label(name=""module: bootcamp""), Label(name=""feature""), Label(name=""triaged"")]"
3625,Proposal: combine requires_grad and retain_grad(),2017-11-10 16:48:51+00:00,,0,12,"[Label(name=""module: autograd""), Label(name=""triaged"")]"
3619,Multiprocessing with torch.solve hangs,2017-11-10 04:20:43+00:00,,0,14,"[Label(name=""module: multiprocessing""), Label(name=""triaged""), Label(name=""module: linear algebra"")]"
3600,making .cuda() falls back to an identity function when gpu is not available,2017-11-09 15:24:09+00:00,,0,15,"[Label(name=""module: cuda""), Label(name=""triaged"")]"
3473,Feature Request: Distributed send arbitrary objects,2017-11-03 21:04:54+00:00,,0,4,"[Label(name=""oncall: distributed""), Label(name=""feature""), Label(name=""module: pickle""), Label(name=""module: serialization""), Label(name=""triaged"")]"
3468,improve performance of common CPU clone / contiguous calls with HPTT,2017-11-03 17:44:32+00:00,,1,4,"[Label(name=""module: cpu""), Label(name=""triaged"")]"
3428,[docs] Disable google indexing of old docs and of master docs and of function/module summary pages and of source code listings,2017-11-01 19:52:35+00:00,,1,59,"[Label(name=""high priority""), Label(name=""triaged""), Label(name=""module: doc infra"")]"
3396,CUDA topk is slow for some input sizes,2017-10-31 15:47:39+00:00,,0,12,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: sorting and selection"")]"
3390,High CPU use by clock_gettime syscall,2017-10-31 12:01:21+00:00,,0,2,"[Label(name=""module: performance""), Label(name=""module: cuda""), Label(name=""triaged"")]"
3364,type of torch.bernoulli and torch.multinomial inconsistent,2017-10-30 11:25:43+00:00,,0,3,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
3356,Data sampling seems to be more complicated than necessary,2017-10-29 17:58:53+00:00,,0,13,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
3281,"DataLoader ""casting"" non statndard objects to lists",2017-10-25 10:53:01+00:00,,0,9,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
3176,Add safety checks in `index_add`/`scatter_add`,2017-10-19 12:51:38+00:00,,0,0,"[Label(name=""triaged"")]"
3152,Sparse tensor .new(size) can be confusing,2017-10-17 18:19:13+00:00,,0,4,"[Label(name=""module: sparse""), Label(name=""triaged"")]"
3076,BN slows down double-backprop enormously,2017-10-11 18:28:22+00:00,,1,14,"[Label(name=""module: performance""), Label(name=""triaged"")]"
3033,Autograd profiler should omit CUDA time columns on CPU profiler,2017-10-09 15:41:53+00:00,,0,0,"[Label(name=""triaged""), Label(name=""oncall: profiler"")]"
2854,Add the new lr_scheduler which called poly,2017-09-25 11:33:47+00:00,,0,0,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
2849,Learning rate scheduler have different APIs,2017-09-25 01:50:30+00:00,,0,2,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
2739,Proposal: simplify overloaded Tensor function signatures,2017-09-14 19:39:14+00:00,,0,3,"[Label(name=""triaged"")]"
2732,support grid_sample with batch=1 but supprting batch affine parameters,2017-09-14 06:37:56+00:00,,0,14,"[Label(name=""triaged""), Label(name=""module: vision""), Label(name=""module: interpolation"")]"
2724,DataLoader gets stuck after model initialization,2017-09-13 17:43:27+00:00,,0,0,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
2703,Have ppc64le docker images? ,2017-09-12 07:06:45+00:00,,0,2,"[Label(name=""triaged""), Label(name=""module: POWER"")]"
2691,Feature Request: Support grad of grad in fused RNNs,2017-09-11 19:22:31+00:00,,0,1,"[Label(name=""module: double backwards""), Label(name=""feature""), Label(name=""module: autograd""), Label(name=""module: nn""), Label(name=""triaged"")]"
2629,[feature request] add pairwise ranking loss,2017-09-05 16:05:07+00:00,,0,3,"[Label(name=""module: loss""), Label(name=""triaged"")]"
2628,BatchNorm{1-2-3}d are redundant,2017-09-05 14:02:33+00:00,,0,3,"[Label(name=""module: nn""), Label(name=""triaged"")]"
2576,CUDA multinomial is limited to 2^24 categories,2017-08-30 15:25:55+00:00,,0,11,"[Label(name=""high priority""), Label(name=""module: distributions""), Label(name=""module: cuda""), Label(name=""triaged""), Label(name=""module: 64-bit""), Label(name=""function request"")]"
2575,ImportError: dlopen: cannot load any more object with static TLS,2017-08-30 15:20:17+00:00,,2,58,"[Label(name=""module: crash""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: assert failure""), Label(name=""has workaround"")]"
2569,Add a hash function for tensor data,2017-08-30 03:31:04+00:00,,0,7,"[Label(name=""triaged""), Label(name=""function request"")]"
2545,Counter-intuitive Patience & Cooldown of ReduceLROnPlateau,2017-08-27 00:48:32+00:00,,0,3,"[Label(name=""todo""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
2539,"DataLoader converts cuda FloatTensor into cpu DoubleTensor when shape is (n,)",2017-08-25 18:27:41+00:00,,0,9,"[Label(name=""needs reproduction""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
2512,detach_() variant that affects all past uses too,2017-08-22 14:08:41+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: autograd""), Label(name=""triaged"")]"
2482,"""Shared memory manager connection has timed out""",2017-08-18 15:20:55+00:00,,0,5,"[Label(name=""needs reproduction""), Label(name=""module: multiprocessing""), Label(name=""triaged"")]"
2478,ReduceLROnPlateau with a naive Backtracking,2017-08-17 21:39:17+00:00,,1,8,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
2466,Autograd test failure on ppc64le,2017-08-17 00:16:13+00:00,,0,0,"[Label(name=""triaged""), Label(name=""module: POWER"")]"
2407,Hard-negative mining using __getitem__ directive in Dataset class,2017-08-14 06:54:16+00:00,,0,5,"[Label(name=""module: dataloader""), Label(name=""triaged"")]"
2400,Add CRF Layer,2017-08-13 04:27:43+00:00,,0,2,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
2312,DataParallel is not compatible with pack_padded_sequence,2017-08-07 07:12:10+00:00,,0,6,"[Label(name=""awaiting response (this tag is deprecated)""), Label(name=""triaged""), Label(name=""module: data parallel"")]"
2180,Discrepancy in BCEWithLogitsLoss and ClassNLLLoss,2017-07-21 14:20:43+00:00,,0,4,"[Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""module: cpu""), Label(name=""triaged"")]"
2129,[Feature request] truncated normal initializer(sampler),2017-07-17 08:15:29+00:00,,0,1,"[Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: initialization"")]"
2001,Implement similar PyTorch function as model.summary() in keras?,2017-07-07 09:06:38+00:00,,0,22,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""function request"")]"
1969,Naming inconsistencies,2017-07-03 18:58:48+00:00,,0,5,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""module: ux"")]"
1932,Feature Request: ReLU on LSTMs and GRUs,2017-06-28 19:51:03+00:00,,0,9,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: rnn""), Label(name=""triaged"")]"
1927,[feature request] time-distributed layers for application of normal layers to sequence data,2017-06-28 12:59:25+00:00,,1,15,"[Label(name=""module: nn""), Label(name=""triaged"")]"
1861,Factorized Output Layer,2017-06-21 08:27:10+00:00,,0,1,"[Label(name=""todo""), Label(name=""feature""), Label(name=""triaged"")]"
1794,Feature request: reverse_padded_sequence,2017-06-13 19:44:25+00:00,,0,17,"[Label(name=""module: rnn""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""actionable"")]"
1750,Add support for colors (and maybe other attributes) to NVTX API,2017-06-07 18:41:12+00:00,,0,22,"[Label(name=""newcomer""), Label(name=""module: cuda""), Label(name=""triaged"")]"
1747,In-place bernoulli_ has more functionality than torch.bernoulli with output parameter,2017-06-07 14:04:57+00:00,,1,1,"[Label(name=""module: distributions""), Label(name=""triaged"")]"
1736,Expose optimizer options as attributes when there's a single param group,2017-06-06 10:45:53+00:00,,0,2,"[Label(name=""module: bootcamp""), Label(name=""module: optimizer""), Label(name=""triaged""), Label(name=""enhancement"")]"
1686,Feature Request: load_state_dict should take filenames,2017-05-30 22:11:12+00:00,,0,3,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
1642,feature request: On-the-fly Operation Batching in Dynamic Computation Graphs,2017-05-24 13:54:16+00:00,,0,1,"[Label(name=""feature""), Label(name=""triaged"")]"
1641,[Feature request] In-place 'max' method for Tensor,2017-05-24 11:14:26+00:00,,0,7,"[Label(name=""todo""), Label(name=""feature""), Label(name=""triaged"")]"
1591,Pad PackedSequences to original batch length,2017-05-19 00:10:18+00:00,,1,7,"[Label(name=""hackamonth""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
1529,[feature request] Caching allocator diagnostics and memory allocation tracing/visualization,2017-05-10 20:08:34+00:00,,0,29,"[Label(name=""feature""), Label(name=""module: memory usage""), Label(name=""triaged"")]"
1512,[feature request] Support tensors of different sizes as batch elements in DataLoader,2017-05-08 16:13:15+00:00,,0,18,"[Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged""), Label(name=""module: nestedtensor"")]"
1505,Cannot find Intel MKL,2017-05-07 18:36:31+00:00,,0,6,"[Label(name=""module: dependency bug""), Label(name=""module: build""), Label(name=""triaged""), Label(name=""module: mkl"")]"
1489,Optimizer should track parameter names and not id,2017-05-05 16:26:45+00:00,,0,10,"[Label(name=""module: optimizer""), Label(name=""triaged"")]"
1487,[feature request/proposal] Relax scale_factor for nearest neighbor upsampling,2017-05-05 15:35:21+00:00,,0,1,"[Label(name=""todo""), Label(name=""feature""), Label(name=""triaged"")]"
1468,avg_pool functions hold input for backward,2017-05-04 10:17:37+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""module: pooling"")]"
1462,"Change sparse_mask to take indexing mask, rather than entire sparse tensor",2017-05-03 20:01:36+00:00,,0,0,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged"")]"
1442,Optimizers can't be moved to a different GPU,2017-05-02 19:23:02+00:00,,0,2,"[Label(name=""feature""), Label(name=""triaged"")]"
1410,BatchNorm should use Bessel's correction consistently,2017-04-30 13:11:50+00:00,,0,7,"[Label(name=""module: nn""), Label(name=""triaged""), Label(name=""module: norms and normalization"")]"
1369,"""Sparsified"" mathematical operations",2017-04-26 21:56:10+00:00,,0,15,"[Label(name=""module: sparse""), Label(name=""low priority""), Label(name=""triaged"")]"
1362,Feature Request: noise contrastive estimation/negative sampling,2017-04-26 18:40:29+00:00,,0,31,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged"")]"
1359,"Conjugate Gradient mentioned in docs, but not implemented",2017-04-26 10:06:09+00:00,,0,9,"[Label(name=""todo""), Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
1329,[proposed feature] Eve: Improving Stochastic Gradient Descent with Feedback,2017-04-22 06:32:24+00:00,,0,1,"[Label(name=""feature""), Label(name=""module: optimizer""), Label(name=""triaged"")]"
1328,Unhelpful CrossEntropyLoss dimension error message,2017-04-22 04:52:22+00:00,,0,8,"[Label(name=""module: loss""), Label(name=""module: cuda""), Label(name=""module: error checking""), Label(name=""triaged"")]"
1249,Dice Loss PR,2017-04-12 22:11:03+00:00,,0,48,"[Label(name=""module: loss""), Label(name=""triaged""), Label(name=""enhancement""), Label(name=""Stale"")]"
1178,Batched sparse QR factorizations and solves with cusolver,2017-04-03 15:03:12+00:00,,1,5,"[Label(name=""module: sparse""), Label(name=""feature""), Label(name=""triaged""), Label(name=""module: linear algebra""), Label(name=""Stale"")]"
934,dataloader parallels over elements vs over batches,2017-03-06 06:20:39+00:00,,0,2,"[Label(name=""todo""), Label(name=""feature""), Label(name=""module: dataloader""), Label(name=""triaged"")]"
842,BCELoss doesn't accept LongTensor targets,2017-02-24 20:06:48+00:00,,0,4,"[Label(name=""feature""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""Stale"")]"
711,Feature Request: Easier to extend base RNN implementation,2017-02-09 22:45:17+00:00,,0,32,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""Stale"")]"
634,Feature Request: NegativeSampling and HierarchicalSoftmax loss functions,2017-01-29 18:30:26+00:00,,0,11,"[Label(name=""feature""), Label(name=""module: nn""), Label(name=""module: loss""), Label(name=""triaged""), Label(name=""Stale""), Label(name=""module: primTorch"")]"
630,Add Peephole connections for LSTMs?,2017-01-29 06:14:27+00:00,,0,18,"[Label(name=""feature""), Label(name=""triaged""), Label(name=""Stale"")]"
499,Feature Request: Locally Connected Layer,2017-01-19 10:36:23+00:00,,0,23,"[Label(name=""proposal accepted""), Label(name=""feature""), Label(name=""module: nn""), Label(name=""triaged""), Label(name=""Stale"")]"
285,Keyword arguments passed to module's __call__ aren't forwarded to the hooks,2016-12-01 22:42:55+00:00,,0,1,"[Label(name=""module: nn""), Label(name=""low priority""), Label(name=""triaged""), Label(name=""enhancement"")]"
88,expose backend selection and cudnn settings to the end user,2016-10-01 21:30:04+00:00,,0,3,"[Label(name=""module: cudnn""), Label(name=""feature""), Label(name=""triaged""), Label(name=""Stale"")]"
