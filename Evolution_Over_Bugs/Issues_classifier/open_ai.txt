1  # Buggy (dynamic shape tests missing)
1  # Buggy (poor performance in C++ extension)
0  # Not Buggy (configurations inquiry)
1  # Buggy (performance issue with OpenMP in CUDA)
1  # Buggy (incorrect results in torch.multinomial)
1  # Buggy (torch.einsum memory issue)
1  # Buggy (MPS assertion failure)
0  # Not Buggy (print statements in utils/cpp_extension.py)
1  # Buggy (duplicate code in python_arg_parser.cpp)
1  # Buggy (heap-buffer-overflow in pack_padded_sequence)
1  # Buggy (Lintrunner takes too long in CI)
1  # Buggy (slow torch.bmm with cuBLAS>12.1.0)
0  # Not Buggy (Validations for 2.1.2 release)
1  # Buggy (Sparse CSC/CSR Tensor Serialization Load Issue)
1  # Buggy (nn.LSTM tolerates wrong input shape)
1  # Buggy (Sparse block tensors issue)
1  # Buggy (precision issue in test_vmapvjpvjp_linalg_tensorsolve_cpu_float32)
1  # Buggy (segfault in torch.Tensor.index_add)
1  # Buggy (SparseTensor index select uses more CUDA memory)
1  # Buggy (Intel GPU oneDNN Upstreaming)
1  # Buggy (CUDA graph doesn't update tensor on replay)
1  # Buggy (Intel GPU Runtime Upstreaming)
1  # Buggy (MacOS tests randomly fail after a commit)
1  # Buggy (Efficient Cholesky and QR updates)
1  # Buggy (Assertion failure with Sparse and Dense Tensors)
1  # Buggy (Unsupported call_method UserDefinedObjectVariable)
1  # Buggy (Add head_mask for transformers)
1  # Buggy (Refactor op level_debug for ONNX)
1  # Buggy (Extend test_fx_op_conistency.py for ONNX)
1  # Buggy (torch.compile x autograd.Function x enum inputs graph breaks)
1  # Buggy (AOTAutograd misnamed assert_functional_graph)
1  # Buggy (Inference failure on aarch64 with `nn.Linear`)
1  # Buggy (aot_module fails to trace modules with shared params)
1  # Buggy (torch.cuda.amp.common.amp_definitely_not_available() failed)
1  # Buggy (Intel GPU Upstreaming)
1  # Buggy (AppleSilicon binaries built without OpenMP support)
1  # Buggy (torch.from_numpy does not support set_default_device)
1  # Buggy (Update pytorch cpuinfo submodule)
1  # Buggy (Unexpected Results in PyTorch Tensor Operations)
1  # Buggy (ONNX export causes file enlargement and crashes with TensorRT)
1  # Buggy (SymFloat object has no attribute 'is_integer')
1  # Buggy (Dynamo guards key error for guarded_backend_cache.cached_backends)
1  # Buggy (torch.fft.ifft crashes for empty input)
1  # Buggy (__torch_dispatch__ fails on functionalization)
1  # Buggy (Error when calculating Jacobian of torch.conj)
1  # Buggy (Back DeviceMesh initialization by custom_pg)
1  # Buggy (RNN argument order)
1  # Buggy (macOS x86 builds/test deprecation)
1  # Buggy (Missing packaging dependency in torch 2.1.x)
1  # Buggy (torch.compiler.disable causes a guard failure)
1  # Buggy (Flawed testing of onesidedness in istft)
0  # Not Buggy (Slow initialization on first model call in version 2.1)
1  # Buggy (Inconsistency between nan cast to int32 on CPU and GPU)
1  # Buggy (Inconsistency on torch.clamp)
1  # Buggy (Internal CI for libTorch)
1  # Buggy (Build LibTorch for Windows ARM64)
1  # Buggy (Create a reproducible build for LibTorch x64 on VS2022)
1  # Buggy (Torchscript produces incorrect result when argmax result is used in indexing)
1  # Buggy (Size error when using bits-level ops + broadcasting + view)
1  # Buggy (PYTORCH_NO_CUDA_MEMORY_CACHING=1 with torch.multiprocessing shared tensors)
1  # Buggy (Tensor copied over to multiple GPUs on its own)
1  # Buggy (Bug in element-wise multiplication of torch.sparse_csr_tensors on GPU)
1  # Buggy (Given a flag, FakeTensors should store metadata about their creation stacktrace)
1  # Buggy (StableDiffusion unet with cudagraphs backend raises fake tensor mismatch error)
1  # Buggy (Update error message on cache size exceeded)
1  # Buggy (Change automatic_dynamic_shapes to trigger on cache_size_limit recompiles but not accumulated_cache_size_limit recompiles)
1  # Buggy (Raise torch._dynamo.config.accumulated_cache_size_limit higher or potentially remove it)
1  # Buggy (_foreach_supported_types is a list type used for in check of _default_to_fused_or_foreach method in optimizer.py)
1  # Buggy (Parameters between models don't copy in the C++ Pytorch Frontend under windows)
1  # Buggy (phi_1_5 accuracy failure and AMP single thread performance regression)
1  # Buggy (detectron2_fcos_r_50_fpn accuracy and performance failure)
1  # Buggy (Installation error: CMake Error at third_party/benchmark/CMakeLists.txt)
1  # Buggy (Transformer with convolutional position-wise feed forward network)
1  # Buggy (Behavior of Using different device in Autocast context)
1  # Buggy (Torch Cpu Memory Leak with FastApi uvicorn)
1  # Buggy (Redundant calling of findOp in findSchemaOrThrow method of Dispatcher.cpp)
1  # Buggy (Remove SmallVector optimization in PyInterpreter.cpp when storing custom sizes)
1  # Buggy (torch.compile <> __torch_dispatch__ support tracker issue)
1  # Buggy (__torch_dispatch__ + compile: extra guards)
1  # Buggy (Refactor TracingContext to take a more limited subset of ViewAndMutationMeta)
1  # Buggy (AOTAutograd, refactor run_functionalized_fw_and_collect_metadata)
1  # Buggy (better testing for subclasses + compile)
1  # Buggy (BUG pytree equal dicts do not imply equal leaves and equal treespecs)
1  # Buggy (Respect user-specified USE_ROCM/USE_CUDA)
1  # Buggy (TypeError: unhashable type: non-singleton SymInt in AOTAutograd merge_view_inputs)
1  # Buggy (Improve usability of CUDA package by adding description of CUDA)
1  # Buggy (Register Meta func for aten::_cslt_sparse_mm)
1  # Buggy (Custom Process Group for Each Module in FSDP)
1  # Buggy (Pytorch DDP across nodes: self._store = TCPStore RuntimeError)
1  # Buggy (WARNING could not load None, generating random data instead)
1  # Buggy (out-parameter in torch.matmul() works for cuda but not for cpu)
1  # Buggy (Incorrect line in description of torch.frombuffer() method)
1  # Buggy (AOTAutograd Incorrect CSE aliasing while requires_grad meta differs)
1  # Buggy (AOTAutograd torch.compile under ambient no_grad is broken)
1  # Buggy (AdaptiveLogSoftmaxWithLoss division by zero)
1  # Buggy (CUDA graph captures multi-stream function, allocations not serviced correctly)
1  # Buggy (Mutation after tensor.expand returns wrong result)
1  # Buggy (Per-Parameter-Sharding FSDP Tracker)
1  # Buggy (Compile pytorch for ppc64 redhat8)
