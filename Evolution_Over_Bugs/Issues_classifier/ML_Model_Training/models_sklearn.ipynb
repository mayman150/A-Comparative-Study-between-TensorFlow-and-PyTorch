{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of this Notebook: \n",
    "#### The purpose of this notebook is simply evaluating the results for pytorch with title and body, pytorch with title, tensorflow with title and body, and tensorflow with title. This will be helpful to choose the best model for our usecase to identify whether the issues are buggy or not. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Using Bert Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "col1 = 'BERT Embedding'\n",
    "col2 = 'Issue Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_torch_Title_bert = pd.read_csv('./Mapped_Data/Data_with_Embeddings/GT_Title_bert_data_pytorch.csv')\n",
    "data_tf_Title_bert    = data = pd.read_csv('./Mapped_Data/Data_with_Embeddings/GT_Title_bert_data_tf.csv')\n",
    "\n",
    "#title and body together as a vector of embeddings\n",
    "data_tf_concat_bert = pd.read_csv('./Mapped_Data/Data_with_Embeddings/GT_bert_concat_data_tf.csv')\n",
    "data_torch_concat_bert = pd.read_csv('./Mapped_Data/Data_with_Embeddings/GT_bert_concat_data_torch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Helpful Functions for preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_extra_commas(input_string):\n",
    "    # Use regular expression to replace multiple commas with a single comma\n",
    "    cleaned_string = re.sub(',+', ',', input_string)\n",
    "    return cleaned_string\n",
    "\n",
    "\n",
    "def modify(input_string):\n",
    "    try:\n",
    "        input_string = input_string.replace('\\n', '').replace(' ', ',').replace(\":\", \"\")\n",
    "        input_string = remove_extra_commas(input_string)\n",
    "        if(input_string[1] == ','):\n",
    "            input_string = input_string[0] + input_string[2:]\n",
    "        input_string = ast.literal_eval(input_string.replace(' ',''))\n",
    "    except:\n",
    "        print(input_string)\n",
    "    return input_string\n",
    "\n",
    "\n",
    "\n",
    "def training(model, X,y):\n",
    "    # model = LogisticRegression()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring_metrics = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score),\n",
    "        'f1_score': make_scorer(f1_score)\n",
    "    }\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    # You can adjust the 'cv' parameter to change the number of folds\n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=scoring_metrics)\n",
    "\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-Validation Accuracy Scores:\", scores['test_accuracy'])\n",
    "    print(\"Mean Accuracy:\", scores['test_accuracy'].mean())\n",
    "\n",
    "    print(\"\\nCross-Validation Precision Scores:\", scores['test_precision'])\n",
    "    print(\"Mean Precision:\", scores['test_precision'].mean())\n",
    "\n",
    "    print(\"\\nCross-Validation Recall Scores:\", scores['test_recall'])\n",
    "    print(\"Mean Recall:\", scores['test_recall'].mean())\n",
    "\n",
    "    print(\"\\nCross-Validation F1 Scores:\", scores['test_f1_score'])\n",
    "    print(\"Mean F1 Score:\", scores['test_f1_score'].mean())\n",
    "    \n",
    "def preprocessEmbeddingsTitle(data, col):\n",
    "    X = data[col].apply(lambda x: modify(x))\n",
    "    X = np.asarray(X.values.tolist(), dtype=np.float32)\n",
    "    #Given data['Is Bug']make them 0 and 1\n",
    "    data['Is Bug'] = data['Is Bug'].apply(lambda x: 1 if x == True else 0)\n",
    "    #get it as numpy array\n",
    "    y = np.asarray(data['Is Bug'], dtype=np.uint8)\n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 1: PyTorch with Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.87179487 0.94871795 0.87179487 0.85714286 0.83116883]\n",
      "Mean Accuracy: 0.8761238761238761\n",
      "\n",
      "Cross-Validation Precision Scores: [0.87179487 0.97297297 0.87179487 0.83333333 0.82051282]\n",
      "Mean Precision: 0.8740817740817741\n",
      "\n",
      "Cross-Validation Recall Scores: [0.87179487 0.92307692 0.87179487 0.8974359  0.84210526]\n",
      "Mean Recall: 0.8812415654520919\n",
      "\n",
      "Cross-Validation F1 Scores: [0.87179487 0.94736842 0.87179487 0.86419753 0.83116883]\n",
      "Mean F1 Score: 0.8772649053350807\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75641026 0.82051282 0.74358974 0.74025974 0.83116883]\n",
      "Mean Accuracy: 0.7783882783882783\n",
      "\n",
      "Cross-Validation Precision Scores: [0.73809524 0.87878788 0.77142857 0.77142857 0.82051282]\n",
      "Mean Precision: 0.796050616050616\n",
      "\n",
      "Cross-Validation Recall Scores: [0.79487179 0.74358974 0.69230769 0.69230769 0.84210526]\n",
      "Mean Recall: 0.7530364372469636\n",
      "\n",
      "Cross-Validation F1 Scores: [0.7654321  0.80555556 0.72972973 0.72972973 0.83116883]\n",
      "Mean F1 Score: 0.7723231889898556\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.85897436 0.93589744 0.85897436 0.83116883 0.83116883]\n",
      "Mean Accuracy: 0.8632367632367632\n",
      "\n",
      "Cross-Validation Precision Scores: [0.78       0.94736842 0.81818182 0.75       0.75510204]\n",
      "Mean Precision: 0.8101304560101553\n",
      "\n",
      "Cross-Validation Recall Scores: [1.         0.92307692 0.92307692 1.         0.97368421]\n",
      "Mean Recall: 0.9639676113360324\n",
      "\n",
      "Cross-Validation F1 Scores: [0.87640449 0.93506494 0.86746988 0.85714286 0.85057471]\n",
      "Mean F1 Score: 0.8773313757503132\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.85897436 0.8974359  0.84615385 0.77922078 0.80519481]\n",
      "Mean Accuracy: 0.8373959373959374\n",
      "\n",
      "Cross-Validation Precision Scores: [0.79166667 0.87804878 0.78723404 0.7037037  0.7254902 ]\n",
      "Mean Precision: 0.7772286778979597\n",
      "\n",
      "Cross-Validation Recall Scores: [0.97435897 0.92307692 0.94871795 0.97435897 0.97368421]\n",
      "Mean Recall: 0.9588394062078273\n",
      "\n",
      "Cross-Validation F1 Scores: [0.87356322 0.9        0.86046512 0.8172043  0.83146067]\n",
      "Mean F1 Score: 0.8565386619804893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 2: PyTorch with Title and Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.83333333 0.92307692 0.8974359  0.87012987 0.87012987]\n",
      "Mean Accuracy: 0.8788211788211788\n",
      "\n",
      "Cross-Validation Precision Scores: [0.84210526 0.97142857 0.87804878 0.82222222 0.85      ]\n",
      "Mean Precision: 0.8727609674592985\n",
      "\n",
      "Cross-Validation Recall Scores: [0.82051282 0.87179487 0.92307692 0.94871795 0.89473684]\n",
      "Mean Recall: 0.8917678812415654\n",
      "\n",
      "Cross-Validation F1 Scores: [0.83116883 0.91891892 0.9        0.88095238 0.87179487]\n",
      "Mean F1 Score: 0.8805670005670005\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.69230769 0.78205128 0.75641026 0.80519481 0.71428571]\n",
      "Mean Accuracy: 0.7500499500499501\n",
      "\n",
      "Cross-Validation Precision Scores: [0.6744186  0.86666667 0.79411765 0.8        0.69047619]\n",
      "Mean Precision: 0.7651358217705686\n",
      "\n",
      "Cross-Validation Recall Scores: [0.74358974 0.66666667 0.69230769 0.82051282 0.76315789]\n",
      "Mean Recall: 0.7372469635627529\n",
      "\n",
      "Cross-Validation F1 Scores: [0.70731707 0.75362319 0.73972603 0.81012658 0.725     ]\n",
      "Mean F1 Score: 0.747158574250454\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.79487179 0.92307692 0.82051282 0.83116883 0.83116883]\n",
      "Mean Accuracy: 0.8401598401598402\n",
      "\n",
      "Cross-Validation Precision Scores: [0.74468085 0.94594595 0.77777778 0.7826087  0.75510204]\n",
      "Mean Precision: 0.8012230622512109\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8974359  0.8974359  0.8974359  0.92307692 0.97368421]\n",
      "Mean Recall: 0.9178137651821864\n",
      "\n",
      "Cross-Validation F1 Scores: [0.81395349 0.92105263 0.83333333 0.84705882 0.85057471]\n",
      "Mean F1 Score: 0.8531945978914927\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.78205128 0.8974359  0.82051282 0.81818182 0.81818182]\n",
      "Mean Accuracy: 0.8272727272727274\n",
      "\n",
      "Cross-Validation Precision Scores: [0.72916667 0.8974359  0.77777778 0.75510204 0.75      ]\n",
      "Mean Precision: 0.7818964765393337\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8974359  0.8974359  0.8974359  0.94871795 0.94736842]\n",
      "Mean Recall: 0.9176788124156546\n",
      "\n",
      "Cross-Validation F1 Scores: [0.8045977  0.8974359  0.83333333 0.84090909 0.8372093 ]\n",
      "Mean F1 Score: 0.8426970650306655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 3: TensorFlow with Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75362319 0.75362319 0.79411765 0.85294118 0.80882353]\n",
      "Mean Accuracy: 0.7926257459505541\n",
      "\n",
      "Cross-Validation Precision Scores: [0.73684211 0.77419355 0.83333333 0.92857143 0.83870968]\n",
      "Mean Precision: 0.8223300185948743\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8        0.70588235 0.73529412 0.76470588 0.76470588]\n",
      "Mean Recall: 0.7541176470588236\n",
      "\n",
      "Cross-Validation F1 Scores: [0.76712329 0.73846154 0.78125    0.83870968 0.8       ]\n",
      "Mean F1 Score: 0.7851089007104253\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.62318841 0.63768116 0.73529412 0.76470588 0.72058824]\n",
      "Mean Accuracy: 0.6962915601023018\n",
      "\n",
      "Cross-Validation Precision Scores: [0.60465116 0.65517241 0.75       0.76470588 0.72727273]\n",
      "Mean Precision: 0.7003604372418939\n",
      "\n",
      "Cross-Validation Recall Scores: [0.74285714 0.55882353 0.70588235 0.76470588 0.70588235]\n",
      "Mean Recall: 0.6956302521008404\n",
      "\n",
      "Cross-Validation F1 Scores: [0.66666667 0.6031746  0.72727273 0.76470588 0.71641791]\n",
      "Mean F1 Score: 0.6956475579829398\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.73913043 0.75362319 0.63235294 0.82352941 0.77941176]\n",
      "Mean Accuracy: 0.7456095481670928\n",
      "\n",
      "Cross-Validation Precision Scores: [0.70731707 0.74285714 0.66666667 0.89285714 0.85185185]\n",
      "Mean Precision: 0.7723099754807071\n",
      "\n",
      "Cross-Validation Recall Scores: [0.82857143 0.76470588 0.52941176 0.73529412 0.67647059]\n",
      "Mean Recall: 0.706890756302521\n",
      "\n",
      "Cross-Validation F1 Scores: [0.76315789 0.75362319 0.59016393 0.80645161 0.75409836]\n",
      "Mean F1 Score: 0.7334989982255664\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75362319 0.72463768 0.66176471 0.70588235 0.75      ]\n",
      "Mean Accuracy: 0.7191815856777494\n",
      "\n",
      "Cross-Validation Precision Scores: [0.6875     0.7027027  0.7037037  0.81818182 0.79310345]\n",
      "Mean Precision: 0.7410383345728173\n",
      "\n",
      "Cross-Validation Recall Scores: [0.94285714 0.76470588 0.55882353 0.52941176 0.67647059]\n",
      "Mean Recall: 0.6944537815126051\n",
      "\n",
      "Cross-Validation F1 Scores: [0.79518072 0.73239437 0.62295082 0.64285714 0.73015873]\n",
      "Mean F1 Score: 0.7047083563553508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 4: TensorFlow with Title and Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.73913043 0.79710145 0.77941176 0.82352941 0.79411765]\n",
      "Mean Accuracy: 0.7866581415174766\n",
      "\n",
      "Cross-Validation Precision Scores: [0.71794872 0.79411765 0.91304348 0.86666667 0.8125    ]\n",
      "Mean Precision: 0.8208553019870155\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8        0.79411765 0.61764706 0.76470588 0.76470588]\n",
      "Mean Recall: 0.7482352941176471\n",
      "\n",
      "Cross-Validation F1 Scores: [0.75675676 0.79411765 0.73684211 0.8125     0.78787879]\n",
      "Mean F1 Score: 0.7776190593915053\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.56521739 0.62318841 0.51470588 0.52941176 0.60294118]\n",
      "Mean Accuracy: 0.5670929241261722\n",
      "\n",
      "Cross-Validation Precision Scores: [0.57575758 0.60526316 0.51351351 0.53125    0.62068966]\n",
      "Mean Precision: 0.5692947804676479\n",
      "\n",
      "Cross-Validation Recall Scores: [0.54285714 0.67647059 0.55882353 0.5        0.52941176]\n",
      "Mean Recall: 0.5615126050420167\n",
      "\n",
      "Cross-Validation F1 Scores: [0.55882353 0.63888889 0.53521127 0.51515152 0.57142857]\n",
      "Mean F1 Score: 0.5639007544972748\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.72463768 0.63768116 0.76470588 0.73529412 0.75      ]\n",
      "Mean Accuracy: 0.722463768115942\n",
      "\n",
      "Cross-Validation Precision Scores: [0.76666667 0.64516129 0.82142857 0.75       0.77419355]\n",
      "Mean Precision: 0.7514900153609831\n",
      "\n",
      "Cross-Validation Recall Scores: [0.65714286 0.58823529 0.67647059 0.70588235 0.70588235]\n",
      "Mean Recall: 0.6667226890756303\n",
      "\n",
      "Cross-Validation F1 Scores: [0.70769231 0.61538462 0.74193548 0.72727273 0.73846154]\n",
      "Mean F1 Score: 0.7061493345364313\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.50724638 0.53623188 0.75       0.72058824 0.60294118]\n",
      "Mean Accuracy: 0.6234015345268543\n",
      "\n",
      "Cross-Validation Precision Scores: [0.51724138 0.53571429 0.79310345 0.74193548 0.58974359]\n",
      "Mean Precision: 0.63554763738301\n",
      "\n",
      "Cross-Validation Recall Scores: [0.42857143 0.44117647 0.67647059 0.67647059 0.67647059]\n",
      "Mean Recall: 0.5798319327731093\n",
      "\n",
      "Cross-Validation F1 Scores: [0.46875    0.48387097 0.73015873 0.70769231 0.63013699]\n",
      "Mean F1 Score: 0.6041217983788687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Results with Issue Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.855072463768116, Precision: 0.8573232323232323, Recall: 0.8585304054054055, F1: 0.8550420168067226\n",
      "Fold 2 - Accuracy: 0.7681159420289855, Precision: 0.7922727272727272, Recall: 0.7701680672268907, F1: 0.7641025641025643\n",
      "Fold 3 - Accuracy: 0.8676470588235294, Precision: 0.8715277777777778, Recall: 0.8731473408892764, F1: 0.8676184295911746\n",
      "Fold 4 - Accuracy: 0.8676470588235294, Precision: 0.8780701754385964, Recall: 0.8757628596338274, F1: 0.8676184295911745\n",
      "Fold 5 - Accuracy: 0.8823529411764706, Precision: 0.8897922312556459, Recall: 0.8761987794245858, F1: 0.8797524314765695\n",
      "\n",
      "Mean Accuracy: 0.8481670929241261\n",
      "Mean Precision: 0.8577972288135959\n",
      "Mean Recall: 0.8507614905159973\n",
      "Mean F1: 0.8468267743136412\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.8985507246376812, Precision: 0.8977272727272727, Recall: 0.8990709459459459, F1: 0.8982086406743941\n",
      "Fold 2 - Accuracy: 0.8695652173913043, Precision: 0.8769230769230769, Recall: 0.8705882352941177, F1: 0.8691253951527924\n",
      "Fold 3 - Accuracy: 0.9264705882352942, Precision: 0.9305555555555556, Recall: 0.9324324324324325, F1: 0.9264546831062082\n",
      "Fold 4 - Accuracy: 0.9558823529411765, Precision: 0.9548611111111112, Recall: 0.9568439407149085, F1: 0.9556425309849967\n",
      "Fold 5 - Accuracy: 0.9705882352941176, Precision: 0.970357454228422, Recall: 0.970357454228422, F1: 0.970357454228422\n",
      "\n",
      "Mean Accuracy: 0.9242114236999148\n",
      "Mean Precision: 0.9260848941090878\n",
      "Mean Recall: 0.9258586017231654\n",
      "Mean F1: 0.9239577408293627\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.8115942  0.69565217 0.85294118 0.80882353 0.82352941]\n",
      "Mean Accuracy: 0.7985080988917306\n",
      "\n",
      "Mean Precision: 0.8215539709459975\n",
      "Mean Recall: 0.802272419647894\n",
      "Mean F1 Score: 0.7941631229001876\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.86956522 0.79710145 0.88235294 0.89705882 0.94117647]\n",
      "Mean Accuracy: 0.8774509803921567\n",
      "\n",
      "Mean Precision: 0.8825963127192843\n",
      "Mean Recall: 0.879666709098635\n",
      "Mean F1 Score: 0.8768171132067584\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Results with Issue Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.8846153846153846, Precision: 0.9055335968379447, Recall: 0.85625, F1: 0.871405019234292\n",
      "Fold 2 - Accuracy: 0.8974358974358975, Precision: 0.9024390243902439, Recall: 0.9111111111111111, F1: 0.897165458141068\n",
      "Fold 3 - Accuracy: 0.9358974358974359, Precision: 0.9377059986816085, Recall: 0.9368421052631579, F1: 0.9358868979122144\n",
      "Fold 4 - Accuracy: 0.922077922077922, Precision: 0.9261904761904762, Recall: 0.9227395411605939, F1: 0.9219594594594595\n",
      "Fold 5 - Accuracy: 0.948051948051948, Precision: 0.9483805668016194, Recall: 0.9489864864864865, F1: 0.9480431848852902\n",
      "\n",
      "Mean Accuracy: 0.9176157176157176\n",
      "Mean Precision: 0.9240499325803786\n",
      "Mean Recall: 0.9151858488042699\n",
      "Mean F1: 0.9148920039264649\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.9358974358974359, Precision: 0.9349049964813512, Recall: 0.9291666666666667, F1: 0.9318539227677791\n",
      "Fold 2 - Accuracy: 0.9102564102564102, Precision: 0.9125, Recall: 0.9222222222222223, F1: 0.9098861198217527\n",
      "Fold 3 - Accuracy: 0.9615384615384616, Precision: 0.9620962425840475, Recall: 0.9611842105263158, F1: 0.9614814814814814\n",
      "Fold 4 - Accuracy: 0.961038961038961, Precision: 0.9612010796221322, Recall: 0.9612010796221322, F1: 0.9610389610389611\n",
      "Fold 5 - Accuracy: 0.961038961038961, Precision: 0.9625, Recall: 0.9625, F1: 0.961038961038961\n",
      "\n",
      "Mean Accuracy: 0.945954045954046\n",
      "Mean Precision: 0.9466404637375062\n",
      "Mean Recall: 0.9472548358074674\n",
      "Mean F1: 0.945059889229787\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.8974359  0.87179487 0.92307692 0.8961039  0.96103896]\n",
      "Mean Accuracy: 0.9098901098901099\n",
      "\n",
      "Mean Precision: 0.9143433037560124\n",
      "Mean Recall: 0.9078044436597068\n",
      "Mean F1 Score: 0.9076686026806204\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words -< Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.88461538 0.82051282 0.91025641 0.90909091 0.90909091]\n",
      "Mean Accuracy: 0.8867132867132866\n",
      "\n",
      "Mean Precision: 0.9021041613536142\n",
      "Mean Recall: 0.8870552181736391\n",
      "Mean F1 Score: 0.8839120659480934\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. TensorFlow Results with title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Accuracy: [0.52173913 0.53623188 0.47058824 0.5        0.45588235]\n",
      "Precision: [0.66269841 0.55373303 0.73134328 0.63809524 0.22794118]\n",
      "Recall: [0.55194257 0.53991597 0.51351351 0.53792502 0.5       ]\n",
      "F1 Score: [0.44259486 0.50626118 0.34264232 0.41438703 0.31313131]\n",
      "\n",
      "Mean Accuracy: 0.49688832054560955\n",
      "Mean Precision: 0.5627622285041074\n",
      "Mean Recall: 0.528659413852725\n",
      "Mean F1 Score: 0.4038033409092924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Tokenization and preprocessing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=preprocessed_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to average Word2Vec vectors for a document\n",
    "def document_embedding(doc, model):\n",
    "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Create document embeddings using Word2Vec\n",
    "embeddings = [document_embedding(doc, word2vec_model) for doc in preprocessed_documents]\n",
    "\n",
    "# Create a pipeline with logistic regression\n",
    "model = make_pipeline(LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(model, embeddings, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "print(\"Accuracy:\", cv_results['test_accuracy'])\n",
    "print(\"Precision:\", cv_results['test_precision'])\n",
    "print(\"Recall:\", cv_results['test_recall'])\n",
    "print(\"F1 Score:\", cv_results['test_f1'])\n",
    "\n",
    "# Calculate and print mean values\n",
    "mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "mean_precision = np.mean(cv_results['test_precision'])\n",
    "mean_recall = np.mean(cv_results['test_recall'])\n",
    "mean_f1 = np.mean(cv_results['test_f1'])\n",
    "\n",
    "print(\"\\nMean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pytorch Results with title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Accuracy: [0.38461538 0.42307692 0.48717949 0.55844156 0.48051948]\n",
      "Precision: [0.19230769 0.21153846 0.24358974 0.76388889 0.24025974]\n",
      "Recall: [0.5        0.5        0.5        0.56410256 0.5       ]\n",
      "F1 Score: [0.27777778 0.2972973  0.32758621 0.45909091 0.3245614 ]\n",
      "\n",
      "Mean Accuracy: 0.4667665667665667\n",
      "Mean Precision: 0.3303169053169053\n",
      "Mean Recall: 0.5128205128205128\n",
      "Mean F1 Score: 0.33726271891426157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Tokenization and preprocessing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=preprocessed_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to average Word2Vec vectors for a document\n",
    "def document_embedding(doc, model):\n",
    "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Create document embeddings using Word2Vec\n",
    "embeddings = [document_embedding(doc, word2vec_model) for doc in preprocessed_documents]\n",
    "\n",
    "# Create a pipeline with logistic regression\n",
    "model = make_pipeline(LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(model, embeddings, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "print(\"Accuracy:\", cv_results['test_accuracy'])\n",
    "print(\"Precision:\", cv_results['test_precision'])\n",
    "print(\"Recall:\", cv_results['test_recall'])\n",
    "print(\"F1 Score:\", cv_results['test_f1'])\n",
    "\n",
    "# Calculate and print mean values\n",
    "mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "mean_precision = np.mean(cv_results['test_precision'])\n",
    "mean_recall = np.mean(cv_results['test_recall'])\n",
    "mean_f1 = np.mean(cv_results['test_f1'])\n",
    "\n",
    "print(\"\\nMean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "From th results above, we can see that using Bag of Words is the best choice for classifying the bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting whether the issue is buggy or not using Bag Of Words for all Issue Titles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_type(string):\n",
    "    # Use regular expression to find all occurrences of 'name=\"type:xyz\"'\n",
    "    matches = re.findall(r'name=\"([^\"]+)', string)\n",
    "    #convert the list to string\n",
    "    matches = ' '.join(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_torch = pd.read_csv('../../Issues_parser/Scraped_Data/torch_issues/torch_issues_classified.csv_0.csv')\n",
    "for i in range(1, 4):\n",
    "    df_torch = pd.concat([df_torch, pd.read_csv('../../Issues_parser/Scraped_Data/torch_issues/torch_issues_classified.csv_' + str(i) + '.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_torch['Tags'] = df_torch['Tags'].apply(get_type)\n",
    "df_torch['Issue Title'] = df_torch['Issue Title'] + ' ' + df_torch['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordBasedChecker(IssueTitle):\n",
    "    '''\n",
    "    Input: IssueTitle, IssueBody\n",
    "    Output: True/False\n",
    "    '''\n",
    "    bug_keywords = {\n",
    "    'error',\n",
    "    'exception',\n",
    "    'traceback',\n",
    "    'crash',\n",
    "    'issue',\n",
    "    'problem',\n",
    "    'unexpected',\n",
    "    'incorrect',\n",
    "    'not working',\n",
    "    'failure',\n",
    "    'flaw',\n",
    "    'mistake',\n",
    "    'fault',\n",
    "    'glitch',\n",
    "    'inconsistency',\n",
    "    'abnormal',\n",
    "    'unexpected behavior',\n",
    "    'unhandled',\n",
    "    'segmentation fault',\n",
    "    'defect',\n",
    "    'bug'\n",
    "    }\n",
    "    #Parse the title\n",
    "    try:\n",
    "        IssueTitle = IssueTitle.lower()\n",
    "        IssueTitle = IssueTitle.split()\n",
    "         #Check if any of the keywords is in the title\n",
    "        for word in IssueTitle:\n",
    "            if word in bug_keywords:\n",
    "                return 1\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Predicted Labels usingwordBasedChecker\n",
    "predicted_labels = []\n",
    "for index, row in df_torch.iterrows():\n",
    "    predicted_labels.append(wordBasedChecker(row['Issue Title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the list to numpy array\n",
    "predicted_labels = np.asarray(predicted_labels)\n",
    "df_torch['Predicted_Is_Bug'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "#using frequency \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        processed_text = ' '.join(tokens)\n",
    "    except: \n",
    "        print(text)\n",
    "        processed_text = \"\"\n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "model.fit(preprocessed_documents, labels)\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = df_torch['Issue Title'].values.tolist()\n",
    "new_data_preprocessed = [preprocess_text(doc) for doc in new_data]\n",
    "LR_prediction = model.predict(new_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Is_Bug\n",
       "1    23028\n",
       "0    14735\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the predictions to the dataframe\n",
    "df_torch['LR_Predicted_Is_Bug'] = LR_prediction\n",
    "df_torch['Final_Is_Bug'] = df_torch['LR_Predicted_Is_Bug'] | df_torch['Predicted_Is_Bug']\n",
    "df_torch['Final_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue Number</th>\n",
       "      <th>Issue Title</th>\n",
       "      <th>Issue Body</th>\n",
       "      <th>Time created</th>\n",
       "      <th>Time closed</th>\n",
       "      <th>Number of Assignees</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Is Bug</th>\n",
       "      <th>Predicted_Is_Bug</th>\n",
       "      <th>LR_Predicted_Is_Bug</th>\n",
       "      <th>Final_Is_Bug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113781</td>\n",
       "      <td>DISABLED test_2d_fsdp_tp_ac_compile (__main__....</td>\n",
       "      <td>Platforms: linux\\n\\nBroken on multigpu\\n\\nTo r...</td>\n",
       "      <td>2023-11-15 17:59:31+00:00</td>\n",
       "      <td>2023-11-15 18:38:16+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>skipped</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113758</td>\n",
       "      <td>missing device=p.device in Adam optimizer, lea...</td>\n",
       "      <td>###  Describe the bug\\n\\nI am using the Adam ...</td>\n",
       "      <td>2023-11-15 13:00:20+00:00</td>\n",
       "      <td>2023-11-15 21:03:24+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>module: optimizer triaged</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113756</td>\n",
       "      <td>Wrongly formatted string in profiler_util.py t...</td>\n",
       "      <td>###  Describe the bug\\n\\nThe string in line h...</td>\n",
       "      <td>2023-11-15 12:43:01+00:00</td>\n",
       "      <td>2023-11-15 17:07:47+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>triaged module: regression oncall: profiler</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113704</td>\n",
       "      <td>RandomResizedCrop: error nll_loss2d_forward_ke...</td>\n",
       "      <td>###  Describe the bug\\n\\nI am running a seman...</td>\n",
       "      <td>2023-11-14 22:35:32+00:00</td>\n",
       "      <td>2023-11-15 16:24:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>needs reproduction module: loss module: cuda t...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113696</td>\n",
       "      <td>Spammy inductor debug log: cannot fuse (vert:2...</td>\n",
       "      <td>###  Describe the bug\\n\\nWhat it looks like:\\...</td>\n",
       "      <td>2023-11-14 22:21:25+00:00</td>\n",
       "      <td>2023-11-15 01:39:09+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12215</th>\n",
       "      <td>634</td>\n",
       "      <td>Feature Request: NegativeSampling and Hierarch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-29 18:30:26+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>feature module: nn module: loss triaged Stale ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>630</td>\n",
       "      <td>Add Peephole connections for LSTMs? feature tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-29 06:14:27+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>feature triaged Stale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12217</th>\n",
       "      <td>499</td>\n",
       "      <td>Feature Request: Locally Connected Layer propo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-19 10:36:23+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>proposal accepted feature module: nn triaged S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12218</th>\n",
       "      <td>285</td>\n",
       "      <td>Keyword arguments passed to module's __call__ ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-01 22:42:55+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>module: nn low priority triaged enhancement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12219</th>\n",
       "      <td>88</td>\n",
       "      <td>expose backend selection and cudnn settings to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-01 21:30:04+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>module: cudnn feature triaged Stale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37763 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Issue Number                                        Issue Title  \\\n",
       "0            113781  DISABLED test_2d_fsdp_tp_ac_compile (__main__....   \n",
       "1            113758  missing device=p.device in Adam optimizer, lea...   \n",
       "2            113756  Wrongly formatted string in profiler_util.py t...   \n",
       "3            113704  RandomResizedCrop: error nll_loss2d_forward_ke...   \n",
       "4            113696  Spammy inductor debug log: cannot fuse (vert:2...   \n",
       "...             ...                                                ...   \n",
       "12215           634  Feature Request: NegativeSampling and Hierarch...   \n",
       "12216           630  Add Peephole connections for LSTMs? feature tr...   \n",
       "12217           499  Feature Request: Locally Connected Layer propo...   \n",
       "12218           285  Keyword arguments passed to module's __call__ ...   \n",
       "12219            88  expose backend selection and cudnn settings to...   \n",
       "\n",
       "                                              Issue Body  \\\n",
       "0      Platforms: linux\\n\\nBroken on multigpu\\n\\nTo r...   \n",
       "1      ###  Describe the bug\\n\\nI am using the Adam ...   \n",
       "2      ###  Describe the bug\\n\\nThe string in line h...   \n",
       "3      ###  Describe the bug\\n\\nI am running a seman...   \n",
       "4      ###  Describe the bug\\n\\nWhat it looks like:\\...   \n",
       "...                                                  ...   \n",
       "12215                                                NaN   \n",
       "12216                                                NaN   \n",
       "12217                                                NaN   \n",
       "12218                                                NaN   \n",
       "12219                                                NaN   \n",
       "\n",
       "                    Time created                Time closed  \\\n",
       "0      2023-11-15 17:59:31+00:00  2023-11-15 18:38:16+00:00   \n",
       "1      2023-11-15 13:00:20+00:00  2023-11-15 21:03:24+00:00   \n",
       "2      2023-11-15 12:43:01+00:00  2023-11-15 17:07:47+00:00   \n",
       "3      2023-11-14 22:35:32+00:00  2023-11-15 16:24:51+00:00   \n",
       "4      2023-11-14 22:21:25+00:00  2023-11-15 01:39:09+00:00   \n",
       "...                          ...                        ...   \n",
       "12215  2017-01-29 18:30:26+00:00                        NaN   \n",
       "12216  2017-01-29 06:14:27+00:00                        NaN   \n",
       "12217  2017-01-19 10:36:23+00:00                        NaN   \n",
       "12218  2016-12-01 22:42:55+00:00                        NaN   \n",
       "12219  2016-10-01 21:30:04+00:00                        NaN   \n",
       "\n",
       "       Number of Assignees  Number of Comments  \\\n",
       "0                        0                   1   \n",
       "1                        0                   1   \n",
       "2                        1                   2   \n",
       "3                        0                   2   \n",
       "4                        0                   4   \n",
       "...                    ...                 ...   \n",
       "12215                    0                  11   \n",
       "12216                    0                  18   \n",
       "12217                    0                  23   \n",
       "12218                    0                   1   \n",
       "12219                    0                   3   \n",
       "\n",
       "                                                    Tags Is Bug  \\\n",
       "0                                                skipped  False   \n",
       "1                              module: optimizer triaged   True   \n",
       "2            triaged module: regression oncall: profiler   True   \n",
       "3      needs reproduction module: loss module: cuda t...   True   \n",
       "4                                                          True   \n",
       "...                                                  ...    ...   \n",
       "12215  feature module: nn module: loss triaged Stale ...    NaN   \n",
       "12216                              feature triaged Stale    NaN   \n",
       "12217  proposal accepted feature module: nn triaged S...    NaN   \n",
       "12218        module: nn low priority triaged enhancement    NaN   \n",
       "12219                module: cudnn feature triaged Stale    NaN   \n",
       "\n",
       "       Predicted_Is_Bug  LR_Predicted_Is_Bug  Final_Is_Bug  \n",
       "0                     0                    0             0  \n",
       "1                     0                    0             0  \n",
       "2                     0                    1             1  \n",
       "3                     1                    1             1  \n",
       "4                     0                    0             0  \n",
       "...                 ...                  ...           ...  \n",
       "12215                 0                    1             1  \n",
       "12216                 0                    0             0  \n",
       "12217                 0                    0             0  \n",
       "12218                 0                    1             1  \n",
       "12219                 0                    1             1  \n",
       "\n",
       "[37763 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR_Predicted_Is_Bug\n",
       "1    20583\n",
       "0    17180\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_torch['LR_Predicted_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Issue Number', 'Issue Title', 'Issue Body', 'Time created',\n",
       "       'Time closed', 'Number of Assignees', 'Number of Comments', 'Tags',\n",
       "       'Is Bug', 'Predicted_Is_Bug', 'LR_Predicted_Is_Bug', 'Final_Is_Bug'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_torch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the csv file \n",
    "saved_df = df_torch[['Issue Number','Issue Title', 'Time created',\n",
    "       'Time closed', 'Number of Assignees', 'Number of Comments', 'Tags', 'Final_Is_Bug']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_df.to_csv('torch_issues_classified.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Results with Issue Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = pd.read_csv('../../Issues_parser/Scraped_Data/tf_issues/tf_issues_classified.csv_0.csv')\n",
    "for i in range(1, 4):\n",
    "    df_tf = pd.concat([df_tf, pd.read_csv('../../Issues_parser/Scraped_Data/tf_issues/tf_issues_classified.csv_' + str(i) + '.csv')])\n",
    "df_tf['Tags'] = df_tf['Tags'].apply(get_type)\n",
    "df_tf['Issue Title'] = df_tf['Issue Title'] + ' ' + df_tf['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Predicted Labels usingwordBasedChecker\n",
    "tf_predicted_labels = []\n",
    "for index, row in df_tf.iterrows():\n",
    "    tf_predicted_labels.append(wordBasedChecker(row['Issue Title']))\n",
    "\n",
    "#convert the list to numpy array\n",
    "tf_predicted_labels = np.asarray(tf_predicted_labels)\n",
    "df_tf['Predicted_Is_Bug'] = tf_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted_Is_Bug\n",
       "0    30177\n",
       "1     6195\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf['Predicted_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "#using frequency \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        processed_text = ' '.join(tokens)\n",
    "    except: \n",
    "        print(text)\n",
    "        processed_text = \"\"\n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "model.fit(preprocessed_documents, labels)\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = df_tf['Issue Title'].values.tolist()\n",
    "new_data_preprocessed = [preprocess_text(doc) for doc in new_data]\n",
    "LR_prediction = model.predict(new_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Is_Bug\n",
       "1    23338\n",
       "0    13034\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the predictions to the dataframe\n",
    "df_tf['LR_Predicted_Is_Bug'] = LR_prediction\n",
    "df_tf['Final_Is_Bug'] = df_tf['LR_Predicted_Is_Bug'] | df_tf['Predicted_Is_Bug']\n",
    "df_tf['Final_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the csv file \n",
    "saved_df = df_tf[['Issue Number','Issue Title', 'Time created',\n",
    "       'Time closed', 'Number of Assignees', 'Number of Comments', 'Tags', 'Final_Is_Bug']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_df.to_csv('tf_issues_classified.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mohamed_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
