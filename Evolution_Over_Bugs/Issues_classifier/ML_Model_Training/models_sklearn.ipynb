{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of this Notebook: \n",
    "#### The purpose of this notebook is simply evaluating the results for pytorch with title and body, pytorch with title, tensorflow with title and body, and tensorflow with title. This will be helpful to choose the best model for our usecase to identify whether the issues are buggy or not. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Using Bert Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "col1 = 'BERT Embedding'\n",
    "col2 = 'Issue Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_torch_Title_bert = pd.read_csv('./Data/Data_with_Embeddings/GT_bert_data_pytorch.csv')\n",
    "data_tf_Title_bert    = data = pd.read_csv('./Data/Data_with_Embeddings/GT_bert_data_tf.csv')\n",
    "\n",
    "#title and body together as a vector of embeddings\n",
    "data_tf_concat_bert = pd.read_csv('./Data/Data_with_Embeddings/GT_bert_concat_data_tf.csv')\n",
    "data_torch_concat_bert = pd.read_csv('./Data/Data_with_Embeddings/GT_bert_concat_data_torch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Helpful Functions for preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_extra_commas(input_string):\n",
    "    # Use regular expression to replace multiple commas with a single comma\n",
    "    cleaned_string = re.sub(',+', ',', input_string)\n",
    "    return cleaned_string\n",
    "\n",
    "\n",
    "def modify(input_string):\n",
    "    try:\n",
    "        input_string = input_string.replace('\\n', '').replace(' ', ',').replace(\":\", \"\")\n",
    "        input_string = remove_extra_commas(input_string)\n",
    "        if(input_string[1] == ','):\n",
    "            input_string = input_string[0] + input_string[2:]\n",
    "        input_string = ast.literal_eval(input_string.replace(' ',''))\n",
    "    except:\n",
    "        print(input_string)\n",
    "    return input_string\n",
    "\n",
    "\n",
    "\n",
    "def training(model, X,y):\n",
    "    # model = LogisticRegression()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring_metrics = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score),\n",
    "        'f1_score': make_scorer(f1_score)\n",
    "    }\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    # You can adjust the 'cv' parameter to change the number of folds\n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=scoring_metrics)\n",
    "\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-Validation Accuracy Scores:\", scores['test_accuracy'])\n",
    "    print(\"Mean Accuracy:\", scores['test_accuracy'].mean())\n",
    "\n",
    "    print(\"\\nCross-Validation Precision Scores:\", scores['test_precision'])\n",
    "    print(\"Mean Precision:\", scores['test_precision'].mean())\n",
    "\n",
    "    print(\"\\nCross-Validation Recall Scores:\", scores['test_recall'])\n",
    "    print(\"Mean Recall:\", scores['test_recall'].mean())\n",
    "\n",
    "    print(\"\\nCross-Validation F1 Scores:\", scores['test_f1_score'])\n",
    "    print(\"Mean F1 Score:\", scores['test_f1_score'].mean())\n",
    "    \n",
    "def preprocessEmbeddingsTitle(data, col):\n",
    "    X = data[col].apply(lambda x: modify(x))\n",
    "    X = np.asarray(X.values.tolist(), dtype=np.float32)\n",
    "    #Given data['Is Bug']make them 0 and 1\n",
    "    data['Is Bug'] = data['Is Bug'].apply(lambda x: 1 if x == True else 0)\n",
    "    #get it as numpy array\n",
    "    y = np.asarray(data['Is Bug'], dtype=np.uint8)\n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 1: PyTorch with Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.87179487 0.94871795 0.87179487 0.85714286 0.83116883]\n",
      "Mean Accuracy: 0.8761238761238761\n",
      "\n",
      "Cross-Validation Precision Scores: [0.87179487 0.97297297 0.87179487 0.83333333 0.82051282]\n",
      "Mean Precision: 0.8740817740817741\n",
      "\n",
      "Cross-Validation Recall Scores: [0.87179487 0.92307692 0.87179487 0.8974359  0.84210526]\n",
      "Mean Recall: 0.8812415654520919\n",
      "\n",
      "Cross-Validation F1 Scores: [0.87179487 0.94736842 0.87179487 0.86419753 0.83116883]\n",
      "Mean F1 Score: 0.8772649053350807\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75641026 0.85897436 0.71794872 0.74025974 0.81818182]\n",
      "Mean Accuracy: 0.7783549783549784\n",
      "\n",
      "Cross-Validation Precision Scores: [0.73809524 0.91176471 0.75757576 0.77142857 0.8       ]\n",
      "Mean Precision: 0.7957728545963839\n",
      "\n",
      "Cross-Validation Recall Scores: [0.79487179 0.79487179 0.64102564 0.69230769 0.84210526]\n",
      "Mean Recall: 0.7530364372469636\n",
      "\n",
      "Cross-Validation F1 Scores: [0.7654321  0.84931507 0.69444444 0.72972973 0.82051282]\n",
      "Mean F1 Score: 0.7718868323891155\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.84615385 0.94871795 0.88461538 0.81818182 0.81818182]\n",
      "Mean Accuracy: 0.8631701631701632\n",
      "\n",
      "Cross-Validation Precision Scores: [0.7755102  0.94871795 0.82608696 0.74509804 0.75      ]\n",
      "Mean Precision: 0.8090826297074013\n",
      "\n",
      "Cross-Validation Recall Scores: [0.97435897 0.94871795 0.97435897 0.97435897 0.94736842]\n",
      "Mean Recall: 0.9638326585695006\n",
      "\n",
      "Cross-Validation F1 Scores: [0.86363636 0.94871795 0.89411765 0.84444444 0.8372093 ]\n",
      "Mean F1 Score: 0.8776251412366323\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.85897436 0.8974359  0.84615385 0.77922078 0.80519481]\n",
      "Mean Accuracy: 0.8373959373959374\n",
      "\n",
      "Cross-Validation Precision Scores: [0.79166667 0.87804878 0.78723404 0.7037037  0.7254902 ]\n",
      "Mean Precision: 0.7772286778979597\n",
      "\n",
      "Cross-Validation Recall Scores: [0.97435897 0.92307692 0.94871795 0.97435897 0.97368421]\n",
      "Mean Recall: 0.9588394062078273\n",
      "\n",
      "Cross-Validation F1 Scores: [0.87356322 0.9        0.86046512 0.8172043  0.83146067]\n",
      "Mean F1 Score: 0.8565386619804893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 2: PyTorch with Title and Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.83333333 0.92307692 0.8974359  0.87012987 0.87012987]\n",
      "Mean Accuracy: 0.8788211788211788\n",
      "\n",
      "Cross-Validation Precision Scores: [0.84210526 0.97142857 0.87804878 0.82222222 0.85      ]\n",
      "Mean Precision: 0.8727609674592985\n",
      "\n",
      "Cross-Validation Recall Scores: [0.82051282 0.87179487 0.92307692 0.94871795 0.89473684]\n",
      "Mean Recall: 0.8917678812415654\n",
      "\n",
      "Cross-Validation F1 Scores: [0.83116883 0.91891892 0.9        0.88095238 0.87179487]\n",
      "Mean F1 Score: 0.8805670005670005\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.67948718 0.74358974 0.78205128 0.75324675 0.75324675]\n",
      "Mean Accuracy: 0.7423243423243424\n",
      "\n",
      "Cross-Validation Precision Scores: [0.65909091 0.85185185 0.78947368 0.76315789 0.74358974]\n",
      "Mean Precision: 0.7614328166959745\n",
      "\n",
      "Cross-Validation Recall Scores: [0.74358974 0.58974359 0.76923077 0.74358974 0.76315789]\n",
      "Mean Recall: 0.7218623481781377\n",
      "\n",
      "Cross-Validation F1 Scores: [0.69879518 0.6969697  0.77922078 0.75324675 0.75324675]\n",
      "Mean F1 Score: 0.7362958326813749\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.79487179 0.88461538 0.83333333 0.83116883 0.84415584]\n",
      "Mean Accuracy: 0.8376290376290377\n",
      "\n",
      "Cross-Validation Precision Scores: [0.75555556 0.91666667 0.79545455 0.75       0.7826087 ]\n",
      "Mean Precision: 0.8000570926657883\n",
      "\n",
      "Cross-Validation Recall Scores: [0.87179487 0.84615385 0.8974359  1.         0.94736842]\n",
      "Mean Recall: 0.9125506072874494\n",
      "\n",
      "Cross-Validation F1 Scores: [0.80952381 0.88       0.84337349 0.85714286 0.85714286]\n",
      "Mean F1 Score: 0.8494366035570854\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.78205128 0.8974359  0.82051282 0.81818182 0.81818182]\n",
      "Mean Accuracy: 0.8272727272727274\n",
      "\n",
      "Cross-Validation Precision Scores: [0.72916667 0.8974359  0.77777778 0.75510204 0.75      ]\n",
      "Mean Precision: 0.7818964765393337\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8974359  0.8974359  0.8974359  0.94871795 0.94736842]\n",
      "Mean Recall: 0.9176788124156546\n",
      "\n",
      "Cross-Validation F1 Scores: [0.8045977  0.8974359  0.83333333 0.84090909 0.8372093 ]\n",
      "Mean F1 Score: 0.8426970650306655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 3: TensorFlow with Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75362319 0.75362319 0.79411765 0.85294118 0.80882353]\n",
      "Mean Accuracy: 0.7926257459505541\n",
      "\n",
      "Cross-Validation Precision Scores: [0.73684211 0.77419355 0.83333333 0.92857143 0.83870968]\n",
      "Mean Precision: 0.8223300185948743\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8        0.70588235 0.73529412 0.76470588 0.76470588]\n",
      "Mean Recall: 0.7541176470588236\n",
      "\n",
      "Cross-Validation F1 Scores: [0.76712329 0.73846154 0.78125    0.83870968 0.8       ]\n",
      "Mean F1 Score: 0.7851089007104253\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.65217391 0.60869565 0.67647059 0.79411765 0.72058824]\n",
      "Mean Accuracy: 0.6904092071611253\n",
      "\n",
      "Cross-Validation Precision Scores: [0.63414634 0.6        0.71428571 0.83333333 0.74193548]\n",
      "Mean Precision: 0.704740174590686\n",
      "\n",
      "Cross-Validation Recall Scores: [0.74285714 0.61764706 0.58823529 0.73529412 0.67647059]\n",
      "Mean Recall: 0.6721008403361346\n",
      "\n",
      "Cross-Validation F1 Scores: [0.68421053 0.60869565 0.64516129 0.78125    0.70769231]\n",
      "Mean F1 Score: 0.6854019553009182\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.73913043 0.72463768 0.72058824 0.76470588 0.77941176]\n",
      "Mean Accuracy: 0.745694799658994\n",
      "\n",
      "Cross-Validation Precision Scores: [0.71794872 0.71428571 0.82608696 0.8        0.80645161]\n",
      "Mean Precision: 0.7729546003318795\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8        0.73529412 0.55882353 0.70588235 0.73529412]\n",
      "Mean Recall: 0.7070588235294119\n",
      "\n",
      "Cross-Validation F1 Scores: [0.75675676 0.72463768 0.66666667 0.75       0.76923077]\n",
      "Mean F1 Score: 0.7334583747627226\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75362319 0.72463768 0.66176471 0.70588235 0.75      ]\n",
      "Mean Accuracy: 0.7191815856777494\n",
      "\n",
      "Cross-Validation Precision Scores: [0.6875     0.7027027  0.7037037  0.81818182 0.79310345]\n",
      "Mean Precision: 0.7410383345728173\n",
      "\n",
      "Cross-Validation Recall Scores: [0.94285714 0.76470588 0.55882353 0.52941176 0.67647059]\n",
      "Mean Recall: 0.6944537815126051\n",
      "\n",
      "Cross-Validation F1 Scores: [0.79518072 0.73239437 0.62295082 0.64285714 0.73015873]\n",
      "Mean F1 Score: 0.7047083563553508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 4: TensorFlow with Title and Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.73913043 0.79710145 0.77941176 0.82352941 0.79411765]\n",
      "Mean Accuracy: 0.7866581415174766\n",
      "\n",
      "Cross-Validation Precision Scores: [0.71794872 0.79411765 0.91304348 0.86666667 0.8125    ]\n",
      "Mean Precision: 0.8208553019870155\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8        0.79411765 0.61764706 0.76470588 0.76470588]\n",
      "Mean Recall: 0.7482352941176471\n",
      "\n",
      "Cross-Validation F1 Scores: [0.75675676 0.79411765 0.73684211 0.8125     0.78787879]\n",
      "Mean F1 Score: 0.7776190593915053\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.60869565 0.60869565 0.54411765 0.54411765 0.52941176]\n",
      "Mean Accuracy: 0.567007672634271\n",
      "\n",
      "Cross-Validation Precision Scores: [0.60526316 0.6        0.54285714 0.54545455 0.53333333]\n",
      "Mean Precision: 0.5653816359079517\n",
      "\n",
      "Cross-Validation Recall Scores: [0.65714286 0.61764706 0.55882353 0.52941176 0.47058824]\n",
      "Mean Recall: 0.5667226890756303\n",
      "\n",
      "Cross-Validation F1 Scores: [0.63013699 0.60869565 0.55072464 0.53731343 0.5       ]\n",
      "Mean F1 Score: 0.5653741417984526\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.69565217 0.68115942 0.67647059 0.77941176 0.70588235]\n",
      "Mean Accuracy: 0.7077152600170503\n",
      "\n",
      "Cross-Validation Precision Scores: [0.75       0.6875     0.75       0.78787879 0.75      ]\n",
      "Mean Precision: 0.7450757575757576\n",
      "\n",
      "Cross-Validation Recall Scores: [0.6        0.64705882 0.52941176 0.76470588 0.61764706]\n",
      "Mean Recall: 0.6317647058823529\n",
      "\n",
      "Cross-Validation F1 Scores: [0.66666667 0.66666667 0.62068966 0.7761194  0.67741935]\n",
      "Mean F1 Score: 0.6815123492659063\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.50724638 0.53623188 0.75       0.72058824 0.60294118]\n",
      "Mean Accuracy: 0.6234015345268543\n",
      "\n",
      "Cross-Validation Precision Scores: [0.51724138 0.53571429 0.79310345 0.74193548 0.58974359]\n",
      "Mean Precision: 0.63554763738301\n",
      "\n",
      "Cross-Validation Recall Scores: [0.42857143 0.44117647 0.67647059 0.67647059 0.67647059]\n",
      "Mean Recall: 0.5798319327731093\n",
      "\n",
      "Cross-Validation F1 Scores: [0.46875    0.48387097 0.73015873 0.70769231 0.63013699]\n",
      "Mean F1 Score: 0.6041217983788687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Results with Issue Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.855072463768116, Precision: 0.8573232323232323, Recall: 0.8585304054054055, F1: 0.8550420168067226\n",
      "Fold 2 - Accuracy: 0.7681159420289855, Precision: 0.7922727272727272, Recall: 0.7701680672268907, F1: 0.7641025641025643\n",
      "Fold 3 - Accuracy: 0.8676470588235294, Precision: 0.8715277777777778, Recall: 0.8731473408892764, F1: 0.8676184295911746\n",
      "Fold 4 - Accuracy: 0.8676470588235294, Precision: 0.8780701754385964, Recall: 0.8757628596338274, F1: 0.8676184295911745\n",
      "Fold 5 - Accuracy: 0.8823529411764706, Precision: 0.8897922312556459, Recall: 0.8761987794245858, F1: 0.8797524314765695\n",
      "\n",
      "Mean Accuracy: 0.8481670929241261\n",
      "Mean Precision: 0.8577972288135959\n",
      "Mean Recall: 0.8507614905159973\n",
      "Mean F1: 0.8468267743136412\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.8985507246376812, Precision: 0.8977272727272727, Recall: 0.8990709459459459, F1: 0.8982086406743941\n",
      "Fold 2 - Accuracy: 0.8695652173913043, Precision: 0.8769230769230769, Recall: 0.8705882352941177, F1: 0.8691253951527924\n",
      "Fold 3 - Accuracy: 0.9264705882352942, Precision: 0.9305555555555556, Recall: 0.9324324324324325, F1: 0.9264546831062082\n",
      "Fold 4 - Accuracy: 0.9558823529411765, Precision: 0.9548611111111112, Recall: 0.9568439407149085, F1: 0.9556425309849967\n",
      "Fold 5 - Accuracy: 0.9705882352941176, Precision: 0.970357454228422, Recall: 0.970357454228422, F1: 0.970357454228422\n",
      "\n",
      "Mean Accuracy: 0.9242114236999148\n",
      "Mean Precision: 0.9260848941090878\n",
      "Mean Recall: 0.9258586017231654\n",
      "Mean F1: 0.9239577408293627\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.8115942  0.69565217 0.85294118 0.80882353 0.82352941]\n",
      "Mean Accuracy: 0.7985080988917306\n",
      "\n",
      "Mean Precision: 0.8215539709459975\n",
      "Mean Recall: 0.802272419647894\n",
      "Mean F1 Score: 0.7941631229001876\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.86956522 0.79710145 0.88235294 0.89705882 0.94117647]\n",
      "Mean Accuracy: 0.8774509803921567\n",
      "\n",
      "Mean Precision: 0.8825963127192843\n",
      "Mean Recall: 0.879666709098635\n",
      "Mean F1 Score: 0.8768171132067584\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Results with Issue Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_validate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mamm/ayman/A-Comparative-Study-between-TensorFlow-and-PyTorch/Evolution_Over_Bugs/Issues_classifier/ML_Model_Training/models_sklearn.ipynb Cell 34\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.40/home/mamm/ayman/A-Comparative-Study-between-TensorFlow-and-PyTorch/Evolution_Over_Bugs/Issues_classifier/ML_Model_Training/models_sklearn.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m kf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.40/home/mamm/ayman/A-Comparative-Study-between-TensorFlow-and-PyTorch/Evolution_Over_Bugs/Issues_classifier/ML_Model_Training/models_sklearn.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Evaluate the model using cross-validation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.40/home/mamm/ayman/A-Comparative-Study-between-TensorFlow-and-PyTorch/Evolution_Over_Bugs/Issues_classifier/ML_Model_Training/models_sklearn.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(model, preprocessed_documents, labels, cv\u001b[39m=\u001b[39mkf, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.40/home/mamm/ayman/A-Comparative-Study-between-TensorFlow-and-PyTorch/Evolution_Over_Bugs/Issues_classifier/ML_Model_Training/models_sklearn.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Display the cross-validation results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.40/home/mamm/ayman/A-Comparative-Study-between-TensorFlow-and-PyTorch/Evolution_Over_Bugs/Issues_classifier/ML_Model_Training/models_sklearn.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCross-validation Results:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_validate' is not defined"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.9358974358974359, Precision: 0.9349049964813512, Recall: 0.9291666666666667, F1: 0.9318539227677791\n",
      "Fold 2 - Accuracy: 0.9102564102564102, Precision: 0.9125, Recall: 0.9222222222222223, F1: 0.9098861198217527\n",
      "Fold 3 - Accuracy: 0.9615384615384616, Precision: 0.9620962425840475, Recall: 0.9611842105263158, F1: 0.9614814814814814\n",
      "Fold 4 - Accuracy: 0.961038961038961, Precision: 0.9612010796221322, Recall: 0.9612010796221322, F1: 0.9610389610389611\n",
      "Fold 5 - Accuracy: 0.961038961038961, Precision: 0.9625, Recall: 0.9625, F1: 0.961038961038961\n",
      "\n",
      "Mean Accuracy: 0.945954045954046\n",
      "Mean Precision: 0.9466404637375062\n",
      "Mean Recall: 0.9472548358074674\n",
      "Mean F1: 0.945059889229787\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.8974359  0.87179487 0.92307692 0.8961039  0.96103896]\n",
      "Mean Accuracy: 0.9098901098901099\n",
      "\n",
      "Mean Precision: 0.9143433037560124\n",
      "Mean Recall: 0.9078044436597068\n",
      "Mean F1 Score: 0.9076686026806204\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words -< Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.88461538 0.82051282 0.91025641 0.90909091 0.90909091]\n",
      "Mean Accuracy: 0.8867132867132866\n",
      "\n",
      "Mean Precision: 0.9021041613536142\n",
      "Mean Recall: 0.8870552181736391\n",
      "Mean F1 Score: 0.8839120659480934\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. TensorFlow Results with title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Accuracy: [0.52173913 0.53623188 0.47058824 0.5        0.45588235]\n",
      "Precision: [0.66269841 0.55373303 0.73134328 0.63809524 0.22794118]\n",
      "Recall: [0.55194257 0.53991597 0.51351351 0.53792502 0.5       ]\n",
      "F1 Score: [0.44259486 0.50626118 0.34264232 0.41438703 0.31313131]\n",
      "\n",
      "Mean Accuracy: 0.49688832054560955\n",
      "Mean Precision: 0.5627622285041074\n",
      "Mean Recall: 0.528659413852725\n",
      "Mean F1 Score: 0.4038033409092924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Tokenization and preprocessing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=preprocessed_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to average Word2Vec vectors for a document\n",
    "def document_embedding(doc, model):\n",
    "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Create document embeddings using Word2Vec\n",
    "embeddings = [document_embedding(doc, word2vec_model) for doc in preprocessed_documents]\n",
    "\n",
    "# Create a pipeline with logistic regression\n",
    "model = make_pipeline(LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(model, embeddings, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "print(\"Accuracy:\", cv_results['test_accuracy'])\n",
    "print(\"Precision:\", cv_results['test_precision'])\n",
    "print(\"Recall:\", cv_results['test_recall'])\n",
    "print(\"F1 Score:\", cv_results['test_f1'])\n",
    "\n",
    "# Calculate and print mean values\n",
    "mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "mean_precision = np.mean(cv_results['test_precision'])\n",
    "mean_recall = np.mean(cv_results['test_recall'])\n",
    "mean_f1 = np.mean(cv_results['test_f1'])\n",
    "\n",
    "print(\"\\nMean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pytorch Results with title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Accuracy: [0.38461538 0.42307692 0.48717949 0.55844156 0.48051948]\n",
      "Precision: [0.19230769 0.21153846 0.24358974 0.76388889 0.24025974]\n",
      "Recall: [0.5        0.5        0.5        0.56410256 0.5       ]\n",
      "F1 Score: [0.27777778 0.2972973  0.32758621 0.45909091 0.3245614 ]\n",
      "\n",
      "Mean Accuracy: 0.4667665667665667\n",
      "Mean Precision: 0.3303169053169053\n",
      "Mean Recall: 0.5128205128205128\n",
      "Mean F1 Score: 0.33726271891426157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Tokenization and preprocessing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=preprocessed_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to average Word2Vec vectors for a document\n",
    "def document_embedding(doc, model):\n",
    "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Create document embeddings using Word2Vec\n",
    "embeddings = [document_embedding(doc, word2vec_model) for doc in preprocessed_documents]\n",
    "\n",
    "# Create a pipeline with logistic regression\n",
    "model = make_pipeline(LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(model, embeddings, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "print(\"Accuracy:\", cv_results['test_accuracy'])\n",
    "print(\"Precision:\", cv_results['test_precision'])\n",
    "print(\"Recall:\", cv_results['test_recall'])\n",
    "print(\"F1 Score:\", cv_results['test_f1'])\n",
    "\n",
    "# Calculate and print mean values\n",
    "mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "mean_precision = np.mean(cv_results['test_precision'])\n",
    "mean_recall = np.mean(cv_results['test_recall'])\n",
    "mean_f1 = np.mean(cv_results['test_f1'])\n",
    "\n",
    "print(\"\\nMean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "From th results above, we can see that using Bag of Words is the best choice for classifying the bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting whether the issue is buggy or not using Bag Of Words for all Issue Titles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_type(string):\n",
    "    # Use regular expression to find all occurrences of 'name=\"type:xyz\"'\n",
    "    matches = re.findall(r'name=\"([^\"]+)', string)\n",
    "    #convert the list to string\n",
    "    matches = ' '.join(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_torch = pd.read_csv('../../Issues_parser/Scraped_Data/torch_issues/Pytorch_open_issue.csv')\n",
    "for i in range(0, 3):\n",
    "    df_torch = pd.concat([df_torch, pd.read_csv('../../issues_parser/Scraped_Data/torch_issues/torch_issues_classified.csv_' + str(i) + '.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_torch['Tags'] = df_torch['Tags'].apply(get_type)\n",
    "df_torch['Issue Title'] = df_torch['Issue Title'] + ' ' + df_torch['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordBasedChecker(IssueTitle):\n",
    "    '''\n",
    "    Input: IssueTitle, IssueBody\n",
    "    Output: True/False\n",
    "    '''\n",
    "    bug_keywords = {\n",
    "    'error',\n",
    "    'exception',\n",
    "    'traceback',\n",
    "    'crash',\n",
    "    'issue',\n",
    "    'problem',\n",
    "    'unexpected',\n",
    "    'incorrect',\n",
    "    'not working',\n",
    "    'failure',\n",
    "    'flaw',\n",
    "    'mistake',\n",
    "    'fault',\n",
    "    'glitch',\n",
    "    'inconsistency',\n",
    "    'abnormal',\n",
    "    'unexpected behavior',\n",
    "    'unhandled',\n",
    "    'segmentation fault',\n",
    "    'defect',\n",
    "    'bug'\n",
    "    }\n",
    "    #Parse the title\n",
    "    try:\n",
    "        IssueTitle = IssueTitle.lower()\n",
    "        IssueTitle = IssueTitle.split()\n",
    "         #Check if any of the keywords is in the title\n",
    "        for word in IssueTitle:\n",
    "            if word in bug_keywords:\n",
    "                return 1\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Predicted Labels usingwordBasedChecker\n",
    "predicted_labels = []\n",
    "for index, row in df_torch.iterrows():\n",
    "    predicted_labels.append(wordBasedChecker(row['Issue Title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the list to numpy array\n",
    "predicted_labels = np.asarray(predicted_labels)\n",
    "df_torch['Predicted_Is_Bug'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#using frequency \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        processed_text = ' '.join(tokens)\n",
    "    except: \n",
    "        print(text)\n",
    "        processed_text = \"\"\n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "model.fit(preprocessed_documents, labels)\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = df_torch['Issue Title'].values.tolist()\n",
    "new_data_preprocessed = [preprocess_text(doc) for doc in new_data]\n",
    "LR_prediction = model.predict(new_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Is_Bug\n",
       "True     9358\n",
       "False    2862\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the predictions to the dataframe\n",
    "df_torch['LR_Predicted_Is_Bug'] = LR_prediction\n",
    "df_torch['Final_Is_Bug'] = df_torch['LR_Predicted_Is_Bug'] | df_torch['Predicted_Is_Bug']\n",
    "df_torch['Final_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue Number</th>\n",
       "      <th>Issue Title</th>\n",
       "      <th>Time created</th>\n",
       "      <th>Time closed</th>\n",
       "      <th>Number of Assignees</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Predicted_Is_Bug</th>\n",
       "      <th>LR_Predicted_Is_Bug</th>\n",
       "      <th>Final_Is_Bug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114968</td>\n",
       "      <td>Missing `.so` files when installing PyTorch 1....</td>\n",
       "      <td>2023-12-01 18:20:37+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oncall: pt2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114967</td>\n",
       "      <td>Inplace update to buffers doesn't work with `a...</td>\n",
       "      <td>2023-12-01 18:10:19+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114966</td>\n",
       "      <td>[dynamo] dynamo does not support dataclasses w...</td>\n",
       "      <td>2023-12-01 18:04:35+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>triaged module: dynamo</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114964</td>\n",
       "      <td>[dynamo] missing support for function `object....</td>\n",
       "      <td>2023-12-01 18:00:39+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>triaged module: dynamo</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114963</td>\n",
       "      <td>[dynamo] missing support for builtin function ...</td>\n",
       "      <td>2023-12-01 17:58:57+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>triaged module: dynamo</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12215</th>\n",
       "      <td>634</td>\n",
       "      <td>Feature Request: NegativeSampling and Hierarch...</td>\n",
       "      <td>2017-01-29 18:30:26+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>feature module: nn module: loss triaged Stale ...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>630</td>\n",
       "      <td>Add Peephole connections for LSTMs? feature tr...</td>\n",
       "      <td>2017-01-29 06:14:27+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>feature triaged Stale</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12217</th>\n",
       "      <td>499</td>\n",
       "      <td>Feature Request: Locally Connected Layer propo...</td>\n",
       "      <td>2017-01-19 10:36:23+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>proposal accepted feature module: nn triaged S...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12218</th>\n",
       "      <td>285</td>\n",
       "      <td>Keyword arguments passed to module's __call__ ...</td>\n",
       "      <td>2016-12-01 22:42:55+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>module: nn low priority triaged enhancement</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12219</th>\n",
       "      <td>88</td>\n",
       "      <td>expose backend selection and cudnn settings to...</td>\n",
       "      <td>2016-10-01 21:30:04+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>module: cudnn feature triaged Stale</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12220 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Issue Number                                        Issue Title  \\\n",
       "0            114968  Missing `.so` files when installing PyTorch 1....   \n",
       "1            114967  Inplace update to buffers doesn't work with `a...   \n",
       "2            114966  [dynamo] dynamo does not support dataclasses w...   \n",
       "3            114964  [dynamo] missing support for function `object....   \n",
       "4            114963  [dynamo] missing support for builtin function ...   \n",
       "...             ...                                                ...   \n",
       "12215           634  Feature Request: NegativeSampling and Hierarch...   \n",
       "12216           630  Add Peephole connections for LSTMs? feature tr...   \n",
       "12217           499  Feature Request: Locally Connected Layer propo...   \n",
       "12218           285  Keyword arguments passed to module's __call__ ...   \n",
       "12219            88  expose backend selection and cudnn settings to...   \n",
       "\n",
       "                    Time created  Time closed  Number of Assignees  \\\n",
       "0      2023-12-01 18:20:37+00:00          NaN                    0   \n",
       "1      2023-12-01 18:10:19+00:00          NaN                    0   \n",
       "2      2023-12-01 18:04:35+00:00          NaN                    0   \n",
       "3      2023-12-01 18:00:39+00:00          NaN                    0   \n",
       "4      2023-12-01 17:58:57+00:00          NaN                    0   \n",
       "...                          ...          ...                  ...   \n",
       "12215  2017-01-29 18:30:26+00:00          NaN                    0   \n",
       "12216  2017-01-29 06:14:27+00:00          NaN                    0   \n",
       "12217  2017-01-19 10:36:23+00:00          NaN                    0   \n",
       "12218  2016-12-01 22:42:55+00:00          NaN                    0   \n",
       "12219  2016-10-01 21:30:04+00:00          NaN                    0   \n",
       "\n",
       "       Number of Comments                                               Tags  \\\n",
       "0                       0                                        oncall: pt2   \n",
       "1                       0                                                      \n",
       "2                       0                             triaged module: dynamo   \n",
       "3                       0                             triaged module: dynamo   \n",
       "4                       0                             triaged module: dynamo   \n",
       "...                   ...                                                ...   \n",
       "12215                  11  feature module: nn module: loss triaged Stale ...   \n",
       "12216                  18                              feature triaged Stale   \n",
       "12217                  23  proposal accepted feature module: nn triaged S...   \n",
       "12218                   1        module: nn low priority triaged enhancement   \n",
       "12219                   3                module: cudnn feature triaged Stale   \n",
       "\n",
       "       Predicted_Is_Bug  LR_Predicted_Is_Bug  Final_Is_Bug  \n",
       "0                     0                False         False  \n",
       "1                     0                False         False  \n",
       "2                     0                False         False  \n",
       "3                     0                False         False  \n",
       "4                     0                False         False  \n",
       "...                 ...                  ...           ...  \n",
       "12215                 0                 True          True  \n",
       "12216                 0                False         False  \n",
       "12217                 0                False         False  \n",
       "12218                 0                 True          True  \n",
       "12219                 0                 True          True  \n",
       "\n",
       "[12220 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR_Predicted_Is_Bug\n",
       "True     8944\n",
       "False    3276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_torch['LR_Predicted_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Issue Number', 'Issue Title', 'Time created', 'Time closed',\n",
       "       'Number of Assignees', 'Number of Comments', 'Tags', 'Predicted_Is_Bug',\n",
       "       'LR_Predicted_Is_Bug', 'Final_Is_Bug'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_torch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the csv file \n",
    "saved_df = df_torch[['Issue Number','Issue Title', 'Time created',\n",
    "       'Time closed', 'Number of Assignees', 'Number of Comments', 'Tags', 'Final_Is_Bug']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_df.to_csv('torch_issues_classified.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Results with Issue Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = pd.read_csv('../../Issues_parser/Scraped_Data/tf_issues/Tensorflow_open_issue.csv')\n",
    "for i in range(0, 4):\n",
    "    df_tf = pd.concat([df_tf, pd.read_csv('../../issues_parser/tf_issues/tf_issues_classified.csv_' + str(i) + '.csv')])\n",
    "df_tf['Tags'] = df_tf['Tags'].apply(get_type)\n",
    "df_tf['Issue Title'] = df_tf['Issue Title'] + ' ' + df_tf['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Predicted Labels usingwordBasedChecker\n",
    "tf_predicted_labels = []\n",
    "for index, row in df_tf.iterrows():\n",
    "    tf_predicted_labels.append(wordBasedChecker(row['Issue Title']))\n",
    "\n",
    "#convert the list to numpy array\n",
    "tf_predicted_labels = np.asarray(tf_predicted_labels)\n",
    "df_tf['Predicted_Is_Bug'] = tf_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted_Is_Bug\n",
       "0    1659\n",
       "1     258\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf['Predicted_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#using frequency \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        processed_text = ' '.join(tokens)\n",
    "    except: \n",
    "        print(text)\n",
    "        processed_text = \"\"\n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "model.fit(preprocessed_documents, labels)\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = df_tf['Issue Title'].values.tolist()\n",
    "new_data_preprocessed = [preprocess_text(doc) for doc in new_data]\n",
    "LR_prediction = model.predict(new_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Is_Bug\n",
       "True     1844\n",
       "False      73\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the predictions to the dataframe\n",
    "df_tf['LR_Predicted_Is_Bug'] = LR_prediction\n",
    "df_tf['Final_Is_Bug'] = df_tf['LR_Predicted_Is_Bug'] | df_tf['Predicted_Is_Bug']\n",
    "df_tf['Final_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the csv file \n",
    "saved_df = df_tf[['Issue Number','Issue Title', 'Time created',\n",
    "       'Time closed', 'Number of Assignees', 'Number of Comments', 'Tags', 'Final_Is_Bug']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_df.to_csv('tf_issues_classified.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mohamed_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
