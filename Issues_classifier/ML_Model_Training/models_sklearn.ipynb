{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of this Notebook: \n",
    "#### The purpose of this notebook is simply evaluating the results for pytorch with title and body, pytorch with title, tensorflow with title and body, and tensorflow with title. This will be helpful to choose the best model for our usecase to identify whether the issues are buggy or not. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Using Bert Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "col1 = 'BERT Embedding'\n",
    "col2 = 'Issue Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_torch_Title_bert = pd.read_csv('./Data/GT_bert_data_pytorch.csv')\n",
    "data_tf_Title_bert    = data = pd.read_csv('./Data/GT_bert_data_tf.csv')\n",
    "\n",
    "#title and body together as a vector of embeddings\n",
    "data_tf_concat_bert = pd.read_csv('./Data/GT_bert_concat_data_tf.csv')\n",
    "data_torch_concat_bert = pd.read_csv('./Data/GT_bert_concat_data_torch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Helpful Functions for preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_extra_commas(input_string):\n",
    "    # Use regular expression to replace multiple commas with a single comma\n",
    "    cleaned_string = re.sub(',+', ',', input_string)\n",
    "    return cleaned_string\n",
    "\n",
    "\n",
    "def modify(input_string):\n",
    "    try:\n",
    "        input_string = input_string.replace('\\n', '').replace(' ', ',').replace(\":\", \"\")\n",
    "        input_string = remove_extra_commas(input_string)\n",
    "        if(input_string[1] == ','):\n",
    "            input_string = input_string[0] + input_string[2:]\n",
    "        input_string = ast.literal_eval(input_string.replace(' ',''))\n",
    "    except:\n",
    "        print(input_string)\n",
    "    return input_string\n",
    "\n",
    "\n",
    "\n",
    "def training(model, X,y):\n",
    "    # model = LogisticRegression()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring_metrics = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score),\n",
    "        'f1_score': make_scorer(f1_score)\n",
    "    }\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    # You can adjust the 'cv' parameter to change the number of folds\n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=scoring_metrics)\n",
    "\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-Validation Accuracy Scores:\", scores['test_accuracy'])\n",
    "    print(\"Mean Accuracy:\", scores['test_accuracy'].mean())\n",
    "\n",
    "    print(\"\\nCross-Validation Precision Scores:\", scores['test_precision'])\n",
    "    print(\"Mean Precision:\", scores['test_precision'].mean())\n",
    "\n",
    "    print(\"\\nCross-Validation Recall Scores:\", scores['test_recall'])\n",
    "    print(\"Mean Recall:\", scores['test_recall'].mean())\n",
    "\n",
    "    print(\"\\nCross-Validation F1 Scores:\", scores['test_f1_score'])\n",
    "    print(\"Mean F1 Score:\", scores['test_f1_score'].mean())\n",
    "    \n",
    "def preprocessEmbeddingsTitle(data, col):\n",
    "    X = data[col].apply(lambda x: modify(x))\n",
    "    X = np.asarray(X.values.tolist(), dtype=np.float32)\n",
    "    #Given data['Is Bug']make them 0 and 1\n",
    "    data['Is Bug'] = data['Is Bug'].apply(lambda x: 1 if x == True else 0)\n",
    "    #get it as numpy array\n",
    "    y = np.asarray(data['Is Bug'], dtype=np.uint8)\n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 1: PyTorch with Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.87179487 0.94871795 0.87179487 0.85714286 0.83116883]\n",
      "Mean Accuracy: 0.8761238761238761\n",
      "\n",
      "Cross-Validation Precision Scores: [0.87179487 0.97297297 0.87179487 0.83333333 0.82051282]\n",
      "Mean Precision: 0.8740817740817741\n",
      "\n",
      "Cross-Validation Recall Scores: [0.87179487 0.92307692 0.87179487 0.8974359  0.84210526]\n",
      "Mean Recall: 0.8812415654520919\n",
      "\n",
      "Cross-Validation F1 Scores: [0.87179487 0.94736842 0.87179487 0.86419753 0.83116883]\n",
      "Mean F1 Score: 0.8772649053350807\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.73076923 0.83333333 0.74358974 0.75324675 0.83116883]\n",
      "Mean Accuracy: 0.7784215784215783\n",
      "\n",
      "Cross-Validation Precision Scores: [0.70454545 0.88235294 0.74358974 0.75       0.80487805]\n",
      "Mean Precision: 0.7770732376184313\n",
      "\n",
      "Cross-Validation Recall Scores: [0.79487179 0.76923077 0.74358974 0.76923077 0.86842105]\n",
      "Mean Recall: 0.7890688259109311\n",
      "\n",
      "Cross-Validation F1 Scores: [0.74698795 0.82191781 0.74358974 0.75949367 0.83544304]\n",
      "Mean F1 Score: 0.781486442495382\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.88461538 0.93589744 0.87179487 0.85714286 0.77922078]\n",
      "Mean Accuracy: 0.8657342657342658\n",
      "\n",
      "Cross-Validation Precision Scores: [0.82608696 0.94736842 0.82222222 0.78       0.70588235]\n",
      "Mean Precision: 0.816311990547554\n",
      "\n",
      "Cross-Validation Recall Scores: [0.97435897 0.92307692 0.94871795 1.         0.94736842]\n",
      "Mean Recall: 0.9587044534412955\n",
      "\n",
      "Cross-Validation F1 Scores: [0.89411765 0.93506494 0.88095238 0.87640449 0.80898876]\n",
      "Mean F1 Score: 0.8791056443006211\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.85897436 0.8974359  0.84615385 0.77922078 0.80519481]\n",
      "Mean Accuracy: 0.8373959373959374\n",
      "\n",
      "Cross-Validation Precision Scores: [0.79166667 0.87804878 0.78723404 0.7037037  0.7254902 ]\n",
      "Mean Precision: 0.7772286778979597\n",
      "\n",
      "Cross-Validation Recall Scores: [0.97435897 0.92307692 0.94871795 0.97435897 0.97368421]\n",
      "Mean Recall: 0.9588394062078273\n",
      "\n",
      "Cross-Validation F1 Scores: [0.87356322 0.9        0.86046512 0.8172043  0.83146067]\n",
      "Mean F1 Score: 0.8565386619804893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_Title_bert, col2)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 2: PyTorch with Title and Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.83333333 0.92307692 0.8974359  0.87012987 0.87012987]\n",
      "Mean Accuracy: 0.8788211788211788\n",
      "\n",
      "Cross-Validation Precision Scores: [0.84210526 0.97142857 0.87804878 0.82222222 0.85      ]\n",
      "Mean Precision: 0.8727609674592985\n",
      "\n",
      "Cross-Validation Recall Scores: [0.82051282 0.87179487 0.92307692 0.94871795 0.89473684]\n",
      "Mean Recall: 0.8917678812415654\n",
      "\n",
      "Cross-Validation F1 Scores: [0.83116883 0.91891892 0.9        0.88095238 0.87179487]\n",
      "Mean F1 Score: 0.8805670005670005\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.71794872 0.74358974 0.79487179 0.80519481 0.63636364]\n",
      "Mean Accuracy: 0.7395937395937395\n",
      "\n",
      "Cross-Validation Precision Scores: [0.70731707 0.82758621 0.81081081 0.8        0.60416667]\n",
      "Mean Precision: 0.7499761515089521\n",
      "\n",
      "Cross-Validation Recall Scores: [0.74358974 0.61538462 0.76923077 0.82051282 0.76315789]\n",
      "Mean Recall: 0.7423751686909582\n",
      "\n",
      "Cross-Validation F1 Scores: [0.725      0.70588235 0.78947368 0.81012658 0.6744186 ]\n",
      "Mean F1 Score: 0.7409802448162692\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.80769231 0.92307692 0.84615385 0.85714286 0.83116883]\n",
      "Mean Accuracy: 0.8530469530469531\n",
      "\n",
      "Cross-Validation Precision Scores: [0.76086957 0.92307692 0.78723404 0.78       0.76595745]\n",
      "Mean Precision: 0.8034275955312034\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8974359  0.92307692 0.94871795 1.         0.94736842]\n",
      "Mean Recall: 0.9433198380566802\n",
      "\n",
      "Cross-Validation F1 Scores: [0.82352941 0.92307692 0.86046512 0.87640449 0.84705882]\n",
      "Mean F1 Score: 0.8661069538064264\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.78205128 0.8974359  0.82051282 0.81818182 0.81818182]\n",
      "Mean Accuracy: 0.8272727272727274\n",
      "\n",
      "Cross-Validation Precision Scores: [0.72916667 0.8974359  0.77777778 0.75510204 0.75      ]\n",
      "Mean Precision: 0.7818964765393337\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8974359  0.8974359  0.8974359  0.94871795 0.94736842]\n",
      "Mean Recall: 0.9176788124156546\n",
      "\n",
      "Cross-Validation F1 Scores: [0.8045977  0.8974359  0.83333333 0.84090909 0.8372093 ]\n",
      "Mean F1 Score: 0.8426970650306655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_torch_concat_bert, col1)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 3: TensorFlow with Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75362319 0.75362319 0.79411765 0.85294118 0.80882353]\n",
      "Mean Accuracy: 0.7926257459505541\n",
      "\n",
      "Cross-Validation Precision Scores: [0.73684211 0.77419355 0.83333333 0.92857143 0.83870968]\n",
      "Mean Precision: 0.8223300185948743\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8        0.70588235 0.73529412 0.76470588 0.76470588]\n",
      "Mean Recall: 0.7541176470588236\n",
      "\n",
      "Cross-Validation F1 Scores: [0.76712329 0.73846154 0.78125    0.83870968 0.8       ]\n",
      "Mean F1 Score: 0.7851089007104253\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.72463768 0.62318841 0.67647059 0.79411765 0.69117647]\n",
      "Mean Accuracy: 0.701918158567775\n",
      "\n",
      "Cross-Validation Precision Scores: [0.72222222 0.61111111 0.73076923 0.8125     0.72413793]\n",
      "Mean Precision: 0.7201480990274094\n",
      "\n",
      "Cross-Validation Recall Scores: [0.74285714 0.64705882 0.55882353 0.76470588 0.61764706]\n",
      "Mean Recall: 0.666218487394958\n",
      "\n",
      "Cross-Validation F1 Scores: [0.73239437 0.62857143 0.63333333 0.78787879 0.66666667]\n",
      "Mean F1 Score: 0.68976891652948\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.7826087  0.69565217 0.73529412 0.76470588 0.79411765]\n",
      "Mean Accuracy: 0.7544757033248082\n",
      "\n",
      "Cross-Validation Precision Scores: [0.75       0.68571429 0.76666667 0.84615385 0.8125    ]\n",
      "Mean Precision: 0.7722069597069597\n",
      "\n",
      "Cross-Validation Recall Scores: [0.85714286 0.70588235 0.67647059 0.64705882 0.76470588]\n",
      "Mean Recall: 0.7302521008403361\n",
      "\n",
      "Cross-Validation F1 Scores: [0.8        0.69565217 0.71875    0.73333333 0.78787879]\n",
      "Mean F1 Score: 0.7471228590250331\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75362319 0.72463768 0.66176471 0.70588235 0.75      ]\n",
      "Mean Accuracy: 0.7191815856777494\n",
      "\n",
      "Cross-Validation Precision Scores: [0.6875     0.7027027  0.7037037  0.81818182 0.79310345]\n",
      "Mean Precision: 0.7410383345728173\n",
      "\n",
      "Cross-Validation Recall Scores: [0.94285714 0.76470588 0.55882353 0.52941176 0.67647059]\n",
      "Mean Recall: 0.6944537815126051\n",
      "\n",
      "Cross-Validation F1 Scores: [0.79518072 0.73239437 0.62295082 0.64285714 0.73015873]\n",
      "Mean F1 Score: 0.7047083563553508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_Title_bert, col2)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result 4: TensorFlow with Title and Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.73913043 0.79710145 0.77941176 0.82352941 0.79411765]\n",
      "Mean Accuracy: 0.7866581415174766\n",
      "\n",
      "Cross-Validation Precision Scores: [0.71794872 0.79411765 0.91304348 0.86666667 0.8125    ]\n",
      "Mean Precision: 0.8208553019870155\n",
      "\n",
      "Cross-Validation Recall Scores: [0.8        0.79411765 0.61764706 0.76470588 0.76470588]\n",
      "Mean Recall: 0.7482352941176471\n",
      "\n",
      "Cross-Validation F1 Scores: [0.75675676 0.79411765 0.73684211 0.8125     0.78787879]\n",
      "Mean F1 Score: 0.7776190593915053\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(LogisticRegression(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.5942029  0.66666667 0.55882353 0.5        0.51470588]\n",
      "Mean Accuracy: 0.5668797953964194\n",
      "\n",
      "Cross-Validation Precision Scores: [0.60606061 0.65714286 0.55263158 0.5        0.51851852]\n",
      "Mean Precision: 0.5668707121338701\n",
      "\n",
      "Cross-Validation Recall Scores: [0.57142857 0.67647059 0.61764706 0.5        0.41176471]\n",
      "Mean Recall: 0.5554621848739496\n",
      "\n",
      "Cross-Validation F1 Scores: [0.58823529 0.66666667 0.58333333 0.5        0.45901639]\n",
      "Mean F1 Score: 0.5594503375120541\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(DecisionTreeClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.71014493 0.66666667 0.77941176 0.82352941 0.77941176]\n",
      "Mean Accuracy: 0.7518329070758737\n",
      "\n",
      "Cross-Validation Precision Scores: [0.74193548 0.7037037  0.85185185 0.86666667 0.78787879]\n",
      "Mean Precision: 0.7904072987943955\n",
      "\n",
      "Cross-Validation Recall Scores: [0.65714286 0.55882353 0.67647059 0.76470588 0.76470588]\n",
      "Mean Recall: 0.6843697478991597\n",
      "\n",
      "Cross-Validation F1 Scores: [0.6969697  0.62295082 0.75409836 0.8125     0.7761194 ]\n",
      "Mean F1 Score: 0.7325276560565281\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(RandomForestClassifier(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.50724638 0.53623188 0.75       0.72058824 0.60294118]\n",
      "Mean Accuracy: 0.6234015345268543\n",
      "\n",
      "Cross-Validation Precision Scores: [0.51724138 0.53571429 0.79310345 0.74193548 0.58974359]\n",
      "Mean Precision: 0.63554763738301\n",
      "\n",
      "Cross-Validation Recall Scores: [0.42857143 0.44117647 0.67647059 0.67647059 0.67647059]\n",
      "Mean Recall: 0.5798319327731093\n",
      "\n",
      "Cross-Validation F1 Scores: [0.46875    0.48387097 0.73015873 0.70769231 0.63013699]\n",
      "Mean F1 Score: 0.6041217983788687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes\n",
    "X,y = preprocessEmbeddingsTitle(data_tf_concat_bert, col1)\n",
    "training(GaussianNB(), X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Results with Issue Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.855072463768116, Precision: 0.8573232323232323, Recall: 0.8585304054054055, F1: 0.8550420168067226\n",
      "Fold 2 - Accuracy: 0.7681159420289855, Precision: 0.7922727272727272, Recall: 0.7701680672268907, F1: 0.7641025641025643\n",
      "Fold 3 - Accuracy: 0.8676470588235294, Precision: 0.8715277777777778, Recall: 0.8731473408892764, F1: 0.8676184295911746\n",
      "Fold 4 - Accuracy: 0.8676470588235294, Precision: 0.8780701754385964, Recall: 0.8757628596338274, F1: 0.8676184295911745\n",
      "Fold 5 - Accuracy: 0.8823529411764706, Precision: 0.8897922312556459, Recall: 0.8761987794245858, F1: 0.8797524314765695\n",
      "\n",
      "Mean Accuracy: 0.8481670929241261\n",
      "Mean Precision: 0.8577972288135959\n",
      "Mean Recall: 0.8507614905159973\n",
      "Mean F1: 0.8468267743136412\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.8985507246376812, Precision: 0.8977272727272727, Recall: 0.8990709459459459, F1: 0.8982086406743941\n",
      "Fold 2 - Accuracy: 0.8695652173913043, Precision: 0.8769230769230769, Recall: 0.8705882352941177, F1: 0.8691253951527924\n",
      "Fold 3 - Accuracy: 0.9264705882352942, Precision: 0.9305555555555556, Recall: 0.9324324324324325, F1: 0.9264546831062082\n",
      "Fold 4 - Accuracy: 0.9558823529411765, Precision: 0.9548611111111112, Recall: 0.9568439407149085, F1: 0.9556425309849967\n",
      "Fold 5 - Accuracy: 0.9705882352941176, Precision: 0.970357454228422, Recall: 0.970357454228422, F1: 0.970357454228422\n",
      "\n",
      "Mean Accuracy: 0.9242114236999148\n",
      "Mean Precision: 0.9260848941090878\n",
      "Mean Recall: 0.9258586017231654\n",
      "Mean F1: 0.9239577408293627\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.8115942  0.69565217 0.85294118 0.80882353 0.82352941]\n",
      "Mean Accuracy: 0.7985080988917306\n",
      "\n",
      "Mean Precision: 0.8215539709459975\n",
      "Mean Recall: 0.802272419647894\n",
      "Mean F1 Score: 0.7941631229001876\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.86956522 0.79710145 0.88235294 0.89705882 0.94117647]\n",
      "Mean Accuracy: 0.8774509803921567\n",
      "\n",
      "Mean Precision: 0.8825963127192843\n",
      "Mean Recall: 0.879666709098635\n",
      "Mean F1 Score: 0.8768171132067584\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Results with Issue Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.8846153846153846, Precision: 0.9055335968379447, Recall: 0.85625, F1: 0.871405019234292\n",
      "Fold 2 - Accuracy: 0.8974358974358975, Precision: 0.9024390243902439, Recall: 0.9111111111111111, F1: 0.897165458141068\n",
      "Fold 3 - Accuracy: 0.9358974358974359, Precision: 0.9377059986816085, Recall: 0.9368421052631579, F1: 0.9358868979122144\n",
      "Fold 4 - Accuracy: 0.922077922077922, Precision: 0.9261904761904762, Recall: 0.9227395411605939, F1: 0.9219594594594595\n",
      "Fold 5 - Accuracy: 0.948051948051948, Precision: 0.9483805668016194, Recall: 0.9489864864864865, F1: 0.9480431848852902\n",
      "\n",
      "Mean Accuracy: 0.9176157176157176\n",
      "Mean Precision: 0.9240499325803786\n",
      "Mean Recall: 0.9151858488042699\n",
      "Mean F1: 0.9148920039264649\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Fold 1 - Accuracy: 0.9358974358974359, Precision: 0.9349049964813512, Recall: 0.9291666666666667, F1: 0.9318539227677791\n",
      "Fold 2 - Accuracy: 0.9102564102564102, Precision: 0.9125, Recall: 0.9222222222222223, F1: 0.9098861198217527\n",
      "Fold 3 - Accuracy: 0.9615384615384616, Precision: 0.9620962425840475, Recall: 0.9611842105263158, F1: 0.9614814814814814\n",
      "Fold 4 - Accuracy: 0.961038961038961, Precision: 0.9612010796221322, Recall: 0.9612010796221322, F1: 0.9610389610389611\n",
      "Fold 5 - Accuracy: 0.961038961038961, Precision: 0.9625, Recall: 0.9625, F1: 0.961038961038961\n",
      "\n",
      "Mean Accuracy: 0.945954045954046\n",
      "Mean Precision: 0.9466404637375062\n",
      "Mean Recall: 0.9472548358074674\n",
      "Mean F1: 0.945059889229787\n"
     ]
    }
   ],
   "source": [
    "#frequency with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "# Create a pipeline with a CountVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'precision': 'precision_macro','recall': 'recall_macro','f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_validate(model, preprocessed_documents, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "for i in range(kf.get_n_splits()):\n",
    "    print(f\"Fold {i+1} - Accuracy: {cv_results['test_accuracy'][i]}, Precision: {cv_results['test_precision'][i]}, Recall: {cv_results['test_recall'][i]}, F1: {cv_results['test_f1'][i]}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "#mean precision, recall, f1\n",
    "print(\"Mean Precision:\", np.mean(cv_results['test_precision']))\n",
    "print(\"Mean Recall:\", np.mean(cv_results['test_recall']))\n",
    "print(\"Mean F1:\", np.mean(cv_results['test_f1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.8974359  0.87179487 0.92307692 0.8961039  0.96103896]\n",
      "Mean Accuracy: 0.9098901098901099\n",
      "\n",
      "Mean Precision: 0.9143433037560124\n",
      "Mean Recall: 0.9078044436597068\n",
      "Mean F1 Score: 0.9076686026806204\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words -< Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results: [0.88461538 0.82051282 0.91025641 0.90909091 0.90909091]\n",
      "Mean Accuracy: 0.8867132867132866\n",
      "\n",
      "Mean Precision: 0.9021041613536142\n",
      "Mean Recall: 0.8870552181736391\n",
      "Mean F1 Score: 0.8839120659480934\n"
     ]
    }
   ],
   "source": [
    "#TFIDF with Bag of Words -> Logistic Regression\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming (optional)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Reassemble the text from processed tokens\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create a pipeline with a TfidfVectorizer and a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'f1': 'f1_macro'}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\", cv_results)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_results))\n",
    "\n",
    "# Additional: Calculate and print mean values for precision, recall, and f1 score\n",
    "precision_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='precision_macro')\n",
    "recall_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='recall_macro')\n",
    "f1_results = cross_val_score(model, preprocessed_documents, labels, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"\\nMean Precision:\", np.mean(precision_results))\n",
    "print(\"Mean Recall:\", np.mean(recall_results))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. TensorFlow Results with title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Accuracy: [0.52173913 0.53623188 0.47058824 0.5        0.45588235]\n",
      "Precision: [0.66269841 0.55373303 0.73134328 0.63809524 0.22794118]\n",
      "Recall: [0.55194257 0.53991597 0.51351351 0.53792502 0.5       ]\n",
      "F1 Score: [0.44259486 0.50626118 0.34264232 0.41438703 0.31313131]\n",
      "\n",
      "Mean Accuracy: 0.49688832054560955\n",
      "Mean Precision: 0.5627622285041074\n",
      "Mean Recall: 0.528659413852725\n",
      "Mean F1 Score: 0.4038033409092924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Tokenization and preprocessing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=preprocessed_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to average Word2Vec vectors for a document\n",
    "def document_embedding(doc, model):\n",
    "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Create document embeddings using Word2Vec\n",
    "embeddings = [document_embedding(doc, word2vec_model) for doc in preprocessed_documents]\n",
    "\n",
    "# Create a pipeline with logistic regression\n",
    "model = make_pipeline(LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(model, embeddings, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "print(\"Accuracy:\", cv_results['test_accuracy'])\n",
    "print(\"Precision:\", cv_results['test_precision'])\n",
    "print(\"Recall:\", cv_results['test_recall'])\n",
    "print(\"F1 Score:\", cv_results['test_f1'])\n",
    "\n",
    "# Calculate and print mean values\n",
    "mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "mean_precision = np.mean(cv_results['test_precision'])\n",
    "mean_recall = np.mean(cv_results['test_recall'])\n",
    "mean_f1 = np.mean(cv_results['test_f1'])\n",
    "\n",
    "print(\"\\nMean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pytorch Results with title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Results:\n",
      "Accuracy: [0.38461538 0.42307692 0.48717949 0.55844156 0.48051948]\n",
      "Precision: [0.19230769 0.21153846 0.24358974 0.76388889 0.24025974]\n",
      "Recall: [0.5        0.5        0.5        0.56410256 0.5       ]\n",
      "F1 Score: [0.27777778 0.2972973  0.32758621 0.45909091 0.3245614 ]\n",
      "\n",
      "Mean Accuracy: 0.4667665667665667\n",
      "Mean Precision: 0.3303169053169053\n",
      "Mean Recall: 0.5128205128205128\n",
      "Mean F1 Score: 0.33726271891426157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mamm/anaconda3/envs/mohamed_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Tokenization and preprocessing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=preprocessed_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to average Word2Vec vectors for a document\n",
    "def document_embedding(doc, model):\n",
    "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Create document embeddings using Word2Vec\n",
    "embeddings = [document_embedding(doc, word2vec_model) for doc in preprocessed_documents]\n",
    "\n",
    "# Create a pipeline with logistic regression\n",
    "model = make_pipeline(LogisticRegression())\n",
    "\n",
    "# Define a custom scorer for cross-validation\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(model, embeddings, labels, cv=kf, scoring=scoring)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation Results:\")\n",
    "print(\"Accuracy:\", cv_results['test_accuracy'])\n",
    "print(\"Precision:\", cv_results['test_precision'])\n",
    "print(\"Recall:\", cv_results['test_recall'])\n",
    "print(\"F1 Score:\", cv_results['test_f1'])\n",
    "\n",
    "# Calculate and print mean values\n",
    "mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "mean_precision = np.mean(cv_results['test_precision'])\n",
    "mean_recall = np.mean(cv_results['test_recall'])\n",
    "mean_f1 = np.mean(cv_results['test_f1'])\n",
    "\n",
    "print(\"\\nMean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "From th results above, we can see that using Bag of Words is the best choice for classifying the bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting whether the issue is buggy or not using Bag Of Words for all Issue Titles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_type(string):\n",
    "    # Use regular expression to find all occurrences of 'name=\"type:xyz\"'\n",
    "    matches = re.findall(r'name=\"([^\"]+)', string)\n",
    "    #convert the list to string\n",
    "    matches = ' '.join(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_torch = pd.read_csv('../../issues_parser/Not_Modified_Data/torch_issues/torch_issues_classified.csv_0.csv')\n",
    "for i in range(1, 3):\n",
    "    df_torch = pd.concat([df_torch, pd.read_csv('../../issues_parser/Not_Modified_Data/torch_issues/torch_issues_classified.csv_' + str(i) + '.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_torch['Tags'] = df_torch['Tags'].apply(get_type)\n",
    "df_torch['Issue Title'] = df_torch['Issue Title'] + ' ' + df_torch['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordBasedChecker(IssueTitle):\n",
    "    '''\n",
    "    Input: IssueTitle, IssueBody\n",
    "    Output: True/False\n",
    "    '''\n",
    "    bug_keywords = {\n",
    "    'error',\n",
    "    'exception',\n",
    "    'traceback',\n",
    "    'crash',\n",
    "    'issue',\n",
    "    'problem',\n",
    "    'unexpected',\n",
    "    'incorrect',\n",
    "    'not working',\n",
    "    'failure',\n",
    "    'flaw',\n",
    "    'mistake',\n",
    "    'fault',\n",
    "    'glitch',\n",
    "    'inconsistency',\n",
    "    'abnormal',\n",
    "    'unexpected behavior',\n",
    "    'unhandled',\n",
    "    'segmentation fault',\n",
    "    'defect',\n",
    "    'bug'\n",
    "    }\n",
    "    #Parse the title\n",
    "    try:\n",
    "        IssueTitle = IssueTitle.lower()\n",
    "        IssueTitle = IssueTitle.split()\n",
    "         #Check if any of the keywords is in the title\n",
    "        for word in IssueTitle:\n",
    "            if word in bug_keywords:\n",
    "                return 1\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Predicted Labels usingwordBasedChecker\n",
    "predicted_labels = []\n",
    "for index, row in df_torch.iterrows():\n",
    "    predicted_labels.append(wordBasedChecker(row['Issue Title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the list to numpy array\n",
    "predicted_labels = np.asarray(predicted_labels)\n",
    "df_torch['Predicted_Is_Bug'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "#using frequency \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        processed_text = ' '.join(tokens)\n",
    "    except: \n",
    "        print(text)\n",
    "        processed_text = \"\"\n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_torch_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_torch_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "model.fit(preprocessed_documents, labels)\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = df_torch['Issue Title'].values.tolist()\n",
    "new_data_preprocessed = [preprocess_text(doc) for doc in new_data]\n",
    "LR_prediction = model.predict(new_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Is_Bug\n",
       "1    13670\n",
       "0    11873\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the predictions to the dataframe\n",
    "df_torch['LR_Predicted_Is_Bug'] = LR_prediction\n",
    "df_torch['Final_Is_Bug'] = df_torch['LR_Predicted_Is_Bug'] | df_torch['Predicted_Is_Bug']\n",
    "df_torch['Final_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue Number</th>\n",
       "      <th>Issue Title</th>\n",
       "      <th>Issue Body</th>\n",
       "      <th>Time created</th>\n",
       "      <th>Time closed</th>\n",
       "      <th>Number of Assignees</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Is Bug</th>\n",
       "      <th>Predicted_Is_Bug</th>\n",
       "      <th>LR_Predicted_Is_Bug</th>\n",
       "      <th>Final_Is_Bug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113781</td>\n",
       "      <td>DISABLED test_2d_fsdp_tp_ac_compile (__main__....</td>\n",
       "      <td>Platforms: linux\\n\\nBroken on multigpu\\n\\nTo r...</td>\n",
       "      <td>2023-11-15 17:59:31+00:00</td>\n",
       "      <td>2023-11-15 18:38:16+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>skipped</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113758</td>\n",
       "      <td>missing device=p.device in Adam optimizer, lea...</td>\n",
       "      <td>### 🐛 Describe the bug\\n\\nI am using the Adam ...</td>\n",
       "      <td>2023-11-15 13:00:20+00:00</td>\n",
       "      <td>2023-11-15 21:03:24+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>module: optimizer triaged</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113756</td>\n",
       "      <td>Wrongly formatted string in profiler_util.py t...</td>\n",
       "      <td>### 🐛 Describe the bug\\n\\nThe string in line h...</td>\n",
       "      <td>2023-11-15 12:43:01+00:00</td>\n",
       "      <td>2023-11-15 17:07:47+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>triaged module: regression oncall: profiler</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113704</td>\n",
       "      <td>RandomResizedCrop: error nll_loss2d_forward_ke...</td>\n",
       "      <td>### 🐛 Describe the bug\\n\\nI am running a seman...</td>\n",
       "      <td>2023-11-14 22:35:32+00:00</td>\n",
       "      <td>2023-11-15 16:24:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>needs reproduction module: loss module: cuda t...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113696</td>\n",
       "      <td>Spammy inductor debug log: cannot fuse (vert:2...</td>\n",
       "      <td>### 🐛 Describe the bug\\n\\nWhat it looks like:\\...</td>\n",
       "      <td>2023-11-14 22:21:25+00:00</td>\n",
       "      <td>2023-11-15 01:39:09+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>6</td>\n",
       "      <td>Remove dampening from SGD</td>\n",
       "      <td>I think we could remove dampening parameter fr...</td>\n",
       "      <td>2016-08-31 14:32:45+00:00</td>\n",
       "      <td>2016-09-10 17:46:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>5</td>\n",
       "      <td>Checklist for Release</td>\n",
       "      <td>## Core\\n### Core Framework code\\n- [x] optim ...</td>\n",
       "      <td>2016-08-26 16:59:48+00:00</td>\n",
       "      <td>2017-04-18 21:31:43+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>3</td>\n",
       "      <td>PEP8 todo</td>\n",
       "      <td>I have an unhealthy obsession with PEP8... Cou...</td>\n",
       "      <td>2016-08-16 18:28:20+00:00</td>\n",
       "      <td>2017-01-28 00:15:52+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>todo</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>2</td>\n",
       "      <td>Don't support legacy Python</td>\n",
       "      <td>There is really no reason to support Python 2....</td>\n",
       "      <td>2016-08-16 13:04:07+00:00</td>\n",
       "      <td>2016-09-10 07:25:59+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>1</td>\n",
       "      <td>Matrix multiplication operator</td>\n",
       "      <td>Instead of overloading the multiplication oper...</td>\n",
       "      <td>2016-08-15 23:01:35+00:00</td>\n",
       "      <td>2016-08-24 14:57:47+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25543 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Issue Number                                        Issue Title  \\\n",
       "0           113781  DISABLED test_2d_fsdp_tp_ac_compile (__main__....   \n",
       "1           113758  missing device=p.device in Adam optimizer, lea...   \n",
       "2           113756  Wrongly formatted string in profiler_util.py t...   \n",
       "3           113704  RandomResizedCrop: error nll_loss2d_forward_ke...   \n",
       "4           113696  Spammy inductor debug log: cannot fuse (vert:2...   \n",
       "...            ...                                                ...   \n",
       "5538             6                         Remove dampening from SGD    \n",
       "5539             5                             Checklist for Release    \n",
       "5540             3                                          PEP8 todo   \n",
       "5541             2                       Don't support legacy Python    \n",
       "5542             1                    Matrix multiplication operator    \n",
       "\n",
       "                                             Issue Body  \\\n",
       "0     Platforms: linux\\n\\nBroken on multigpu\\n\\nTo r...   \n",
       "1     ### 🐛 Describe the bug\\n\\nI am using the Adam ...   \n",
       "2     ### 🐛 Describe the bug\\n\\nThe string in line h...   \n",
       "3     ### 🐛 Describe the bug\\n\\nI am running a seman...   \n",
       "4     ### 🐛 Describe the bug\\n\\nWhat it looks like:\\...   \n",
       "...                                                 ...   \n",
       "5538  I think we could remove dampening parameter fr...   \n",
       "5539  ## Core\\n### Core Framework code\\n- [x] optim ...   \n",
       "5540  I have an unhealthy obsession with PEP8... Cou...   \n",
       "5541  There is really no reason to support Python 2....   \n",
       "5542  Instead of overloading the multiplication oper...   \n",
       "\n",
       "                   Time created                Time closed  \\\n",
       "0     2023-11-15 17:59:31+00:00  2023-11-15 18:38:16+00:00   \n",
       "1     2023-11-15 13:00:20+00:00  2023-11-15 21:03:24+00:00   \n",
       "2     2023-11-15 12:43:01+00:00  2023-11-15 17:07:47+00:00   \n",
       "3     2023-11-14 22:35:32+00:00  2023-11-15 16:24:51+00:00   \n",
       "4     2023-11-14 22:21:25+00:00  2023-11-15 01:39:09+00:00   \n",
       "...                         ...                        ...   \n",
       "5538  2016-08-31 14:32:45+00:00  2016-09-10 17:46:00+00:00   \n",
       "5539  2016-08-26 16:59:48+00:00  2017-04-18 21:31:43+00:00   \n",
       "5540  2016-08-16 18:28:20+00:00  2017-01-28 00:15:52+00:00   \n",
       "5541  2016-08-16 13:04:07+00:00  2016-09-10 07:25:59+00:00   \n",
       "5542  2016-08-15 23:01:35+00:00  2016-08-24 14:57:47+00:00   \n",
       "\n",
       "      Number of Assignees  Number of Comments  \\\n",
       "0                       0                   1   \n",
       "1                       0                   1   \n",
       "2                       1                   2   \n",
       "3                       0                   2   \n",
       "4                       0                   4   \n",
       "...                   ...                 ...   \n",
       "5538                    0                   3   \n",
       "5539                    0                   4   \n",
       "5540                    0                   5   \n",
       "5541                    0                   5   \n",
       "5542                    0                   3   \n",
       "\n",
       "                                                   Tags  Is Bug  \\\n",
       "0                                               skipped   False   \n",
       "1                             module: optimizer triaged    True   \n",
       "2           triaged module: regression oncall: profiler    True   \n",
       "3     needs reproduction module: loss module: cuda t...    True   \n",
       "4                                                          True   \n",
       "...                                                 ...     ...   \n",
       "5538                                                      False   \n",
       "5539                                                      False   \n",
       "5540                                               todo   False   \n",
       "5541                                                      False   \n",
       "5542                                                      False   \n",
       "\n",
       "      Predicted_Is_Bug  LR_Predicted_Is_Bug  Final_Is_Bug  \n",
       "0                    0                    0             0  \n",
       "1                    0                    0             0  \n",
       "2                    0                    1             1  \n",
       "3                    1                    1             1  \n",
       "4                    0                    0             0  \n",
       "...                ...                  ...           ...  \n",
       "5538                 0                    0             0  \n",
       "5539                 0                    0             0  \n",
       "5540                 0                    0             0  \n",
       "5541                 0                    0             0  \n",
       "5542                 0                    0             0  \n",
       "\n",
       "[25543 rows x 12 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR_Predicted_Is_Bug\n",
       "0    13904\n",
       "1    11639\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_torch['LR_Predicted_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Issue Number', 'Issue Title', 'Issue Body', 'Time created',\n",
       "       'Time closed', 'Number of Assignees', 'Number of Comments', 'Tags',\n",
       "       'Is Bug', 'Predicted_Is_Bug', 'LR_Predicted_Is_Bug', 'Final_Is_Bug'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_torch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the csv file \n",
    "saved_df = df_torch[['Issue Number','Issue Title', 'Issue Body', 'Time created',\n",
    "       'Time closed', 'Number of Assignees', 'Number of Comments', 'Tags', 'Final_Is_Bug']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_df.to_csv('torch_issues_classified.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Results with Issue Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = pd.read_csv('../../issues_parser/Not_Modified_Data/tf_issues/tf_issues_classified.csv_0.csv')\n",
    "for i in range(1, 4):\n",
    "    df_tf = pd.concat([df_tf, pd.read_csv('../../issues_parser/Not_Modified_Data/tf_issues/tf_issues_classified.csv_' + str(i) + '.csv')])\n",
    "df_tf['Tags'] = df_tf['Tags'].apply(get_type)\n",
    "df_tf['Issue Title'] = df_tf['Issue Title'] + ' ' + df_tf['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Predicted Labels usingwordBasedChecker\n",
    "tf_predicted_labels = []\n",
    "for index, row in df_tf.iterrows():\n",
    "    tf_predicted_labels.append(wordBasedChecker(row['Issue Title']))\n",
    "\n",
    "#convert the list to numpy array\n",
    "tf_predicted_labels = np.asarray(tf_predicted_labels)\n",
    "df_tf['Predicted_Is_Bug'] = tf_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted_Is_Bug\n",
       "0    30177\n",
       "1     6195\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf['Predicted_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mamm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "#using frequency \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        processed_text = ' '.join(tokens)\n",
    "    except: \n",
    "        print(text)\n",
    "        processed_text = \"\"\n",
    "    return processed_text\n",
    "\n",
    "# Example data\n",
    "documents = data_tf_concat_bert['Issue Title'].values.tolist()\n",
    "labels = data_tf_concat_bert['Is Bug'].values.tolist()\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "model.fit(preprocessed_documents, labels)\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = df_tf['Issue Title'].values.tolist()\n",
    "new_data_preprocessed = [preprocess_text(doc) for doc in new_data]\n",
    "LR_prediction = model.predict(new_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Is_Bug\n",
       "1    23338\n",
       "0    13034\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the predictions to the dataframe\n",
    "df_tf['LR_Predicted_Is_Bug'] = LR_prediction\n",
    "df_tf['Final_Is_Bug'] = df_tf['LR_Predicted_Is_Bug'] | df_tf['Predicted_Is_Bug']\n",
    "df_tf['Final_Is_Bug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the csv file \n",
    "saved_df = df_tf[['Issue Number','Issue Title', 'Issue Body', 'Time created',\n",
    "       'Time closed', 'Number of Assignees', 'Number of Comments', 'Tags', 'Final_Is_Bug']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_df.to_csv('tf_issues_classified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mohamed_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
