Issue Number,Issue Title,Issue Body
34734,tensor_diag_part does not vectorize?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.1
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7

**Describe the current behavior**
This code throws an error, despite `tf.linalg.tensor_diag_part` works on each of the two matrices:

```python
    k = tf.convert_to_tensor(np.arange(8).reshape((2,2,2)))
    tf.vectorized_map(tf.linalg.tensor_diag_part, k)
```

> UnrecognizedFlagError: Unknown command line flag 'f'

It should return the diagonal of each of the two submatrices."
34733,loss=tf.keras.backend.sparse_categorical_crossentropy is different than loss='sparse_categorical_crossentropy',"So they run differently, with the version from the backend performing significantly worse.
This was performed on a google colab notebook reset each time, with GPU acceleration.

**Code 1**
`
%tensorflow_version 2.x

import tensorflow as tf

print(tf.__version__)

mnist = tf.keras.datasets.fashion_mnist

(training_images,training_labels),(test_images,test_labels)=mnist.load_data()

training_images=training_images/255.0

#training_images=tf.reshape(training_images,(training_images.shape+(1,)))

test_images=test_images/255.0

#test_images=tf.reshape(test_images,(test_images.shape+(1,)))

model = tf.keras.models.Sequential([

  tf.keras.layers.InputLayer(input_shape=(28, 28)),

  tf.keras.layers.Reshape((28, 28, 1)),

  tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.leaky_relu,input_shape=(28,28,1)),

  tf.keras.layers.MaxPooling2D(2,2),

  tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.leaky_relu),

  tf.keras.layers.MaxPooling2D(2,2),

  tf.keras.layers.Flatten(),

  tf.keras.layers.Dense(128,activation=tf.nn.leaky_relu),

  tf.keras.layers.Dense(10,activation='softmax')

])

model.compile(optimizer='adam',loss=tf.keras.backend.sparse_categorical_crossentropy,metrics=
['accuracy'])

#model.summary()

model.fit(training_images,training_labels,epochs=5)

test_loss=model.evaluate(test_images,test_labels)

`

Results 1

`

TensorFlow 2.x selected.

2.0.0

Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-
idx1-ubyte.gz

32768/29515 [=================================] - 0s 0us/step

Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-
idx3-ubyte.gz

26427392/26421880 [==============================] - 0s 0us/step

Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-
idx1-ubyte.gz

8192/5148 [===============================================] - 0s 0us/step

Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-
idx3-ubyte.gz

4423680/4422102 [==============================] - 0s 0us/step

Train on 60000 samples

Epoch 1/5

60000/60000 [==============================] - 24s 392us/sample - loss: 0.4204 - 
accuracy: 0.1043

Epoch 2/5

60000/60000 [==============================] - 18s 301us/sample - loss: 0.2878 - 
accuracy: 0.1026

Epoch 3/5

60000/60000 [==============================] - 18s 307us/sample - loss: 0.2474 - 
accuracy: 0.1016

Epoch 4/5

60000/60000 [==============================] - 18s 293us/sample - loss: 0.2156 - 
accuracy: 0.1011

Epoch 5/5

60000/60000 [==============================] - 18s 296us/sample - loss: 0.1936 - 
accuracy: 0.1011

`

**Code 2**

`

%tensorflow_version 2.x

import tensorflow as tf

print(tf.__version__)

mnist = tf.keras.datasets.fashion_mnist

(training_images,training_labels),(test_images,test_labels)=mnist.load_data()

training_images=training_images/255.0

#training_images=tf.reshape(training_images,(training_images.shape+(1,)))

test_images=test_images/255.0

#test_images=tf.reshape(test_images,(test_images.shape+(1,)))

model = tf.keras.models.Sequential([

  tf.keras.layers.InputLayer(input_shape=(28, 28)),

  tf.keras.layers.Reshape((28, 28, 1)),

  tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.leaky_relu,input_shape=(28,28,1)),

  tf.keras.layers.MaxPooling2D(2,2),

  tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.leaky_relu),

  tf.keras.layers.MaxPooling2D(2,2),

  tf.keras.layers.Flatten(),

  tf.keras.layers.Dense(128,activation=tf.nn.leaky_relu),

  tf.keras.layers.Dense(10,activation='softmax')

])

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

#model.summary()

model.fit(training_images,training_labels,epochs=5)

test_loss=model.evaluate(test_images,test_labels)

`

Results 2

`

TensorFlow 2.x selected.

2.0.0

Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-
idx1-ubyte.gz

32768/29515 [=================================] - 0s 0us/step

Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-
idx3-ubyte.gz

26427392/26421880 [==============================] - 0s 0us/step

Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-
idx1-ubyte.gz

8192/5148 [===============================================] - 0s 0us/step

Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-
idx3-ubyte.gz

4423680/4422102 [==============================] - 0s 0us/step

Train on 60000 samples

Epoch 1/5

60000/60000 [==============================] - 11s 186us/sample - loss: 0.4279 - 
accuracy: 0.8448

Epoch 2/5

60000/60000 [==============================] - 6s 92us/sample - loss: 0.2905 - 
accuracy: 0.8934

Epoch 3/5
60000/60000 [==============================] - 6s 92us/sample - loss: 0.2466 - accuracy: 0.9096
Epoch 4/5
60000/60000 [==============================] - 6s 92us/sample - loss: 0.2177 - accuracy: 0.9183
Epoch 5/5
60000/60000 [==============================] - 5s 91us/sample - loss: 0.1942 - accuracy: 0.9271
`"
34732,Bug with embedding layer for position of sequence using tf.cumsum,"Greetings,

I wanted to create an embedding layer for token position along with an embedding layer for token
in the sequence.

The first way I did was that I create a pos_ids input tensor, and feed an numpy array of position into the input. I then use embedding layer for the input as usual:

`word_ids = Input(dtype='int32', batch_shape=(batch_size, max_seq_length), name='word_ids')
pos_ids = Input(dtype='int32', batch_shape=(batch_size, max_seq_length), name='pos_ids')
pos_embedding_layer = tensorflow.keras.layers.Embedding(input_dim=(max_seq_length+1), 
            output_dim=word_embedding_size, 
            input_length=max_seq_length, mask_zero=True, trainable=True)
embedding_layer = tensorflow.keras.layers.Embedding(input_dim=(len(d)+1), 
            output_dim=word_embedding_size, 
            input_length=max_seq_length, mask_zero=True, trainable=True)
pos_ids_embeddings = pos_embedding_layer(pos_ids)`

With this I noticed the network is as usual, with parameters (18432) for the embedding layer. Here is what I get when I print the model summary.

![image](https://user-images.githubusercontent.com/8759715/69912311-129b4800-145a-11ea-98c2-b9947e0c6bb9.png)


However, I wanted to use tf.cumsum as another way to create the index of position. By doing that I can avoid having pos_ids as the another Input. My code is as follows, which I believe it is correct.

`word_ids = Input(dtype='int32', batch_shape=(batch_size, max_seq_length), name='word_ids')
pos_embedding_layer = tensorflow.keras.layers.Embedding(input_dim=(max_seq_length+1), 
            output_dim=word_embedding_size, 
            input_length=max_seq_length, mask_zero=True, trainable=True)
embedding_layer = tensorflow.keras.layers.Embedding(input_dim=(len(d)+1), 
            output_dim=word_embedding_size, 
            input_length=max_seq_length, mask_zero=True, trainable=True)
pos_tensor = tf.cumsum(tf.ones_like(word_ids, 'int32'), axis=-1)
pos_ids_embeddings = pos_embedding_layer(pos_tensor)`

However, with this, I noticed pos_embedding_layer does not have any param when I print the model summary (model.summary()). The layer also does not connect to anything in the network.

![image](https://user-images.githubusercontent.com/8759715/69912147-cb13bc80-1457-11ea-8ca5-833821041199.png)

I guess this is a bug, and please correct me if it is the case. Also, how to fix this problem?
Thx.

"
34731,ValueError: Unknown loss function:smooth_l1_loss,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):  anaconda
- TensorFlow version (use command below): 2.0
- Python version: 3.7.5
- CUDA/cuDNN version: 10.1

**Error info**
```
Traceback (most recent call last):
  File ""/home/lxz/PycharmProjects/PoseREN_tf2/src/train_baseline.py"", line 115, in <module>
    baseline_model_load = tf.keras.models.load_model(MODEL_DIR, 'baseline.h5')
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 93, in load
    model._training_config))  # pylint: disable=protected-access
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 336, in compile
    self.loss, self.output_names)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 1351, in prepare_loss_functions
    loss_functions = [get_loss_function(loss) for _ in output_names]
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 1351, in <listcomp>
    loss_functions = [get_loss_function(loss) for _ in output_names]
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 1087, in get_loss_function
    loss_fn = losses.get(loss)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py"", line 1183, in get
    return deserialize(identifier)
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py"", line 1174, in deserialize
    printable_module_name='loss function')
  File ""/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 210, in deserialize_keras_object
    raise ValueError('Unknown ' + printable_module_name + ':' + object_name)
ValueError: Unknown loss function:smooth_l1_loss
```

**Code crop**
```
# Loss func
@tf.function
def smooth_l1_loss(y_true, y_pred):
    return tf.compat.v1.losses.huber_loss(y_true, y_pred)


baseline_model.compile(optimizer=keras.optimizers.SGD(learning_rate=LEARNING_RATE, momentum=MOMENTUM, decay=DECAY),
                           loss=smooth_l1_loss, 
                           metrics=['MeanAbsoluteError'])  

history = baseline_model.fit(x=train_images, y=train_labels, validation_data=(vali_images, vali_labels),
                                 steps_per_epoch=np.ceil(train_images.shape[0] / BATCH_SIZE),
                                 validation_steps=np.ceil(vali_images.shape[0] / BATCH_SIZE),
                                 epochs=EPOCHS, batch_size=BATCH_SIZE,
                                 callbacks=callbacks)

baseline_model.save(MODEL_DIR, 'baseline.h5')

baseline_model_load = tf.keras.models.load_model(MODEL_DIR, 'baseline.h5')

test_data = np.random.random((1, 96, 96)).reshape((-1, 96, 96, 1))
print(baseline_model_load.predict(test_data))
```

"
34727,AttributeError: module 'tensorflow_datasets' has no attribute 'load',"This problem is usually caused by the mismatch between cuda and NVIDIA drivers, but my environment should be compatible. When I use tf2.0 to do other things, everything is normal, but when testing the transformers (https://github.com/huggingface/ transformers) encountered an error.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (pip):
- TensorFlow version (2.0):
- Python version: 3.6
- cuda: release 10.0, V10.0.130
- cudnn: 7.6.4
- driver version: Driver Version: 415.27

**Code to reproduce the issue**
cd transformers/
python -m pytest -sv ./examples/

I noticed that This repo((https://github.com/huggingface/ transformers)) is tested on Python 2.7 and 3.5+ (examples are tested only on python 3.5+), but i use python 3.6? Is this the cause?"
34726,tensorflow/workspace: re2 dependency does not use release/master branch,"tensorflow/workspace.bzl has this for the re2 dep:

```
    tf_http_archive(
        name = ""com_googlesource_code_re2"",
        sha256 = ""d070e2ffc5476c496a6a872a6f246bfddce8e7797d6ba605a7c8d72866743bf9"",
        strip_prefix = ""re2-506cfa4bffd060c06ec338ce50ea3468daa6c814"",
        system_build_file = clean_dep(""//third_party/systemlibs:re2.BUILD""),
        urls = [
            ""https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/re2/archive/506cfa4bffd060c06ec338ce50ea3468daa6c814.tar.gz"",
            ""https://github.com/google/re2/archive/506cfa4bffd060c06ec338ce50ea3468daa6c814.tar.gz"",
        ],
    )
```

That commit is https://github.com/google/re2/commit/506cfa4bffd060c06ec338ce50ea3468daa6c814 which is on some random branch called abseil (https://github.com/google/re2/commits/abseil) and incompatible with master or any released version of re2. This completely breaks building against system libs. On Gentoo we have re2-2019.09.01 packaged (and i cant and wont change the package to use a random branch because other packages (eg chromium) need the real released versions not a random branch).

TF wont build against master, it fails with errors about ""StringPiece"" vs ""string_view"". I cant figure out how to link properly to the diff but go here https://github.com/google/re2/compare/abseil#diff-6dc69df7618951357bb5fb674c66aa34 and click ""files changed"" then ""showing 120 changed files"" then click re2/re2.h. Its fairly obvious why its failing to build. 

What even is the abseil branch? The stats say `This branch is 166 commits ahead, 167 commits behind master.` So its clearly not just some feature branch that is going to be merged in soon.
TF should be using master, if TF needs some new functionality in deps then please make a new re2 release first? I (grudgingly) understand why for eigen and llvm, but re2 has monthly release cycles

@gunan @angerson @martinwicke 
"
34724,Can't accept a 2d array,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (latest version)
- TensorFlow installed from (source or binary): PIP
- TensorFlow version (use command below): 1.14
- Python version: 3.7.4

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**When feeding the fully connected layer my last 2d rnn matrix even though the documentation says that it should be able to accept a 2d matrix**

**It should take a 2d matrix**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
import tensorflow as tf

inputs = tf.placeholder(tf.int32, shape=(None, 750), name=""inputs"")
questions = tf.placeholder(tf.int32, shape=(None, 750), name=""inputs"")

gru_cell = tf.nn,rnn_cell.GRUCell(64) # Units= 64
output, (state_c, state_h) = gru_cell(inputs, questions)
# Both output & both states dimension is 2
logits = tf.contrib.layers.fully_connected(output, num_outputs=100, activation_fn=None) # vocab_size = 100
# We don't have to run the session since Tensorflow will check the tensors for the right shape
```
"
34723,2.1.0rc0 cudart64_101.dll not found,"**System information**
- OS Platform: Windows 10
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1.0rc0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: virtualenv
- CUDA/cuDNN version: 10.0
- GPU model and memory: rtx 2060



**Describe the problem**

When I tried to install tensorflow 2.1.0rc0, It didn't recognize my gpu and gave me this error:

Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found

Is that mean 2.1.0rc0 support cuda 10.1 now? It doesn't mention on release notes?


"
34722,ModuleNotFoundError tensorflow.python' is not a package,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home
- TensorFlow version (use command below): 2.0
- Python version: 3.6.7 and 3.7.4

**Describe the current behavior**
When trying to import Tensorflow using this line:
`import tensorflow as tf`

I get this error:

> Traceback (most recent call last):
  File ""singlestock/code.py"", line 1, in <module>
    import tensorflow as tf
  File ""D:\documenten\programs\Python\3.6.7\lib\site-packages\tensorflow\__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""D:\documenten\programs\Python\3.6.7\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
ModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package

**Describe the expected behavior**
I shouldn't get this error. I should just be able to import tensorflow and then use it.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

This is the code which doesn't work for me:
I've tried this in python 3.7 and 3.6.
```
import tensorflow as tf

tensor = tf.convert_to_tensor([[1, 2, 3, 4], [2, 3, 4, 5]], tf.int32)
print(""hello"")
```

I don't think the issue is in the code though, but I have no idea what the problem could be.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

error:
> Traceback (most recent call last):
  File ""singlestock/code.py"", line 1, in <module>
    import tensorflow as tf
  File ""D:\documenten\programs\Python\3.6.7\lib\site-packages\tensorflow\__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""D:\documenten\programs\Python\3.6.7\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
ModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package

code:
```
import tensorflow as tf

tensor = tf.convert_to_tensor([[1, 2, 3, 4], [2, 3, 4, 5]], tf.int32)
print(""hello"")
```
"
34721,Missing information: embedding_lookup automatically returns 0 for an out-of-vocab index,"Greetings,

I expected embedding layer gives an error when a word id is beyond the fixed pre-determined vocab size. Nonetheless, it is not the case as tf.nn.embedding_lookup automatically return 0 for an out-of-vocab index. While this is nice, it is risky because there is no information or anything like that from the website https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding. I personally did not know that until digging to the code carefully.

So I think more information at the website should be updated.

Example code to see how embedding_lookup returns output:

>>> sess = tf.compat.v1.InteractiveSession()
>>> params = tf.constant([10,20,30,40])
>>> ids = tf.constant([0,1,2,3,4,5])
>>> tf.nn.embedding_lookup(params,ids).eval()
array([10, 20, 30, 40,  0,  0], dtype=int32)"
34720,Bug in person_detection tf-lite example ,"tf==1.15
I just follow the step in [person_detection example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/examples/person_detection/training_a_model.md), after i get `vww_96_grayscale_frozen.pb`, when i want to generate `vww_96_grayscale_quantized.tflite`, I get a error `ValueError: Cannot set tensor: Dimension mismatch`, can you see it  @dansitu 

```
Traceback (most recent call last):                                                                    
  File ""get_tflite.py"", line 32, in <module>                                                          
    tflite_quant_model = converter.convert()                                                          
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py"", line 993, in conv
ert                                                                                                   
    inference_output_type)                                                                            
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py"", line 239, in _cal
ibrate_quantize_model                                                                                 
    inference_output_type, allow_float)                                                               
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/calibrator.py"", li
ne 75, in calibrate_and_quantize                                                                      
    self._calibrator.FeedTensor(calibration_sample)                                                   
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wr
ap_calibration_wrapper.py"", line 112, in FeedTensor                                                   
    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_FeedTensor(self, input_value) 
ValueError: Cannot set tensor: Dimension mismatch
```"
34719,Docker build for TensorFlow GPU taking too long(Up 45 hours!) ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Docker image (tensorflow/tensorflow:devel-gpu-py3)
- TensorFlow version: 2.0
- Python version: 3
- Installed using virtualenv? pip? conda?: Docker 
- Bazel version (if compiling from source): default for docker image
- GCC/Compiler version (if compiling from source): default for docker image
- CUDA/cuDNN version: 10.0
- GPU model and memory: GT 750m
- CPU: Intel® Core™ i7-4500U CPU @ 1.80GHz × 4 


**Describe the problem**
I'm trying to build TensorFlow for my GPU with CUDA compute capability 3.0. The build seems to take forever to complete.
I'm following these guides:
[Build from source using Docker](https://www.tensorflow.org/install/source#gpu_support_3)
[Setup Docker for TensorFlow ](https://www.tensorflow.org/install/docker)

I can't figure out if I did something wrong.


**Provide the exact sequence of commands/steps that you executed before running into the problem**

Following Docker commands were used to run the container:
```
docker pull tensorflow/tensorflow:devel-gpu-py3
docker run --gpus all -it -w /tensorflow -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" tensorflow/tensorflow:devel-gpu-py3 bash
```

Then navigating to `tensorflow_src`,  `./configure` the command was run setting all values to defaults and ""No"" to all features(CUDA and CUdnn were automatically detected)

Finally, the following command was run to start the build process:
```
bazel build --config=v2 --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Currently, the container has been up for 45 hours!. It doesn't seem like it is coming to end anytime soon. At the time of writing Bazel build is on action 29,910/29,333.
```
CONTAINER ID        IMAGE                                 COMMAND             CREATED             STATUS              PORTS               NAMES
9bcd8e96c6ce        tensorflow/tensorflow:devel-gpu-py3   ""bash""              45 hours ago        Up 45 hours                             cool_spence
```
"
34718,"explicit GPU device placement failed due to runtime error ""unknown CPU""","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf2.0
- Python version: 3.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10
- GPU model and memory: NV V100 32GB

**Describe the current behavior**
The graphic memory of the specified GPU has been allocated, but a runtime error occurred, saying `RuntimeError: /job:localhost/replica:0/task:0/device:CPU:1 unknown device.`
**Describe the expected behavior**
Successfully deploy the model to the specified GPU
**Code to reproduce the issue**
```python
with tf.device('GPU:1'):
    mobile_net_local_path = ""/mobilenet"" # the local model is the same as the one on https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4, which is runnable on GPU:0
    mobile_net = hub.KerasLayer(mobile_net_local_path,output_shape = [1280] , trainable=True)
```

**Other info / logs**
The logical devices(given by `tf.config.experimental.list_logical_devices()`) are below:
```python
[LogicalDevice(name='/job:localhost/replica:0/task:0/device:CPU:0', device_type='CPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_CPU:0', device_type='XLA_CPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:0', device_type='GPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:1', device_type='GPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:2', device_type='GPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:3', device_type='GPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:4', device_type='GPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:0', device_type='XLA_GPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:1', device_type='XLA_GPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:2', device_type='XLA_GPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:3', device_type='XLA_GPU'),
 LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:4', device_type='XLA_GPU')]
```
and physical devices are below:
```python
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),
 PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),
 PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),
 PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),
 PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),
 PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),
 PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),
 PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),
 PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'),
 PhysicalDevice(name='/physical_device:XLA_GPU:2', device_type='XLA_GPU'),
 PhysicalDevice(name='/physical_device:XLA_GPU:3', device_type='XLA_GPU'),
 PhysicalDevice(name='/physical_device:XLA_GPU:4', device_type='XLA_GPU')]
```

the error is 
```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-4-f31b7e9deb50> in <module>
      3 with tf.device('GPU:1'):
      4     mobile_net_local_path = ""HandGestureRecognizer/tf2models/mobilenet""
----> 5     mobile_net = hub.KerasLayer(mobile_net_local_path,output_shape = [1280] , trainable=True)

~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py in __init__(self, handle, trainable, arguments, **kwargs)
    102       self._func = handle
    103     else:
--> 104       self._func = module_v2.load(handle)
    105       if not callable(self._func):
    106         raise ValueError(""Non-callable result from hub.load('%s')"" %

~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_hub/module_v2.py in load(handle, tags)
     75   if hasattr(tf_v1.saved_model, ""load_v2""):
     76     module_handle = resolve(handle)
---> 77     return tf_v1.saved_model.load_v2(module_handle, tags=tags)
     78   else:
     79     raise NotImplementedError(""hub.load() is not implemented for TF < 1.14.x, ""

~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py in load(export_dir, tags)
    515     ValueError: If `tags` don't match a MetaGraph in the SavedModel.
    516   """"""
--> 517   return load_internal(export_dir, tags)
    518 
    519 

~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py in load_internal(export_dir, tags, loader_cls)
    539       loader = loader_cls(object_graph_proto,
    540                           saved_model_proto,
--> 541                           export_dir)
    542       root = loader.get(0)
    543     root.tensorflow_version = meta_graph_def.meta_info_def.tensorflow_version

~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py in __init__(self, object_graph_proto, saved_model_proto, export_dir)
    126     self._setup_functions_structures()
    127     self._setup_functions_captures()
--> 128     self._restore_checkpoint()
    129 
    130     for node in self._nodes:

~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py in _restore_checkpoint(self)
    277     saver = util.TrackableSaver(graph_view.ObjectGraphView(self.get(0)))
    278     with ops.device(""CPU""):
--> 279       saver._file_prefix_placeholder = constant_op.constant(variables_path)
    280     load_status = saver.restore(variables_path)
    281     load_status.assert_existing_objects_matched()

~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in constant(value, dtype, shape, name)
    225   """"""
    226   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 227                         allow_broadcast=True)
    228 
    229 

~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    233   ctx = context.context()
    234   if ctx.executing_eagerly():
--> 235     t = convert_to_eager_tensor(value, ctx, dtype)
    236     if shape is None:
    237       return t

~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
     94       dtype = dtypes.as_dtype(dtype).as_datatype_enum
     95   ctx.ensure_initialized()
---> 96   return ops.EagerTensor(value, ctx.device_name, dtype)
     97 
     98 

RuntimeError: /job:localhost/replica:0/task:0/device:CPU:1 unknown device.
```
After executing the python codes above, it can be seen in `nvidia-smi` that the graphic memory of the specified GPU (GPU:1) has been allocated.
```
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     12253      C   ...user/anaconda3/envs/tf2/bin/python   307MiB |
|    0     20120      C   python3                                     2617MiB |
|    0     27393      C   python3                                     1701MiB |
|    0     68670      C   python3                                      941MiB |
|    0     73404      C   python3                                     1209MiB |
|    1     12253      C   ...user/anaconda3/envs/tf2/bin/python 31009MiB |
|    2     12253      C   ...user/anaconda3/envs/tf2/bin/python   307MiB |
|    3     12253      C   ...user/anaconda3/envs/tf2/bin/python   307MiB |
|    4     12253      C   ...user/anaconda3/envs/tf2/bin/python   307MiB |
+-----------------------------------------------------------------------------+
```
"
34717,How to boost speed for cpu in TF2?,"I am running a program based on tensorflow2.0 and do not use GPU, i use the 'top' command, i found the CPU's usage is strange:
%Cpu0  : 21.0 us,  1.0 sy,  0.0 ni, 78.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  : 15.7 us,  0.0 sy,  0.0 ni, 84.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu2  : 13.8 us,  1.3 sy,  0.0 ni, 84.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu3  : 15.2 us,  1.3 sy,  0.0 ni, 83.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu4  : 18.1 us,  1.3 sy,  0.0 ni, 80.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu5  : 14.9 us,  1.4 sy,  0.0 ni, 83.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu6  :  3.7 us,  1.3 sy,  0.0 ni, 95.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu7  :  5.0 us,  0.7 sy,  0.0 ni, 94.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu8  :  5.0 us,  0.7 sy,  0.0 ni, 94.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu9  :  5.0 us,  1.3 sy,  0.0 ni, 93.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu10 :  5.0 us,  1.3 sy,  0.0 ni, 93.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu11 :  4.4 us,  1.0 sy,  0.0 ni, 94.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st

In 12 cores, why just 6 cores are running at high load and 6cores is low high load? How can i boost speed with 12 core at high speed just like blas etc. parallel? Note i run this program in the environment where no other programs affect as i reboot my server.
Thanks!"
34716,tf.map_fn does not execute in parallel,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
2.0.0
- Python version:
3.7.4
- CUDA/cuDNN version:
10.1/7.6.5
- GPU model and memory:
GTX 1070


**Describe the current behavior**
The [documentation ](https://www.tensorflow.org/api_docs/python/tf/map_fn) for `map_fn` specifies that 

> When executing eagerly, map_fn does not execute in parallel even if parallel_iterations is set to a value > 1. You can still get the performance benefits of running a function in parallel by using the tf.contrib.eager.defun decorator,

However, `tf.contrib.eager.defun` no longer is available in TensorFlow 2.0. Hence, `map_fn` would only run on a single thread. 

How can I parallelize `map_fn ` in TensorFlow 2.0?
"
34715,Can't use assert statement inside tf.function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Manjaro Linux
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7

**Describe the current behavior**
`assert` with a tensor inside a `tf.function` results in the following error:
```
OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.
```

**Describe the expected behavior**
The assert statement should be converted to `tf.Assert` by AutoGraph.

**Code to reproduce the issue**
```python
import tensorflow as tf

@tf.function
def f(x):
    assert tf.constant(True), 'assert failed'
    return x

x = tf.ones(())
print(f(x))
```"
34714,TensorFlow 1.15.0 fails to build .so files in contrib ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>


**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina, Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.15
- Python version: 3
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 
macOS: Apple clang version 11.0.0 (clang-1100.0.33.12)
Ubuntu 18.04: 7.x
Ubuntu 16.04: 5.x
- CUDA/cuDNN version:
- GPU model and memory:
Only the machine with Ubuntu 16.04 has Tesla and CUDA

**Describe the problem**
I am trying to generate two `.so` files from contrib in TensorFlow `1.15.0`. I understand this version comes without contrib, so when it's installed via `pip` or `conda` I cannot find my two `.so` files like previous versions (1.12.0, 1.13.1): `_lstm_ops.so` and `_sparse_feature_cross_op.so`. However, if I build from the source of TF 1.15.0 in Ubuntu 16.04 I can see these two files for Linux. Since I need these two for macOS as well I tried to build from the source on my macOS. 

The build goes until the end without any problem, however, I cannot find these two `.so` files on my macOS. I have tried to replicate the same thing on Ubuntu 18.04, but I cannot find the `.so` files there neither. It seems the only place I can build from the source and get my `.so` files is in Ubuntu 16.04. 

How is it possible that Ubuntu 16.04 can build TF 1.15 from source and produce those two `.so` files, but it fails in macOS Catalina and Ubuntu 18.04? Is it because these two are newer systems? Is there a requirement for contrib to be a lower version?

**Provide the exact sequence of commands / steps that you executed before running into the problem**

- git clone TensorFlow
- git checkout r1.15
- ./configure (no gpu or anything extra - no to all questions)
- bazel build for java

The mentioned steps will produce the `.so` files I required in Ubuntu 16.04 but fail to do so in macOS (Catalina) nor in Ubuntu 18.04. 

The command to build from source for Java:
```bash
bazel build //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni
```

**Any other info / logs**
No, there is no error in any of the builds (Java, Python) in any of the three OS."
34713,Keras multi-output has array-like behaviour despite using dictionaries in output of dataset!,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, I've tweaked some example code from the docs. See below.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 16.04
- TensorFlow installed from (source or binary):
pip install --user tensorflow
- TensorFlow version (use command below):
('v2.0.0-rc2-26-g64c3d38', '2.0.0')
- Python version:
2.7

**Describe the current behavior**
If you set up a multi-output model with a loss attached to a single output, keras appears to create a loss for other heads anyhow, depending on the ordering of the outputs in the list argument. I believe that keras is utilizing some list-like behaviour where it shouldn't. Please see the example code and traceback below. 
**Describe the expected behavior**
In principle, the code should do as the [docs](https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models) appear to indicate and do things in a dictionary-based manner, not an array-based manner. For example, see the warning in the traceback: it indicates that other outputs besides the one that is tagged with a loss will be ignored, yet this does not appear to happen.

**Code to reproduce the issue**
I have taken bits of code from the docs linked above and tweaked it to reproduce the bug: 

Here is the tweaked code:
```from tensorflow import keras
import tensorflow as tf
import numpy as np
from tensorflow.keras import layers

image_input = keras.Input(shape=(32, 32, 3), name='img_input')
timeseries_input = keras.Input(shape=(None, 10), name='ts_input')

x1 = layers.Conv2D(3, 3)(image_input)
x1pool = layers.GlobalMaxPooling2D()(x1)

x2 = layers.Conv1D(3, 3)(timeseries_input)
x2pool = layers.GlobalMaxPooling1D(name='x2pool')(x2)

x = layers.concatenate([x1pool, x2pool])

# score_output = layers.Dense(1, name='score_output')(x)
class_output = layers.Dense(5, activation='softmax', name='class_output')(x)

# original outputs from docs example code
# outputs = [class_output, score_output]

# the commented one works (only by coincidence!), but the uncommented one doesnt
# outputs = [class_output, x2pool]
outputs = [x2pool, class_output]

model = keras.Model(inputs=[image_input, timeseries_input],
                    outputs=outputs)

model.compile(
    optimizer=keras.optimizers.Adam(),
    loss={'class_output': keras.losses.CategoricalCrossentropy()})


img_data = np.random.random_sample(size=(100, 32, 32, 3))
ts_data = np.random.random_sample(size=(100, 20, 10))
score_targets = np.random.random_sample(size=(100, 1))
class_targets = np.random.random_sample(size=(100, 5))


# we supply the targets for the loss that we tagged to the class_output head.
train_dataset = tf.data.Dataset.from_tensor_slices(
    ({'img_input': img_data, 'ts_input': ts_data},
     {'class_output': class_targets}))
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)

model.fit(train_dataset, epochs=3)
```

**Other info / logs**
Here's the traceback below. Notice it indicates that it will ignore x2pool in the warning, which is the behaviour that I want...but then it appears to have a loss for this at the end of the traceback and also connects the wrong output data to it!:

```2019-11-29 12:21:14.905823: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-29 12:21:14.930454: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3792445000 Hz
2019-11-29 12:21:14.931532: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c00230 executing computations on platform Host. Devices:
2019-11-29 12:21:14.931573: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Output x2pool missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to x2pool.
Epoch 1/3
      1/Unknown - 0s 27ms/stepTraceback (most recent call last):
  File ""tftest.py"", line 48, in <module>
    model.fit(train_dataset, epochs=3)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 73, in distributed_function
    per_replica_function, args=(model, x, y, sample_weights))
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 760, in experimental_run_v2
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1787, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 2132, in _call_for_each_replica
    return fn(*args, **kwargs)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 292, in wrapper
    return func(*args, **kwargs)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 264, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 311, in train_on_batch
    output_loss_metrics=output_loss_metrics))
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 252, in _process_single_batch
    training=training))
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 166, in _model_loss
    per_sample_losses = loss_fn.call(targets[i], outs[i])
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/losses.py"", line 221, in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/losses.py"", line 971, in categorical_crossentropy
    return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/backend.py"", line 4468, in categorical_crossentropy
    return -math_ops.reduce_sum(target * math_ops.log(output), axis)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/ops/math_ops.py"", line 899, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/ops/math_ops.py"", line 1206, in _mul_dispatch
    return gen_math_ops.mul(x, y, name=name)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py"", line 6701, in mul
    ""Mul"", x=x, y=y, name=name)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 548, in create_op
    compute_device)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal
    op_def=op_def)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1773, in __init__
    control_input_ops)
  File ""/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1613, in _create_c_op
    raise ValueError(str(e))
ValueError: Dimensions must be equal, but are 5 and 3 for 'loss/x2pool_loss/mul' (op: 'Mul') with input shapes: [?,5], [?,3].
```
"
34712,Please fix the example section of tf.constant_initialize,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/constant_initializer#used_in_the_tutorials

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/constant_initializer#used_in_the_tutorials

## Description of issue (what needs changing):
Please fix the example section of tf.constant_initialize
### Clear description
Examples section of the page is not properly compiled making it unreadable
For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style"
34710,Multiple inputs multiple outputs support for tensorflow serving,Hi I cannot deploy my keras-TF model via tensorflow serving because I have 4 inputs. Is there any chance to do it in other ways?
34709,allow_growth not working when using estimator and MirroredStrategy distribution,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0.130/7.6.4
- GPU model and memory: 8 * Tesla P40, 22919MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

When I use estimator and distribute.MirroredStrategy, it will allocate all GPU memory, even if I just use one GPU.

```
import tensorflow as tf
session_config = tf.ConfigProto()
session_config.gpu_options.allow_growth = True
session_config.allow_soft_placement = True
strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)
config = tf.estimator.RunConfig(session_config=session_config, train_distribute=strategy)
estimator = tf.estimator.Estimator(model_fn, model_dir, config, params)
estimator.train()
```

If I set `os.environ[""TF_FORCE_GPU_ALLOW_GROWTH""] = ""true""`, GPU memory will be correctly allocated. 

I don't know if it's related to `session_config.allow_soft_placement = True`, but if I don't set this value, it will raise error ""cannot assign a device for operation argmax"".

**Describe the expected behavior**

Make ""allow_growth"" working when using estimator and MirroredStrategy distribution.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import os
import tensorflow as tf
import tensorflow.keras.layers as layers
import numpy as np


def model_fn(features, labels, mode):
  """"""A simple 2-classify model.
  
  """"""
  model = tf.keras.Sequential([layers.Dense(80, activation=""relu""), layers.Dense(2)])
  logits = model(features)
  loss = tf.losses.softmax_cross_entropy(labels, logits)

  if mode == tf.estimator.ModeKeys.TRAIN:
    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)
    train_op = optimizer.minimize(loss, tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)


def input_fn():
  """"""dataset that return feature and label.

  """"""
  features_mat = np.random.randn(10, 10) 
  labels_mat = np.random.randint(0, 2, size=(10, 2)) 
  dataset = tf.data.Dataset.from_tensor_slices((features_mat, labels_mat))
  return dataset.batch(1)

os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""  # Set available GPU id. 
session_config = tf.ConfigProto()
session_config.gpu_options.allow_growth = True

session_config.allow_soft_placement = True
strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=1)
config = tf.estimator.RunConfig(session_config=session_config, train_distribute=strategy)
# If disable above 3 lines and using following line, GPU memory allocation will be correct.
#config = tf.estimator.RunConfig(session_config=session_config)

estimator = tf.estimator.Estimator(model_fn, config=config)

while True:
  estimator.train(input_fn)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34708,Can not convert a TF2 saved model to a TensorRT engine and save it.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): nightly
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: 2070Ti 8GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I want to convert a TF2 saved model to a TensorRT engine (already built). I following the instruction [here](https://github.com/tensorflow/tensorflow/blob/99cb9fd68d1b8c6f0857c0775c366234537bacf5/tensorflow/python/compiler/tensorrt/trt_convert.py#L823). However, it only gives me errors. I would give my code and log in following part.

BTW, I installed TensorRT 6.0.1 in my PC.


**Describe the expected behavior**

Convert saved model to a TensorRT engine and save it.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
import numpy as np
import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt

model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)
model.save(""dir1/"")

input_saved_model_dir = ""dir1/""
output_saved_model_dir = ""dir2/""

params = DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode='FP16', maximum_cached_engines=16, is_dynamic_op=True)
converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir, conversion_params=params)
converter.convert()
# converter.save(output_saved_model_dir)

def my_input_fn():
    num_runs = 10
    for _ in range(num_runs):
        inp1,inp2 = np.random.random([4, 128, 128, 3]), np.random.random([4, 128, 128, 1])
        yield inp1,inp2
        
converter.build(input_fn=my_input_fn)  # Generate corresponding TRT engines
converter.save(output_saved_model_dir)  # Generated engines will be saved.
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```bash
WARNING:tensorflow:From /home/shl666/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1788: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.

[11/29/2019 21:46:27 WARNING] From /home/shl666/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1788: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.

INFO:tensorflow:Assets written to: inference/sample/saved_model/assets

[11/29/2019 21:46:28 INFO] Assets written to: inference/sample/saved_model/assets

INFO:tensorflow:Linked TensorRT version: (6, 0, 1)
INFO:tensorflow:Loaded TensorRT version: (6, 0, 1)

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-5-9b2262c7c046> in <module>
     14         yield inp1, inp2
     15 
---> 16 converter.build(input_fn=my_input_fn)  # Generate corresponding TRT engines
     17 converter.save(output_saved_model_dir)  # Generated engines will be saved.

~/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py in build(self, input_fn)
   1049     """"""
   1050     for inp in input_fn():
-> 1051       self._converted_func(*map(ops.convert_to_tensor, inp))
   1052 
   1053   def save(self, output_saved_model_dir):

~/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   1549       TypeError: For invalid positional/keyword argument combinations.
   1550     """"""
-> 1551     return self._call_impl(args, kwargs)
   1552 
   1553   def _call_impl(self, args, kwargs, cancellation_manager=None):

~/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_impl(self, args, kwargs, cancellation_manager)
   1568            ""of {}), got {}. When calling a concrete function, positional ""
   1569            ""arguments may not be bound to Tensors within nested structures.""
-> 1570           ).format(self._num_positional_args, self._arg_keywords, args))
   1571     args = list(args)
   1572     for keyword in self._arg_keywords[len(args):]:

TypeError: Expected at most 1 positional arguments (and the rest keywords, of ['input_3']), got (<tf.Tensor: shape=(4, 128, 128, 3), dtype=float64, numpy=
array([[[[0.37694877, 0.14433618, 0.15041287],
         [0.28948027, 0.52537459, 0.51882755],
         [0.48836555, 0.45480828, 0.0779434 ],
....
....
....
        [0.02064168, 0.76855384, 0.64690949],
         [0.98667418, 0.9156569 , 0.58136711],
         [0.84539588, 0.7338271 , 0.15894349]],

        [[0.03578103, 0.24472914, 0.62393987],
         [0.51681037, 0.75395885, 0.83268599],
         [0.81616645, 0.4863684 , 0.25114351],
         ...,
         [0.08293289, 0.90668744, 0.94976784],
         [0.39264721, 0.33914333, 0.58584557],
         [0.57539905, 0.29829974, 0.33732885]]]])>, <tf.Tensor: shape=(4, 128, 128, 1), dtype=float64, numpy=
array([[[[0.55649055],
         [0.97303716],
         [0.90465544],
         ...,
         [0.76755675],
         [0.07142947],
         [0.80021061]],
....
....
....
        [[0.88080569],
         [0.53601004],
         [0.69139559],
         ...,
         [0.89977499],
         [0.73776336],
         [0.65023825]]]])>). When calling a concrete function, positional arguments may not be bound to Tensors within nested structures.


```
"
34707,Cannot deploy Tensorflow 2.0.0 to Google cloud functions,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google cloud functions
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

We are getting following error while trying to deploy Tensorflow 2.0.0. 

```
gcloud functions deploy matchProbability --runtime python37 --trigger-http --memory 2048MB --timeout=540 --set-env-vars TEMP=/tmp/
```

```
Deploying function (may take a while - up to 2 minutes)...failed.                                                                                                                         
ERROR: (gcloud.functions.deploy) OperationError: code=3, message=Build failed: {""error"": {""canonicalCode"": ""INVALID_ARGUMENT"", ""errorMessage"": ""'pip_download_wheels' had stderr output:\n 
 Could not find a version that satisfies the requirement tensorflow==2.0.0 (from -r requirements.txt (line 53)) (from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1,
 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1)\nNo matching distribution found for tensorflow==2.0.0 (from -r requirements.txt (line 53))\n\nerror: 'pip_download_wheels' returned code: 1"", ""errorTyp
e"": ""InternalError"", ""errorId"": ""72357014""}}
```

Not sure what are next steps should be, only [article](https://cloud.google.com/blog/products/ai-machine-learning/how-to-serve-deep-learning-models-using-tensorflow-2-0-with-cloud-functions) describing deploying Tensorflow to google cloud functions is using version 2.0.0b1. Should we downgrade?
"
34706,Complete support for LSTM/GRU for TFLite,"
**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Reading the [roadmap](https://www.tensorflow.org/lite/guide/roadmap) of Tensorflow Lite for 2019 there should be full LSTM/GRU support by the end of this year, but I don't seen anything done, also no recent update of the state of the roadmap. At the moment there are two [workarounds](https://www.tensorflow.org/lite/convert/rnn) that work suboptimally. I have never been able to reproduce nearly the results I had with plain TF.


**Who will benefit with this feature?**

I think having LSTM/GRU is crucial since a lot of architectures are using them and mobile/embedded DL development is a big topic right now.

"
34705,cuDNN error initializing ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOs 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.5.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 9.0 
- GPU model and memory: 4 * K80 - 24GB GDDR5 ECC

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
```
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
	 [[total_loss/_9637]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
0 successful operations.
0 derived errors ignored.
```
**Describe the expected behavior**
The training should proceed smoothly.
Actually I'm using object detection API, use ssd_mobilenet_v2_coco_2018_03_29

**Code to reproduce the issue**
On PBS system launch script code:
```
#!/bin/bash

# 'select' set number node
# 'ncpus' set number cpu
# 'mem' set RAM value * node = total
#PBS -l select=8:ncpus=4:mem=16gb

# set run queue

# specify qgpu resource
#PBS -q common_gpuQ

# set maximum exectuion time
#PBS -l walltime=1500:00:0

# set mail
#PBS -M francesco.argentieri@studenti.unitn.it

# send mail when start and end job
#PBS -m be
# write error log
#PBS -e error_dronelanding352.log

# write out log
#PBS -o result_dronelanding352.log

# show module
module avail

# load moudle
module load python-3.5.2 cuda-9.0

# show loaded module
module list

##############################################################################
# setup environmnet
##############################################################################
git clone -b develop https://github.com/frank1789/ProjectThesis.git
cd ProjectThesis
rm -rf train_labels.csv
rm -rf validate_labels.csv
git reset --hard
git pull
rm -rf models
python3 -c ""import tensorflow as tf; print('tensorflow version installed', tf.__version__)""
# run script
sh setup_tf.sh ssd_coco
```
my code is available at https://github.com/frank1789/ProjectThesis.git -> branch develop

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
[francesco.argentieri@hpc-head-n1 ~]$ cat error_dronelanding352.log

------------------------------ /apps/Modules/apps ------------------------------
atlas-3.10.3                    Magma
BertiniMPI_v1.5                 magma-2.24
Bertini_v1.5.1                  matlab_R2018b
BLAS                            matlab_runtime_91
cmake-3.10.2                    miniconda
cmake-3.15.4                    mpfr-3.1.5
cuda-10.0                       mpich-3.2
cuda-8.0                        mpich-3.2.1--gcc-9.1.0
cuda-9.0                        mpich-3.2.1--intel-xe-2019u1
espresso                        mpichtest
fftw-3.3.8                      ncview-1.93g
fiji                            netcdf-4.7.0--gcc-9.1.0
gcc54                           netCDF-Fortran-4.4.5--gcc-9.1.0
gcc91                           numactl
gmp-6.1.1                       OpenBLAS-0.3.7
hdf5-1.10.5--gcc-9.1.0          openmpi-3.0.0
hdf5-1.8.18                     python-2.7.12
hwloc-2.0.4                     python-3.5.2
ImageJ-1.5                      python-3.7.2
Intel_parallel_studio_xe2018u2  R-3.3.1
Intel_parallel_studio_xe2019u1  R-3.4.3
jdk-11.0.1                      R-3.6.1
jre1.8.0_161                    singularity
lammps                          singularity-2.4
lapack-3.7.0                    valgrind-3.15.0
lapack-3.8.0                    zlib-1.2.11--gcc-9.1.0
likwid-4.3.4
Currently Loaded Modulefiles:
  1) python-3.5.2   2) cuda-9.0
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

Running tests under Python 3.5.2: /apps/python-3.5.2/bin/python3
[ RUN      ] ModelBuilderTest.test_create_experimental_model
[       OK ] ModelBuilderTest.test_create_experimental_model
[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner
[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner
[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul
[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul
[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul
[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul
[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul
[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul
[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul
[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul
[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config
[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config
[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config
[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config
[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config
[       OK ] ModelBuilderTest.test_create_ssd_models_from_config
[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update
[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update
[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold
[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold
[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto
[       OK ] ModelBuilderTest.test_invalid_model_config_proto
[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size
[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size
[ RUN      ] ModelBuilderTest.test_session
[  SKIPPED ] ModelBuilderTest.test_session
[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor
[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor
[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture
[       OK ] ModelBuilderTest.test_unknown_meta_architecture
[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor
[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor
----------------------------------------------------------------------
Ran 17 tests in 0.217s

OK (skipped=1)
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  179M  100  179M    0     0  74.3M      0  0:00:02  0:00:02 --:--:-- 74.3M
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  4097  100  4097    0     0  19941      0 --:--:-- --:--:-- --:--:-- 19985
/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/visualization_utils.py:29: UserWarning:
This call to matplotlib.use() has no effect because the backend has already
been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,
or matplotlib.backends is imported for the first time.

The backend was *originally* set to 'TkAgg' by the following code:
  File ""/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/eval_util.py"", line 33, in <module>
    from object_detection.metrics import coco_evaluation
  File ""/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/metrics/coco_evaluation.py"", line 25, in <module>
    from object_detection.metrics import coco_tools
  File ""/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/metrics/coco_tools.py"", line 51, in <module>
    from pycocotools import coco
  File ""/home/francesco.argentieri/ProjectThesis/tf-models/research/pycocotools/coco.py"", line 49, in <module>
    import matplotlib.pyplot as plt
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/matplotlib/pyplot.py"", line 72, in <module>
    from matplotlib.backends import pylab_setup
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/matplotlib/backends/__init__.py"", line 14, in <module>
    line for line in traceback.format_stack()


  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W1129 13:11:00.107400 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

W1129 13:11:00.114970 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W1129 13:11:00.115096 46916307045888 model_lib.py:629] Forced number of epochs for all eval validations to be 1.
WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W1129 13:11:00.115231 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
I1129 13:11:00.115335 46916307045888 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I1129 13:11:00.115433 46916307045888 config_util.py:488] Maybe overwriting eval_num_epochs: 1
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I1129 13:11:00.115521 46916307045888 config_util.py:488] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting train_steps: 50000
I1129 13:11:00.115603 46916307045888 config_util.py:488] Maybe overwriting train_steps: 50000
INFO:tensorflow:Maybe overwriting load_pretrained: True
I1129 13:11:00.115684 46916307045888 config_util.py:488] Maybe overwriting load_pretrained: True
INFO:tensorflow:Ignoring config override key: load_pretrained
I1129 13:11:00.115762 46916307045888 config_util.py:498] Ignoring config override key: load_pretrained
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W1129 13:11:00.116141 46916307045888 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False
I1129 13:11:00.116248 46916307045888 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False
INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_task_id': 0, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac11329438>, '_experimental_distribute': None, '_is_chief': True, '_session_creation_timeout_secs': 7200, '_device_fn': None, '_tf_random_seed': None, '_task_type': 'worker', '_save_checkpoints_steps': None, '_train_distribute': None, '_num_worker_replicas': 1, '_model_dir': '/home/francesco.argentieri/ProjectThesis/models/ssd_mobilenet_v2_coco_2018_03_29', '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_master': '', '_experimental_max_worker_delay_secs': None, '_protocol': None, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_eval_distribute': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
}
I1129 13:11:00.116693 46916307045888 estimator.py:212] Using config: {'_keep_checkpoint_max': 5, '_task_id': 0, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac11329438>, '_experimental_distribute': None, '_is_chief': True, '_session_creation_timeout_secs': 7200, '_device_fn': None, '_tf_random_seed': None, '_task_type': 'worker', '_save_checkpoints_steps': None, '_train_distribute': None, '_num_worker_replicas': 1, '_model_dir': '/home/francesco.argentieri/ProjectThesis/models/ssd_mobilenet_v2_coco_2018_03_29', '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_master': '', '_experimental_max_worker_delay_secs': None, '_protocol': None, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_eval_distribute': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x2aac11338598>) includes params argument, but params are not passed to Estimator.
W1129 13:11:00.116895 46916307045888 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x2aac11338598>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Not using Distribute Coordinator.
I1129 13:11:00.117480 46916307045888 estimator_training.py:186] Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
I1129 13:11:00.117681 46916307045888 training.py:612] Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
I1129 13:11:00.117958 46916307045888 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1129 13:11:00.123463 46916307045888 deprecation.py:323] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

W1129 13:11:00.134167 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.

W1129 13:11:00.134382 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

W1129 13:11:00.156062 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W1129 13:11:00.157456 46916307045888 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
W1129 13:11:00.163085 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W1129 13:11:00.163222 46916307045888 deprecation.py:323] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W1129 13:11:00.186017 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.

W1129 13:11:01.717208 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.

WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.

W1129 13:11:10.354478 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W1129 13:11:10.452341 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W1129 13:11:13.191320 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W1129 13:11:17.294937 46916307045888 api.py:332] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

W1129 13:11:21.228440 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

W1129 13:11:21.229693 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W1129 13:11:21.742646 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.

W1129 13:11:23.752529 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
W1129 13:11:24.356604 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
INFO:tensorflow:Calling model_fn.
I1129 13:11:24.371528 46916307045888 estimator.py:1148] Calling model_fn.
WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1129 13:11:24.739926 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W1129 13:11:24.742907 46916307045888 deprecation.py:323] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.

W1129 13:11:27.975720 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.

INFO:tensorflow:depth of additional conv before box predictor: 0
I1129 13:11:27.987807 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I1129 13:11:28.023709 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I1129 13:11:28.059213 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I1129 13:11:28.095044 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I1129 13:11:28.130629 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I1129 13:11:28.166254 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W1129 13:11:28.207245 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.

W1129 13:11:28.208312 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

W1129 13:11:28.217204 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.

W1129 13:11:29.469171 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W1129 13:11:33.735143 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.

W1129 13:11:33.741652 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.

W1129 13:11:33.742920 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W1129 13:11:34.359708 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W1129 13:11:34.362771 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

W1129 13:11:34.363040 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W1129 13:11:34.372650 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1129 13:11:34.372868 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W1129 13:11:36.890684 46916307045888 deprecation.py:506] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W1129 13:11:43.759206 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

W1129 13:11:44.819307 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

WARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.

W1129 13:11:44.819580 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.

INFO:tensorflow:Done calling model_fn.
I1129 13:11:44.820056 46916307045888 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1129 13:11:44.821458 46916307045888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1129 13:11:50.663527 46916307045888 monitored_session.py:240] Graph was finalized.
INFO:tensorflow:Running local_init_op.
I1129 13:11:57.670931 46916307045888 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1129 13:11:58.240870 46916307045888 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /home/francesco.argentieri/ProjectThesis/models/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.
I1129 13:12:13.180183 46916307045888 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /home/francesco.argentieri/ProjectThesis/models/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.
Traceback (most recent call last):
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node FeatureExtractor/MobilenetV2/Conv/Conv2D}}]]
	 [[total_loss/_9637]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node FeatureExtractor/MobilenetV2/Conv/Conv2D}}]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py"", line 109, in <module>
    tf.app.run()
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py"", line 613, in run
    return self.run_local()
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1161, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1195, in _train_model_default
    saving_listeners)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1494, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run
    run_metadata=run_metadata)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run
    raise six.reraise(*original_exc_info)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run
    return self._sess.run(*args, **kwargs)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run
    run_metadata=run_metadata)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run
    return self._sess.run(*args, **kwargs)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
	 [[total_loss/_9637]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
0 successful operations.
0 derived errors ignored.

Original stack trace for 'FeatureExtractor/MobilenetV2/Conv/Conv2D':
  File ""home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py"", line 109, in <module>
    tf.app.run()
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py"", line 613, in run
    return self.run_local()
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1161, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1191, in _train_model_default
    features, labels, ModeKeys.TRAIN, self.config)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1149, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py"", line 308, in model_fn
    features[fields.InputDataFields.true_image_shape])
  File ""home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 600, in predict
    preprocessed_inputs)
  File ""home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/models/ssd_mobilenet_v2_feature_extractor.py"", line 132, in extract_features
    scope=scope)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet_v2.py"", line 210, in mobilenet_base
    base_only=True, **kwargs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet_v2.py"", line 184, in mobilenet
    **kwargs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet.py"", line 366, in mobilenet
    net, end_points = mobilenet_base(inputs, scope=scope, **mobilenet_args)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet.py"", line 285, in mobilenet_base
    net = opdef.op(net, **params)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py"", line 1159, in convolution2d
    conv_dims=2)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py"", line 1057, in convolution
    outputs = layer.apply(inputs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1700, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 854, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper
    return converted_call(f, options, args, kwargs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted
    return f(*args, **kwargs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call
    outputs = self._convolution_op(inputs, self.kernel)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__
    return self.conv_op(inp, filter)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__
    return self.call(inp, filter)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__
    name=self.name)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d
    name=name)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 794, in _apply_op_helper
    op_def=op_def)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py"", line 3357, in create_op
    attrs, op_def, compute_device)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py"", line 3426, in _create_op_internal
    op_def=op_def)
  File ""apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py"", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()
```
"
34704,Program aborted after use tf.io.gfile.makedirs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- TensorFlow installed from (source or binary): pip install tensorflow==1.14.0
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.8
```
LSB Version:	:core-4.1-amd64:core-4.1-noarch
Distributor ID:	CentOS
Description:	CentOS Linux release 7.6.1810 (Core) 
Release:	7.6.1810
Codename:	Core
```


**Describe the current behavior**
I follow this [link](https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/hadoop.md) to set up Hadoop environment 
After execute below snippet of code, my terminal aborted 

**Describe the expected behavior**
should create test directory in hdfs file system

**Code to reproduce the issue**
```
import tensorflow as tf
tf.io.gfile.makedirs(""hdfs://kevin0:8020/user/root/test"")
```

**Other info / logs**
```
FileSystem: loadFileSystems failed error:
(unable to get root cause for java.lang.NoClassDefFoundError)
(unable to get stack trace for java.lang.NoClassDefFoundError)
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00007f6be49c64f1, pid=61570, tid=0x00007f6ca07c0740
#
# JRE version: Java(TM) SE Runtime Environment (8.0_221-b11) (build 1.8.0_221-b11)
# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.221-b11 mixed mode linux-amd64 compressed oops)
# Problematic frame:
# C  [libhdfs.so+0xa4f1]
#
# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again
#
# An error report file with more information is saved as:
# /root/hs_err_pid61570.log
#
# If you would like to submit a bug report, please visit:
#   http://bugreport.java.com/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
```
"
34703,How to view CI build history of master branch,"Hi team,
How can I view the CI build history in ci systems internal to Google or in Jenkins ?
I did not find the url of the build history of tensorflow master branch.
Any ideas ? Thank you.

"
34702,Where do i get the better accurate model for image segmentation?,"Hi,I am using tensor flow lite for Image segmentation within my app.I am using the following gradle dependency for tensor flow lite""    implementation 'org.tensorflow:tensorflow-lite:0.0.0-gpu-experimental'"".With this implementation the accuracy of the resultant cutout is not up to the mark .How can i improve the accuracy of image with tensor flow lite?And is there any pre-trained model other than deeplab v3+ for tensor flow.Please Help
"
34701,"std::uniform_int_distribution<int8_t> is undefined in the C++17 standard, but TFLite violates this limitation.","As [the C++ reference](https://en.cppreference.com/w/cpp/numeric/random/uniform_int_distribution) mentioned, std::uniform_int_distribution<int8_t> is undefined in the C++17.
Therefore microsoft visual C++ 2017 will give the following build error when the code includes [benchmark_tflite_model.cc #L496]( https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc#L496).

In fact, the recent TFLite model benchmark couldn't build on windows as [my CI environment](https://dev.azure.com/mlops/tensorflow/_build/results?buildId=548&view=logs&j=e1e4dfe0-fc62-5ca1-9c02-b15972c8e9c4&t=9da95ac0-03a9-5448-4a9d-063bdd2c2605&l=1058) shows.

```sh
bazel build -c opt --verbose_failures //tensorflow/lite/tools/benchmark:benchmark_model
```

```
C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\VC\Tools\MSVC\14.16.27023\include\random(2401): error C2338: invalid template argument for uniform_int_distribution: N4659 29.6.1.1 [rand.req.genl]/1e requires one of short, int, long, long long, unsigned short, unsigned int, unsigned long, or unsigned long long
tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc(496): note: see reference to class template instantiation 'std::uniform_int_distribution<uint8_t>' being compiled
C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\VC\Tools\MSVC\14.16.27023\include\random(2401): error C2338: note: char, signed char, unsigned char, int8_t, and uint8_t are not allowed
```

Would you like to modify benchmark_tflite_model.cc?
"
34700,"std::uniform_int_distribution<int8_t> is undefined in the C++17 standard, but TFLite violates this limitation.","As [the C++ reference](https://en.cppreference.com/w/cpp/numeric/random/uniform_int_distribution) mentioned, std::uniform_int_distribution<int8_t> is undefined in the C++17.
Therefore microsoft visual C++ 2017 will give the following build error when the code includes [benchmark_tflite_model.cc #L496]( https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc#L496).

In fact, the recent TFLite model benchmark couldn't build on windows as [my CI environment](https://dev.azure.com/mlops/tensorflow/_build/results?buildId=548&view=logs&j=e1e4dfe0-fc62-5ca1-9c02-b15972c8e9c4&t=9da95ac0-03a9-5448-4a9d-063bdd2c2605&l=1058) shows.

```sh
bazel build -c opt --verbose_failures //tensorflow/lite/tools/benchmark:benchmark_model
```

```
C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\VC\Tools\MSVC\14.16.27023\include\random(2401): error C2338: invalid template argument for uniform_int_distribution: N4659 29.6.1.1 [rand.req.genl]/1e requires one of short, int, long, long long, unsigned short, unsigned int, unsigned long, or unsigned long long
tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc(496): note: see reference to class template instantiation 'std::uniform_int_distribution<uint8_t>' being compiled
C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\VC\Tools\MSVC\14.16.27023\include\random(2401): error C2338: note: char, signed char, unsigned char, int8_t, and uint8_t are not allowed
```

Would you like to modify benchmark_tflite_model.cc?
"
34699,Dear Team after training model evaluation precision is nan for lots of catedories and some of having 0 how could i solve it because i am using faster rcnn resnet 101 model,Dear Team after training model evaluation precision is nan for lots of catedories and some of having 0 how could i solve it because i am using faster rcnn resnet 101 model
34698,toco_from_protos: not found - breaking,"Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18 LTS
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
Python version: 3.6

**Command used to run the converter or code if you’re using the Python API**
```
    # Read the saved model from disk. Assumes it is downloaded.
    converter = tf.lite.TFLiteConverter.from_saved_model(model_out)
    lite_model = converter.convert()

    # Format model file paths to store the file in the right directory:
    lite_name = model_name + '.tflite'
    out_path = model_out + '/' + lite_name

    # Write the converted model to disk:
    open(out_path, ""wb"").write(lite_model)
```


```
Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""/home/[]/[]/[]/v1/[]/models/main.py"", line 124, in convert_lite
    lite_model = converter.convert()
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 446, in convert
    **converter_kwargs)
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
/bin/sh: 1: toco_from_protos: not found
```

This happens, even after adding my python bin from the virtualenv to my $PATH variable.

It seems that the path to toco is hardcoded and therefore Tensorflow will never look for it anywhere else?

It's now not possible to use the converter in a Python virtualenv ( the recommended way to use Tensorflow )

Note that when activating the virtualenv from the commandline, the toco and toco_from_protos commands do work. It is only when running the Python program with Tensorflow that Tensorflow is not able to find toco_from_protos.
"
34697,Keras model pickle-able but tf.keras model not pickle-able,"**System information**
- Windows 10 
- Tensorflow 2.0 (CPU)
- joblib 0.14.0
- Python 3.7.5
- Keras 2.3.1

Hello everybody! This is my first post so please forgive me if I have missed something. So I'm trying to use a genetic algorithm to train and evaluate multiple NN architectures so I need to parallelize them on a multi-core CPU. Therefore I have used joblib to try to parallelize this. However, I was stuck on my tf.keras code because it wasn't pickleable. After many hours of debugging I finally realised that the tf.keras models are not pickleable whereas keras models are.

**Describe the current behavior**
The code below works but if you replaced keras with tf.keras, there will be an error:
**Could not pickle the task to send it to the workers.**

**Describe the expected behavior**
Moving forward, tf.keras should be replacing keras and therefore tf.keras should also be pickleable.

**Code to reproduce the issue**
```
#The following is a simple code to illustrate the problem:
from joblib import Parallel, delayed
import keras
import tensorflow as tf

def test():
    model = keras.models.Sequential()
    return

Parallel(n_jobs=8)(delayed(test)(i) for i in range(10)) #this works as intended

def test_tf():
    model = tf.keras.models.Sequential()
    return

Parallel(n_jobs=8)(delayed(test_tf)(i) for i in range(10)) #this will spit out the error above
```

**Other comments**
I guess a quick fix would just be to replace all the existing code with tf.keras to just keras but seeing as keras support will be discontinued and absorbed by Tensorflow 2.0, I think this should be fixed.
"
34696,Attention of the value_embeddings inputs,"This [line](https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/keras/layers/dense_attention.py#L241) and this [one](https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/keras/layers/dense_attention.py#L368) should be:
```
value_embeddings = token_embedding(value_input)
```
"
34695,Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR,"I have TF 2.0 on Ubuntu 18.04 LTS.
My GPU is the Nvidia RTX 2070 with driver 440.33.01.
When I train a model everything is fine and it works correctly.
But after the model is saved as .h5 file and I load it back, I cannot predict anything and I got this log:

```
`Using TensorFlow backend.
2019-11-29 00:59:27.178674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-29 00:59:27.220014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-29 00:59:27.220381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2019-11-29 00:59:27.222887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-29 00:59:27.259558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-29 00:59:27.278651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-29 00:59:27.284736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-29 00:59:27.330947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-29 00:59:27.359948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-29 00:59:27.426684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-29 00:59:27.426784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-29 00:59:27.427108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-29 00:59:27.427373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-29 00:59:27.427889: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-29 00:59:27.457927: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-11-29 00:59:27.460601: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5169da0 executing computations on platform Host. Devices:
2019-11-29 00:59:27.460654: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-29 00:59:27.567015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-29 00:59:27.567342: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x51fc6f0 executing computations on platform CUDA. Devices:
2019-11-29 00:59:27.567353: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5
2019-11-29 00:59:27.567459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-29 00:59:27.567704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2019-11-29 00:59:27.567727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-29 00:59:27.567735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-29 00:59:27.567743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-29 00:59:27.567749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-29 00:59:27.567756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-29 00:59:27.567763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-29 00:59:27.567770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-29 00:59:27.567801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-29 00:59:27.568059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-29 00:59:27.568291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-29 00:59:27.568720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-29 00:59:27.569778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-29 00:59:27.569787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-29 00:59:27.569790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-29 00:59:27.570517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-29 00:59:27.570901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-29 00:59:27.571160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7225 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-11-29 00:59:30.035047: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-29 00:59:30.389311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-29 00:59:31.306557: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-11-29 00:59:31.307242: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-11-29 00:59:31.307791: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node conv2d_1/convolution}}]]`

```

On Windows 10 it works correctly with the same loaded model. I tried also to downgrade TF to v. 1.14 but nothing changed.
I installed cuda with aptitude. The strange thing is that I can train a model but not load it.
This is my test code for load and test a model:



```
from keras.models import load_model

import cv2
from PIL import Image
from io import BytesIO
import numpy as np
import tensorflow as tf

modelN = load_model('../model/nvidiaModel.h5')
with open(""../data/images/1574517989418963.jpg"", ""rb"") as f:
    data = f.read()


def image_preprocess(image):
    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)
    image = cv2.GaussianBlur(image, (3, 3), 0)
    image = cv2.resize(image, (200, 66))  # Image input size of the Nvidia model architecture
    image = (image / 127.5) - 1

    return image


image = Image.open(BytesIO(bytearray(data)))
image = np.asarray(image)
image = image_preprocess(image)
image = np.array([image])
steering_angle = str(modelN.predict_classes(image))
print(steering_angle)
```"
34694,API Documentation - Incorrect formatting for tanh activation function,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh

## Description of issue (what needs changing):

The arguments section of the tanh activation documentation is not formatted correctly.

I am uncertain as to why, but suspect it may be due to a lack of a newline after the example block ([code here](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/activations.py#L201-L221))
"
34693,Size and CombinedNMS Op support request for tflite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): 2.0.0

Like in the issue https://github.com/tensorflow/tensorflow/issues/33059 i want to be able to convert my model to TFLite and I have tried changing to: tf.image.non_max_suppression_padded and tf.image.non_max_suppression_with_scores but with both I still get errors

**Provide the text output from tflite_convert**

```
2019-11-28 19:01:40.384887: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2019-11-28 19:01:40.385067: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-28 19:01:40.408717: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-28 19:01:40.408744: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 481 nodes (0), 688 edges (0), time = 4.814ms.
2019-11-28 19:01:40.408760: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 481 nodes (0), 688 edges (0), time = 5.216ms.
2019-11-28 19:01:40.408769: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: Tiny_YOLOv3_inference_non_max_suppression_map_while_body_3226
2019-11-28 19:01:40.408775: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2019-11-28 19:01:40.408781: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-28 19:01:40.408788: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: Tiny_YOLOv3_inference_non_max_suppression_map_while_cond_3225
2019-11-28 19:01:40.408794: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2019-11-28 19:01:40.408802: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-28 19:01:41.252079: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2019-11-28 19:01:41.252177: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-28 19:01:41.456787: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-28 19:01:41.456818: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 359 nodes (-58), 584 edges (-58), time = 111.647ms.
2019-11-28 19:01:41.456824: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 359 nodes (0), 584 edges (0), time = 26.561ms.
2019-11-28 19:01:41.456829: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: Tiny_YOLOv3_inference_non_max_suppression_map_while_body_3226_frozen
2019-11-28 19:01:41.456833: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 52 nodes (0), 55 edges (0), time = 1.265ms.
2019-11-28 19:01:41.456838: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 52 nodes (0), 55 edges (0), time = 1.103ms.
2019-11-28 19:01:41.456842: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: Tiny_YOLOv3_inference_non_max_suppression_map_while_cond_3225_frozen
2019-11-28 19:01:41.456846: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 14 nodes (0), 8 edges (0), time = 0.617ms.
2019-11-28 19:01:41.456850: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 14 nodes (0), 8 edges (0), time = 0.394ms.
Traceback (most recent call last):
  File ""/home/brechard/miniconda3/envs/modeling/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-7-c548bab089a8>"", line 1, in <module>
    tflite_model = converter.convert()
  File ""/home/brechard/miniconda3/envs/modeling/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py"", line 446, in convert
    **converter_kwargs)
  File ""/home/brechard/miniconda3/envs/modeling/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/home/brechard/miniconda3/envs/modeling/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2019-11-28 19:01:43.495379: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-28 19:01:43.517231: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2712000000 Hz
2019-11-28 19:01:43.518000: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d1e210d680 executing computations on platform Host. Devices:
2019-11-28 19:01:43.518031: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-28 19:01:43.520442: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2019-11-28 19:01:43.520471: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-28 19:01:43.520503: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nl1lxl-107914): /proc/driver/nvidia/version does not exist
2019-11-28 19:01:43.549801: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2019-11-28 19:01:43.549850: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2019-11-28 19:01:43.550020: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2019-11-28 19:01:43.550039: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2019-11-28 19:01:43.550121: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2019-11-28 19:01:43.550139: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550183: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2019-11-28 19:01:43.550193: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550205: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2019-11-28 19:01:43.550212: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550219: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2019-11-28 19:01:43.550225: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550232: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2019-11-28 19:01:43.550240: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550253: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2019-11-28 19:01:43.550270: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550275: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550279: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550283: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550287: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-28 19:01:43.550299: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2019-11-28 19:01:43.550308: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2019-11-28 19:01:43.550317: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2019-11-28 19:01:43.554013: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 226 operators, 430 arrays (0 quantized)
2019-11-28 19:01:43.557143: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 226 operators, 430 arrays (0 quantized)
2019-11-28 19:01:43.648439: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 111 operators, 212 arrays (0 quantized)
2019-11-28 19:01:43.650428: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 111 operators, 212 arrays (0 quantized)
2019-11-28 19:01:43.652457: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 111 operators, 212 arrays (0 quantized)
2019-11-28 19:01:43.653866: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 111 operators, 212 arrays (0 quantized)
2019-11-28 19:01:43.655915: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 22151168 bytes, theoretical optimal value: 22151168 bytes.
2019-11-28 19:01:43.656807: E tensorflow/lite/toco/toco_tooling.cc:466] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MAX_POOL_2D, MUL, PACK, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: Size, TensorListFromTensor, TensorListReserve, TensorListStack, While.
Traceback (most recent call last):
  File ""/home/brechard/miniconda3/envs/modeling/bin/toco_from_protos"", line 10, in <module>
    sys.exit(main())
  File ""/home/brechard/miniconda3/envs/modeling/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/brechard/miniconda3/envs/modeling/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/brechard/miniconda3/envs/modeling/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/brechard/miniconda3/envs/modeling/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/brechard/miniconda3/envs/modeling/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MAX_POOL_2D, MUL, PACK, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: Size, TensorListFromTensor, TensorListReserve, TensorListStack, While.
```

If it helps, the function that I am trying to modify can be found in: 
https://github.com/Brechard/computer-vision-tf2/blob/master/src/models/detection/yolov3.py#L240

my modification right now looks like this:

```
    def non_max_suppression(self, outputs):

        bboxes, confidence, class_prob = [], [], []
        for o in outputs:
            bboxes.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))
            confidence.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))
            class_prob.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))

        bbox = tf.concat(bboxes, axis=1)
        confidence = tf.concat(confidence, axis=1)
        class_probs = tf.concat(class_prob, axis=1)

        scores = confidence * class_probs

        # Process for each image of the batch
        def _nms_single_image(args):
            image_bbox, image_scores = args[0], args[1]
            classes = tf.math.argmax(image_scores, axis=1)
            new_img_scores = tf.math.reduce_max(image_scores, axis=1)

            selected_items, selected_scores = tf.image.non_max_suppression_with_scores(
                boxes=tf.reshape(image_bbox, (-1, 4)),
                scores=new_img_scores,
                max_output_size=100,
                iou_threshold=self.iou_threshold,
                score_threshold=self.score_threshold
            )

            return [tf.gather(image_bbox, selected_items), tf.gather(new_img_scores, selected_items),
                    tf.gather(classes, selected_items)]

        bboxes, scores, classes = tf.map_fn(_nms_single_image, elems=[bbox, scores],
                                            dtype=[tf.float32, tf.float32, tf.int64])

        return bboxes, scores, classes
```
"
34691,keras Model with a dictionary as output: compile and fit expect layers names instead of the output dictionary's keys,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- TensorFlow installed from (source or binary): pip install tensorflow==2.0.0-beta1
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

**Describe the current behavior**

Using the functional Keras API, I build a model which has multiple outputs that are in a dictionary:
```
def make_model():
    inp = tf.keras.Input(1)
    y = tf.keras.layers.Dense(1)(inp)
    y_times_2 = tf.math.multiply(2., y)
    model = tf.keras.Model(inputs=inp, outputs={'y':y, 'y_times_2':y_times_2})
    return model
```
When compiling the model, I want to pass as the `loss` argument the following dictionary:
`{'y':'mean_squared_error', 'y_times_2':'mean_squared_error'}` 
and as the `metrics` argument the following dictionary:
`{'y':'mean_absolute_error', 'y_times_2':'mean_absolute_error'}`
as it is both intuitive and suggested [by the documentation of `compile`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#compile) (see what is written for the `metrics` argument).
Similarly, for training the model, I want to pass as the `y` argument of `fit` the following dictionary:
`{'y':y, 'y_times_2':2*y}`.

It turns out that none of this works and using any of those dictionaries throws an error, because, strangely, the API does not expect `'y'` and `'y_times2'` as keys, whereas those are the keys of the output of the model, but it expects the name of the layers producing the outputs! For the `y` output, the layer producing it is the `Dense` layer defined in the model. For `y_times2` the layer producing it is an instance of `TensorFlowOpLayer` produced by the call of `tf.math.multiply` in the model definition. So, for example, the correct dictionary to use as the `loss` argument of `compile` is:
`{'dense':'mean_squared_error', 'tf_op_layer_Mul':'mean_squared_error'}`

Note that given that `TensorFlowOpLayer` layers are named automatically (even if I use the `name` argument of `tf.math.multiply`, because the name of the `TensorFlowOpLayer` layer is not the same as the name of the op), it can be really difficult to know the proper names to pass to `compile` and `fit` in a more complex example.

**Describe the expected behavior**

The expected behaviour should be as described in [the documentation of `compile`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#compile) and should use the output names.

**Code to reproduce the issue**

```
import tensorflow as tf
import numpy as np

print('Using Tensorflow version {} (git version {})'.format(tf.version.VERSION, tf.version.GIT_VERSION))

x = np.random.normal(size=(64,))
y = x

def make_model():
    inp = tf.keras.Input(1)
    y = tf.keras.layers.Dense(1)(inp)
    y_times_2 = tf.math.multiply(2., y)
    model = tf.keras.Model(inputs=inp, outputs={'y':y, 'y_times_2':y_times_2})
    return model

model = make_model()

model.summary()

try:
    print('Trying compilation with the output names')
    model.compile(optimizer=tf.keras.optimizers.Adam(0.1), 
                  loss={'y':'mean_squared_error', 'y_times_2':'mean_squared_error'})
except Exception as e:
    print('The compilation failed with the following message error:')
    print(e)
    print('Trying compilation with the layers names')
    model.compile(optimizer=tf.keras.optimizers.Adam(0.1),
                  loss={'dense':'mean_squared_error', 'tf_op_layer_Mul':'mean_squared_error'})
    
try:
    print('\nTrying training with the output names')
    model.fit(x, {'y':y, 'y_times_2':2*y}, epochs=2)
except Exception as e:
    print('The training failed with the following message error:')
    print(e)
    print('Trying training with the layers names')
    model.fit(x, {'dense':y, 'tf_op_layer_Mul':2*y}, epochs=2)
    
print('\n###################\nAdd metrics to the example:')

model = make_model()

model.summary()

try:
    print('Trying compilation with the output names')
    model.compile(optimizer=tf.keras.optimizers.Adam(0.1), 
                  loss={'dense_1':'mean_squared_error', 'tf_op_layer_Mul_1':'mean_squared_error'},
                  metrics={'y':'mean_absolute_error', 'y_times_2':'mean_absolute_error'})
except Exception as e:
    print('The compilation failed with the following message error:')
    print(e)
    print('Trying compilation with the layers names')
    model.compile(optimizer=tf.keras.optimizers.Adam(0.1),
                  loss={'dense_1':'mean_squared_error', 'tf_op_layer_Mul_1':'mean_squared_error'},
                  metrics={'dense_1':'mean_absolute_error', 'tf_op_layer_Mul_1':'mean_absolute_error'})

model.fit(x, {'dense_1':y, 'tf_op_layer_Mul_1':2*y}, epochs=2)
```

with the following output:
```
Using Tensorflow version 2.0.0 (git version v2.0.0-rc2-26-g64c3d382ca)
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2         
_________________________________________________________________
tf_op_layer_Mul (TensorFlowO [(None, 1)]               0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
Trying compilation with the output names
The compilation failed with the following message error:
Unknown entries in loss dictionary: ['y', 'y_times_2']. Only expected following keys: ['dense', 'tf_op_layer_Mul']
Trying compilation with the layers names

Trying training with the output names
The training failed with the following message error:
No data provided for ""dense"". Need data for each key in: ['dense', 'tf_op_layer_Mul']
Trying training with the layers names
Train on 64 samples
Epoch 1/2
64/64 [==============================] - 1s 9ms/sample - loss: 10.1650 - dense_loss: 2.0330 - tf_op_layer_Mul_loss: 8.1320
Epoch 2/2
64/64 [==============================] - 0s 62us/sample - loss: 7.1354 - dense_loss: 1.4271 - tf_op_layer_Mul_loss: 5.7084

###################
Add metrics to the example:
Model: ""model_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 2         
_________________________________________________________________
tf_op_layer_Mul_1 (TensorFlo [(None, 1)]               0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
Trying compilation with the output names
The compilation failed with the following message error:
Unknown entries in metrics dictionary: ['y', 'y_times_2']. Only expected following keys: ['dense_1', 'tf_op_layer_Mul_1']
Trying compilation with the layers names
Train on 64 samples
Epoch 1/2
64/64 [==============================] - 0s 5ms/sample - loss: 1.4019 - dense_1_loss: 0.2804 - tf_op_layer_Mul_1_loss: 1.1215 - dense_1_mean_absolute_error: 0.4108 - tf_op_layer_Mul_1_mean_absolute_error: 0.8217
Epoch 2/2
64/64 [==============================] - 0s 71us/sample - loss: 0.4672 - dense_1_loss: 0.0934 - tf_op_layer_Mul_1_loss: 0.3737 - dense_1_mean_absolute_error: 0.2408 - tf_op_layer_Mul_1_mean_absolute_error: 0.4816
```"
34690,Using clip_by_value anywhere in the model graph (including in a metric) produces a model which cannot be saved as h5.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 and Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0
- Python version: 3.7.4 and 3.6.8


**Describe the current behavior**

Using a custom metric function which employs tf.clip_by_value, then adding it to the model by model.add_loss, and attempting to save it using model.save results in a ValueError exception saying ""Unable to create group (name already exists) - full trace provided at the end.

Playing around with this model, the custom metric is irrelevant, it also happens with this:

```python
from tensorflow.keras import Model, layers
import tensorflow as tf

x = layers.Input((10, 10, 1))
t = tf.clip_by_value(x, 0, 1)
pred = layers.Dense(8, activation='relu')(t)
model = Model(inputs=x, outputs=pred)
model.compile(loss='binary_crossentropy', optimizer='adam')
model.save('bla.h5')
```


**Describe the expected behavior**
I would expect the model to get saved without an issue.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
from tensorflow.keras import Model, layers
import tensorflow as tf

x = layers.Input((10, 10, 1))
pred = layers.Dense(8, activation='relu')(x)
model = Model(inputs=x, outputs=pred)

def custom_metric(y_pred):
    y_pred = tf.clip_by_value(y_pred, 0, 1)
    return tf.reduce_mean(y_pred)

model.add_metric(custom_metric(pred), name='val_custom', aggregation='mean')

model.compile(loss='binary_crossentropy', optimizer='adam')
model.save('bla.h5')
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```python
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-6-11f183ffac31> in <module>
----> 1 model.save('bla.h5')

~/projects/tensorflow/env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
    973     """"""
    974     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,
--> 975                       signatures, options)
    976 
    977   def save_weights(self, filepath, overwrite=True, save_format=None):

~/projects/tensorflow/env/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    110           'or using `save_weights`.')
    111     hdf5_format.save_model_to_hdf5(
--> 112         model, filepath, overwrite, include_optimizer)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,

~/projects/tensorflow/env/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)
    107     model_weights_group = f.create_group('model_weights')
    108     model_layers = model.layers
--> 109     save_weights_to_hdf5_group(model_weights_group, model_layers)
    110 
    111     # TODO(b/128683857): Add integration tests between tf.keras and external

~/projects/tensorflow/env/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py in save_weights_to_hdf5_group(f, layers)
    623 
    624   for layer in layers:
--> 625     g = f.create_group(layer.name)
    626     weights = _legacy_weights(layer)
    627     weight_values = K.batch_get_value(weights)

~/projects/tensorflow/env/lib/python3.6/site-packages/h5py/_hl/group.py in create_group(self, name, track_order)
     66             name, lcpl = self._e(name, lcpl=True)
     67             gcpl = Group._gcpl_crt_order if track_order else None
---> 68             gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
     69             return Group(gid)
     70 

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/h5g.pyx in h5py.h5g.create()

ValueError: Unable to create group (name already exists)
```

"
34689,Keras scikit-learn wrapper not compatible with keras functional model,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- TensorFlow version (use command below): TF version: 2.0, 1.15
- Python version: 3.6 , 3.7

**Describe the current behavior**
when using a keras functional api model via the keras scikit-learn wrapper a crash occurs.
see: 
https://github.com/tensorflow/tensorflow/blob/13f2db1e7071ae109d2f51c7202867a154f587d2/tensorflow/python/keras/wrappers/scikit_learn.py#L241
**Describe the expected behavior**
model.predict() should work on all keras model types besides sequential 

**Code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf
import tensorflow.keras
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier

def build_model():
  input = tf.keras.layers.Input(shape=(2,))
  pred = tf.keras.layers.Dense(2, activation='softmax')(input)
  model = tf.keras.models.Model(inputs=input, outputs=pred)
  model.compile(loss='categorical_crossentropy', metrics=['accuracy'])
  return model

X = np.array([[1,2],[3,1]])
Y = np.array([[1,0], [0,1]])
model = build_model()
model.fit(X, Y)
print(model.predict(X))  # this works

model_wrapped = KerasClassifier(build_model)
model_wrapped.fit(X, Y)
model_wrapped.predict(X)  # this crashes
```
Output: 
Train on 2 samples
2/2 [==============================] - 0s 62ms/sample - loss: 1.1024 - acc: 0.5000
[[0.62487346 0.37512657]
 [0.8205698  0.17943017]]
Train on 2 samples
2/2 [==============================] - 0s 64ms/sample - loss: 0.2733 - acc: 1.0000
```python
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-14-48bacae97b80> in <module>()
     19 model_wrapped = KerasClassifier(build_model)
     20 model_wrapped.fit(X, Y)
---> 21 model_wrapped.predict(X)  # this crashes
     22 
     23 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/wrappers/scikit_learn.py in predict(self, x, **kwargs)
    239     """"""
    240     kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)
--> 241     classes = self.model.predict_classes(x, **kwargs)
    242     return self.classes_[classes]
    243 

AttributeError: 'Model' object has no attribute 'predict_classes'
```"
34688,Failed to load nodes from frozen graph file(.pb),"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS High Sierra 10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Python binary(pip install tensorflow==1.7.0)
- TensorFlow version (use command below): 1.7.0
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.10.0(never used bazel)
- GCC/Compiler version (if compiling from source): Apple LLVM version 10.0.0 (clang-1000.11.45.5)
- CUDA/cuDNN version: Not used CUDA/cuDNN
- GPU model and memory: Not used GPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When I tried to load frozen graph(.pb) as graph_def, I couldn't get success to run [import_graph_def](https://github.com/tensorflow/tensorflow/blob/9156fcc7a8a901ca9e553297da8237a313255bd8/tensorflow/python/framework/importer.py#L402).
I received a ValueError: **ValueError: graph_def is invalid at node 'inpaint_net/conv1/kernel/Assign': Input tensor 'inpaint_net/conv1/kernel:0' Cannot convert a tensor of type float32 to an input of type float32_ref.**
I found similar issues from #3628 and #24062, but I can not resolve with @barbolo's suggested [code](https://github.com/tensorflow/tensorflow/issues/3628#issuecomment-272147744).

**Describe the expected behavior**
It should load gragh_def object by using [tf.import_graph_def](https://github.com/tensorflow/tensorflow/blob/9156fcc7a8a901ca9e553297da8237a313255bd8/tensorflow/python/framework/importer.py#L402) function.

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow.python.platform import gfile
input = 'model/snapmodel-160000.pb'
with tf.Session() as sess:
    print(""load graph"")
    with gfile.FastGFile(input,'rb') as f:
       graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    f = open(node_file, 'a')
    # fix nodes
    for node in graph_def.node:
        if node.op == 'RefSwitch':
            node.op = 'Switch'
            for index in range(len(node.input)):
                node.input[index] = node.input[index] + '/read'
        elif node.op == 'AssignSub':
            node.op = 'Sub'
            if 'use_locking' in node.attr: del node.attr['use_locking']
        elif node.op == 'AssignAdd':
            node.op = 'Add'
            if 'use_locking' in node.attr: del node.attr['use_locking']
        elif node.op == 'Assign':
            if 'use_locking' in node.attr: del node.attr['use_locking']

    with sess.graph.as_default() as tf_graph:
        tf.import_graph_def(graph_def, name='')
```

**Other info / logs**
There is full log:
```
/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
2019-11-28 05:03:22.022135: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
load graph
Traceback (most recent call last):
  File ""/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 667, in import_graph_def
    op._add_input(source_tensor, dtype=input_type)
  File ""/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1898, in _add_input
    (tensor.dtype.name, dtype.name))
TypeError: Cannot convert a tensor of type float32 to an input of type float32_ref

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py"", line 1664, in <module>
    main()
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/Volumes/Work/2019_Work/Inpainting/tensorflow-onnx/convert.py"", line 68, in <module>
    tf.import_graph_def(graph_def, name='')
  File ""/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 671, in import_graph_def
    node, 'Input tensor %r %s' % (input_name, te)))
ValueError: graph_def is invalid at node 'inpaint_net/conv1/kernel/Assign': Input tensor 'inpaint_net/conv1/kernel:0' Cannot convert a tensor of type float32 to an input of type float32_ref.
```

Please give me a help for resolving this issue asap.
Thank you"
34687,Wrong inputs shape for 1D-inputs in keras with run_eagerly=True,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): default v2 for Colab
- TensorFlow version (use command below): v2.0.0-0-g64c3d382ca 2.0.0
- Python version: default for Colab
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: Colab
- GPU model and memory: Colab

**Describe the current behavior**
When compiling keras model with run_eagerly=True and passing 1D-inputs, model reshapes it into 2D.
When compiling with run_eagerly=False everything works as expected: layer obtains 1D-input.

**Describe the expected behavior**
Model should not corrupt inputs shape.

**Code to reproduce the issue**
https://colab.research.google.com/drive/1LHtQRE1CnjkZCOqGe-O7VbBKHWSTCtJS
"
34686,tf.cast with division impose different influence on python2 v.s. python3,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.12.0
- Python version: 3.6.5, 2.7.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v1.12.0-rc2-3-ga6d8ffae09 1.12.0

**Describe the current behavior**
When I run a tf.cast() including a division('/'), the change of random seed is different on python2 and python3
For example, if I run the following code
```
import tensorflow as tf
tf.set_random_seed(1)

with tf.Session() as sess:
    print('tf random_normal:{}'.format(sess.run(tf.random_normal([1, 2]))))
a = tf.cast(tf.constant(1)/tf.constant(2), tf.float32)
with tf.Session() as sess:
    print('tf random_normal:{}'.format(sess.run(tf.random_normal([1, 2]))))
```
I get following result on python2.7.10
```
tf random_normal:[[-0.67086124  0.22357143]]
tf random_normal:[[-0.3143593  0.6476281]]
```
But I get following result on python3.6.5
```
tf random_normal:[[-0.67086124  0.22357143]]
tf random_normal:[[-0.21253194  0.47261432]]
```
At first, py2 and py3 create the same random_normal. But after run the tf.cast, they get different result.

**Describe the expected behavior**
The tf.random_normal() of py2 and py3 with same seed should get the same result.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import tensorflow as tf
tf.set_random_seed(1)

with tf.Session() as sess:
    print('tf random_normal:{}'.format(sess.run(tf.random_normal([1, 2]))))
a = tf.cast(tf.constant(1)/tf.constant(2), tf.float32)
with tf.Session() as sess:
    print('tf random_normal:{}'.format(sess.run(tf.random_normal([1, 2]))))
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34683,TensorArray objects improperly handled as tf.function arguments or return values,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Ubuntu 16.04
- TensorFlow installed from (source or binary): tensorflow-gpu from binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6.7
- CUDA/cuDNN version: CUDA 10.0, cuDNN 7.6.0.64
- GPU model and memory: GeForce GTX  1080

**Describe the current behavior**
When you return a created TensorArray from a function decorated with tf.function, the returned object is an empty Tensor with an illegal state:
  object type is **tf.Tensor(<unprintable>, shape=(), dtype=variant)**

This object cannot be used and will throw an exception when attempting to use it.
See also attached image for more details.

Example of the exception, when calling concat method:
AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'concat'


**Describe the expected behavior**
The returned object should be a legal TensorArray instance, as is the case when you use only Eager mode functions.
In this case the object type is **<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f73b0386208>**

The code works fine if all functions are in Eager mode (see code example).
The code works fine if you concat the TensorArray before returning it (see code example).

**Code to reproduce the issue**
```
@tf.function
def accumulate_no_error_graph(d):
    arr = tf.TensorArray(tf.float32, num_rows)

    for i in range(num_rows):
        arr = arr.write(i, d[i])

    return arr.concat()

def accumulate_no_error_eager(d):
    arr = tf.TensorArray(tf.float32, num_rows)

    for i in range(num_rows):
        arr = arr.write(i, d[i])

    return arr

@tf.function
def accumulate_error_graph(d):
    arr = tf.TensorArray(tf.float32, num_rows)

    for i in range(num_rows):
        arr = arr.write(i, d[i])

    return arr

num_rows = 10
a = tf.random.uniform([num_rows, 2])

# Works well
data = accumulate_no_error_eager(a)
print(f'From eager: {data}')

data = accumulate_no_error_graph(a)
print(f'From Graph with concat: {data}')

# Doesn't work!
data = accumulate_error_graph(a)
print(f'From Graph no concat: {data}')
```

**Other info / logs**
Output of the code:
```
From eager: <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7ff67c5ac470>
From Graph with concat: [0.6765479  0.28778458 0.85561883 0.41792393 0.667024   0.35702074
 0.33666503 0.6575141  0.05998921 0.06930244 0.05852807 0.65689635
 0.4156996  0.39695132 0.78036475 0.79794145 0.96339357 0.49462914
 0.885311   0.04960382]

Traceback (most recent call last):
ValueError: Tensorflow type 21 not convertible to numpy dtype.
```

![image](https://user-images.githubusercontent.com/569000/69805111-a7970a80-11e8-11ea-8233-54b2385728c0.png)


"
34681,Skipping optimization due to error while loading function libraries: Invalid argument,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04 docker image
- TensorFlow installed from (source or binary):
```pip install tensorflow-gpu=2.0```
- TensorFlow version (use command below):
GIT_VERSION: v2.0.0-rc2-26-g64c3d38 VERSION: 2.0.0
- Python version:
3.7.3
- CUDA/cuDNN version:
CUDA: 10.0, cuDNN: 7.6.2.24-1
- GPU model and memory:
Tesla P100 16GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When training LSTMs using the tf.keras API I get a warning:
```
W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_2111_2291_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_2921' and '__inference___backward_cudnn_lstm_with_fallback_2111_2291' both implement 'lstm_9ed5de36-e395-476d-91c9-2cd0a6da489a' but their signatures do not match.
```
**Describe the expected behavior**
Should probably not give any warnings
**Code to reproduce the issue**
```python
import tensorflow as tf


batch_size = 16
num_batches = 4
num_timesteps = 100
num_features = 40
num_targets = 2

model = tf.keras.Sequential()
model.add(tf.keras.layers.LSTM(2, input_shape=(None, num_features), return_sequences=True))
model.compile(optimizer='adam', loss='mse')
model.summary()


X = tf.random.normal((batch_size * num_batches, num_timesteps, num_features))
y = tf.random.normal((batch_size * num_batches, num_timesteps, num_targets))

model.fit(X, y)
```
**Other info / logs**
```
python reproduce.py
2019-11-28 10:07:13.562280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-28 10:07:13.988578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:13.999849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:13:00.0
2019-11-28 10:07:13.999984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.061208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:1b:00.0
2019-11-28 10:07:14.061465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-28 10:07:14.062923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-28 10:07:14.064178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-28 10:07:14.064527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-28 10:07:14.066268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-28 10:07:14.067651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-28 10:07:14.071730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-28 10:07:14.071863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.072508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.073136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.073750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.074320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-11-28 10:07:14.074596: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-28 10:07:14.084185: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494140000 Hz
2019-11-28 10:07:14.087023: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5618f79346f0 executing computations on platform Host. Devices:
2019-11-28 10:07:14.087055: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-28 10:07:14.233596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.235446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.237594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5618f7996f10 executing computations on platform CUDA. Devices:
2019-11-28 10:07:14.237621: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
2019-11-28 10:07:14.237630: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla P100-PCIE-16GB, Compute Capability 6.0
2019-11-28 10:07:14.237933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.238529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:13:00.0
2019-11-28 10:07:14.238608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.239161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:1b:00.0
2019-11-28 10:07:14.239197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-28 10:07:14.239214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-28 10:07:14.239226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-28 10:07:14.239241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-28 10:07:14.239257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-28 10:07:14.239272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-28 10:07:14.239288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-28 10:07:14.239349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.239942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.240527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.241117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.241680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-11-28 10:07:14.241720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-28 10:07:14.243465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-28 10:07:14.243489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1
2019-11-28 10:07:14.243502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N
2019-11-28 10:07:14.243514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N
2019-11-28 10:07:14.243666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.244276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.244873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.245455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:13:00.0, compute capability: 6.0)
2019-11-28 10:07:14.245932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-28 10:07:14.246534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15216 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:1b:00.0, compute capability: 6.0)
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
lstm (LSTM)                  (None, None, 2)           344
=================================================================
Total params: 344
Trainable params: 344
Non-trainable params: 0
_________________________________________________________________
Train on 64 samples
2019-11-28 10:07:16.655379: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_2111_2291_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_2921' and '__inference___backward_cudnn_lstm_with_fallback_2111_2291' both implement 'lstm_9ed5de36-e395-476d-91c9-2cd0a6da489a' but their signatures do not match.
2019-11-28 10:07:16.787844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
64/64 [==============================] - 3s 40ms/sample - loss: 1.0611
```
"
34680,"Generator function didn't preserve needed nodes, copying old replacements back in instead.","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
ubuntu 16.04 / 
python 3.6 /
tf 1.14.0 /
onnx 1.6.0 

**Describe the current behavior**
I want to convert siamfc network pb model to onnx model.
I build tensorflow siamfc project  from [https://github.com/bilylee/SiamFC-TensorFlow.git](url).
after a lot of step ,I got .ckpt.* file successfully, then I freeze to pb file.
this is a part of network below:
![image](https://user-images.githubusercontent.com/16054460/69796416-f9e82380-1208-11ea-8859-d74889fb0917.png)
then,I need to convert to onnx model.
by this cmd:
python -m tf2onnx.convert --input=./siamfc-edit.pb --inputs=inference/examplar_input:0,inference/instance_input:0 --outputs=inference/detection/add:0 --opset=11 --continue_on_error --fold_const --output=siamfc-edit.onnx --verbose
I think this cmd is correct, because I can convert a lot of other network successfully.
but when it convert , a lot of warning come up ,and never stop.
so that I can't convert to onnx .the warning is below 

......
2019-11-28 17:19:56.308150: W tensorflow/tools/graph_transforms/transform_utils.cc:448] Generator function didn't preserve needed nodes, copying old replacements back in instead.
2019-11-28 17:19:56.309946: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv2/b2/BatchNorm/beta/read/_10__cf__10 to be preserved.
2019-11-28 17:19:56.309960: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv2/b2/BatchNorm/gamma/read/_11__cf__11 to be preserved.
2019-11-28 17:19:56.309975: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv2/b2/BatchNorm/moving_mean/read/_12__cf__12 to be preserved.
2019-11-28 17:19:56.309983: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv2/b2/BatchNorm/moving_variance/read/_13__cf__13 to be preserved.
2019-11-28 17:19:56.310000: W tensorflow/tools/graph_transforms/transform_utils.cc:448] Generator function didn't preserve needed nodes, copying old replacements back in instead.
2019-11-28 17:19:56.319616: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv3/BatchNorm/beta/read/_15__cf__15 to be preserved.
2019-11-28 17:19:56.319670: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv3/BatchNorm/gamma/read/_16__cf__16 to be preserved.
2019-11-28 17:19:56.319678: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv3/BatchNorm/moving_mean/read/_17__cf__17 to be preserved.
2019-11-28 17:19:56.319686: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv3/BatchNorm/moving_variance/read/_18__cf__18 to be preserved.
2019-11-28 17:19:56.319718: W tensorflow/tools/graph_transforms/transform_utils.cc:448] Generator function didn't preserve needed nodes, copying old replacements back in instead.
2019-11-28 17:19:56.323429: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv4/b2/BatchNorm/beta/read/_25__cf__25 to be preserved.
2019-11-28 17:19:56.323456: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv4/b2/BatchNorm/gamma/read/_26__cf__26 to be preserved.
2019-11-28 17:19:56.323464: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv4/b2/BatchNorm/moving_mean/read/_27__cf__27 to be preserved.
2019-11-28 17:19:56.323471: W tensorflow/tools/graph_transforms/transform_utils.cc:441] Expected convolutional_alexnet/conv4/b2/BatchNorm/moving_variance/read/_28__cf__28 to be preserved.
2019-11-28 17:19:56.323479: W tensorflow/tools/graph_transforms/transform_utils.cc:448] Generator function didn't preserve needed nodes, copying old replacements back in instead.
......

so what's wrong with it or me?

I expect to know what's this warning mean,I found there are a lot of identity op as input op share for other op. 
![image](https://user-images.githubusercontent.com/16054460/69797447-ad9de300-120a-11ea-9dd0-cd01138d4fd2.png)
does it because of this?

I look forward to your reply . thanks a lot."
34679,Missing Operations for TfLite GPU Delegate,"
**System information**
- TensorFlow version (you are using): 
on Android: 'org.tensorflow:tensorflow-lite:0.0.0-nightly' and 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'
- Are you willing to contribute it (Yes/No): Yes to the best of my possibilities



**Describe the feature and the current behavior/state.**
I'm trying to use the GPU delegate for my custom tflite model. Creating the interpreter with the GPU delegate using this code:
```
 val options = Options()
options.setUseNNAPI(false)
options.setAllowFp16PrecisionForFp32(true)
options.setNumThreads(NUM_THREADS)
val gpuDelegate = GpuDelegate()
options.addDelegate(gpuDelegate)

d.tfLite = Interpreter( loadModelFile(assetManager)!!, options)
```
 results in my model being run normally, hence delivering the correct outputs but not being accelerated by the GPU in my opinion, since the execution time is exactly the same as without using the delegate. Adding the line  `d.tfLite!!.modifyGraphWithDelegate(gpuDelegate)` (I don't know if this is necessary, it would also be nice to know?) results in the following error:
```
java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Next operations are not supported by GPU delegate:
    CONV_2D: Max version supported: 1. Requested version 2.
    LOCAL_RESPONSE_NORMALIZATION: Operation is not supported.
    SPLIT: Operation is not supported.
    First 0 operations will run on the GPU, and the remaining 12 on the CPU.ModifyGraphWithDelegate is disallowed when graph is immutable.
    java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Next operations are not supported by GPU delegate:
    CONV_2D: Max version supported: 1. Requested version 2.
    LOCAL_RESPONSE_NORMALIZATION: Operation is not supported.
    SPLIT: Operation is not supported.
    First 0 operations will run on the GPU, and the remaining 12 on the CPU.ModifyGraphWithDelegate is disallowed when graph is immutable.
```

So first of all: It would be nice to have those unsupported operations, i.e. 

- CONV_2D v2
- LOCAL_RESPONSE_NORMALIZATION
- SPLIT

Second of all: what does `ModifyGraphWithDelegate is disallowed when graph is immutable` mean? Do I have to make any changes to my tflite model?

"
34678,What value should I assign to the polling sizes (p) in main.py,"It seems that there is no specific assigned value to the pooling sizes in main.py. I only figured out the last element should be 20.
![企业微信截图_15749326291298](https://user-images.githubusercontent.com/30167606/69793254-06697d80-1203-11ea-89eb-50dc3d61e027.png)
"
34677,Suspected memory leak when loading multiple models,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: **Yes**
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: **Windows 10**
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: **NA**
- **TensorFlow installed from (source or binary)**: **binary wheel via PyPI**
- **TensorFlow version (use command below)**: **2.0.0**
- **Python version**: **3.6.2**
- **Bazel version (if compiling from source)**: **NA**
- **GCC/Compiler version (if compiling from source)**: **NA**
- **CUDA/cuDNN version**: **NA**
- **GPU model and memory**: **NA**

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
I'm suspecting a memory leak when loading multiple models(running on cpu only).
When im running infinite loop that keeps creating the same model while using the same variable the memory (private bytes and working  set)  of the process keep increasing. At some points the working set seems to free some memory, but the trend is that the memory keeps on rising,

This trend happens even though I call gc.collect() on every iteration.
In addition - using gc.get_objects() I can see that every iteration leaks exactly 1928 new objects. Using objgraph the leaked objects are:

If I add  tf.keras.backend.clear_session() between iterations it does clear the memory and the graph of the memory is flat.
Can someone please explain this behavior (and the mechanism) and approve that it is the correct flow when working with multiple models.

**Describe the expected behavior**
The memory shouldnt increase on each interation

**Code to reproduce the issue**
```
import tensorflow as tf
import gc
import objgraph

def mem_stat():
  objs = gc.get_objects()
  print(""total objects count"", len(objs))

c = 1
while True:
  print(""----------- iter"", c)
  model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
  ])
  
  gc.collect()
  
  print(""mem stat after model creation:"")
  mem_stat()
  objgraph.show_growth(limit=30)
  c += 1
```

with the clear session:
```
import tensorflow as tf
import gc
import objgraph


def mem_stat():
  objs = gc.get_objects()
  print(""total objects count"", len(objs))


c = 1
while True:
  print(""----------- iter"", c)
  model = tf.keras.models.Sequential([
      tf.keras.layers.Flatten(input_shape=(28, 28)),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.Dense(10, activation='softmax')
  ])
  tf.keras.backend.clear_session()
  gc.collect()
  
  print(""mem stat after model creation:"")
  mem_stat()
  objgraph.show_growth(limit=30)
  c += 1
```


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Attaching perfmon screenshot:

![image](https://user-images.githubusercontent.com/43209657/69791462-457cdc00-11cd-11ea-8103-6ac73532be68.png)

![image](https://user-images.githubusercontent.com/43209657/69791948-42362000-11ce-11ea-9ee3-17fbc67da753.png)


"
34676,"When building a custom model using keras.Model, a warning was triggered","My environment:
window10
CUDA10.0
tensorflow-gpu 1.14

When I built a more complex model today, I triggered the following warning:

> W1128 15: 22: 59.781456 32404 ag_logging.py:145] Entity <bound method DiMP.call of <__ main __. DiMP object at 0x0000024606A21208 >> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY = 10`) and attach the full output. Cause: (unicode error) 'utf-8' codec can't decode byte 0xca in position 250: invalid continuation byte (tmp56zh3z7b.py, line 15)

I don't know if this warning will affect the model operation, and the content of the warning says that it needs to be reported. So I came here.
Because there are a lot of engineering components, I can't determine which part triggered this warning. I won't upload all the code for the time being. If I need to upload code, I will not refuse.
Here is the entire print:

> C:\software\Anaconda3\envs\CV_env\python.exe C:/Users/stars_ocean/Desktop/DiMP_TF/models/DiMP.py
WARNING: Logging before flag parsing goes to stderr.
W1128 15:22:57.572051 32404 deprecation_wrapper.py:119] From C:\Users\stars_ocean\Desktop\DiMP_TF\models\backbone\MobileNet_V3_By_Model.py:4: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.

> used backbone layers: [5, 12]
> W1128 15:22:57.689736 32404 deprecation_wrapper.py:119] From C:\Users\stars_ocean\Desktop\DiMP_TF\models\classifiter\Initializer.py:24: The name tf.keras.initializers.RandomNormal is deprecated. Please use tf.compat.v1.keras.initializers.RandomNormal instead.
> 
> W1128 15:22:57.691731 32404 deprecation_wrapper.py:119] From C:\Users\stars_ocean\Desktop\DiMP_TF\models\classifiter\Optimizer.py:36: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.
> 
> 2019-11-28 15:22:57.692470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll
> 2019-11-28 15:22:58.922915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
> name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
> pciBusID: 0000:01:00.0
> 2019-11-28 15:22:58.923123: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
> 2019-11-28 15:22:58.926473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
> 2019-11-28 15:22:58.926787: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
> 2019-11-28 15:22:58.930528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
> name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
> pciBusID: 0000:01:00.0
> 2019-11-28 15:22:58.930820: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
> 2019-11-28 15:22:58.934215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
> 2019-11-28 15:22:59.447520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
> 2019-11-28 15:22:59.447669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
> 2019-11-28 15:22:59.447755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
> 2019-11-28 15:22:59.453515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2995 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
> W1128 15:22:59.781456 32404 ag_logging.py:145] Entity <bound method DiMP.call of <__main__.DiMP object at 0x0000024606A21208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: (unicode error) 'utf-8' codec can't decode byte 0xca in position 250: invalid continuation byte (tmp56zh3z7b.py, line 15)
> W1128 15:23:05.219440 32404 deprecation.py:323] From C:\software\Anaconda3\envs\CV_env\lib\site-packages\tensorflow\python\autograph\impl\api.py:255: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use tf.where in 2.0, which has the same broadcast rule as np.where
> 2019-11-28 15:23:06.199208: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: __inference_conv_and_transpose_10931
> 
> Process finished with exit code 0
> "
34675,Feature request: lock some of the layers alternately in training,"For example, a model with 3 dense layers named L0, L1, L2. Train it in below steps:

1, Set all layers trainable, train it for 10 epochs.
2, Set L0 not trainable, train it for 10 epochs.
3, Set L0 trainable, set L1 not trainable, train it for 10 epochs.
4, Set L1 trainable, set L2 not trainable, train it for 10 epochs.
5, Like step 2, set L2 trainable, set L0 not trainable, train it for 10 epochs.
6, Like step 3.
.......

It seems to train in this way is better than to train all the layers together. I think to reduce the trainable layers may reduce the gradient disappearance.

But for each time to alter the layers I have to recompile the whole model. I want there is some feature to do it automatically something like dropout.

If there already has this feature, please notice me."
34674,`py_function` in eager mode with Tensors fails,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-8709-gddde447 2.0.0-dev20190813
- Python version: 3.6.9

## Current Behaviour

`tf.py_function` fails when run in eager mode with `tf.Tensor`s from `tf.keras.Input`s

## Expected Behariour

Same as in graph mode.

## Code to reproduce the issue
```python
import tensorflow as tf
tf.compat.v1.enable_eager_execution()

x = tf.keras.layers.Input(shape=(), dtype=tf.float32)
y = tf.keras.layers.Input(shape=(), dtype=tf.float32)

def f(x, y):
    return x + y

z = tf.py_function(f, (x, y), tf.float32)
```

## Stack trace
```
Traceback (most recent call last):
  File ""../site-packages/tensorflow_core/python/ops/gen_script_ops.py"", line 53, in eager_py_func
    token, ""is_async"", is_async, ""Tout"", Tout)
tensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""pfk.py"", line 11, in <module>
    z = tf.py_function(f, (x, y), tf.float32)
  File ""../site-packages/tensorflow_core/python/ops/script_ops.py"", line 404, in eager_py_func
    return _internal_py_func(func=func, inp=inp, Tout=Tout, eager=True, name=name)
  File ""../site-packages/tensorflow_core/python/ops/script_ops.py"", line 293, in _internal_py_func
    name=name)
  File ""../site-packages/tensorflow_core/python/ops/gen_script_ops.py"", line 59, in eager_py_func
    ctx=_ctx)
  File ""../site-packages/tensorflow_core/python/ops/gen_script_ops.py"", line 113, in eager_py_func_eager_fallback
    _attr_Tin, input = _execute.convert_to_mixed_eager_tensors(input, _ctx)
  File ""../site-packages/tensorflow_core/python/eager/execute.py"", line 277, in convert_to_mixed_eager_tensors
    types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access
  File ""../site-packages/tensorflow_core/python/eager/execute.py"", line 277, in <listcomp>
    types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access
AttributeError: 'Tensor' object has no attribute '_datatype_enum'
```"
34673,what is the model inception5h?,"With what data is this model trained?

How do I keep training it?"
34672,You must feed a value for placeholder tensor 'Placeholder' with dtype int32,"```
    import tensorflow as tf  

    d1 = tf.placeholder(tf.int32)
    d2 = tf.add(6, 2, name=""Add_these_numbers2"")
    d3 = tf.add(d1, d2, name=""res5"")
    d4 = tf.add(d1, d3, name=""res5"")
    
    with tf.Session() as sess:
       # writer = tf.summary.FileWriter(""output"", sessi.graph)
        print(sess.run(d3))
        print(sess.run(d4,feed_dict={d1:0}))
```


why do you give me this error?


use python 3 with google colab gpu
F"
34671,how can i visualize activation of a layer?,"python 3
google colab
gpu"
34670,How to stop the process while sess.run in TensorFlowInferenceInterface?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes


**Describe the feature and the current behavior/state.**
I'm now developing the application with TensorFlowInferenceInterface in android. What I tried to find was stop function that stop the running calculation by setting some flag that can make calculation quit. However, the only thing I found was `TensorFlowInferenceInterface.close()` that couldn't stop running calculation. 

Is there any feature to set flag to stop the process? If there is already related information, I'm sorry and please let me know :)

**Will this change the current api? How?**
Little bit?

**Who will benefit with this feature?**
Android developers who are running the Tensorflow can make their application more responsive to the user.

**Any Other info.**
I run TensorFlowInferenceInterface with `rxJava` to serve it in background.

Thank you so much!"
34669,"armeabi-v7a libtensorflowlite_jni.so：signal 7 (SIGBUS), code 1 (BUS_ADRALN), fault addr 0xeef5445f","11-26 06:29:37.207 25216 25216 F DEBUG   : Revision: '1234'
11-26 06:29:37.207 25216 25216 F DEBUG   : ABI: 'arm'
11-26 06:29:37.207 25216 25216 F DEBUG   : pid: 24454, tid: 24528, name: RxCachedThreadS  
11-26 06:29:37.207 25216 25216 F DEBUG   : signal 7 (SIGBUS), code 1 (BUS_ADRALN), fault addr 0xeef5445f
11-26 06:29:37.207 25216 25216 F DEBUG   :     r0  eef5445f  r1  cd222804  r2  cd222800  r3  00000000
11-26 06:29:37.207 25216 25216 F DEBUG   :     r4  0000005a  r5  00000000  r6  cd2234c0  r7  d1ec0f28
11-26 06:29:37.207 25216 25216 F DEBUG   :     r8  00000000  r9  eef5445f  r10 00000168  r11 cd2234c0
11-26 06:29:37.207 25216 25216 F DEBUG   :     ip  00000009  sp  d1ec0e68  lr  00000004  pc  cd725ede"
34666,Weight Normalization,"**System information**
- TensorFlow version : 1.11
- Are you willing to contribute it : Yes


**Describe the feature and the current behavior/state.**

Weight Normalization is described in [Weight Normalization: A Simple Reparameterization
to Accelerate Training of Deep Neural Networks](https://arxiv.org/pdf/1602.07868.pdf).

Current, only in tf2.0 and use tensorflow-addons can achieve this normalization, it's [tfa-2.0](https://www.tensorflow.org/addons/tutorials/layers_weightnormalization)

In [Github](https://github.com/zoli333/Weight-Normalization) , someone write it in Conv2D

**Will this change the current api? How?**
It should build a serious of new apis.

**Who will benefit with this feature?**
Especially who want to train a GAN.
"
34665,"TypeError: Cannot convert value dtype([('resource', 'u1')]) to a TensorFlow DType.","Hello, I just started learning tf2.0, I tried to implement Chinese word2vec using tf2.0, I trained the model and passed `tf.compat.v1.train.Saver (). Save (session, ckpt_file_path, global_step = 2) The `command saves the trained model. However, when I load tf2.0 for prediction, an unexpected error occurs. I tried many methods but it was not resolved, but I used tf1.x to load the model prediction without any problems. In .0, the unexpected errors are as follows:
```
home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/client/session.py:1443: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  run_metadata)
Traceback (most recent call last):
  File ""predict2.py"", line 34, in <module>
    norm = tf.sqrt(tf.reduce_sum(input_tensor=tf.square(embeddings), axis=1, keepdims=True), name=""norm"")
  File ""/home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py"", line 10931, in square
    ""Square"", x=x, name=name)
  File ""/home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 530, in _apply_op_helper
    raise err
  File ""/home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 527, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1296, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py"", line 227, in constant
    allow_broadcast=True)
  File ""/home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py"", line 265, in _constant_impl
    allow_broadcast=allow_broadcast))
  File ""/home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py"", line 472, in make_tensor_proto
    numpy_dtype = dtypes.as_dtype(nparray.dtype)
  File ""/home/zh/sda3/Anaconda3/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/dtypes.py"", line 721, in as_dtype
    (type_value,))
TypeError: Cannot convert value dtype([('resource', 'u1')]) to a TensorFlow DType.

```

my predict code:
```
dictionary = {""UNK"": 0, ""，"": 1, ""的"": 2, ""。"": 3, ""了"": 4, ""是"": 5, ""『"": 6, ""』"": 7, ""萧炎"": 8}
reverse_dictionary = {""0"": ""UNK"", ""1"": ""，"", ""2"": ""的"", ""3"": ""。"", ""4"": ""了"", ""5"": ""是"", ""6"": ""『"", ""7"": ""』"", ""8"": ""萧炎""}
valid_word = ['萧炎']

valid_size = 1
valid_examples =[dictionary[li] for li in valid_word]
# valid_dataset = tf.constant(valid_examples, dtype=tf.int32)
valid_dataset = np.array(valid_examples)
with tf.compat.v1.Session() as sess:
    saver = tf.compat.v1.train.import_meta_graph('./model/-2
[model.zip](https://github.com/tensorflow/tensorflow/files/3899434/model.zip)
.meta')  
    saver.restore(sess, tf.train.latest_checkpoint('./model/'))  
    gragh = tf.compat.v1.get_default_graph()
    tensor_name_list = [tensor.name for tensor in gragh.as_graph_def().node]
    input_x = sess.graph.get_tensor_by_name('x:0')
    input_y = sess.graph.get_tensor_by_name('y:0')
    embeddings = sess.graph.get_tensor_by_name('embedding:0')
    feed_dict = {input_x: valid_dataset}
    embeddings = sess.run(embeddings,feed_dict)
    norm = tf.sqrt(tf.reduce_sum(input_tensor=tf.square(embeddings), axis=1, keepdims=True), name=""norm"")
    normalized_embeddings = embeddings / norm
    valid_embeddings = tf.nn.embedding_lookup(params=normalized_embeddings, ids=valid_dataset)
    similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)
    sim = similarity.eval()
    for i in xrange(valid_size):
        valid_word = reverse_dictionary[str(valid_examples[i])]
        top_k = 8  # number of nearest neighbors
        nearest = (-sim[i, :]).argsort()[:top_k]
        log_str = ""Nearest to %s:"" % valid_word
        for k in xrange(top_k):
            close_word = reverse_dictionary[str(nearest[k])]
            log_str = ""%s %s,"" % (log_str, close_word)
        print(log_str)
```
`model.zip` is the model used for testing. Could you please help me to see what problems I encountered? I have tried many methods but still not solved, please give me more guidance, thanks!


"
34664,TensorFlow Lite for Microcontrollers fails to build ,"Attempting to build the test arduino library using:
./tensorflow/lite/experimental/micro/tools/ci_build/test_arduino.sh
Throws a error about not being able to execute Arduino-cli.
I installed Arduino-cli through brew but still get the error.

**System information**
- Mac OSX 10.15.1
- TensorFlow version: Master
- Python version: 2.7

If I had to guess the build script is pulling down the linux binary and failing to run it. But I have not verified this."
34659,Dataset iterator hanging from within a dataset interleave ,"
> 
> == check python ===================================================
> python version: 3.7.4
> python branch: 
> python build version: ('default', 'Sep  7 2019 18:27:02')
> python compiler version: Clang 10.0.1 (clang-1001.0.46.4)
> python implementation: CPython
> 
> 
> == check os platform ===============================================
> os: Darwin
> os kernel version: Darwin Kernel Version 19.0.0: Wed Sep 25 20:18:50 PDT 2019; root:xnu-6153.11.26~2/RELEASE_X86_64
> os release version: 19.0.0
> os platform: Darwin-19.0.0-x86_64-i386-64bit
> linux distribution: ('', '', '')
> linux os distribution: ('', '', '')
> mac version: ('10.15', ('', '', ''), 'x86_64')
> uname: uname_result(system='Darwin', node='Andrews-MacBook.local', release='19.0.0', version='Darwin Kernel Version 19.0.0: Wed Sep 25 20:18:50 PDT 2019; root:xnu-6153.11.26~2/RELEASE_X86_64', machine='x86_64', processor='i386')
> architecture: ('64bit', '')
> machine: x86_64
> 
> 
> == are we in docker =============================================
> No
> 
> == compiler =====================================================
> xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun
> 
> == check pips ===================================================
> numpy                1.17.4   
> protobuf             3.10.0   
> tensorflow           2.0.0    
> tensorflow-estimator 2.0.1    
> 
> == check for virtualenv =========================================
> True
> 
> == tensorflow import ============================================
> tf.version.VERSION = 2.0.0
> tf.version.GIT_VERSION = v2.0.0-rc2-26-g64c3d382ca
> tf.version.COMPILER_VERSION = 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)
> 
> == env ==========================================================
> LD_LIBRARY_PATH is unset
> DYLD_LIBRARY_PATH is unset
> 
> == nvidia-smi ===================================================
> ./tf_env_collect.sh: line 147: nvidia-smi: command not found
> 
> == cuda libs  ===================================================
> 
> == tensorflow installed from info ==================
> Name: tensorflow
> Version: 2.0.0
> Summary: TensorFlow is an open source machine learning framework for everyone.
> Home-page: https://www.tensorflow.org/
> Author-email: packages@tensorflow.org
> License: Apache 2.0
> Location: /Users/andrew/.local/share/virtualenvs/lib_andrew_scratch--yvJ8pLH/lib/python3.7/site-packages
> Required-by: 
> 
> == python version  ==============================================
> (major, minor, micro, releaselevel, serial)
> (3, 7, 4, 'final', 0)
> 
> == bazel version  ===============================================
> 

**Describe the current behavior**
It seems all threads are waiting in a deadlock behaviour

**Describe the expected behavior**
To return a dataset iterator

**Code to reproduce the issue**



```
#!/usr/bin/env python
import tensorflow as tf

def gen( ):
	noise_tfrecord = ""test.tfrecord""
	raw_noise_dataset = tf.data.TFRecordDataset(noise_tfrecord)
	noise_count = sum(1 for _ in raw_noise_dataset)
	yield 1.

def do_bug():
	signal_tfrecord = ""test.tfrecord""
	raw_signal_dataset = tf.data.TFRecordDataset(signal_tfrecord)
	dataset = raw_signal_dataset.interleave(lambda x: tf.data.Dataset.from_generator(gen, 
			output_types=(tf.float32), 
			args=( )),
			cycle_length=2,
			block_length=1,
			num_parallel_calls = 1 )

	for d in dataset:
		print(d)

	return 

def _int_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def make_dataset():
	tfrecord_filename = ""test.tfrecord""
	with tf.io.TFRecordWriter(tfrecord_filename) as writer:
		for i in range(4):
			feature = {'feat' : _int_feature(42)}

			example_proto = tf.train.Example(features=tf.train.Features(feature=feature))
			writer.write(example_proto.SerializeToString())  

if __name__== ""__main__"":
	make_dataset()
	do_bug()

```


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

[bug.py.zip](https://github.com/tensorflow/tensorflow/files/3898706/bug.py.zip)
"
34658,AttributeError: module 'tensorflow' has no attribute 'Session',"> import tensorflow as tf
> sess = tf.Session()

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-9-f75057d1d95f> in <module>
----> 1 sess = tf.Session()

AttributeError: module 'tensorflow' has no attribute 'Session'
Environment details : 
Anaconda Python : 3.6
tensorflow version : 2.0.0
Machine (OS) : LINUX , Ubuntu 16.04

New to tensorflow, I am facing this error help me with this!"
34657,"problems when I build tensorflow from source, someone helps please","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source(not sure, i am using ./configure and  then bazel build)
- TensorFlow version: 1.14(for my conda environment)
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: conda create -n xxx python=3.6.8 the enter the env and pip install tensorflow==1.14
- Bazel version (if compiling from source):1.1.0
- GCC/Compiler version (if compiling from source): 6.4.0
- CUDA/cuDNN version: cuda 10/cudnn  CUDNN_MAJOR 7
- GPU model and memory: TESLA P40



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

HI, GUYS, I was trying to build tensorflow transform_graph tools  from source(same way as build tensorflow), I already installed bazel and clone tensorflow from github. When i use command
bazel build tensorflow/tools/graph_transforms:transform_graph, i got this problem
![image](https://user-images.githubusercontent.com/51428350/69752002-2286f500-1105-11ea-9f50-547851b71f59.png)

after searching for a while, i think it might because of the CUDA , so i ./configure again, this time, when it needs me to choose do you wish to build tf with cuda support, i chose no
and build again, but this time still not work
![image](https://user-images.githubusercontent.com/51428350/69752146-78f43380-1105-11ea-8407-c0de92760ec9.png)

could you please help me out? thanks so much
"
34656,tensorflow-serving apt-get not working,"**System information**
- OS : Linux
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0.0
- Python version: 3.7
- Installed using virtualenv? pip

**Describe the problem**
Upon following instructions in https://www.tensorflow.org/tfx/serving/setup for apt-get method to install tensorflow-model-serving-universal 

get the following error

Err:3 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease   503  Service Unavailable [IP: 172.217.6.80 80]

**Provide the exact sequence of commands / steps that you executed before running into the problem**

echo ""deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal"" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \
curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -
apt-get update && apt-get install tensorflow-model-server


"
34652,"GPU unit-test infrastructure breakage (`Dockerfile.gpu`, `gpu/run_py3_core.sh`) ","Evertyime we sync (the `develop-upstream` branch) in our TF fork (with the `master` branch of this repo), we run a bunch of test-suites to qualify the changes before taking them.

One of those testsuites involves running the `GPU` tests (on the `cuda` platform) using the following command 

```
tensorflow/tools/ci_build/ci_build.sh GPU ./tensorflow/tools/ci_build/linux/gpu/run_py3_core.sh
```

The above testsuite failed for us during our latest sync attempt. 

We re-ran the CI job directly on the code in the `master` branch (as opposed to the merged code in our repo), and we see the same errors, leading us to believe that the breakage originates due to changes in the upstream repo.

Link to the CI run log mentioned above : http://ml-ci.amd.com:21096/job/tensorflow-cuda/1/console

Our last successful merge was about 3 weeks ago, so the breakage seems to have been introduced sometime within the last 3 weeks. 

Errors similar to the ones we see, have been reported in other github issues.
https://github.com/tensorflow/tensorflow/issues/34429
https://github.com/tensorflow/tensorflow/issues/34117

When we look at the invocation log for the `Linux GPU` (in the **Continuous build status** section of README.md), the run is passing, but it seems to use a different script and different env-vars/options/etc as compared to those used by the `Dockerfile.gpu` and `./tensorflow/tools/ci_build/linux/gpu/*.sh` scripts that are used by our CI job.

The request here is to please identify what is causing the breakage we see on our end, and fix it. Also please update the GPU test scripts (`Dockerfile.gpu` + `./tensorflow/tools/ci_build/linux/gpu/*.sh` ) to match what is done by the GPU CI runs kicked off internally.

thanks


/cc @chsigg @parallelo @sunway513 @whchung 

"
34651,Euclidean distance transform add on to support 3D images?,"Hello as the euclidean distance transform has been implemented with specific input shapes, I was wondering if this would be expanded to more general shapes. I am currently trying to generate a distance matrix based on 3D ground truth data (i.e. W X H X D) which could easily be 4D  (Batch size x W x H x D). Is this something that would be possible?
"
34650,TFRecordsWriter default write mode?,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/io/TFRecordWriter

## Description of issue:

So I've been using TFRecordWriter for a while now and I would be interested in the method it writes to files. If I create two TFRecord files with the exact same name what is the default wrtiing option? `append` or `(re)write`? It would be crucial to know this in my use case. Thanks in advance."
34649,Tensorflow lite converter error,"I was running a tensorflowlite converter and it gave the following error.


ConverterError                            Traceback (most recent call last)
<ipython-input-12-501417991c7a> in <module>
----> 1 tflite=converter.convert()

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\lite\python\lite.py in convert(self)
    444         input_tensors=input_tensors,
    445         output_tensors=output_tensors,
--> 446         **converter_kwargs)
    447 
    448     if self._is_calibration_quantize():

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    447       input_data.SerializeToString(),
    448       debug_info_str=debug_info_str,
--> 449       enable_mlir_converter=enable_mlir_converter)
    450   return data
    451 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    198       stdout = _try_convert_to_unicode(stdout)
    199       stderr = _try_convert_to_unicode(stderr)
--> 200       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    201   finally:
    202     # Must manually cleanup files.

ConverterError: See console for info.
2019-11-27 19:59:16.411699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2019-11-27 19:59:20.890923: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-11-27 19:59:20.894284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2019-11-27 19:59:20.919992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce 940M major: 5 minor: 0 memoryClockRate(GHz): 1.176
pciBusID: 0000:01:00.0
2019-11-27 19:59:20.920714: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-11-27 19:59:20.921672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-27 19:59:22.502049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-27 19:59:22.502595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-27 19:59:22.502905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-27 19:59:22.504028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3048 MB memory) -> physical GPU (device: 0, name: GeForce 940M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2019-11-27 19:59:22.550147: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2019-11-27 19:59:22.551545: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-27 19:59:22.552833: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2019-11-27 19:59:22.554116: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-27 19:59:22.555345: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2019-11-27 19:59:22.556546: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-27 19:59:22.557739: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-27 19:59:22.558973: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2019-11-27 19:59:22.566435: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 18 operators, 54 arrays (0 quantized)
2019-11-27 19:59:22.568675: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 18 operators, 54 arrays (0 quantized)
2019-11-27 19:59:22.574828: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 6 operators, 34 arrays (0 quantized)
2019-11-27 19:59:22.576359: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 6 operators, 34 arrays (0 quantized)
2019-11-27 19:59:22.577888: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 6 operators, 34 arrays (0 quantized)
2019-11-27 19:59:22.579626: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.
2019-11-27 19:59:22.582696: E tensorflow/lite/toco/toco_tooling.cc:466] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While."
34648,Use TPU on Colab shows:Session edefaa660de08d53 is not found.,"I want to use the tpu on colab to do some exercise. i follow the colab tutorial to use the tpu. i can run the example on tpu. but when i run a new  custom model, the console shows ""Session edefaa660de08d53 is not found.""
i don't know what mistake there is

**System information**
- env:   colab
- TensorFlow installed from (source or binary):  
- TensorFlow version (use command below): 1.15
- Python version: python3

**Describe the current behavior**
i download a data from internet on loacl storage. Then i read the data and convert it to the tfrecord,
And i bulid a custom model. i  use the tup like the tutorial shows.
But when i run model.fit(), the console shows this mistake.
how do i fix it?


**Code to reproduce the issue**
```python
filename = os.listdir(r'./tfrecord')
files = [os.path.join(r'./tfrecord', x) for x in filename]
dataset = tf.data.TFRecordDataset(files)
dataset = dataset.map(_parse_func)
dataset = dataset.shuffle(256)
dataset = dataset.batch(128,drop_remainder=True)

# define some custom layer, those layer made by Conv2D, Concat, softmax
# define the custom model

resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.contrib.distribute.initialize_tpu_system(resolver)
strategy = tf.contrib.distribute.TPUStrategy(resolver)

with strategy.scope():
    opt = tf.keras.optimizers.Adam()
    def rmse(y_true, y_pred):
        return tf.reduce_mean(tf.math.sqrt(tf.math.squared_difference(y_pred, y_true)))
    generator = generator_() # my custom model
    generator.compile(optimizer=opt, loss=tf.keras.metrics.MSE, metrics=[rmse])
model.fit()
```
the github gist to reproduce the problem is:
https://gist.github.com/x7night/45ba9eb08f568909bde0cc5f65050653
**Other info / logs**
Session edefaa660de08d53 is not found."
34647,How to build static libtensorflowlite.a for Android ?,"bazel build -c opt --config=andrdoi_arm --cxxopt='--std=c++11' --cpu=arm64-v8a \
tensorflow/lite:libtensorflowlite.so

I can build libtensorflowlite.so using above command .
Is there any way to build static libtensorflowlite.a for Android ?"
34645,TypeError: minimize() missing 1 required positional argument: 'var_list',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**


import tensorflow as tf

from tensorflow.keras.datasets import mnist


def model_fn(features, labels, mode, params):
    features = tf.cast(features, dtype=tf.float32)
    print(features.dtype)
    img = tf.keras.layers.Conv2D(32, (3, 3), activation=""relu"")(features)
    img = tf.keras.layers.MaxPool2D((2, 2), 2)(img)
    img = tf.keras.layers.Conv2D(64, (3, 3), activation=""relu"")(img)
    img = tf.keras.layers.MaxPool2D((2, 2), 2)(img)
    img = tf.keras.layers.Conv2D(64, (3, 3), activation=""relu"")(img)
    img = tf.keras.layers.Flatten()(img)
    img = tf.keras.layers.Dense(units=256, activation=""relu"")(img)
    img = tf.keras.layers.Dense(units=128, activation=""relu"")(img)
    logits = tf.keras.layers.Dense(units=10, activation=None)(img)

    probs = tf.keras.activations.softmax(logits)
    predicted_classes = tf.argmax(probs, 1)

    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, probs)

    acc = tf.compat.v1.metrics.accuracy(labels, predicted_classes)
    metrics = {""accuracy"": acc}
    tf.summary.scalar(""accuracy"", acc[1])

    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode,
                                          loss=loss, eval_metric_ops=metrics)

    assert mode == tf.estimator.ModeKeys.TRAIN

    optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.001)
    train_op = optimizer.minimize(loss)
    return tf.estimator.EstimatorSpec(mode,
                                      loss=loss, train_op=train_op)


def load_mnist():
    train, test = mnist.load_data()
    return train, test


def train_input_fn(features, labels, batch_size):
    # features = tf.convert_to_tensor(features, dtype=tf.float32)
    # labels = tf.convert_to_tensor(labels, dtype=tf.int32)
    dataset = tf.data.Dataset.from_tensor_slices((features, labels))
    dataset = dataset.shuffle(500)
    dataset = dataset.repeat().batch(batch_size)
    return dataset


def eval_input_fn(imgs, labels, batch_size):
    dataset = tf.data.Dataset.from_tensor_slices((imgs, labels))
    dataset = dataset.batch(batch_size)
    return dataset


def main(m_dir=None):
    (x_train, y_train), (x_test, y_test) = load_mnist()
    x_train = x_train.reshape(60000, 28, 28, 1)
    x_test = x_test.reshape(10000, 28, 28, 1)
    classifier = tf.estimator.Estimator(model_fn=model_fn, model_dir=m_dir)

    classifier.train(input_fn=lambda: train_input_fn(x_train, y_train, 500), steps=100)


if __name__ == ""__main__"":
    main()
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34644,Can't save stateful LSTM as savedmodel (TF 2.0),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): UBUNTU
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary):  DOCKER IMAGE
- TensorFlow version (use command below): DOCKER IMAGE 2.0
- Python version: DOCKER IMAGE 2.0
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: DOCKER IMAGE 2.0
- GPU model and memory: N/A

**Describe the current behavior**
Attemping to save a model containing a stateful LSTM to savedmodel format fails with the following error:

> AssertionError: Tried to export a function which references untracked object Tensor(""StatefulPartitionedCall/args_1:0"", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.

**Describe the expected behavior**
No errors, and a correctly saved model :-)

**Code to reproduce the issue**

```
import tensorflow as tf
from tensorflow.keras import layers


def get_model(stateful=False, batch_size=None):
    n_channels = 1
    sample_size = 10
    n_units = 5

    inputs = layers.Input(batch_shape=(batch_size, sample_size, n_channels),
                          name='timeseries_inputs')
    y = layers.LSTM(units=n_units, input_shape=(sample_size, n_channels),
                    activation='tanh', recurrent_activation='sigmoid', return_sequences=False,
                    stateful=stateful)(inputs)

    y = layers.Dense(1)(y)

    model = tf.keras.models.Model(inputs=inputs, outputs=y)

    return model


stateless_model = get_model(stateful=False)

stateful_model = get_model(stateful=True, batch_size=1)

stateless_model.save('stateless.h5')
stateful_model.save('stateful.h5')

stateless_model.save('stateless.tf')
stateful_model.save('stateful.tf')
```
"
34643,TypeError while importing tensorflow caused by site.USER_SITE is set to None,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source): --
- GCC/Compiler version (if compiling from source): --
- CUDA/cuDNN version: --
- GPU model and memory: --

**Describe the current behavior**

When importing the tensorflow module with

`import tensorflow`

the following Exception gets thrown

> Traceback (most recent call last):
>   File ""IMPORT_TENSORFLOW"", line 8, in run
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py"", line 98, in <module>
>     from tensorflow_core import *
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py"", line 403, in <module>
>     if _running_from_pip_package():
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py"", line 401, in _running_from_pip_package
>     _current_file_location.startswith(dir_) for dir_ in _site_packages_dirs)
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py"", line 401, in <genexpr>
    _current_file_location.startswith(dir_) for dir_ in _site_packages_dirs)
> TypeError: startswith first arg must be str or a tuple of str, not NoneType

from

https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/api_template.__init__.py#L119

The cause for this is

https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/api_template.__init__.py#L104

because `site.USER_SITE` can be `None` accordingly to the python documentation https://docs.python.org/3.6/library/site.html#site.USER_SITE and in this environment it happens to be the case.

A workaround for this is to call  site.getusersitepackages() before importing tensorflow. However, in my opinion the `USER_SITE` needs to be checked here before it is used, or the list _site_packages_dirs needs to be filtered for `None` values.

**Describe the expected behavior**

`import tensorflow` succeeds without the exception

**Code to reproduce the issue**

Start container:

`docker run --rm -it tensorflow/tensorflow:2.0.0-py3 bash`

Start python3 in the container without site initialization:

`python3 -S`

Add package locations to the sys.path and import tensorflow:

```
import sys
sys.path=['', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages']
import tensorflow
```
"
34642,[tflite] Output difference for simple MobileNetV2 model,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Arch Linux**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (or github SHA if from source): **Tested on tf_nightly_gpu-2.1.0.dev20191126 from pip and 2.0.0 from the Arch repositories.**


**Command used to run the converter or code if you’re using the Python API**
Original implementation from [here](https://www.tensorflow.org/lite/convert/python_api#end-to-end_mobilenet_conversion_).

```python
import numpy as np
import tensorflow as tf

# Load the MobileNet tf.keras model (and set include_top=False).
model = tf.keras.applications.MobileNetV2(
    weights=""imagenet"", input_shape=(224, 224, 3), include_top=False)

# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the TensorFlow Lite model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
tflite_results = interpreter.get_tensor(output_details[0]['index'])

# Test the TensorFlow model on random input data.
tf_results = model(tf.constant(input_data))

# Compare the result.
for tf_result, tflite_result in zip(tf_results, tflite_results):
  np.testing.assert_almost_equal(tf_result, tflite_result, decimal=5)
```

**The output from the converter invocation**

```
AssertionError: 
Arrays are not almost equal to 5 decimals

Mismatch: 2.78%
Max absolute difference: 5.4180622e-05
Max relative difference: 0.01288559
 x: array([[[0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],
        [0.     , 0.     , 0.     , ..., 0.     , 0.82339, 0.74743],
        [0.     , 0.88872, 0.     , ..., 0.     , 2.61463, 2.41743],...
 y: array([[[0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],
        [0.     , 0.     , 0.     , ..., 0.     , 0.8234 , 0.74745],
        [0.     , 0.88871, 0.     , ..., 0.     , 2.61464, 2.41744],...

```

**Failure details**
As per the [converter documentation](https://www.tensorflow.org/lite/convert/python_api), I am trying to verify that the output of my converted model and the output of my original model are identical. This is the case if I run [this](https://www.tensorflow.org/lite/convert/python_api#end-to-end_mobilenet_conversion_) code from the documentation page, however if I add `include_top=False` to the `MobileNetV2` constructor, then I get different output. I would expect the exact same output, regardless of what part of the model I select.

As per the output log, there is a max relative difference of 0.01288559, which in my opinion is pretty significant.

Note that there is no quantization being performed. It is simply creating a random MobileNetV2 model, converting it and passing through some random data. I find it weird that the output is different, but that the outputs are identical if `include_top=True`.

**Any other info / logs**
I have tested on other backbones as well, `MobileNet` and `ResNet50`; they have the same issue that the output is different when adding `include_top=False`.
"
34641,Shape_refiner.cc documentation,"I get this as an output from my model, but the model runs and outputs a loss and an accuracy. It always posts the same 49 index numbers (I'm only posting one to avoid flooding), each of them twice. 

`W tensorflow/core/common_runtime/shape_refiner.cc:89] Function instantiation has undefined input shape at index: 380 in the outer inference context.`

What does it mean? I'm using Python and I've posted a question about this [here](https://stackoverflow.com/questions/59057300/what-is-the-outer-inference-context-shape-refiner-cc-in-tensorflow-2?noredirect=1#comment104357261_59057300) and [here](https://stackoverflow.com/questions/59039788/how-to-combine-a-pre-trained-keraslayer-from-tensorflow-v-2-hub-and-tfrecords).
"
34639,Contribution guideline for Interative Notebook needs to be modified.,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/community/contribute/docs 

## Description of issue (what needs changing):
Documentation under ""Interactive notebooks"" needs to be modified to accommodate issues created after direct editing of Jupyter Notebook in Colab.
  

### Clear description. 

Direct editing (on colab or using VSCode) Jupyter Notebook and committing as mentioned [here](https://www.tensorflow.org/community/contribute/docs) adds additional unintended changes like prettifying and escapes unicode symbols. 

For example, see here: https://github.com/tensorflow/docs/pull/1238 

Related code commit : https://github.com/copperwiring/docs/commit/98f35604617d1ecc93b3dc75ac6ec4ab108536eb 

### Correct links

Yes

### Parameters defined

N/A

### Returns defined

N/A

### Raises listed and defined

None.

### Usage example

It is useful and needed for any PR request for Jupyter Notebook

### Request visuals, if applicable

N/A

### Submit a pull request?

I am planning to submit a PR to improve the documentation.
"
34638,"when set CollectiveCommunication NCCL, the train is stucking","System information

    Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
    OS Platform and Distribution: Ubuntu 18.04
    TensorFlow installed from (source or binary): pip install tensorflow-gpu
    TensorFlow version (use command below): 2.0
    Python version: 3.6.9
    CUDA/cuDNN version: 10/7.6.4.38
    GPU model and memory: Tesla P4  8G

Describe the current behavior
I  run the code described below:

**TEST 1:   (two machine)**

os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""server1:12345"", ""server2:12345""]
    },
    'task': {'type': 'worker', 'index': 0}
})

In the other machine

os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""server1:12345"", ""server2:12345""]
    },
    'task': {'type': 'worker', 'index': 1}
})

When the script start processing the first epoch it crashes,

**Describe the expected behavior**

15s/epoch  is so slow

<img width=""1162"" alt=""图片"" src=""https://user-images.githubusercontent.com/12653212/69707374-942a6780-1134-11ea-8dd1-994fd7e41451.png"">


**TEST 2:   (one machine)**

os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""server1:12345""]
    },
    'task': {'type': 'worker', 'index': 0}
})

**Describe the expected behavior**

5s/epoch      same as use  strategy = tf.distribute.MirroredStrategy()  one GPU card

<img width=""1072"" alt=""图片"" src=""https://user-images.githubusercontent.com/12653212/69707387-9b517580-1134-11ea-976a-73c9d36fdc2b.png"">


**CODE**

```
import ssl

ssl._create_default_https_context = ssl._create_unverified_context
import os
import json

import tensorflow as tf
import tensorflow_datasets as tfds

import argparse


def configure_cluster(worker_hosts=None, task_index=-1):
    """"""Set multi-worker cluster spec in TF_CONFIG environment variable.
    Args:
      worker_hosts: comma-separated list of worker ip:port pairs.
    Returns:
      Number of workers in the cluster.
    """"""
    tf_config = json.loads(os.environ.get('TF_CONFIG', '{}'))
    if tf_config:
        num_workers = len(tf_config['cluster'].get('worker', []))
    elif worker_hosts:
        workers = worker_hosts.split(',')
        num_workers = len(workers)
        if num_workers > 1 and task_index < 0:
            raise ValueError('Must specify task_index when number of workers > 1')
        task_index = 0 if num_workers == 1 else task_index
        os.environ['TF_CONFIG'] = json.dumps({
            'cluster': {
                'worker': workers
            },
            'task': {'type': 'worker', 'index': task_index}
        })
    else:
        num_workers = 1
    return num_workers


parser = argparse.ArgumentParser(description='TensorFlow Benchmark',
                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('--num-epochs', type=int, default=5, help='input batch size')
parser.add_argument('--batch-size-per-replica', type=int, default=64, help='input batch size')
parser.add_argument('--worker-hosts', type=str, default=None)
parser.add_argument('--worker-index', type=int, default=0)

args = parser.parse_args()

worker_num = configure_cluster(args.worker_hosts, args.worker_index)
batch_size = args.batch_size_per_replica * worker_num
print('Batch Size: %d' % batch_size)

gpus = tf.config.experimental.list_physical_devices('GPU')
print(""Physical GPU Devices Num:"", len(gpus))
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(
    communication=tf.distribute.experimental.CollectiveCommunication.RING)

def resize(image, label):
    image = tf.image.resize(image, [128, 128]) / 255.0
    return image, label


# if as_supervised is True，return image abd label
dataset, info = tfds.load(""tf_flowers"", split=tfds.Split.TRAIN, with_info=True, as_supervised=True)
dataset = dataset.map(resize).repeat().shuffle(1024).batch(batch_size)
total_num_examples = 3670

with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, [3, 3], activation='relu'),
        tf.keras.layers.Conv2D(64, [3, 3], activation='relu'),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Dropout(0.25),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(info.features['label'].num_classes, activation='softmax')
    ])
    model.compile(
        optimizer=tf.optimizers.Adam(learning_rate=0.001),
        loss=tf.keras.losses.sparse_categorical_crossentropy,
        metrics=[tf.keras.metrics.sparse_categorical_accuracy]
    )

model.fit(dataset, steps_per_epoch=total_num_examples // batch_size, epochs=args.num_epochs)


```

In TEST 2:    only 1 worker,   5s/epoch ~ 6s/epoch  （batch_szie = 128）

In TEST 1:  2 workers,     15s/epoch  ~ 19s/epoch  （per_batch_szie = 64, batch_size = 64 *2 = 128）


**Question1:** 
So, I cannot understand,  with dist MultiWorkerMirroredStrategy  worker nums > 1,  
why Training is so slow

**Question2:**
when I  set   strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(
    communication=tf.distribute.experimental.CollectiveCommunication.NCCL) 

In TEST 1:  2 workers,  the training will stuck  in epoch 2,   epoch 1 done.

<img width=""1185"" alt=""图片"" src=""https://user-images.githubusercontent.com/12653212/69708066-e750ea00-1135-11ea-9bb4-362340737b76.png"">



"
34637,multi-device function optimization failure,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 19.10
- TensorFlow installed from (source or binary):github release
- TensorFlow version (use command below):2.0
- Python version:3.7.5
- Bazel version (if compiling from source):0.26.1
- GCC/Compiler version (if compiling from source):9.2.1 20191008
- CUDA/cuDNN version:10.1, 7.6.4
- GPU model and memory: RTX2080Ti x2 NVLink

**Describe the current behavior**
It takes to much time and shows W:""multi-device function optimization failure""

**Describe the expected behavior**
Fastly start train after compile the model with no W.

**Code to reproduce the issue**

> main:
```
import os
os.environ['TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_IGNORE_PERFORMANCE'] = '1'
import tensorflow as tf
from Models import MCN
from DataSets import ImageNet

for gpu in tf.config.experimental.list_physical_devices('GPU'):
    tf.config.experimental.set_memory_growth(gpu, True)
logical_gpus = tf.config.experimental.list_logical_devices('GPU')

BATCH_SIZE=20
BATCHS_PER_APLY_GRADIENTS=1000//BATCH_SIZE

ds=ImageNet.ImageNetP()
starategy=tf.distribute.MirroredStrategy()
with starategy.scope():
    model=MCN.mcn_520(2,24)
    model.summary()
    model.compile(
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        optimizer=tf.keras.optimizers.SGD(),
        metrics=[tf.keras.metrics.TopKCategoricalAccuracy(1,'top1'),tf.keras.metrics.TopKCategoricalAccuracy(5,'top5')]
        )
    fit_ds,val_ds=ds(BATCH_SIZE)
    model.fit(
        fit_ds,
        epochs=1000000,
        steps_per_epoch=BATCHS_PER_APLY_GRADIENTS*200,
        validation_data=val_ds,
        validation_steps=ds.val_images//BATCH_SIZE,
    )
```

> MCN.py:

```
import math
import tensorflow as tf
from tensorflow import keras

class Swish(keras.layers.Layer):
    def __init__(self):
        super(Swish, self).__init__()
        self.weight = self.add_weight(initializer='uniform',trainable=True)

    def __call__(self, inputs):
        return inputs+tf.sigmoid(self.weight*inputs)


class Conv(keras.Model):
    def __init__(self,filters,kernel_size=1,strides=1,padding='valid'):
        super(Conv, self).__init__()
        self.conv = keras.layers.Conv2D(filters,kernel_size,strides,padding)
        self.bn = keras.layers.BatchNormalization()
        self.ac = Swish()

    def __call__(self,inputs):
        return self.ac(self.bn(self.conv(inputs)))


class SEBlock(keras.Model):
    def __init__(self, filters):
        super(SEBlock, self).__init__()
        self.conv0 = keras.layers.Conv2D(filters//4,1,1)
        self.drop = keras.layers.Dropout(0.25)
        self.conv1 = keras.layers.Conv2D(filters,1,1)
        self.bn = keras.layers.BatchNormalization()
        self.ac = Swish()

    def __call__(self,inputs):
        x = self.conv1(self.drop(self.conv0(tf.reduce_mean(inputs,[1,2],keepdims=True))))
        return self.ac(self.bn(tf.sigmoid(x)*inputs))


class ResBlock(keras.Model):
    def __init__(self, filters):
        super(ResBlock, self).__init__()
        self.conv0 = keras.layers.Conv2D(filters//4,1,1)
        self.drop = keras.layers.Dropout(0.25)
        self.conv1 = keras.layers.Conv2D(filters,3,1,'same')
        self.bn = keras.layers.BatchNormalization()
        self.ac = Swish()

    def __call__(self,inputs):
        x = self.conv1(self.drop(self.conv0(inputs)))
        return self.ac(self.bn(inputs+x))

def mcn_520(width, growth,input_shape=[256,256,3]):
    fs = int(width*growth)
    inputs=keras.layers.Input(input_shape)
    x=keras.layers.Conv2D(fs,8,2)(inputs)
    x=keras.layers.MaxPool2D(2)(x)
    x1=Conv(fs//width)(SEBlock(fs)(x))
    x2=Conv(fs//width)(ResBlock(fs)(x))
    for i, depth in enumerate([2, 3, 5, 4]):
        for _ in range(int(6*depth)):
            fs+=int(math.sqrt(fs*width))
            t=keras.layers.Concatenate()([x,x1,x2])
            t=keras.layers.Dropout(0.25)(t)
            t=Conv(fs//width, 1, 1)(t)
            t=keras.layers.Dropout(0.25)(t)
            x1=SEBlock(fs//width)(t)
            x2=ResBlock(fs//width)(t)
            t=keras.layers.Concatenate()([t,x1,x2])
            t=keras.layers.Dropout(0.25)(t)
            t=Conv(growth,1,1)(t)
            x=keras.layers.Concatenate()([x,t])
        if i != 3:
            fs //= 2
            x=keras.layers.MaxPool2D(2)(Conv(fs)(x))
            x1=keras.layers.MaxPool2D(2)(Conv(fs//width)(x1))
            x2=keras.layers.MaxPool2D(2)(Conv(fs//width)(x2))
    x=keras.layers.GlobalMaxPool2D()(x)
    x=keras.layers.Dropout(0.25)(x)
    outputs=keras.layers.Dense(1000,activation='softmax')(x)
    return keras.Model(inputs=inputs,outputs=outputs,name='MCN520')
```
**Other info / logs**

> Train for 10000 steps, validate for 2500 steps
> Epoch 1/1000000
> 2019-11-27 07:06:16.642667: W tensorflow/core/common_runtime/process_function_library_runtime.cc:675] Ignoring multi-device function optimization failure: Deadline exceeded: meta_optimizer exceeded deadline.
> 2019-11-27 07:06:27.657015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
> 2019-11-27 07:06:28.144415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
> "
34636,Different behaviour in keras.layers.TimeDistributed() and tf.keras.layers.TimeDistributed()?,"Environment:
Windows 10
GPU
TensorFlow 1.13.1 (install from pip)
Anaconda
IDE: Spyder
python 3.6

I am going to convert matterport's MaskRCNN implementation from keras to tf.keras. It gives the different output, as for example, for the following code-segment:
```
x = PyramidROIAlign([pool_size, pool_size],name=""roi_align_classifier"")([rois, image_meta] + feature_maps)
print('x1:',x)
# Two 1024 FC layers (implemented with Conv2D for consistency)
 x = KL.TimeDistributed(KL.Conv2D(fc_layers_size, (pool_size, pool_size), padding=""valid""),
                           name=""mrcnn_class_conv1"")(x)
print('x2:', x)
```
The printed output for keras:
```
x1: Tensor(""roi_align_classifier_10/Reshape:0"", shape=(1, ?, 7, 7, 256), dtype=float32, device=/device:GPU:0)
x2: Tensor(""mrcnn_class_conv1_10/Reshape_1:0"", shape=(?, 200, 1, 1, 1024), dtype=float32, device=/device:GPU:0)
```

The printed output for tf.keras:
```
x1: Tensor(""roi_align_classifier_11/Reshape:0"", shape=(1, ?, 7, 7, 256), dtype=float32, device=/device:GPU:0)
x2: Tensor(""mrcnn_class_conv1_11/transpose_1:0"", shape=(1, ?, 1, 1, 1024), dtype=float32, device=/device:GPU:0)

the TimeDistributed gives different results.

Is there any suggestion and solution pleas?

Thanks
```

"
34635,optimizer.apply_gradients() logs warnings using Tensor.name which is not supported by eager execution,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version: v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7.4
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: RTX 2070 super 8gb

**Describe the current behavior**
When using a gradient tape in eager mode, if the gradient computation fails and returns `None`, the `apply_gradients()` function will attempt to log a warning using `Tensor.name` which isn't supported in eager execution. The exact line can be found [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L1043). This is a breaking issue because it is simply a logged warning, and the code should continue to execute; however in eager mode it raises an `AttributeError` due to `Tensor.name`. A similar issue can be found above on [line 1039](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L1039) however that one is less serious, as the code would terminate due to the `ValueError` anyway.

**Describe the expected behavior**
A warning is logged and the code continues to execute.

**Code to reproduce the issue**
There is a workaround for RTX GPUs at the top per the comment in #24828 

```python
import tensorflow as tf
import numpy as np

conv1_filters = 32
conv1_window = 3
input_dims = 50
num_classes = 10

random_normal = tf.initializers.RandomNormal()

# Magic fix for RTX GPUs
# gpus = tf.config.experimental.list_physical_devices('GPU')
# for gpu in gpus:
#   tf.config.experimental.set_memory_growth(gpu, True)

weights = {
  'wc1': tf.Variable(random_normal([conv1_window, input_dims, conv1_filters])),
  'out': tf.Variable(random_normal([conv1_filters, num_classes]))
}

biases = {
  # This line is the one that's wrong. Here I forgot to wrap the tf.zeros in a tf.Variable which is how I discovered the issue.
  'bc1': tf.zeros(conv1_filters),
  'out': tf.Variable(tf.zeros(num_classes))
}

def conv1d(x, W, b, stride=1):
  """"""
  Conv1D wrapper, with bias and relu activation.
  """"""
  x = tf.nn.conv1d(x, W, stride=stride, padding='SAME')
  x = tf.nn.bias_add(x, b)
  return tf.nn.relu(x)

def model(inputs):
  x = inputs
  x = conv1d(x, weights['wc1'], biases['bc1'])
  x = tf.add(tf.matmul(x, weights['out']), biases['out'])
  return tf.nn.softmax(x)

def cross_entropy(y_pred, y_true):
  y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)
  return -tf.reduce_sum(y_true * tf.math.log(y_pred)) / tf.reduce_sum(y_true)

def train_one_batch(optimizer, minibatch_x, minibatch_y):
  with tf.GradientTape() as g:
    pred = model(minibatch_x)
    loss = cross_entropy(pred, minibatch_y)
  trainable_variables = list(weights.values()) + list(biases.values())
  gradients = g.gradient(loss, trainable_variables)
  optimizer.apply_gradients(zip(gradients, trainable_variables))

batch_size = 2
sequence_len = 4
x = tf.zeros([batch_size, sequence_len, input_dims], dtype=tf.float32)
y = tf.ones([batch_size, sequence_len], dtype=tf.int64)
y_onehot = tf.one_hot(y, depth=num_classes)
optimizer = tf.optimizers.Adam()
train_one_batch(optimizer, x, y_onehot)
```

**Other info / logs**
```
Traceback (most recent call last):
  File ""code/tf_testcase.py"", line 58, in <module>
    train_one_batch(optimizer, x, y_onehot)
  File ""code/tf_testcase.py"", line 50, in train_one_batch
    optimizer.apply_gradients(zip(gradients, trainable_variables))
  File ""/home/ikhatri/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py"", line 427, in apply_gradients
    grads_and_vars = _filter_grads(grads_and_vars)
  File ""/home/ikhatri/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py"", line 1029, in _filter_grads
    ([v.name for v in vars_with_empty_grads]))
  File ""/home/ikhatri/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py"", line 1029, in <listcomp>
    ([v.name for v in vars_with_empty_grads]))
  File ""/home/ikhatri/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1090, in name
    ""Tensor.name is meaningless when eager execution is enabled."")
AttributeError: Tensor.name is meaningless when eager execution is enabled.
```
 "
34634,Why model.Summary() shows all layers in sub model.,"In old version(I forget which one). Sub model just shows model's name but not all layers.
But now,it shows all layers.

My versoin: TF2.0(GPU)

demo code:
```
class Swish(keras.layers.Layer):
    def __init__(self):
        super(Swish, self).__init__()
        self.weight = self.add_weight(initializer='uniform',trainable=True)

    def __call__(self, inputs):
        return inputs+tf.sigmoid(self.weight*inputs)
```"
34633,Profiling with Tensorboard is unable to catch GPU operations,"**System information**

- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow version (use command below):v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version:3.7.3
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.2
- GPU : P40

**Describe the current behavior**
Following the description in doc, I use the code snippet below to profile model.
```python3
log_dir=""logs/"" + datetime.now().strftime(""%Y%m%d-%H%M%S"")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = 3)

merge_model.fit(
    dataset, epochs=2, steps_per_epoch=100,
    validation_data=eval_dataset,
    validation_steps=66,
    validation_freq=1,
    callbacks=[tensorboard_callback]
)
```
But tensorboard callback only captured  cpu ops.
![image](https://user-images.githubusercontent.com/14145834/69692741-f459e300-110d-11ea-9391-e7900280ef96.png)

It's for sure that i'm using a gpu version tf and the device is used during training.

"
34632,[Performance Problem] The tf.image.crop_and_resize op costs much time during training,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/7.6.4
- GPU model and memory: GTX 1080Ti, 11Gb

**Problem Description**
Hi Dear experts, my question is about the performance problem on the `tf.image.crop_and_resize` op. My code is as follows:

    def roi_pooling(featuremap, boxes, box_inds, crop_size, data_format='channels_last'):
        if data_format == 'channels_first':
            shp2d = tf.shape(featuremap)[2:]
            featuremap = tf.transpose(featuremap, [0, 2, 3, 1])
        else:
            shp2d = tf.shape(featuremap)[1:3]
        feat_h, feat_w = tf.cast(shp2d[0], tf.float32), tf.cast(shp2d[1], tf.float32)
        xmin, ymin, xmax, ymax = tf.split(boxes, num_or_size_splits=4, axis=1)
        xmin /= feat_w
        ymin /= feat_h
        xmax /= feat_w
        ymax /= feat_h
        normalized_boxes = tf.concat([ymin, xmin, ymax, xmax], axis=1)
        normalized_boxes = tf.stop_gradient(normalized_boxes)
    
        box_features = tf.image.crop_and_resize(image=featuremap,
                                                boxes=normalized_boxes,
                                                box_ind=box_inds,
                                                crop_size=crop_size)  # nhwc
        box_features = tf.layers.average_pooling2d(inputs=box_features, pool_size=2,
                                                   strides=2, padding='valid',
                                                   data_format='channels_last')
    
        if data_format == 'channels_first':
            box_features = tf.transpose(box_features, [0, 3, 1, 2])  # nhwc --> nchw
    
        return box_features
    
And I've take the full trace of the training procedure using the `tensorflow.python.client.timeline` object and got the following tracing graph. 
![A0587B57-0D3A-49ba-81C9-56DC9332CB57](https://user-images.githubusercontent.com/43327429/69691790-01c19e00-110b-11ea-8eb3-85e3988eb209.png)

From this graph, we can see that the `tf.image.crop_and_resize` ops costs much time during one training step. So is this reasonable? Could you please give some advice on how to improve the performance? Thanks."
34631,Tutorial on basic classification needs some documentation improvement ,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue: 

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/tutorials/keras/classification/ 

## Description of issue (what needs changing):
One of the first step-by-step tutorial which explains a neural network is on Basic Classification [here](https://www.tensorflow.org/tutorials/keras/classification/). However, it can benefit from additional explanations on few terms like overfitting, optimizer etc.  

### Clear description
We add one line description for *overfitting*  to help user get a first hand idea of what *overfitting* does. Later, we add an extra line with a link to TensorFlow definition of overfit where user can find more information. The suggested changes  are expected to make it easier for users to get an intuitive understanding of the term.

### Correct links

Is the link to the source code correct? Yes

### Submit a pull request? 

Yes.

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
34622,Fold ADD with TRANSPOSECONV in tflite converter.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

- This is a feature request and also relative to performance issue.

**System information**
- TensorFlow version (you are using):
tf-nightly '2.1.0-dev20191126'
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**
For generating _.tflite_ file with [_TFLiteConverter_](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter), when model contains [_Conv2DTranspose_](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose) layers, bias cannot fold into Operator TRANSPOSECONV. It will result with extra Op ADD following Op TRANSPOSECONV.
But with other CONV-like layers (Conv2D, DepthwiseConv2D), bias will be fold into CONV layer.

- [ ] **bias should fold into Op TRANSPOSECONV in tflite.**

Reproduce current behaviors with example code and model graph:
```
def get_keras_model():
    input_0 = tf.keras.layers.Input(shape=[100,100,3])
    # Conv2D with bias
    conv_0 = tf.keras.layers.Conv2D(filters=3, kernel_size=[3, 3],
                                    use_bias=True, padding=""same"",
                                    kernel_initializer=tf.random_uniform_initializer,
                                    bias_initializer=tf.random_uniform_initializer)(input_0)
    # Conv2D without bias
    conv_1 = tf.keras.layers.Conv2D(filters=3, kernel_size=[3, 3],
                                    use_bias=False, padding=""same"",
                                    kernel_initializer=tf.random_uniform_initializer)(conv_0)
    # DepthwiseConv2D with bias
    depthwise_conv_0 = tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3],
                                                       use_bias=True, padding=""same"",
                                                       kernel_initializer=tf.random_uniform_initializer,
                                                       bias_initializer=tf.random_uniform_initializer)(conv_1)
    # DepthiseConv2D without bias
    depthwise_conv_1 = tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3],
                                                       use_bias=False, padding=""same"",
                                                       kernel_initializer=tf.random_uniform_initializer)(depthwise_conv_0)
    # TrasposeConv with bias
    transpose_conv_0 = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=[3,3],
                                                       use_bias=True, padding=""same"",
                                                       kernel_initializer=tf.random_uniform_initializer,
                                                       bias_initializer=tf.random_uniform_initializer)(depthwise_conv_1)
    # TrasposeConv without bias
    transpose_conv_1 = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=[3, 3],
                                                       use_bias=False, padding=""same"",
                                                       kernel_initializer=tf.random_uniform_initializer)(transpose_conv_0)

    keras_model = tf.keras.models.Model(inputs=[input_0], outputs=[transpose_conv_1])

    return keras_model


def gen_tflite():

    keras_model = get_keras_model()
    keras_model.compile(loss=tf.keras.losses.categorical_crossentropy,
                        optimizer='adam',
                        metrics=['accuracy'])
    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
    tflite_quant_model = converter.convert()
    open('conv.tflite', 'wb').write(tflite_quant_model)

gen_tflite()
```
As the graph below shows, _TFLiteConverter_ will fold bias with Conv2D and Depthwise2D, but not fold bias with TransposeConv:
![image](https://user-images.githubusercontent.com/55463253/69658482-2f0f3d00-1074-11ea-944f-f46fe3723453.png)

**Will this change the current api? How?**

It will not affect any TF python api.
It will affect [tflite](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/transpose_conv.cc#L341) as bias added.

**Who will benefit with this feature?**

Users of TensorFlow, as 

- consistent implementation/behavior between conv-like layers

- Performance boost when tflite running on device, as TRANSPOSECONV + ADD folded into TRANSPOSECONV

**Any Other info.**
N/A"
34620,Batch size reset to 1 after conversion,"**System information**
- OS Platform and Distribution Windows 10 and Ubuntu 64 bit
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): 2.0.0


**Command used to run the converter or code if you’re using the Python API**
```python
x=tf.keras.Input(shape=(256,1), batch_size=50)
y=tf.keras.layers.Convolution1D(kernel_size=5,filters=8,input_shape=(50,256,1))(x)
model=tf.keras.Model(x,y)
# compile and train
# ... 
converter=tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
converter.representative_dataset = setgen
modelq=converter.convert()

conv_interpreter=tf.lite.Interpreter(model_content=modelq)
input_details = conv_interpreter.get_input_details()
```

**The output from the converter invocation**

```
{'name': 'input_5',
 'index': 8,
 'shape': array([   1, 256,    1]),
 'dtype': numpy.float32,
 'quantization': (0.0, 0)}
```

**Failure details**
Despite before conversion the batch size is explicitly set to 50, after conversion the batch size is always 1.
The reason why I am trying to have batch size >1 is because the model has to be executed in the edge TPU and I want to exploit as best the parallelism offered by the chip, thus performing the convolution on as many inputs as possible in parallel.
If not supported by TF Lite, any suggestion to achieve the same result is welcome and appreciated
"
34619,Wrong output printing when using fit_generator,"On TensorFlow 1.15 (OS Ubuntu 16.04), when I'm using generators to train a model via the tf.keras.model fit_generator() function call prints a wrong and duplicated output of ""Epoch 1"" when starting the validation steps on every epoch.  The function fit_generator() prints:

```
Epoch 1/2
Epoch 1/2
32/32 - 5s - loss: 2.3132 - val_loss: 2.3116
Epoch 2/2
Epoch 1/2
32/32 - 1s - loss: 2.3070 - val_loss: 2.3075
```

The minimal code to reproduce is:

```
import math
import tensorflow as tf
from tensorflow.keras.utils import to_categorical


def data_generator(X, Y, batch_size, start=0, end=None):
    end = len(X) if end is None else end
    num_batches = int(math.ceil((end-start)/batch_size))
    while True:
        lob = list(range(num_batches))
        for bi in lob:
            sb = start + bi*batch_size
            eb = sb + batch_size
            eb = end if eb > end else eb
            Xb = X[sb:eb]
            Yb = Y[sb:eb]
            yield Xb, Yb


(Xtr, Ytr), (Xva, Yva) = tf.keras.datasets.cifar10.load_data()
Xtr, Ytr, Xva, Yva, nc = Xtr[:1000], Ytr[:1000], Xva[:100], Yva[:100], 10
Xtr, Xva = Xtr.astype('float32') / 255, Xva.astype('float32') / 255
Ytr, Yva, ins = to_categorical(Ytr, nc), to_categorical(Yva, nc), Xtr.shape[1:]

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Input(ins))
model.add(tf.keras.layers.Conv2D(8, (3, 3)))
model.add(tf.keras.layers.Activation('relu'))
model.add(tf.keras.layers.Conv2D(8, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.25))
model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))
model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.25))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(nc, activation='softmax'))
opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[])

batch_size = 32
tr_gen = data_generator(Xtr, Ytr, batch_size)
va_gen = data_generator(Xva, Yva, batch_size)
tr_steps = int(math.ceil(len(Xtr)/batch_size))
va_steps = int(math.ceil(len(Xva)/batch_size))

model.fit_generator(tr_gen, steps_per_epoch=tr_steps, epochs=2, verbose=2,
                    validation_data=va_gen, validation_steps=va_steps)
```

If I run it on TensorFlow 2.0, the duplicated and wrong prints disappear."
34618,Support exporting the transform graph from tf.Transform together with the model graph defined using Keras to SavedModel in TensorFlow 2.0,"**System information**
- TensorFlow version (you are using): TensorFlow 2.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
The feature is:  improve `tf.saved.saved_model` Api in Keras and support exporting the transform graph from tf.Transform and the graph from the Keras model together into a single SavedModel.

**Current behavior/state** about how to export transform graph and model graph together to a SavedModel?  
Estimator (Work well):  
From [tf.transform official tutorial](https://github.com/tensorflow/transform/blob/cf517f1a8765e6552d09cee65efea80e26c05f5e/examples/census_example.py#L380-L382), at the stage of exporting model, it will call [estimator.export_saved_model(exported_model_dir, serving_input_fn)](https://github.com/tensorflow/estimator/blob/b22a912de2693322622d6f50e3a19e98fecac441/tensorflow_estimator/python/estimator/estimator.py#L661) to complete the model exporting work. Inside its implementation, it calls serving_input_fn to load the transform graph from SavedModel at first, and then calls estimator's model_fn to generate the model graph, combines these two graph into one graph and finally exports it into one SavedModel. Please check the [code snippet](https://github.com/tensorflow/estimator/blob/43921b4552d1c30acc31d3b5989112cb397383e0/tensorflow_estimator/python/estimator/estimator.py#L926-L937).  

Keras (Can not):  
For TF2.0, we define a model using keras and exports it by calling [tf.saved.saved_model](https://www.tensorflow.org/api_docs/python/tf/saved_model/save). This SavedModel only contains the model definition including feature columns and network structure. `tf.saved.saved_model` api doesn't have the parameter `serving_input_fn` just like estimator and **it lacks the flexibility to combine transform graph and model graph together for inference**.

**Will this change the current api? How?**
Will change the Api `tf.saved.save_model`, add a new parameter `serving_input_fn`.

**Who will benefit with this feature?**
The users of tf.Transform and TensorFlow 2.0

**Any Other info.**
"
34617,ValueError: model_fn (<tensorflow.python.eager.def_function.Function object at 0x7f0391abc4a8>) must include features argument.,"I have been trying to solve this for 5 hours but to no avails. Kindly help if any of you have solved this. I have renamed all the variable accordingly but it still says, value error. I can share my code with you if you want. 
I am using **Tensorflow 2.0**"
34615,Fail to load frozen model converted from FP32 to FP16 because of type mismatch,"Hi, I was converting tensorflow frozen pb model from fp32 to fp16 using a method in this [post](https://stackoverflow.com/questions/55827368/loading-tensorflow-object-detection-model-post-training-quantization-to-fp16-is?noredirect=1#comment104009065_55827368). The conversion succeeded (the model I used was [ssd mobilenet v2 coco](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)). But when I try to load the converted model, error `ValueError: Input 0 of node Preprocessor/map/while/Enter_2 was passed float from Preprocessor/map/TensorArray_1:1 incompatible with expected half.` was raised. Then I checked the node information in the converted model in pbtxt format, the node `Preprocessor/map/TensorArray_1` was a `TensorArrayV3` as this one:
```
node {
  name: ""Preprocessor/map/TensorArray_1""
  op: ""TensorArrayV3""
  input: ""Preprocessor/map/strided_slice""
  attr {
    key: ""clear_after_read""
    value {
      b: true
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_HALF
    }
  }
  attr {
    key: ""dynamic_size""
    value {
      b: false
    }
  }
  attr {
    key: ""element_shape""
    value {
      shape {
        unknown_rank: true
      }
    }
  }
  attr {
    key: ""identical_element_shapes""
    value {
      b: true
    }
  }
  attr {
    key: ""tensor_array_name""
    value {
      s: """"
    }
  }
}
```
And the output node `Preprocessor/map/while/Enter_2` was:
```
node {
  name: ""Preprocessor/map/while/Enter_2""
  op: ""Enter""
  input: ""Preprocessor/map/TensorArray_1:1""
  attr {
    key: ""T""
    value {
      type: DT_HALF
    }
  }
  attr {
    key: ""frame_name""
    value {
      s: ""Preprocessor/map/while/while_context""
    }
  }
  attr {
    key: ""is_constant""
    value {
      b: false
    }
  }
  attr {
    key: ""parallel_iterations""
    value {
      i: 32
    }
  }
}
```
The node's [type](https://www.tensorflow.org/api_docs/python/tf/TensorArray) was DT_HALF, which indicated FP16 as expected. But according to the error information, the first node seemed export a FP32 node rather than FP16 value. So I'm confused about the source of FP32: where does this FP32 info come from? If the op `Enter` requires FP16? Any explanation about loading frozen model is really appreciated! Thanks!"
34614,遇到ValueError: Invalid tensors 'input/input_data:0' were found.,"遇到ValueError: Invalid tensors 'input/input_data:0' were found.
同样问题，请问有谁解决了吗？帮我， 'input/input_data:0' 是我测试pb模型是的输入变量名，但是转tflite时，报上述错误。谢谢。。。
"
34613,try,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34612,Build a static tensorflow on Alpine linux ,"Any instructions, documents or blogs show us how to build static library of tensorflow on Alpine linux? I want to port the object detection model(and other) to aws lambda, build tensorflow as a static library could save a lot of troubles"
34610,Difference output when dumb freeze .pb from .hdf5,"Hi I'm trying to dumb frozen .pb graph from .hdf5 file but I my .pb have difference output with .h5 file 
### input and output name of .hdf5 file
```bash
All input nodes: [<tf.Tensor 'input_1:0' shape=(?, 256, 320, 3) dtype=float32>]
All output nodes: [<tf.Tensor 'fcn17/truediv:0' shape=(?, ?, ?, 4) dtype=float32>]
```
### and output value of hdf5 file like this: 
```bash
array([[[[0.95520484, 0.02454368, 0.01151993, 0.0087315 ],
         [0.96743697, 0.01915975, 0.00736554, 0.00603788],
         [0.97429854, 0.01614887, 0.00556678, 0.00398591],
         ...,
         [0.96292394, 0.01786121, 0.00704672, 0.01216816],
         [0.95855474, 0.02005052, 0.00870537, 0.0126894 ],
         [0.9483133 , 0.02560406, 0.01250436, 0.01357825]],
         ...,
         [0.6439966 , 0.33929765, 0.01019213, 0.00651362],
         [0.64723253, 0.3306629 , 0.01337334, 0.00873124],
         [0.649275  , 0.3211698 , 0.01852187, 0.0110333 ]]]],
      dtype=float32)
```
###  this is output of .pb file ( 'fcn17/truediv:0' ) : 
```bash
[[[0.24999999 0.25       0.25       0.25      ]
  [0.25       0.25       0.25       0.25      ]
  [0.25       0.25       0.24999999 0.24999999]
  ...
  [0.25       0.25       0.25       0.25      ]
  [0.25       0.25       0.25       0.25      ]
  [0.25       0.25       0.25       0.25      ]]]
```
and i see my output of hdf5 file difference pb file
### this is my code i try to dumb freeze graph from hdf5 file 
```bash
def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):
    """"""
    Freezes the state of a session into a pruned computation graph.

    Creates a new computation graph where variable nodes are replaced by
    constants taking their current value in the session. The new graph will be
    pruned so subgraphs that are not necessary to compute the requested
    outputs are removed.
    @param session The TensorFlow session to be frozen.
    @param keep_var_names A list of variable names that should not be frozen,
                          or None to freeze all the variables in the graph.
    @param output_names Names of the relevant graph outputs.
    @param clear_devices Remove the device directives from the graph for better portability.
    @return The frozen graph definition.
    """"""
    graph = session.graph
    with graph.as_default():
        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))
        output_names = output_names or []
        output_names += [v.op.name for v in tf.global_variables()]
        input_graph_def = graph.as_graph_def()
        if clear_devices:
            for node in input_graph_def.node:
                node.device = """"
        frozen_graph = tf.graph_util.convert_variables_to_constants(
            session, input_graph_def, output_names, freeze_var_names)
        return frozen_graph

def freeze_graph_keras(net, model_dir):
    """"""Extract the sub graph defined by the output nodes and convert 
    all its variables into constant 
    Args:
        model_dir: the root folder containing the checkpoint state file
        output_node_names: a string, containing all the output node's names, 
                            comma separated
    """"""

    # The export path contains the name and the version of the model
    tf.keras.backend.set_learning_phase(0)  # Ignore dropout at inference
    file_name = os.path.basename(model_dir).replace('.hdf5', '.pb')
    model_dir = os.path.dirname(model_dir)
    print(os.path.join(model_dir, file_name))
    with tf.keras.backend.get_session() as sess:
        tf.initialize_all_variables().run()
        frozen_graph = freeze_session(K.get_session(),
                                      output_names=[out.op.name for out in net.outputs])
        tf.train.write_graph(frozen_graph, model_dir,
                             file_name, as_text=False)
    print('All input nodes:', net.inputs)
    print('All output nodes:', net.outputs)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(""--model_dir"", type=str,
                        default=""path.hdf5"", help=""Model folder to export"")

    args = parser.parse_args()                    

    model = build_my_model((256,320,3), num_classes=4,
                    lr_init=1e-3, lr_decay=5e-4)
    model.load_weights('path')
    freeze_graph_keras(model, args.model_dir)
```
I'm using tensorflow version 1.14.0 and keras 2.2.4"
34609,tf.function retracing for multigpu(mirrored_strategy) operations(tf.keras.models),"**System information**
- Have I [written]() custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ('CentOS Linux', '7.6.1810', 'Core')
- os platform: Linux-3.10.0-862.14.4.el7.x86_64-x86_64-with-centos-7.6.1810-Core
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): No
- TensorFlow version (use command below): unknown 2.0.0
- Python version: 3.7.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:  cudatoolkit-10.0.130 / cudnn-7.6.4 
- GPU model and memory: TITAN Xp   (12G) * 8

**Describe the current behavior**

Currently I have 8 gpus in develop environment(titanxp's), and converting single gpu training model using tf.distributed.mirror_strategy & tf.function gives slow training(gpu uses) and print WARNINGS below.
Since I confirmed model trains well in single gpu environment, I Wrote simple test code similar to the structure of my actual code of my model, which shows the same WARNINGS.

`W1126 17:46:13.538742 139942541895424 def_function.py:474] 5 out of the last 5 calls to <function inference at 0x7f4a76ab12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxesargument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
W1126 17:46:13.584210 139942533502720 def_function.py:474] 6 out of the last 6 calls to <function inference at 0x7f4a76ab12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxesargument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
W1126 17:46:13.634693 139941979879168 def_function.py:474] 7 out of the last 7 calls to <function inference at 0x7f4a76ab12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxesargument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
W1126 17:46:13.689692 139941971486464 def_function.py:474] 8 out of the last 8 calls to <function inference at 0x7f4a76ab12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxesargument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.`

I wonder if this retracing could occur from restricted network policy or outdated kernels. Since this workstation is originally intended for the service purpose so it is under strong monitoring for network packets(ports). I found mirrored_strategy open several network ports randomly at startup.

**Describe the expected behavior**
No retracing warnings with fully dedicated GPU usages.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
import tensorflow as tf
import os, sys
from tensorflow.keras import layers
from tensorflow.python.keras import backend, layers, models, utils
from os.path import join, basename, dirname
from os import listdir
tf.__version__
tf.executing_eagerly()

mirrored_strategy = tf.distribute.MirroredStrategy()#devices=[""/gpu:0"", ""/gpu:1""])#devices=[""/gpu:0"", ""/gpu:1""])#,
                                                  #cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
    
def create_model():
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu'),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Conv2D(64, 3, activation='relu'),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10, activation='softmax')
    ])

  return model


with mirrored_strategy.scope():
    
    inp = layers.Input([240,320,6])
    
    
    test = create_model()
    

@tf.function
def inference(input):
    return test(input)
@tf.function
def inf():
    with mirrored_strategy.scope():
            mirrored_strategy.experimental_run_v2(inference, args=(tf.random.normal(shape=[32,240,320,3]),)) 

inf()

```
**Other info / logs**
Although I remove the loss calculation and optimizations, I checked this retracing occurs irrelevant to the loss or optimization steps."
34608, whether tflite can not support the two operator ( MaxPool2D and QUANTIZE) in TensorFlow 2.0.0 when running the mode in embed freeRTOS system?,"**System information**
- OS Platform and Distribution : Window 7
- TensorFlow installed from : Install TensorFlow 2.0.0  by anaconda. It should be binary
- TensorFlow version (or github SHA if from source): 2.0.0


**Provide the text output from tflite_convert**
Below is the tf.lite.convert output information after convert finished.
```
2019-11-26 16:16:17.608537: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-26 16:16:17.609537: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-26 16:16:17.712547: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-26 16:16:17.712547: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 8.001ms.
2019-11-26 16:16:17.712547: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-26 16:16:17.738550: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-26 16:16:17.739550: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-26 16:16:17.807557: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-26 16:16:17.808557: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 15 nodes (-4), 18 edges (-4), time = 52.005ms.
2019-11-26 16:16:17.808557: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 15 nodes (0), 18 edges (0), time = 1ms.
INFO: Initialized TensorFlow Lite runtime.
generate: ./cnn.tflite
```

Also, please include a link to a GraphDef or the model if possible.
My first model code:
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(filters=32,   kernel_size=[5, 5],  padding='same',
                                activation=tf.nn.relu,input_shape=(feature_cnt_max, feature_dim_cnt,1)))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2))
model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=[3, 3],padding='same',activation=tf.nn.relu))
model.add(tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(units=num_fc_hide,activation=tf.nn.relu))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(units=num_class,activation=tf.nn.softmax))
model.build(input_shape=(None,feature_cnt_max, feature_dim_cnt,1))

My second model code:
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(filters=186,
                                kernel_size=[first_filter_height, first_filter_width],
                                padding='valid',
                                activation=tf.nn.relu,input_shape=(feature_cnt_max, feature_dim_cnt,1)))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(units=num_class,activation=tf.nn.softmax))
model.build(input_shape=(None,feature_cnt_max, feature_dim_cnt,1))


**Any other info / logs**
I convert the two model into *tflite by below code:
(https://github.com/tensorflow/tensorflow/files/3890814/covert_h5_to_tflite.txt)

covert_h5_to_tflite.py
My question is:
1: When i use the first model and do not do quantization, i meet the the err info report ""Didn't find op for builtin opcode 'MaxPool2D' version '1'"" when run the the model in my Embedded freeRTOS system.
2: When i use the second model and do quantization, i meet the the err info report ""Didn't find op for builtin opcode 'QUANTIZE' version '1'"" when run the the model in my Embedded freeRTOS system.
3: Below code add the TF_OPS, but the tflite are same with no TF_OPS, why?
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]

So i want to know whether tflite can not support the two operator ( MaxPool2D and QUANTIZE) in tensorflow 2.0.0? How about tensorflow 1.1x?

"
34607,ModuleNotFoundError: No module named 'tensorflow_core.keras' in Flask,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS X 10.15.1 Catalina
- TensorFlow version: 1.15.0
- Python version: 3.7.3
- virtualenv (Flask)

**Describe the problem**
I'm unable to import and run a model using Flask services because of this error: ModuleNotFoundError: No module named 'tensorflow_core.keras'

**Provide the exact sequence of commands / steps that you executed before running into the problem**
- I have pip installed keras and tensorflow into my virtualenv (I've also tried pip3 install)
- My code is like this:
```
import tensorflow as tf
from keras.models import load_model
model = load_model(""model.hdf5"")
# ... preprocess images
predictions = model.predict(processed_images)
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
Traceback (most recent call last):
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/bin/flask"", line 8, in <module>
    sys.exit(main())
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/flask/cli.py"", line 966, in main
    cli.main(prog_name=""python -m flask"" if as_module else None)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/flask/cli.py"", line 586, in main
    return super(FlaskGroup, self).main(*args, **kwargs)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/click/core.py"", line 717, in main
    rv = self.invoke(ctx)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/click/core.py"", line 1137, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/click/core.py"", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/click/core.py"", line 555, in invoke
    return callback(*args, **kwargs)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/click/decorators.py"", line 64, in new_func
    return ctx.invoke(f, obj, *args, **kwargs)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/click/core.py"", line 555, in invoke
    return callback(*args, **kwargs)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/flask/cli.py"", line 860, in run_command
    extra_files=extra_files,
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/werkzeug/serving.py"", line 1008, in run_simple
    run_with_reloader(inner, extra_files, reloader_interval, reloader_type)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/werkzeug/_reloader.py"", line 337, in run_with_reloader
    reloader.run()
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/werkzeug/_reloader.py"", line 202, in run
    for filename in chain(_iter_module_files(), self.extra_files):
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/werkzeug/_reloader.py"", line 24, in _iter_module_files
    filename = getattr(module, ""__file__"", None)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/tensorflow/__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/tensorflow/__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""/Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 965, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'tensorflow_core.keras'
Using TensorFlow backend.
Using TensorFlow backend.
WARNING:tensorflow:From /Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

2019-11-26 15:33:29.703531: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb84403e4f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-26 15:33:29.703585: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-26 15:33:29.705059: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1f9bbcd00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-26 15:33:29.705389: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /Users/llemonthyme/Desktop/traffic-app/flaskservice/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.
```"
34606,Memory leak when append predictions to list,"When append prediction tensors to list, gpu memory will gradually increase, the occupied memory (model memory) will not be released (even when move the model prediction in @tf.function)
```
for data in dataset:
    pred = model(...)
    preds.append(pred)
```
this works as expected
```
for data in dataset:
  pred = model(...)
  preds.append(np.array(pred))
```"
34605,tensorflow::Node*->out_edges() BUG ,"I am writing my own graph optimization pass as a customized lib, which is register as follows: 
```

REGISTER_OPTIMIZATION(OptimizationPassRegistry::PRE_PLACEMENT, 0,
                      PartOptimization);
```

when I use the tensorflow::Node* -> out_edges() interfaces to rewrite the output nodes, I always get the number of output edges which is one less than the number tensorflow::Node* -> out_edges().size() gives me. This bugs me for quite a while. I am not sure if I use it the wrong way, or simply I register my pass in the wrong phase, or there is indeed some what bug (which I think is unlikely).

Any insights will be appreciated! 

I am using tf-v.1.15
```
class PartOptimization : public GraphOptimizationPass
{
public:
    Status Run(const GraphOptimizationPassOptions &options) override
    {
        Graph *g = options.graph->get();
        for (auto n : g->op_nodes())
        {
            cout << n->DebugString() << endl;
            cout << ""sizeof int edges: "" << n->in_edges().size() << endl;
            for (const Edge *e : n->in_edges())
                cout << e->DebugString() << endl;
            cout << ""sizeof out edges: "" << n->out_edges().size() << endl;
            for (const Edge *e : n->out_edges())
            if(e)
                cout << e->DebugString() << endl;
            cout << endl;
        }

        return Status::OK();
    }

REGISTER_OPTIMIZATION(OptimizationPassRegistry::PRE_PLACEMENT, 0,
                      PartOptimization);
```

my toy model for testing:
```
import tensorflow as tf
tf.load_library('./tf_graph_partition.so')

a = tf.Variable(tf.zeros([10]))
b = tf.Variable(tf.ones([10]))
c = tf.add(a,b)
d = tf.multiply(a, c)
e = tf.add(a,d)
f = tf.multiply(a, e)

with tf.Session() as sess:
    sess.run(tf.compat.v1.global_variables_initializer())
    print(sess.run(f))

```

And the result is like:
```
{name:'save/Assign_1' id:23 op device:{} def:{{{node save/Assign_1}} = Assign[T=DT_FLOAT, _class=[""loc:@w2""], use_locking=true, validate_shape=true](w2, save/RestoreV2:1)}}
sizeof int edges: 2
[id=25 w2:0 -> save/Assign_1:0]
[id=26 save/RestoreV2:1 -> save/Assign_1:1]
sizeof out edges: 1

{name:'w2' id:7 op device:{} def:{{{node w2}} = VariableV2[container="""", dtype=DT_FLOAT, shape=[2], shared_name=""""]()}}
sizeof int edges: 1
[id=34 _SOURCE:-1 -> w2:-1]
sizeof out edges: 4
[id=6 w2:0 -> w2/read:0]
[id=17 w2:0 -> save/SaveV2:4]
[id=25 w2:0 -> save/Assign_1:0]

```



@tensorflower-gardener "
34604,How to quickly add extract_image_patch op support in tflite?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
- TensorFlow installed from (source or binary):Source
- TensorFlow version (or github SHA if from source):1.14


**Command used to run the converter or code if you’re using the Python API**

```
import tensorflow as tf
saved_model_dir=""./""
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
#converter.allow_custom_ops=True
tflite_model = converter.convert()
open(""./converted_model.tflite"", ""wb"").write(tflite_model)
```

**The output from the converter invocation**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, ELU, LOGISTIC, MAXIMUM, MINIMUM, MUL, RELU, RESHAPE, RESIZE_NEAREST_NEIGHBOR, REVERSE_V2, SOFTMAX, SPLIT, SQRT, SQUARE, STRIDED_SLICE, SUM, TANH, TRANSPOSE, TRANSPOSE_CONV. Here is a list of operators for which you will need custom implementations: ExtractImagePatches.
Traceback (most recent call last):
  File ""/home/siju/.local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/home/siju/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/siju/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/siju/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/siju/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/siju/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, ELU, LOGISTIC, MAXIMUM, MINIMUM, MUL, RELU, RESHAPE, RESIZE_NEAREST_NEIGHBOR, REVERSE_V2, SOFTMAX, SPLIT, SQRT, SQUARE, STRIDED_SLICE, SUM, TANH, TRANSPOSE, TRANSPOSE_CONV. Here is a list of operators for which you will need custom implementations: ExtractImagePatches.
```

**Also, please include a link to the saved model or GraphDef**

[saved_model.zip](https://github.com/tensorflow/tensorflow/files/3890254/saved_model.zip)


**Failure details**
I want to implement a block of contextual attenuation which contains op
[extract image patches](https://www.tensorflow.org/api_docs/python/tf/image/extract_patches)
This op is not the first/last one. its in the middle so that i cannot do the processing outside the model.

**Any other info / logs**
NO

"
34603,Unable to save model using tf.saved_model when model outputs RaggedTensor,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Darwin Kernel Version 19.0.0: macOS Catalina
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.4

**Describe the current behavior**
Using `tf.function` seems to work fine for autographing functions that take a `RaggedTensor` as input and produce a `RaggedTensor` as the output. However, serializing such a module using `tf.saved_model.save()` seems to not work.

We run into
```
2019-11-25 20:39:57.800887: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-25 20:39:57.809936: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1e014a930 executing computations on platform Host. Devices:
2019-11-25 20:39:57.809946: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-25 20:39:58.145214: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
Traceback (most recent call last):
  File ""/Users/raghavmehta/Developer/UCSD-NLP/blah.py"", line 26, in <module>
    main()
  File ""/Users/raghavmehta/Developer/UCSD-NLP/blah.py"", line 22, in main
    tf.saved_model.save(my_module, 'model/', signatures=my_module.my_func)
  File ""/Users/raghavmehta/.local/share/virtualenvs/UCSD-NLP-eKFj1XZo/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 893, in save
    meta_graph_def, saveable_view, signatures, options.namespace_whitelist)
  File ""/Users/raghavmehta/.local/share/virtualenvs/UCSD-NLP-eKFj1XZo/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 593, in _fill_meta_graph_def
    signatures = _generate_signatures(signature_functions, resource_map)
  File ""/Users/raghavmehta/.local/share/virtualenvs/UCSD-NLP-eKFj1XZo/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 468, in _generate_signatures
    _tensor_dict_to_tensorinfo(outputs),
  File ""/Users/raghavmehta/.local/share/virtualenvs/UCSD-NLP-eKFj1XZo/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 308, in _tensor_dict_to_tensorinfo
    for key, value in tensor_dict.items()}
  File ""/Users/raghavmehta/.local/share/virtualenvs/UCSD-NLP-eKFj1XZo/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 308, in <dictcomp>
    for key, value in tensor_dict.items()}
  File ""/Users/raghavmehta/.local/share/virtualenvs/UCSD-NLP-eKFj1XZo/lib/python3.7/site-packages/tensorflow_core/python/saved_model/utils_impl.py"", line 70, in build_tensor_info_internal
    tensor_shape=tensor.get_shape().as_proto())
AttributeError: 'RaggedTensor' object has no attribute 'get_shape'
```

**Describe the expected behavior**
`tf.saved_model.save()` should work naturally for autographed functions even if they output a `RaggedTensor`.

**Code to reproduce the issue**
```python
import tensorflow as tf


class MyModule(tf.Module):
    def __init__(self, name='my_module'):
        super(MyModule, self).__init__(name=name)

    @tf.function(input_signature=[
        tf.RaggedTensorSpec(shape=(None, None), dtype=tf.string)
    ])
    def my_func(self, inputs):
        return tf.ragged.constant([
            ['Some', 'string'],
            ['Some', 'other', 'string']
        ])


def main():
    my_module = MyModule()
    my_module.my_func(tf.ragged.constant([['random', 'input']]))
    # Returns <tf.RaggedTensor [[b'Some', b'string'], [b'Some', b'other', b'string']]> correctly!
    tf.saved_model.save(my_module, 'model/', signatures=my_module.my_func)


if __name__ == '__main__':
    main()
```
**Other info / logs**
Saving a model that takes `RaggedTensor` as an input but returns a regular `Tensor` as the output using `tf.saved_model.save()` seems to work just fine."
34600,Rewrite SECURITY.md with technical writing,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style

Rewriting SECURITY.md with technical writing for better understanding."
34598,Description in README.md can be more descriptive,Description of Tensorflow in README.md can be more descriptive.
34595,Custom loss with VGG16 features works in keras and doesn't work in tf.keras,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab. Ubuntu 18.04.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.15
- Python version: 3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

I'm using tensorflow.keras with TF 1.15 in Colab. I have custom loss function that loads VGG16 from tf.keras and does feature extraction from y_pred and y_true. This feature extraction works if I pass as arguments either y_true or y_pred or any expression without y_true. If I pass expression with y_true and something else it raises error: `You must feed a value for placeholder tensor 'dense_4_target' with dtype float and shape [?,?,?,?]
	 [[{{node dense_4_target}}]]` The same code works when I change tensorflow.keras to just keras.

**Describe the expected behavior**

Model should compile without errors as in pure Keras

**Code to reproduce the issue**
Please find gist [here](https://colab.research.google.com/gist/muxgt/c467f0a999f3a517264040465af4a5a0/untitled10.ipynb#scrollTo=GEBbaquGImyU)
"
34594,Reading/Writing via Azure blob storage APIs.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version 1.14:
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Similar to GCS FileSystem and S3 Filesystem, there could be a Azure FileSystem which could access data in azure blob storage using the azure blob storage APIs.

**Will this change the current api? How?**

No. Only another implementation for a new storage system.

**Who will benefit with this feature?**

Anyone who runs tensorflow over files on Azure blob storage.

**Any Other info.**
"
34592,TensorFlow SavedModel export fails with AttributeError,"I'm following the tutorial exactly as it is here: https://www.tensorflow.org/tutorials/keras/text_classification_with_hub

Finally, if I want to export the trained model from this tutorial using model.save() I get this error message:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-19-768eb5acd4e8> in <module>()
      3 
      4 export_path = ""/tmp/saved_models/{}"".format(int(t))
----> 5 model.save(export_path, save_format='tf')

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
    984     """"""
    985     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,
--> 986                       signatures, options)
    987 
    988   def save_weights(self, filepath, overwrite=True, save_format=None):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--> 115                           signatures, options)
    116 
    117 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     72   # default learning phase placeholder.
     73   with K.learning_phase_scope(0):
---> 74     save_lib.save(model, filepath, signatures, options)
     75 
     76   if not include_optimizer:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    905   # Note we run this twice since, while constructing the view the first time
    906   # there can be side effects of creating variables.
--> 907   _ = _SaveableView(checkpoint_graph_view)
    908   saveable_view = _SaveableView(checkpoint_graph_view)
    909 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py in __init__(self, checkpoint_view)
    189           concrete_functions = [function]
    190         for concrete_function in concrete_functions:
--> 191           if concrete_function.name not in seen_function_names:
    192             seen_function_names.add(concrete_function.name)
    193             self.concrete_functions.append(concrete_function)

AttributeError: 'NoneType' object has no attribute 'name'
```

What's going on? Shouldn't it be possible to simply export this model to the `SavedModel` format? I'm trying with and without the `save_format='tf'` parameter."
34591,TensorFlow SavedModel export fails with AttributeError,"I'm following the tutorial exactly as it is here: https://www.tensorflow.org/tutorials/keras/text_classification_with_hub

Finally, if I want to export the trained model from this tutorial using model.save() I get this error message:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-19-768eb5acd4e8> in <module>()
      3 
      4 export_path = ""/tmp/saved_models/{}"".format(int(t))
----> 5 model.save(export_path, save_format='tf')

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
    984     """"""
    985     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,
--> 986                       signatures, options)
    987 
    988   def save_weights(self, filepath, overwrite=True, save_format=None):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--> 115                           signatures, options)
    116 
    117 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     72   # default learning phase placeholder.
     73   with K.learning_phase_scope(0):
---> 74     save_lib.save(model, filepath, signatures, options)
     75 
     76   if not include_optimizer:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    905   # Note we run this twice since, while constructing the view the first time
    906   # there can be side effects of creating variables.
--> 907   _ = _SaveableView(checkpoint_graph_view)
    908   saveable_view = _SaveableView(checkpoint_graph_view)
    909 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py in __init__(self, checkpoint_view)
    189           concrete_functions = [function]
    190         for concrete_function in concrete_functions:
--> 191           if concrete_function.name not in seen_function_names:
    192             seen_function_names.add(concrete_function.name)
    193             self.concrete_functions.append(concrete_function)

AttributeError: 'NoneType' object has no attribute 'name'
```

What's going on? Shouldn't it be possible to simply export this model to the `SavedModel` format? I tried with and without the `save_format='tf'` parameter

"
34588,training with dataset cifar100fails: KeyError: 'conv2d_input,"**System information**System information
- OS Platform and Distribution: Arch Linux, 5.3.7-arch1-1-ARCH
- TensorFlow installed from: binary
- TensorFlow version: 2.0.0
- Keras version: 2.2.4-tf
- Python version: 3.7.4
- CUDA/cuDNN version: CUDA 10.1.243 / cuDNN 7.6.2.24
- GPU model and memory: 2x GTX 1080 Ti 11GB""`

**Describe the current behavior**
exception thrown: ""KeyError: 'conv2d_input'""

**backtrace**

> Epoch 1/10
>       1/Unknown - 0s 70ms/stepTraceback (most recent call last):
>   File ""cifar100.py"", line 35, in <module>
>     verbose=1)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
>     use_multiprocessing=use_multiprocessing)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
>     total_epochs=epochs)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
>     batch_outs = execution_function(iterator)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
>     distributed_function(input_fn))
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
>     result = self._call(*args, **kwds)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 503, in _call
>     self._initialize(args, kwds, add_initializers_to=initializer_map)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
>     *args, **kwds))
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
>     graph_function, _, _ = self._maybe_define_function(args, kwargs)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
>     graph_function = self._create_graph_function(args, kwargs)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
>     capture_by_value=self._capture_by_value),
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
>     func_outputs = python_func(*func_args, **func_kwargs)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
>     return weak_wrapped_fn().__wrapped__(*args, **kwds)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 66, in distributed_function
>     model, input_iterator, mode)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 118, in _prepare_feed_values
>     inputs = [inputs[key] for key in model._feed_input_names]
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 118, in <listcomp>
>     inputs = [inputs[key] for key in model._feed_input_names]
> KeyError: 'conv2d_input'

**Describe the expected behavior**
training the network doesn't fail

**Code to reproduce the issue**

```
import tensorflow as tf
import tensorflow_datasets as tfds

from tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D

ds_train = tfds.load(name=""cifar100"", split=tfds.Split.TRAIN)
ds_test = tfds.load(name=""cifar100"", split=tfds.Split.TEST)

input_shape = (32,32, 3)
num_classes = 10
epochs = 10

model = tf.keras.Sequential([
    Conv2D(32, 5, padding='same', activation='relu', input_shape=input_shape),
    MaxPooling2D((2, 2), (2, 2), padding='same'),
    BatchNormalization(),
    Conv2D(64, 5, padding='same', activation='relu'),
    MaxPooling2D((2, 2), (2, 2), padding='same'),
    Flatten(),
    Dense(1024, activation='relu'),
    Dropout(0.4),
    Dense(num_classes, activation='softmax')
])

model.summary()

model.compile(
    loss=tf.keras.losses.categorical_crossentropy,
    optimizer='adam',
    metrics=['accuracy'])

model.fit(ds_train,
          epochs=epochs,
          validation_data=ds_test,
          verbose=1)
```

"
34586,Documentation Error on nn.ctc_loss,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss

## Description of issue (what needs changing):
The logits and logits_time_major parameters are ill defined.
### Current on docs
* logits: tensor of shape [frames, batch_size, num_labels], if logits_time_major == False, shape is [batch_size, frames, num_labels].
* logits_time_major: (optional) If True (default), logits is shaped [time, batch, logits]. If False, shape is [batch, time, logits]

### Clear description
* logits: tensor of shape [time, batch_size, num_labels], if logits_time_major == True. Shape is [batch_size, frames, num_labels] if logits_time_major == False.
* logits_time_major: (optional) If True (default), logits is shaped [time, batch_size, num_labels]. If False, shape is [batch_size, time, num_labels]

### Submit a pull request?
I'm preparing a PR
"
34585,Tensorflow 2.0 does not iterate through entire dataset when tf.keras.model.fit is called,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Mac OS 10.14.6**
- TensorFlow installed from (source or binary): **source**
- TensorFlow version (use command below): **2.0**
- Python version: **3.6.0**

**Describe the current behavior**
I am training a model in tf.keras with tensorflow 2.0. **I am having an issue where my model appears to train successfully, but it is not iterating through the entire dataset.** A few things indicate that it's not going through the entire dataset: 

1. the model is training super fast (an epoch should take ~45 minutes, which is estimated, but it always finishes in < 1 minute),
2. the validation metrics are always reported 0. and,
3. the progress bar that prints out never fills up, and it stops at ~1/1000 of the data. 

The progress bar during training looks something like this:

```
Epoch 1/300   192/162636 [..............................] - ETA: 45:42 - loss: 0.4783 - mean_squared_error: 0.4783 - val_loss: 0.0000e+00 - val_mean_squared_error: 0.0000e+00
Epoch 2/300   186/162636 [..............................] - ETA: 45:42 - loss: 0.4783 - mean_squared_error: 0.4783 - val_loss: 0.0000e+00 - val_mean_squared_error: 0.0000e+00
...
Epoch X/300   192/162636 [..............................] - ETA: 45:42 - loss: 0.4783 - mean_squared_error: 0.4783 - val_loss: 0.0000e+00 - val_mean_squared_error: 0.0000e+00
```

 I restructured the code into tensorflow 1.15, and I do not have this issue. When I call `tf.compat.v1.enable_v2_behavior()`, I see this behavior again. There are no errors, warnings, or info that is reported, it just stops iterating through my dataset early. I am following [this tutorial](https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/#comment-510384) for Multiple Input Series. 

**Describe the expected behavior**
The expected behavior is that an epoch will completely go through the dataset, and it will report a reasonable validation loss, and it will take some time to go through the entire dataset. I see the correct behavior in TF 1.15, and the epochs take ~45 minutes to complete (as expected), the validation metrics are calculated, and the progress bar looks something like this (which is nothing special :) )
```
Epoch 16/300
162605/162636 [============================>.] - ETA: 0s - loss: 1.2883e-05
162636/162636 [==============================] - 2946s 1ms/sample - loss: 1.2883e-05 - val_loss: 1.5680e-05
Epoch 17/300
162605/162636 [============================>.] - ETA: 0s - loss: 1.2631e-05
162636/162636 [==============================] - 2688s 5ms/sample - loss: 1.2633e-05 - val_loss: 2.1342e-05
```

**Code to reproduce the issue**
I have a time-series dataset. It is very small so I am able to load it into memory, so I do not need the dataset API. I am windowing the time-series to produce two arrays, X and Y, and it looks something like this, 

```
X=[
   [[1,2,3],[4,5,6],   [7,8,9]],
   [[4,5,6],[7,8,9],   [10,11,12]],
   [[7,8,9],[10,11,12],[13,14,15]],
   ...
  ] 
Y = [
     [4],
     [7],
     [10],
     ...
    ]
```

(yes, I realize that I could just as easily only include one of the features. I've tried that, i.e. `X=[[[1,2,3]], [[4,5,6]], [[7,8,9]], ...], and it still doesn't work)

Then, I build my model:

```
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
```

and then I train it:

```
model.fit([X],[Y],num_epochs=300,validation_split=0.2)
```

It correctly reports the number of train and validation samples, and then the progress bar pops up... but that's where the success stops. The val_loss and val_mean_squared_error is always 0, for every epoch, and it appears to never train more than a fraction (~1/1000) of my dataset, although that fraction varies slightly between epochs. This is the print out:

```
Epoch 1/300   192/162636 [..............................] - ETA: 45:42 - loss: 0.4783 - mean_squared_error: 0.4783 - val_loss: 0.0000e+00 - val_mean_squared_error: 0.0000e+00
Epoch 2/300   186/162636 [..............................] - ETA: 45:42 - loss: 0.4783 - mean_squared_error: 0.4783 - val_loss: 0.0000e+00 - val_mean_squared_error: 0.0000e+00
...
Epoch X/300   192/162636 [..............................] - ETA: 45:42 - loss: 0.4783 - mean_squared_error: 0.4783 - val_loss: 0.0000e+00 - val_mean_squared_error: 0.0000e+00
```

When I call `tf.compat.v1.enable_v2_behavior()` in TF 1.15, the behavior is the same as TF 2.0.


**Other info / logs**
[Here is a link to the StackOverflow question that I proposed before I had confirmed that this is a TensorFlow bug](https://stackoverflow.com/questions/58826512/tensorflow-2-0-does-not-iterate-through-entire-dataset-when-tf-keras-model-fit-i/59001781#59001781)
"
34584,"I have no idea how properly run pb file with ""serve"" tag do you have any idea?","This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
34583,Filter outputs for available estimators,"Hi,

I have trouble standardizing outputs of Tensorflow estimators. This is achievable for pre-estimator `tf.session()` era and in custom estimators.

1. Before `tf.Estimators()` came into play, I could play with the output of inference graph using `add_meta_graph_and_variables`. But I can't use this in estimators since it wraps intitalizing sessions from user.
2. When building a custom estimator, I can specify `export_output` parameter and define the specific fields which I want to output.

For pre-made estimators, is there a way to pick specific fields out of the standard output?"
34580,Golang tensorflow no longer builds due to bad import in saved_model.go,"A recent change (Change-Id: Iefdf75ed88f54d97a0a7d210f5a42f3123205bf2) has broken an import in file tensorflow/blob/master/tensorflow/go/saved_model.go

tfpb ""github.com/tensorflow/tensorflow/tensorflow/go/genop/internal/proto/github.com/tensorflow/tensorflow/tensorflow/go/core/framework""

"
34579,Suspected memory leak - model.predict,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
NA
- TensorFlow installed from (source or binary):
binary wheel via PyPI
- TensorFlow version (use command below):
v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version:
3.6.8
- Bazel version (if compiling from source):
NA
- GCC/Compiler version (if compiling from source):
NA
- CUDA/cuDNN version:
NA
- GPU model and memory:
NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm suspecting a memory leak on keras model.predict (**running on cpu only**).
Performing model.predict in an infinite loop - demonstrates memory leak trend (~400MB in 30min, please see image below).
This trend happens even though I call `gc.collect()` on every iteration.
In addition - using `gc.get_objects()` I can see that every iteration leaks exactly 1298 new objects. Using `objgraph` the leaked objects are:
```bash
tuple                          751101      +741
list                           202237      +197
dict                           155046      +137
Tensor                          26665       +27
TF_Output                       26621       +27
Operation                       26686       +27
_InputList                      26686       +27
Dimension                       15675       +16
set                             18103       +15
TraceableStack                  11629       +12
TensorShape                     10845       +11
builtin_function_or_method      10757        +9
OrderedDict                      8799        +9
weakref                         14739        +6
TensorSpec                       3873        +4
Condition                        2926        +3
deque                            2930        +3
_local                           2925        +3
ObjectIdentitySet                2909        +3
ScopedTFGraph                    2909        +3
GroupLock                        2909        +3
FuncGraph                        2906        +3
ObjectIdentityWeakSet            2908        +3
_EagerDefinedFunction            2904        +3
ScopedTFFunction                 2904        +3
_EagerDefinedFunctionDeleter     2904        +3
```
**Describe the expected behavior**
Memory shouldn't increase over time when calling `gc.collect()` nor should there be objects leaks per prediction.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
import tensorflow as tf
from collections import defaultdict
import gc
import objgraph

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)

model.evaluate(x_test,  y_test, verbose=2)


def mem_stat():
    
    objs = gc.get_objects()
    print(""total objects count"", len(objs))
    
c = 1
while True:
    print(""----------- iter"", c)

    model.predict(x_test)
    
    gc.collect()

    print(""mem stat after predict:"")
    mem_stat()
    objgraph.show_growth(limit=30)
    c += 1
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
![image](https://user-images.githubusercontent.com/17004015/69528569-27b63980-0f77-11ea-8db3-ada1688c4d3b.png)

"
34578,Many problems when to convert pb to tflite," 
- OS Platform and Distribution ( Linux Ubuntu 18.04 **install on VMware Fusion **):
- TensorFlow installed from (source or binary): binary 
- TensorFlow version (or github SHA if from source): 1.14.0


> train model
I download pet data source and train

```
 python3 object_detection/model_main.py --pipeline_config_path=ssd_mobilenet_v1_pets.config  --model_dir=output
```
 

> use to get tflite_graph.pb and tflite_graph.pbtxt 

```
 python3 object_detection/export_tflite_ssd_graph.py  --pipeline_config_path=ssd_mobilenet_v1_pets.config  --trained_checkpoint_prefix=output/model.ckpt-0  --output_directory=output --add_postprocessing_op=true
```

> get tflite 

```
bazel run -c opt tensorflow/lite/toco:toco --  --input_file=$TRAINHOME/tflite/tflite_graph.pb --output_file=$TRAINHOME/tflite/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops
```

`tensorflow/lite/toco:` is a directory which i download tensorflow source code from github
 
error message :

```bash
 INFO: Writing tracer profile to '/home/kscorpio/.cache/bazel/_bazel_kscorpio/875b32c2c1b2a0876b2c7691115da3ca/command.profile.gz'
ERROR: Skipping 'tensorflow/lite/toco:toco': error loading package 'tensorflow/lite/toco': in /home/kscorpio/tensorflow/tensorflow.bzl: in /home/kscorpio/tensorflow/core/platform/default/build_config_root.bzl: Unable to find package for @local_config_remote_execution//:remote_execution.bzl: The repository '@local_config_remote_execution' could not be resolved.
WARNING: Target pattern parsing failed.
ERROR: error loading package 'tensorflow/lite/toco': in /home/kscorpio/tensorflow/tensorflow.bzl: in /home/kscorpio/tensorflow/core/platform/default/build_config_root.bzl: Unable to find package for @local_config_remote_execution//:remote_execution.bzl: The repository '@local_config_remote_execution' could not be resolved.
INFO: Elapsed time: 0.183s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded)
FAILED: Build did NOT complete successfully (1 packages loaded)

```

in addition , `bazel run xxxxx:toco` and `tflite_convert ` which is the right way ?
 
 


 
"
34577,tf.losses.cosine_similarity is a negative quantity between -1 and 0 ,"In tensorflow website, it describes tf.losses.cosine_simialrity as follows:
Note that it is a negative quantity between -1 and 0, where 0 indicates orthogonality and values closer to -1 indicate greater similarity. 
In fact, the quantity is from 1. to -1., it just takes a negative from normal cosine_similarity.
The page is at
https://tensorflow.google.cn/api_docs/python/tf/keras/losses/cosine_similarity"
34576,[tflite] Need custom implementantion for operators,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While."
34575,GPU support for tf.stack / tf.unstack with complex64 / complex128,"**System information**
- TensorFlow version (you are using): 1.14
- Are you willing to contribute it (Yes/No): Yes (although I don't know what's involved)



**Describe the feature and the current behavior/state.**
There currently don't seem to be GPU kernels for complex64 and complex128 `stack` and `unstack` operations. For example, the following code:
```
with tf.Graph().as_default():
    with tf.device('/gpu:0'):
        x = tf.placeholder(shape=(1, ), dtype=tf.complex128)
        y = tf.placeholder(shape=(1, ), dtype=tf.complex128)
        z = tf.stack([x, y], axis=0)
        with tf.Session() as s:
            s.run(z, feed_dict={x: [1], y: [2]})
```
throws an error:
```InvalidArgumentError: Cannot assign a device for operation stack: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]
Pack: CPU XLA_CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  stack (Pack) /device:GPU:0

Op: Pack
Node attrs: axis=0, N=2, T=DT_COMPLEX128
Registered kernels:
  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]
  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_BFLOAT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_BFLOAT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]
  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]
  device='CPU'; T in [DT_QINT32]
  device='CPU'; T in [DT_QUINT8]
  device='CPU'; T in [DT_QINT8]
  device='CPU'; T in [DT_VARIANT]
  device='CPU'; T in [DT_RESOURCE]
  device='CPU'; T in [DT_STRING]
  device='CPU'; T in [DT_BOOL]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_UINT16]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_INT64]
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_BOOL]
  device='GPU'; T in [DT_INT16]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_BFLOAT16]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_HALF]
```

**Will this change the current api? How?**
No.

**Who will benefit with this feature?**
Anybody using TensorFlow with GPU for calculations involving complex numbers."
34574,tf-trt using error,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

when I run  the model of  trensorrt model transforming from a tensorflow pb modle, it turn out to be an error.
the code is below:
import numpy as np
import tensorflow as tf
import time

import os
os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""
os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""

float16 = False

if float16:
    trtfilepath = ""/home/andy/models_trt/ssd/ssd_rt_16.pb""
else:
    trtfilepath = ""/home/andy/models_trt/ssd/ssd_rt_32.pb""

featurepath = ""/home/andy/model_data/cat.npy""

outputpath1 = ""/home/andy/model_data/ssdoutput1.npy""
outputpath2 = ""/home/andy/model_data/ssdoutput2.npy""
outputpath3 = ""/home/andy/model_data/ssdoutput3.npy""
outputpath4 = ""/home/andy/model_data/ssdoutput4.npy""

features = np.load(featurepath)

if float16:
    features = np.load(featurepath).astype(np.float16)
else:
    features = np.load(featurepath).astype(np.float32)


inputs = ""image_tensor:0""
outputs1 = ""detection_boxes:0""
outputs2 = ""detection_scores:0""
outputs3 = ""num_detections:0""
outputs4 = ""detection_classes:0""

config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.6

with tf.Session(config=config) as sess:
    with tf.gfile.GFile(trtfilepath, 'rb') as f:
        frozen_graph = tf.GraphDef()
        frozen_graph.ParseFromString(f.read())
        sess.graph.as_default()
        tf.import_graph_def(frozen_graph, name='')
        tf_input = sess.graph.get_tensor_by_name(inputs)

        tf_output1 = sess.graph.get_tensor_by_name(outputs1)
        tf_output2 = sess.graph.get_tensor_by_name(outputs2)
        tf_output3 = sess.graph.get_tensor_by_name(outputs3)
        tf_output4 = sess.graph.get_tensor_by_name(outputs4)
        t1 = time.time()
        output1, output2, output3, output4 = sess.run([tf_output1, tf_output2, tf_output3, tf_output4], feed_dict={
            tf_input: features
        })
        t2 = time.time() 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no
- OS Platform and Distribution :Linux Ubuntu 16.04):

- TensorFlow installed from (source or binary):yes
- TensorFlow version (use command below):tensorflow-1.14.0
- Python version:python3.6
- Bazel version (if compiling from source):0.24.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:cuda version:10.0/cudnn version7.6.2
- GPU model and memory:GForce １０６０

the error list as:
2019-11-25 14:23:12.077309: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1558] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-11-25 14:23:12.635331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-25 14:23:13.452120: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-25 14:23:13.457413: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-25 14:23:13.462873: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-25 14:23:13.468059: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-25 14:23:13.473325: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-25 14:23:13.478631: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-25 14:23:13.484220: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-25 14:23:13.490953: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-25 14:23:13.502852: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-25 14:23:13.510147: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)

which make me puzzle.wish to get your reply soon.
"
34572,How to achieve elementwise convolution for two tensors?,"In my problem, I want to convolve two tensors in my neural network model. 

The shape of two tensors is **[None, 2, 1], [None, 3, 1]** respectively. The axis with dimension None means the batch size of the input tensor. For each sample in batch, I want to convolve the two tensors with shape [2, 1] and [3, 1].

However, the tf.nn.conv1d in TensorFlow can only convolve the input with **a fixed kernel.** Is there any function that can support the convolution of two tensors according to the batch size axis, similar to the tf.multiply which can multiply two tensors for each sample or just elementwise multiplication."
34571,How to convolve two tensor according to the batch axis?,"In my problem, I want to convolve two tensors in my neural network model. The shape of two tensors is [None, 2, 1], [None, 3, 1] respectively. The axis with dimension None means the batch size of the input tensor. For each sample in batch, I want to convolve the two tensors with shape [2, 1] and [3, 1].
However, the tf.nn.conv1d in TensorFlow can only convolve the input with a fixed kernel. Is there any function that can support the convolution of two tensors according to the batch size axis, similar to the tf.multiply which can element wisely multiply two tensors."
34570,How to convolve two tensor according to the batch axis?,"In my problem, I want to convolve two tensors in my neural network model. The shape of two tensors is [None, 2, 1], [None, 3, 1] respectively. The axis with dimension None means the batch size of the input tensor. For each sample in batch, I want to convolve the two tensors with shape [2, 1] and [3, 1].
However, the tf.nn.conv1d in TensorFlow can only convolve the input with a fixed kernel. Is there any function that can support the convolution of two tensors according to the batch size axis, similar to the tf.multiply which can element wisely multiply two tensors."
34568,RuntimeError: Collective ops must be configured at program startup,"Running distributed TensorFlow gives:

> RuntimeError: Collective ops must be configured at program startup

**System information**
- Tutorial: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras
- Ubuntu 18.04 (4.15.0-70-generic)
- TensorFlow installed from pip using pip install tensorflow==2.0.0
- Python 2.7.15

> numpy                    1.16.5
> protobuf                 3.10.0
> tensorflow-datasets      1.3.0
> tensorflow-estimator     2.0.1
> tensorflow-metadata      0.15.1


In the sequence of code, first TF_CONFIG is set using:
`os.environ[""TF_CONFIG""] = json.dumps({""cluster"": {""worker"": [""abc:12345"", ""bcd:23456"", ""cde:34567""]},""task"": {""type"": ""worker"", ""index"": 0}})`

and then:
`strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()`

The expected behavior should be that this strategy should work but I get: 
`RuntimeError: Collective ops must be configured at program startup`

As per the documentation, the TF_CONFIG is defined before the strategy command. I read some of the issues and people suggested to upgrade to the latest tf-nightly but even after I did that I still get the same issue."
34567,No way to use tensorflow with cuda on windows.  cudaGetDevice() failed.,"Hi,

I'm trying to use cuda with tensorflow. I installed cuda 10.0 and tensorflow 2.0, my version of VS is 2017. I set my env variables and the problem persists.

This is the error message: **cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.**

Thanks to u all!"
34566,"Google Colab: InvalidArgumentError: Cannot update variable with shape [] using a Tensor with shape [32], shapes must be equal. 	 [[{{node metrics_26/acc/AssignAddVariableOp}}]]","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: Google Colab
- TensorFlow installed from (source or binary): 2.00
- TensorFlow version (use command below): 2.00
- Python version: 3.6

**Describe the current behavior**
I'm working on an image classification project using Tensorflow and running the code on Google Colab. The dataset is hosted on my Google Drive.
Everything works as expected until the model begins to train and I get an error as shown below.


**Describe the expected behavior**
If I run the same code on my Windows 10 setup, I do not run into any errors.



**Code to reproduce the issue**
```
!pip install --quiet tensorflow==2.0.0-rc0
!pip install --quiet neural-structured-learning

from __future__ import absolute_import, division, print_function, unicode_literals

# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import datasets, layers, models

print(tf.__version__)


import numpy as np
import matplotlib.pyplot as plt
import os
import cv2
from tqdm import tqdm
import pathlib
import random

from google.colab import drive
drive.mount('/content/gdrive')

train_data_dir = ""/content/gdrive/My Drive/Resize/train""
train_label_dir = pathlib.Path(train_data_dir)

test_data_dir = ""/content/gdrive/My Drive/Resize/test""
test_label_dir = pathlib.Path(test_data_dir)



CATEGORIES = np.array([item.name for item in train_label_dir.glob('*') if item.name != ""LICENSE.txt""])
class_names = CATEGORIES
print(CATEGORIES)



def createdataset(DATADIR, label_dir, CATEGORIES, img_size):
    image_count = len(list(label_dir.glob('*/*.jpg')))
    print(image_count)


    IMG_SIZE = img_size

    datalist = []

    for category in CATEGORIES:  # do dogs and cats

        path = os.path.join(DATADIR,category)  # create path to dogs and cats
        class_num = np.where(CATEGORIES == category)

        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats
            try:
                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array
                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size
                datalist.append([new_array, class_num])  # add this to our training_data
            except Exception as e:  # in the interest in keeping the output clean...
                pass
            #except OSError as e:
            #    print(""OSErrroBad img most likely"", e, os.path.join(path,img))
            #except Exception as e:
            #    print(""general exception"", e, os.path.join(path,img))
    return datalist


training_dataset = createdataset(train_data_dir, train_label_dir, CATEGORIES, 200)
testing_dataset = createdataset(test_data_dir, test_label_dir, CATEGORIES, 200)

print(len(training_dataset))
print(len(testing_dataset))


def dataset(datasets):
    xdata = []
    ylabels = []
    # random.shuffle(datasets)
    for datas,labels in datasets:
        xdata.append(datas)
        ylabels.append(labels)
    return xdata, ylabels

train_images, train_labels = dataset(training_dataset)
test_images, test_labels = dataset(testing_dataset)
print(len(train_images))
print(len(train_labels))
print(len(test_images))
print(len(test_labels))

train_images = np.array(train_images)
test_images = np.array(test_images)
train_labels = np.array(train_labels)
test_labels = np.array(test_labels)

print(train_images.shape)
print(test_images.shape)

train_images = train_images.reshape(train_images.shape[0], 200, 200, 1)
test_images = test_images.reshape(test_images.shape[0], 200, 200, 1)

train_images = train_images / 255.0
test_images = test_images / 255.0

model = models.Sequential()

model.add(layers.Conv2D(32, (3, 3), input_shape=(200,200,1)))
model.add(layers.BatchNormalization(axis=-1))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(32, (3, 3)))
model.add(layers.BatchNormalization(axis=-1))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))

model.add(layers.Conv2D(64,(3, 3)))
model.add(layers.BatchNormalization(axis=-1))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(64, (3, 3)))
model.add(layers.BatchNormalization(axis=-1))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))

model.add(layers.Flatten())

# Fully connected layer
model.add(layers.Dense(512))
model.add(layers.BatchNormalization())
model.add(layers.Activation('relu'))
model.add(layers.Dropout(0.2))
model.add(layers.Dense(4))

model.add(layers.Activation('softmax'))

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=3)

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

print('\nTest accuracy:', test_acc)
```


**Other info / logs**
```
Train on 1610 samples
Epoch 1/3
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-59-e10ee906ee19> in <module>()
     36               metrics=['accuracy'])
     37 
---> 38 model.fit(train_images, train_labels, epochs=3)
     39 
     40 test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    725         shuffle=shuffle,
    726         class_weight=class_weight,
--> 727         sample_weight=sample_weight,
    728         initial_epoch=initial_epoch,
    729         steps_per_epoch=steps_per_epoch,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    673         validation_freq=validation_freq,
    674         steps_name='steps_per_epoch')
--> 675 
    676   def evaluate(self,
    677                model,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)
    392         # Get outputs.
    393         batch_outs = f(ins_batch)
--> 394         if not isinstance(batch_outs, list):
    395           batch_outs = [batch_outs]
    396 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in __call__(self, inputs)
   3474     # CompositeTensors. E.g., if output_structure contains a SparseTensor, then
   3475     # this ensures that we return its value as a SparseTensorValue rather than
-> 3476     # a SparseTensor.
   3477     return nest.map_structure(self._eval_if_composite, output_structure)
   3478 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in __call__(self, *args, **kwargs)
   1470         ret = tf_session.TF_SessionRunCallable(self._session._session,
   1471                                                self._handle, args,
-> 1472                                                run_metadata_ptr)
   1473         if run_metadata:
   1474           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

InvalidArgumentError: Cannot update variable with shape [] using a Tensor with shape [32], shapes must be equal.
	 [[{{node metrics_26/acc/AssignAddVariableOp}}]]
```"
34565,Applying certain ImgAug augmenters inside of a `tf.py_function` causes AutoGraph errors.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 1.15.1
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.5
- Bazel version (if compiling from source): N / A
- GCC/Compiler version (if compiling from source): N / A
- CUDA/cuDNN version: N / A
- GPU model and memory: N / A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm currently using `imgaug==0.3.0` to augment images as part of a map function applied to a tf.data.Dataset. I'm using `tf.py_function` to call the augmenter and it appears that Autograph is incorrectly generating ops for some of the augmenters causing the pipeline to error.

**Describe the expected behavior**
I'm upgrading from `tf.py_func` in TF 1.14 to `tf.py_function` TF 2.0 and it was possible to map the `tf.py_func` that called the augmentation onto the dataset.

**Code to reproduce the issue**
Here is a minimal example, [also runable in Colab](https://colab.research.google.com/drive/1X6NiCnGxNFG9pAZ1Jzd7R1In8BNh9pts#scrollTo=Q_scaVKrpKwJ):

```
import imgaug.augmenters as iaa
import tensorflow as tf

seq = iaa.Sequential([
    # A non-offending augmenter
    iaa.Multiply(200),
    # the offending augmenter
    iaa.ChangeColorspace(""HSV"")
])

def augment_batch(image):

    def augment_image(image):
        return seq.augment(images=image.numpy())

    image = tf.cast(image, tf.uint8)
    image = tf.py_function(augment_image, [image], tf.uint8)
    return image

# Create a dataset and apply the augmentation.
image = tf.random.uniform((2, 256, 256, 3), minval=0, maxval=100, dtype=tf.float32)
dataset = tf.data.Dataset.from_tensor_slices((image))
dataset = dataset.batch(2)
dataset = dataset.map(augment_batch)

for record in dataset:
    break
```

**Other info / logs**
Full stack trace:
```
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
<ipython-input-2-84e7acd87c82> in <module>()
     24 dataset = dataset.map(augment_batch)
     25 
---> 26 for record in dataset:
     27     break

4 frames
/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/ops/iterator_ops.py in __next__(self)
    620 
    621   def __next__(self):  # For Python 3 compatibility
--> 622     return self.next()
    623 
    624   def _next_internal(self):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/ops/iterator_ops.py in next(self)
    664     """"""Returns a nested structure of `Tensor`s containing the next element.""""""
    665     try:
--> 666       return self._next_internal()
    667     except errors.OutOfRangeError:
    668       raise StopIteration

/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/ops/iterator_ops.py in _next_internal(self)
    649             self._iterator_resource,
    650             output_types=self._flat_output_types,
--> 651             output_shapes=self._flat_output_shapes)
    652 
    653       try:

/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)
   2671       else:
   2672         message = e.message
-> 2673       _six.raise_from(_core._status_to_exception(e.code, message), None)
   2674   # Add nodes to the TensorFlow graph.
   2675   if not isinstance(output_types, (list, tuple)):

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnknownError: {{function_node __inference_Dataset_map_augment_batch_17}} KeyError: 'to_colorspace'
Traceback (most recent call last):

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/script_ops.py"", line 219, in __call__
    return func(device, token, args)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/script_ops.py"", line 113, in __call__
    ret = self._func(*args)

  File ""/tmp/tmpu_6oegng.py"", line 17, in augment_image
    retval__1 = augment_image_scope.mark_return_value(ag__.converted_call(seq.augment, augment_image_scope.callopts, (), {'images': ag__.converted_call(image.numpy, augment_image_scope.callopts, (), None, augment_image_scope)}, augment_image_scope))

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py"", line 539, in converted_call
    result = converted_f(*effective_args, **kwargs)

  File ""/tmp/tmp5wnqr3ev.py"", line 298, in tf__augment
    batch_aug = ag__.converted_call(self.augment_batch, augment_scope.callopts, (batch,), {'hooks': hooks}, augment_scope)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py"", line 539, in converted_call
    result = converted_f(*effective_args, **kwargs)

  File ""/tmp/tmp_d1lunu_.py"", line 78, in tf__augment_batch
    ag__.for_stmt(augmentables, None, loop_body, get_state_2, set_state_2, (), (), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 339, in for_stmt
    return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 350, in _py_for_stmt
    state = body(target, *state)

  File ""/tmp/tmp_d1lunu_.py"", line 75, in loop_body
    aug = ag__.converted_call(ag__.converted_call(getattr, augment_batch_scope.callopts, (augseq, 'augment_%s' % (attr_name,)), None, augment_batch_scope), augment_batch_scope.callopts, (attr,), {'hooks': hooks}, augment_batch_scope)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py"", line 539, in converted_call
    result = converted_f(*effective_args, **kwargs)

  File ""/tmp/tmpwzc17v74.py"", line 237, in tf__augment_images
    do_return, retval_ = ag__.if_stmt(cond_10, if_true_10, if_false_10, get_state_10, set_state_10, ('do_return', 'retval_'), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 895, in if_stmt
    return _py_if_stmt(cond, body, orelse)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 1004, in _py_if_stmt
    return body() if cond else orelse()

  File ""/tmp/tmpwzc17v74.py"", line 216, in if_false_10
    images_result = ag__.if_stmt(cond_8, if_true_8, if_false_8, get_state_8, set_state_8, ('images_result',), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 895, in if_stmt
    return _py_if_stmt(cond, body, orelse)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 1004, in _py_if_stmt
    return body() if cond else orelse()

  File ""/tmp/tmpwzc17v74.py"", line 210, in if_true_8
    images_result_1 = ag__.if_stmt(cond_7, if_true_7, if_false_7, get_state_7, set_state_7, ('images_result',), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 895, in if_stmt
    return _py_if_stmt(cond, body, orelse)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 1004, in _py_if_stmt
    return body() if cond else orelse()

  File ""/tmp/tmpwzc17v74.py"", line 204, in if_true_7
    images_result_1 = ag__.converted_call(self._augment_images, augment_images_scope.callopts, (images_copy,), {'random_state': self.random_state, 'parents': parents_1, 'hooks': hooks}, augment_images_scope)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py"", line 539, in converted_call
    result = converted_f(*effective_args, **kwargs)

  File ""/tmp/tmppisluv_j.py"", line 15, in tf___augment_images
    retval_ = _augment_images_scope.mark_return_value(ag__.converted_call(self._augment_augmentables, _augment_images_scope.callopts, (images, random_state, parents, hooks, 'augment_images'), None, _augment_images_scope))

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py"", line 541, in converted_call
    result = converted_f(*effective_args)

  File ""/tmp/tmpjnm069kq.py"", line 56, in tf___augment_augmentables
    augmentables = ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_2, set_state_2, ('augmentables',), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 895, in if_stmt
    return _py_if_stmt(cond, body, orelse)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 1004, in _py_if_stmt
    return body() if cond else orelse()

  File ""/tmp/tmpjnm069kq.py"", line 50, in if_true_1
    augmentables_1, = ag__.for_stmt(order, None, loop_body, get_state_1, set_state_1, (augmentables_1,), ('augmentables',), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 339, in for_stmt
    return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 350, in _py_for_stmt
    state = body(target, *state)

  File ""/tmp/tmpjnm069kq.py"", line 48, in loop_body
    augmentables_1 = ag__.converted_call(ag__.converted_call(getattr, _augment_augmentables_scope.callopts, (self[index], augfunc_name), None, _augment_augmentables_scope), _augment_augmentables_scope.callopts, (augmentables_1,), {'parents': parents + [self], 'hooks': hooks}, _augment_augmentables_scope)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py"", line 539, in converted_call
    result = converted_f(*effective_args, **kwargs)

  File ""/tmp/tmpwzc17v74.py"", line 237, in tf__augment_images
    do_return, retval_ = ag__.if_stmt(cond_10, if_true_10, if_false_10, get_state_10, set_state_10, ('do_return', 'retval_'), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 895, in if_stmt
    return _py_if_stmt(cond, body, orelse)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 1004, in _py_if_stmt
    return body() if cond else orelse()

  File ""/tmp/tmpwzc17v74.py"", line 88, in if_true_10
    do_return, retval_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state, ('do_return', 'retval_'), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 895, in if_stmt
    return _py_if_stmt(cond, body, orelse)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 1004, in _py_if_stmt
    return body() if cond else orelse()

  File ""/tmp/tmpwzc17v74.py"", line 83, in if_false
    images_result = ag__.converted_call(self._augment_images, augment_images_scope.callopts, (images,), {'random_state': self.random_state, 'parents': parents, 'hooks': hooks}, augment_images_scope)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py"", line 539, in converted_call
    result = converted_f(*effective_args, **kwargs)

  File ""/tmp/tmpyhqkjn3y.py"", line 48, in tf___augment_images
    ag__.for_stmt(ag__.converted_call(sm.xrange, _augment_images_scope.callopts, (nb_images,), None, _augment_images_scope), None, loop_body, get_state_1, set_state_1, (), (), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 339, in for_stmt
    return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 350, in _py_for_stmt
    state = body(target, *state)

  File ""/tmp/tmpyhqkjn3y.py"", line 46, in loop_body
    ag__.if_stmt(cond, if_true, if_false, get_state, set_state, (), ('result[i]',))

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 895, in if_stmt
    return _py_if_stmt(cond, body, orelse)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 1004, in _py_if_stmt
    return body() if cond else orelse()

  File ""/tmp/tmpyhqkjn3y.py"", line 42, in if_false
    image_aug = ag__.converted_call(change_colorspace_, _augment_images_scope.callopts, (image, to_colorspace, self.from_colorspace), None, _augment_images_scope)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py"", line 541, in converted_call
    result = converted_f(*effective_args)

  File ""/tmp/tmpr5xrj81x.py"", line 221, in tf__change_colorspace_
    do_return, retval_ = ag__.if_stmt(cond_6, if_true_6, if_false_6, get_state_7, set_state_7, ('do_return', 'retval_'), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 895, in if_stmt
    return _py_if_stmt(cond, body, orelse)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 1004, in _py_if_stmt
    return body() if cond else orelse()

  File ""/tmp/tmpr5xrj81x.py"", line 151, in if_false_6
    ag__.for_stmt(['to_colorspace', 'from_colorspace'], None, loop_body, get_state_3, set_state_3, (), (), ())

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 339, in for_stmt
    return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)

  File ""/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py"", line 350, in _py_for_stmt
    state = body(target, *state)

  File ""/tmp/tmpr5xrj81x.py"", line 149, in loop_body
    assert ag__.converted_call(locals, change_colorspace__scope.callopts, (), None, change_colorspace__scope)[arg_name] in CSPACE_ALL, 'Expected `%s` to be one of: %s. Got: %s.' % (arg_name, CSPACE_ALL, ag__.converted_call(locals, change_colorspace__scope.callopts, (), None, change_colorspace__scope)[arg_name])

KeyError: 'to_colorspace'


	 [[{{node EagerPyFunc}}]] [Op:IteratorGetNextSync]
```
"
34564,experimental_connect_to_cluster hangs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):No custom code

- TensorFlow installed from (source or binary):Binary
- TensorFlow version (use command below): '2.1.0-dev20191124'
- Python version:3.5.3
- Using GCP image: debian-9-tf-nightly-2-x-v20191124
- Using TPU version: v2-8 , nightly-2.x , preempitble
- zone(probably irrelevent): us-central1-b

*The TPU and Host were built without `ctpu` tool

**Code to reproduce the issue**
```
import tensorflow as tf
resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://10.0.101.2:8470')
tf.config.experimental_connect_to_cluster(resolver)
```


**Describe the current behavior**
The `experimental_connect_to_cluster` call hangs indefinitely. 
No error message is produced, it is unclear what should be done.
I had the same problem in 2.0.0.

**Describe the expected behavior**
a.Call shouldn't hang and should provide informative error information
b. If some environment settings need to be set to facilitate TPU-host communications, it should be better documented.

**Other info / logs**
Jupyter log is:
```
[I 22:07:17.299 NotebookApp] Kernel restarted: c9cf10ac-3d03-4a62-a737-3f8e94b44aec
[W 22:07:18.426 NotebookApp] SSL Error on 13 ('79.181.28.67', 59971): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:720)
[I 22:07:18.935 NotebookApp] Restoring connection for c9cf10ac-3d03-4a62-a737-3f8e94b44aec:c5d1ab723abe433986849772ed497483
[I 22:07:18.935 NotebookApp] Replaying 3 buffered messages
2019-11-24 22:07:31.539205: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-24 22:07:31.546892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-11-24 22:07:31.547399: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc09561c30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-24 22:07:31.547455: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-24 22:07:31.554227: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.101.2:8470}
2019-11-24 22:07:31.554338: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:31900}
[I 22:07:43.819 NotebookApp] Saving file at /project_drive/project/Trainv3.ipynb
[W 22:07:43.820 NotebookApp] Notebook project_drive/project/Trainv3.ipynb is not trusted
```

gcloud compute instances describe host:
```
canIpForward: false                                                                                                                        
cpuPlatform: Intel Haswell                                                                                                                 
creationTimestamp: '2019-11-24T10:28:54.344-08:00'                                                                                         
deletionProtection: false                                                                                                                  
description: ''                                                                                                                            
disks:                                                                                                                                     
- autoDelete: false                                                                                                                        
  boot: true                                                                                                                               
  deviceName: instance-1                                                                                                                   
  guestOsFeatures:                                                                                                                         
  - type: VIRTIO_SCSI_MULTIQUEUE                                                                                                           
  index: 0                                                                                                                                 
  interface: SCSI                                                                                                                          
  kind: compute#attachedDisk                                                                                                               
  licenses:                                                                                                                                
  - https://www.googleapis.com/compute/v1/projects/debian-cloud/global/licenses/debian-9-stretch                                           
  - https://www.googleapis.com/compute/v1/projects/ml-images/global/licenses/debian-tensorflow                                             
  mode: READ_WRITE                                                                                                                         
  source: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b/disks/instance-1                          
  type: PERSISTENT                                                                                                                         
- autoDelete: false                                                                                                                        
  boot: false                                                                                                                              
  deviceName: yaop-project                                                                                                                 
  index: 1                                                                                                                                 
  interface: SCSI                                                                                                                          
  kind: compute#attachedDisk                                                                                                               
  mode: READ_WRITE                                                                                                                         
  source: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b/disks/yaop-project                        
  type: PERSISTENT                                                                                                                         
displayDevice:                                                                                                                             
  enableDisplay: false                                                                                                                     
id: '7023192423693513994'                                                                                                                  
kind: compute#instance                                                                                                                     
labelFingerprint: 42WmSpB8rSM=                                                                                                             
machineType: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b/machineTypes/n1-highmem-4              
metadata:                                                                                                                                  
  fingerprint: oW9kyu6jwEE=                                                                                                                
  kind: compute#metadata                                                                                                                   
name: instance-1                                                                                                                           
networkInterfaces:                                                                                                                         
- accessConfigs:                                                                                                                           
  - kind: compute#accessConfig                                                                                                             
    name: External NAT                                                                                                                     
    natIP: 35.225.64.207                                                                                                                   
    networkTier: PREMIUM                                                                                                                   
    type: ONE_TO_ONE_NAT                                                                                                                   
  fingerprint: VbmPG2_4Dak=                                                                                                                
  kind: compute#networkInterface                                                                                                           
  name: nic0                                                                                                                               
  network: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/global/networks/default                                      
  networkIP: 10.128.0.18                                                                                                                   
  subnetwork: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/regions/us-central1/subnetworks/default                   
reservationAffinity:                                                                                                                       
  consumeReservationType: ANY_RESERVATION                                                                                                  
scheduling:                                                                                                                                
  automaticRestart: true                                                                                                                   
  onHostMaintenance: MIGRATE                                                                                                               
  preemptible: false                                                                                                                       
selfLink: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b/instances/instance-1                      
serviceAccounts:                                                                                                                           
- email: 312164605303-compute@developer.gserviceaccount.com                                                                                
  scopes:                                                                                                                                  
  - https://www.googleapis.com/auth/devstorage.read_only                                                                                   
  - https://www.googleapis.com/auth/logging.write                                                                                          
  - https://www.googleapis.com/auth/monitoring.write                                                                                       
  - https://www.googleapis.com/auth/servicecontrol                                                                                         
  - https://www.googleapis.com/auth/service.management.readonly                                                                            
  - https://www.googleapis.com/auth/trace.append                                                                                           
startRestricted: false                                                                                                                     
status: RUNNING                                                                                                                            
tags:                                                                                                                                      
  fingerprint: Uv7CXg8qQhM=                                                                                                                
  items:                                                                                                                                   
  - http-server                                                                                                                            
  - https-server                                                                                                                           
  - jupyter                                                                                                                                
  - nomachine                                                                                                                              
zone: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b                                               
```
"
34563,operators in the model are not supported by the standard TensorFlow Lite runtime,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 x64
- TensorFlow version (or github SHA if from source):  2.0


**Provide the text output from tflite_convert**



```
# CODE
```
----------------------------------------------------------------------------



import tensorflow as tf

filename = 'model_24_11_19_3'
model = tf.saved_model.load(filename)

concrete_func = model.signatures[
  tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]

concrete_func.inputs[0].set_shape([1,8])
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])

Tflite_model = converter.convert()
open(""converted_model_new1.tflite"", ""wb"").write(Tflite_model)



*LOGS* 



2019-11-25 02:07:37.676230: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-11-25 02:07:38.516215: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-25 02:07:38.516605: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-25 02:07:38.537041: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2019-11-25 02:07:38.537143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 243 nodes (231), 405 edges (393), time = 7.653ms.
2019-11-25 02:07:38.537239: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 243 nodes (0), 405 edges (0), time = 3.096ms.
2019-11-25 02:07:38.537326: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_while_body_296488_706
2019-11-25 02:07:38.537407: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2019-11-25 02:07:38.537479: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-25 02:07:38.537555: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_while_cond_296487_4136
2019-11-25 02:07:38.537652: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-25 02:07:38.537730: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-25 02:07:38.537821: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_1_while_cond_296673_1329
2019-11-25 02:07:38.537908: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-25 02:07:38.537982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-25 02:07:38.538056: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_1_while_body_296674_505
2019-11-25 02:07:38.538147: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2019-11-25 02:07:38.538697: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-25 02:07:38.963864: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-25 02:07:38.964405: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-25 02:07:40.804458: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2019-11-25 02:07:40.804545: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 167 nodes (-77), 290 edges (-115), time = 1596.62ms.
2019-11-25 02:07:40.804631: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 167 nodes (0), 290 edges (0), time = 168.831ms.
2019-11-25 02:07:40.804719: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_while_cond_296487_4136_frozen
2019-11-25 02:07:40.804817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 16 nodes (0), 4 edges (0), time = 0.611ms.
2019-11-25 02:07:40.804907: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 16 nodes (0), 4 edges (0), time = 0.151ms.
2019-11-25 02:07:40.804991: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_1_while_body_296674_505_frozen
2019-11-25 02:07:40.805089: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 53 nodes (-1), 71 edges (0), time = 1.521ms.
2019-11-25 02:07:40.805182: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 53 nodes (0), 71 edges (0), time = 0.589ms.
2019-11-25 02:07:40.805618: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_1_while_cond_296673_1329_frozen
2019-11-25 02:07:40.805734: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.561ms.
2019-11-25 02:07:40.805837: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.155ms.
2019-11-25 02:07:40.805941: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_while_body_296488_706_frozen
2019-11-25 02:07:40.806047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 69 nodes (-1), 95 edges (0), time = 1.81ms.
2019-11-25 02:07:40.806125: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 69 nodes (0), 95 edges (0), time = 0.815ms.
Traceback (most recent call last):
  File ""D:/Projects/Test3/NMT.py"", line 15, in <module>
    Tflite_model = converter.convert()
  File ""C:\Users\Jiraiya\Anaconda3\envs\env_tensorflow2\lib\site-packages\tensorflow_core\lite\python\lite.py"", line 474, in convert
    **converter_kwargs)
  File ""C:\Users\Jiraiya\Anaconda3\envs\env_tensorflow2\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 475, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""C:\Users\Jiraiya\Anaconda3\envs\env_tensorflow2\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 215, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2019-11-25 02:07:42.853028: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-11-25 02:07:42.970994: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2019-11-25 02:07:42.971178: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.971275: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2019-11-25 02:07:42.971504: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.971600: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2019-11-25 02:07:42.971734: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.971851: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2019-11-25 02:07:42.971919: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.972082: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.972184: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.972291: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2019-11-25 02:07:42.972388: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2019-11-25 02:07:42.972463: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.972543: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2019-11-25 02:07:42.972613: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.972845: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2019-11-25 02:07:42.972914: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.973048: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2019-11-25 02:07:42.973170: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2019-11-25 02:07:42.992717: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 77 operators, 174 arrays (0 quantized)
2019-11-25 02:07:42.993725: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 77 operators, 174 arrays (0 quantized)
2019-11-25 02:07:43.009358: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 53 operators, 139 arrays (0 quantized)
2019-11-25 02:07:43.012720: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 51 operators, 136 arrays (0 quantized)
2019-11-25 02:07:43.013768: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 51 operators, 136 arrays (0 quantized)
2019-11-25 02:07:43.014716: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 51 operators, 136 arrays (0 quantized)
2019-11-25 02:07:43.015495: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 51 operators, 136 arrays (0 quantized)
2019-11-25 02:07:43.016573: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 32896 bytes, theoretical optimal value: 32768 bytes.
2019-11-25 02:07:43.016915: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 8969974
2019-11-25 02:07:43.017550: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, DIV, EXP, EXPAND_DIMS, FILL, FULLY_CONNECTED, GATHER, LOGISTIC, MUL, NOT_EQUAL, PACK, REDUCE_MAX, RESHAPE, SHAPE, SPLIT, STRIDED_SLICE, SUB, SUM, TANH, TILE, TRANSPOSE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.
Traceback (most recent call last):
  File ""c:\users\jiraiya\anaconda3\envs\env_tensorflow2\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\users\jiraiya\anaconda3\envs\env_tensorflow2\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\Jiraiya\Anaconda3\envs\env_tensorflow2\Scripts\toco_from_protos.exe\__main__.py"", line 7, in <module>
  File ""c:\users\jiraiya\anaconda3\envs\env_tensorflow2\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""c:\users\jiraiya\anaconda3\envs\env_tensorflow2\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""c:\users\jiraiya\anaconda3\envs\env_tensorflow2\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""c:\users\jiraiya\anaconda3\envs\env_tensorflow2\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""c:\users\jiraiya\anaconda3\envs\env_tensorflow2\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, DIV, EXP, EXPAND_DIMS, FILL, FULLY_CONNECTED, GATHER, LOGISTIC, MUL, NOT_EQUAL, PACK, REDUCE_MAX, RESHAPE, SHAPE, SPLIT, STRIDED_SLICE, SUB, SUM, TANH, TILE, TRANSPOSE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.




Process finished with exit code 1
"
34562,multi previous states RNN ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**


I try to use the RNN model to do the time series as 
h_t  = F(  h_{t-1},   h_{t-2}   X_t  )
I found that  RNN in TF2.0  not works.

It only works for the following model.
h_t  = F(  h_{t-1},  X_t  )

Could you give me some help  which RNN model in TF2.0 could do the 
h_t  = F(  h_{t-1},   h_{t-2}   X_t  ),

where t is a sequence of time [t_0, t_1,  t_2,  ...,   t_N ].

Thanks










**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
34561,Import statement for Tensorflow returning error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0.0
- Python version: 3.6.2
- Installed using: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- UserBenchmarks: Game 11%, Desk 12%, Work 11%
- CPU: Intel Pentium D 3.40GHz - 1.4%
- GPU: Nvidia GeForce 8600 GT - 1%
- HDD: Seagate Barracuda 7200.10 320GB - 17.9%
- USB: JetFlash Transcend 8GB - 1.5%
- RAM: Unknown 3GB - 2.8%
- MBD: Gigabyte GA-945PL-S3


<em>Hi, I recently installed tensorflow using pip (after going through so much problems), and just when i tried to import tensorflow as tf in my project it returns this error:</em>

<p>Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Program Files\Python36\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Program Files\Python36\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Lase\Documents\Programming stuff\Python\demo 1\.vs\demo 1\main.py"", line 137, in <module>
    import tensorflow as tf
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Program Files\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Program Files\Python36\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Program Files\Python36\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
</p>

<em>Steps taken to solve problem</em>
1. Repeatedly uninstalling and reinstalling tensorflow to see any change, but none worked
2. I also noticed the same thing happens when i try to import keras . Keras tries to import tensorflow and returns the same error
3. Tried installing it on a virtual environment using virtualenv but still didnt work

   "
34560,Check failed: s.ok() copy tensor to gpu sync,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): [v1.13.1](https://github.com/tensorflow/tensorflow/archive/v1.13.1.zip)
- Python version: 2.7
- Bazel version (if compiling from source): 0.19.2
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version: 9.0 / 7
- GPU model and memory: Tesla K40c 12GB


**Describe the current behavior**
I tried to run distributed training (1 ps and 1 worker). I used VGG19 from [tensorflow/benchmark v1.13 compatible](https://github.com/tensorflow/benchmarks) as the training model.  
When `server_protocol` was set to `grpc` or `grpc+gdr`, the training was normal. But when it was set to `grpc+verbs`, the error `F tensorflow/contrib/verbs/rdma.cc:1635] Check failed: s.ok() copy tensor to gpu sync
Aborted (core dumped)` occured at PS (not at worker).  Is this a bug?
The whole log is as follows:

```
$ CUDA_VISIBLE_DEVICES='' python benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=1 --batch_size=64 --model=vgg19 --variable_update=parameter_server --num_batches=5000 --server_protocol=grpc+verbs --ps_hosts=""localhost:2222"" --worker_hosts=""localhost:3333"" --job_name=ps --task_index=0
2019-11-24 22:06:17.143431: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-11-24 22:06:17.143507: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: g3-nasp
2019-11-24 22:06:17.143525: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: g3-nasp
2019-11-24 22:06:17.143595: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 418.39.0
2019-11-24 22:06:17.143652: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 418.39.0
2019-11-24 22:06:17.143668: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 418.39.0
2019-11-24 22:06:17.145757: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-11-24 22:06:17.145788: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> 12.12.12.13:3333}
2019-11-24 22:06:17.151396: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-11-24 22:06:17.151432: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> 12.12.12.13:3333}
2019-11-24 22:06:17.161484: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:2222
2019-11-24 22:06:17.164512: I tensorflow/contrib/verbs/rdma_mgr.cc:130] Connected to remote node /job:worker/replica:0/task:0
TensorFlow:  1.13
Model:       vgg19
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  64 global
             64 per device
Num batches: 5000
Num epochs:  0.25
Devices:     ['/job:worker/replica:0/task:0/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Running parameter server 0
2019-11-24 22:06:22.987281: F tensorflow/contrib/verbs/rdma.cc:1635] Check failed: s.ok() copy tensor to gpu sync
Aborted (core dumped)
```
and the gdb log is as follows:
```
[...]
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
Core was generated by `python benchmarks/scripts/tf_cnn_benchmarks/t'.
Program terminated with signal SIGABRT, Aborted.
#0  0x00007fc91eb02428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54
54      ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.
[Current thread is 1 (Thread 0x7fc782ffd700 (LWP 1941))]
(gdb) where
#0  0x00007fc91eb02428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54
#1  0x00007fc91eb0402a in __GI_abort () at abort.c:89
#2  0x00007fc8c14a2a94 in tensorflow::internal::LogMessageFatal::~LogMessageFatal() ()
   from /tf1.13/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007fc8bc9a6fe3 in tensorflow::RdmaTensorRequest::RecvTensorContent()::{lambda(tensorflow::Status const&)#2}::operator()(tensorflow::Status const&) const ()
   from /tf1.13/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007fc8ba236688 in tensorflow::GPUUtil::CopyCPUTensorToGPU(tensorflow::Tensor const*, tensorflow::DeviceContext const*, tensorflow::Device*, tensorflow::Tensor*, std::function<void (tensorflow::Status const&)>) () from /tf1.13/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#5  0x00007fc8bc9a9199 in tensorflow::RdmaTensorRequest::RecvTensorContent() ()
   from /tf1.13/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007fc8bc9ab95e in tensorflow::RdmaAdapter::Process_CQ() ()
   from /tf1.13/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007fc8b0545c80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#8  0x00007fc91f5ae6ba in start_thread (arg=0x7fc782ffd700) at pthread_create.c:333
#9  0x00007fc91ebd441d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109
```"
34559,Gradient doesn't exist/ becomes None for conv_transpose layers,"**System information**
- Custom code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0
- Python version: 3.6.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
I get a warning 
`WARNING:tensorflow:Gradients do not exist for variables ['mrf__block_2/conv2d_transpose_5/kernel:0', 'mrf__block_2/conv2d_transpose_5/bias:0'] when minimizing the loss.` 
when trying to backprop loss for a specific layer in my model. The gradients keep turning out to be None regardless of optimizer.


**Describe the expected behavior**
The gradients should exist for these layers.


**Code to reproduce the issue**
This is the model in question:
```
import tensorflow as tf
import tensorflow.keras.layers as layers
from tensorflow.keras import Model

class MRF_Block(Model):
  def __init__(self, out_channels, num_inputs, use_deconv=True, 
               kernel_size=(3,3), strides=(1,1), padding='same'):
    super(MRF_Block, self).__init__()

    # Add the conv/deconv layers.
    for i in range(num_inputs):
      # Convolve input tensors to output tensors of same channel depth (# of channels)
      conv_layer = layers.Conv2D(out_channels, kernel_size, strides=strides, padding=padding)
      setattr(self, f'conv_{i}', conv_layer)

      # Deconv input tensors. Input tensor at index i will be upsampled by factor 2^(n_inputs - (i+1))
      # Eg: if input tensors are [t1, t2, t3], t1 will be upsampled x 4, t2 upsampled x 2, t3 not upsampled.
      if use_deconv:
        deconv_layer = layers.Conv2DTranspose(out_channels, kernel_size, padding='same',
                                              strides=(2**(num_inputs-(i+1)), 2**(num_inputs-(i+1))))
        setattr(self, f'deconv_{i}', deconv_layer)

  ## inputs: a list of tensors being inputted to the block.
  def call(self, inputs):

    # Make #channels the same for input tensors (smallest depth)
    convolved = []
    for i, t in enumerate(inputs):
      conv = getattr(self, f'conv_{i}')
      convolved.append(conv(t))

    # Upsample to largest (h, w) resolution
    largest_res = max(inputs, key=lambda t: t.shape[1] * t.shape[2])
    resized = []
    for i, t in enumerate(convolved):
      deconv = getattr(self, f'deconv_{i}', lambda t: t)
      up_sampled = deconv(t)
      
      # Use bilinear resizing if resolution of optional conv_transpose doesn't match
      if up_sampled.shape[1:3] != largest_res.shape[1:3]:
        up_sampled = tf.image.resize(t, size=largest_res.shape[1:3])
    
      resized.append(up_sampled)

    # Fuse by summing
    return sum(resized)
```

And then running this code is what results in the error:
```
t = tf.random.normal((2, 224, 224, 3))
optimizer = tf.keras.optimizers.SGD()

mrf = MRF_Block(12, 2)
with tf.GradientTape() as tape: 
    preds = mrf([t, t]) 
    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.random.normal((2, 224, 224, 12)), preds) 
gradients = tape.gradient(loss, mrf.trainable_variables)
optimizer.apply_gradients(zip(gradients, mrf.trainable_variables))  
```
Changing SGD() to Adam() yields the same warning. Is it a problem with how the model is defined? Repeatedly running the above code yields the same warning (with/without reinitialising the optimizer).

**Other info / logs**
None at the moment.
"
34558,undefined reference to `_imp__TF_Version' when compiling in C,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x86 Version 10.0.18362.476]
- TensorFlow installed from (source or binary): Binary
- TensorFlow version: Below 2.0
**GCC:**
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=c:/mingw/bin/../libexec/gcc/mingw32/8.2.0/lto-wrapper.exe
Target: mingw32
Configured with: ../src/gcc-8.2.0/configure --build=x86_64-pc-linux-gnu --host=mingw32 --target=mingw32 --prefix=/mingw --disable-win32-registry --with-arch=i586 --with-tune=generic --enable-languages=c,c++,objc,obj-c++,fortran,ada --with-pkgversion='MinGW.org GCC-8.2.0-3' --with-gmp=/mingw --with-mpfr=/mingw --with-mpc=/mingw --enable-static --enable-shared --enable-threads --with-dwarf2 --disable-sjlj-exceptions --enable-version-specific-runtime-libs --with-libiconv-prefix=/mingw --with-libintl-prefix=/mingw --enable-libstdcxx-debug --with-isl=/mingw --enable-libgomp --disable-libvtv --enable-nls --disable-build-format-warnings
Thread model: win32
gcc version 8.2.0 (MinGW.org GCC-8.2.0-3)

**Describe the problem**
Tensorflow functions for C api doesn't work.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Visited: https://www.tensorflow.org/install/lang_c
Downloaded Binary for Windows (CPU Only): https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.14.0.zip
Extracted zip file into folder.
Copy and Pasted lib files (including the dll file) into C:\MinGW\lib 
Copy and Pasted include files and folders into C:\MinGW\include

Made new file called ""hello_tf.c"".
Copy and pasted the example program source code from https://www.tensorflow.org/install/lang_c into the file.

Opened up cmd, went to the file directory and typed:
**gcc hello_tf.c -ltensorflow -o hello_tf.exe && hello_tf.exe**

Output:
![image](https://user-images.githubusercontent.com/36951064/69496153-c6f91380-0f1a-11ea-8be0-80786052dfcb.png)

Basically the same on other functions like TF_DataTypeSize:
![image](https://user-images.githubusercontent.com/36951064/69496162-e8f29600-0f1a-11ea-86a6-a92afa4229a5.png)

Code: 
![image](https://user-images.githubusercontent.com/36951064/69496178-20614280-0f1b-11ea-84cd-ea039b5d1ad1.png)


"
34557,Failed to load the native TensorFlow runtime,"**System information**
- Windows 10
- pip install tensorflow in Anaconda
- TensorFlow version: 2.0.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip

While trying to load keras.datasets,

Traceback (most recent call last):
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""c:\users\chris\anaconda3\envs\ml\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""c:\users\chris\anaconda3\envs\ml\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-7-d6cb0ef8e627>"", line 15, in <module>
    from keras import datasets
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\keras\backend\load_backend.py"", line 90, in <module>
    from .tensorflow_backend import *
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow\__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""c:\users\chris\anaconda3\envs\ml\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\users\chris\anaconda3\envs\ml\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""c:\users\chris\anaconda3\envs\ml\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""c:\users\chris\anaconda3\envs\ml\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.
"
34556,tf.keras fit is incompatible with tf.function,"**System information**
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7

**Describe the current behavior**
I'm not sure if this is a bug or a documentation issue. The [migration guide](https://www.tensorflow.org/guide/migrate#mixed_variables_v1layers) recommends adding the `@tf.function` decorator to the `call` method of subclassed Keras models or layers. However, this causes problems when using the `Layer.add_loss` method with input-dependent losses as described in the [Keras guide](https://www.tensorflow.org/guide/keras/custom_layers_and_models#layers_recursively_collect_losses_created_during_the_forward_pass). In retrospect it makes sense that this doesn't work since `tf.function` requires all outputs to be returned from the function, but this is not made very clear in the docs and the resulting error message is not very helpful.

**Code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers

class MyModel(tf.keras.Model):
    def __init__(self, num_classes):
        super().__init__()
        self.num_classes = num_classes
        self.dense = layers.Dense(num_classes, activation='sigmoid')

    @tf.function
    def call(self, inputs):
        self.add_loss(tf.reduce_sum(inputs), inputs=True)
        return self.dense(inputs)

data = np.random.random((1000, 32))
labels = np.random.random((1000, 10))
model = MyModel(num_classes=10)
model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),
              loss='categorical_crossentropy')
model.fit(data, labels, epochs=50)
```
And the resulting error:
```
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: Sum:0
```

**Expected behavior**
Ideally `add_loss` and `tf.function` would somehow be compatible. This would give me the flexibility to use the model directly by calling it or use the keras `fit` and `predict` functions as I please without hurting performance. Alternatively, at least the `tf.keras` guide should make the incompatibility clear, and perhaps an explicit check should be added to make sure `add_loss` is not called inside a `tf.function`."
34555,ppc64le hang nsync::nsync_mu_semaphore_p_with_deadline,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
custom
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
```
uname -a    
Linux 00da561b85b1 4.14.0-115.13.1.el7a.ppc64le #1 SMP Thu Sep 19 14:12:21 UTC 2019 ppc64le ppc64le ppc64le GNU/Linux
```
```
cpu		: POWER9, altivec supported
clock		: 3783.000000MHz
revision	: 2.2 (pvr 004e 1202)

timebase	: 512000000
platform	: PowerNV
model		: 8335-GTH
machine		: PowerNV 8335-GTH
firmware	: OPAL
MMU		: Radix
```
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
source compiled with
```
ENV PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/lib/python2.7/site-packages \
    TF_NEED_JEMALLOC=1 \
    TF_NEED_GCP=0 \
    TF_NEED_HDFS=0 \
    TF_NEED_AWS=0 \
    TF_NEED_KAFKA=0 \
    TF_ENABLE_XLA=0 \
    TF_NEED_GDR=0 \
    TF_NEED_VERBS=0 \
    TF_NEED_NGRAPH=0 \
    TF_NEED_OPENCL_SYCL=0 \
    TF_NEED_CUDA=0 \
    TF_CUDA_CLANG=0 \
    TF_DOWNLOAD_CLANG=0 \
    TF_NEED_MPI=0 \
    GCC_HOST_COMPILER_PATH=gcc \
    CC_OPT_FLAGS=FROM_OPT \
    TF_SET_ANDROID_WORKSPACE=0
```
- TensorFlow version (use command below):
https://github.com/tensorflow/tensorflow/archive/v1.13.1.tar.gz
- Python version:
2.7
- Bazel version (if compiling from source):
https://github.com/bazelbuild/bazel/releases/download/0.19.2/bazel-0.19.2-dist.zip
- GCC/Compiler version (if compiling from source):
```
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
```
- CUDA/cuDNN version:
None
- GPU model and memory:
Tesla V100-SXM2-32GB, but tf is compiled without gpu support

Process hangs sometimes. bt is in attachments
[bt.log](https://github.com/tensorflow/tensorflow/files/3883495/bt.log)
 

"
34554,Forward-mode-by-double-backprop fails on tf.square ops,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- TensorFlow version (use command below): 1.15
- Python version: 3.x

The double-backprop trick (https://j-towns.github.io/2017/06/12/A-new-trick.html) for computing jacobian-vector products (JVPs) fails when `tf.square` ops are in the graph. Recall the double-backprop trick constructs an initial throwaway backward graph, which linearly depends on some dummy variables, and then backpropagates through this throwaway graph with respect to the dummy variables. The result should be constant wrt the dummy variables, and the throwaway graph should be disconnected from the final result.

Below I've taken the example JVP code from https://github.com/renmengye/tensorflow-forward-ad/issues/2#issue-234418055 and changed `tf.tanh` to `tf.square` to illustrate the failure. The code crashes with an `InvalidArgumentError` because the dummy placeholder created in `fwd_gradients` is not fed a value. The true underlying issue is that the dummy should have disappeared in the second call to `tf.gradients` inside `fwd_gradients` (because `g` is linear in `v`). Presumably the cause is that the backward op for `tf.square` somehow depends nonlinearly on the dummy variables.

```python
%tensorflow_version 1.x
import numpy as np
import numpy.random as npr
import tensorflow as tf

def fwd_gradients(ys, xs, d_xs):
  """"""Forward-mode pushforward analogous to the pullback defined by tf.gradients.
  With tf.gradients, grad_ys is the vector being pulled back, and here d_xs is
  the vector being pushed forward.""""""
  v = tf.placeholder(ys.dtype, shape=ys.get_shape(), name=""dummy"")
  g = tf.gradients(ys, xs, grad_ys=v)
  return tf.gradients(g, v, grad_ys=d_xs)

A = tf.constant(npr.randn(5, 3), dtype=tf.float32)
x = tf.placeholder(tf.float32, [1, 5])
y = tf.square(tf.matmul(x, A))
u = tf.placeholder(tf.float32, [1, 5])

jvp = fwd_gradients(y, x, u)

x_val = npr.randn(1, 5)
u_val = npr.randn(1, 5)

init_op = tf.initialize_all_variables()
with tf.Session() as sess:
  sess.run(init_op)
  print(sess.run(jvp, feed_dict={x: x_val, u: u_val}))
```"
34553,numpy.dot and tensorflow.tensordot can't be used together in MacBook,"Hi, 

I was using tensorflow (2.0.0) and numpy (1.7.3) on my MacBook (with Python 3.7.5), but it failed to use both `numpy.dot` (or `numpy.tensordot`) and `tensorflow.tensordot` in one jupyter notebook (no error reported but never finish), though any of them alone works properly.

I have tried the same codes on Linux with the same conda environment, and there is no such issue.

Codes I tested:
```
import numpy as np
import tensorflow as tf

Nd, Nk, Ns = 3, 2, 5
w_np = np.ones([Nd, Nk], dtype=np.float32)
z_np = np.ones([Nk, Ns], dtype=np.float32)
```

Only one the the following two works on MacBook:
```
tf.tensordot(w_np, z_np, axes=1)
```

Or

```
np.tensordot(w_np, z_np, axes=1) # or np.dot(w_np, z_np)
```"
34552,Tensorflow 2.0  build fail in Windows 10,"### Environment
Windows 10
gtx 1050Ti
CUDA driver 441
CUDA tool kit 10.0
CuDNN 7
Python 3.5
Bazel 0.27.1

### Action
follow the official instruction. https://www.tensorflow.org/install/source_windows

run :
`C:\Users\admin\tensorflow>bazel build //tensorflow/tools/pip_package:build_pip_package`
### ERROR INFO

> **ERROR: An error occurred during the fetch of repository 'local_config_cuda':**
   Traceback (most recent call last):
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1304
                _create_local_cuda_repository(repository_ctx)
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1132, in _create_local_cuda_repository
                find_cc(repository_ctx)
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 227, in find_cc
                _get_msvc_compiler(repository_ctx)
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 145, in _get_msvc_compiler
                find_msvc_tool(repository_ctx, vc_path, ""cl.exe"").replace(""\\"", ""/"")
type 'NoneType' has no method replace()
**ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda':** Traceback (most recent call last):
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1304
                _create_local_cuda_repository(repository_ctx)
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1132, in _create_local_cuda_repository
                find_cc(repository_ctx)
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 227, in find_cc
                _get_msvc_compiler(repository_ctx)
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 145, in _get_msvc_compiler
                find_msvc_tool(repository_ctx, vc_path, ""cl.exe"").replace(""\\"", ""/"")
type 'NoneType' has no method replace()
WARNING: Target pattern parsing failed.
**ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda':** Traceback (most recent call last):
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1304
                _create_local_cuda_repository(repository_ctx)
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1132, in _create_local_cuda_repository
                find_cc(repository_ctx)
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 227, in find_cc
                _get_msvc_compiler(repository_ctx)
        File ""C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl"", line 145, in _get_msvc_compiler
                find_msvc_tool(repository_ctx, vc_path, ""cl.exe"").replace(""\\"", ""/"")
type 'NoneType' has no method replace()
INFO: Elapsed time: 31.315s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package

Hope for your help"
34551,Bound method <Conv.call> could not be transformed,"Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2557c76048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2557c76048>>: AssertionError: Bad argument number for Name: 3, expecting 4 "
34550,"Cannot install tensorflow on raspberry pi-0, raspbian buster","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Raspbian Buster
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Raspberry Pi-0
- TensorFlow installed from (source or binary): binary
- TensorFlow version:1.14.0, 1.13.0
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: virtualenv and pip3
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I tried to perform steps given here: https://www.tensorflow.org/install/pip?lang=python3
for full tf install using binary

last command to install tensorflow being 
pip3 install https://storage.googleapis.com/tensorflow/raspberrypi/tensorflow-1.14.0-cp34-none-linux_armv6l.whl

**Any other info / logs**
I get the following error
ERROR: tensorflow-1.14.0-cp34-none-linux_armv6l.whl is not a supported wheel on this platform.

If I just do pip3 install --no-cache-dir tensorflow (rpi-0 memory is too small) I get,

ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you                                                                                                                                                              have updated the package versions, please update the hashes. Otherwise, examine                                                                                                                                                              the package contents carefully; someone may have tampered with them.
    tensorflow from https://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1                                                                                                                                                             -cp37-none-linux_armv6l.whl#sha256=25f4ff027beec1e568baf8e90a07bad59d354560533d6                                                                                                                                                             b37318b9efeb70beeb1:
        Expected sha256 25f4ff027beec1e568baf8e90a07bad59d354560533d6b37318b9efe                                                                                                                                                             b70beeb1
             Got        3aad2c162168a62adae30e226bcddfef74e5db1ca98bec1383958fb5                                                                                                                                                             80e67123




"
34549,Dynamic assignment of tensor elements fails in custom layer,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

I'm not an expert but after a week of research, I would like to know your opinion. 


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution : Linux Ubuntu 18
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): S
- TensorFlow version (use command below): 2.0
- Python version: 3.6.8
- CUDA/cuDNN version:10.0
- GPU model and memory:  GeForce RTX 2060

**Describe the current behavior**
It seems that I can't build a graph in which I assign dynamically some specific values in some specific positions of the filters during the training phase. However I'm not an expert on TF2.0 maybe I didn't understand the new usage of the hidden placeholders, or some operations do not respect the symbolic programming. 

ValueError: tf.function-decorated function tried to create variables on non-first call.

**Describe the expected behavior**
With the script below my idea is to understand how I can modify, with a customized layer, the value of the tensors of a network being trained. 
I would like to model this behaviour with static and dynamic assignments. 
It seems that I succeeded by assigning constant values see the function *assign_op*, 
while if I use the symbolic values ​​of the tensor to modify the same values of the tensor
​​I cannot understand what is wrong. I make several tests but fail, in particular, with atomic assignments. Where for atomic assignments I mean single value tensor assignments. 

**Code to reproduce the issue**
Here I provide a reproducible test case. The problem is in the function: assign_dyn_vals() once I instantiate a variable and I try to assign to this variable some computations. 
```python
import tensorflow as tf
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

import keras
from keras.models import Sequential
from keras.datasets import mnist
from keras import layers
from keras import backend as K
from keras.layers import Dense, Dropout, Flatten, Lambda
from keras.layers import Conv2D


batch_size = 128
num_classes = 10
epochs = 12
# input image dimensions
img_rows, img_cols = 28, 28


def create_model():
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3, 3),
                     activation='relu',
                     input_shape=input_shape))
    model.add(Conv2D(2, (3, 3), activation='relu'))
    model.add(CustomLayer())
    model.add(Conv2D(1, (3, 3), activation='relu'))
    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
    return model

def ith_element(x, i, j, n_chan):
    return tf.reshape( x[i:i + 1, j:j + 1, n_chan ], (-1,))

#A sort of dynamic assignment
def assign_dyn_vals( x, h, w, n_chan, T=0.5):
    row = 1
    col = 1
    sel_chan = 1
    out_val0 = ith_element(x, row, col, sel_chan)*T
    out_val1 = ith_element(x, row, col, sel_chan)*T
    x1 = tf.Variable(tf.zeros([h,w,n_chan], tf.float32)) ###???????????????
    #x1=tf.identity(x) #obviously with this works...
    x1 = x1[1:2,1:2, sel_chan].assign(tf.math.accumulate_n([out_val0, out_val1 ], name=""value_to_assign"")) ###???????????????
    return(x1)


@tf.function
#Static assignment
def assign_op(x, up_val, cord_i, cord_j, n_chan):
    updates = tf.constant([up_val])
    indices = tf.constant([[-1, cord_i, cord_j, n_chan]])
    updated = tf.tensor_scatter_nd_update(x, indices, updates)
    return(updated)

@tf.function
def out_res(x):
    dim = x.shape
    h = dim[1]
    w = dim[2]
    n_chan = dim[3]

    #Dynamic assignment on a tensor with some modifications ???????????????
    copy_img = tf.identity(x)
    thresh_img= assign_dyn_vals(copy_img, h, w, n_chan, 0.5)

    #Static assignment.
    up_val =  17.0
    thresh_img = assign_op(thresh_img, up_val, 0, 2, 1)
    return thresh_img

@tf.custom_gradient
def custom_op(x):
    result = out_res(x) # do forward computation
    def custom_grad(dy):
        print(dy, [dy])
        grad = dy # compute gradient
        return grad
    return result, custom_grad

class CustomLayer(layers.Layer):
    def __init__(self):
        super(CustomLayer, self).__init__()

    def call(self, x):
        return custom_op(x)

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
print(x_train.shape)
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
# build the model

model = create_model()
# compile the model

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
# train the model
model.summary()

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))
```


"
34548,Does TFLite (Python API) require Tensorflow installed (RISCV64 porting),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux from Buildroot 2019.08.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: RISCV64 Ariane core
- TensorFlow installed from (source or binary): TF non installed, TFLite installed
- TensorFlow version: 2.0.0
- Python version: Python 3.7.5
- Installed using virtualenv? pip? conda?: I cross-compiled a wheel after I adapted the instructions as https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package
- Bazel version (if compiling from source): none
- GCC/Compiler version (if compiling from source): GCC 7.4.0 (Ubuntu)
- CUDA/cuDNN version: none
- GPU model and memory: none

**Describe the problem**

I have Python 3, NumPy and PyPi running on Ariane (RISCV64, https://github.com/pulp-platform/ariane). The CPU and system run on FPGA (emulated).

I assumed that to run the TFLite Python interpreter, I needed just a wheel of the `tflite_runtime` that I crosscompiled (`tflite_runtime-2.0.0-cp37-cp37m-linux_riscv64.whl`).

After I installed the `tflite_runtime` wheel, I tried the following:
```
# echo ""import tflite_runtime.interpreter as tflite"" > test.py
# python test.py
```

This gives the following error:
```
Traceback (most recent call last):
  File ""/usr/lib/python3.7/site-packages/tflite_runtime/interpreter.py"", line 27, in <module>
    from tensorflow.python.util.lazy_loader import LazyLoader
ModuleNotFoundError: No module named 'tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.7/site-packages/tflite_runtime/interpreter_wrapper.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""/usr/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 670, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 583, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 1015, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: /usr/lib/python3.7/site-packages/tflite_runtime/_interpreter_wrapper.so: undefined symbol: shm_open

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 1, in <module>
    import tflite_runtime.interpreter as tflite
  File ""/usr/lib/python3.7/site-packages/tflite_runtime/interpreter.py"", line 44, in <module>
    from tflite_runtime import interpreter_wrapper as _interpreter_wrapper
  File ""/usr/lib/python3.7/site-packages/tflite_runtime/interpreter_wrapper.py"", line 17, in <module>
    _interpreter_wrapper = swig_import_helper()
  File ""/usr/lib/python3.7/site-packages/tflite_runtime/interpreter_wrapper.py"", line 16, in swig_import_helper
    return importlib.import_module('_interpreter_wrapper')
  File ""/usr/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_interpreter_wrapper'
```

Do I need a wheel of Tensorflow as well? Is there a way to provide the `LazyLoader` without cross-compiling the entire Tensorflow for RISCV64?
"
34547,AttributeError: module 'tensorflow' has no attribute 'data',"**System information**
- OS Platform and Distribution :Linux Ubuntu 18.0.4
- TensorFlow installed from (source or binary): anaconda3
- TensorFlow version (use command below):2.0.0
- Python version:3.6.9
- CUDA/cuDNN version:10.1
- GPU model and memory:GTX2070 8GB

**Code to reproduce the issue**
``` python
from net.baseline import Baseline
from tensorflow import keras
import tensorflow as tf
from data.dataset import MSRA

train_data = tf.data.Dataset.from_tensor_slices((images, labels))
train_data = train_data.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=len(images)))
train_data = train_data.map(dataset.load_and_preprocess_data)
train_data = train_data.batch(BATCH_SIZE)
```

**info / logs**
```
Traceback (most recent call last):
  File ""/home/lxz/PycharmProjects/PoseREN_tf2/src/train_baseline.py"", line 26, in <module>
    train_data = tf.data.Dataset.from_tensor_slices((images, labels))
AttributeError: module 'tensorflow' has no attribute 'data'
```"
34544,"Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [585,1024,3], [batch]: [600,799,3]","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary (Used pip to install tensorflow 1.15 and downloaded models from github and used checkout version v1.13.0 and after that followed: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md
- TensorFlow version (use command below): 1.15
- Python version: 3.6.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: Tesla K80


I am trying to train a model, at first I had dataset of 5000 images and training worked fine, Now I have added couple of more images and now my dataset contains 6,423‬ images. Now when I use:

python model_main.py --logtostderr --pipeline_config_path=training/faster_rcnn_resnet50_coco.config --model_dir=training

It starts settings up for couple of minutes and after these lines:

```
    INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.                                                                                                                                                                           
    I1123 10:26:21.548237 140482563244160 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.                                                                                                                     
    2019-11-23 10:28:30.801453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0 
```

I get following erros:

```
    2019-11-23 10:08:38.843259: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:788 : Not found: Resource localhost/_3_hash_table_2/N10tensorflow6lookup15LookupInterfaceE does not exist.               
    2019-11-23 10:08:38.843323: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:788 : Not found: Resource localhost/_1_hash_table_1/N10tensorflow6lookup15LookupInterfaceE does not exist.               
    2019-11-23 10:08:38.843345: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:788 : Not found: Resource localhost/_2_hash_table/N10tensorflow6lookup15LookupInterfaceE does not exist.                 
    2019-11-23 10:08:38.851405: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:788 : Not found: Resource localhost/_3_hash_table_2/N10tensorflow6lookup15LookupInterfaceE does not exist.               
    2019-11-23 10:08:38.851488: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:788 : Not found: Resource localhost/_1_hash_table_1/N10tensorflow6lookup15LookupInterfaceE does not exist.               
    2019-11-23 10:08:38.851512: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:788 : Not found: Resource localhost/_2_hash_table/N10tensorflow6lookup15LookupInterfaceE does not exist.                 
    2019-11-23 10:08:38.851807: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:788 : Not found: Resource localhost/_1_hash_table_1/N10tensorflow6lookup15LookupInterfaceE does not exist.               
    2019-11-23 10:08:38.851848: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:788 : Not found: Resource localhost/_2_hash_table/N10tensorflow6lookup15LookupInterfaceE does not exist.                 
    2019-11-23 10:08:38.851899: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:788 : Not found: Resource localhost/_3_hash_table_2/N10tensorflow6lookup15LookupInterfaceE does not exist.               
    Traceback (most recent call last):                                                                                                                                                                                                             
    File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call                                                                                                                                 
     return fn(*args)                                                                                                                                                                                                                           
    File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn                                                                                                                                  
     target_list, run_metadata)                                                                                                                                                                                                                 
    File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun                                                                                                                      
     run_metadata)                                                                                                                                                                                                                            
    tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.                                                                                                                                                           
    (0) Invalid argument: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [585,1024,3], [batch]: [600,799,3]                                                                                                   
    [[{{node IteratorGetNext}}]]                                                                                                                                                                                                                 
    [[ToAbsoluteCoordinates_118/Assert/AssertGuard/Assert/data_0/_5709]]                                                                                                                                                                  
    (1) Invalid argument: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [585,1024,3], [batch]: [600,799,3]                                                                                                   
    [[{{node IteratorGetNext}}]]                                                                                                                                                                                                        
    0 successful operations.                                                                                                                                                                                                                     
    0 derived errors ignored. 
```


and training stops.

My train.record and test.record: https://drive.google.com/file/d/1sWn_bNp_9TwGMDxxA52WKgeI9B7GfBnr/view?usp=sharing

I am using faster_rcnn_resnet50_coco_2018_01_28 and my config file: https://drive.google.com/file/d/1tsKcPgDUoQdERzvFCfQ4eBBraS4DcNnb/view?usp=sharing"
34543,Hey i need help with this problem in kali linux,"Umm so i was using Kali linux today and I wanted to download HiddenEye but i get this problem here is a screneshot - http://prntscr.com/q0xuqi

Any way on how i can fix that and i am new to kali linux stuff"
34542,向下兼容性太差了，一升级全完蛋，好气人啊！,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
34541,RNN with cell  get_initial_state  and state_size incompatible,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): TF2.0
- Python version: py3.74
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

ValueError: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(None, 100, 1), ndim=3)]); however `cell.state_size` is [100]

**Describe the expected behavior**

**Code to reproduce the issue**
```
# coding:utf-8
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
import tensorflow.keras.layers as layers
import numpy as np
from tensorflow.keras.utils import plot_model

from tensorflow.keras.utils import plot_model
from tensorflow.keras import layers
tf.keras.backend.set_floatx('float64')
#%%###################################################################
# y(n) = func_g(x)y(n-1) + X\beta + \alpha
###############################################################
def func_g (x):
    v = np.sin(x)
    return v
########################################################
#%% deine the neutron for X\beta + alpha
############################################
class Linear(layers.Layer):

  def __init__(self, CityNum, CityFactorNum):   
    self.CityNum = CityNum    
    self.CityFactorNum = CityFactorNum
    super(Linear, self).__init__()
    
  def build(self, input_shape):
    self.beta  = self.add_weight(shape=(self.CityFactorNum, 1),  initializer='random_normal', trainable=True)
    self.alpha = self.add_weight(shape=(self.CityNum,),        initializer='random_normal', trainable=True)

  def call(self, X):
    v = tf.matmul( X[:,1:], self.beta)  + self.alpha[ tf.dtypes.cast( X[0,0], tf.int32 ) ]
    return v
#############################################33
#%% define rnn cell node
###############################################
class MinimalRNNCell(tf.keras.layers.Layer):
    def __init__(self, units, CityNum, CityFactorNum, **kwargs):
        self.units = units
        self.state_size = 100
        self.CityNum = CityNum    
        self.CityFactorNum = CityFactorNum
        super(MinimalRNNCell, self).__init__(**kwargs)

    def build(self, input_shape):
        
        self.beta  = self.add_weight(shape=(self.CityNum,),  initializer='random_normal', trainable=True)
        self.alpha = self.add_weight(shape=(self.CityFactorNum-1,), initializer='random_normal', trainable=True)
        
        self.dense_1  = layers.Dense(32, activation='tanh')
        self.dense_2  = layers.Dense(64, activation='tanh')
        self.dense_3  = layers.Dense(64, activation='tanh')
        self.dense_4  = layers.Dense(64, activation='tanh')
        self.dense_5= layers.Dense(1)

        
        self.Xbeta_Add_alpha = Linear(self.CityNum, self.CityFactorNum)
                
        self.built = True
    
    def get_initial_state(self, inputs, batch_size=None, dtype=None):
        initial_states = []
        initial_states = [tf.ones(1)]

        return tuple(initial_states)
        

    def call(self, inputs, states):
 
        X_input = inputs[0]
        U_input = inputs[1]
     
        s1 = states[0] 

        gU = self.dense_1(U_input)
        gU = self.dense_2(gU)
        gU = self.dense_3(gU)
        gU = self.dense_4(gU)
        gU = self.dense_5(gU)
        X = self.Xbeta_Add_alpha(U_input)

        gUZ  = layers.dot( [gU, s1], axes=1, name = 'dot')
        gUZX = layers.add( [gUZ, X], name = 'add')
    
        output = [gUZ, gUZX]
        new_state = [gUZX]
        
        return output, new_state

#########################################
#%% define model 
sample_num = 2000
time_step = 100
CityNum, CityFactorNum = 100, 1
UFactorNum = 1
#############################################
def rnn_model (CityNum, CityFactorNum, time_step):
    
    input_X = tf.keras.Input(shape=[time_step, CityFactorNum])
    input_U = tf.keras.Input(shape=[time_step, UFactorNum])
    
    
    
    cells = MinimalRNNCell(1, CityNum, CityFactorNum)
    
    #rnn = tf.keras.layers.RNN(cells, return_sequences=True)(input)
    #out = tf.keras.layers.Dense(units=1)(rnn)

    out = tf.keras.layers.RNN(cells, return_sequences=True)([input_X, input_U])
    out = tf.keras.layers.Dense(1)(out)
    
    
    
    model = tf.keras.Model(inputs=[input_X, input_U], outputs=out)
    plot_model(model, to_file='model.png')
    
    model.summary()
    model.compile(optimizer='rmsprop',  loss=['mse'],  metrics=['mse'])
    
    return model 

################################################################
#%% set the test data
##(sample_num,  time_step_num, units)
######################################################################
sample_num = 2000
time_step = 100
CityNum, CityFactorNum = 100, 1

X = np.random.uniform(-10,10, size=(sample_num,time_step,1))
Y = np.zeros((sample_num,time_step,1))

#for i1 in range()


for i1 in range(sample_num):
    for i2 in range(1,time_step):
        for i3 in range(1):
            Y[i1, i2, i3] = func_g(X[i1, i2, i3]) +  Y[i1, i2-1, i3]

#-----------------------------------------------------------------------
model = rnn_model (CityNum, CityFactorNum, time_step)
model.fit(X, Y, batch_size = 100, epochs = 50)
#----------------------------------------------------------------------
start = np.random.uniform(-10,10, size=(1,time_step,1))
start = np.linspace(-10,10,time_step)
start = np.reshape(start, (1,time_step,1))
next = model.predict(start)


plt.plot(start[0,:,0], next[0,:,0],'rs')
################################################################
#%% true solution 
##############################################################
next = next
for i1 in range(1):
    for i2 in range(1,time_step):
        for i3 in range(1):
            next[i1, i2, i3] = func_g(start[i1, i2, i3]) + next[i1, i2-1, i3]

plt.plot(start[0,:,0], next[0,:,0],'bo')

```"
34540,autograph bug,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.15
- Python version:3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
autograph failed when I use autoaugment which provided on [here](https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py) in tf.function
**Describe the expected behavior**
Works well with autograph
**Code to reproduce the issue**
[colab](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/zh-cn/tutorials/quickstart/beginner.ipynb#scrollTo=jvl8IpUaM-VL)

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
[tensorflow.log](https://github.com/tensorflow/tensorflow/files/3882224/tensorflow.log)

"
34539,RNN document is not clear,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

Problem 1:
Could you provides the math model of the rnn?

Problem 2:   this is not return information about  the method of 
get_initial_state(inputs=None, batch_size=None, dtype=None).
and 
how to define own get_initial_state ?
what is the connect between   state_size  and get_initial_state
Problem 3, 
could  you write more clear about  arguments  of the methods:  call, build, get_initial_state,
such as the   dimension of them.  each dimension is what .

Problem 4:
is the  cell  defined layer by user ?

thanks! 













 

"
34538,Build from head fails with Bazel 1.1.0 but succeeds with Bazel 0.26.1,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source (building source issue)
- TensorFlow version: build from head (2.0.0)
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: Conda
- Bazel version (if compiling from source): 1.1.0 fails while 0.26.1 succeeds
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6.5
- GPU model and memory: Nvidia RTX 2080 Ti

**Describe the problem**

Building with Bazel 1.1.0 fails with the following message:
ImportError: /home/daniel/.cache/bazel/_bazel_daniel/79db702fc9f94af7d11e11c5d64854d0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/compiler/tf2tensorrt/_wrap_py_utils.so: undefined symbol: _ZN10tensorflowlsERSoRKNS_6StatusE

Note: The failure of target //tensorflow/python/keras/api:create_tensorflow.python_api_1_keras_python_api_gen (with exit code 1) may have been caused by the fact that it is a Python 2 program that was built in the host configuration, which uses Python 3. You can change the host configuration (for the entire build) to instead use Python 2 by setting --host_force_python=PY2.
If this error started occurring in Bazel 0.27 and later, it may be because the Python toolchain now enforces that targets analyzed as PY2 and PY3 run under a Python 2 and Python 3 interpreter, respectively. See https://github.com/bazelbuild/bazel/issues/7899 for more information.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout -b mybranch
./configure
[tf_configure.bazelrc.txt](https://github.com/tensorflow/tensorflow/files/3882194/tf_configure.bazelrc.txt)
bazel build --explain=verbose_explanations.txt --verbose_explanations --verbose_failures --subcommands=pretty_print --config=opt --config=cuda --config=v2 --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/tools/pip_package:build_pip_package &> log.txt

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

See ful log.txt (which shows failure with Bazel 1.1.0)
and log2.txt (which shows success with Bazel 0.26.1)
from the following link: [Dropbox folder](https://www.dropbox.com/sh/mz1qvrd2yw0fb0a/AAB5ZAIWH0fj7C5okI1By-rna?dl=0)"
34536,Is TF Lite optimized for nvidia gpu's and Intel CPUs?,"Is TF Lite optimized for nvidia gpu's (as similar to TensorRT) and Intel CPUs. If not is there a list of supported hardware/accelerators out there?

"
34534,[TF2.0] tf.function use within tf.custom_gradient is extremly slow,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I wrote a simple example similar to the provided examples
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not tested
- TensorFlow installed from (source or binary): pip 
- TensorFlow version (use command below): r2.0
- Python version: 3.7
- Bazel version (if compiling from source): does not apply
- GCC/Compiler version (if compiling from source): does not apply
- CUDA/cuDNN version: 10.2
- GPU model and memory: Nvidia GTX 1050 2048MB

**Describe the current behavior**
When calling a `tf.function` from within a `tf.custom_gradient` function a large delay occurs **before** and **after** the `tf.function` call. With more complex functions this delay before and after goes up.

**Describe the expected behavior**
There should not be any delay or at least no perceivable.

**Code to reproduce the issue**
The following code snippet reproduces this behavior. I execute the code twice to account for `tf.function`s tracing which has to be one once for `_df`.
```python
@tf.function
def _df(x):
    tf.print('Start inner')
    start = tf.timestamp()
    
    result = x@x
    
    end = tf.timestamp()
    tf.print('End inner; took: ', end-start)
    return result
    
@tf.custom_gradient
def f(x):
    def df(dy):
        tf.print('Before outer')
        start = tf.timestamp()
        
        grad = _df(x)
        
        end = tf.timestamp()
        tf.print('After outer; took: ', end-start)
        return dy*grad
    return x@x, df


for i in range(2):
    x = tf.random.normal((1000, 1000))
    t = tf.timestamp()
    with tf.GradientTape() as tape:
        tape.watch([x])
        r = f(x)
    tf.print('Forwardpass took', tf.timestamp() - t)
    t = tf.timestamp()
    tape.gradient(r, x)
    tf.print('Backwardpass took', tf.timestamp() - t)
```

Output:
```
Forwardpass took 0.00038313865661621094
Before outer
Start inner
End inner; took:  2.6941299438476563e-05
After outer; took:  0.093798160552978516
Backwardpass took 0.099112987518310547
Forwardpass took 0.0002689361572265625
Before outer
Start inner
End inner; took:  2.8848648071289063e-05
After outer; took:  0.00881505012512207
Backwardpass took 0.01347804069519043
```"
34530,Prediction fails on variable size inputs due to np.concatenate,"I've built an autoencoder that takes input of size `(None, 2)` (batch size must be 1). This works for training, because it deals with each batch individually. I've posted my implementation [here]( https://datascience.stackexchange.com/questions/63571/tensorflow-training-with-batch-size-of-1-none-features-but-model-expects-ex?noredirect=1#comment68767_63571)

When it comes to prediction however, the model first (correctly) predicts on every input, but then fails because it tries to concatenate them, as you can see from the traceback.

````
self.results = np.concatenate(self.results, axis=0)
  File ""<__array_function__ internals>"", line 6, in concatenate
ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 12 and the array at index 1 has size 51
2019-11-22 16:08:58.238687: W tensorflow/core/kernels/data/generator_dataset_op.cc:102] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
````

Is there any way to disable this, in order to keep the performance optimization? Predicting on each sample in a loop instead gives a warning, and is roughly 10 times slower.
````
WARNING:tensorflow:5 out of the last 5 calls to <function _make_execution_function.<locals>.distributed_function at 0x7f63d8635268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
````"
34528,External loss function raises error on incompatible types,"On TensorFlow 2.0 (OS Ubuntu 16.04), when I've an external loss function, the tf.keras.model fit() function call raises an error of incompatible types, whereas the same code on TensorFlow 1.15 does not raise any error and works fine.  The function fit() fails with:

```
(...)
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py in
_apply_op_helper(self, op_type_name, name, **keywords)
    561                   ""%s type %s of argument '%s'."" %
    562                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
--> 563                    inferred_from[input_arg.type_attr]))
    564 
    565           types = [values.dtype]

TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type uint8 of
argument 'x'.
```

The minimal code to reproduce is:

```
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import backend as K

def loss_func(y_true, y_pred):
    y_true_f = K.batch_flatten(y_true)
    y_pred_f = K.batch_flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f, axis=1, keepdims=True)
    union = K.sum(y_true_f, axis=1, keepdims=True) \
            + K.sum(y_pred_f, axis=1, keepdims=True)
    return -(2. * intersection + K.epsilon()) / (union + K.epsilon())

(Xtr, Ytr), (Xva, Yva) = tf.keras.datasets.cifar10.load_data()
Xtr, Ytr, Xva, Yva, nc = Xtr[:1000], Ytr[:1000], Xva[:100], Yva[:100], 10
Xtr, Xva = Xtr.astype('float32') / 255, Xva.astype('float32') / 255
Ytr, Yva, ins = to_categorical(Ytr, nc), to_categorical(Yva, nc), Xtr.shape[1:]

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Input(ins))
model.add(tf.keras.layers.Conv2D(8, (3, 3)))
model.add(tf.keras.layers.Activation('relu'))
model.add(tf.keras.layers.Conv2D(8, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.25))
model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))
model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.25))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(nc, activation='softmax'))
opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)
model.compile(loss=loss_func, optimizer=opt, metrics=[])

Ytr, Yva = Ytr.astype('uint8'), Yva.astype('uint8') # (1)

model.fit(x=Xtr, y=Ytr, batch_size=32, epochs=1, validation_data=(Xva, Yva))
```

If I remove line (1) it works on TensorFlow 2.0."
34527,Xxx,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

https://pornhublive.com/landing/mg-mobile/mg-top-cats-v2/&AFNO=1-537210&UHNSMTY=437?stno=2-630-0-5767-0-0-3192-4807"
34526,Xxx,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):



**Provide the text output from tflite_convert**

```
# Copy and paste here
https://pornhublive.com/landing/mg-mobile/mg-top-cats-v2/&AFNO=1-537210&UHNSMTY=437?stno=2-630-0-5767-0-0-3192-4807
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached."
34525,Cannot Use GpuDelegate on simple model with 3D input,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina and Android 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.0.0


**Provide the text output from tflite_convert**

```
2019-11-22 17:05:40.034915: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-22 17:05:40.034972: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-22 17:05:40.046101: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-22 17:05:40.046128: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 39 nodes (34), 63 edges (58), time = 4.433ms.
2019-11-22 17:05:40.046137: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.069ms.
2019-11-22 17:05:40.075988: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-22 17:05:40.076066: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-22 17:05:40.089383: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-22 17:05:40.089403: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 34 nodes (-5), 54 edges (-9), time = 9.559ms.
2019-11-22 17:05:40.089408: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 34 nodes (0), 54 edges (0), time = 0.949ms.
```

**Any other info / logs**

*The model*

```
import tensorflow as tf

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Input(shape=(40, 300), dtype=tf.dtypes.float32))
model.add(tf.keras.layers.Dense(10))

saved_model_dir = './saved_model/'
model.save(saved_model_dir, save_format='tf')
```

*TFLite conversion code*

```
tflite_model_path = './model.tflite'
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]
tflite_model = converter.convert()
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)
```

*Android code*

```
String dst = ""<Absolute path to the .tflite file>""
Interpreter.Options options = new Interpreter.Options();
GpuDelegate gpuDelegate = new GpuDelegate();
options.addDelegate(gpuDelegate);
Interpreter interpreter = new Interpreter(new File(dst), options);  // The exception is thrown here

float[][][] input = new float[1][40][300];
for (int i = 0; i < input.length; i++) {
    for (int j = 0; j < input[i].length; j++) {
        for (int k = 0; k < input[i][j].length; k++) {
            input[i][j][k] = (float) Math.random();
        }
    }
}
float[][][] output = new float[1][40][10];
interpreter.run(input, output);
```

This works on Android when running on CPU (not using the GPU delegate), but when using the GPU delegate, the following exception is thrown:
```
E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.example.tflitegpu, PID: 24680
    java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.tflitegpu/com.example.tflitegpu.MainActivity}: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: FULLY_CONNECTED: Amount of input data should match weights width
    TfLiteGpuDelegate Prepare: delegate is not initialized
    Node number 2 (TfLiteGpuDelegateV2) failed to prepare.
```

The Full Traceback and the TFLite file are attached.

Thank you for your help!

[traceback.txt](https://github.com/tensorflow/tensorflow/files/3880354/traceback.txt)
[model.tflite.zip](https://github.com/tensorflow/tensorflow/files/3880355/model.tflite.zip)
"
34524,`tfjs.converters.convert_tf_saved_model` fails for NN with embedding (in most cases),"**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux x64
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
2.0.0
- Python version:
3.7.4
- CUDA/cuDNN version:
CUDA Version: 10.0
- GPU model and memory:
Multiple GeForce GTX 1080

**Describe the current behavior**

`tfjs.converters.convert_tf_saved_model` fails:
1. When converting module with `tf.nn.embedding_lookup` and single GPU (of few in the system) is used (for conversion).
or
2. If module contains prebuilt `tf.keras.layers.Embedding` layer.


**Describe the expected behavior**

`tfjs.converters.convert_tf_saved_model` is expected to work fine in both cases.

**Code to reproduce the issue**

Case 1:
```python
import tensorflow as tf
import tensorflowjs as tfjs

gpus = tf.config.experimental.list_physical_devices('GPU')
assert len(gpus) > 1, 'Probably multiple GPUs required'
tf.config.experimental.set_visible_devices([gpus[0]], 'GPU')

class EmbModule(tf.Module):
    
    def __init__(self):
        super().__init__()
    
    @tf.function(input_signature = [tf.TensorSpec(shape = [1, 2], dtype = tf.int32)])
    def apply(self, inp):
        return tf.nn.embedding_lookup(tf.ones([3, 4]), inp)

embModule = EmbModule()

tf.saved_model.save(embModule, 'embModule/1/')
# Next line fails as single GPU (of few in the system) is used:
tfjs.converters.convert_tf_saved_model('embModule/1/', 'embModule/1-js')
```
Error:
```
UnknownError: Failed to create session

During handling of the above exception, another exception occurred:
...
AssertionError: Identity is not in graph
```

Case 2:
```python
import tensorflow as tf
import tensorflowjs as tfjs

class EmbModule(tf.Module):
    
    def __init__(self):
        super().__init__()
        self.emb = tf.keras.layers.Embedding(3, 4)
        self.emb.build((1, 2))
    
    @tf.function(input_signature = [tf.TensorSpec(shape = [1, 2], dtype = tf.int32)])
    def apply(self, inp):
        return self.emb(inp)

embModule = EmbModule()

tf.saved_model.save(embModule, 'embModule/1/')
# Next line fails as 'Embedding' layer was built in constructor:
tfjs.converters.convert_tf_saved_model('embModule/1/', 'embModule/1-js')
```
Error:
```
InvalidArgumentError: Input 0 of node StatefulPartitionedCall/embedding/embedding_lookup was passed float from Func/StatefulPartitionedCall/input/_2:0 incompatible with expected resource.

During handling of the above exception, another exception occurred:
...
ValueError: Input 0 of node StatefulPartitionedCall/embedding/embedding_lookup was passed float from Func/StatefulPartitionedCall/input/_2:0 incompatible with expected resource.

During handling of the above exception, another exception occurred:
...
AssertionError: Identity is not in graph
```
"
34523,TensorFlow Lite schema updater loses floating-point precision,"I am concerned about [tensorflow/lite/schema/upgrade_schema.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/upgrade_schema.py). I see that the schema upgrade is performed by converting flatbuffers binary to JSON and then backward.
However, there is a problem with flatbuffers binary -> JSON step described in https://github.com/google/flatbuffers/issues/5371 which leads to float32 precision loss. `float`-s are serialized as `""0.6f""` and `double`-s as `""0.12d""` (equivalent to C++'s stringstream API). Thus, for example, float32 values that are very small, e.g. `0.123e-6`, will be written as `0.0`."
34521,keras.Model does not work with keras.Input that was created with `tensor=` kwarg.,"### System information
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04 LTS**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **1.15.0-rc2**
- Python version: **3.7.4**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

### current behavior
`keras.Input` and `keras.InputLayer` give the option to pass in a `tf.placeholder` through the argument `tensor=None`. When using the output of `keras.Input(tensor=some_placeholder)` as inputs to the functional keras.Model and subsequently calling `model.predict(batch)` on the newly created model an error occurs:

```
ValueError: ('Error when checking model input: expected no data, but got:', array([[0., 1.],
       [2., 3.],
       [4., 5.],
       [6., 7.],
       [8., 9.]]))
```


### expected behavior
No error occurs and keras.Model correctly feeds the inputs through the graph.

### Code to reproduce the issue
The following code breaks:
**snippet 1**
```
import tensorflow as tf
import tensorflow.keras as keras
import numpy as np

print(""TF VERSION: "", tf.__version__)

ph = tf.placeholder(shape=[None,2], dtype=tf.float32)

# create input layer from a predefined tensorflow placeholder
inputs = keras.Input(tensor=ph)
# perform some operation
A = tf.constant([[0.5, 0],[0, 0.5]], dtype=tf.float32)
x = tf.linalg.matmul(inputs, A)
outputs = tf.reduce_sum(x, axis=1)

# make a model
model = keras.Model(inputs=inputs, outputs=outputs)

# try to feed a batch through the model
batch = np.linspace(0, 9, 10).reshape(5, 2)
out = model.predict(batch)

print(out)
```
### Explanation
I already debugged through the keras code and I think I spotted the issue:
_tesorflow/python/keras/engine/network.py, lines 342-352_
**snippet 2**
```
for i, layer in enumerate(self._input_layers):
      self.input_names.append(layer.name)
      if layer.is_placeholder:
        self._feed_input_names.append(layer.name)
        # Use batch_input_shape here because non-eager composite tensors may not
        # have a shape attribute that's meaningful (sparse, for instance, has
        # a tensor that's non-constant and needs to be fed). This means that
        # input layers that create placeholders will need to have the
        # batch_input_shape attr to allow for input shape validation.
        self._feed_input_shapes.append(layer._batch_input_shape)
        self._feed_inputs.append(layer.input)
```
snippet 2 is taken from the Network constructor. As can be seen, only tensors coming from layers with `is_placeholder` set to true are added to the `_feed_inputs` array.
In out case, this array is empty, because our `InputLayer` that was created from a `tf.placeholder` has `is_placeholder` set to false.
Looking at the constructor code of `InputLayer` we can see why this is the case:
_tensorflow/python/keras/engine/input_layer.py, lines 115 - 138_
**snippet 3**
```
    if input_tensor is None:
      if input_shape is not None:
        batch_input_shape = (batch_size,) + tuple(input_shape)
      else:
        batch_input_shape = None
      graph = backend.get_graph()
      with graph.as_default():
        input_tensor = backend.placeholder(
            shape=batch_input_shape,
            dtype=dtype,
            name=self.name,
            sparse=sparse,
            ragged=ragged)

      self.is_placeholder = True
      self._batch_input_shape = batch_input_shape
    else:
      if not tf_utils.is_symbolic_tensor(input_tensor):
        raise ValueError('You should not pass an EagerTensor to `Input`. '
                         'For example, instead of creating an '
                         'InputLayer, you should instantiate your model and '
                         'directly call it on your input.')
      self.is_placeholder = False
      self._batch_input_shape = tuple(input_tensor.shape.as_list())
```
input_tensor has the value from the `tensor=` argument. In our case, this holds the placeholder we passed to `Input(tensor=ph)`. Since it is not None `self.is_placeholder = False` is run in the else-case.
This subsequently results in the layer not being added to the _feed_inputs of the model which then does not expect any inputs to the predict method.

The issue can be worked around by manually setting the `is_placeholder` field of our input layer.
**snippet 4**
```
inputs._keras_history[0].is_placeholder = True
```
Adding this line of code just below line 10 of **snippet 1** resolves the error.
Fixed code:
**snippet 5**
```
import tensorflow as tf
import tensorflow.keras as keras
import numpy as np

print(""TF VERSION: "", tf.__version__)

ph = tf.placeholder(shape=[None,2], dtype=tf.float32)

# create input layer from a predefined tensorflow placeholder
inputs = keras.Input(tensor=ph)
inputs._keras_history[0].is_placeholder=True
# perform some operation
A = tf.constant([[0.5, 0],[0, 0.5]], dtype=tf.float32)
x = tf.linalg.matmul(inputs, A)
outputs = tf.reduce_sum(x, axis=1)

# make a model
model = keras.Model(inputs=inputs, outputs=outputs)

# try to feed a batch through the model
batch = np.linspace(0, 9, 10).reshape(5, 2)
out = model.predict(batch)

print(out)
```
Output:
```
TF VERSION:  1.15.0-rc2
[0.5 2.5 4.5 6.5 8.5]
```

Since I can not think of any reason, why an InputLayer created from a placeholder should have `is_placeholder=False` I think this issue can be resolved by removing the respective line of code.
"
34520,does not contain a toolchain for cpu 'arm64-v8a' when building tensorflow lite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version:r1.15
- Bazel version (if compiling from source):0.24.1

Hi,
I'm trying to build the tensorflow lite for 'arm64-v8a' with linux on an amd64 with linux. the command i us`bazel build -c opt //tensorflow/lite:libtensorflowlite.so --cpu=arm64-v8a`, I got the following error:

`/home/wang/.cache/bazel/_bazel_wang/c72f4772665ac4cb0690414b07635968/external/local_config_cc/BUILD:45:1: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'arm64-v8a'`
I'm new to bazel and cannot find a detailed walkthrough.what should i do?
"
34519,"tf.range + for x,y in dataset issue","**System information**
- Have I written custom code: yes
- OS Platform and Distribution: win10 1809, pycharm2019.2.3
- TensorFlow installed from: pip install tensorflow-gpu
- TensorFlow version: tensorflow-gpu 2.0.0
- Python version: 3.6
- CUDA/cuDNN version: 10.0/7.6.4
- GPU model and memory: rtx2080 8g

**Describe the current behavior**
tf.range + for x,y in dataset raise exception.

**Describe the expected behavior**
run normally

**Code to reproduce the issue**
```python
import tensorflow as tf

if __name__ == '__main__':
    dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3], [4, 5, 6]))

    @tf.function
    def f():
        for e in tf.range(3):
            for x, y in dataset:
                tf.print(x, y, e)
    f()
```

**Other info / logs**
```
2019-11-22 18:56:57.100113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2019-11-22 18:56:58.357108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2019-11-22 18:56:58.432503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.8
pciBusID: 0000:01:00.0
2019-11-22 18:56:58.432679: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-11-22 18:56:58.433099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-22 18:56:58.433463: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-11-22 18:56:58.435936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.8
pciBusID: 0000:01:00.0
2019-11-22 18:56:58.436136: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-11-22 18:56:58.436559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-22 18:56:59.016772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-22 18:56:59.016930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-22 18:56:59.017022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-22 18:56:59.017714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6273 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-11-22 18:56:59.409303: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: No unary variant device copy function found for direction: 1 and Variant type_index: class tensorflow::data::`anonymous namespace'::DatasetVariantWrapper
	 [[{{node while_input_4/_12}}]]
	 [[Func/while/body/_1/input/_47/_20]]
2019-11-22 18:56:59.409640: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: No unary variant device copy function found for direction: 1 and Variant type_index: class tensorflow::data::`anonymous namespace'::DatasetVariantWrapper
	 [[{{node while_input_4/_12}}]]
Traceback (most recent call last):
  File ""D:/work/python/PycharmProjects/tftest/test.py"", line 83, in <module>
    f()
  File ""D:\work\python\PycharmProjects\tftest\venv-gpu\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""D:\work\python\PycharmProjects\tftest\venv-gpu\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 526, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""D:\work\python\PycharmProjects\tftest\venv-gpu\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""D:\work\python\PycharmProjects\tftest\venv-gpu\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""D:\work\python\PycharmProjects\tftest\venv-gpu\lib\site-packages\tensorflow_core\python\eager\function.py"", line 511, in call
    ctx=ctx)
  File ""D:\work\python\PycharmProjects\tftest\venv-gpu\lib\site-packages\tensorflow_core\python\eager\execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.
  (0) Internal:  No unary variant device copy function found for direction: 1 and Variant type_index: class tensorflow::data::`anonymous namespace'::DatasetVariantWrapper
	 [[{{node while_input_4/_12}}]]
	 [[Func/while/body/_1/input/_47/_20]]
  (1) Internal:  No unary variant device copy function found for direction: 1 and Variant type_index: class tensorflow::data::`anonymous namespace'::DatasetVariantWrapper
	 [[{{node while_input_4/_12}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_f_61]

Function call stack:
f -> f


Process finished with exit code 1
```"
34518," Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.","I researched that issue, but unfortunnately all i was able to find was a compatibility problems. i made sure to install exactly what was specified in the tensorflow gpu installation procedure. The only thing that is different is that i'm running the 430 nvidia driver (which was installed by asking to install the 418)

**System information**
- https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb
- Ubuntu 18.04
- Tensorflow-gpu installed using pip 
- Tensorflow-gpu 2.0.0
- Python version: 3.6.8
- CUDA/cuDNN version: cuda 10.1 /cuDNN 7.6.5
- GPU model and memory: NVIDIA GeForce GTX 1050 Mobile  2Gb

**Describe the current behavior**
``` python
for image_path in TEST_IMAGE_PATHS:
  show_inference(detection_model, image_path)
```
``` python
Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
```
**Describe the expected behavior**
Expecting to show the image with rectangle for detected objects

**Code to reproduce the issue**
https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb

I used the provided code and i'm getting this error while computing the block
 ``` python
for image_path in TEST_IMAGE_PATHS:
  show_inference(detection_model, image_path)
```

**Other info / logs**
 ``` python
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
<ipython-input-18-c197149a2864> in <module>
      1 for image_path in TEST_IMAGE_PATHS:
----> 2   show_inference(detection_model, image_path)

<ipython-input-17-e474e557b383> in show_inference(model, image_path)
      4   image_np = np.array(Image.open(image_path))
      5   # Actual detection.
----> 6   output_dict = run_inference_for_single_image(model, image_np)
      7   # Visualization of the results of a detection.
      8   vis_util.visualize_boxes_and_labels_on_image_array(

<ipython-input-16-4110867dcb70> in run_inference_for_single_image(model, image)
      7 
      8   # Run inference
----> 9   output_dict = model(input_tensor)
     10 
     11   # All outputs are batches tensors.

~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   1079       TypeError: For invalid positional/keyword argument combinations.
   1080     """"""
-> 1081     return self._call_impl(args, kwargs)
   1082 
   1083   def _call_impl(self, args, kwargs, cancellation_manager=None):

~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _call_impl(self, args, kwargs, cancellation_manager)
   1119       raise TypeError(""Keyword arguments {} unknown. Expected {}."".format(
   1120           list(kwargs.keys()), list(self._arg_keywords)))
-> 1121     return self._call_flat(args, self.captured_inputs, cancellation_manager)
   1122 
   1123   def _filtered_call(self, args, kwargs):

~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1222     if executing_eagerly:
   1223       flat_outputs = forward_function.call(
-> 1224           ctx, args, cancellation_manager=cancellation_manager)
   1225     else:
   1226       gradient_name = self._delayed_rewrite_functions.register()

~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    509               inputs=args,
    510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 511               ctx=ctx)
    512         else:
    513           outputs = execute.execute_with_cancellation(

~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~/.local/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

UnknownError: 2 root error(s) found.
  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/batchnorm/mul_1 (defined at /home/niccle27/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]
	 [[Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Switch_5/_970]]
  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/BatchNorm/batchnorm/mul_1 (defined at /home/niccle27/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]
0 successful operations.
0 derived errors ignored. [Op:__inference_pruned_16931]

Function call stack:
pruned -> pruned
 ``` 
"
34517,Tensorflow deadlock when using multi-feed_dicts or multi-queues to different gpus,"
**System information**
- pycharm
- 1.10
- Python version:3.6
- CUDA/cuDNN version:9
- GPU model and memory:GTX 1080Ti

**Describe the current behavior**
I used the data-parallel mode to train my network. For the require of research, I needed feed different category images to different GPU(all The images have same size, such as input dogs' images to GPU 0 and cats' images to GPU 1), so I initiated two tf.placeholder() and feed the different images batch to different GPU and started to train the network. It seems fine at the beginning. But after 4000 iterations or some uncertain steps, it hangs up!
**Describe the expected behavior**
 I needed feed different category images to different GPU(all The images have same size, such as input dogs' images to GPU 0 and cats' images to GPU 1) and apply the averaged gradients.
**Code to reproduce the issue**

images0, images1 = self.load_batches()

self.images0 = tf.placeholder(tf.float32, shape=(self.batch_size, self.c_dim, self.output_size, self.output_size))
self.images1 = tf.placeholder(tf.float32, shape=(self.batch_size, self.c_dim, self.output_size, self.output_size))

for  i  in range(self.config.num_gpus):
    with tf.device(device_setter):
            if i == 0:
                    self.set_tower_loss('', self.images0, Generator, Discriminator)
            else:
                    self.set_tower_loss('', self.images1, Generator, Discriminator)
   
 _, g_grads= self.sess.run([self.d_grads] , feed_dict={self.images0: images0, self.images1: images1} )

**Other info / logs**
GPU memory is employed but utility is 0 and system doe not updated.
"
34514,module 'tensorflow' has no attribute 'enable_eager_execution',"My tensorflow 2.0 has encountered a strange problem, I showed it when creating a new regression model class.
Module 'tensorflow' has no attribute 'enable_eager_execution'
I am confused.I really hope to get your answer. Here is my code.

import tensorflow as tf
tf.enable_eager_execution()
x=tf.constant([[1.0,2.0,3.0],[4.0,5.0,6.0]])
y=tf.constant([[10.0],[20.0]])
class Linear(tf.keras.Model):
    def __init__self():
        super().__init__()
        self.dense=tf.keras.layers.Dense(units=1,kernel_initializer=tf.zeros_initializer(),
                                        bias_initializer=tf.zeros_initializer())
    def call(self,input):
        output=self.dense(input)
        return output

model=Linear()
optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01)
for i in range(100):
    with tf.GradientTape() as tape:
        y_pred=model(x)
        loss=tf.reduce_mean(tf.square(y_pred-y))
    grads=tape.gradient(loss,model.variables)
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-22-12c6c55a29ae> in <module>
      1 import tensorflow as tf
----> 2 tf.enable_eager_execution()
      3 x=tf.constant([[1.0,2.0,3.0],[4.0,5.0,6.0]])
      4 y=tf.constant([[10.0],[20.0]])
      5 class Linear(tf.keras.Model):

AttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'
"
34513,Q,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information** 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached...
"
34512,Learning VM,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
34511,Grammar.txt not found pip3 install --upgrade tensorflow-gpu,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Win10 Pro [Version 10.0.19013.1122]
- Tried to install TensorFlow  installed using pip3
- TensorFlow version: auto-select
- Python version: Python 3.5.0 (v3.5.0:374f501f4567)
- Installed using - pip
- CUDA/cuDNN version: Cuda compilation tools, release 10.1, V10.1.243
- GPU model and memory: NVIDIA GeForce 920M, 2GB



**Describe the problem**

I have `python-3.5.0-embed-amd64` on my system and `pip`, `pip3` also.
They are also defined in path.

Now when I try to install : **pip3 install --upgrade tensorflow-gpu**

It gives me error saying :
```
error: [Errno 2] No such file or directory: 'e:\\software\\python-3.5.0-embed-amd64\\python35.zip\\lib2to3\\Grammar.txt'
```
Full error : [here](https://pastebin.com/VxQRXKYj)

But as you can see, it it present actually:

[![grammer.txt not found pip3 install --upgrade tensorflow-gpu][1]][1]

  [1]: https://i.stack.imgur.com/6BnRr.png

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**

Full error : [here](https://pastebin.com/VxQRXKYj)
"
34510,BufferedInputStream should avoid doing Reset() in Seek when new position is still in buffer. ,"Check the [code here](https://github.com/tensorflow/tensorflow/blob/597a30bc61134ee1deec0b439b3649f346f1f119/tensorflow/core/lib/io/buffered_inputstream.cc#L161) 
``` 
 // Position of the buffer within file.
  const int64 bufpos = Tell();
  if (position < bufpos) {
    // Reset input stream and skip 'position' bytes.
    TF_RETURN_IF_ERROR(Reset());
    return SkipNBytes(position);
  }
```

 I see two issues, correct me if i'm wrong:
1. Tell() doesn't return the position of the buffer within file as suggested in comment, in fact it returns the position of the `pos_` within the file.
2. when `position` is still inside buffer, it will do a `Reset` anyway, which could impact the performance for read later since it would fill buffer of the previously buffered data. 

Fixing PR: #34515 "
34508,How to get sample_weights and learning_phase? (TF2 Eager),"`model.sample_weights` works w/ `from keras` imports but not `from tensorflow.keras`; I need the sample weights _tensor_  to feed to `K.function` to get layer gradients, outputs, etc.

Using `model._feed_sample_weights` instead does eliminate the error, but returns `[]`, and feeding `np.ones(32)` vs. `4*np.ones(32)` for sample weights yields the same outputs (it shouldn't).

<hr>

**Note**: see [this thread](https://github.com/tensorflow/tensorflow/issues/34507) regarding learning_phase

<hr>

**Applied example**:

```python
import tensorflow.keras.backend as K
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
import numpy as np

ipt = Input((16,))
out = Dense(16)(ipt)
model = Model(ipt, out)
model.compile('adam', 'mse')

x = np.random.randn(32, 16)
model.train_on_batch(x, x)

grads = model.optimizer.get_gradients(model.total_loss, model.layers[-1].output)
grads_fn = K.function(inputs=[model.inputs[0], model._feed_targets[0], model.sample_weights[0]], 
                      outputs=grads)
```

**Full error trace**:

```python
File ""<ipython-input-3-ef022490b960>"", line 16, in <module>
  outputs=grads)
File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 3773, in function
  return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)
File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 3670, in __init__
  base_graph=source_graph)
File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\eager\lift_to_graph.py"", line 249, in lift_to_graph
  visited_ops = set([x.op for x in sources])
File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\eager\lift_to_graph.py"", line 249, in <listcomp>
  visited_ops = set([x.op for x in sources])

AttributeError: 'NoneType' object has no attribute 'op'
```"
34507,How to get symbolic learning_phase? (TF2 Eager),"`K.learning_phase()` fetches the value, not the tensor itself - following _backend.py_, I found somewhat of a workaround, but it isn't user/API-friendly. I need the learning phase tensor to feed to `K.function` to get layer gradients, outputs, etc. Works fine w/ `import keras.backend as K`, but fails for `import tensorflow.keras.backend as K`.

Passing the symbolic learning_phase into `K.function` yields:

```python
ValueError: Cannot create an execution function which is comprised of elements 
from multiple graphs.
```

<hr>

**Minimal applied example**:

```python
import tensorflow.keras.backend as K
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
import numpy as np

ipt = Input((16,))
out = Dense(16)(ipt)
model = Model(ipt, out)
model.compile('adam', 'mse')

x = np.random.randn(32, 16)
model.train_on_batch(x, x)

grads = model.optimizer.get_gradients(model.total_loss, model.layers[-1].output)
grads_fn = K.function(inputs=[model.inputs[0], model._feed_targets[0], K.learning_phase()], 
                      outputs=grads)
```

**Full error trace**:

```python
File ""<ipython-input-2-7f74922d7492>"", line 3, in <module>
  outputs=grads)
File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 3773, in function
  return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)
File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 3670, in __init__
  base_graph=source_graph)
File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\eager\lift_to_graph.py"", line 249, in lift_to_graph
  visited_ops = set([x.op for x in sources])
File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\eager\lift_to_graph.py"", line 249, in <listcomp>
  visited_ops = set([x.op for x in sources])

AttributeError: 'int' object has no attribute 'op'
```

<hr>

**Partial workaround**:

```python
import tensorflow.keras.backend as K
from tensorflow.python.eager import context
from tensorflow.python.ops import array_ops
import weakref
from tensorflow.python.framework import func_graph

def symbolic_learning_phase():
  graph = get_graph()
  with graph.as_default():
    if graph not in _GRAPH_LEARNING_PHASES:
      with K.name_scope(''):
        phase = array_ops.placeholder_with_default(
            False, shape=(), name='keras_learning_phase')
      _GRAPH_LEARNING_PHASES[graph] = phase
    return _GRAPH_LEARNING_PHASES[graph]

def get_graph():
  if context.executing_eagerly():
    global _GRAPH
    if _GRAPH is None:
      _GRAPH = func_graph.FuncGraph('keras_graph')
    return _GRAPH
  else:
    return ops.get_default_graph()

_GRAPH = None
_GRAPH_LEARNING_PHASES = weakref.WeakKeyDictionary()

symbolic_learning_phase()
# <tf.Tensor 'keras_learning_phase:0' shape=() dtype=bool>
```
"
34503,[TF2.0] Enable nested tf.custom_gradient,"**System information**
- TensorFlow version (you are using): 2.0
- Python 3.7


**Describe the feature and the current behavior/state.**
Implementing a custom op in python with a custom second-order derivative requires a lot of redundant code because tf.custom_gradient functions can not be nested. The following code will not use the defined second-order gradient:
```
@tf.custom_gradient
def op(x):
  @tf.custom_gradient
  def grad(dy):
    def grad2(dx, ddy):
      print('This will not be executed')
      return 1, 1 # I return a second-order gradient wrt to x and a gradient wrt to dy
    return dy*5, grad2
  return x*5, grad

x = tf.random.normal((1,))
with tf.GradientTape() as tape:
  tape.watch(x)
  with tf.GradientTape() as tape2:
    tape2.watch(x)
    y = op(x)
  dydx = tape2.gradient(y, x)
d2ydx2 = tape.gradient(dydx, x)
```
d2ydx2 is None in this example but I expect it to be 1.

A workaround is the following:
```
@tf.custom_gradient
def grad(x, dy):
  def grad2(dx2):
    print('This is executed')
    return 1, 2 # the first gradient is wrt to x, the second one wrt to dy
  return 5, grad2

@tf.custom_gradient
def op(x):
  return x*5, lambda dy: grad(x, dy)

x = tf.random.normal((1,))
with tf.GradientTape() as tape:
  tape.watch(x)
  with tf.GradientTape() as tape2:
    tape2.watch(x)
    y = op(x)
  dydx = tape2.gradient(y, x)
d2ydx2 = tape.gradient(dydx, x)
print(d2ydx2)
```
In this case d2ydx2 is 1.

**Will this change the current api? How?**
It should not have a direct impact on the API. The behavior of tf.custom_gradient has to include the return values of the parent function. The higher-order derivatives should be computed wrt to every parameter of all parent functions.

**Who will benefit with this feature?**
People who need to implement custom higher-order derivatives either because of performance or because of numerical stability issues."
34502,Concat within tf.range loop throwing error when converting to tflite: StatelessWhile custom implementation needed,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.14.6
- TensorFlow installed from (source or binary): 
- TensorFlow version (or github SHA if from source): '2.0.0-dev20191002'


**Provide the text output from tflite_convert**

```
ConverterError: See console for info.
2019-11-21 19:25:54.528881: E tensorflow/core/platform/hadoop/hadoop_file_system.cc:132] HadoopFileSystem load error: dlopen(libhdfs.dylib, 6): image not found
2019-11-21 19:25:56.545440: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-21 19:25:56.559290: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d67546760 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-21 19:25:56.559306: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-21 19:25:56.568668: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: StatelessWhile
2019-11-21 19:25:56.568994: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4 operators, 19 arrays (0 quantized)
2019-11-21 19:25:56.569203: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 4 operators, 19 arrays (0 quantized)
2019-11-21 19:25:56.569378: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 3 operators, 18 arrays (0 quantized)
2019-11-21 19:25:56.569450: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 3 operators, 18 arrays (0 quantized)
2019-11-21 19:25:56.569489: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 3 operators, 18 arrays (0 quantized)
2019-11-21 19:25:56.569553: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 6769536 bytes, theoretical optimal value: 6769536 bytes.
2019-11-21 19:25:56.569584: I tensorflow/lite/toco/toco_tooling.cc:439] Estimated count of arithmetic ops: 0 ops, equivalently 0 MACs
2019-11-21 19:25:56.569588: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 828
2019-11-21 19:25:56.569891: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: RESHAPE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: StatelessWhile.

```


Below is the function I am trying to convert to tflite (which will eventually be put into a custom layer). I'm trying to extract argmax coordinates from a series of filters. I was initially using **tf.tensor_scatter_nd_update** to accomplish this task, however tflite does not support that op either, so I went with the 'concat_with_padding' loop as described here:  https://www.tensorflow.org/tutorials/customization/performance. The function works fine, it only throws that error when trying to convert to tflite. 

```
@tf.function(input_signature=[tf.TensorSpec(shape=[1,24,34,61,17], dtype=tf.float32)])
def extract_points(heatmaps):
    batch_size = heatmaps.shape[0]
    timesteps = heatmaps.shape[1]
    filter_width = heatmaps.shape[2]
    filter_height = heatmaps.shape[3]
    keypoints = heatmaps.shape[-1]
    
    n = batch_size*timesteps*keypoints
    hm2 = tf.transpose(heatmaps, [0,1,4,2,3])
    hm3 = tf.reshape(hm2, (n,-1))
    x = tf.zeros([n, 2])

    for i in tf.range(n):
        X_argm = tf.argmax(hm3[i])
        coords = tf.reshape(tf.cast(tf.unravel_index(X_argm, (filter_width, filter_height)), 'float32'), (1,2))
        x = tf.concat([x[:i], coords, tf.zeros([n-1-i, 2])], axis=0)
        x = tf.reshape(x, [n, 2])
    return  x       

concrete_func = extract_points.get_concrete_function()
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
tflite_model = converter.convert()
```



"
34501,ValueError: slice index 12231 of dimension 1 out of bounds. for 'strided_slice_14' (op,"Hello, 

I am trying to work on an Intepretable AI solution for Image classification. Our work is based on Smooth Grad CAM plus plus. I had a perfectly working code until  I installed pytorch in my environment. I had been working with keras library. I am passing image to a classifier and trying to visualize the layers.

I am getting an error only after I installed pytorch in the same environment as I was working on my code. Now I am not able to remove the error even if I have created different environments with different tensorflow versions. 


Here is the fullstack of the error:

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
C:\Anaconda\envs\python3.6.5\lib\site-packages\tensorflow\python\framework\ops.py in _create_c_op(graph, node_def, inputs, control_inputs)
   1658   try:
-> 1659     c_op = c_api.TF_FinishOperation(op_desc)
   1660   except errors.InvalidArgumentError as e:

InvalidArgumentError: slice index 7231 of dimension 1 out of bounds. for 'strided_slice_5' (op: 'StridedSlice') with input shapes: [?,1000], [2], [2], [2] and with computed input tensors: input[1] = <0 7231>, input[2] = <1 7232>, input[3] = <1 1>.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-15-4856e9167fcf> in <module>
     10     gradCAM_VGG16 = cam(GradCAM,base_model,target_layer,X)
     11     gradCAMPP_VGG16 = cam(GradCAMPlusPlus,base_model,target_layer,X)
---> 12     smoothgradCAMPP_VGG16 = cam(SmoothGradCAMPlusPlus, base_model, target_layer, X, 10, 0.15)
     13     print(""Guided CAMs for "",decoded_y[0],"" using "",base_model)
     14 

<ipython-input-11-de0c0cde57a2> in cam(classname, model, target_layer, image, n_samples, stdev_spread)
      1 def cam(classname,model,target_layer,image,n_samples=25, stdev_spread=0.15):
      2     class_object = classname(model,target_layer=target_layer)
----> 3     cam = class_object(image)
      4 
      5     return cam

<ipython-input-4-4b25ccb616c7> in __call__(self, x)
     18 
     19     def __call__(self, x):
---> 20         return self.forward(x)
     21 
     22     def forward(self, x):

<ipython-input-4-4b25ccb616c7> in forward(self, x)
     29 
     30         prediction = np.argmax(self.model.predict(x))
---> 31         cam = self.getSmoothGradCAMPP(prediction,x)
     32 
     33         return cam

<ipython-input-4-4b25ccb616c7> in getSmoothGradCAMPP(self, prediction, x)
     47             #x_with_noise = GaussianNoise(np.array(x))
     48             x_with_noise = K.random_normal(shape = (x.shape), mean=x,stddev=std_tensor)
---> 49             smg_cam = cam(GradCAMPlusPlus,self.model,self.target_layer,x_with_noise)
     50 
     51             if i == 0:

<ipython-input-11-de0c0cde57a2> in cam(classname, model, target_layer, image, n_samples, stdev_spread)
      1 def cam(classname,model,target_layer,image,n_samples=25, stdev_spread=0.15):
      2     class_object = classname(model,target_layer=target_layer)
----> 3     cam = class_object(image)
      4 
      5     return cam

<ipython-input-3-9e2b9ebbb414> in __call__(self, x)
     35 
     36     def __call__(self, x):
---> 37         return self.forward(x)
     38 
     39     def getGradCAMPlusPlus(self, prediction,image):

<ipython-input-3-9e2b9ebbb414> in forward(self, x, idx)
     30         """"""
     31         prediction = np.argmax(self.model.predict(x,steps=16))
---> 32         cam = self.getGradCAMPlusPlus(prediction,x)
     33 
     34         return cam

<ipython-input-3-9e2b9ebbb414> in getGradCAMPlusPlus(self, prediction, image)
     48         cam: class activation map.  shape=> (1, 1, H, W)
     49         '''
---> 50         class_score = self.model.output[0, prediction]
     51         conv_layer_output = self.model.get_layer(self.target_layer).output
     52         grads = K.gradients(class_score, conv_layer_output)[0]

C:\Anaconda\envs\python3.6.5\lib\site-packages\tensorflow\python\ops\array_ops.py in _slice_helper(tensor, slice_spec, var)
    652         ellipsis_mask=ellipsis_mask,
    653         var=var,
--> 654         name=name)
    655 
    656 

C:\Anaconda\envs\python3.6.5\lib\site-packages\tensorflow\python\ops\array_ops.py in strided_slice(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)
    818       ellipsis_mask=ellipsis_mask,
    819       new_axis_mask=new_axis_mask,
--> 820       shrink_axis_mask=shrink_axis_mask)
    821 
    822   parent_name = name

C:\Anaconda\envs\python3.6.5\lib\site-packages\tensorflow\python\ops\gen_array_ops.py in strided_slice(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)
  11364                         ellipsis_mask=ellipsis_mask,
  11365                         new_axis_mask=new_axis_mask,
> 11366                         shrink_axis_mask=shrink_axis_mask, name=name)
  11367   _result = _op.outputs[:]
  11368   _inputs_flat = _op.inputs

C:\Anaconda\envs\python3.6.5\lib\site-packages\tensorflow\python\framework\op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    786         op = g.create_op(op_type_name, inputs, output_types, name=scope,
    787                          input_types=input_types, attrs=attr_protos,
--> 788                          op_def=op_def)
    789       return output_structure, op_def.is_stateful, op
    790 

C:\Anaconda\envs\python3.6.5\lib\site-packages\tensorflow\python\util\deprecation.py in new_func(*args, **kwargs)
    505                 'in a future version' if date is None else ('after %s' % date),
    506                 instructions)
--> 507       return func(*args, **kwargs)
    508 
    509     doc = _add_deprecated_arg_notice_to_docstring(

C:\Anaconda\envs\python3.6.5\lib\site-packages\tensorflow\python\framework\ops.py in create_op(***failed resolving arguments***)
   3298           input_types=input_types,
   3299           original_op=self._default_original_op,
-> 3300           op_def=op_def)
   3301       self._create_op_helper(ret, compute_device=compute_device)
   3302     return ret

C:\Anaconda\envs\python3.6.5\lib\site-packages\tensorflow\python\framework\ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)
   1821           op_def, inputs, node_def.attr)
   1822       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,
-> 1823                                 control_input_ops)
   1824 
   1825     # Initialize self._outputs.

C:\Anaconda\envs\python3.6.5\lib\site-packages\tensorflow\python\framework\ops.py in _create_c_op(graph, node_def, inputs, control_inputs)
   1660   except errors.InvalidArgumentError as e:
   1661     # Convert to ValueError for backwards compatibility.
-> 1662     raise ValueError(str(e))
   1663 
   1664   return c_op

ValueError: slice index 7231 of dimension 1 out of bounds. for 'strided_slice_5' (op: 'StridedSlice') with input shapes: [?,1000], [2], [2], [2] and with computed input tensors: input[1] = <0 7231>, input[2] = <1 7232>, input[3] = <1 1>.
"
34500,[TF2.1] Performance: Control flow and scalar ops 225x slower than raw Python and 24000x slower than C++,"**Summary**
TF Op performance for a simple subgraph (built with AutoGraph) is at-least 2 orders of magnitude slower than expected: looping over 100K numbers takes 4+ seconds instead of 18ms (or much faster)

**Benchmark code and repro instructions:**
https://github.com/divyekapoor/ml-op-benchmarks

1. Clone the repo
2. `make tfbench`

```
class FizzBuzz(tf.Module):
    @tf.function(input_signature=[tf.TensorSpec([], tf.int32)])
    def model(self,
              n  # Shape [] -- int32 the max number to loop FizzBuzz to
              ):  # Returns counts for fizz, buzz and fizzbuzz. Shape: [1] with length 3
        fizz = 0
        buzz = 0
        fizzbuzz = 0
        for i in range(n):
            if i % 6 == 0:
                fizzbuzz += 1
            elif i % 3 == 0:
                buzz += 1
            elif i % 2 == 0:
                fizz += 1
        return [fizz, buzz, fizzbuzz]
```
Raw python: Running the same code without tf.Module and @tf.function.
Raw C++: Equivalent implementation in straight C++.

Performance table:

FizzBuzz Iteration Counts | 100000 |   |   |  
-- | -- | -- | -- | --
  | Raw Latency (ms) | Per Run Latency (usec) | Python Multiplier | C++ Multiplier
Tensorflow Python | 4087 | 40.87 | **227.06** | 24327
Tensorflow Saved Model Python | 4046 | 40.46 | **224.78** | 24083
Raw Python | 18 | 0.18 | 1.00 | 107
Raw C++ | 0.168 | 0.00168 | 0.01 | 1

The multiplers use the corresponding Python and C++ code as unit = 1.
Benchmark script is attached at the bottom of this issue and only has a dependency on Tensorflow.

https://github.com/divyekapoor/ml-op-benchmarks has something to directly clone and execute.

(If it would help, TF ops are ~40% slower than Torch ops for the same FizzBuzz benchmark)
https://github.com/pytorch/pytorch/issues/30365 for the related PyTorch issue.

FizzBuzz Iteration Counts | 100000 |   |   |  
-- | -- | -- | -- | --
  | Raw Latency (ms) | Per Run Latency (usec) | Python Multiplier | C++ Multiplier
PyTorch Python | 4007 | 40.07 | 222.61 | 23851
PyTorch TorchScript Python (from Loaded TorchScript) | 2830 | 28.3 | **157.22** | 16845
PyTorch TorchScript C++ (Native) | 255 | 2.55 | **14.17** | 1518
PyTorch TorchScript C++ (Native + ATen Tensors) | 252 | 2.52 | **14.00** | 1500
Raw Python | 18 | 0.18 | 1.00 | 107
Raw C++ | 0.168 | 0.00168 | 0.01 | 1




Performance similar to raw Python is the expected behavior.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.6 (18G1012)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not tested.
- TensorFlow installed from (source or binary): binary.
- TensorFlow version (use command below): 
== tensorflow import ============================================
tf.version.VERSION = 2.1.0-dev20191107
tf.version.GIT_VERSION = v1.12.1-17543-gb4b5ce680c
tf.version.COMPILER_VERSION = 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)
- Python version: 
== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 7, 4, 'final', 0)
- Bazel version (if compiling from source): NA.
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Setup**
Performance benchmark for conditional ops set up with a FizzBuzz test case:
Input: n -> a range limit (100K)
Output: a 3 element tensor with counts for (fizz, buzz, fizzbuzz)
Goal: To estimate the performance overhead of TF ops versus raw python / raw C++.
Benchmark file is attached.

**Describe the current behavior**
FizzBuzz with TF ops is 225x slower than the same code in Raw Python and 24K+x slower than the corresponding C++ implementation. 

**Describe the expected behavior**
FizzBuzz with TF ops should be within 10-50% of raw Python or faster.  

**Code to reproduce the issue**
Attached to this report.
To reproduce:
```
$ python3 -m venv venv3
$ source venv3/bin/activate
$ pip3 install tensorflow
$ python3 fizz.py
```
Full version: https://github.com/divyekapoor/ml-op-benchmarks

**Other info / logs**
Performance table:

FizzBuzz Iteration Counts | 100000 |   |   |  
-- | -- | -- | -- | --
  | Raw Latency (ms) | Per Run Latency (usec) | Python Multiplier | C++ Multiplier
Tensorflow Python | 4087 | 40.87 | 227.06 | 24327
Tensorflow Saved Model Python | 4046 | 40.46 | 224.78 | 24083
Raw Python | 18 | 0.18 | 1.00 | 107
Raw C++ | 0.168 | 0.00168 | 0.01 | 1

Raw latency == run with range input N = 100K
Per Run latency == Raw latency / 100K (one run through the op graph)
[fizz.tar.gz](https://github.com/tensorflow/tensorflow/files/3877175/fizz.tar.gz)
"
34499,E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] layout failed: Invalid argument: size of values 0 does not match size of permutation 4.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below):  2.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
- GPU model and memory: RTX 2080Ti 11GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Originally, I built this model in tensorflow 1.1x and I transferred the model to TF 2.0 manually to use tf.keras. It is working but it shows me this error message  (E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] layout failed: Invalid argument: size of values 0 does not match size of permutation 4.) and its performance is worse than tf 1.1x. 

I suspect that this error interrupts to train somehow. 

I didn't put any permutation layer in my model. It is hard to find it. 

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34496,"""Conv2DBackpropFilter uses a while_loop. Fix that!""","
**Describe the current behavior**
Currently when I compute Jacobian with the option ""experimental_use_pfor=True"" on Conv2D layers, the GPU memory will explode. For other layers like FC (with the same amount of parameters), there is no such issue.

**Describe the expected behavior**
If there is any efficient alternative way of doing this (hopefully YES, as indicated by the warning message in the code ""Conv2DBackpropFilter uses a while_loop. Fix that!""), please kindly update.

**Code to reproduce the issue**
Call tape.jacobian on a Conv2D network of a moderate size with ""experimental_use_pfor=True"".

"
34491,tf.keras computes incorrect loss values with Masking,"**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): pip install tensorflow  /  pip install tf-nightly-2.0-preview
- TensorFlow version (use command below): 2.0  /  2.0.0-dev20191002
- Python version: 3.7.5

**Describe the current behavior**

When fitting an LSTM model with a Masking layer using Keras, if you use binary_crossentropy both as loss and metric, the values are different. In particular, the printed metric is correct, while the loss appears to be calculated without masking.

**Code to reproduce the issue**

```
import numpy as np
from numpy.random import normal, randint
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Masking, LSTM, Activation, Dense

time_steps = 20
num_seqs = 100
X = normal(size=(num_seqs, time_steps))  # create artificial data
Y = np.where(X > 0, 1, 0)  # create simple target

lens = randint(low=1, high=time_steps, size=num_seqs)  # create lengths < time_steps (padding needed)
seqs = [row[:row_len] for row, row_len in zip(X, lens)]  # artificially cut sequences
target_seqs = [row[:row_len] for row, row_len in zip(Y, lens)]  # artificially cut target sequences

padded_seqs = pad_sequences(seqs, padding='post', dtype='float32', maxlen=time_steps).reshape(num_seqs, time_steps, -1)
padded_targets = pad_sequences(target_seqs, dtype='float32', padding='post', maxlen=time_steps).reshape(num_seqs, time_steps, -1)

LSTM_SIZE = 16
model = Sequential()
model.add(Masking(mask_value=0., input_shape=(time_steps,1)))
model.add(LSTM(LSTM_SIZE, return_sequences=True))
model.add(Dense(1))
model.add(Activation(""sigmoid""))
model.compile(loss=""binary_crossentropy"", optimizer=""adam"", metrics=[""binary_crossentropy""])
print(model.summary())

model.fit(padded_seqs, padded_targets, batch_size=1024, epochs=10)
```

and observe that the loss and metric values are different:

```
Train on 100 samples
Epoch 1/10
100/100 [==============================] - 4s 38ms/sample - loss: 0.3365 - binary_crossentropy: 0.6434
Epoch 2/10
100/100 [==============================] - 0s 253us/sample - loss: 0.3361 - binary_crossentropy: 0.6427
Epoch 3/10
100/100 [==============================] - 0s 260us/sample - loss: 0.3357 - binary_crossentropy: 0.6419
Epoch 4/10
100/100 [==============================] - 0s 271us/sample - loss: 0.3353 - binary_crossentropy: 0.6412
Epoch 5/10
100/100 [==============================] - 0s 266us/sample - loss: 0.3349 - binary_crossentropy: 0.6404
Epoch 6/10
100/100 [==============================] - 0s 250us/sample - loss: 0.3345 - binary_crossentropy: 0.6396
Epoch 7/10
100/100 [==============================] - 0s 275us/sample - loss: 0.3341 - binary_crossentropy: 0.6389
Epoch 8/10
100/100 [==============================] - 0s 247us/sample - loss: 0.3337 - binary_crossentropy: 0.6381
Epoch 9/10
100/100 [==============================] - 0s 196us/sample - loss: 0.3333 - binary_crossentropy: 0.6373
Epoch 10/10
100/100 [==============================] - 0s 217us/sample - loss: 0.3329 - binary_crossentropy: 0.6366
```

**Other info / logs**

I already saw this closed issue: https://github.com/tensorflow/tensorflow/issues/25970 and the linked https://stackoverflow.com/questions/54802328/why-am-i-getting-different-values-between-loss-functions-and-metrics-in-tensorfl
That problem appears to be solved in my version, but my problem persists.
 
I also saw this stackoverflow post: https://stackoverflow.com/questions/53808163/same-function-in-keras-loss-and-metric-give-different-values-even-without-regula

The solution doesn't work for me. I tried changing the import statements to

```
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Masking, LSTM, Activation, Dense
```

but the problem remains.
"
34490,Tensorflow 1.6 without SSE4.1,"Hello,
It seems that Tensorflow 1.6 and later versions are configured to require SSE4.1 instructions by default. Some processors (like AMD Phenom II x4 965) do not have these instructions.

**How to configure / rebuild Tensorflow for Python 3 to run on CPUs without SSE4.1?**
"
34489,how to build tensorflow lite static library for android use ndk?,"i check all issue about build static library with ndk for android c++ code, but no one give a complete guide.  and different version from r1.12 r.113 r1.15 has very different tensorflow/lite/tools/make   build_**.sh and target/**.inc, any guide for me to use cmake or bazel to build a libtensorflow-lite.a with armv-8a and armv7a on mac or linux machine."
34488,ListWrapper does not support insert method for nested lists of layers,"**System information**
- Have I written custom code: **yes**
- OS Platform and Distribution: **Linux Ubuntu 18.04**
- Mobile device: **N/A**
- TensorFlow installed from: **binary**
- TensorFlow version: **2.0.0**
- Python version: **3.7.5**
- Bazel version: **N/A**
- GCC/Compiler version: **N/A**
- CUDA/cuDNN version: **10.1 / 7.6.4**
- GPU model and memory: **GeForce GTX 1070, 8 GB**

**Describe the current behavior**
List of layers added to another `list` with the `insert` method are ignored by the model; it works fine with the `append` method.

This seems to be a problem with ListWrapper.

**Describe the expected behavior**
All `list` methods should be supported for defining nested list of layers.

**Code to reproduce the issue**

Minimal example:

```python
class MyModel(tf.keras.Model): 
    def __init__(self, **kwargs): 
        super().__init__(**kwargs) 
        self.conv1 = [] 
        self.conv1.append([tf.keras.layers.Conv2D(8, 3, name=""conv1"")]) 
        self.conv2 = [] 
        self.conv2.insert(0, [tf.keras.layers.Conv2D(16, 3, name=""conv2"")]) 

    def call(self, inputs): 
        x = inputs 
        x = self.conv1[0][0](x) 
        x = self.conv2[0][0](x) 
        return x


m = MyModel()
m.build((None, None, None, 3))
m.summary()

for w in m.trainable_weights: 
    print(w.name)
```
output is:
```
Model: ""my_model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1 (Conv2D)               multiple                  224       
=================================================================
Total params: 224
Trainable params: 224
Non-trainable params: 0
_________________________________________________________________

conv1/kernel:0
conv1/bias:0
```
Note that `conv2` has been ignored.

**Other info / logs**

N/A"
34487,Training deep learning model on a cluster of machines,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
34485,"Tensorflow 2.0 does not use GPU, while Tensorflow 1.15 does","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04

- TensorFlow installed from (source or binary):
binary (pip install tensorflow==2.0 vs pip install tensorflow==1.15

- TensorFlow version (use command below):
2.0 and 1.15

- Python version:
Python 3.6.5

- CUDA/cuDNN version:
== cuda libs  ===================================================
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-10.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-10.0/doc/man/man7/libcudart.7
/usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudart.so.10.0.130

- GPU model and memory:
Nvidia Quadro T2000

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
import tensorflow as tf
tf.test.is_gpu_available()
this gives False for Tensorflow 2.0 and True for Tensorflow 1.15

**Describe the expected behavior**
It should be True for both

**Code to reproduce the issue**
import tensorflow as tf
tf.test.is_gpu_available()

**Other info / logs**

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Thu Nov 21 14:40:53 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Quadro T2000        Off  | 00000000:01:00.0 Off |                  N/A |
| N/A   55C    P8     1W /  N/A |    654MiB /  3914MiB |      5%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      2059      G   /usr/lib/xorg/Xorg                           331MiB |
|    0      2237      G   /usr/bin/gnome-shell                         146MiB |
|    0      2606      G   ...quest-channel-token=3079153680037509795   172MiB |
|    0      4718      G   /snap/pycharm-community/167/jbr/bin/java       2MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-10.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-10.0/doc/man/man7/libcudart.7
/usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudart.so.10.0.130

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.0.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /home/derk/playground/venv/lib/python3.6/site-packages
Required-by: 

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 6, 5, 'final', 0)

== bazel version  ===============================================
"
34483,Limit GPU memory,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
34482,Error with Placeholder_1,"I tried to run el script https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/Sketch_RNN.ipynb but with diferente dataset (pig.npz) and with the checkpoints of that and i have the next problem : 
![download](https://user-images.githubusercontent.com/38189240/69332857-d8f75f80-0c57-11ea-813c-22fe4db6b636.png)
Thnak you :)
"
34481,Summaries producing warnings,"The example code states 

```
writer = tf.summary.create_file_writer(""/tmp/mylogs/tf_function"")

@tf.function
def my_func(step):
  with writer.as_default():
    # other model code would go here
    tf.summary.scalar(""my_metric"", 0.5, step=step)

for step in range(100):
  my_func(step)
  writer.flush()
```

But on multiple systems and operating systems I am seeing warnings using code like this of the form 

> 
WARNING:tensorflow:5 out of the last 5 calls to <function my_func at 0x7fc4f0197ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
"
34479,"Got ""ValueError: Unable to create group (name already exists)"" when saving a convolutional model","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca
- Python version: 3.7.3
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
I'm currently building a YOLOv3 model, the training was good, but when I try to save the model to h5 format, it throws out the ""ValueError: Unable to create group (name already exists)"".

**Describe the expected behavior**
It should finish the save process successfully.

**Code to reproduce the issue**
```
tf.keras.models.save_model(model, ""model.h5"", save_format=""h5"")
```

**Other info / logs**
The log:
```
Traceback (most recent call last):
  File ""image_demo.py"", line 58, in <module>
    tf.keras.models.save_model(model, ""model.h5"", save_format=""h5"")
  File ""/Users/xhguo/Workspace/TensorFlow2.0-Examples/4-Object_Detection/YOLOV3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 112, in save_model
    model, filepath, overwrite, include_optimizer)
  File ""/Users/xhguo/Workspace/TensorFlow2.0-Examples/4-Object_Detection/YOLOV3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 110, in save_model_to_hdf5
    save_weights_to_hdf5_group(model_weights_group, model_layers)
  File ""/Users/xhguo/Workspace/TensorFlow2.0-Examples/4-Object_Detection/YOLOV3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 627, in save_weights_to_hdf5_group
    g = f.create_group(layer.name)
  File ""/Users/xhguo/Workspace/TensorFlow2.0-Examples/4-Object_Detection/YOLOV3/lib/python3.7/site-packages/h5py/_hl/group.py"", line 61, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""h5py/h5g.pyx"", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)
```"
34478,Gradient computation return None,"hello, i write an example to test **tf.while_loop** and **tf.TensorArray**,  it return None when compute gradients, it seem that there is no connection from input to output, i don't know why?

tensorflow version:  1.10.1
code:  https://github.com/dingevin/example/blob/master/example.py

log:
<tf.Variable 'forward/dense/kernel:0' shape=(1024, 512) dtype=float32_ref>
<tf.Variable 'forward/dense/bias:0' shape=(1024,) dtype=float32_ref>
<tf.Variable 'output/dense/kernel:0' shape=(10, 21504) dtype=float32_ref>
<tf.Variable 'output/dense/bias:0' shape=(10,) dtype=float32_ref>
**[(None, <tf.Variable 'forward/dense/kernel:0' shape=(1024, 512) dtype=float32_ref>), (None, <tf.Variable 'forward/dense/bias:0' shape=(1024,) dtype=float32_ref>), (<tf.Tensor 'gradients/output/dense/dense/MatMul_grad/tuple/control_dependency_1:0' shape=(10, 21504) dtype=float32>, <tf.Variable 'output/dense/kernel:0' shape=(10, 21504) dtype=float32_ref>), (<tf.Tensor 'gradients/output/dense/dense/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>, <tf.Variable 'output/dense/bias:0' shape=(10,) dtype=float32_ref>)]**
Traceback (most recent call last):
  File ""1.py"", line 203, in <module>
    tf.app.run(main)
  File ""/home/dingzhenyou/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""1.py"", line 188, in main
    model.build_train_model()
  File ""1.py"", line 81, in build_train_model
    grads_and_vars = self.average_gradients(gv_list)
  File ""1.py"", line 100, in average_gradients
    expanded_g = tf.expand_dims(g, 0)
  File ""/home/dingzhenyou/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 454, in new_func
    return func(*args, **kwargs)
  File ""/home/dingzhenyou/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 136, in expand_dims
    return gen_array_ops.expand_dims(input, axis, name)
  File ""/home/dingzhenyou/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2020, in expand_dims
    ""ExpandDims"", input=input, dim=axis, name=name)
  File ""/home/dingzhenyou/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 528, in _apply_op_helper
    (input_name, err))
**ValueError: Tried to convert 'input' to a tensor and failed. Error: None values not supported.**

"
34475,WHere is staging package in tf2?,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Hi there, i want to use the StagingArea structure by using 'from tensorflow.contrib.staging import StagingArea' in old version. How could i use it in tf2, and i see the definition is here :tensorflow/python/ops/data_flow_ops.py
**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34474,Get a confused error when using tf.keras.layers.Conv2D to create Gan model,"Hello, I tried to convert my tensorflow 1.x code to tensorflow 2.0, but met with some problems here:

the original 1.x code is:
def generator(inputs_real, is_train=True, alpha=0.01, name=""generator""):
    # 256*256*3
    with tf.variable_scope(name, reuse=(not is_train)):
        # 128*128*64
        conv1 = tf.layers.conv2d(inputs_real, 64, (3,3), padding='same')
        conv1 = tf.nn.relu(conv1)
        conv1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')
        # 64*64*128
        conv2 = tf.layers.conv2d(conv1, 128, (3,3), padding='same')
        conv2 = tf.layers.conv2d(conv1, 128, (3,3), padding='same')
        conv2 = tf.nn.relu(conv2)
        conv2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')
        # 32*32*256
        conv3 = tf.layers.conv2d(conv2, 256, (3,3), padding='same')
        conv3 = tf.layers.conv2d(conv2, 256, (3,3), padding='same')
        conv3 = tf.nn.relu(conv3)
        conv3 = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')
        # 16*16*512
        conv4 = tf.layers.conv2d(conv3, 512, (3,3), padding='same')
        conv4 = tf.layers.conv2d(conv3, 512, (3,3), padding='same')
        conv4 = tf.nn.relu(conv4)
        conv4 = tf.layers.max_pooling2d(conv4, (2,2), (2,2), padding='same')
        # 8*8*512
        conv5 = tf.layers.conv2d(conv4, 512, (3,3), padding='same')
        conv5 = tf.layers.conv2d(conv4, 512, (3,3), padding='same')
        conv5 = tf.nn.relu(conv5)
        conv5 = tf.layers.max_pooling2d(conv5, (2,2), (2,2), padding='same')
        # 4*4*512
        conv6 = tf.layers.conv2d(conv5, 512, (3,3), padding='same')
        conv6 = tf.layers.conv2d(conv5, 512, (3,3), padding='same')
        conv6 = tf.nn.relu(conv6)
        conv6 = tf.layers.max_pooling2d(conv6, (2,2), (2,2), padding='same')

everything worked fine, but when I try to convert to:

class Generator(tf.keras.Model):
  def __init__(self, is_train):
    super(Generator, self).__init__()
    self.is_train = is_train
    self.conv64 = tf.keras.layers.Conv2D(64, (3, 3), input_shape=(256, 256, 3), data_format='channels_last', padding='same')
    self.conv128 = tf.keras.layers.Conv2D(128, (3, 3), data_format='channels_last', padding='same')
    self.conv256 = tf.keras.layers.Conv2D(256, (3, 3), data_format='channels_last', padding='same')
    self.conv512 = tf.keras.layers.Conv2D(512, (3, 3), data_format='channels_last', padding='same')
    self.conv_transpose1 = tf.keras.layers.Conv2DTranspose(1, (3, 3), strides=(2, 2), data_format='channels_last', padding='same')
    self.conv_transpose64 = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), data_format='channels_last', padding='same')
    self.conv_transpose128 = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), data_format='channels_last', padding='same')
    self.conv_transpose256 = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), data_format='channels_last', padding='same')
    self.conv_transpose512 = tf.keras.layers.Conv2DTranspose(512, (3, 3), strides=(2, 2), data_format='channels_last', padding='same')
    self.MaxPool2D = tf.keras.layers.MaxPool2D((2,2), (2,2), padding='same')
    self.BatchNormalization = tf.keras.layers.BatchNormalization(trainable=is_train)

  def call(self, inputs_real):
    conv1 = self.conv64(inputs_real)
    conv1 = layers.ReLU()(conv1)
    conv1 = self.MaxPool2D(conv1)

    # 64*64*128
    conv2 = self.conv128(conv1)
    conv2 = layers.ReLU()(conv2)
    conv2 = self.MaxPool2D(conv2)

    # 32*32*256
    conv3 = self.conv256(conv2)
    conv3 = layers.ReLU()(conv3)
    conv3 = self.MaxPool2D(conv3)
    print(conv3.shape)

    # 16*16*512
    conv4 = self.conv512(conv3)
    conv4 = layers.ReLU()(conv4)
    conv4 = self.MaxPool2D(conv4)
    print(conv4.shape)

    # 8*8*512
    conv5 = self.conv512(conv4)
    conv5 = layers.ReLU()(conv5)
    conv5 = self.MaxPool2D(conv5)
        
    # 4*4*512
    conv6 = self.conv512(conv5)
    conv6 = layers.ReLU()(conv6)
    conv6 = self.MaxPool2D(conv6)

The error is:
Traceback (most recent call last):
  File ""gan_2.0.py"", line 269, in <module>
    train()
  File ""gan_2.0.py"", line 266, in train
    loss_dict = train_step(image_batch, cartoon_batch)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\func_graph.py"", line 905, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    gan_2.0.py:228 train_step  *
        fake_cartoons = generatorc(image_batch)
    C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py:847 __call__
        outputs = call_fn(cast_inputs, *args, **kwargs)
    gan_2.0.py:59 call  *
        conv6 = self.conv512(conv5)
    C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py:812 __call__
        self.name)
    C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\input_spec.py:213 assert_input_compatibility
        ' but received input with shape ' + str(shape))

    ValueError: Input 0 of layer conv2d_3 is incompatible with the layer: expected axis -1 of input shape to have value 256 but received input with shape [1, 8, 8, 512]

It seems that conv5 = self.conv512(conv4) only takes the input of shape[, , , 256], but after conv4 = self.conv512(conv3), the last shape is 512 after the con2d's kernel size is 512.  Which means the kernel size should be different between stacked layers?
I'm really confused here..."
34473,fit_generator with use_multiprocessing=True causes runtime error when initializing worker pool,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): This -> https://cloud.google.com/ml-engine/docs/runtime-version-list#1.14
- TensorFlow installed from (source or binary): Binary.
- TensorFlow version (use command below): 1.14
- Python version: 3.5

**Describe the current behavior**

Train a model with:

```
import multiprocessing as mp

if __name__ == '__main__':
    mp.set_start_method('spawn') # or 'forkserver'

    ...
    ...
    model.fit_generator(
        generator=train_seq,
        validation_data=val_seq,
        callbacks=callbacks,
        shuffle=True,
        initial_epoch=0,
        epochs=1000,
        max_queue_size=16,
        workers=4,
        use_multiprocessing=True,
        verbose=1,
    )
```

The following runtime error is usually raised in the middle of training (a few epochs has elapsed), near the end of an epoch, and training hanged:

```
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		Exception in thread Thread-33:
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		Traceback (most recent call last):
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    self.run()
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/threading.py"", line 862, in run
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    self._target(*self._args, **self._kwargs)
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py"", line 748, in _run
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py"", line 727, in pool_fn
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    initargs=(seqs, None, get_worker_id_queue()))
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/multiprocessing/context.py"", line 118, in Pool
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    context=self.get_context())
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/multiprocessing/pool.py"", line 168, in __init__
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    self._repopulate_pool()
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/multiprocessing/pool.py"", line 233, in _repopulate_pool
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    w.start()
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/multiprocessing/process.py"", line 105, in start
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    self._popen = self._Popen(self)
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/multiprocessing/context.py"", line 274, in _Popen
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    return Popen(process_obj)
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/multiprocessing/popen_spawn_posix.py"", line 33, in __init__
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    super().__init__(process_obj)
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/multiprocessing/popen_fork.py"", line 20, in __init__
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    self._launch(process_obj)
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/multiprocessing/popen_spawn_posix.py"", line 48, in _launch
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    reduction.dump(process_obj, fp)
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		  File ""/usr/lib/python3.5/multiprocessing/reduction.py"", line 59, in dump
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		    ForkingPickler(file, protocol).dump(obj)
ERROR	2019-11-21 10:20:18 +0800	master-replica-0		RuntimeError: dictionary changed size during iteration
```

Similarly when using ```forkserver``` as the start method:

```
2019-11-20T16:54:34.389836549Z master-replica-0 Exception in thread Thread-33: E  master-replica-0
2019-11-20T16:54:34.390263319Z master-replica-0 Traceback (most recent call last): E  master-replica-0
2019-11-20T16:54:34.391031265Z master-replica-0   File ""/usr/lib/python3.5/threading.py"", line 914, in _bootstrap_inner E  master-replica-0
2019-11-20T16:54:34.391372919Z master-replica-0     self.run() E  master-replica-0
2019-11-20T16:54:34.391650676Z master-replica-0   File ""/usr/lib/python3.5/threading.py"", line 862, in run E  master-replica-0
2019-11-20T16:54:34.391963958Z master-replica-0     self._target(*self._args, **self._kwargs) E  master-replica-0
2019-11-20T16:54:34.392265796Z master-replica-0   File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py"", line 748, in _run E  master-replica-0
2019-11-20T16:54:34.392584800Z master-replica-0     with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor: E  master-replica-0
2019-11-20T16:54:34.392927646Z master-replica-0   File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py"", line 727, in pool_fn E  master-replica-0
2019-11-20T16:54:34.393241405Z master-replica-0     initargs=(seqs, None, get_worker_id_queue())) E  master-replica-0
2019-11-20T16:54:34.393555641Z master-replica-0   File ""/usr/lib/python3.5/multiprocessing/context.py"", line 118, in Pool E  master-replica-0
2019-11-20T16:54:34.394298315Z master-replica-0     context=self.get_context()) E  master-replica-0
2019-11-20T16:54:34.394565820Z master-replica-0   File ""/usr/lib/python3.5/multiprocessing/pool.py"", line 168, in __init__ E  master-replica-0
2019-11-20T16:54:34.394963264Z master-replica-0     self._repopulate_pool() E  master-replica-0
2019-11-20T16:54:34.395295143Z master-replica-0   File ""/usr/lib/python3.5/multiprocessing/pool.py"", line 233, in _repopulate_pool E  master-replica-0
2019-11-20T16:54:34.395615577Z master-replica-0     w.start() E  master-replica-0
2019-11-20T16:54:34.395916461Z master-replica-0   File ""/usr/lib/python3.5/multiprocessing/process.py"", line 105, in start E  master-replica-0
2019-11-20T16:54:34.396240472Z master-replica-0     self._popen = self._Popen(self) E  master-replica-0
2019-11-20T16:54:34.396524190Z master-replica-0   File ""/usr/lib/python3.5/multiprocessing/context.py"", line 281, in _Popen E  master-replica-0
2019-11-20T16:54:34.396835565Z master-replica-0     return Popen(process_obj) E  master-replica-0
2019-11-20T16:54:34.397135734Z master-replica-0   File ""/usr/lib/python3.5/multiprocessing/popen_forkserver.py"", line 36, in __init__ E  master-replica-0
2019-11-20T16:54:34.397473096Z master-replica-0     super().__init__(process_obj) E  master-replica-0
2019-11-20T16:54:34.397750616Z master-replica-0   File ""/usr/lib/python3.5/multiprocessing/popen_fork.py"", line 20, in __init__ E  master-replica-0
2019-11-20T16:54:34.398015022Z master-replica-0     self._launch(process_obj) E  master-replica-0
2019-11-20T16:54:34.398270130Z master-replica-0   File ""/usr/lib/python3.5/multiprocessing/popen_forkserver.py"", line 48, in _launch E  master-replica-0
2019-11-20T16:54:34.398548603Z master-replica-0     reduction.dump(process_obj, buf) E  master-replica-0
2019-11-20T16:54:34.398846387Z master-replica-0   File ""/usr/lib/python3.5/multiprocessing/reduction.py"", line 59, in dump E  master-replica-0
2019-11-20T16:54:34.399111270Z master-replica-0     ForkingPickler(file, protocol).dump(obj) E  master-replica-0
2019-11-20T16:54:34.399379014Z master-replica-0 RuntimeError: dictionary changed size during iteration E  master-replica-0
```"
34470,tf.meshgrid bug: Duplicate node name in graph,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda 10.0, cudnn 7
- GPU model and memory: GTX 1080Ti

**Describe the current behavior**.
What I am trying to do is to warp a feature map (shape (N, H, W, C)) using an offset (shape (N, H, W, 2)). However, it doesn't compile. It seems there's some problem on name scopes inside tf.meshgrid.
```
Traceback (most recent call last):
  File ""/home/kingo/Documents/projects/SunRelight/code/sun_relight/network_training/test.py"", line 25, in <module>
    out = warp(x, offset)
  File ""/home/kingo/Documents/projects/SunRelight/code/sun_relight/network_training/test.py"", line 14, in warp
    base_coord2 = tf.stack(tf.meshgrid(tf.range(W), tf.range(H))[::-1], axis=-1)
  File ""/home/kingo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 2954, in meshgrid
    mult_fact = ones(shapes, output_dtype)
  File ""/home/kingo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 2583, in ones
    output = fill(shape, constant(one, dtype=dtype), name=name)
  File ""/home/kingo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 171, in fill
    result = gen_array_ops.fill(dims, value, name=name)
  File ""/home/kingo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 3602, in fill
    ""Fill"", dims=dims, value=value, name=name)
  File ""/home/kingo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""/home/kingo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 548, in create_op
    compute_device)
  File ""/home/kingo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal
    op_def=op_def)
  File ""/home/kingo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1773, in __init__
    control_input_ops)
  File ""/home/kingo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1613, in _create_c_op
    raise ValueError(str(e))
ValueError: Duplicate node name in graph: 'ones'
```


**Describe the expected behavior**
No error should happen.


**Code to reproduce the issue**
```
import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.python.keras import backend as K

def warp(inputs, offset):
  tensor_input_shape = K.shape(inputs)
  batch_size = tensor_input_shape[0]
  H = tensor_input_shape[1]
  W = tensor_input_shape[2]

  base_coord = tf.stack(tf.meshgrid(tf.range(W), tf.range(H))[::-1], axis=-1)
  base_coord2 = tf.stack(tf.meshgrid(tf.range(W), tf.range(H))[::-1], axis=-1) # Only to show the bug
  # base_coord = tf.tile(base_coord[tf.newaxis, :, :, :], [batch_size, 1, 1, 1])
  # target_coord = tf.cast(tf.cast(base_coord, tf.float32) + offset, tf.int32)
  # target_coord = tf.clip_by_value(
  #     target_coord, 0,
  #     tf.stack([H-1, W-1])[tf.newaxis, tf.newaxis, tf.newaxis, :])

  return tf.gather_nd(inputs, base_coord2, batch_dims=1)

x = keras.Input(shape=(None, None, 3))
offset = keras.Input(shape=(None, None, 2))
out = warp(x, offset)
net = keras.Model(inputs=[x, offset], outputs=out)
```

"
34469,ValueError with tf.data.Dataset and model.fit and tf.distribute,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Docker image
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not mobile
- TensorFlow installed from (source or binary): Docker image: tensorflow/tensorflow:nightly-gpu-py3
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/7.6
- GPU model and memory: NVIDIA V100

**Describe the current behaviour**
I receive the following stack trace
```
Traceback (most recent call last):
  File ""main.py"", line 571, in <module>
    verbose=2,
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 792, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 264, in fit
    training_dataset)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 677, in experimental_distribute_dataset
    return self._extended._experimental_distribute_dataset(dataset)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py"", line 574, in _experimental_distribute_dataset
    split_batch_by=self._num_replicas_in_sync)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py"", line 89, in get_distributed_dataset
    input_context=input_context)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py"", line 509, in __init__
    dataset = distribute._RebatchDataset(dataset, split_batch_by)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/experimental/ops/distribute.py"", line 110, in __init__
    rebatch, dataset_ops.get_structure(input_dataset))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/nest.py"", line 245, in map_structure
    structure[0], [func(*x) for x in entries])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/nest.py"", line 245, in <listcomp>
    structure[0], [func(*x) for x in entries])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/experimental/ops/distribute.py"", line 105, in rebatch
    batch_size = recalculate_batch_size(type_spec._to_legacy_output_shapes())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/experimental/ops/distribute.py"", line 90, in recalculate_batch_size
    if len(output_shapes) < 1:
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py"", line 823, in __len__
    raise ValueError(""Cannot take the length of shape with unknown rank."")
ValueError: Cannot take the length of shape with unknown rank.
```

**Describe the expected behavior**
I expect training to proceed without issue.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

This is an excerpt of my code, hopefully it is sufficient to demonstrate what I am doing.
```
def parse_entry(entry):
    # Create a dictionary describing the features
    feature_description = {
        ""num"": tf.io.FixedLenFeature(shape=[], dtype=tf.string),
        ""width"": tf.io.FixedLenFeature(shape=[], dtype=tf.int64),
        ""height"": tf.io.FixedLenFeature(shape=[], dtype=tf.int64),
        ""image_l"": tf.io.FixedLenFeature(shape=[], dtype=tf.string),
        ""image_r"": tf.io.FixedLenFeature(shape=[], dtype=tf.string),
        ""disparity_l"": tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32, allow_missing=True),
        ""disparity_r"": tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32, allow_missing=True),
    }
    example = tf.io.parse_single_example(entry, feature_description)

    # Need to decode the image data
    example[""image_l""] = tf.io.decode_image(example[""image_l""], channels=0, dtype=tf.uint8)
    example[""image_r""] = tf.io.decode_image(example[""image_r""], channels=0, dtype=tf.uint8)

    # Disparities were flattened, need to recover their actual shape
    # Assuming that channels will be the last axis
    example[""disparity_l""] = tf.reshape(example[""disparity_l""], (example[""width""], example[""height""], 1))
    example[""disparity_r""] = tf.reshape(example[""disparity_r""], (example[""width""], example[""height""], 1))

    return (
        (example[""num""], example[""width""], example[""height""], example[""image_l""], example[""image_r""],),
        (example[""num""], example[""width""], example[""height""], example[""disparity_l""], example[""disparity_r""],),
    )

def create_dataset(path, args):
    # Create a stats aggregator for the dataset
    aggregator = tf.data.experimental.StatsAggregator()

    # Load in the dataset
    dataset = tf.data.TFRecordDataset(path)

    # Shuffle the elements
    if args.shuffle_size > 1:
        dataset = dataset.shuffle(args.shuffle_size, reshuffle_each_iteration=False)

    # Convert dataset to training format
    dataset = dataset.map(parse_entry)

    # Set up batch size
    dataset = dataset.batch(batch_size=args.batch_size, drop_remainder=False)

    # Set output shapes, types, and classes
    dataset.output_classes = (
        (tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor),
        (tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor),
    )
    dataset.output_types = (
        (tf.dtypes.string, tf.dtypes.int64, tf.dtypes.int64, tf.dtypes.uint8, tf.dtypes.uint8,),
        (tf.dtypes.string, tf.dtypes.int64, tf.dtypes.int64, tf.dtypes.float32, tf.dtypes.float32,),
    )
    dataset.output_shapes = (
        ([], [], [], tf.TensorShape([None, None, 3]), tf.TensorShape([None, None, 3]),),
        ([], [], [], tf.TensorShape([None, None, 1]), tf.TensorShape([None, None, 1]),),
    )

    # Extract the first element so we can retrieve image shapes
    for entry in tf.data.TFRecordDataset(path).take(1):
        element = parse_entry(entry)
        # shape = (element[0][""width""], element[0][""height""])
        shape = (element[0][2], element[0][1])

    return dataset, shape

train_dataset, input_resolution = create_dataset(args.train_dataset, args)
valid_dataset, _ = create_dataset(args.valid_dataset, args)

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    # Create the model
    model = CustomKerasModel()

    # Compile the model, set optimiser, loss function, and metrics to use
    model.compile(optimizer=optimiser, loss=loss, metrics=metrics)

    # Train
    model.fit(
        x=train_dataset,
        validation_data=valid_dataset,
        validation_steps=None,
        validation_freq=1,
        callbacks=callbacks,
        epochs=args.num_epochs,
        verbose=2,
    )

    model.save(
        output_path,
        overwrite=True,
        include_optimizer=True,
        save_format=""h5"",
    )
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I think this problem is similar to #24520 but with `tf.distribute.MirroredStrategy` mixed in. I am using a TFRecordDataset and I am setting `output_classes`, `output_shapes`, and `output_types`, so I am not sure which tensor it is unable to get the shape of. Is there anything I can do to narrow down what is causing this bug? Keep in mind, I am running in a docker container, so code changes are a little difficult to achieve.

This may only happen when using `tf.distribute.MirriredStrategy` with a single GPU.
"
34466,TF 1.15 to TF 2.0 breaking changes even with tf.compat.v1 for saving models for use with tf serving,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): debian dockerized
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): docker
- TensorFlow version (use command below): 1.15 and 2.0.0
- Python version: 3.7
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Currently trying to export a `tf.keras` model in v `2.0.0` using `tf.compat.v1` functions (which will be removed in the future) does not work. Using the same code in `1.15.0` works.  Currently there is not a `tf.compat.v2` function which is concerning for those using this functionality for compatibility with tf serving.


**Describe the expected behavior**
That code with `tf.compat.v1` works in `2.0` as it does in `1.15`

**Code to reproduce the issue**
This repo: https://gitlab.com/SumNeuron/docker-nf
Is my dockerized TF MWE. It contains the code necessary to reproduce the issue as well as subsequent steps (e.g. spin up a dockerized web app with the served model).

In order to reproduce the bug there are two files of relevance:

1. `Dockerfile.ai`
2. `notebooks/Make Toy Model.ipynb`

The first two lines of `Dockerfile.ai`:
```
FROM tensorflow/tensorflow:1.15.0rc2-gpu-py3-jupyter
# FROM tensorflow/tensorflow:2.0.0-gpu-py3-jupyter
```
are for convenience of toggling between TF versions.

To spin up the service:

```
docker-compose -f docker-compose.ai.development.yml build
docker-compose -f docker-compose.ai.development.yml up
```

Then navigate to the mounted notebook.
After running the toy model there is a code cell with markdown content:

>Simple Save for Serving

under which has the following code (which is more or less copy-paste from a tf official documentation example).

```
MODEL_DIR = '../models/serving/toy'
version = 1
export_path = os.path.join(MODEL_DIR, str(version))
if not os.path.isdir(export_path):
    os.makedirs(export_path)
    
tf.compat.v1.saved_model.simple_save(
    tf.compat.v1.keras.backend.get_session(),
    export_path,
    inputs={'input_tensor': model.input},
    outputs={'output_tensor': model.outputs[0]})
```
This will work when using tf version `1.15`. It will fail with tf version `2.0`


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34463,Unify the APIs on a tf.keras.Model when trained vs when it is saved and loaded.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0.0
- Are you willing to contribute it (Yes/No): No


**Describe the feature and the current behavior/state.**
Explaining the issue using inference as an example API:
Running inference on a loaded model is different than running inference on model you just trained and this causes confusion. For a trained model we use: `model.predict(input)` but for a loaded saved model we need to directly invoke the model by running `model(input)` as explained below:

a) Train a Model
```
model = tf.keras.Model(...)
model.compile(...)
model.fit(...)
```

**Method 1:**
b) Run Predictions
`model.predict(input)`

**Method 2:**
b) Save a Model
`tf.saved_model.save(model, '/tmp/model')`
c) Load a Model
`tf.saved_model.load(model, '/tmp/model')`
d) Run predictions on loaded model
`model(input)`

Note: There are many other model APIs that also differ this way. It would be better to have a consistent format.

**Will this change the current api? How?**
Yes, it would change the current API. You'd have to add additional functions to the current loaded model format or ensure it is loaded in the same way as a model trained in a jupyter notebook.

**Who will benefit with this feature?**
Everyone using tensorflow 2.0

**Any Other info.**
-
"
34462,Please don't implement a feature suggested in a categorical cross-entropy TODO,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): v2.0.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
This is actually an anti-request. I'm requesting that the developers not implement suggested future behavior.

There is a TODO comment in [tensorflow/python/ops/nn_ops.py line 3289](https://github.com/tensorflow/tensorflow/blob/b646d41f69f8a1cf2f5c76d934adbf8c067e4444/tensorflow/python/ops/nn_ops.py#L3289) that states an intention to change the categorical cross-entropy loss algorithm so that it will raise an error if the sum of any label vector is not equal to 1. The comment states:
```
  # TODO(pcmurray) Raise an error when the labels do not sum to 1. Note: This
  # could break users who call this with bad labels, but disregard the bad
  # results.
```

I make use of label vectors with all elements set to zero in order to perform spatial masking of data in my 2D convolutional neural network. I have regions in some of my images where there is no label available, and the regions change from image to image. These regions make no contribution to the loss if the corresponding label vectors are set to all zero, effectively removing them from gradient calculation and back-propagation. (The regions in the images have valid input data, but a label cannot be assigned.) My suggestion is that this TODO not be implemented or that the implementation would allow for all-zero label vectors.

**Will this change the current api? How?**
This will not change the current API.

**Who will benefit with this feature?**
People (like me) who use the current way the algorithm is implemented to do per-image spatial masking."
34461,Can't load libcublas 10.0 on nightly build 2.1.0,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: tf-nightly-gpu==2.1.0.dev20191120
- Python version: 3.6.8 or 3.7.3
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0 - 7.6
- GPU model and memory: RTX 2080 8Go



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I'm trying to run the 2.1.0 nightly build on an RTX 2080. It fails to load all libcublas, libcudart, etc..
In a tensorflow-gpu==2.0.0 environment, those files load perfectly.

Running a simple script triggers the error:
```
import tensorflow as tf

print(tf.random.uniform((2, 2)))
```

On the 2.0.0 environment:
![image](https://user-images.githubusercontent.com/12402673/69258553-13f88500-0bbd-11ea-8145-323c27c22e3f.png)

On the nightly 2.1.0 environment:
![image](https://user-images.githubusercontent.com/12402673/69258616-2d013600-0bbd-11ea-94af-ef9e665ea14d.png)


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

2.1.0 trace
```
2019-11-20 17:45:31.698108: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2019-11-20 17:45:31.698128: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2019-11-20 17:45:32.396003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-20 17:45:32.422048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:45:32.422487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.785GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s
2019-11-20 17:45:32.422551: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2019-11-20 17:45:32.422591: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory
2019-11-20 17:45:32.422629: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2019-11-20 17:45:32.422664: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory
2019-11-20 17:45:32.422700: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory
2019-11-20 17:45:32.422734: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory
2019-11-20 17:45:32.425284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-20 17:45:32.425298: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2019-11-20 17:45:32.425514: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-20 17:45:32.430540: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz
2019-11-20 17:45:32.430970: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4fefaa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-20 17:45:32.430984: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-20 17:45:32.528493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:45:32.529025: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ff19e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2019-11-20 17:45:32.529091: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5
2019-11-20 17:45:32.529149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-20 17:45:32.529156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      
tf.Tensor(
[[0.8163065  0.6548419 ]
 [0.81401074 0.1661377 ]], shape=(2, 2), dtype=float32)

```

2.0.0 trace
```
2019-11-20 17:44:00.771398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-20 17:44:00.795944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:44:00.796375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.785
pciBusID: 0000:01:00.0
2019-11-20 17:44:00.796524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-20 17:44:00.797505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-20 17:44:00.798254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-20 17:44:00.798438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-20 17:44:00.799488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-20 17:44:00.800282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-20 17:44:00.802750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-20 17:44:00.802822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:44:00.803281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:44:00.803677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-20 17:44:00.803901: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-20 17:44:00.808387: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz
2019-11-20 17:44:00.808663: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4eb4be0 executing computations on platform Host. Devices:
2019-11-20 17:44:00.808725: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-20 17:44:00.905964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:44:00.906455: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4eb6a40 executing computations on platform CUDA. Devices:
2019-11-20 17:44:00.906471: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5
2019-11-20 17:44:00.906570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:44:00.906972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.785
pciBusID: 0000:01:00.0
2019-11-20 17:44:00.906997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-20 17:44:00.907006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-20 17:44:00.907014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-20 17:44:00.907022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-20 17:44:00.907030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-20 17:44:00.907038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-20 17:44:00.907046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-20 17:44:00.907078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:44:00.907480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:44:00.907858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-20 17:44:00.907882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-20 17:44:00.908473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-20 17:44:00.908484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-20 17:44:00.908489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-20 17:44:00.908554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:44:00.909022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-20 17:44:00.909423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7466 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5)
tf.Tensor(
[[0.36159635 0.30549836]
 [0.09631395 0.7153827 ]], shape=(2, 2), dtype=float32)
```
"
34460,404 link in documentation,"## URL(s) with the issue:

https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md

## Description of issue (what needs changing):

Non functioning link in the documentation:

```
### Custom Training Data
By default the script will download the [Speech Commands
dataset](https://download.tensorflow.org/data/speech_commands_v0.01.tgz)
```

https://download.tensorflow.org/data/speech_commands_v0.01.tgz leads to a non working page. "
34459,Modifications to BUILD to Use Target libtensorflowlite and make tar.gz,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: tag v2.0.0
- Python version: Python 3.6.8
- Installed using virtualenv? pip? conda?: from GitHub repository
- Bazel version (if compiling from source): Build label: 0.26.0
- GCC/Compiler version (if compiling from source): gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1)
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**

I modified `tensorflow/tensorflow/tools/lib_package/BUILD` (enclosed). I am trying to build Tensorflow Lite in the same way the Tensorflow C library is built.

```bash
bazel build --jobs=1 --local_ram_resources=1024 --config=opt --config=v2 --config=noaws //tensorflow/tools/lib_package:libtensorflow
```

Final output:

```
Target //tensorflow/tools/lib_package:libtensorflow up-to-date:
  bazel-bin/tensorflow/tools/lib_package/libtensorflow.tar.gz
```
I'd like to do the same for Tensorflow Lite.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. Compiled Tensorflow C package using `bazel build --jobs=1 --local_ram_resources=1024 --config=opt --config=v2 --config=noaws //tensorflow/tools/lib_package:libtensorflow`
2. Modified `tensorflow/tensorflow/tools/lib_package/BUILD`.
3. Compiled Tensorflow Lite using `bazel build --jobs=1 --local_ram_resources=1024 --config=opt --config=v2 --config=noaws //tensorflow/lite:libtensorflowlite.so`.
4. The archive `libtensorflowlite.tar.gz` is not produced.
5. Tried `bazel build --jobs=1 --local_ram_resources=1024 --config=opt --config=v2 --config=noaws //tensorflow/lite:libtensorflowlite.so` but got the error

```
ERROR: Skipping '//tensorflow/lite:libtensorflowlite': no such target '//tensorflow/lite:libtensorflowlite': target 'libtensorflowlite' not declared in package 'tensorflow/lite' (did you mean 'libtensorflowlite.so'?) defined by /mnt/drive/stuff/src/tensorflow/tensorflow/lite/BUILD
WARNING: Target pattern parsing failed.
ERROR: no such target '//tensorflow/lite:libtensorflowlite': target 'libtensorflowlite' not declared in package 'tensorflow/lite' (did you mean 'libtensorflowlite.so'?) defined by /mnt/drive/stuff/src/tensorflow/tensorflow/lite/BUILD
INFO: Elapsed time: 0.279s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 pac\
kages loaded)
```

I am happy to turn this into a PR.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
N/A

[BUILD.zip](https://github.com/tensorflow/tensorflow/files/3870140/BUILD.zip)

"
34458,Using skip and ignore_errors cause training hang,"Using skip on a dataset that contains corrupted data and then applying ignore_errors() causes fit method to hang before the validation step. The fit method uses dataset for training and validation.

This behavior was reported using
Ubuntu 18.04, Tensorflow 2.0.0 installed using pip, python 3.7.3


```
import tensorflow as tf
dataset = tf.data.Dataset.from_tensor_slices([1., 0., 2., 1.,])
dataset = dataset.map(lambda x: tf.debugging.check_numerics(1. / x, ""error""))

train = tf.data.Dataset.zip((dataset, dataset)).batch(1).repeat().apply(tf.data.experimental.ignore_errors())
val = tf.data.Dataset.zip((dataset, dataset)).skip(2).batch(1).repeat().apply(tf.data.experimental.ignore_errors())

model = tf.keras.Sequential([
    tf.keras.layers.Dense(32, activation='relu', input_shape=(1,)),
])
model.compile(optimizer='adam', loss='mse')
model.fit(train, epochs=10, steps_per_epoch=4, validation_data=val, validation_steps=2 )
```

"
34457,Model.fit displays wrong total count in progress bar when using validation data with undefined length,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.6 LTS
- TensorFlow installed from (source or binary): binary (pip install tensorflow)
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6.8
- CUDA/cuDNN version: /
- GPU model and memory: /

**Describe the current behavior**

When using `model.fit` method with specified `validation_data`, the progress bar reports the validation (instead of training) dataset size as the total count in the progress bar. After the end of the epoch the values are correctly displayed.

The bug occurs when using tf.data datasets with unknown number of elements (for example when using generators).

Example output:

Epoch 1/10
1024/1024 [==============================] - 7s 7ms/step - loss: 23984083.2295 - accuracy: 0.1007 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00
Epoch 2/10
1024/1024 [==============================] - 5s 5ms/step - loss: 25074923.1717 - accuracy: 0.0985 - val_loss: 30138559.6406 - val_accuracy: 0.1052
Epoch 3/10
 78/128 [=================>............] - ETA: 0s - loss: 28146315.7692 - accuracy: 0.1126

**Describe the expected behavior**

The progress bar should report the total number of elements infered from the training dataset, not from the validation dataset. The last line in the example output should be 78/1024, not 78/128.

**Code to reproduce the issue**

```python
import tensorflow as tf
from tensorflow.keras import layers
import numpy as np

# Model from tf Keras overview
model = tf.keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(32,)),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(0.01),
              loss='categorical_crossentropy',
              metrics=['accuracy'])


# Data generator
def get_dataset(batch_size, num_batches):
    """""" Get random tf.data dataset with given batch size and number of batches. """"""

    def _generator():
        for i in range(num_batches):
            data = np.random.random((batch_size, 32))
            labels = np.random.random((batch_size, 10))

            yield data, labels
            
    dataset = tf.data.Dataset.from_generator(
        _generator,
        (tf.float32, tf.float32),
        ((batch_size, 32), (batch_size, 10))
    )
    
    return dataset

# Create datasets
dataset = get_dataset(batch_size=32, num_batches=1024)
val_dataset = get_dataset(batch_size=32, num_batches=128)

# Train
model.fit(dataset, epochs=10,
          validation_data=val_dataset)
```

**Other info / logs**

The problem still occurs if `steps_per_epoch` is specified in the fit method. If `validation_steps` is provided, then the behaviour is correct. 

Seems like the computation of number of elements in the validation dataset somehow overrides the computed number from the training dataset."
34456,AsyncResult hangs in unexpected cases in fit_generator,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from: pip
- TensorFlow version: 2.0.0b1
- Python version: 3.6.8
- CUDA/cuDNN version: V10.0.130
- GPU model and memory: Quadro P5000 (16GB)

**Describe the current behavior**
I have a very complicated model solving an image-to-image problem. I also use a custom callback which at some point generates some noise using `numpy`.
When I use `fit_generator` on this model, it manages to do the first epoch, then on the second, third or fourth it hangs at the beginning of the epoch. I managed to see where the problem was happening, and it happens here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/data_utils.py#L875
Basically, if I put a timeout on the second `get` it times out after a few successful epochs (sometimes just one). There is no error thrown out so I don't know why it hangs. Furthermore, if I debug at that point in code, I can just execute the function synchronously and everything will work just fine.

**Describe the expected behavior**
I would like `fit_generator` to complete even when I use my custom callback.

**Code to reproduce the issue**
I didn't manage to get a minimal example using `fit_generator` (basically it relies too much on me using my model which is complex). However, I have a minimal example which reproduces the bug when I mimic the [`model_iteration`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_generator.py#L41) function.
You need to install the following to make it work: `pip install tensorflow-gpu==2.0.0b1 numpy tqdm`
```python
# imports
import time

import numpy as np
import tensorflow as tf
from tensorflow.python.keras import callbacks as cbks
from tensorflow.keras.callbacks import Callback
from tensorflow.python.keras.models import Model
from tensorflow.python.keras.engine import training_utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.python.keras.utils import data_utils
from tensorflow.python.keras.utils import generic_utils
from tqdm import tqdm_notebook

# helper function (taken from https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/training_generator.py#L500)
def _make_enqueued_generator(generator,
                             workers=1,
                              use_multiprocessing=False,
                             max_queue_size=10,
                             shuffle=False):    
    enqueuer = data_utils.OrderedEnqueuer(
        generator, use_multiprocessing=use_multiprocessing, shuffle=shuffle)
    enqueuer.start(workers=workers, max_queue_size=max_queue_size)
    output_generator = enqueuer.get()
    return output_generator, enqueuer

# My silly callback
class Noise(Callback):
     def on_batch_end(self, batch, logs={}):
        image_shape = [1, 2**7, 2**7, 1]
        noise = np.random.normal(scale=1.0, size=image_shape)

# My data
batch_size = 8
n_samples_train = 720
x = np.random.rand(n_samples_train, 256, 256, 1)
im_gen_train = ImageDataGenerator().flow(x, batch_size=batch_size)


# My training set up (to mimic https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/training_generator.py#L41)
data = im_gen_train
steps_per_epoch = int(n_samples_train / batch_size)
epochs = 20
max_queue_size=35
workers=35
use_multiprocessing=True
shuffle=False
initial_epoch=0
mode=1
steps_name='steps'
noise_cb = Noise()
noise_cb.on_train_batch_end = noise_cb.on_batch_end
callbacks=[noise_cb]

generator, enqueuer = _make_enqueued_generator(
    im_gen_train,
    workers=workers,
    use_multiprocessing=use_multiprocessing,
    max_queue_size=max_queue_size,
    shuffle=shuffle)

callbacks = cbks.configure_callbacks(
    callbacks,
    Model(),
    do_validation=False,
    epochs=epochs,
    steps_per_epoch=steps_per_epoch,
    batch_size=batch_size,
    samples=n_samples_train,
    verbose=0,  # Handle ProgBar as part of Callbacks once hooks are ready.
    mode=mode,
)
callbacks._call_begin_hook(mode)

for epoch in tqdm_notebook(range(initial_epoch, epochs)):
    callbacks.on_epoch_begin(epoch, {})

    for step in tqdm_notebook(range(steps_per_epoch), leave=False):
        callbacks._call_batch_hook('train', 'begin', step, {})
        batch_data = next(generator)
        
        # I don't actually train a model, so I just sleep for this time, this would be the backprop
        time.sleep(0.1)
        callbacks._call_batch_hook('train', 'end', step, {})
```

If you leave it as such, it will hang after about 1, 2, 3, or 4 iterations.
You can comment out the `noise = np.random.normal(scale=1.0, size=image_shape)` line and see that it doesn't hang.

You can also modify tensorflow's source code and timeout [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/data_utils.py#L875) in the second `get` so you can debug.

Note also that if the sleeping time is not high enough, hanging doesn't appear.

I am still working on a minimal example involving `fit_generator` directly, but to me this example is enough to understand what's happening.
"
34455,tf.ragged.stack breaks with rank-1 regular tensors,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary pip 
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6.5
- CUDA/cuDNN version: CUDA 10.1 cuDNN 7.6.2.24
- GPU model and memory: Quadro P2000

**Describe the current behavior**

When creating a ragged tensor by using `tf.ragged.stack` on several regular tensors on the 0-th axis, the function crashes when the rank of the input tensors is 1.

**Describe the expected behavior**

According to the [documentation](https://www.tensorflow.org/api_docs/python/tf/ragged/stack): `Given a list of tensors or ragged tensors with the same rank R (R >= axis) [...]`. Here, R=1 and  axis=0, so the preconditions should be fulfilled.

**Code to reproduce the issue**
```python
import tensorflow as tf
tf.ragged.stack([[1, 2, 3], [1, 2]], axis=0)
```

**Other info / logs**
Calling the 2 lines above results in:
```
Traceback (most recent call last):
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-14-488f6e6430bd>"", line 1, in <module>
    tf.ragged.stack([[1, 2, 3], [1, 2]], axis=0)
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/ragged/ragged_concat_ops.py"", line 113, in stack
    return _ragged_stack_concat_helper(values, axis, stack_values=True)
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/ragged/ragged_concat_ops.py"", line 167, in _ragged_stack_concat_helper
    return array_ops.stack(rt_inputs, axis)
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py"", line 1154, in stack
    return ops.convert_to_tensor(values, name=name)
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1184, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1242, in convert_to_tensor_v2
    as_ref=False)
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1296, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py"", line 1278, in _autopacking_conversion_function
    return _autopacking_helper(v, dtype, name or ""packed"")
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py"", line 1184, in _autopacking_helper
    return gen_array_ops.pack(list_or_tuple, name=name)
  File ""/home/veith/Projects/venvs/anontf2/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 6293, in pack
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [3] != values[1].shape = [2] [Op:Pack] name: stack
```

**Workaround**

Expanding the rank-1 tensors to rank-2 tensors followed by squeezing the redundant dimension seems to work:
```python
import tensorflow as tf
x = tf.ragged.stack([[[1, 2, 3]], [[1, 2]]], axis=0)
print(x.bounding_shape())  # <tf.Tensor: id=929, shape=(3,), dtype=int64, numpy=array([2, 1, 3])>
x = tf.squeeze(x, axis=1) 
print(x.bounding_shape())  # <tf.Tensor: id=1109, shape=(2,), dtype=int64, numpy=array([2, 3])>
```

**Estimated cause**

I did not check the tensorflow source code for this, but the [general ragged documentation](https://www.tensorflow.org/guide/ragged_tensor#ragged_tensors_definitions) states:
![image](https://user-images.githubusercontent.com/12949211/69247798-544f0780-0bab-11ea-8ff0-3f6626a8e2f8.png)
I assume the issue is that there is no uniform dimension in the regular tensors before stacking them. Intuitively I would have assumed that I can use `tf.ragged.stack` to create this uniform dimension to form a ragged tensor from several non-ragged different-dimension tensors as above, similar to the regulat `tf.stack`, which creates a new dimension.
I am not sure whether this is considered a bug or an error in the documentation of `tf.ragged.stack`, but it feels like a bug from a user perspective."
34454,"Layer model is not connected, no input to return.","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macos mohave
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow==2.0.0
- TensorFlow version (use command below): 2.0.0
- Python version: Python 3.7.4
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**

Raises exception.
When loading saved model through the tf.keras.Model we get (tf=2.0.0):
    
    AttributeError: Layer model is not connected, no input to return.

**Describe the expected behavior**

It should pass. It pass when saving and loading model from .h5 format.

**Code to reproduce the issue**

```python
import tensorflow as tf

shape = (224, 224, 3)

# functional model
base_model2 = tf.keras.applications.MobileNetV2(include_top=False, weights=""imagenet"", input_shape=shape)
inputs = tf.keras.Input(shape=shape, name=""input"")
x = base_model2(inputs)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(256, activation=""relu"", name=""embeddings"")(x)
outputs = tf.keras.layers.Dense(2, activation=""softmax"", name=""probs"")(x)
model2 = tf.keras.Model(inputs=inputs, outputs=outputs)


tf.keras.models.save_model(model2, ""model"")
model_l2 = tf.keras.models.load_model(""model"")

# this raises exception
model_loaded = tf.keras.Model(
    inputs=model_l2.input, outputs=[model_l2.get_layer(layer_name).output for layer_name in [""probs"", ""embeddings""]]
)
```

**Other info / logs**

```
2019-11-20 15:24:41.862516: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-20 15:24:41.873895: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa773aa38b0 executing computations on platform Host. Devices:
2019-11-20 15:24:41.873913: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-20 15:24:55.102446: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /Users/userx/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Traceback (most recent call last):
  File ""save2.py"", line 20, in <module>
    inputs=model_l2.input, outputs=[model_l2.get_layer(layer_name).output for layer_name in [""probs"", ""embeddings""]]
  File ""/Users/userx/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1557, in input
    ' is not connected, no input to return.')
AttributeError: Layer model is not connected, no input to return.
```"
34452,python3.7.3 Anaconda tensorflow   No module named 'joblib',"I have successfully installed the sklearn library, but it shows the code running result display.
No module named 'joblib'
I am very confused, I hope to get your answer, thanks ‘
Here is my code

---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-25-638e12154cef> in <module>
----> 1 from sklearn.datasets import load_wine
      2 win_dataset=load_wine()
      3 print('\n\n\n')
      4 print(""the result is"")
      5 print(""红酒中的数据：\n{}"".format(wine_dataset.keys()))

~\AppData\Roaming\Python\Python37\site-packages\sklearn\__init__.py in <module>
     74 else:
     75     from . import __check_build
---> 76     from .base import clone
     77     from .utils._show_versions import show_versions
     78 

~\AppData\Roaming\Python\Python37\site-packages\sklearn\base.py in <module>
     14 
     15 from . import __version__
---> 16 from .utils import _IS_32BIT
     17 
     18 _DEFAULT_TAGS = {

~\AppData\Roaming\Python\Python37\site-packages\sklearn\utils\__init__.py in <module>
     15 from .murmurhash import murmurhash3_32
     16 from .class_weight import compute_class_weight, compute_sample_weight
---> 17 from . import _joblib
     18 from ..exceptions import DataConversionWarning
     19 from .deprecation import deprecated

~\AppData\Roaming\Python\Python37\site-packages\sklearn\utils\_joblib.py in <module>
      6     # joblib imports may raise DeprecationWarning on certain Python
      7     # versions
----> 8     import joblib
      9     from joblib import logger
     10     from joblib import dump, load

ModuleNotFoundError: No module named 'joblib'


"
34451,'accuracy' and tf.metrics.get('accuracy') produce different results,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, see below
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OpenSUSE
- TensorFlow installed from (source or binary): pip binary within pyenv
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7.5

**Describe the current behavior**
The same model behaves differently whether one uses `'accuracy'` or `tf.keras.metrics.get('accuracy')` (see below).

**Describe the expected behavior**
They should behave identically.

**Code to reproduce the issue**
```
""""""Bug.""""""
# import keras
import numpy as np
import tensorflow.keras as keras

X = np.empty([10, 224, 224, 3])
Y = np.empty([10, 2])

MODEL = keras.applications.vgg16.VGG16(weights=None, classes=2)

MODEL.compile(optimizer=keras.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
MODEL.fit(X, Y, epochs=10)

MODEL.compile(optimizer=keras.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=[keras.metrics.get('accuracy')])
MODEL.fit(X, Y, epochs=10)
```
Example output:
```
Train on 10 samples
Epoch 1/10

10/10 [==============================] - 4s 389ms/sample - loss: inf - accuracy: 0.9000
Epoch 2/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 3/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 4/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 5/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 6/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 7/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 8/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 9/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 10/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Train on 10 samples
Epoch 1/10

10/10 [==============================] - 1s 131ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 2/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 3/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 4/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 5/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 6/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 7/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 8/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 9/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 10/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
```

**Other info / logs**
Closely related to #34088"
34449,TensorBoard callback should not close and reopen writers to enable reuse,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, see below
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OpenSUSE
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7.5

**Describe the current behavior**
Currently, the `tf.keras.callbacks.TensorBoard.set_model` function closes the `train` writer, only to reopen it two lines later:

https://github.com/tensorflow/tensorflow/blob/7eef97bba7a9018d6b0630418d0810f94c1d2222/tensorflow/python/keras/callbacks.py#L1535-L1537

This complicates sharing the writer with other callbacks, e.g., in my code below: this code throws a `RuntimeError: SummaryWriter is already closed`.

**Describe the expected behavior**
`tf.keras.callbacks.TensorBoard.set_model` should only close those writers that will not be needed any longer.

**Code to reproduce the issue**
```
# import keras
import numpy as np
import tensorboard.plugins.hparams.api as hp
import tensorflow.keras as keras

tb_callback = keras.callbacks.TensorBoard(log_dir='/tmp')
tb_train_writer = tb_callback._get_writer(tb_callback._train_run_name)  # pylint:disable=protected-access
hp_callback = hp.KerasCallback(tb_train_writer, {'param': 42})
model = keras.applications.VGG16()
model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy')
model.fit(np.empty((1, 224, 224, 3)), np.empty((1, 1000)), callbacks=[tb_callback, hp_callback])
```
"
34448,model.compile() should check for unknown kwargs,"**System information**
- TensorFlow version (you are using): TF2
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
This code works:
```
# import keras
import tensorflow.keras as keras

model = keras.applications.VGG16()
model.compile(loss='mse', optimizer=keras.optimizers.Adam(),
              why_does_this_not_fail=42.0)
print(""Success"")
```

I believe this code should throw an exception stating that `why_does_this_not_fail` is not a known argument.

**Will this change the current api? How?**
No.

**Who will benefit with this feature?**
Anyone who inadvertently adds the `callbacks` argument to the `model.compile` method (instead of `model.fit`) and asks themselves why their callbacks are not working.
"
34447,Tensorflow C/C++ only?,"- OS Platform and Distribution Linux Ubuntu 18.04
- Virtual guest on windows hyperV

Trying your installation steps and fails again and again:

pip install -U pip six numpy wheel setuptools mock 'future>=0

It's trying to connect without success, although the machine does not have any network issue.

Is there a way to use TensorFlow w/o python , only C/C++?"
34445,Adapter to allow sparse matrix as target labels in Keras models,"Tensorflow version : 2.0
OS : Debian 9

I am training a sequential model as shown below : 

    model = Sequential()
    model.add(Embedding(input_dim=170000, output_dim=100, input_length=10))
    model.add(GlobalAveragePooling1D())
    model.add(Dense(num_target=3811, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001))

    model.fit(X_train,
              Y_train
              batch_size=16384,
              epochs=200,
              verbose=1)

X_train.shape = (12528566, 10)
Y_train.shape = (12528566, 3811) 

X_train type : numpy.ndarray
Y_train type : scipy.sparse.csr.csr_matrix

Earlier in tensorflow 1.13 the training worked fine, but in Tensorflow 2.0 it is throwing error :
` Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, <class 'scipy.sparse.csr.csr_matrix'>`

I can convert Y_train dense type, by command :
`Y_train.toarray()`

but it throws error saying, 
`MemoryError: Unable to allocate array with shape (12528566, 3811) and data type int64`

The size of Y_train when dense is, 12528566 * 3811 * 8 = ~381GB

Dense Y_train works fine, but only for smaller data.


So in order to make above thing work, I changed my loss to 'sparse_categorical_crossentropy' & Y_train to `np.asarray(Y_train.tocoo().col)` which is basically the index of my label vector which maps to the corresponding output label, and model gets trained on Tensorflow 2.0 and predicts as expected.

    model = Sequential()
    model.add(Embedding(input_dim=170000, output_dim=100, input_length=10))
    model.add(GlobalAveragePooling1D())
    model.add(Dense(num_target=3811, activation='softmax'))
    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001))


Now I want to train a model with 'binary_crossentropy' loss model with 'sigmoid' activation for which I need to make Y_train as dense matrix, since there is no 'sparse_binary_crossentropy' loss type. If I don't use dense Y_train I get an error : 

`ValueError: A target array with shape (12528566, 1) was passed for an output of shape (None, 3811) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output.`



1. Why is the adapter to handle sparse matrix removed from Tensorflow 2.0?
2. Why is there no 'sparse_binary_crossentropy' loss type?


"
34444,tf.reduce_mean crashes TensorFlow Lite,"**System information**
- Ubuntu 18.04 4.15.0-66-generic x86_64 
- TensorFlow installed from (source or binary): official wheel
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7
- CUDA/cuDNN version: N/A

**Describe the current behavior**

The program SIGABRTs (see the code below).

**Describe the expected behavior**

The program does not crash.

**Code to reproduce the issue**

<details>
<summary>Code</summary>

```python
from time import time

import numpy as np
import tensorflow as tf
from tensorflow.lite.python.interpreter import load_delegate


def measure(size, rep, tpu):
    @tf.function(input_signature=[tf.TensorSpec([size] * 2, tf.float32)] * 2)
    def bench_func(a, b):
        x = tf.linalg.matmul(a, b)
        return tf.reduce_mean(x)
    
    def gen_input_samples():
        i = np.identity(size, np.float32)
        yield [-i, i]
        yield [i, i]

    converter = tf.lite.TFLiteConverter.from_concrete_functions([bench_func.get_concrete_function()])
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = gen_input_samples
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.uint8
    converter.inference_output_type = tf.uint8
    tflite_model = converter.convert()
    delegates = [load_delegate(""libedgetpu.so.1.0"")] if tpu else []
    interpreter = tf.lite.Interpreter(model_content=tflite_model, experimental_delegates=delegates)
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    tensor_in1 = interpreter.tensor(input_details[0][""index""])
    tensor_in2 = interpreter.tensor(input_details[1][""index""])
    tensor_out = interpreter.tensor(output_details[0][""index""])
    inp1 = np.random.rand(size, size) - 0.5
    inp2 = np.random.rand(size, size) - 0.5
    tensor_in1()[:] = inp1
    tensor_in2()[:] = inp2
    now = time()
    for _ in range(rep):
        interpreter.invoke()
    return time() - now
 
print(measure(2048, 1, tpu=False))
```
</details>

**Other info / logs**
<details>
<summary>Log</summary>

```
2019-11-20 10:43:18.538007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-20 10:43:18.546197: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-11-20 10:43:18.546227: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vadim-XPS-13-9380): /proc/driver/nvidia/version does not exist
2019-11-20 10:43:18.546569: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-20 10:43:18.572569: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1992000000 Hz
2019-11-20 10:43:18.573251: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x48fd5a0 executing computations on platform Host. Devices:
2019-11-20 10:43:18.573290: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-20 10:43:18.671265: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2019-11-20 10:43:18.671336: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-20 10:43:18.690246: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-20 10:43:18.690274: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.005ms.
2019-11-20 10:43:18.690277: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-20 10:43:18.700228: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2019-11-20 10:43:18.700397: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-20 10:43:18.720772: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-20 10:43:18.720800: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 0.895ms.
2019-11-20 10:43:18.720822: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 0.072ms.
INFO: Initialized TensorFlow Lite runtime.
INFO: Initialized TensorFlow Lite runtime.
Aborted (core dumped)
```
</details>

<details>
<summary>gdb bt</summary>

```
#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:51
#1  0x00007ffff7a24801 in __GI_abort () at abort.c:79
#2  0x00007fff3c18b616 in TfLiteStatus tflite::ops::builtin::reduce::EvalMean<(tflite::ops::builtin::reduce::KernelType)0>(TfLiteContext*, TfLiteNode*) ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#3  0x00007fff3c1f0577 in tflite::Subgraph::Invoke() ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#4  0x00007fff3c1f222a in tflite::Interpreter::Invoke() ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#5  0x00007fff3c0bff58 in tflite::interpreter_wrapper::InterpreterWrapper::Invoke() ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#6  0x00007fff3c0be054 in _wrap_InterpreterWrapper_Invoke ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#7  0x00000000005b0462 in _PyMethodDef_RawFastCallKeywords () at ../Objects/call.c:694
#8  0x00000000005cc860 in _PyCFunction_FastCallKeywords (kwnames=<optimized out>, nargs=<optimized out>, args=0x7fff6c1216c0, func=
    <built-in method InterpreterWrapper_Invoke of module object at remote 0x7fff6c11ed18>) at ../Objects/call.c:730
#9  call_function.lto_priv () at ../Python/ceval.c:4568
#10 0x000000000051add9 in _PyEval_EvalFrameDefault () at ../Python/ceval.c:3093
#11 0x00000000005b0eac in PyEval_EvalFrameEx (throwflag=0, f=
    Frame 0x7fff6c121540, for file /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py, line 109, in Invoke (self=<InterpreterWrapper(this=<SwigPyObject at remote 0x7fff74aca030>) at remote 0x7fff741f1c88>)) at ../Python/ceval.c:547
#12 function_code_fastcall (globals=<optimized out>, nargs=<optimized out>, args=<optimized out>, co=<optimized out>) at ../Objects/call.c:283
#13 _PyFunction_FastCallKeywords () at ../Objects/call.c:408
#14 0x00000000005cc6ea in call_function.lto_priv () at ../Python/ceval.c:4616
#15 0x000000000051add9 in _PyEval_EvalFrameDefault () at ../Python/ceval.c:3093
#16 0x00000000005b0eac in PyEval_EvalFrameEx (throwflag=0, 
    f=Frame 0x7fff6c125048, for file /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter.py, line 453, in invoke (self=<Interpreter(_model_content=b' \x00\x00\x00TFL3\x00\x00\x00\x00\x00\x00\x12\x00\x1c\x00\x04\x00\x08\x00\x0c\x00\x10\x00\x14\x00\x00\x00\x18\x00\x12\x00\x00\x00\x03\x00\x00\x00\x00&\x00\x00\xf0 \x00\x00\xd8 \x00\x00<\x00\x00\x00\x04\x00\x00\x00\x01\x00\x00\x00\x0c\x00\x00\x00\x08\x00\x0c\x00\x04\x00\x08\x00\x08\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\x13\x00\x00\x00min_runtime_version\x00\n\x00\x00\x00\x90 \x00\x00\x80\x00\x00\x00p\x00\x00\x00d\x00\x00\x00L\x00\x00\x004\x00\x00\x00,\x00\x00\x00$\x00\x00\x00\x1c\x00\x00\x00\x04\x00\x00\x00\xaa\xff\xff\xff\x04\x00\x00\x00\x05\x00\x00\x001.6.0\x00\x00\x00\xa4\xda\xff\xff\xa8\xda\xff\xff\xac\xda\xff\xff\xca\xff\xff\xff\x04\x00\x00\x00\x08\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\xde\xff\xff\xff\x04\x00\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\xd8\xda\xff\xff\x04\x00\x06\x00\x04\x00\x00\x00\x00\x00\x06\x00\x...(truncated)) at ../Python/ceval.c:547
#17 function_code_fastcall (globals=<optimized out>, nargs=<optimized out>, args=<optimized out>, co=<optimized out>) at ../Objects/call.c:283
#18 _PyFunction_FastCallKeywords () at ../Objects/call.c:408
#19 0x0000000000516d6a in call_function (kwnames=0x0, oparg=<optimized out>, pp_stack=0x7fffffffd010) at ../Python/ceval.c:4616
#20 _PyEval_EvalFrameDefault () at ../Python/ceval.c:3110
#21 0x00000000005cd202 in PyEval_EvalFrameEx (throwflag=0, 
    f=Frame 0xf20238, for file bench.py, line 40, in measure (rep=1, tpu=False, bench_func=<Function(_lock=<_thread.lock at remote 0x7fffe26e7b98>, _python_function=<function at remote 0x7fffe05bf9d8>, _function_spec=<FunctionSpec(_fullargspec=<FullArgSpec at remote 0x7fff74b27c88>, _is_method=False, _default_values=None, _args_to_indices={'a': 0, 'b': 1}, arg_names=['a', 'b'], vararg_name=None, _arg_indices_to_default_values={}, _input_signature=(<TensorSpec at remote 0x7fff74ab6dc8>, <...>), _flat_input_signature=(<...>, <...>)) at remote 0x7ffff6614710>, _autograph=True, _experimental_autograph_options=None, experimental_relax_shapes=False, _created_variables=[], _stateful_fn=<Function(_python_function=<function at remote 0x7fff74ac2158>, _function_spec=<FunctionSpec(_fullargspec=<FullArgSpec at remote 0x7fff74b27cf8>, _is_method=False, _default_values=None, _args_to_indices={'a': 0, 'b': 1}, arg_names=['a', 'b'], vararg_name=None, _arg_indices_to_default_values={}, _input_signature=(...), _flat_input_signature=...(truncated)) at ../Python/ceval.c:547
```
</details>

`tf.reduce_sum()` does not crash."
34443,Metrics not added when tf.keras.Model is compiled without loss,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): ✅ 
- OS Platform and Distribution : Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.0.0
```
print(tf.version.GIT_VERSION, tf.version.VERSION)
v2.0.0-rc2-26-g64c3d38 2.0.0
```

- Python version:
```
Python 3.6.8 (default, Jan 14 2019, 11:02:34)
[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux
```

- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

When compiling a `tf.keras` model without adding a loss, the `metrics` are not added.

**Describe the expected behavior**

`metrics` should be computed in any case to give insights about the training as it is based on model output and true value given by the data loader/sequence.

**Code to reproduce the issue**

```
from tensorflow.python.keras.layers import Conv2D, GlobalAveragePooling2D, Input, Dense
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.regularizers import l2

model = Sequential([
    Input((224, 224, 3)),
    Conv2D(256, (3, 3), kernel_regularizer=l2()),
    GlobalAveragePooling2D(),
    Dense(10, activation='sigmoid'),
])

# Metrics are added
model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])
print(model.metrics)

# Metric are empty
model.compile(optimizer='Adam', metrics=['accuracy'])
print(model.metrics)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34442,OOM (out of memory) Without any reason on Tensorflow,"Everytime I try to run deepfacelab cuda 9.2 (the most updated version from a week ago) receive the following:

Using TensorFlow backend.
Loading: 100%|######################################################################| 654/654 [00:03<00:00, 196.88it/s]
Loading: 100%|####################################################################| 1491/1491 [00:06<00:00, 238.51it/s]
============= Model Summary =============
==                                     ==
==        Model name: H64              ==
==                                     ==
== Current iteration: 0                ==
==                                     ==
==----------- Model Options -----------==
==                                     ==
==       sort_by_yaw: False            ==
==       random_flip: False            ==
==        lighter_ae: False            ==
==        pixel_loss: False            ==
==        batch_size: 2                ==
==                                     ==
==------------ Running On -------------==
==                                     ==
==      Device index: 0                ==
==              Name: GeForce GTX 1050 ==
==              VRAM: 4.00GB           ==
==                                     ==

Starting. Press ""Enter"" to stop training and save model.
[10:34:55][#000001][9096ms][3.6420][2.6351]
Error: OOM when allocating tensor with shape[2048,1024,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[{{node training/Adam/gradients/model_1/conv2d_5/convolution_grad/Conv2DBackpropFilter}} = Conv2DBackpropFilter[T=DT_FLOAT, _class=[""loc:@train...kpropInput""], data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](training/Adam/gradients/model_1/conv2d_5/convolution_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, ConstantFolding/training/Adam/gradients/model_1/conv2d_5/convolution_grad/ShapeN-matshapes-1, training/Adam/gradients/AddN_23)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

Traceback (most recent call last):
  File ""C:\Users\Jorge\Downloads\DeepFaceLab_CUDA_9.2_SSE\_internal\DeepFaceLab\mainscripts\Trainer.py"", line 109, in trainerThread
    iter, iter_time = model.train_one_iter()
  File ""C:\Users\Jorge\Downloads\DeepFaceLab_CUDA_9.2_SSE\_internal\DeepFaceLab\models\ModelBase.py"", line 525, in train_one_iter
    losses = self.onTrainOneIter(sample, self.generator_list)
  File ""C:\Users\Jorge\Downloads\DeepFaceLab_CUDA_9.2_SSE\_internal\DeepFaceLab\models\Model_H64\Model.py"", line 89, in onTrainOneIter
    total, loss_src_bgr, loss_src_mask, loss_dst_bgr, loss_dst_mask = self.ae.train_on_batch( [warped_src, target_src_full_mask, warped_dst, target_dst_full_mask], [target_src, target_src_full_mask, target_dst, target_dst_full_mask] )
  File ""C:\Users\Jorge\Downloads\DeepFaceLab_CUDA_9.2_SSE\_internal\python-3.6.8\lib\site-packages\keras\engine\training.py"", line 1217, in train_on_batch
    outputs = self.train_function(ins)
  File ""C:\Users\Jorge\Downloads\DeepFaceLab_CUDA_9.2_SSE\_internal\python-3.6.8\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2715, in __call__
    return self._call(inputs)
  File ""C:\Users\Jorge\Downloads\DeepFaceLab_CUDA_9.2_SSE\_internal\python-3.6.8\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File ""C:\Users\Jorge\Downloads\DeepFaceLab_CUDA_9.2_SSE\_internal\python-3.6.8\lib\site-packages\tensorflow\python\client\session.py"", line 1439, in __call__
    run_metadata_ptr)
  File ""C:\Users\Jorge\Downloads\DeepFaceLab_CUDA_9.2_SSE\_internal\python-3.6.8\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[2048,1024,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[{{node training/Adam/gradients/model_1/conv2d_5/convolution_grad/Conv2DBackpropFilter}} = Conv2DBackpropFilter[T=DT_FLOAT, _class=[""loc:@train...kpropInput""], data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](training/Adam/gradients/model_1/conv2d_5/convolution_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, ConstantFolding/training/Adam/gradients/model_1/conv2d_5/convolution_grad/ShapeN-matshapes-1, training/Adam/gradients/AddN_23)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

Done.


I have an i5 8300 and a GTX 1050, in this case I was running the H64 on the example videos (the just do it one and the iron man as source) and doesnt make sense that with 4gb of vram it goes OOM on like the (10 - 30) first iterations

PLease help!
"
34441,Updating the guide for building TensorFlow Lite with select ops for iOS,"Hi!

We followed the [guide](https://www.tensorflow.org/lite/guide/ops_select#ios), which seems bit outdated as `tensorflow/contrib` has been removed. We couldn't get TFLite model with select ops working on iOS, while the same model is working well on Android. It seems that bazel could also be used for building the library together with using private CocoaPods. We tested this approach but were also unsuccessful. Could the documentation be improved with this regard for having clearer guidelines?

Ideas and explanations of how to get it working are also welcome under this issue. Do you have an estimation when could we expect the CocoaPods (with-select-ops version) for iOS/Swift?

## URL(s) with the issue:
https://www.tensorflow.org/lite/guide/ops_select#ios

## Description of issue (what needs changing):
The current guide could be improved, especially because `tensorflow/contrib` is removed in the latest version of TensorFlow. Therefore, `tensorflow/contrib/makefile/build_all_ios_with_tflite.sh` is no longer available for building TensorFlow Lite with select ops support.

### Clear description
Couldn't get a TFLite model with select ops working in iOS by following the [guide](https://www.tensorflow.org/lite/guide/ops_select#ios). The same model was successfully working on Android with nightly builds. Would be nice to have a guide for how to build it with bazel.

### Correct links
N/A

### Parameters defined
N/A

### Returns defined
N/A

### Raises listed and defined
N/A

### Usage example
Would be good if it would be explained in more detail what has to be done. Do we only have to compile and link libraries as explained in the documentation or do we need to modify the code also, e.g. add Flex delegate as an option for Interpreter?

### Request visuals, if applicable
No need for visuals

### Submit a pull request?
N/A"
34440,Error while building API docs,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/compat/v1/flags/tf_decorator/tf_stack/FileAndLine

## Description of issue (what needs changing):
Get a `ValueError` while setting up to view TensorFlow-style HTML locally. (According to https://www.tensorflow.org/community/contribute/docs)

### Clear description
```
Traceback (most recent call last):
  File ""generate2.py"", line 284, in <module>
    app.run(main)
  File ""C:\Users\ASPIRE\.conda\envs\tensorflow2\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\ASPIRE\.conda\envs\tensorflow2\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""generate2.py"", line 280, in main
    search_hints=FLAGS.search_hints)
  File ""generate2.py"", line 273, in build_docs
    doc_generator.build(output_dir)
  File ""C:\Users\ASPIRE\.conda\envs\tensorflow2\lib\site-packages\tensorflow_docs\api_generator\generate_lib.py"", line 839, in build
    site_path=self._site_path)
  File ""C:\Users\ASPIRE\.conda\envs\tensorflow2\lib\site-packages\tensorflow_docs\api_generator\generate_lib.py"", line 507, in write_docs
    'Failed to generate docs for symbol: `{}`'.format(full_name))
ValueError: Failed to generate docs for symbol: `tf.compat.v1.flags.tf_decorator.tf_stack.FileAndLine`
```"
34439,Build failure: undefined reference to protobuf symbols #34117 closed issue still occurring on r2.1,"Re: [https://github.com/tensorflow/tensorflow/issues/34117](url)
This issue is still occurring when I build r2.1 branch with bazel 1.1.0.
It has been fixed on head.  Would it be possible to implement the fix on build r2.1
Also the maximum bazel version needs to be increased to 1.1.0 in configure.py once the fix is implemented (in both head and r2.1)."
34438,Build libtensorflow-lite.a with android-ndk-r14b and some errors has occurred,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version:master
- Python version:3.5.2
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 1.0.1
- GCC/Compiler version (if compiling from source): 4.9.X
- CUDA/cuDNN version:N/A
- GPU model and memory: I7 + 16G



**Describe the problem**
/tensorflow/lite/kernels/internal/reference/reference_ops.h:1100:36: error: 'round' is not a member of 'std'
               static_cast<int32_t>(std::round(input_ptr[j] * scale + bias)) +

./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:4097:38: error: 'rint' is not a member of 'std'
       const int32_t prob_quantized = std::rint(log_prob) + params.zero_point;

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I had created two files:
 ./tensorflow/lite/tools/make/build_android_ndk_lib.sh
The contents are as follows:

#############################START#############################
#!/bin/bash
# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

set -x
set -e

SCRIPT_DIR=""$(cd ""$(dirname ""${BASH_SOURCE[0]}"")"" && pwd)""
TENSORFLOW_DIR=""${SCRIPT_DIR}/../../../..""

make -j 4 TARGET=android_ndk -C ""${TENSORFLOW_DIR}"" -f tensorflow/lite/tools/make/Makefile
#############################END#############################

 ./tensorflow/lite/tools/make/targets/android_ndk_makefile.inc
The contents are as follows:

#############################START#############################
# Settings for generic aarch64 boards such as Odroid C2 or Pine64.
ifeq ($(TARGET),android_ndk)
  # The aarch64 architecture covers all 64-bit ARM chips. This arch mandates
  # NEON, so FPU flags are not needed below.
  TARGET_ARCH := armv7-a
  TARGET_TOOLCHAIN_PREFIX := /opt/build_tools/android-ndk-r14b/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-

  CXXFLAGS += \
    -march=armv7-a \
    -mfpu=neon \
    -funsafe-math-optimizations \
    -ftree-vectorize \
    -Wall \
    -std=c++11 \
    -fPIC

  CFLAGS += \
    -march=armv7-a \
    -mfpu=neon \
    -funsafe-math-optimizations \
    -ftree-vectorize \
    -Wall \
    -fPIC

  LDFLAGS := \
    -Wl,--no-export-dynamic \
    -Wl,--exclude-libs,ALL \
    -Wl,--gc-sections \
    -Wl,--as-needed \
    -lrt
       
  LIBS := \
    -lstdc++ \
    -lpthread \
    -lm \
    -ldl
    
  INCLUDES += \
    -I/opt/build_tools/android-ndk-r14b/platforms/android-21/arch-arm/usr/include \
    -I/opt/build_tools/android-ndk-r14b/platforms/android-21/arch-arm/usr/include/sys \
    -I/opt/build_tools/android-ndk-r14b/sources/cxx-stl/gnu-libstdc++/4.9/include \
    -I/opt/build_tools/android-ndk-r14b/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include  \
    -I/opt/build_tools/android-ndk-r14b/sources/cxx-stl/gnu-libstdc++/4.9/include/bits 
       
endif
##############################END#####################################

and run  ./tensorflow/lite/tools/make/build_android_ndk_lib.sh 

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34436,Add GPU delegate support to the TFLite experimental c api,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes


**Describe the feature and the current behavior/state.**
the lite experimental c api (used by the unity plugin) currently only supports running the network on the CPU.
It would be very useful to be able to use the GPU delegate for apps made directly in unity.


**Will this change the current api? How?**
It extends the lite c api to be more in line with the c++ api. 

**Who will benefit with this feature?**
Anyone who wants to use Tensorflow in unity on modern phones.
"
34435,Significantly slow training with TFRecords when the labels are one-hot encoded,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: K80

**Describe the current behavior**

I am incorporating TFRecords along with all the `tf.data` legacy functions in my projects. I primarily work with images. I am trying to develop a data input pipeline for an image classification project with the **Flowers-17** dataset. My aim is to first serialize the entire dataset in form TFRecords with multiple shards. I have been able to do that. I am then reading those TFRecords, preprocessing them, augmenting them and finally, I am feeding them to a model. 

Now, I ran two versions of the above experiment:
- One where the image labels were simply encoded using indexing
- Another one where the image labels were one-hot encoded

While compiling the model for the above two scenarios I supplied the loss functions accordingly as well. It now seems that the first experiment where the model **was not** supplied one-hot encoded class labels is training _much faster_ than the other one. 

**Describe the expected behavior**

Model training time should be closely equal in both the cases I mentioned. 

**Code to reproduce the issue**
- [Colab notebook](https://colab.research.google.com/github/sayakpaul/TF-2.0-Hacks/blob/master/tf.data%20exploration/TFRecords_with_tf_data_Advanced.ipynb) for where one-hot encoding wasn't done. 
- [Colab notebook](https://colab.research.google.com/drive/1CuOZJNlWsXdGlhCCfZ14PvSEU2Gtcrdf) with one-hot encoding. "
34434,tensorflow is not using GPU,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:None
- TensorFlow installed from (source or binary):binary
- TensorFlow version:tensorflow-gpu==1.14
- Python version:3.6.8
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):none
- GCC/Compiler version (if compiling from source):none
- CUDA/cuDNN version:10.1/7.6.4
- GPU model and memory:GeForce GTX 1060 6GB and 6144 MB



**Describe the problem** my problem is that my gpu is not being used during training 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I have run the following command for training my model
python -u ""DeepSpeech.py""\
    --train_files ""/home/sehar/urdu/cv-valid-train.csv""\
    --dev_files ""/home/sehar/urdu/cv-valid-dev.csv"" \
    --test_files ""/home/sehar/urdu/cv-valid-test.csv"" \
    --alphabet_config_path ""/home/sehar/urdu-models/alphabet.txt"" \
    --lm_binary_path ""/home/sehar/urdu-models/lm.binary"" \
    --lm_trie_path ""/home/sehar/urdu-models/trie"" \
    --learning_rate 0.000025 \
    --dropout_rate 0\
    --log_level 1 \
    --noearly_stop \
    --epochs 100 \
    --max_to_keep 1 \
    --checkpoint_dir ""/home/sehar/DeepSpeech/check"" \
    --export_dir ""/home/sehar/urdu-models""



**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34433,r2.0/2.1 Python 3.8 AutoGraph could not transform <bound method LinearRegressionTF.fit of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f7a5ccc1fa0>> and will run it as-is,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (attached file code_warning_py38.py.txt -> rename it as .py and execute it)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): This problem occurs with both r2.0 (built from head) and r2.1rc0
- Python version: 3.8 virtual environment (The problem does not occur with Python 3.7.3)
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: CUDA 10 / cuDNN 7.6.5
- GPU model and memory: Nvidia Geforce RTX 2080 Ti

**Describe the current behavior**
export AUTOGRAPH_VERBOSITY=10
Run the attached python script (renamed as .py)
python code_warning_py38.py &> output.txt
Read the output in the attached output.txt

**Describe the expected behavior**
There is no warning message when the script is run with Python 3.7.3

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
See both files attached.
[code_warning_py38.py.txt](https://github.com/tensorflow/tensorflow/files/3867410/code_warning_py38.py.txt)
[output.txt](https://github.com/tensorflow/tensorflow/files/3867412/output.txt)
"
34432,Model mismatch between create_low_latency_conv_model and cnn-one-fstride4,"https://github.com/tensorflow/tensorflow/blob/ba63d9082a2265da91ec4daefecfa4cd47fcf07f/tensorflow/examples/speech_commands/models.py#L337-L339

But the stride is actually **one** instead of **four**:

https://github.com/tensorflow/tensorflow/blob/ba63d9082a2265da91ec4daefecfa4cd47fcf07f/tensorflow/examples/speech_commands/models.py#L388-L389

which results in a **huge** increase of the number of parameters of the subsequent FC layer."
34431,AttributeError: module 'tensorflow' has no attribute 'app',"Hi, I'm new in the field of machine learning, and I started watching a video about how to classify images
Video: https://www.youtube.com/watch?v=EKe05rMG-Ww


but in a part when I run: python csv_a_tf.py --csv_input=CSV/test.csv --output_path=TFRecords/test.record --images=images


this gives me back:
----------------------------------------
Traceback (most recent call last):
  File ""csv_a_tf.py"", line 24, in <module>
    flags = tf.app.flags
AttributeError: module 'tensorflow' has no attribute 'app'
----------------------------------------
any ideas?

"
34430,"Speech_command validation accuracy is very low,just 8.3%,Why?","Hi ALL , I download from this repo. Run the example of speech_command.However, I find the validation accuracy just is 8.3%. I run the model by pycharm and the edition of tensorflow is 2.0.0b.

"
34429,build failed with cuda 10.2,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0.0
- Python version: 3.7.5 x64
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 1.1.0 x64
- GCC/Compiler version (if compiling from source):  7.4.0
- CUDA/cuDNN version: 10.2 / 7.6.5
- GPU model and memory: GTX1080Ti GDDR5X 11GB



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


```
ERROR: /home/vai/.cache/bazel/_bazel_vai/964c7018fd2d0d2d2cf98e15f592d3c8/external/nccl_archive/BUILD.bazel:53:1: fatbinary external/nccl_archive/device_dlink_hdrs.fatbin failed (Exit 1)
fatbinary fatal   : Unknown option '-bin2c-path'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/vai/repo/tensorflow/tensorflow/python/tools/BUILD:81:1 fatbinary external/nccl_archive/device_dlink_hdrs.fatbin failed (Exit 1)
```"
34428,Multiple public header files are not usable. Dependencies are missing.,"Hi,

The following files import header files from path which are not existing:

```bash
$ cd /usr/local/lib/python3.6/dist-packages/tensorflow/include/
$ grep -rnw '.' -e 'third_party/gpus/cuda'

./tensorflow/stream_executor/gpu/gpu_types.h:31:#include ""third_party/gpus/cuda/include/cuComplex.h""
./tensorflow/stream_executor/gpu/gpu_types.h:32:#include ""third_party/gpus/cuda/include/cuda.h""
./tensorflow/core/util/gpu_kernel_helper.h:22:#include ""third_party/gpus/cuda/include/cuda_fp16.h""
./tensorflow/core/util/gpu_device_functions.h:34:#include ""third_party/gpus/cuda/include/cuComplex.h""
./tensorflow/core/util/gpu_device_functions.h:35:#include ""third_party/gpus/cuda/include/cuda.h""
```

This is problematic because the headers can't be imported as the path requested does not exist:
```bash
$ ls /usr/local/lib/python3.6/dist-packages/tensorflow/include/third_party/gpus/cuda/include/
ls: cannot access '/usr/local/lib/python3.6/dist-packages/tensorflow/include/third_party/gpus/cuda/include/': No such file or directory
```

Problem was caused by this commit: https://github.com/tensorflow/tensorflow/commit/922386b9fcc23596877da3500787a045a861cb52#diff-3146a2ef48234a027b42c52f71bcb177

This issue lead to multiple issues as soon as CUDA GPUs are used with the C++ API.

**Workaround:**
As a temporary solution, one may create a symbolic link from the CUDA path, nonetheless modifying system should not be a permanent solution.
```bash
mkdir -p /usr/local/lib/python3.6/dist-packages/tensorflow/include/third_party/gpus/cuda/
ln -s /usr/local/cuda/include /usr/local/lib/python3.6/dist-packages/tensorflow/include/third_party/gpus/cuda/
ls /usr/local/lib/python3.6/dist-packages/tensorflow/include/third_party/gpus/cuda/include
```

**Solution:**
Instead of:
```cpp
#include ""third_party/gpus/cuda/include/cuComplex.h""
#include ""third_party/gpus/cuda/include/cuda.h""
```

Please do:
```cpp
#include ""cuda/include/cuComplex.h""
#include ""cuda/include/cuda.h""
```"
34427,Segfaults and SIGABRTs on nightlies since 2019-11-19,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): ('v1.12.1-18736-g229a46c', '2.1.0-dev20191119')
- Python version: Python 2.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

TensorFlow version `tf-nightly==2.1.0.dev20191119` experiences core
dumps on some simple summary operations. I can’t reproduce this on my
normal workstation, but I have a consistent repro on a Cloud VM (which
does not have Cuda installed; maybe relevant?).

Repro steps:

Create a new virtual machine running Ubuntu 14.04:
<https://console.cloud.google.com/compute/instancesDeploySolution?solution=ubuntu-os-cloud:ubuntu-trusty>

Prepare the system:

```
sudo apt install python-pip python-virtualenv python3.5
```

Create a virtualenv:

```
virtualenv -p python2.7 ./ve &&
. ./ve/bin/activate &&
pip install -U pip setuptools &&
pip install tf-nightly==2.1.0.dev20191119 &&
:
```

Attempt to reproduce the failure:

```
python -c '__import__(""tensorboard"").summary.scalar(""test"", 1)'
```

About half the time, the last command will SIGABRT. On Python 2.7, the message is:

```
(ve)wchargin@trusty-travis-debug-37:~$ python -c '__import__(""tensorboard"").summary.scalar(""test"", 1)'
2019-11-19 21:08:01.525309: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2019-11-19 21:08:01.525350: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-19 21:08:01.525377: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (trusty-travis-debug-37): /proc/driver/nvidia/version does not exist
2019-11-19 21:08:01.525707: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-19 21:08:01.534370: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz
2019-11-19 21:08:01.535487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x526b010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-19 21:08:01.535515: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
*** Error in `python': free(): invalid pointer: 0x0000000001ecaad0 ***
Aborted (core dumped)
```

On Python 3.5, the log is:

```
(ve3.5a)wchargin@trusty-travis-debug-37:~$ python -c '__import__(""tensorboard"").summary.scalar(""test"", 1)'
2019-11-19 21:06:03.550539: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2019-11-19 21:06:03.550578: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-19 21:06:03.550601: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (trusty-travis-debug-37): /proc/driver/nvidia/version does not exist
2019-11-19 21:06:03.550931: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-19 21:06:03.559645: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz
2019-11-19 21:06:03.560529: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a31d20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-19 21:06:03.560558: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
*** Error in `python': corrupted size vs. prev_size: 0x0000000001572680 ***
Aborted (core dumped)
```

Note that though this code is invoked through TensorBoard APIs, the
error is actually in TensorFlow (TensorBoard does not have any C++ code
of its own), and the TensorBoard nightlies did not change substantially
between the last good nightly and the current broken nightly.
Downgrading TensorBoard to nightly `tb-nightly==2.1.0a20191118` or to
stable `tensorboard==2.0.1` does not fix the problem.

If you instead install the following dependencies—

<details>
<summary>`pip freeze` output; install with `pip install -r requirements.txt`</summary>

```
absl-py==0.8.1
astor==0.8.0
attrs==17.3.0
aws-xray-sdk==0.95
backports.ssl-match-hostname==3.7.0.1
backports.tempfile==1.0
backports.weakref==1.0.post1
boto==2.49.0
boto3==1.9.86
botocore==1.12.253
cachetools==3.1.1
certifi==2019.9.11
cffi==1.13.2
chardet==3.0.4
configparser==4.0.2
cookies==2.2.1
cryptography==2.8
docker==4.1.0
docutils==0.15.2
ecdsa==0.14.1
entrypoints==0.3
enum34==1.1.6
flake8==3.7.8
funcsigs==1.0.2
functools32==3.2.3.post2
future==0.18.2
futures==3.3.0
gast==0.2.2
google-auth==1.7.1
google-auth-oauthlib==0.4.1
google-pasta==0.1.8
grpcio==1.25.0
grpcio-testing==1.24.3
h5py==2.10.0
idna==2.8
ipaddress==1.0.23
Jinja2==2.10.3
jmespath==0.9.4
jsondiff==1.1.1
jsonpickle==1.2
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
Markdown==3.1.1
MarkupSafe==1.1.1
mccabe==0.6.1
mock==3.0.5
moto==1.3.7
nose==1.3.7
numpy==1.16.5
oauthlib==3.1.0
opt-einsum==2.3.2
pathspec==0.6.0
pbr==3.1.1
pluggy==0.6.0
protobuf==3.10.0
py==1.5.2
pyaml==19.4.1
pyasn1==0.4.8
pyasn1-modules==0.2.7
pycodestyle==2.5.0
pycparser==2.19
pycryptodome==3.9.4
pyflakes==2.1.1
pytest==3.3.0
python-dateutil==2.8.1
python-jose==2.0.2
pytz==2019.3
PyYAML==5.1.2
requests==2.22.0
requests-oauthlib==1.3.0
responses==0.10.6
rsa==4.0
s3transfer==0.1.13
six==1.13.0
tb-nightly==2.1.0a20191119
termcolor==1.1.0
tf-estimator-nightly==2.0.0.dev2019111909
tf-nightly==2.1.0.dev20191119
typing==3.7.4.1
urllib3==1.25.7
websocket-client==0.56.0
Werkzeug==0.16.0
wrapt==1.11.2
xmltodict==0.12.0
yamllint==1.17.0
```

</details>

—then the following script consistently segfaults after completing each
command (except rarely when it SIGABRTs instead):


```
(ve2.7)wchargin@trusty-travis-debug-37:~$ cat scriptzz.py
import tensorboard as tb
tb.summary.v1.scalar_pb('test', 42)
tb.summary.scalar('test v2', 1337)
from tensorboard.plugins.beholder import Beholder, BeholderHook
print(""DONE"")
(ve2.7)wchargin@trusty-travis-debug-37:~$ python scriptzz.py
2019-11-19 21:26:36.188506: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2019-11-19 21:26:36.188546: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-19 21:26:36.188579: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (trusty-travis-debug-37): /proc/driver/nvidia/version does not exist
2019-11-19 21:26:36.188899: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-19 21:26:36.197595: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz
2019-11-19 21:26:36.198580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5df0030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-19 21:26:36.198617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
DONE
Segmentation fault (core dumped)
```

Example double-free/invalid-free in failed build log:
<https://travis-ci.com/tensorflow/tensorboard/jobs/258256205>

Example segfault in failed build log:
<https://travis-ci.com/tensorflow/tensorboard/jobs/258256206>

**Describe the expected behavior**

Running TensorFlow code should never SIGSEGV or SIGABRT.

**Code to reproduce the issue**

See above.

**Other info / logs**

This previously occurred with TensorFlow’s 20191024 nightlies:

```
pip: tb-nightly==2.1.0a20191024
pip: tf-nightly==2.1.0.dev20191024
python: tb.__version__ == 2.1.0a20191024
python: tf.__git_version__ == v1.12.1-16634-g0e90b26
python: tf.__version__ == 2.1.0-dev20191024
```

See <https://github.com/tensorflow/tensorboard/pull/2834> for context.

This is blocking TensorBoard CI. We’ll probably just pin yesterday’s
nightlies in the short term, but last time we did that (see above PR)
the underyling issue was evidently never actually resolved.
"
34426,"Error on distributed training "" Variable is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.""","I have this issue when I try to run distributed training with my own custom training loop. 

There is something going wrong when calling apply_gradient. 

**System information**
Test on Google Colab with GPU TF 2.0

**Code to reproduce the issue**
```
def model_builder():
    resnet = ResNet50(include_top=False, weights='imagenet')
    model = Sequential()
    model.add(resnet)
    
    model.add(Dense(100, activation=""softmax""))

    return model

def experiment_dist(model_builder, x_train, y_train, x_test, y_test):  
    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(64)
    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(64)
    
    mirrored_strategy = tf.distribute.MirroredStrategy()
    train_ds = mirrored_strategy.experimental_distribute_dataset(train_ds)
    test_ds = mirrored_strategy.experimental_distribute_dataset(test_ds)
   
    

    with mirrored_strategy.scope():

        test_loss = tf.keras.metrics.Mean(name='test_loss')

        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
            name='train_accuracy')
        test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
            name='test_accuracy')

        model = model_builder()
        # model = ResNet50(include_top=False, weights='imagenet')

        optimizer = tf.keras.optimizers.SGD()
        loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
            reduction=tf.keras.losses.Reduction.NONE)
        def train_step(inputs):
            x, y = inputs
            x = tf.dtypes.cast(x, tf.float32)
            with tf.GradientTape() as tape:
                predictions = model(x)
                loss = loss_object(y, predictions)
            gradients = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(gradients, model.trainable_variables))
            
            train_loss(loss)
            train_accuracy(y, predictions)

        def test_step(inputs) :
            x, y = inputs
            x = tf.dtypes.cast(x, tf.float32)

            predictions = model(x)
            t_loss = loss_object(y, predictions)

            test_loss(t_loss)
            test_accuracy(y, predictions)

        @tf.function
        def distributed_train_step(inputs):
            per_replica_losses = strategy.experimental_run_v2(train_step,
                                                            args=(inputs, ))
            return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,
                                axis=None)
        
        @tf.function
        def distributed_test_step(inputs):
            return strategy.experimental_run_v2(test_step, args=(inputs, ))            
    iter_count = 0
    MAX_ITER = 95000

    while True:
        print(""start"")
        for inputs in train_ds:
            print(""train_loop"")
            train_step(inputs)
            iter_count += 1
            if iter_count > MAX_ITER:
                break


        for test_images, test_labels in test_ds:
            images = tf.dtypes.cast(images, tf.float32)
            test_step(test_images, test_labels)

        template = 'Iteration {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'
        print(template.format(iter_count,
                                train_loss.result(),
                                train_accuracy.result()*100,
                                test_loss.result(),
                                test_accuracy.result()*100))

        # Reset the metrics for the next epoch
        train_loss.reset_states()
        train_accuracy.reset_states()
        test_loss.reset_states()
        test_accuracy.reset_states()

        if iter_count > MAX_ITER:
            break
    
experiment_dist(model_builder, x_train, y_train, x_test, y_test)
```


**Error Track**
```
WARNING:tensorflow:There is non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
start
train_loop
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-29-d2da1a38aa3a> in <module>()
----> 1 experiment_dist(model_builder, x_train, y_train, x_test, y_test)

14 frames
<ipython-input-28-357ae31bb355> in experiment_dist(model_builder, x_train, y_train, x_test, y_test)
     72         for inputs in train_ds:
     73             print(""train_loop"")
---> 74             train_step(inputs)
     75             iter_count += 1
     76             if iter_count > MAX_ITER:

<ipython-input-28-357ae31bb355> in train_step(inputs)
     40                 loss = loss_object(y, predictions)
     41             gradients = tape.gradient(loss, model.trainable_variables)
---> 42             optimizer.apply_gradients(zip(gradients, model.trainable_variables))
     43 
     44             train_loss(loss)

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in apply_gradients(self, grads_and_vars, name)
    439           functools.partial(self._distributed_apply, apply_state=apply_state),
    440           args=(grads_and_vars,),
--> 441           kwargs={""name"": name})
    442 
    443   def _distributed_apply(self, distribution, grads_and_vars, name, apply_state):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/distribute_lib.py in merge_call(self, merge_fn, args, kwargs)
   1915     if kwargs is None:
   1916       kwargs = {}
-> 1917     return self._merge_call(merge_fn, args, kwargs)
   1918 
   1919   def _merge_call(self, merge_fn, args, kwargs):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/distribute_lib.py in _merge_call(self, merge_fn, args, kwargs)
   1922         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access
   1923     try:
-> 1924       return merge_fn(self._strategy, *args, **kwargs)
   1925     finally:
   1926       _pop_per_thread_mode()

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in _distributed_apply(self, distribution, grads_and_vars, name, apply_state)
    483           update_ops.extend(
    484               distribution.extended.update(
--> 485                   var, apply_grad_to_update_var, args=(grad,), group=False))
    486 
    487       any_symbolic = any(isinstance(i, ops.Operation) or

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/distribute_lib.py in update(self, var, fn, args, kwargs, group)
   1528       kwargs = {}
   1529     with self._container_strategy().scope():
-> 1530       return self._update(var, fn, args, kwargs, group)
   1531 
   1532   def _update(self, var, fn, args, kwargs, group):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/distribute_lib.py in _update(self, var, fn, args, kwargs, group)
   2140     # The implementations of _update() and _update_non_slot() are identical
   2141     # except _update() passes `var` as the first argument to `fn()`.
-> 2142     return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)
   2143 
   2144   def _update_non_slot(self, colocate_with, fn, args, kwargs, should_group):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/distribute_lib.py in _update_non_slot(self, colocate_with, fn, args, kwargs, should_group)
   2146     # once that value is used for something.
   2147     with UpdateContext(colocate_with):
-> 2148       result = fn(*args, **kwargs)
   2149       if should_group:
   2150         return result

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in apply_grad_to_update_var(var, grad)
    465       if ""apply_state"" in self._dense_apply_args:
    466         apply_kwargs[""apply_state""] = apply_state
--> 467       update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
    468       if var.constraint is not None:
    469         with ops.control_dependencies([update_op]):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/optimizer_v2/gradient_descent.py in _resource_apply_dense(self, grad, var, apply_state)
    106 
    107   def _resource_apply_dense(self, grad, var, apply_state=None):
--> 108     var_device, var_dtype = var.device, var.dtype.base_dtype
    109     coefficients = ((apply_state or {}).get((var_device, var_dtype))
    110                     or self._fallback_apply_state(var_device, var_dtype))

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/values.py in device(self)
    735   @property
    736   def device(self):
--> 737     return self._get_closest().device
    738 
    739   @property

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/values.py in _get_closest(self)
    663     if device is None:
    664       device = device_util.canonicalize(device_util.current())
--> 665     replica_id = self._device_map.replica_for_device(device)
    666     if replica_id is None:
    667       return self.primary

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/values.py in replica_for_device(self, device)
    210 
    211   def replica_for_device(self, device):
--> 212     return self._device_to_replica.get(device)
    213 
    214   def select_for_device(self, values, device):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/variables.py in __hash__(self)
   1084   def __hash__(self):
   1085     if ops.Tensor._USE_EQUALITY and ops.executing_eagerly_outside_functions():  # pylint: disable=protected-access
-> 1086       raise TypeError(""Variable is unhashable if Tensor equality is enabled. ""
   1087                       ""Instead, use tensor.experimental_ref() as the key."")
   1088     else:

TypeError: Variable is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.
```"
34425,bazel build issue for tensorflow 2.0,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04 
- TensorFlow installed from source
- TensorFlow version 2.0.0
- Python version: 2.7.15+ and python 3.6.8
- Installed using pip
- Bazel version 1.1.0
- GCC/Compiler version : gcc 7.4.0
- CUDA/cuDNN version: CUDA Version 10.1.243,  cuDNN version 7.6.5
- CPU model and memory: Intel® Core™ i7-7700HQ CPU @ 2.80GHz × 8, 15.4GB
- GPU model and memory: GeForce GTX 1050 Ti/PCIe/SSE2, 4GB




**Describe the problem**
I try to do bazel build for tensorflow
when running this command $bazel build //tensorflow/tools/pip_package:build_pip_package
it give me these error:

```
ERROR: /home/linxiang/tensorflow/tensorflow/stream_executor/cuda/BUILD:198:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cublas_stub' failed (Exit 1)
In file included from tensorflow/stream_executor/cuda/cublas_stub.cc:66:0:
./tensorflow/stream_executor/cuda/cublas_10_1.inc:122:25: error: 'cublasLogCallback' was not declared in this scope
 cublasSetLoggerCallback(cublasLogCallback userCallback) {
                         ^~~~~~~~~~~~~~~~~
./tensorflow/stream_executor/cuda/cublas_10_1.inc:122:25: note: suggested alternative: 'cublasSetLoggerCallback'
 cublasSetLoggerCallback(cublasLogCallback userCallback) {
                         ^~~~~~~~~~~~~~~~~
                         cublasSetLoggerCallback
./tensorflow/stream_executor/cuda/cublas_10_1.inc:130:25: error: 'cublasLogCallback' was not declared in this scope
 cublasGetLoggerCallback(cublasLogCallback *userCallback) {
                         ^~~~~~~~~~~~~~~~~
./tensorflow/stream_executor/cuda/cublas_10_1.inc:130:25: note: suggested alternative: 'cublasGetLoggerCallback'
 cublasGetLoggerCallback(cublasLogCallback *userCallback) {
                         ^~~~~~~~~~~~~~~~~
                         cublasGetLoggerCallback
./tensorflow/stream_executor/cuda/cublas_10_1.inc:130:44: error: 'userCallback' was not declared in this scope
 cublasGetLoggerCallback(cublasLogCallback *userCallback) {
                                            ^~~~~~~~~~~~
./tensorflow/stream_executor/cuda/cublas_10_1.inc:130:44: note: suggested alternative: 'CUstreamCallback'
 cublasGetLoggerCallback(cublasLogCallback *userCallback) {
                                            ^~~~~~~~~~~~
                                            CUstreamCallback

```"
34424,Extremely slow pre-processing of images using InceptionV3,"**System information**
- OS Platform and Distribution: Google AI Platform
- TensorFlow version: v2.0
- Python version: v3.*
- Machine type: 4 vCPUs, 15 GB RAM
- GPU: 1x NVIDIA Tesla K80

I am training a model to caption images and have mostly used this tutorial: https://www.tensorflow.org/tutorials/text/image_captioning#download_and_prepare_the_ms-coco_dataset

The issue is, I am trying to pre-process each image with InceptionV3 and cache the output to disk, however, each iteration (code snippet below) takes about 22s without GPUs and 18s with NVIDIA Tesla K80. This is way too slow for 30,000+ images for example. 

My image file size ranges between 60-150kb each.

```
# Get unique images
encode_train = sorted(set(img_name_vector))

image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)
image_dataset = image_dataset.map(
  load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)

for img, path in image_dataset:
  batch_features = image_features_extract_model(img)
  batch_features = tf.reshape(batch_features,
                              (batch_features.shape[0], -1, batch_features.shape[3]))

  for bf, p in zip(batch_features, path):
    np.save(tf.io.gfile.GFile(IMG_PATH, 'w'), bf.numpy())
```

The tensorflow tutorial claims that caching will take about 10 minutes to run in Colab with a GPU (for 30,000 images).

I wonder if I am doing something wrong, or if there is a more efficient way to achieve this?

Any help is appreciated!
"
34423,Issue in building TFLITE static library for linux environment ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution 
Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): v1.15.0-rc-2
- Python version: 3.6
- Installed using virtualenv? pip? conda?: From source
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): gcc5.5
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
Cannot compile static library for TFLITE inference engine using the provided Makefile. When run, generated_scheme.h will not be link with flatbuffers/flatbuffers.h and will flag variable not declared in this scope for everything 
**Provide the exact sequence of commands / steps that you executed before running into the problem**
git clone https://github.com/tensorflow/tensorflow.git
git checkout tags/v1.15.0-rc-2
cd tensorflow
./tensorflow/lite/tools/make/download_dependencies.sh 
 ./tensorflow/lite/tools/make/build_lib.sh

**Any other info / logs**

"
34418,TensorFlow-gpu 2.0 - Forward features in estimators prediction output,"
**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**

In tensorflow-gpu 1.14, we were passing the ID key(s) as a forward feature so that it appears in prediction outputs

estimator = tf.contrib.estimator.forward_features(
        estimator,
        keys=[
            feature_forward_key.name
            for feature_forward_key in metadata.FEATURE_FORWARD_KEYS
        ])

On migrating the code to Tensorflow-gpu 2.0, tf.contrib package is removed and we couldn't find forward-features functionality in tensorflow core for an estimator.

**Will this change the current api? How?** No

**Who will benefit with this feature?** Everyone

**Any Other info.**
"
34417,Have the count mode passed to the callbacks,"**System information**
- TensorFlow version: 2.0.0
- Are you willing to contribute it: Yes



**Describe the feature and the current behavior/state.**
Right now when training on a generator (I don't know about the other cases), when the callbacks are configured, the number of samples passed in might actually be the number of steps (i.e. divided by batch size). To cope with that for the progress bar, a `count_mode` variable is used to know how to update it.

I would like the `count_mode` variable to also be passed to the callbacks in order for them to also adapt their behaviour based on it.

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
The [`keras-tqdm`](https://github.com/bstriner/keras-tqdm) library is currently [not working properly because of that lack](https://github.com/bstriner/keras-tqdm/issues/37). It could implement a new way to deal with the count, once this variable is provided in the callbacks parameters.
"
34416,Error trying to convert a model using full integer quantization,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04.3:
- TensorFlow installed from source: pip3 install --upgrade tensorflow==1.15
- TensorFlow version: 1.15


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, SOFTMAX. Here is a list of operators for which you will need custom implementations: IdentityN.
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, SOFTMAX. Here is a list of operators for which you will need custom implementations: IdentityN.
```

**Model:**
```
import pathlib

import tensorflow as tf


mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  # tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)

model.evaluate(x_test,  y_test, verbose=2)


# Save the model into SaveModel format

saved_model_dir = pathlib.Path(""./saved_model/"")
tf.saved_model.save(model, str(saved_model_dir))
```

**Convert the model:**
```
import pathlib

import tensorflow as tf


mnist = tf.keras.datasets.mnist
x_train = mnist.load_data()[0][0] / 255.0

saved_model_dir = pathlib.Path(""./saved_model/"")


# Convert the model from saved model

images = tf.cast(x_train, tf.float32)
mnist_ds = tf.data.Dataset.from_tensor_slices(images).batch(1)


def representative_dataset_gen():
    for input_value in mnist_ds.take(100):
        yield [input_value]


converter = tf.lite.TFLiteConverter.from_saved_model(str(saved_model_dir))
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.representative_dataset = representative_dataset_gen

tflite_quant_model = converter.convert()

tflite_quant_model_file = saved_model_dir/""mnist_post_quant_model_io.tflite""
tflite_quant_model_file.write_bytes(tflite_quant_model)
```

**Any other info / logs**

```
/usr/bin/python3.6 /home/mapeima/Code/python/edgeTPU/model_converter.py
2019-11-19 13:34:02.791346: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2019-11-19 13:34:02.791364: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-19 13:34:02.791397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jihr): /proc/driver/nvidia/version does not exist
2019-11-19 13:34:02.791614: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-19 13:34:02.814669: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2712000000 Hz
2019-11-19 13:34:02.815094: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3b64140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-19 13:34:02.815124: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
2019-11-19 13:34:02.937627: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2019-11-19 13:34:02.937702: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-19 13:34:02.948371: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize
2019-11-19 13:34:02.948393: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: Graph size after: 189 nodes (144), 355 edges (290), time = 4.452ms.
2019-11-19 13:34:02.948398: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.08ms.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py:854: UserWarning: Property target_ops is deprecated, please use target_spec.supported_ops instead.
  ""target_spec.supported_ops instead."" % name)
2019-11-19 13:34:02.971121: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2019-11-19 13:34:02.971187: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-19 13:34:02.977074: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize
2019-11-19 13:34:02.977098: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 34 nodes (-8), 57 edges (-12), time = 3.248ms.
2019-11-19 13:34:02.977102: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 34 nodes (0), 57 edges (0), time = 0.73ms.
Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Use '@tf.function' or '@defun' to decorate the function.Traceback (most recent call last):
  File ""/home/mapeima/Code/python/edgeTPU/model_converter.py"", line 30, in <module>
    tflite_quant_model = converter.convert()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py"", line 983, in convert
    **converter_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2019-11-19 13:34:04.120420: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: IdentityN
2019-11-19 13:34:04.120589: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 17 operators, 26 arrays (0 quantized)
2019-11-19 13:34:04.120707: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 17 operators, 26 arrays (0 quantized)
2019-11-19 13:34:04.120849: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 6 operators, 12 arrays (0 quantized)
2019-11-19 13:34:04.121155: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 5 operators, 11 arrays (0 quantized)
2019-11-19 13:34:04.121196: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 4 operators, 9 arrays (0 quantized)
2019-11-19 13:34:04.121224: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 4 operators, 9 arrays (0 quantized)
2019-11-19 13:34:04.121241: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 4 operators, 9 arrays (0 quantized)
2019-11-19 13:34:04.121273: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 576 bytes, theoretical optimal value: 576 bytes.
2019-11-19 13:34:04.121289: I tensorflow/lite/toco/toco_tooling.cc:439] Estimated count of arithmetic ops: 204042 ops, equivalently 102021 MACs
2019-11-19 13:34:04.121293: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 101770
2019-11-19 13:34:04.121470: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, SOFTMAX. Here is a list of operators for which you will need custom implementations: IdentityN.
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, SOFTMAX. Here is a list of operators for which you will need custom implementations: IdentityN.




Process finished with exit code 1
```
"
34415,How to limit the cpu core number in Tensorflow 2.0,"I am using tf.keras to train a model with cpu and I want to limit the cpu usage of this program. I found this article(https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/43383):

```
from keras import backend as K
import tensorflow as tf

config = tf.ConfigProto(intra_op_parallelism_threads=args.jobs, \ 
                        inter_op_parallelism_threads=args.jobs, \
                        allow_soft_placement=True, \
                        device_count = {'CPU': args.jobs})
session = tf.Session(config=config)
K.set_session(session)
```

But in Tensorflow 2.0, ConfigProto is deprecated and Session is gone. What's the correct method to limit cpu usage?"
34413,tf.12 to tf2.0,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

```
def compile(self, learning_rate, momentum):
    """"""Gets the model ready for training. Adds losses, regularization, and
    metrics. Then calls the Keras compile() function.
    """"""
    # Optimizer object
    optimizer = keras.optimizers.SGD(
        lr=learning_rate, momentum=momentum,
        clipnorm=self.config.GRADIENT_CLIP_NORM)
    # Add Losses
    # First, clear previously set losses to avoid duplication
    self.keras_model._losses = []
    self.keras_model._per_input_losses = {}
    loss_names = [
        ""rpn_class_loss"",  ""rpn_bbox_loss"",
        ""mrcnn_class_loss"", ""mrcnn_bbox_loss"", ""mrcnn_mask_loss""]
    for name in loss_names:
        layer = self.keras_model.get_layer(name)
        if layer.output in self.keras_model.losses:
            continue
        loss = (
            tf.reduce_mean(layer.output, keepdims=True)
            * self.config.LOSS_WEIGHTS.get(name, 1.))
        self.keras_model.add_loss(loss)

    # Add L2 Regularization
    # Skip gamma and beta weights of batch normalization layers.
    reg_losses = [
        keras.regularizers.l2(self.config.WEIGHT_DECAY)(w) / tf.cast(tf.size(w), tf.float32)
        for w in self.keras_model.trainable_weights
        if 'gamma' not in w.name and 'beta' not in w.name]
    self.keras_model.add_loss(tf.add_n(reg_losses))

    # Compile
    self.keras_model.compile(
        optimizer=optimizer,
        loss=[None] * len(self.keras_model.outputs))

    # Add metrics for losses
    for name in loss_names:
        if name in self.keras_model.metrics_names:
            continue
        layer = self.keras_model.get_layer(name)
        self.keras_model.metrics_names.append(name)
        loss = (
            tf.reduce_mean(layer.output, keepdims=True)
            * self.config.LOSS_WEIGHTS.get(name, 1.))
        self.keras_model.metrics_tensors.append(loss)
```
This code works in tensorflow1.12 with tf.keras, while it does not work in tensorflow 2.0 with tf.keras, where should i change ?  When i turn off eager mode by using `tf.compat.v1.disable_eager_execution()`, it can start to train while there is only loss displayed (without ""rpn_class_loss"",  ""rpn_bbox_loss"", ""mrcnn_class_loss"", ""mrcnn_bbox_loss"", ""mrcnn_mask_loss"").

 In eager mode, it raises error using a tf.Tensor as a Python bool is not allowed in Graph execution in `        if layer.output in self.keras_model.losses:
            continue` ; x and y must have the same dtype, got tf.float64!=tf.float32 in `    reg_losses = [
        keras.regularizers.l2(self.config.WEIGHT_DECAY)(w) / tf.cast(tf.size(w), tf.float32)
        for w in self.keras_model.trainable_weights
        if 'gamma' not in w.name and 'beta' not in w.name]`, If i delete those lines, it would have error No gradients provided for any variable."
34410,How to limit tensorflow CPU and memory usage in c_api?,"**In python:**
`sess = tf.Session(config=
    tf.ConfigProto(inter_op_parallelism_threads=1,
                   intra_op_parallelism_threads=1))`
**c_api:**
How?"
34409,C++ compilation of rule '//tensorflow/cc:cc_op_gen_main' failed (Ex it 1),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
  CentOS 6.10
- TensorFlow installed from (source or binary):
  source
- TensorFlow version:
  Branch r2.0
- Python version:
 3.7.5
- Bazel version (if compiling from source):
  0.26.1
- GCC/Compiler version (if compiling from source):
 gcc version 4.9.1 20140922 (Red Hat 4.9.1-10) (GCC)
- CUDA/cuDNN version:
  CUDA 10.1  cuDNN 7.6.5
- GPU model and memory:
  Tesla P4 8G

**Describe the problem**
  While building TensorFlow from r2.0 branch the build fails.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
  ``` bash
  bazel build --config=opt --config=cuda --config=nonccl --verbose_failures //tensorflow/tools/pip_package:build_pip_package
 ```

**Any other info / logs**

**configure output**
```
WARNING: Running Bazel server needs to be killed, because the startup options are different.
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
You have bazel 0.26.1 installed.
Please specify the location of python. [Default is /usr/local/bin/python3]: 


Found possible Python library paths:
  /usr/local/python3/lib/python3.7/site-packages
Please input the desired Python library path to use.  Default is [/usr/local/python3/lib/python3.7/site-packages]

Do you wish to build TensorFlow with XLA JIT support? [Y/n]: Y
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: N
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: Y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: N
No TensorRT support will be enabled for TensorFlow.

Found CUDA 10.1 in:
    /usr/local/cuda/lib64
    /usr/local/cuda/include
Found cuDNN 7 in:
    /usr/local/cuda/lib64
    /usr/local/cuda/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1]: 


Do you want to use clang as CUDA compiler? [y/N]: N
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /opt/rh/devtoolset-3/root/usr/bin/gcc]: 


Do you wish to build TensorFlow with MPI support? [y/N]: N
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=gdr            # Build with GDR support.
        --config=verbs          # Build with libverbs support.
        --config=ngraph         # Build with Intel nGraph support.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=noignite       # Disable Apache Ignite support.
        --config=nokafka        # Disable Apache Kafka support.
        --config=nonccl         # Disable NVIDIA NCCL support.
```

**build output**
```
ERROR: /root/tensorflow/tensorflow/cc/BUILD:636:1: C++ compilation of rule '//tensorflow/cc:cc_op_gen_main' failed (Ex
it 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/opt/rh/devtoolset-3/root/usr/lib64:/opt/rh/devtoolset-3/root/usr/lib:/usr/local/cuda-10.1/lib64 \
    PATH=/usr/local/python3/bin/:/usr/local/git/bin:/opt/rh/devtoolset-3/root/usr/bin:/usr/lib/jvm/jdk1.8.0_212/bin:/u
sr/local/bin:/usr/local/cuda-10.1/bin:/usr/local/cuda-10.1/NsightCompute-2019.1:/usr/local/openresty/nginx/sbin:/usr/l
ocal/php/bin:/usr/local/openssl/bin:/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/root/bin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/cc/_objs/cc_op_gen_main/cc_op_gen_main.d '-frandom-seed=bazel-out/host/bin/tensorflow/cc/_objs/cc_op_gen_main/cc_op_gen_main.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/com_google_protobuf -iquote bazel-out/host/bin/external/com_google_protobuf -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -iquote external/local_config_tensorrt -iquote bazel-out/host/bin/external/local_config_tensorrt -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/host/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/gif_archive -isystem bazel-out/host/bin/external/gif_archive -isystem external/com_google_protobuf/src -isystem bazel-out/host/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIE -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-DGOOGLE_CUDA=1' -msse3 -pthread -c tensorflow/cc/framework/cc_op_gen_main.cc -o bazel-out/host/bin/tensorflow/cc/_objs/cc_op_gen_main/cc_op_gen_main.o)
Execution platform: @bazel_tools//platforms:host_platform
In file included from tensorflow/cc/framework/cc_op_gen_main.cc:21:0:
./tensorflow/core/lib/io/path.h: In instantiation of 'std::string tensorflow::io::JoinPath(const T& ...) [with T = {st
d::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::basic_string<char, std::char_traits<char>, 
std::allocator<char> >}; std::string = std::basic_string<char>]':
tensorflow/cc/framework/cc_op_gen_main.cc:42:72:   required from here
./tensorflow/core/lib/io/path.h:47:42: error: could not convert '{args#0, args#1}' from '<brace-enclosed initializer l
ist>' to 'std::initializer_list<absl::string_view>'
   return internal::JoinPathImpl({args...});
                                          ^
./tensorflow/core/lib/io/path.h: In function 'std::string tensorflow::io::JoinPath(const T& ...) [with T = {std::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::basic_string<char, std::char_traits<char>, std::allocator<char> >}; std::string = std::basic_string<char>]':
./tensorflow/core/lib/io/path.h:48:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 27.597s, Critical Path: 19.68s
INFO: 145 processes: 145 local.
FAILED: Build did NOT complete successfully
```"
34408,tensorflow.python.keras.testing_utils.layer_test breaks when a (custom) layer is returning a list/tuple of tensor ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): gLinux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip3 installed
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6

**Describe the current behavior**
When we create a custom `tensorflow.keras.layer.Layer`, said `MyCustomLayer`, that returns a list/tuple of tensors in it's `call` method, calling `layer_test(MyCustomLayer, input_shape=expected_input_shape)` will break as `layer_test` does not expect list / tuple as outputs of the custom layer's `call` method, and by tensorflow's keras layer documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call), list / tuple of tensors are valid output. 

**Code to reproduce the issue**

```python
import tensorflow as tf
from tensorflow.python.keras.testing_utils import layer_test

# a dummy layer that just returns a list of input
class MyCustomLayer(tf.keras.layers.Layer):
  def call(self, input):
    return [input, input]

layer_test(MyCustomLayer, input_shape=(1,2))
```

**Describe the expected behavior**
The expected behavior is that the above snippet will not return errors (log attached below)

Potential Solution: Check the input `x` in `dtype()` method in `tensorflow_core/python/keras/backend.py`.

Happy to contribute if this is helpful :)

**Other info / logs**

Error Log:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-9-0eea06e136e5> in <module>()
----> 1 layer_test(MyCustomLayer, input_shape=(1,2))

2 frames
/tensorflow-2.0.0/python3.6/tensorflow_core/python/framework/test_util.py in decorated(self, *args, **kwargs)
   1583       original_var = os.environ.get(""TF_CUDNN_DETERMINISTIC"", """")
   1584       os.environ[""TF_CUDNN_DETERMINISTIC""] = ""true""
-> 1585       result = f(self, *args, **kwargs)
   1586       os.environ[""TF_CUDNN_DETERMINISTIC""] = original_var
   1587       return result

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/testing_utils.py in layer_test(layer_cls, kwargs, input_shape, input_dtype, input_data, expected_output, expected_output_dtype, expected_output_shape, validate_training, adapt_data)
    140   x = keras.layers.Input(shape=input_shape[1:], dtype=input_dtype)
    141   y = layer(x)
--> 142   if keras.backend.dtype(y) != expected_output_dtype:
    143     raise AssertionError('When testing layer %s, for input %s, found output '
    144                          'dtype=%s but expected to find %s.\nFull kwargs: %s' %

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/backend.py in dtype(x)
   1247   ```
   1248   """"""
-> 1249   return x.dtype.base_dtype.name
   1250 
   1251 

AttributeError: 'list' object has no attribute 'dtype'
```
"
34407,How to access the context menu in pywinauto,"Hello All,

I could not able to access the menus(tool bars in the left side of an application). Can you please help how to acsess thos menus using pywinauto ?
I could not able to attach the screenshot because of some issue in the attachment process.


Thanks in Advance!!


"
34406,Mixed precision training with tf.keras 2.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.0.0
- Python version: 3.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: V100

**Describe the current behavior**

I am trying to incorporate mixed-precision training in my `tf.keras` models. After going through [the instructions on the NVIDIA docs](https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html), I used the following code snippet (full code is provided in the end):

```python
opt = tf.keras.optimizers.Adam()
opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)
model.compile(loss=loss, optimizer=opt)
model.fit(...)
```
I do not see any speed up after mixed precision is enabled. I tried out `tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, ""dynamic"")`. Still there is no significant improvement to note. On the other hand, I tried to experiment with `tf.keras.mixed_precision.experimental.set_policy('mixed_float16')` but I am kind of confused about how to appropriately use it. I am trying to train the following model on the FashionMNIST dataset:

```python
tf.keras.mixed_precision.experimental.set_policy('mixed_float16')
model = Sequential([
            Input((28,28,1)),
            Conv2D(32, (3, 3), activation='relu'),
            MaxPooling2D((2,2)),
            Conv2D(64, (3, 3), activation='relu'),
            MaxPooling2D((2,2)),
            Conv2D(64, (3, 3), activation='relu'),
            GlobalAveragePooling2D(),
            Dense(64, activation='relu'),
            Dense(10, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
```

But when I call `model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=128)`, I get the following:

```
/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    561                   ""%s type %s of argument '%s'."" %
    562                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
--> 563                    inferred_from[input_arg.type_attr]))
    564 
    565           types = [values.dtype]

TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.
```

The entire error trace is there in the attached notebook. The second experiment in this line I did was with `policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')`. In that, I just set the `dtype` of the penultimate dense layer (of the above-mentioned model) to `policy`. The works fine but throws this warning:

```
WARNING:tensorflow:Layer dense_1 is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.
```

Any recommended way of using these policies along with simple and more complex models? 

**Describe the expected behavior**

**Code to reproduce the issue**
[Mixed Precision Training in tf.keras 2.0.zip](https://github.com/tensorflow/tensorflow/files/3862764/Mixed.Precision.Training.in.tf.keras.2.0.zip)

"
34405,tf.keras.utils.get_file error in Extracting .zip format,"Hi, 
**Issue**: tf.keras.utils.get_filecannot extract .zip file and returns a list
Basicallly I have to convert the entire data set into tar.gz format since for some reason the above module is unable to extract the .zip folder. Another bug is that the .tar folder name and the fname have to be compulsorily same as per present module. I hope these two issues get fixed by the Tensorflow community :)
Any help will be appreciate...
Thanks in Advance..."
34404, Distributed training resnet50 using 4 nodes 32  TeslaV100 cards,"
I checked a lot of literature, but I didn't find the results. The questions are as follows:
How many hours can it converge？（Distributed training resnet50 using 4 nodes 32 TeslaV100 cards）

Do you have internal test results that can be displayed to better understand the performance of your distributed training."
34401,"Building from source ""undefined reference to `cublasGemmStridedBatchedEx' ""","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source 
- TensorFlow version:1.15
- Python version:3.5.12
- Installed using virtualenv? pip? conda?: pip install
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): GCC-5.4.0
- CUDA/cuDNN version: CUDA 9.1.85 cuDNN 7.0.5
- GPU model and memory: Tesla M4 4Gb



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
You have bazel 0.29.1- (@non-git) installed.
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python


Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.5/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]
/usr/local/lib/python3.5/dist-packages
Do you wish to build TensorFlow with XLA JIT support? [Y/n]: y
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: n
No TensorRT support will be enabled for TensorFlow.

Found CUDA 9.1 in:
    /usr/local/cuda/lib64
    /usr/local/cuda/include
Found cuDNN 7 in:
    /usr/local/cuda/lib64
    /usr/local/cuda/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 5.2]: 5.2


Do you want to use clang as CUDA compiler? [y/N]: n
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=ngraph         # Build with Intel nGraph support.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=nonccl         # Disable NVIDIA NCCL support.
Configuration finished

$bazel build --verbose_failures --action_env=LD_LIBRARY_PATH=/usr/local/cuda/lib64 --config=cuda --config=opt //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --config=nonccl --config=nohdfs --config=mkl --config=monolithic --config=noaws --config=nogcp --config=monolithic

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

ERROR: /home/tensorflow/tensorflow/tensorflow/lite/toco/BUILD:439:1: Linking of rule '//tensorflow/lite/toco:toco' failed (Exit 1)
[19,054 / 21,282] 46 actions running
    Compiling tensorflow/core/kernels/slice_op_gpu.cu.cc [for host]; 181s local
    Compiling tensorflow/core/kernels/pad_op_gpu.cu.cc [for host]; 154s local
    Compiling tensorflow/core/kernels/tile_functor_cpu.cc [for host]; 123s local
    Compiling tensorflow/core/kernels/resource_variable_ops.cc [for host]; 106s local
    Compiling tensorflow/core/kernels/conv_ops_fused_float.cc [for host]; 94s local
    Compiling tensorflow/core/kernels/conv_ops_fused_double.cc [for host]; 91s local
    Compiling tensorflow/core/kernels/conv_ops.cc [for host]; 91s local
    Compiling tensorflow/core/kernels/conv_grad_ops_3d.cc [for host]; 90s local ...
bazel-out/host/bin/tensorflow/stream_executor/cuda/libcublas_plugin.lo(cuda_blas.o): In function `tensorflow::Status stream_executor::gpu::CUDABlas::DoBlasGemmBatchedInternal<Eigen::half, float, cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, float const*, float const**, int, float const**, int, float const*, float**, int, int)>(cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, float const*, float const**, int, float const**, int, float const*, float**, int, int), stream_executor::Stream*, stream_executor::blas::Transpose, stream_executor::blas::Transpose, unsigned long long, unsigned long long, unsigned long long, float, absl::Span<stream_executor::DeviceMemory<Eigen::half>* const> const&, int, absl::Span<stream_executor::DeviceMemory<Eigen::half>* const> const&, int, float, absl::Span<stream_executor::DeviceMemory<Eigen::half>* const> const&, int, int, stream_executor::ScratchAllocator*)':
cuda_blas.cc:(.text._ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalIN5Eigen4halfEfPF14cublasStatus_tP13cublasContext17cublasOperation_tS8_iiiPKfPSA_iSB_iSA_PPfiiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESM_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSX_iSN_SX_iiPNS_16ScratchAllocatorE[_ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalIN5Eigen4halfEfPF14cublasStatus_tP13cublasContext17cublasOperation_tS8_iiiPKfPSA_iSB_iSA_PPfiiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESM_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSX_iSN_SX_iiPNS_16ScratchAllocatorE]+0x8c2): undefined reference to `cublasGemmBatchedEx'
bazel-out/host/bin/tensorflow/stream_executor/cuda/libcublas_plugin.lo(cuda_blas.o): In function `tensorflow::Status stream_executor::gpu::CUDABlas::DoBlasGemmBatchedInternal<float, float, cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, float const*, float const**, int, float const**, int, float const*, float**, int, int)>(cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, float const*, float const**, int, float const**, int, float const*, float**, int, int), stream_executor::Stream*, stream_executor::blas::Transpose, stream_executor::blas::Transpose, unsigned long long, unsigned long long, unsigned long long, float, absl::Span<stream_executor::DeviceMemory<float>* const> const&, int, absl::Span<stream_executor::DeviceMemory<float>* const> const&, int, float, absl::Span<stream_executor::DeviceMemory<float>* const> const&, int, int, stream_executor::ScratchAllocator*)':
cuda_blas.cc:(.text._ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalIffPF14cublasStatus_tP13cublasContext17cublasOperation_tS6_iiiPKfPS8_iS9_iS8_PPfiiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESK_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSV_iSL_SV_iiPNS_16ScratchAllocatorE[_ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalIffPF14cublasStatus_tP13cublasContext17cublasOperation_tS6_iiiPKfPS8_iS9_iS8_PPfiiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESK_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSV_iSL_SV_iiPNS_16ScratchAllocatorE]+0x9c7): undefined reference to `cublasGemmBatchedEx'
bazel-out/host/bin/tensorflow/stream_executor/cuda/libcublas_plugin.lo(cuda_blas.o): In function `tensorflow::Status stream_executor::gpu::CUDABlas::DoBlasGemmBatchedInternal<double, double, cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, double const*, double const**, int, double const**, int, double const*, double**, int, int)>(cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, double const*, double const**, int, double const**, int, double const*, double**, int, int), stream_executor::Stream*, stream_executor::blas::Transpose, stream_executor::blas::Transpose, unsigned long long, unsigned long long, unsigned long long, double, absl::Span<stream_executor::DeviceMemory<double>* const> const&, int, absl::Span<stream_executor::DeviceMemory<double>* const> const&, int, double, absl::Span<stream_executor::DeviceMemory<double>* const> const&, int, int, stream_executor::ScratchAllocator*)':
cuda_blas.cc:(.text._ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalIddPF14cublasStatus_tP13cublasContext17cublasOperation_tS6_iiiPKdPS8_iS9_iS8_PPdiiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESK_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSV_iSL_SV_iiPNS_16ScratchAllocatorE[_ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalIddPF14cublasStatus_tP13cublasContext17cublasOperation_tS6_iiiPKdPS8_iS9_iS8_PPdiiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESK_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSV_iSL_SV_iiPNS_16ScratchAllocatorE]+0xceb): undefined reference to `cublasGemmBatchedEx'
bazel-out/host/bin/tensorflow/stream_executor/cuda/libcublas_plugin.lo(cuda_blas.o): In function `tensorflow::Status stream_executor::gpu::CUDABlas::DoBlasGemmBatchedInternal<std::complex<float>, std::complex<float>, cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, float2 const*, float2 const**, int, float2 const**, int, float2 const*, float2**, int, int)>(cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, float2 const*, float2 const**, int, float2 const**, int, float2 const*, float2**, int, int), stream_executor::Stream*, stream_executor::blas::Transpose, stream_executor::blas::Transpose, unsigned long long, unsigned long long, unsigned long long, std::complex<float>, absl::Span<stream_executor::DeviceMemory<std::complex<float> >* const> const&, int, absl::Span<stream_executor::DeviceMemory<std::complex<float> >* const> const&, int, std::complex<float>, absl::Span<stream_executor::DeviceMemory<std::complex<float> >* const> const&, int, int, stream_executor::ScratchAllocator*)':
cuda_blas.cc:(.text._ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalISt7complexIfES4_PF14cublasStatus_tP13cublasContext17cublasOperation_tS8_iiiPK6float2PSB_iSC_iSB_PPS9_iiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESN_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSY_iSO_SY_iiPNS_16ScratchAllocatorE[_ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalISt7complexIfES4_PF14cublasStatus_tP13cublasContext17cublasOperation_tS8_iiiPK6float2PSB_iSC_iSB_PPS9_iiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESN_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSY_iSO_SY_iiPNS_16ScratchAllocatorE]+0xd2b): undefined reference to `cublasGemmBatchedEx'
bazel-out/host/bin/tensorflow/stream_executor/cuda/libcublas_plugin.lo(cuda_blas.o): In function `tensorflow::Status stream_executor::gpu::CUDABlas::DoBlasGemmBatchedInternal<std::complex<double>, std::complex<double>, cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, double2 const*, double2 const**, int, double2 const**, int, double2 const*, double2**, int, int)>(cublasStatus_t (*)(cublasContext*, cublasOperation_t, cublasOperation_t, int, int, int, double2 const*, double2 const**, int, double2 const**, int, double2 const*, double2**, int, int), stream_executor::Stream*, stream_executor::blas::Transpose, stream_executor::blas::Transpose, unsigned long long, unsigned long long, unsigned long long, std::complex<double>, absl::Span<stream_executor::DeviceMemory<std::complex<double> >* const> const&, int, absl::Span<stream_executor::DeviceMemory<std::complex<double> >* const> const&, int, std::complex<double>, absl::Span<stream_executor::DeviceMemory<std::complex<double> >* const> const&, int, int, stream_executor::ScratchAllocator*)':
cuda_blas.cc:(.text._ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalISt7complexIdES4_PF14cublasStatus_tP13cublasContext17cublasOperation_tS8_iiiPK7double2PSB_iSC_iSB_PPS9_iiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESN_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSY_iSO_SY_iiPNS_16ScratchAllocatorE[_ZN15stream_executor3gpu8CUDABlas25DoBlasGemmBatchedInternalISt7complexIdES4_PF14cublasStatus_tP13cublasContext17cublasOperation_tS8_iiiPK7double2PSB_iSC_iSB_PPS9_iiEEEN10tensorflow6StatusET1_PNS_6StreamENS_4blas9TransposeESN_yyyT0_RKN4absl4SpanIKPNS_12DeviceMemoryIT_EEEEiSY_iSO_SY_iiPNS_16ScratchAllocatorE]+0xcfb): undefined reference to `cublasGemmBatchedEx'
bazel-out/host/bin/tensorflow/stream_executor/cuda/libcublas_plugin.lo(cuda_blas.o): In function `stream_executor::gpu::CUDABlas::DoBlasGemmStridedBatched(stream_executor::Stream*, stream_executor::blas::Transpose, stream_executor::blas::Transpose, unsigned long long, unsigned long long, unsigned long long, float, stream_executor::DeviceMemory<Eigen::half> const&, int, long long, stream_executor::DeviceMemory<Eigen::half> const&, int, long long, float, stream_executor::DeviceMemory<Eigen::half>*, int, long long, int)':
cuda_blas.cc:(.text._ZN15stream_executor3gpu8CUDABlas24DoBlasGemmStridedBatchedEPNS_6StreamENS_4blas9TransposeES5_yyyfRKNS_12DeviceMemoryIN5Eigen4halfEEEixSB_ixfPS9_ixi+0x2e3): undefined reference to `cublasGemmStridedBatchedEx'
collect2: error: ld returned 1 exit status
[19,054 / 21,282] 46 actions running
    Compiling tensorflow/core/kernels/slice_op_gpu.cu.cc [for host]; 181s local
    Compiling tensorflow/core/kernels/pad_op_gpu.cu.cc [for host]; 154s local
    Compiling tensorflow/core/kernels/tile_functor_cpu.cc [for host]; 123s local
    Compiling tensorflow/core/kernels/resource_variable_ops.cc [for host]; 106s local
    Compiling tensorflow/core/kernels/conv_ops_fused_float.cc [for host]; 94s local
    Compiling tensorflow/core/kernels/conv_ops_fused_double.cc [for host]; 91s local
    Compiling tensorflow/core/kernels/conv_ops.cc [for host]; 91s local
    Compiling tensorflow/core/kernels/conv_grad_ops_3d.cc [for host]; 90s local ...
Target //tensorflow/tools/pip_package:build_pip_package failed to build
[19,101 / 21,282] checking cached actions
INFO: Elapsed time: 1270.016s, Critical Path: 336.18s
[19,101 / 21,282] checking cached actions
INFO: 10667 processes: 10667 local.
[19,101 / 21,282] checking cached actions
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
 
I just search all the issues about ""undefined reference to `cublasGemmStridedBatchedEx'"", but I believe mine is different."
34398,Possible bug (wrong sign) in BTRS algorithm for binomial sampling?,"This is a very esoteric issue: I was reading the [BTRS paper](https://www.tandfonline.com/doi/abs/10.1080/00949659308811496) and trying to understand the algorithm by reading the [TF implementation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/random_binomial_op.cc), and I think I found a bug on line 99, in the Stirling approximation for `log(k!)`:

```
return (1.0 / 12 - (1.0 / 360 + 1.0 / 1260 / kp1sq) / kp1sq) / (k + 1);
```

If I'm reading the paper correctly, the sign on the third term is wrong, because it should be positive in the final sum (see page 106-106 of Hörmann et al):

```
return (1.0 / 12 - (1.0 / 360 - 1.0 / 1260 / kp1sq) / kp1sq) / (k + 1);
```

Or maybe there's an error in the paper? Anyway just thought I'd mention it.
"
34396,Error converting universal sentence encoder to TFLite with new converter. Failed to find function '__inference_pruned_1633',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macos 10.14.6
- TensorFlow installed from (source or binary): pip tf-nightly
- TensorFlow version (or github SHA if from source): tf-nightly==2.1.0.dev20191113


**Command used to run the converter or code if you’re using the Python API**

```
tflite_convert --experimental_new_converter --saved_model_dir . --output_file use.tflite
```

**The output from the converter invocation**

```
2019-11-18 16:34:10.641404: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-18 16:34:10.653375: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbe5ebb5250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-18 16:34:10.653433: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-18 16:34:13.643728: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-18 16:34:13.643858: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-18 16:34:13.717700: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2019-11-18 16:34:13.717743: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 183 nodes (0), 183 edges (0), time = 19.817ms.
2019-11-18 16:34:13.717754: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 183 nodes (0), 183 edges (0), time = 19.384ms.
2019-11-18 16:34:13.717762: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_pruned_1633
2019-11-18 16:34:13.717770: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2019-11-18 16:34:13.717778: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-18 16:34:14.576811: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-18 16:34:14.576933: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-18 16:34:14.587930: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2019-11-18 16:34:14.587975: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 183 nodes (0), 183 edges (0), time = 3.225ms.
2019-11-18 16:34:14.587986: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 183 nodes (0), 183 edges (0), time = 3.633ms.
Traceback (most recent call last):
  File ""/Users/caleb.p/Development/tflite-hub/.venv/bin/tflite_convert"", line 8, in <module>
    sys.exit(main())
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 594, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 577, in run_main
    _convert_tf2_model(tflite_flags)
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 235, in _convert_tf2_model
    tflite_model = converter.convert()
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 474, in convert
    **converter_kwargs)
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2019-11-18 16:34:16.190068: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:106] Ignored output_format.
2019-11-18 16:34:16.190086: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:112] Ignored drop_control_dependency.
Traceback (most recent call last):
  File ""/Users/caleb.p/Development/tflite-hub/.venv/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/caleb.p/Development/tflite-hub/.venv/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: Failed to find function '__inference_pruned_1633'. The imported TensorFlow GraphDef is ill-formed.

```

**Also, please include a link to the saved model or GraphDef**

```
https://tfhub.dev/google/universal-sentence-encoder/3
```
Since [this](https://groups.google.com/a/tensorflow.org/forum/#!topic/tflite/C7Ag0sUrLYg) announcement I thought that converting the universal sentence encoder to TFLite might be supported. Could anyone explain the reason for failure here? Thanks a lot!
"
34395,TFLite GL Delegate build is leaking Foundation libraries,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.14.6 Mojave
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: v1.15.0
- Python version: 3.7.4
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.26.0
- GCC/Compiler version (if compiling from source): NDK 18
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the problem**

The Foundation Library is leaking into the GL delegate on v1.15.0.  This is related to [this bug](https://github.com/abseil/abseil-cpp/issues/326), but it didn't happen on v1.14.0

**Any other info / logs**
```
Joes-MacBook-Pro-3:gpu jbowser$ bazel build -c opt --config android_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt -fvisibility=hidden --linkopt -s --strip always :libtensorflowlite_gpu_gl.so
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=238
INFO: Reading rc options for 'build' from /Users/jbowser/tensorflow_source/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'build' from /Users/jbowser/tensorflow_source/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/local/opt/python3/bin/python3.7 --action_env PYTHON_LIB_PATH=/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages --python_path=/usr/local/opt/python3/bin/python3.7 --config=xla --action_env ANDROID_NDK_HOME=/Users/jbowser/ndk_builds/android-ndk-r18 --action_env ANDROID_NDK_API_LEVEL=18 --action_env ANDROID_BUILD_TOOLS_VERSION=29.0.2 --action_env ANDROID_SDK_API_LEVEL=29 --action_env ANDROID_SDK_HOME=/Users/jbowser/library/Android/Sdk --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:xla in file /Users/jbowser/tensorflow_source/tensorflow/.tf_configure.bazelrc: --define with_xla_support=true
INFO: Found applicable config definition build:android_arm64 in file /Users/jbowser/tensorflow_source/tensorflow/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a
INFO: Found applicable config definition build:android in file /Users/jbowser/tensorflow_source/tensorflow/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain
INFO: Analyzed target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_gl.so (45 packages loaded, 3483 targets configured).
INFO: Found 1 target...
INFO: Deleting stale sandbox base /private/var/tmp/_bazel_jbowser/e70d978bebad2fab57f73474f3b8c22a/sandbox
ERROR: /Users/jbowser/tensorflow_source/tensorflow/tensorflow/lite/delegates/gpu/BUILD:110:1: Linking of rule '//tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_gl.so' failed (Exit 1)
external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64/lib/gcc/aarch64-linux-android/4.9.x/../../../../aarch64-linux-android/bin/ld: cannot find Foundation: No such file or directory
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_gl.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 68.598s, Critical Path: 26.36s
INFO: 227 processes: 227 local.
FAILED: Build did NOT complete successfully```"
34393,TFLite SIGILL on Invoke(),"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I am using the C++ API on Android
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 10, Android 9
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 3, Samsung Galaxy S8
- TensorFlow installed from (source or binary): Built from tag (build included in repro repo)
- TensorFlow version (use command below): v2.0.0
- Python version:
- Bazel version (if compiling from source): 0.28.0
- GCC/Compiler version (if compiling from source): NDK 18
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behaviour**
While debugging C++ on Android, SIGILL is triggered on the interpreter->Invoke() call.  If you step past inference, TFLite still successfully infers and produces the correct result, but SIGILL shouldn't happen.

**Describe the expected behavior**
SIGILL shouldn't happen

**Code to reproduce the issue**
This repro reproduces this issue:
git@github.com:infil00p/TFLiteSigILL.git

**Other info / logs**
Debug frame for SIGILL
<img width=""1286"" alt=""Screen Shot 2019-11-18 at 12 56 57 PM"" src=""https://user-images.githubusercontent.com/2313/69093285-026b7d80-0a03-11ea-809b-1e73d1537bf4.png"">
"
34392,Training stucking and strange GPU usage,"Hi there,
Im recently trying to train my model using configs from zoo.
But sometimes my training is stucking.
full Issue is described here 
https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/issues/385

And the GPU usage looks like here - im uploading you a graph from MSI Afterburner :

https://drive.google.com/file/d/1Z6q6uQnOfMn2VGDlpcWAHAwYW10qI1jA/view?usp=sharing

Thanks for help.
"
34391,TPUStrategy broken in TF2 Keras,"**System information**
- Have I written custom code: YES
- OS Platform and Distribution: Google Colab
- TensorFlow installed from (source or binary): Colab
- TensorFlow version (use command below):  ('v2.0.0-rc2-26-g64c3d38', '2.0.0')
- GPU model and memory:  Colab TPU

**Describe the current behavior**
TPU in collab cannot be used with TF 2, trying to use `TFRecordDataset` as an input to a Keras `Model.fit()` generates different exceptions depending on the whether `TPUStrategy.experimental_distribute_dataset()` is used or not.


1. when `TPUStrategy.experimental_distribute_dataset()` is **not** used or used but not within an `/job:worker` context:
```
InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run AutoShardDataset: Unable to parse tensor proto
Additional GRPC error information:
{""created"":""@1574107145.043685979"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to parse tensor proto"",""grpc_status"":3} [Op:AutoShardDataset]
```

2. using a `/job:worker` context without `experimental_distribute_dataset` crashes the Colab session with:
```
Nov 18, 2019, 9:17:39 PM	WARNING	2019-11-18 20:17:39.591672: E tensorflow/core/framework/variant.cc:102] Could not decode variant with type_name: ""tensorflow::DatasetVariantWrapper"". Perhaps you forgot to register a decoder via REGISTER_UNARY_VARIANT_DECODE_FUNCTION?
Nov 18, 2019, 9:09:53 PM	WARNING	2019-11-18 20:09:53.396513: E tensorflow/core/framework/dataset.cc:76] The Encode() method is not implemented for DatasetVariantWrapper objects.
Nov 18, 2019, 9:08:19 PM	WARNING	2019-11-18 20:08:19.842178: E tensorflow/core/framework/dataset.cc:76] The Encode() method is not implemented for DatasetVariantWrapper objects.
```

3. and 4. when `experimental_distribute_dataset` is used in a `tf.device(""/job:worker"")` context:
```
/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py in _distribution_standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, validation_split, shuffle, epochs, allow_partial_batch)
   2313         x = ds.batch(batch_size, drop_remainder=drop_remainder)
   2314       else:
-> 2315         assert isinstance(x, dataset_ops.DatasetV2)
   2316         training_utils.validate_dataset_input(x, y, sample_weight,
   2317                                               validation_split)
```

**Describe the expected behavior**
There should be at least one way of making the example bellow work with TF2 (it works with TF1).

**Code to reproduce the issue**
could also be checked here https://colab.research.google.com/gist/kpe/22340866c1dd3208d9177d2c8a9322e3/tpu-emb.ipynb

```python
%tensorflow_version 2.x
import tensorflow as tf
print(""TF version:"", tf.__version__)

import os

tfrec_path = ""gs://kpe-pub/pub/tpu-strategy-ds-issue/test.tfrecords""

def parse_example(proto):
    return tf.io.parse_single_example(proto, {
        ""feature"": tf.io.VarLenFeature(tf.float32), 
        ""label"":   tf.io.VarLenFeature(tf.int64)
    })

def from_tfrecords_file(tfrec_path):
    ds = tf.data.TFRecordDataset([tfrec_path], compression_type=""GZIP"")
    ds = ds.map(parse_example)
    def to_dense(example):
        feature = tf.cast(tf.sparse.to_dense(example[""feature""]), tf.float32)
        label   = tf.cast(tf.sparse.to_dense(example[""label""]), tf.int32)
        return feature, tf.squeeze(label, -1)
    ds = ds.map(to_dense)
    return ds

try:
    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']
    tf.config.experimental_connect_to_host(TPU_WORKER)
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
except:
    strategy = tf.distribute.get_strategy()
print(strategy)


def test_strategy(use_case):
    assert use_case in [0,1,2,3,4]

    if tf.__version__.startswith(""1.""): # in TF1 no need to distribute the dataset
        ds = from_tfrecords_file(tfrec_path).repeat().batch(32)
    else:
        if use_case == 0:
            ds = from_tfrecords_file(tfrec_path).repeat().batch(32)
        if use_case == 1:
            ds = from_tfrecords_file(tfrec_path).repeat().batch(32)
            ds = strategy.experimental_distribute_dataset(ds)
        if use_case == 2:            
            with tf.device(""/job:worker""):
                ds = from_tfrecords_file(tfrec_path).repeat().batch(32)
        if use_case == 3:
            with tf.device(""/job:worker""):
                ds = from_tfrecords_file(tfrec_path).repeat().batch(32)
                ds = strategy.experimental_distribute_dataset(ds)
        if use_case == 4:
            with strategy.scope(), tf.device(""/job:worker""):
                ds = from_tfrecords_file(tfrec_path).repeat().batch(32)
                ds = strategy.experimental_distribute_dataset(ds)

    with strategy.scope():
        model = tf.keras.models.Sequential([
            tf.keras.layers.InputLayer(input_shape=(128,)),
            tf.keras.layers.Dense(2)
        ])
        model.build()
        model.compile(""adam"", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))
        model.fit(ds, steps_per_epoch=4)

test_strategy(0) # try 0 ot 4
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34390,[TF2.0] tf.reduce_mean crashes Python (Floating point exception) if the count becomes zero due to overflow,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from: binary, source tested as well
- TensorFlow version: 2.0
- Python version: 3.7

**Describe the current behavior**

Running the script:
```python
import tensorflow as tf
data = tf.zeros(256, dtype=tf.uint8)
print(tf.reduce_mean(data))
```
Crashes the Python interpreter (e.g. `Floating point exception (core dumped)`).
(Likely as 256 overflows in `uint8` to 0, leading to an uncaught division by zero.

**Describe the expected behavior**
A result, possibly incorrect (due to too small dtype), or some other way to deal with the issue, e.g. assertion errors or other exceptions, however no crashing of Python.
*Ideally*, `tf.reduce_mean` could yield correct results for non-floating-point dtypes as well.

**Code to reproduce the issue**
See above.
"
34385,GPU device not found in Colab,"My code worked well with GPU in Colab yesterday. But this morning it became very slow. So I suspect that CPU is used despite hardware accelerator is set to GPU in “change runtime type” explicitly. So I check the availability of GPU following the tutorial:
https://colab.research.google.com/notebooks/gpu.ipynb

code chunk:
```
%tensorflow_version 2.x
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))
```

Indeed, I got SystemError: GPU device not found. I tried this with different sessions or google user accounts, the same results. You should be able to replicate this in a new Colab session.
Maybe some tensorflow updates are involved? It could be that Colab session provide GPU, but tensorflow can’t see it, e.g. tf.test.gpu_device_name() or tf.test.is_gpu_available(). 
Please help, thank you!"
34381,Segmentation fault (core dumped) tf 1.12.0-gpu-py3 image (works with cuda:9.0-cudnn7-devel-ubuntu16.04 and manual tf install),"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no (code from https://keras.io/examples/mnist_cnn/)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu Pop!_OS 19.10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): docker image 1.12.0-gpu-py
- TensorFlow version (use command below): 1.12.0
- Python version: 3.5.2
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: from Tensorflow image
- GPU model and memory: GeForce RTX 2070 | 8GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When running the aforementioned example inside the Tensorflow `1.12.0-gpu-py3` container I get the following output:

```bash
docker run -it tensorflow/tensorflow:1.12.0-gpu-py3 bash
root@da57df222465:/notebooks# cd /export/home/bartosz.miselis/code/repos/cicd/
root@da57df222465:/export/home/bartosz.miselis/code/repos/cicd# python mnist.py
2019-11-18 16:57:56.234513: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-18 16:57:56.335561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-18 16:57:56.335832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:01:00.0
totalMemory: 7.79GiB freeMemory: 7.34GiB
2019-11-18 16:57:56.335847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-11-18 16:57:56.519252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-18 16:57:56.519282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0
2019-11-18 16:57:56.519287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N
2019-11-18 16:57:56.519367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7056 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 1/12
Segmentation fault (core dumped)
```

**Describe the expected behavior**
The training should run smoothly.

**Code to reproduce the issue**
As stated above, the code is directly accessible through the URL.

**Other info / logs**
`nvidia-smi` output:

```bash
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.31       Driver Version: 440.31       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 2070    Off  | 00000000:01:00.0 Off |                  N/A |
|  0%   41C    P8    19W / 185W |    363MiB /  7981MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```

Additionally, running the code inside `cuda:9.0-cudnn7-devel-ubuntu16.04` container with manual `tensorflow-gpu==1.12.0` package via pip makes it run properly.

Even more strangely, the code runs perfectly fine when using `1.12.3-gpu-py3` container. I'm limited to using `1.12.0` currently (strict project requirements)."
34380,Why is autoencoder with tensorflow 2.0 is performing very bad compared to the same code in keras?,"I am training an autoencoder on the mnist data With keras the validation loss is great (starting from 0.2687 to .1) While with tensorflow(version 2.0).keras validation loss is stuck at (.6) Even though I am using the same code.

Below is the code with keras ([you can test it in colab](https://colab.research.google.com/drive/1AD5Z_pXsaM6Ubn6Yfg0uD230J9o8AfRS)) and followed by the code with tf.keras ([you can test it in colab](https://colab.research.google.com/drive/1Hj3-_Bjfkp3-dmd38-1CmIR4VLOV98hB))

```
from keras.layers import Input, Dense
from keras.models import Model, Sequential
from keras.datasets import mnist
import numpy as np

#Import the MNIST data, only take the images since we don't need the targets
(x_train, y_train), (x_test, y_test) = mnist.load_data()
#Normalize and reshape images to vectors
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print (x_train.shape)
print (x_test.shape)


input = Input(shape=(784,))
y = Dense(64, activation='relu')(input)
z = Dense(784, activation='sigmoid')(y)
ae = Model(input, z)
encoder = Model(input, y)
input_decoder = Input(shape = (64,))
decoder_layer = ae.layers[-1]
decoder = Model(input_decoder, decoder_layer(input_decoder))
ae.compile(optimizer='adadelta', loss = 'binary_crossentropy')
ae.fit(x_train, x_train, epochs = 50, batch_size=256, shuffle=False, validation_data=(x_test, x_test))
```

60000/60000 [==============================] - 5s 88us/step - loss: 0.3494 - val_loss: 0.2688 Epoch 2/50 60000/60000 [==============================] - 4s 74us/step - loss: 0.2578 - val_loss: 0.2445 Epoch 3/50

```
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.datasets import mnist
import numpy as np

#Import the MNIST data, only take the images since we don't need the targets
(x_train, y_train), (x_test, y_test) = mnist.load_data()
#Normalize and reshape images to vectors
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print (x_train.shape)
print (x_test.shape)


input = Input(shape=(784,))
y = Dense(64, activation='relu')(input)
z = Dense(784, activation='sigmoid')(y)
ae = Model(input, z)
encoder = Model(input, y)
input_decoder = Input(shape = (64,))
decoder_layer = ae.layers[-1]
decoder = Model(input_decoder, decoder_layer(input_decoder))
ae.compile(optimizer='adadelta', loss = 'binary_crossentropy')
ae.fit(x_train, x_train, epochs = 50, batch_size=256, shuffle=False, validation_data=(x_test, x_test))

```
Train on 60000 samples, validate on 10000 samples Epoch 1/50 60000/60000 [==============================] - 4s 59us/sample - loss: 0.6941 - val_loss: 0.6939 Epoch 2/50 60000/60000 [==============================] - 3s 47us/sample - loss: 0.6937 - val_loss: 0.6936
"
34379,Memory leak in custom tensors,"Hello everyone,

cc: @alextp 

There is a memory leak for custom tensors from https://github.com/tensorflow/tensorflow/issues/24865. You can find an MWE here: https://colab.research.google.com/drive/1v-PEv3-qubszfK0gFS2RLhcP6qbDUvIK. Long story short. In GPflow we define parameters of the model as custom tensors (variables) https://github.com/GPflow/GPflow/blob/develop/gpflow/base.py#L36. The parameter is a `tf.Module` container with single tf.Variable and TFP bijector inside. The custom tensor behaves as a standard TensorFlow tensor, **plus** it applies transformation on internal `tf.Variable` and returns forward transformed Tensor of the variable every-time when someone decides to read it (user, tensorflow function).

When I use a model with Parameter class and compute gradients w.r.t. the loss, I observe constant memory growth. And when I use the model with same variables but do transformation of the variables manually the memory stays the same.

If I do forward mode only, there are no issues. It happens only when `GradientTape` is involved.

PS: memory profiler doesn't work in colab, you will have to run it on your computer.

- macOS 10.14.6
- Python 3.7.0
- TensorFlow version:
```bash
→ python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
v2.0.0-rc2-26-g64c3d382ca 2.0.0
```

Middle of the training:

```python
Compute gradient
Iteration 56 has passed with loss = 494609555730402.0
Filename: mwe2.py

Line #    Mem usage    Increment   Line Contents
================================================
   118    484.5 MiB    484.5 MiB   @profile
   119                             def train_step(compute_grads: bool = True):
   120    484.6 MiB      0.1 MiB       data = next(dataset_it)
   121    484.6 MiB      0.0 MiB       variables = model.trainable_variables
   122    484.6 MiB      0.0 MiB       with tf.GradientTape(watch_accessed_variables=False) as tape:
   123    484.6 MiB      0.0 MiB           tape.watch(variables)
   124    490.6 MiB      6.1 MiB           loss = loss_fn(data)
   125
   126    490.6 MiB      0.0 MiB       if compute_grads:
   127    490.6 MiB      0.0 MiB           tf.print(f""Compute gradient"")
   128    491.2 MiB      0.6 MiB           grads = tape.gradient(loss, variables)
   129    491.2 MiB      0.0 MiB           grads_and_vals = zip(grads, variables)
   130    491.2 MiB      0.0 MiB           opt.apply_gradients(grads_and_vals)
   131
   132    491.2 MiB      0.0 MiB       tf.print(f""Iteration {opt.iterations.numpy()} has passed with loss = {loss.numpy()}"")
```

In the end:
```python
Compute gradient
Iteration 100 has passed with loss = 273947779893557.2
Filename: mwe2.py

Line #    Mem usage    Increment   Line Contents
================================================
   118    514.8 MiB    514.8 MiB   @profile
   119                             def train_step(compute_grads: bool = True):
   120    514.9 MiB      0.1 MiB       data = next(dataset_it)
   121    514.9 MiB      0.0 MiB       variables = model.trainable_variables
   122    514.9 MiB      0.0 MiB       with tf.GradientTape(watch_accessed_variables=False) as tape:
   123    514.9 MiB      0.0 MiB           tape.watch(variables)
   124    520.9 MiB      6.1 MiB           loss = loss_fn(data)
   125
   126    520.9 MiB      0.0 MiB       if compute_grads:
   127    520.9 MiB      0.0 MiB           tf.print(f""Compute gradient"")
   128    521.5 MiB      0.6 MiB           grads = tape.gradient(loss, variables)
   129    521.5 MiB      0.0 MiB           grads_and_vals = zip(grads, variables)
   130    521.5 MiB      0.0 MiB           opt.apply_gradients(grads_and_vals)
   131
   132    521.5 MiB      0.0 MiB       tf.print(f""Iteration {opt.iterations.numpy()} has passed with loss = {loss.numpy()}"")
```"
34378,Identifying activating neurons for specific classes,"Hi all, hope this question is ok placed here! any help would be much appreciated!

I have a question i am hoping somebody might be able to help with. I have trained a sequential model (keras) that attempts to understand multiple labels in a data set. There are hundreds of samples (more samples to follow), and each individual sample will have multiple labels (an organ, an age and sex).

the model performs really well and is able to understand every concept above (age sex and organ), with really high performance. I would like to know which nodes in the network interact with one another, especially, which samples in the network interact with one another (i.e, are the features that activate for example, a brain and lung if your male at a specific age).

For this reason, I have taken the activation's of every node in the hidden layers and I attach a UMAP to this post. There is a slight problem because the most common activation are actually organ specific. This makes sense as the concept of organ is very strong, so it not surprising that this is the easiest class to pick apart. The problem is is that when I use dimensionality reduction on the node activation, the nodes that separate most closely cluster according to organ, again because this is the class that has an overwhelming signature.

This is even the case in the penultimate layer (image attached)...

My question is, is there a way of identifying and removing the neurons that lead specifically to organ decisions so that i can then repeat the dimensionality reduction in the intermediate layer to look for relationships in the data?

If i plot a normal heatmap i can see where activation's are shared and which samples where they are shared, but i would also like to use dimensionality reduction to view which neurons activate in a similar manner and what samples share features beyond just the overwhelming organ signature.

i am happy to provide code if required!

many thanks!
![umap](https://user-images.githubusercontent.com/33659783/69063806-0902f080-0a15-11ea-9692-9ca361b583dc.png)
"
34376,"RunTimeError: DST Tensor Not initialised - while saving checkpoint, not while training.","

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18 LTS
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6
- CUDA/cuDNN version: 
nvidia-driver-418
cuda-10-0
libcudnn7=7.6.2.24-1+cuda10.0
libcudnn7-dev=7.6.2.24-1+cuda10.0
libnvinfer5=5.1.5-1+cuda10.0
libnvinfer-dev=5.1.5-1+cuda10.0

- GPU model and memory: T4 16GB

**Describe the current behavior**

The GPU memory is only used for 58%, detected by using limit_growth option:
GPU Total memory:  15843721216
GPU Free memory:  6628966400
GPU Used memory:  9214754816
GPU Memory Percentage Used:  58

```
    if gpus:
      try:
        # Currently, memory growth needs to be the same across GPUs
        for gpu in gpus:
          tf.config.experimental.set_memory_growth(gpu, True)
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
      except RuntimeError as e:
        # Memory growth must be set before GPUs have been initialized
        print(e)
```

Training runs fine, but only when saving the model as a checkpoint, it crashes:
```

        def createCheckpointManager(self):

            if self.model_weight_path:
                checkpoint_dir = self.model_weight_path + '/' + self.training_session_id + '_checkpoint/ckpt'

                print(""Store Checkpoint: "",checkpoint_dir)

                self.checkpoint = tf.train.Checkpoint(optimizer=self.optimizer,
                                                 encode_network=self.encode_network,
                                                 decode_network=self.decode_network)

                self.manager = tf.train.CheckpointManager(self.checkpoint,checkpoint_dir, max_to_keep=3)
            else:
                print(""Model checkpoint path not found, not saving checkpoint."")

CheckpointManager.save()
```

Log:
```
Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""/home/[]/[]/[]/v1/[]/[].py"", line 107, in runTrainingEpoch
    [].storeCheckpoint()
  File ""/home/[]/[]/[]/v1/[]/[].py"", line 179, in storeCheckpoint
    self.manager.save()
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/training/checkpoint_management.py"", line 720, in save
    save_path = self._checkpoint.write(prefix)
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1819, in write
    output = self._saver.save(file_prefix=file_prefix)
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1155, in save
    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1103, in _save_cached_when_graph_building
    save_op = saver.save(file_prefix)  
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 230, in save
    sharded_saves.append(saver.save(shard_prefix))
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 69, in save
    tensors.append(spec.tensor)
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/training/saving/saveable_object.py"", line 52, in tensor
    return self._tensor() if callable(self._tensor) else self._tensor
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/training/saving/saveable_object_util.py"", line 94, in f
    return array_ops.identity(x)
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py"", line 209, in identity
    copied = input._copy()  # pylint: disable=protected-access
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1015, in _copy
    new_tensor = self._copy_nograd(ctx, device_name)
  File ""/home/[]/env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1008, in _copy_nograd
    new_tensor = self._copy_to_device(device_name)
RuntimeError: Dst tensor is not initialized.
```

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

The model is the exact implementation of the CVAE tutorial from the Tensorflow website:
```
self.optimizer = tf.keras.optimizers.Adam(1e-4)

       self.encode_network = tf.keras.Sequential(
              [
                  tf.keras.layers.InputLayer(input_shape=(self.width, self.height, 3)),
                  tf.keras.layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2), activation='relu'),
                  tf.keras.layers.Conv2D(filters=64, kernel_size=2, strides=(2, 2), activation='relu'),
                  tf.keras.layers.Flatten(),
                  tf.keras.layers.Dense(self.latent_dim + self.latent_dim),
              ]
            )

            # Deconvolution 2D Transpose Formula:
            # Output Shape = Input Shape * stride

            self.decode_network = tf.keras.Sequential(
                [
                  tf.keras.layers.InputLayer(input_shape=(self.latent_dim,)),
                  tf.keras.layers.Dense(units=64 * 64 * 128, activation=tf.nn.relu),
                  tf.keras.layers.Reshape(target_shape=(64, 64, 128)),
                  tf.keras.layers.Conv2DTranspose(
                      filters=64,
                      kernel_size=3,
                      strides=(2, 2),
                      padding=""SAME"",
                      activation='relu'),
                  tf.keras.layers.Conv2DTranspose(
                      filters=32,
                      kernel_size=3,
                      strides=(2, 2),
                      padding=""SAME"",
                      activation='relu'),
                  tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=2, strides=(1, 1), padding=""SAME"")
                ]
            )
```

Because the layer size is increased, I suspect it has something to do with memory, because earlier issues refer the 'DST tensor' issue to a memory problem with the GPU.
However this is not possible because only 58% is utilised and training runs fine, therefore it seems there is an issue with saving the checkpoint.
"
34375,Run multi-worker with nccl error: NET/IB : collective mismatch error,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `tensorflow/models`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  `ubuntu 18.04.3`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  `tensorflow:2.0.0-gpu` (docker image)
- TensorFlow version (use command below):  `2.0.0`
- Python version: 2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: `10.1/7.6.0.64`
- NCCL version: `2.5.4`
- GPU model and memory:  Nvidia P40

**Describe the current behavior**

* worker A

```
CUDA_VISIBLE_DEVICES=0 NCCL_DEBUG=INFO  NCCL_IB_GID_INDEX=3 NCCL_IB_HCA=mlx5_1:1 NCCL_IB_SL=3 NCCL_SOCKET_IFNAME=eth1 python -m resnet_imagenet_main --model_dir=/tmp/model_dir/resnet  --num_gpus=1   --batch_size=32  --use_synthetic_data=true --worker_hosts=A:2222,B:2222  --task_index=0 --distribution_strategy=multi_worker_mirrored --all_reduce_alg=nccl
```
* worker B
```
CUDA_VISIBLE_DEVICES=0 NCCL_DEBUG=INFO  NCCL_IB_GID_INDEX=3 NCCL_IB_HCA=mlx5_1:1 NCCL_IB_SL=3 NCCL_SOCKET_IFNAME=eth1 python -m resnet_imagenet_main --model_dir=/tmp/model_dir/resnet  --num_gpus=1   --batch_size=32  --use_synthetic_data=true --worker_hosts=A:2222,B:2222 --task_index=1 --distribution_strategy=multi_worker_mirrored --all_reduce_alg=nccl
```

The error as follows:

```
...
2019-11-18 10:26:43.012421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
:499:967 [0] NCCL INFO NET/Socket : Using [0]eth1:100.x.x.x<0>
:499:967 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
2019-11-18 10:26:43.248455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
:499:967 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE ; OOB eth1:100.x.x.x<0>
:499:978 [0] NCCL INFO Setting affinity for GPU 0 to 03,fffff000,003fffff
:499:978 [0] NCCL INFO CUDA Dev 0[0], IB NIC distance :  PHB
:499:978 [0] NCCL INFO Ring 00 : 0 -> 1 [receive] via NET/IB/0
:499:978 [0] NCCL INFO Ring 00 : 1 -> 0 [send] via NET/IB/0
:499:978 [0] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
:499:978 [0] NCCL INFO NCCL_IB_SL set by environment to 3.
:499:978 [0] NCCL INFO comm 0x7f3e640025b0 rank 1 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE

:499:979 [0] external/nccl_archive/src/transport/net_ib.cc:651 NCCL WARN NET/IB : collective mismatch error local size 1048576 remote 32768 addr 7f7563811000 rkey 103480 seq 2/2
:499:979 [0] NCCL INFO bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs/net.h:31 -> 3
:499:979 [0] NCCL INFO external/nccl_archive/src/transport/net.cc:470 -> 3
:499:979 [0] NCCL INFO external/nccl_archive/src/transport.cc:163 -> 3 [Proxy Thread]
...
```"
34374,TFLite android example custom model error: java.lang.ArrayIndexOutOfBoundsException: length=10; index=-2147483646,"Hi @achowdhery ,

I'm getting this error while placing my custom model in tensorflow lite android example. I've gone through the post which resolves the same 
int labelOffset = 1;
      recognitions.add(
          new Recognition(
              """" + i,
              labels.get((int) outputClasses[0][i] + labelOffset),
              outputScores[0][i],
              detection));

this is the part which is throwing the error. But i'm not getting how to resolve it.

I annotated images using labelimg tool with class names as parallel_parking and perpendicular parking. Then while creating tf.record I did this:

item {
  id: 1
  name: 'parallel_parking'
}
item {
  id: 2
  name: 'perpendicular_parking'
}

and followed the steps mentioned here https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193.

now, while running the tflite app, i'm getting the above mentioned error. Need help."
34371,tf.io.gfile.glob does not list all files in a Google Cloud Storage bucket,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): ?
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: /
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3
- Bazel version (if compiling from source): /
- GCC/Compiler version (if compiling from source): /
- CUDA/cuDNN version: /
- GPU model and memory: /

**Describe the current behavior**
When listing file with `tf.io.gfile.glob` not all images are returned. It seems it is not resolving the folders recursively. 
When using the same path with gsutils  we get the correct image count.


**Describe the expected behavior**
When using the same gs:// path with **gsutils** we get the correct amount of images. 

**Code to reproduce the issue**
In order to reproduce the behavior I prepared a Google Bucket with the following structure. The bucket is public accessible, please feel free to use it to reproduce the behavior on your end: `gs://tensorflow-issue-reproduction`

![level0](https://user-images.githubusercontent.com/1991664/69040135-93375e80-09ed-11ea-927f-da445d2bae10.png)
![level1](https://user-images.githubusercontent.com/1991664/69040139-94688b80-09ed-11ea-9e19-28af47c3bcee.png)
![level2](https://user-images.githubusercontent.com/1991664/69040146-96cae580-09ed-11ea-8894-c69a82acbbaa.png)
![level3](https://user-images.githubusercontent.com/1991664/69040150-9894a900-09ed-11ea-94dc-49fb2d9b3b9b.png)

In summary we have 4 jpg images nested in different folder levels.

TensorFlow 2 code to reproduce
```
files = tf.io.gfile.glob('gs://tensorflow-issue-reproduction/**/*.jpg')
print('file count: ', len(files))
# found files 1
```

gsutil command which works properly
```
gsutil du gs://tensorflow-issue-reproduction/**/*.jpg | wc -l
# found files 4
```

**Other info / logs**
/

Best regards
Sascha
"
34369,"TF2 Warning :  Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.","When i compute grads by tf.GradientTape, console presents  a **warning : Sets are not currently considered sequences, but this may change in future, so consider avoiding using them.** My code is like this 
```python
import tensorflow as tf
import numpy as np
import logging

logging.basicConfig(format='%(message)s', level=logging.INFO)

input = np.array([[0.1, 0], [0, 0.1]], np.float32)
target = np.array([1, 0], np.float32)


class layer(tf.Module):
    def __init__(self):
        super(layer, self).__init__()
        with self.name_scope:
            self.w1 = tf.Variable(tf.ones([2, 2]), name='w1')

    @tf.Module.with_name_scope
    def __call__(self, x):
        return tf.nn.tanh(x * self.w1)


def get_loss(pred, y_):
    return tf.losses.binary_crossentropy(pred, y_)


def get_opti():
    return tf.optimizers.SGD()


my_layer = layer()

optimizer = get_opti()

for _ in range(2):
    for x_, y_ in zip(input, target):
        with tf.GradientTape() as tape:
            pred = my_layer(x_)

            loss = get_loss(pred, y_)
        grads = tape.gradient(loss, my_layer.trainable_variables )
        optimizer.apply_gradients(zip(grads, my_layer.trainable_variables ))


print('-----------')
print(my_layer.w1.numpy())
```
![image](https://user-images.githubusercontent.com/47944452/69391681-8a58cc80-0d0e-11ea-9b73-f35742116387.png)
"
34368,MemcpyHtoD blocks gpu computing when using StagingArea,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.13.1
- Python version: 3.5.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/7.4
- GPU model and memory: v100 32GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I used StagingArea to make data transferring and coputing as a pipeline. But it turned out that MemcpyHtoD was not overlapped with computing. 
![image](https://user-images.githubusercontent.com/12964346/69027289-62652280-0a09-11ea-9f4d-721ba29f8442.png)

**Describe the expected behavior**
Data transferring overlaps with computing in order to speed up training.
**Code to reproduce the issue**
```
with tf.device(""/gpu:0""):
    cpu_to_gpu_stage = data_flow_ops.StagingArea(dtypes=_dtypes(data), shapes=_shapes(data))
    cpu_to_gpu_op = cpu_to_gpu_stage.put(data)

    data2 = cpu_to_gpu_stage.get()
    train_op = model.build_graph(data2)

sess.run([cpu_to_gpu_op])
while 1:
    res = sess.run([train_op, cpu_to_gpu_op])[0]

```
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34366,with tf.GradientTape() tf.image.non_max_suppression returns  unexpected result,"  with tf.GradientTape() as tape:
    predictions = model(images)
    vol = predictions.shape[1]
    col = predictions.shape[2]
    num_boxes = vol*col*anchor_len
    predictions = tf.reshape(predictions,[num_boxes,5+classes])
    
    scores = predictions[:,0]
    boxes = predictions[:,1:5]
    num_labels = len(labels)
    print(num_labels,'num_labels')
    nms_index = tf.image.non_max_suppression(boxes,scores,max_output_size=num_labels,score_threshold=0.1)

errors:
Tensor(""non_max_suppression/NonMaxSuppressionV3:0"", shape=(None,), dtype=int32)

the same input ,when eval, the nms_index will be normal. but in training, it returns nothing.

why? is  tf2.0's eagermode only supported in some steps? 
where can i find the document about eagermode vs traditional ways?"
34365,Why tf.concat not support multiply types,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): TF2.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
I have 2 tensor with shape(1,4)
but one tensor(a) is string type.
Another tensor(b) is int32 type.
When I try to concat them
tf.concat([a,b], 0)
I get the error message:
_tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute ConcatV2 as input #1(zero-based) was expected to be a string tensor but is a int32 tensor [Op:ConcatV2] name: concat_

**Will this change the current api? How?**

**Who will benefit with this feature?**
tf.concat users

**Any Other info.**
"
34364,build failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04.3 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1.0-rc.0
- Python version: 3.7.5 x64
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 0.29.1 x64
- GCC/Compiler version (if compiling from source):  7.4.0
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: GTX1080Ti



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
 bazel build
 
**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
ERROR: /home/wmind/repo/tensorflow/tensorflow/python/BUILD:2591:1: Linking of rule '//tensorflow/python:gen_sparse_ops_py_wrappers_cc' failed (Exit 1)
bazel-out/host/bin/tensorflow/core/libop_gen_lib.a(op_gen_lib.o): In function `google::protobuf::internal::ArenaStringPtr::CreateInstance(google::protobuf::Arena*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*)':
```
"
34363,"random.uniform((),minval,maxval) returns array instead of scalar tensor when min or maxval is not a scalar tensor","```
>>> import tensorflow as tf
>>> scalar = tf.zeros(shape=())
>>> array = tf.zeros(shape=(1,))

>>> tf.random.uniform(shape=(),minval = scalar)
<tf.Tensor: id=25, shape=(), dtype=float32, numpy=0.021499991>

>>> tf.random.uniform(shape=(),minval = array)
<tf.Tensor: id=31, shape=(1,), dtype=float32, numpy=array([0.9388697], dtype=float32)>
```
Expected behavior is to either trow an error or treat single element tensor as scalar and return a scalar.

-win10, tf2, cuda"
34362,TF Speech recognition issue,When I debugg the TF apk file and after installing speech recognition after pressing Start button it's just not working ...
34361,module 'keras.applications' has no attribute 'resnet',"I tried to google the whole day and nothing worked for me.

So in the beginning I got this:
module 'keras.applications' has no attribute 'resnet'

Then I tried a few ways that I got from googling, I got this:
module 'tensorflow' has no attribute 'get_default_graph'

seems like related but I can't understand what's wrong here. My keras version is 2.2.4."
34358,Dynamic Batch size ( Bucketing ) for GPU in MirrorStrategy in TF 2.0 and avoid NaN .,"

Tensorflow - version 2 

Hi All, I am trying to do bucketing my tensorflow datasets, so that I can change my batch size (dynamic batch size) based on different sequence length, so that I can exploit GPU performance better. I am using ```strategy = tf.distribute.MirroredStrategy()``` . 

Assume I am having 8 GPUs ```n_gpus=8```, according to mirror strategy if we are having a batch size of 16 ```batch_size=16```, it will distribute ```2 ( batch_size / n_gpus ) ``` batch datasets to each of the GPUs. Now, assume ```batch_size``` is dynamic and changing in each iteration over the ```dataset iterator```. In order to make it distributed, whenever  ```batch_size``` is not a multiple of ```n_gpus```, I will pad it and make it to the nearest possible multiple of ```n_gpus```. (If ```batch_size = 6```, I will pad with ```2 rows of zeros``` to make it ```8``` ).  Everything works well in CPUs. But when I am using ```iterator = strategy.experimental_distribute_dataset(input_data)```, things becomes difficult. I am providing the code .

```
import tensorflow as tf
import numpy as np

def create_dummy_squad_data(max_seq_length,n,vocab_size=30000):
    np.random.seed(1)
    input_ids   = np.random.randint(1, vocab_size-1, (n,max_seq_length))
    input_mask  = np.random.randint(0, 2, (n,max_seq_length))
    token_type_ids   = np.random.randint(1, 2, (n,max_seq_length))
    start_labels = np.random.randint(1, max_seq_length-1, (n))
    end_labels = np.random.randint(1, max_seq_length-1, (n))

    return (input_ids, input_mask, token_type_ids, start_labels, end_labels)


def map_to_dict(input_ids, input_mask, token_type_ids, start_labels, end_labels):
    inputs = {}
    inputs['input_ids']   = input_ids
    inputs['input_mask']  = input_mask
    inputs['segment_ids'] = token_type_ids

    labels = {}
    labels['start_positions'] = start_labels
    labels['end_positions'] = end_labels

    return inputs, labels

def pad_batch(inputs, labels, batch_multiple=8):
    batch_size = tf.shape(inputs['input_ids'])[0]
    mod = batch_size % batch_multiple
    has_mod = tf.cast(tf.cast(mod, tf.bool), tf.int32)
    batch_padding = batch_multiple * has_mod - mod

    inputs_padded = {}
    for k, feature in inputs.items():
        rank = len(feature.shape)
        paddings = [[0, 0] for _ in range(rank)]
        paddings[0][1] = batch_padding
        padded_feature = tf.pad(feature, paddings)
        inputs_padded[k] = padded_feature

    labels_padded = {}
    for k, feature in labels.items():
        rank = len(feature.shape)
        paddings = [[0, 0] for _ in range(rank)]
        paddings[0][1] = batch_padding
        padded_feature = tf.pad(feature, paddings)
        labels_padded[k] = padded_feature
    return inputs_padded, labels_padded

#### Main code starts from here (CPU code)
input_ids, input_mask, token_type_ids, start_labels, end_labels = create_dummy_squad_data(5, 100)
d = tf.data.Dataset.from_tensor_slices((input_ids, input_mask, token_type_ids, start_labels, end_labels))
d = d.map(map_to_dict)

batch_size_per_gpu = 1
num_gpus       = 8

batch_size = batch_size_per_gpu * num_gpus

d = d.batch(batch_size)
d = d.map(pad_batch)
for item in d:
    pass
```
Last batch of ```item``` is having ```batch_size = 4 ( if we dont pad )```. As I am using padding, things are good

Sample output ( item[0]['input_ids'] )
------------------------------------
```
<tf.Tensor: id=1801, shape=(8, 5), dtype=int64, numpy=
array([[29865,  5139,  4322,  7079, 24896],
       [ 2548,  1583,  7529, 14554, 21480],
       [20593,  2560, 27139, 26397, 28367],
       [25292, 23995, 26283,  4891, 28905],
       [    0,     0,     0,     0,     0],
       [    0,     0,     0,     0,     0],
       [    0,     0,     0,     0,     0],
       [    0,     0,     0,     0,     0]])>
```

#### Code in GPU ( This is what I want )

````
    with strategy.scope():
        iterator = strategy.experimental_distribute_dataset(d)
    all_batch_data = [] #### was curious to know how things work
    with strategy.scope():
        for batch_data in iterator:
            all_batch_data.append(batch_data)
            print(""Batch  Data shape per gpus"", batch_data[0]['input_ids'].values[0].shape)
````
As you see below, ```GPU [0,1,2,3]``` takes each 4 elements and padded it individually ( which was not I expected ). and ```GPU[4,5,6,7]```, not receiving anything. At the time of modeling, the last 4 GPUs, returns ```nan``` as loss, and when I am using ```strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,
                               axis=None)```, it becomes ```nan``` . Here, ```per_replica_losses``` is losses from ```8 GPUs```. First 4 is having values, but last 4 is ```nan```. 

Sample output ( batch_data[0]['input_ids'])
------------------------------------------

```
'input_ids': PerReplica:{
    0 /job:localhost/replica:0/task:0/device:GPU:0: <tf.Tensor: id=123188, shape=(8, 5), dtype=int64, numpy=
  array([[29865,  5139,  4322,  7079, 24896],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0]])>,
    1 /job:localhost/replica:0/task:0/device:GPU:1: <tf.Tensor: id=123194, shape=(8, 5), dtype=int64, numpy=
  array([[ 2548,  1583,  7529, 14554, 21480],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0]])>,
    2 /job:localhost/replica:0/task:0/device:GPU:2: <tf.Tensor: id=123200, shape=(8, 5), dtype=int64, numpy=
  array([[20593,  2560, 27139, 26397, 28367],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0]])>,
    3 /job:localhost/replica:0/task:0/device:GPU:3: <tf.Tensor: id=123206, shape=(8, 5), dtype=int64, numpy=
  array([[25292, 23995, 26283,  4891, 28905],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0],
         [    0,     0,     0,     0,     0]])>,
    4 /job:localhost/replica:0/task:0/device:GPU:4: <tf.Tensor: id=123214, shape=(0, 5), dtype=int64, numpy=array([], shape=(0, 5), dtype=int64)>,
    5 /job:localhost/replica:0/task:0/device:GPU:5: <tf.Tensor: id=123230, shape=(0, 5), dtype=int64, numpy=array([], shape=(0, 5), dtype=int64)>,
    6 /job:localhost/replica:0/task:0/device:GPU:6: <tf.Tensor: id=123246, shape=(0, 5), dtype=int64, numpy=array([], shape=(0, 5), dtype=int64)>,
    7 /job:localhost/replica:0/task:0/device:GPU:7: <tf.Tensor: id=123262, shape=(0, 5), dtype=int64, numpy=array([], shape=(0, 5), dtype=int64)>
  }}
```

Expected behaviour
--------------------

If I am not using ```pad_batch```, when ```batch_size = 8```, each GPU gets ```1 dataset``` each and things are good. But, as I am having ```dynamic batch size```, all batch sizes are not multiple of ```n_gpus=8```. Now, when i am trying to make sure that, ```batch_size``` is multiple of ```n_gpus```, things get messed up. 

If the last batch is 4, we pad 4 zeros to make it 8. and I expect it will be distribute to each GPU ( 1 dataset each ) and last 4 GPUs get zero padded rows each, so that they wont return ```nan``` and things are good. But, how could I achieve it. @guptapriya 

Might be an extension of https://github.com/tensorflow/tensorflow/issues/29975 . 

Sorry if I confuse you with long explanation .
"
34357,object_detection  dataset could not be checkpointed,"Hi, guys:
for TF1.14/1.15 used with tensorflow_model object_detction,

if I tried to save the state of the dataset for next restoring, I would encounter an issue.

> tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: Op[name: RandomHorizontalFlip/random_uniform/RandomUniform, type: RandomUniform] in function Dataset_map_process_fn_70 is stateful. Saving stateful functions is not supported yet.
         [[node SerializeIterator (defined at /local/mnt/workspace/zhanghao/download/tensorflow_model/research/object_detection/inputs.py:588) ]]
  (1) Invalid argument: Op[name: RandomHorizontalFlip/random_uniform/RandomUniform, type: RandomUniform] in function Dataset_map_process_fn_70 is stateful. Saving stateful functions is not supported yet.
         [[node SerializeIterator (defined at /local/mnt/workspace/zhanghao/download/tensorflow_model/research/object_detection/inputs.py:588) ]]
         [[FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp_1/_7416]]

And the try is just adding the code to ""<dir>/tensorflow_model/research/object_detection/inputs.py::train_input""

`  dataset = INPUT_BUILDER_UTIL_MAP['dataset_build'](
      train_input_config,
      transform_input_data_fn=transform_and_pad_input_data_fn,
      batch_size=params['batch_size'] if params else train_config.batch_size)

  iterator = dataset.make_initializable_iterator()
  tf.add_to_collection(tf.GraphKeys.TABLE_INITIALIZERS, iterator.initializer)

  saveable_obj = tf.data.experimental.make_saveable_from_iterator(iterator)

  tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, saveable_obj)

  return dataset`

And if I adopt ""tf.data.experimental.CheckpointInputPipelineHook"", got the same issue."
34355,"Error Massage: tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above."," - python version: 3.6.7
 - tensorflow-gpu version: 2.0.0 
 - keras version: 2.3.1 
 - cuDNN version:10.0 
 - CUDA version:10.0


mnist_mlp.py (https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) works perfectly but code which is given below gives me this error:

```
    tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
             [[node conv2d_7/convolution (defined at C:\Users\ACSECKIN\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\framework\ops.py:1751) ]] [Op:__inference_keras_scratch_graph_4815]
    
    Function call stack:
    keras_scratch_graph
```

Project code derived from https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/

code:

    ```
    from numpy import load
    from numpy import zeros
    from numpy import ones
    from numpy.random import randint
    from keras.optimizers import Adam
    from keras.initializers import RandomNormal
    from keras.models import Model
    from keras.models import Input
    from keras.layers import Conv2D
    from keras.layers import Conv2DTranspose
    from keras.layers import LeakyReLU
    from keras.layers import Activation
    from keras.layers import Concatenate
    from keras.layers import Dropout
    from keras.layers import BatchNormalization
    from keras.layers import LeakyReLU
    from matplotlib import pyplot
    
    # define the discriminator model
    def define_discriminator(image_shape):
    	# weight initialization
    	init = RandomNormal(stddev=0.02)
    	# source image input
    	in_src_image = Input(shape=image_shape)
    	# target image input
    	in_target_image = Input(shape=image_shape)
    	# concatenate images channel-wise
    	merged = Concatenate()([in_src_image, in_target_image])
    	# C64
    	d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)
    	d = LeakyReLU(alpha=0.2)(d)
    	# C128
    	d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
    	d = BatchNormalization()(d)
    	d = LeakyReLU(alpha=0.2)(d)
    	# C256
    	d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
    	d = BatchNormalization()(d)
    	d = LeakyReLU(alpha=0.2)(d)
    	# C512
    	d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
    	d = BatchNormalization()(d)
    	d = LeakyReLU(alpha=0.2)(d)
    	# second last output layer
    	d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)
    	d = BatchNormalization()(d)
    	d = LeakyReLU(alpha=0.2)(d)
    	# patch output
    	d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)
    	patch_out = Activation('sigmoid')(d)
    	# define model
    	model = Model([in_src_image, in_target_image], patch_out)
    	# compile model
    	opt = Adam(lr=0.0002, beta_1=0.5)
    	model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])
    	return model
    
    # define an encoder block
    def define_encoder_block(layer_in, n_filters, batchnorm=True):
    	# weight initialization
    	init = RandomNormal(stddev=0.02)
    	# add downsampling layer
    	g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)
    	# conditionally add batch normalization
    	if batchnorm:
    		g = BatchNormalization()(g, training=True)
    	# leaky relu activation
    	g = LeakyReLU(alpha=0.2)(g)
    	return g
    
    # define a decoder block
    def decoder_block(layer_in, skip_in, n_filters, dropout=True):
    	# weight initialization
    	init = RandomNormal(stddev=0.02)
    	# add upsampling layer
    	g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)
    	# add batch normalization
    	g = BatchNormalization()(g, training=True)
    	# conditionally add dropout
    	if dropout:
    		g = Dropout(0.5)(g, training=True)
    	# merge with skip connection
    	g = Concatenate()([g, skip_in])
    	# relu activation
    	g = Activation('relu')(g)
    	return g
    
    # define the standalone generator model
    def define_generator(image_shape=(256,256,3)):
    	# weight initialization
    	init = RandomNormal(stddev=0.02)
    	# image input
    	in_image = Input(shape=image_shape)
    	# encoder model
    	e1 = define_encoder_block(in_image, 64, batchnorm=False)
    	e2 = define_encoder_block(e1, 128)
    	e3 = define_encoder_block(e2, 256)
    	e4 = define_encoder_block(e3, 512)
    	e5 = define_encoder_block(e4, 512)
    	e6 = define_encoder_block(e5, 512)
    	e7 = define_encoder_block(e6, 512)
    	# bottleneck, no batch norm and relu
    	b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)
    	b = Activation('relu')(b)
    	# decoder model
    	d1 = decoder_block(b, e7, 512)
    	d2 = decoder_block(d1, e6, 512)
    	d3 = decoder_block(d2, e5, 512)
    	d4 = decoder_block(d3, e4, 512, dropout=False)
    	d5 = decoder_block(d4, e3, 256, dropout=False)
    	d6 = decoder_block(d5, e2, 128, dropout=False)
    	d7 = decoder_block(d6, e1, 64, dropout=False)
    	# output
    	g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)
    	out_image = Activation('tanh')(g)
    	# define model
    	model = Model(in_image, out_image)
    	return model
    
    # define the combined generator and discriminator model, for updating the generator
    def define_gan(g_model, d_model, image_shape):
    	# make weights in the discriminator not trainable
    	d_model.trainable = False
    	# define the source image
    	in_src = Input(shape=image_shape)
    	# connect the source image to the generator input
    	gen_out = g_model(in_src)
    	# connect the source input and generator output to the discriminator input
    	dis_out = d_model([in_src, gen_out])
    	# src image as input, generated image and classification output
    	model = Model(in_src, [dis_out, gen_out])
    	# compile model
    	opt = Adam(lr=0.0002, beta_1=0.5)
    	model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])
    	return model
    
    # load and prepare training images
    def load_real_samples(filename):
    	# load compressed arrays
    	data = load(filename)
    	# unpack arrays
    	X1, X2 = data['arr_0'], data['arr_1']
    	# scale from [0,255] to [-1,1]
    	X1 = (X1 - 127.5) / 127.5
    	X2 = (X2 - 127.5) / 127.5
    	return [X1, X2]
    
    # select a batch of random samples, returns images and target
    def generate_real_samples(dataset, n_samples, patch_shape):
    	# unpack dataset
    	trainA, trainB = dataset
    	# choose random instances
    	ix = randint(0, trainA.shape[0], n_samples)
    	# retrieve selected images
    	X1, X2 = trainA[ix], trainB[ix]
    	# generate 'real' class labels (1)
    	y = ones((n_samples, patch_shape, patch_shape, 1))
    	return [X1, X2], y
    
    # generate a batch of images, returns images and targets
    def generate_fake_samples(g_model, samples, patch_shape):
    	# generate fake instance
    	X = g_model.predict(samples)
    	# create 'fake' class labels (0)
    	y = zeros((len(X), patch_shape, patch_shape, 1))
    	return X, y
    
    # generate samples and save as a plot and save the model
    def summarize_performance(step, g_model, dataset, n_samples=3):
    	# select a sample of input images
    	[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)
    	# generate a batch of fake samples
    	X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)
    	# scale all pixels from [-1,1] to [0,1]
    	X_realA = (X_realA + 1) / 2.0
    	X_realB = (X_realB + 1) / 2.0
    	X_fakeB = (X_fakeB + 1) / 2.0
    	# plot real source images
    	for i in range(n_samples):
    		pyplot.subplot(3, n_samples, 1 + i)
    		pyplot.axis('off')
    		pyplot.imshow(X_realA[i])
    	# plot generated target image
    	for i in range(n_samples):
    		pyplot.subplot(3, n_samples, 1 + n_samples + i)
    		pyplot.axis('off')
    		pyplot.imshow(X_fakeB[i])
    	# plot real target image
    	for i in range(n_samples):
    		pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)
    		pyplot.axis('off')
    		pyplot.imshow(X_realB[i])
    	# save plot to file
    	filename1 = 'plot_%06d.png' % (step+1)
    	pyplot.savefig(filename1)
    	pyplot.close()
    	# save the generator model
    	filename2 = 'model_%06d.h5' % (step+1)
    	g_model.save(filename2)
    	print('>Saved: %s and %s' % (filename1, filename2))
    
    # train pix2pix models
    def train(d_model, g_model, gan_model, dataset, n_epochs=50, n_batch=1):
    	# determine the output square shape of the discriminator
    	n_patch = d_model.output_shape[1]
    	# unpack dataset
    	trainA, trainB = dataset
    	# calculate the number of batches per training epoch
    	bat_per_epo = int(len(trainA) / n_batch)
    	# calculate the number of training iterations
    	n_steps = bat_per_epo * n_epochs
    	# manually enumerate epochs
    	for i in range(n_steps):
    		# select a batch of real samples
    		[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)
    		# generate a batch of fake samples
    		X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)
    		# update discriminator for real samples
    		d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)
    		# update discriminator for generated samples
    		d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)
    		# update the generator
    		g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])
    		# summarize performance
    		print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))
    		# summarize model performance
    		if (i+1) % (bat_per_epo * 10) == 0:
    			summarize_performance(i, g_model, dataset)
    
    
    # load image data
    dataset = load_real_samples('fabric_256.npz')
    print('Loaded', dataset[0].shape, dataset[1].shape)
    # define input shape based on the loaded dataset
    image_shape = dataset[0].shape[1:]
    # define the models
    d_model = define_discriminator(image_shape)
    g_model = define_generator(image_shape)
    # define the composite model
    gan_model = define_gan(g_model, d_model, image_shape)
    # train model
    train(d_model, g_model, gan_model, dataset)

```
"
34354,tensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found,"hello = tf.constant('Hello, TensorFlow!')
----
Traceback (most recent call last):
  File ""<pyshell#5>"", line 1, in <module>
    hello = tf.constant('Hello, TensorFlow!')
  File ""C:\Users\yang kil ho\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 227, in constant
    allow_broadcast=True)
  File ""C:\Users\yang kil ho\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 235, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""C:\Users\yang kil ho\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 95, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""C:\Users\yang kil ho\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\eager\context.py"", line 492, in ensure_initialized
    self._context_handle = pywrap_tensorflow.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.


I updated my CUDA version to 10.1, but it doesn't work."
34353,Merging two RT graphs throughs an error,"I want to merge two RT graphs into a single graph. But while merging I'm getting error.
My code is as follows:

```
import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt

saved_model1 = ""/home/xavier2/saved_model/ssd_tomato_l1""
saved_model2 = ""/home/xavier2/saved_model/faster_rcnn_tomato_l2_grid_750x750""

def create_trt_inference_graph(graph_path):
    converter = trt.TrtGraphConverter(input_saved_model_dir=graph_path , 
        precision_mode=trt.TrtPrecisionMode.FP16)
    converted_graph_def = converter.convert()
    return converted_graph_def

def get_serialized_graph(graph_path):
    converted_graph_def = create_trt_inference_graph(graph_path)
    serial_def = converted_graph_def.SerializeToString()
    return serial_def

def get_frozen_graph(graph_path):
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(get_serialized_graph(graph_path))
    return graph_def

def rename_frame_name(graphdef, suffix):
    # Bug reported at https://github.com/tensorflow/tensorflow/issues/22162#issuecomment-428091121
    for n in graphdef.node:
        if ""while"" in n.name:
            if ""frame_name"" in n.attr:
                n.attr[""frame_name""].s = str(n.attr[""frame_name""]).replace(""while_context"",""while_context"" + suffix).encode('utf-8')

l1_graph = tf.Graph()
with l1_graph.as_default():
    trt_graph1 = get_frozen_graph(saved_model1)
    [tf_input1, tf_scores1, tf_boxes1, tf_classes1, tf_num_detections1] = tf.import_graph_def(trt_graph1, 
            return_elements=['import/image_tensor:0', 'import/detection_scores:0', 'import/detection_boxes:0', 'import/detection_classes:0','import/num_detections:0'])

connected_graph = tf.Graph()
with connected_graph.as_default():
    l1_graph_def = l1_graph.as_graph_def()
    g1name = 'ved'
    rename_frame_name(l1_graph_def, g1name)
    tf.import_graph_def(l1_graph_def, name=g1name)
    trt_graph2 = get_frozen_graph(saved_model2)
    g2name = 'level2'
    rename_frame_name(trt_graph2, g2name)
    [tf_scores, tf_boxes, tf_classes, tf_num_detections] = tf.import_graph_def(trt_graph2,
            return_elements=['import/detection_scores:0', 'import/detection_boxes:0', 'import/detection_classes:0','import/num_detections:0'])
```

It throws following error:

```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py"", line 427, in import_graph_def
    graph._c_graph, serialized, options)  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot add function 'TRTEngineOp_1_native_segment' because a different function with the same name already exists.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 10, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py"", line 431, in import_graph_def
    raise ValueError(str(e))
ValueError: Cannot add function 'TRTEngineOp_1_native_segment' because a different function with the same name already exists.
```

My specs are:

Tensorflow: 1.14.0
Python: 3.6.8
Platform: Ubuntu 18.04.2 LTS (GNU/Linux 4.9.140-tegra aarch64)"
34351,tf-nightly: Cannot import name 'tensorflow' from 'opt_einsum.backends',"`pip install tf-nightly` --> `pip install tf-nightly-gpu`, or in reverse order, fails in a fresh Anaconda virtual environment w/ error shown below - install/uninstall steps also shown. Any workarounds?

<hr>

**Installation**:

 1. Clone Anaconda base environment (which doesn't have TF or Keras) as `tf3_env`
 2. Delete any files/folders in env w/ name substring ""tensorflow"", ""nightly"", or ""keras"" (just in case)
 3. Run Anaconda Powershell Prompt:
     - `conda activate tf3_env`
     - `conda clean --all` (removes TF, Keras, cudatoolkit, cudnn, others from Anaconda/pkgs)
     - `pip uninstall grpcio`
     - `pip install grpcio` (tf-nightly asks for >=1.24)
     - `pip install tf-nightly-gpu`
 4. Run Spyder, `import tensorflow` --> ERR
 5. Run Anaconda Powershell Prompt:
     - `pip install keras`
     - `pip install tf-nightly`
 6. Run Spyder, `import tensorflow` --> ERR

<hr>

**Environment**: 
 - Win-10 OS, GTX 1070, i7-7700HQ 2.8 GHz CPU
 - CUDA 10.1.243, cuDNN 7.6.4, Python 3.7.5, Anaconda 11/2019, Spyder 3.3.6

<hr>

**ERR: Full Error Trace** (error is printed repeatedly and can only be stopped by restarting the kernel -- restarting the kernel only stops the error, but doesn't restart the kernel, unless restarted a second time)

```python
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\IPython\extensions\autoreload.py"", line 538, in post_execute_hook
  _, pymtime = self._reloader.filename_and_mtime(sys.modules[modname])
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\IPython\extensions\autoreload.py"", line 184, in filename_and_mtime
  if not hasattr(module, '__file__') or module.__file__ is None:
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
  module = self._load()
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
  module = _importlib.import_module(self.__name__)
File ""D:\Anaconda\envs\tf3_env\lib\importlib\__init__.py"", line 127, in import_module
  return _bootstrap._gcd_import(name[level:], package, level)
File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\__init__.py"", line 46, in <module>
  from ._api.v2 import compat
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\__init__.py"", line 39, in <module>
  from . import v1
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\v1\__init__.py"", line 32, in <module>
  from . import compat
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\__init__.py"", line 39, in <module>
  from . import v1
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\v1\__init__.py"", line 29, in <module>
  from tensorflow._api.v2.compat.v1 import app
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\__init__.py"", line 39, in <module>
  from . import v1
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\v1\__init__.py"", line 32, in <module>
  from . import compat
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\__init__.py"", line 39, in <module>
  from . import v1
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\v1\__init__.py"", line 35, in <module>
  from tensorflow._api.v2.compat.v1 import debugging
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\v1\debugging\__init__.py"", line 10, in <module>
  from . import experimental
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\_api\v2\compat\v1\debugging\experimental\__init__.py"", line 10, in <module>
  from tensorflow.python.debug.lib.dumping_callback import disable_dump_debug_info
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\python\debug\lib\dumping_callback.py"", line 31, in <module>
  from tensorflow.python.debug.lib import debug_events_writer
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\python\debug\lib\debug_events_writer.py"", line 24, in <module>
  from tensorflow.python import _pywrap_debug_events_writer
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
  module = self._load()
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
  module = _importlib.import_module(self.__name__)
File ""D:\Anaconda\envs\tf3_env\lib\importlib\__init__.py"", line 127, in import_module
  return _bootstrap._gcd_import(name[level:], package, level)
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\python\__init__.py"", line 83, in <module>
  from tensorflow.python.ops.standard_ops import *
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\python\ops\standard_ops.py"", line 48, in <module>
  from tensorflow.python.ops.special_math_ops import *
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\tensorflow_core\python\ops\special_math_ops.py"", line 30, in <module>
  import opt_einsum
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\opt_einsum\__init__.py"", line 9, in <module>
  from .contract import contract, contract_path, contract_expression
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\opt_einsum\contract.py"", line 10, in <module>
  from . import backends
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\opt_einsum\backends\__init__.py"", line 7, in <module>
  from .dispatch import (get_func, has_einsum, has_tensordot, build_expression, evaluate_constants, has_backend)
File ""D:\Anaconda\envs\tf3_env\lib\site-packages\opt_einsum\backends\dispatch.py"", line 13, in <module>
  from . import tensorflow as _tensorflow

ImportError: cannot import name 'tensorflow' from 'opt_einsum.backends' 
(D:\Anaconda\envs\tf3_env\lib\site-packages\opt_einsum\backends\__init__.py)
```
 "
34350,ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.,"when I convert pre-trained mobilenet model to tflite, there is a error:
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/project/pyenv/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py"", line 400, in convert
    raise ValueError(""This converter can only convert a single ""
ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.
```

my code is

```python 
import tensorflow as tf
from tensorflow.keras.applications.mobilenet import MobileNet
model = MobileNet(weights='imagenet')
saved_model_path = ""./saved_models/{}"".format(int(time.time()))
tf.keras.experimental.export_saved_model(model, saved_model_path)
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()
```

my os is 
Ubuntu 16.04.6 LTS
"
34349,Serialization support for RaggedTensor,"**System information**
- TensorFlow version (you are using):2.0.0
- Are you willing to contribute it (Yes/No):No

**Describe the feature and the current behavior/state.**
Currently, there is no support for serializing RaggedTensors similiraly to tf.io.serialize_tensor

**Will this change the current api? How?**
This shouldn't affect any other functionality

**Who will benefit with this feature?**
Users of ragged tensors wishing to use TFrecords
"
34348,save method shows buggy/confusing behaviour,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NN
- TensorFlow installed from (source or binary): NN
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source): NN
- GCC/Compiler version (if compiling from source): NN
- CUDA/cuDNN version: NN
- GPU model and memory: NN

**Describe the current behavior**
tf.keras.Model.save shows confusing behavior with the save_format argument.
See [gist](https://colab.research.google.com/gist/nikochiko/7a624ae90563b831d5229eb0ee5b0d41/tf_model_save_buggy.ipynb).
Even when save_format is set as  'tf', the model is saved as 'h5' if the filepath ends in suffix '.h5'
Also, it defaults random string arguments to tf format. 

**Describe the expected behavior**
The value of the save_format argument should be the format of the saved file irrespective of the filepath. 
Or else, there should be a boolean argument like 'save_as_h5' instead.

**Code to reproduce the issue**
https://colab.research.google.com/gist/nikochiko/7a624ae90563b831d5229eb0ee5b0d41/tf_model_save_buggy.ipynb#scrollTo=1H73RxH5sTgl

**Other info / logs**
[Source code](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/network.py#L923-L975)
[Outdated documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save)
Updated docs for current behavior in [PR](https://github.com/tensorflow/tensorflow/pull/34347/files)

**More details**
model.save_weights handles it better: see [gist](https://colab.research.google.com/gist/nikochiko/ff693562546dbda5d5868ec7e7d75bad/tf_save_weights.ipynb)"
34346,ImageDataGenerator does not work with tpu,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): tensorflow from colab
- TensorFlow version (use command below): 1.15
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: None
- GPU model and memory: None

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Currently it is not possible to use fit_generator. Instead we need to use .fit function.

Using ImageDataGenetor, I tried to fit the model but I got an issue :
```
AssertionError                            Traceback (most recent call last)

<ipython-input-18-46d4a00b20c5> in <module>()
      5      train_gen.flow(X_train, y_train, batch_size=batch_size), # tf.data.Dataset.from_tensor_slices((X_train[:2000], y_train[:2000])).batch(batch_size).repeat(), #
      6     steps_per_epoch=  len(X_train)//batch_size,
----> 7     epochs=3,
      8      )

2 frames

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    725         max_queue_size=max_queue_size,
    726         workers=workers,
--> 727         use_multiprocessing=use_multiprocessing)
    728 
    729   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    617         validation_split=validation_split,
    618         shuffle=shuffle,
--> 619         epochs=epochs)
    620     if not dist_utils.is_distributing_by_cloning(model):
    621       with model._distribution_strategy.scope():

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in _distribution_standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, validation_split, shuffle, epochs, allow_partial_batch)
   2312         x = ds.batch(batch_size, drop_remainder=drop_remainder)
   2313       else:
-> 2314         assert isinstance(x, dataset_ops.DatasetV2)
   2315         training_utils.validate_dataset_input(x, y, sample_weight,
   2316                                               validation_split)

AssertionError: 
```


**Describe the expected behavior**
from the keras documentation, it should work. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Here the link to the colab code : https://colab.research.google.com/drive/1bdNfb127n-VI6ab9_sUTOgRzkil88a9n
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Does that mean we cannot use generator with tensorflow 1.15 ? "
34345,TFLite allocate tensors fails: (CONCATENATION) failed to prepare after input shape resize,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **OSX**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**
- TensorFlow installed from (source or binary): **binary** 
- TensorFlow version (use command below):  **2.1.0-dev20191113**
- Python version: **3.7.4**

**Describe the current behavior**

I create a fully convolutional simple model using tf.keras API.
I convert the model to TFlite.
I resize the shape of the input tensor, but when I ask the interpreter to allocate the tensors, I get this error:

`RuntimeError: tensorflow/lite/kernels/concatenation.cc:74 t->dims->data[d] != t0->dims->data[d] (24 != 52)Node number 12 (CONCATENATION) failed to prepare.
`

**Describe the expected behavior**

I expect the interpreter to be able to resize all the tensors.
Below you can find the simple model I've built to reproduce this issue.
What I've notice is that without the `Concatenate` op the allocation works correctly.

**Code to reproduce the issue**

```
from tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate
from tensorflow.keras import Model, layers
from tensorflow import keras
import tensorflow as tf

# Encoder
encoder_input = keras.Input(shape=(28, 28, 1), name='img')
conv1 = layers.Conv2D(16, 3, activation='relu')(encoder_input)
conv2 = layers.Conv2D(32, 3, activation='relu')(conv1)
max1 = layers.MaxPooling2D(3)(conv2)
conv3 = layers.Conv2D(32, 3, activation='relu')(max1)
conv4 = layers.Conv2D(16, 3, activation='relu')(conv3)
encoder_output = layers.GlobalMaxPooling2D()(conv4)
encoder = keras.Model(encoder_input, encoder_output, name='encoder')

# Decoder
resh = layers.Reshape((4, 4, 1))(encoder_output)
upconv1 = layers.Conv2DTranspose(16, 3, activation='relu')(resh)
upconv2 = layers.Conv2DTranspose(32, 3, activation='relu')(upconv1)
upsample = layers.UpSampling2D(3)(upconv2)
conc = layers.Concatenate()([conv2,upsample])
conv5 = layers.Conv2DTranspose(16, 3, activation='relu')(conc)
decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(conv5)

# autoencoder
autoencoder = keras.Model(encoder_input, decoder_output, name='autoencoder')

# conversion
converter = tf.lite.TFLiteConverter.from_keras_model(autoencoder)
tflite_model = converter.convert()
open(""model.tflite"", ""wb"").write(tflite_model)

# inference
interpreter = tf.lite.Interpreter(model_path=""model.tflite"")
input_details = interpreter.get_input_details()
interpreter.resize_tensor_input(input_details[0][""index""],[1,56,56,1])
interpreter.allocate_tensors()
```
"
34344,tf2.0: tf.image.resize_with_pad fails with “using a `tf.Tensor` as a Python `bool” with tf.keras.Input,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0
- Python version: 3.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA (CPU)
- GPU model and memory: NA (CPU)

**Describe the current behavior**
With tensorflow 2.0, `resize_with_pad` does not seem to work when `tf.keras.Input` is given as an input, although `resize` works nicely.

**Describe the expected behavior**
There should not be an error.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import tensorflow as tf

# with tensorflow constant
img_arr = tf.zeros([1,100,100,3])
tf.image.resize(img_arr, [224, 224]) # works
tf.image.resize_with_pad(img_arr, 224, 224) # works

# with keras input
img_arr = tf.keras.Input(shape = (100,100,3))
tf.image.resize(img_arr, [224, 224]) # works
tf.image.resize_with_pad(img_arr, 224, 224) # doesn't work
```


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
---------------------------------------------------------------------------
OperatorNotAllowedInGraphError            Traceback (most recent call last)
<ipython-input-29-aee2cbd13944> in <module>
      9 img_arr = tf.keras.Input(shape = (100,100,3))
     10 tf.image.resize(img_arr, [224, 224]) # works
---> 11 tf.image.resize_with_pad(img_arr, 224, 224) # doesn't work

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in resize_image_with_pad_v2(image, target_height, target_width, method, antialias)
   1472 
   1473   return _resize_image_with_pad_common(image, target_height, target_width,
-> 1474                                        _resize_fn)
   1475 
   1476 

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _resize_image_with_pad_common(image, target_height, target_width, resize_fn)
   1337       raise ValueError('\'image\' must have either 3 or 4 dimensions.')
   1338 
-> 1339     assert_ops = _CheckAtLeast3DImage(image, require_static=False)
   1340     assert_ops += _assert(target_width > 0, ValueError,
   1341                           'target_width must be > 0.')

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _CheckAtLeast3DImage(image, require_static)
    226         check_ops.assert_positive(
    227             array_ops.shape(image),
--> 228             [""all dims of 'image.shape' ""
    229              'must be > 0.']),
    230         check_ops.assert_greater_equal(

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/check_ops.py in assert_positive(x, data, summarize, message, name)
    266           'x (%s) = ' % name, x]
    267     zero = ops.convert_to_tensor(0, dtype=x.dtype)
--> 268     return assert_less(zero, x, data=data, summarize=summarize)
    269 
    270 

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/check_ops.py in assert_less(x, y, data, summarize, message, name)
    865       ]
    866     condition = math_ops.reduce_all(math_ops.less(x, y))
--> 867     return control_flow_ops.Assert(condition, data, summarize=summarize)
    868 
    869 

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/util/tf_should_use.py in wrapped(*args, **kwargs)
    196   """"""
    197   def wrapped(*args, **kwargs):
--> 198     return _add_should_use_warning(fn(*args, **kwargs))
    199   return tf_decorator.make_decorator(
    200       fn, wrapped, 'should_use_result',

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py in Assert(condition, data, summarize, name)
    147   """"""
    148   if context.executing_eagerly():
--> 149     if not condition:
    150       xs = ops.convert_n_to_tensor(data)
    151       data_str = [_summarize_eager(x, summarize) for x in xs]

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in __bool__(self)
    763       `TypeError`.
    764     """"""
--> 765     self._disallow_bool_casting()
    766 
    767   def __nonzero__(self):

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _disallow_bool_casting(self)
    532     else:
    533       # Default: V1-style Graph execution.
--> 534       self._disallow_in_graph_mode(""using a `tf.Tensor` as a Python `bool`"")
    535 
    536   def _disallow_iteration(self):

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _disallow_in_graph_mode(self, task)
    521     raise errors.OperatorNotAllowedInGraphError(
    522         ""{} is not allowed in Graph execution. Use Eager execution or decorate""
--> 523         "" this function with @tf.function."".format(task))
    524 
    525   def _disallow_bool_casting(self):

OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
```"
34341,Adam weight decay optimizer for TF 2.0,"**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
I am looking to migrate some optimization code I forked from BERT to TF 2.0. The optimization involves the Adam weight decay optimizer and is implemented in TF 1.15 according to
https://github.com/artitw/text2class/blob/master/text2class/optimization.py

**Will this change the current api? How?**
For the TF 2.0 API, we can specify the Adam optimizer like below. However, it is unclear how the weight decay component can be implemented as it requires keeping track of the global step. 
```
model.compile(optimizer=tf.keras.optimizers.Adam(
    learning_rate=2e-5,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-6,),
                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=""acc"")])
```

**Who will benefit with this feature?**
Researchers and engineers working with BERT and BERT-based models will benefit. The original BERT repo has almost 20k stars, but it has yet to be migrated to TF 2.0.

**Any Other info.**
If the capability to achieve what I describe above already exists, please let me know!
"
34340,Image preprocessing for transfer learning confusing,"I'm really confused about what preprocessing to apply on image data when working with pre-trained models for transfer learning. Of course, this is very specific for each model, but I thought Keras brought some disambiguation by bringing the _**preprocess_input**_ function. By using it, users should normally not worry about how to transform an image before pushing it into the pre-trained model.

I recently tried to use one of such model provided in Tensorflow 2.Keras. Even if this function exists, the related documentation is, let's say, minimal:
https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/preprocess_input

But what is very disturbing is that this function is not used at all in the provided tutorials. For example, this one (https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub) pre-processes images by dividing raw pixels by 255.

> image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)

In this other tutorial (https://www.tensorflow.org/tutorials/images/transfer_learning), pre-processing is done like this: 

> image = (image/127.5) - 1

However, both tutorial are supposed to use a **mobilenet_v2** model pre-trained on _ImageNet_

This makes **3 different ways to process an image**, without any helping documentation to shed some light on what appears to me like ""black magic"". Any help would be welcome, along with an appropriate documentation of course.
"
34339,TensorRT not working due to eager execution,"I'm trying to convert my saved model to tensorRT but I'm failing due to following error:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 911, in __init__
    assert context.executing_eagerly()
AssertionError
```

Here, is my code
```
from tensorflow.python.compiler.tensorrt import trt_convert

conversion_params = trt_convert.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=trt_convert.TrtPrecisionMode.FP16, max_batch_size=1, max_workspace_size_bytes=8000000000)

trt_converter = trt_convert.TrtGraphConverterV2(input_saved_model_dir='/home/xavier2/apple_trt_l1/nonRT',  conversion_params=conversion_params)
```

Here are my specs:
Tensorflow version: 1.14.0
Platform: NVIDIA Jetson AGX Xavier developer kit
Python: 3.6.8
"
34338,not had an installation in the kali linux ova filed os on the python3.8 version,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
had said that the suitable version was not available on doing pip install tensorflow."
34336,Example where softmax_cross_entropy_with_logits_v2 fails but softmax_cross_entropy_with_logits works,"**System information**
- Have I written custom code: ?
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- Python version: Python 3.6.5 :: Anaconda, Inc.
- CUDA/cuDNN version: CPU
- GPU model and memory: CPU

**Describe the current behavior**
While implementing this paper [1] I found that using `softmax_cross_entropy_with_logits` leads to convergence and the correct results, whereas `softmax_cross_entropy_with_logits_v2` fails.
[1]: https://arxiv.org/abs/1906.07748

**Describe the expected behavior**
I suppose that `softmax_cross_entropy_with_logits_v2` should work just as `softmax_cross_entropy_with_logits`.

**Code to reproduce the issue**
Here a notebook:
https://github.com/Rassibassi/claude/blob/master/examples/tf_AutoEncoderForProbabilisticShapingAndAwgn.ipynb

In cell [8], just uncomment this line
```
# loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=s, logits=dec) # v2 does not work :(
```
and run for the code to fail, yet with `softmax_cross_entropy_with_logits` the result looks fine.


With `softmax_cross_entropy_with_logits`
```
epoch: 5 - outLossHat: -3.35 - always 1: 1.0
epoch: 10 - outLossHat: -4.08 - always 1: 1.0
epoch: 15 - outLossHat: -4.38 - always 1: 1.0
epoch: 20 - outLossHat: -4.47 - always 1: 1.0
epoch: 25 - outLossHat: -4.51 - always 1: 1.0
epoch: 30 - outLossHat: -4.51 - always 1: 1.0
epoch: 35 - outLossHat: -4.53 - always 1: 1.0
epoch: 40 - outLossHat: -4.53 - always 1: 1.0
epoch: 45 - outLossHat: -4.53 - always 1: 1.0
epoch: 50 - outLossHat: -4.53 - always 1: 1.0
```

with `softmax_cross_entropy_with_logits_v2`
```
epoch: 5 - outLossHat: -3.41 - always 1: 1.0
epoch: 10 - outLossHat: -3.7 - always 1: 1.0
epoch: 15 - outLossHat: -0.603 - always 1: 1.0
epoch: 20 - outLossHat: -0.00371 - always 1: 1.0
epoch: 25 - outLossHat: -0.0017 - always 1: 1.0
epoch: 30 - outLossHat: -0.00103 - always 1: 1.0
epoch: 35 - outLossHat: -0.000673 - always 1: 1.0
epoch: 40 - outLossHat: -0.00049 - always 1: 1.0
epoch: 45 - outLossHat: -0.000398 - always 1: 1.0
epoch: 50 - outLossHat: -0.000311 - always 1: 1.0
```
"
34335,[TF 2.0] Nested Gradient Tape - unconnected graphs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: MacOS 10.15.1
- TensorFlow installed from binary (pip 19.3.1)
- TensorFlow version: v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version: Python 3.6.5

**Describe the current behavior**
A copy of my model (model_copy) should be trained one step, then I need my meta_model to be trained with the loss of my model_copy. It seems, that the graphs are unconnected.
It only works, if I use the meta_model for the training step.

**Describe the expected behavior**
I would expect, that model_copy is known to both gradient tapes and can be used w/o using meta_model.

**Code to reproduce the issue**
```python
import tensorflow as tf
import tensorflow.keras.backend as keras_backend
import tensorflow.keras as keras

class MetaModel(keras.Model):
    def __init__(self):
        super().__init__()
        self.hidden1 = keras.layers.Dense(5, input_shape=(1,))
        self.out = keras.layers.Dense(1)
    def forward(self, x):
        x = keras.activations.relu(self.hidden1(x))
        x = self.out(x)
        return x

def copy_model(model, x):
    copied_model = MetaModel()
    copied_model.forward(x)
    copied_model.set_weights(model.get_weights())
    return copied_model

def compute_loss(model, x, y):
    logits = model.forward(x)  # prediction of my model
    mse = keras_backend.mean(keras.losses.mean_squared_error(y, logits))  # compute loss between prediciton and label/truth
    return mse, logits

optimizer_outer = keras.optimizers.Adam()
alpha = 0.01
with tf.GradientTape() as g:
    # meta_model to learn in outer gradient tape
    meta_model = MetaModel()
    # inputs for training
    x = tf.constant(3.0, shape=(1, 1, 1))
    y = tf.constant(3.0, shape=(1, 1, 1))

    meta_model.forward(x)
    model_copy = copy_model(meta_model, x)
    with tf.GradientTape() as gg:
        loss, _ = compute_loss(model_copy, x, y)
        gradients = gg.gradient(loss, model_copy.trainable_variables)
        k = 0
        for layer in range(len(model_copy.layers)):
            """""" If I use meta-model for updating, this works """"""
            # model_copy.layers[layer].kernel = tf.subtract(meta_model.layers[layer].kernel,
            #                                               tf.multiply(alpha, gradients[k]))
            # model_copy.layers[layer].bias = tf.subtract(meta_model.layers[layer].bias,
            #                                             tf.multiply(alpha, gradients[k + 1]))

            """""" If I use model-copy for updating instead, gradients_meta always will be [None,None,...]""""""
            model_copy.layers[layer].kernel = tf.subtract(model_copy.layers[layer].kernel,
                                                          tf.multiply(alpha, gradients[k]))
            model_copy.layers[layer].bias = tf.subtract(model_copy.layers[layer].bias,
                                                        tf.multiply(alpha, gradients[k + 1]))

            k += 2

    # calculate loss of model_copy
    test_loss, _ = compute_loss(model_copy, x, y)
    # build gradients for meta_model update
    gradients_meta = g.gradient(test_loss, meta_model.trainable_variables)
    """""" gradients always None !?!!11 elf """"""
    optimizer_outer.apply_gradients(zip(gradients_meta, meta_model.trainable_variables))
```

**Other info / logs**
Is it intended to work as above? This would force me not to be able to use a different optimizer in the inner loop, as the networks need somehow to be connected.
"
34334,"default installed version of tensorflow lite arduino library is pre-compiled, causing confusing error reports","hiya @petewarden ive been re-porting my demos (hooray) for Arduino boards
https://learn.adafruit.com/tensorflow-lite-for-edgebadge-kit-quickstart

right now when folks install the TensorFlow library it defaults to the pre-compiled version, which causes very obscure errors about register arguments if they are not using the exact same processor.

https://learn.adafruit.com/tensorflow-lite-for-edgebadge-kit-quickstart/troubleshooting#uses-vfp-register-arguments-and-libtensorflowlite-dot-a-does-not-error-10-2

please make the default non-pre-compiled...Arduino IDE has a huge collection of supported boards, and as is, will confuse a lot of people :)"
34333,Tensorflow 1.14 GPU hanging when running models,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code: yes, I have coded an AEGAN that used to work but no longer.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Conda install tensorflow-gpu==1.14.0
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:Installed by Anaconda, unknown
- GPU model and memory: Geforce GTX 1070 8G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

N/A, issue is described exactly by this stackoverflow question:
https://stackoverflow.com/questions/47272869/tensorflow-stops-training-and-hanged-on-gpu-randomly/58887825#58887825
"
34332,AutoCastVariable.assign returns wrapped variable instead of casted version,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0, 2.1-nightly
- Python version: 3.7

**Describe the current behavior**

`AutoCastVariable` variable forwards `assign` and `scatter` to the underlying `float32` variable:
https://github.com/tensorflow/tensorflow/blob/cee2a43b8184e92ba26ec0e3d6e00a3f8ca6e3c8/tensorflow/python/keras/mixed_precision/experimental/autocast_variable.py#L187-L188
Thus, the return value of `assign` methods with `read_value=True` is a normal `tf.Variable` and not an `AutoCastVariable`. This means that calculations directly depending on the assign operation, might run in `float32` instead of `float16`, or am I missing something?

**Describe the expected behavior**
`AutoCastVariable.assign*` should return an `AutoCastVariable` variable instead `tf.Variable` so that the `dtype` is preserved.

@reedwm Is this intended behaviour?

**Code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow.python.keras.mixed_precision.experimental import autocast_variable

var = tf.Variable(0., dtype=tf.float32)
var = autocast_variable.AutoCastVariable(var)

with tf.compat.v1.get_default_graph()._enable_auto_casting_variables(tf.float16):
    assert var.dtype == tf.float16
    # assign should return an AutoCastVariable but returns tf.Variable
    var_assign = var.assign(5.)
    assert not isinstance(var_assign, autocast_variable.AutoCastVariable)
    assert var_assign.dtype == tf.float32
```"
34330,TF World '19 Talk: Facemesh with TF.js in the browser,"Just saw the wonderful Unlocking the power of ML for your JavaScript applications with TensorFlow.js talk, link: https://youtu.be/kKp7HLnPDxc.

I'd also like to try the code of using Facemesh in the browser. Following the example code in the video at 25:48, I went to https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh. 

However, I get the message ""Failed to resolve the requested file."" 

Will you please help me find the Facemesh model?"
34329,Tensorflow TensorRT: Could not load dynamic library 'libnvinfer.so.5',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): Tensorflow 2.0
- Python version: 3.7.4
- CUDA/cuDNN version: 10.0
- GPU model and memory: V100

**Describe the current behavior**
_(Note - also posted to NVIDIA developer forums)_

I'm following the Tensorflow 2.0 [instructions](https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#usage-example) for optimizing a SavedModel file with TensorRT. I have my Tensorflow model saved to models/mymodel. When I run the following:

```
from tensorflow.python.compiler.tensorrt import trt_convert as trt
converter = trt.TrtGraphConverterV2(input_saved_model_dir='models/mymodel')
converter.convert()
converter.save('models/mymodel_tensorrt')
```

I get the error (from second line):

> 2019-11-14 17:29:07.427738: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.5'; dlerror: libnvinfer.so.5: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/home/ubuntu/src/cntk/bindings/python/cntk/libs:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:
2019-11-14 17:29:07.427783: F tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:49] getInferLibVersion symbol not found.
Aborted (core dumped)

Looking at the thread [here](https://devtalk.nvidia.com/default/topic/1036527/tensorrt/importerror-libnvinfer-so-4-cannot-open-shared-object-file-no-such-file-or-directory/), it seems like it may be an issue with needing to set LD_LIBRARY_PATH.

However, when I google setting the LD_LIBRARY_PATH, it seems only necessary when manually installing TensorRT from tar. I have not built/installed TensorRT separately and am just using what's bundled in with Tensorflow 2.0. 

**Describe the expected behavior**
The converter should run and save optimized model to 'models/mymodel_tensorrt'"
34328,prepare_attention API of tensorflow 1.0.0 equivalent in tensorflow 1.13.1,"What is the equivalent API in tensorflow 1.13.1 for prepare_attention(tf.contrib.seq2seq.prepare_attention) of tensorflow 1.0.0?

Thanks!!!"
34326,tf.signal.mfccs_from_log_mel_spectrograms caused internal error in converted TensorFlow Lite model,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: OnePlus A3010
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 2.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.26.1
- **GCC/Compiler version (if compiling from source)**:  Apple clang version 11.0.0 (clang-1100.0.33.12)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Hello everyone,

I have tried to extract MFCC features from audio signal using tf.signal.mfccs_from_log_mel_spectrograms. My python code runs pretty well, but when I converted it to a TensorFlow Lite model, and used it on android phone. I got the following error:

""
...
...
Caused by: java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/strided_slice.cc ellipsis_mask is not implemented yet.
    Node number 20 (STRIDED_SLICE) failed to prepare.
...
...
""

I am pretty sure the error was caused by tf.signal.mfccs_from_log_mel_spectrograms, since I did not directly use ""strided_slice"" directly in my code, and in the visualized graph of the html file obtained by [visualization tool](https://www.tensorflow.org/lite/guide/faq) , I can only find the context of strided_slice like: 

""
...
161 | StatefulPartitionedCall/model_1/lambda/mfccs_from_log_mel_spectrograms_2/dct/strided_slice | COMPLEX64 | [] | 59 | {u'quantized_dimension': 0, u'details_type': u'NONE'}
-- | -- | -- | -- | -- | --
162 | StatefulPartitionedCall/model_1/lambda/mfccs_from_log_mel_spectrograms_2/dct/strided_slice/stack | INT32 | [2] | 136 | {u'quantized_dimension': 0, u'details_type': u'NONE'}
163 | StatefulPartitionedCall/model_1/lambda/mfccs_from_log_mel_spectrograms_2/dct/strided_slice/stack_1 | INT32 | [2] | 177 | {u'quantized_dimension': 0, u'details_type': u'NONE'}
164 | StatefulPartitionedCall/model_1/lambda/mfccs_from_log_mel_spectrograms_2/dct/strided_slice/stack_2 | INT32 | [2] | 63 | {u'quantized_dimension': 0, u'details_type': u'NONE'}
...
""

In the same graph file, I also found
""
22 | [157, 162, 163, 164] | [161] | {u'begin_mask': 2, u'ellipsis_mask': 1, u'end_mask': 0, u'new_axis_mask': 0, u'shrink_axis_mask': 0}
-- | -- | -- | --
""

So I think tf.signal.mfccs_from_log_mel_spectrograms trigged a dct, following a strided_slice, whose ""ellipsis_mask"" was set to 1, which is not implemented in TensorFlow Lite. 

But I truly don't know how to avoid that error, actually, I got the same error, when using tf.signal.stft, also tf.signal.frame. They all called ""tf.strided_slice"" implicitly and set ""ellipsis_mask"" to 1.

By the way, the dimension of input tensor(log of mel spectrograms) to tf.signal.mfccs_from_log_mel_spectrograms was (None, 64, 20). Please kindly help me!

Regards,
Simon







### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
34324,Complex dtype support tflite converter,"Are complex dtypes planned to be supported in the experimental converter? using nightly 1108 build and it is throwing an error. This is super useful for MFCC calculations.

```python
def generate_mfcc_features(audio_array):
    sample_rate = 16000.0

    # A 1024-point STFT with frames of 64 ms and 75% overlap.
    stfts = tf.signal.stft(audio_array, frame_length=1024, frame_step=256,fft_length=1024)
    spectrograms = tf.abs(stfts)
#     spectrograms = tf.cast(stfts + 1, tf.float32)

    # Warp the linear scale spectrograms into the mel-scale.
    num_spectrogram_bins = stfts.shape[-1]
    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80
    linear_to_mel_weight_matrix = tf.cast(tf.signal.linear_to_mel_weight_matrix(num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz, upper_edge_hertz), tf.float32)
    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)
    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))

    # Compute a stabilized log to get log-magnitude mel-scale spectrograms.
    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)

    # Compute MFCCs from log_mel_spectrograms and take the first 13.
    return tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :13]

cnn = tf.keras.Sequential([
    tf.keras.layers.Lambda(generate_mfcc_features, input_shape=(40000,)),
    tf.keras.layers.Conv1D(filters=32, kernel_size=10, strides=2, padding='same', activation='relu')
])
```

Error:
```
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-295-26886e1134e8> in <module>()
      8 converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]
      9 converter.target_spec.supported_ops = set([tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS])
---> 10 tflite_model_enc = converter.convert()
     11 
     12 print('Converting decoder')

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py in convert(self)
    462         input_tensors=input_tensors,
    463         output_tensors=output_tensors,
--> 464         **converter_kwargs)
    465 
    466     if self._is_calibration_quantize():

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    455       input_data.SerializeToString(),
    456       debug_info_str=debug_info_str,
--> 457       enable_mlir_converter=enable_mlir_converter)
    458   return data
    459 

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    201       stdout = _try_convert_to_unicode(stdout)
    202       stderr = _try_convert_to_unicode(stderr)
--> 203       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    204   finally:
    205     # Must manually cleanup files.

ConverterError: See console for info.
2019-11-15 15:12:34.503239: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2019-11-15 15:12:34.503275: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2019-11-15 15:12:35.451940: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2019-11-15 15:12:35.452051: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2019-11-15 15:12:35.452072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2019-11-15 15:12:36.763021: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.
2019-11-15 15:12:36.763078: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.
2019-11-15 15:12:36.923578: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-15 15:12:36.930986: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294685000 Hz
2019-11-15 15:12:36.931794: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb1a6ac800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-15 15:12:36.931821: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-15 15:12:36.933506: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2019-11-15 15:12:36.933531: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-15 15:12:36.933572: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (VXML-Ubuntu): /proc/driver/nvidia/version does not exist
loc(callsite(""sequential_5/lambda_4/mfccs_from_log_mel_spectrograms/dct/strided_slice""(""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/ops/signal/dct_ops.py"":130:0) at callsite(""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/ops/signal/mfcc_ops.py"":107:0 at callsite(""<ipython-input-228-d9ade39d80ce>"":20:0 at callsite(""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py"":827:0 at callsite(""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"":778:0 at callsite(""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py"":891:0 at callsite(""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py"":717:0 at callsite(""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py"":267:0 at callsite(""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"":778:0 at ""<ipython-input-290-205be255c740>"":3:0)))))))))): error: 'tfl.strided_slice' op operand #0 must be tensor of 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or 1-bit integer values, but got 'tensor<1x153x81xcomplex<f32>>'
Traceback (most recent call last):
  File ""/home/mattc/anaconda3/envs/main/bin/toco_from_protos"", line 10, in <module>
    sys.exit(main())
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: /home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/ops/signal/dct_ops.py:130:15: error: 'tfl.strided_slice' op operand #0 must be tensor of 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or 1-bit integer values, but got 'tensor<1x153x81xcomplex<f32>>'
              input, fft_length=[2 * axis_dim])[..., :axis_dim] * scale)
              ^
/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/ops/signal/mfcc_ops.py:107:5: note: called from
    dct2 = dct_ops.dct(log_mel_spectrograms, type=2)
    ^
<ipython-input-228-d9ade39d80ce>: note: called from
/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py:827:7: note: called from
      return self.function(inputs, **arguments)
      ^
/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778:19: note: called from
                  outputs = call_fn(cast_inputs, *args, **kwargs)
                  ^
/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py:891:11: note: called from
          output_tensors = layer(computed_tensors, **kwargs)
          ^
/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py:717:9: note: called from
        convert_kwargs_to_constants=base_layer_utils.call_context().saving)
        ^
/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py:267:7: note: called from
      return super(Sequential, self).call(inputs, training=training, mask=mask)
      ^
/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778:19: note: called from
                  outputs = call_fn(cast_inputs, *args, **kwargs)
                  ^
<ipython-input-290-205be255c740>: note: called from
```

Is there a plan to support signal operations like this in a TFLite model?"
34322,Collective AllGather Fails to Collect Tensors in Multi-(TF)Task Between-Graph Distributed Execution,"**System information**
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): binary whl
- TensorFlow version (use command below): `tensorflow-gpu==2.0.0`
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0 / 7.6.4, recommended with the support of `nccl`
- GPU model and memory: GeForce GTX 1080 Ti


**Describe the current behavior**
First, we need the two files below.
`cluster.py`:
```python
import time
from multiprocessing import Process

from tensorflow.core.protobuf import config_pb2
from tensorflow.python.training.server_lib import Server

CLUSTER_SPEC = {
    ""worker"": [
        ""localhost:14286"",
        ""localhost:14287""
    ]
}

GROUP_SIZE = 4


def _configure(group_size):
    gpu_options = config_pb2.GPUOptions(
        visible_device_list='0,1',
        per_process_gpu_memory_fraction=0.7 / group_size
    )
    experimental = config_pb2.ConfigProto.Experimental(collective_nccl=True)
    experimental.collective_group_leader = '/job:worker/replica:0/task:0'
    return config_pb2.ConfigProto(gpu_options=gpu_options, experimental=experimental)


class TFCluster:
    def __init__(self, cluster_spec):
        self._cluster_spec = cluster_spec
        self._num_worker = len(self._cluster_spec.get(""worker"", []))
        self._tf_servers = []

    def start(self):
        def server(job_name: str, task_index: int):
            s = Server(self._cluster_spec,
                       job_name=job_name,
                       task_index=task_index,
                       config=_configure(GROUP_SIZE))
            s.join()

        assert self._num_worker >= 1
        for i in range(self._num_worker):
            self._tf_servers.append(Process(target=server,
                                            args=(""worker"", i), daemon=True))
            # break
        for proc in self._tf_servers:
            proc.start()

    def stop(self):
        for proc in self._tf_servers:
            proc.terminate()


if __name__ == '__main__':
    cluster = TFCluster(CLUSTER_SPEC)
    cluster.start()
    time.sleep(5)
    input('Press Enter to Stop.')
    cluster.stop()
```
`task.py`:
```python
import argparse

import numpy as np
import tensorflow as tf
from tensorflow.core.protobuf import config_pb2
from tensorflow.python import ops
from tensorflow.python.client.session import Session
from tensorflow.python.ops import collective_ops

from cluster import CLUSTER_SPEC, GROUP_SIZE

VAR = np.array([0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1])
VAR_TASK_INDEX = 0


def test_collective(job_name, task_index, num_gpus):
    worker_device = ""/job:%s/task:%d"" % (job_name, task_index)
    master_target = ""grpc://"" + CLUSTER_SPEC[job_name][task_index]
    print('> Session Target:', master_target)

    with ops.Graph().as_default(), Session(target=master_target) as sess:
        def run(x):
            run_options = config_pb2.RunOptions()
            run_options.experimental.collective_graph_key = task_index + 1
            # Different positive graph key for different task to avoid racing conditions.
            return sess.run(x, options=run_options)

        with ops.device('/job:worker/task:%d/device:CPU:0' % VAR_TASK_INDEX):  # make sure all use the same variable
            var = tf.Variable(VAR, name='W')

        targets = []
        collectives = []
        for i in range(num_gpus):
            with ops.device(worker_device + '/device:GPU:' + str(i)):
                t = var + 0.2 * task_index + 0.1 * i
                targets.append(t)
                collectives.append(
                    collective_ops.all_gather(
                        t,
                        group_size=GROUP_SIZE,
                        group_key=1, instance_key=1
                    )
                    # collective_ops.all_reduce(
                    #     t,
                    #     group_size=GROUP_SIZE,
                    #     group_key=1, instance_key=1, merge_op='Add', final_op='Div'
                    # )
                )

        run(tf.compat.v1.global_variables_initializer())

        var_value = run(var)
        print('> Variable Value:', var_value)

        targets_value = run(targets)
        print('> Targets Value:', targets_value)

        collectives_value = run(collectives)
        print('> Collectives Value:', collectives_value)


if __name__ == ""__main__"":
    parser = argparse.ArgumentParser()
    parser.register(""type"", ""bool"", lambda v: v.lower() == ""true"")

    parser.add_argument(
        ""--job_name"",
        type=str,
        default="""",
    )
    parser.add_argument(
        ""--task_index"",
        type=int,
        default=0,
    )
    FLAGS, unparsed = parser.parse_known_args()
    num_gpus_per_node = 2
    test_collective(job_name=FLAGS.job_name, task_index=FLAGS.task_index, num_gpus=num_gpus_per_node)
```

Then one could use the following commands to run the experiment:
```bash
python cluster.py
python task.py --job_name=worker --task_index=0
python task.py --job_name=worker --task_index=1
```

* EXPERIMENT 1 (FAILURE):
  * Run the above code without change. Note that the `GROUP_SIZE=4`. It is programmed to all gather the 4 tensors across `task:0/GPU:0/` `task:0/GPU:1` `task:1/GPU:0` `task:1/GPU:1`, but gets stuck. If one turns on the env `TF_CPP_MIN_VLOG_LEVEL=1` , one will notice it successfully gathers the values but gets stuck right after it, specifically after `tensorflow/core/common_runtime/collective_rma_local.cc:105] PostToPeer ...`

* EXPERIMENT 2 (SUCCESS):
 * Run the above code with `GROUP_SIZE=2`. On each task, It is programmed to gather 2 tensors on the 2 GPUs of that task. For example, on `task 0`, it gathers `task:0/GPU:0` and `task:0/GPU:1` and it succeeds.

* EXPERIMENT 3 (SUCCESS):
* Run the above code with the original `GROUP_SIZE=4` but with the `all_reduce` op (as provided in the commented code) instead of `all_gather`. It succeeds.


**Describe the expected behavior**

It is expected that all the experiments above should succeed. However, EXPERIMENT 1 fails, but 2 and 3 succeed. 3 means the collective executor works in a multi-task way of executing the graph on `all_reduce`. 2 means `all_gather` works if only collects tensor within one graph. 1 means the bug where `all_gather` fails to collect tensors across the tasks. 

**Code to reproduce the issue**
See above
"
34321,"Colab, TPU training using keras  InternalError: Failed to serialize message","Hi,

I am trying to test TPU on colab in order to see how that works on keras.
I try to train 3 models. And differents bugs/abnormal behaviors occured : 
1) when I trained a simple model ( see ""create_model"" function in colab) it works well with an image size of (100,100,3) but it does not work with (200,200,3). The batch size is about 80 so I doubt it is about an OOM error. 



2)  same as 1) with vgg19/inceptionresnetv2 + issue if I use the parameters imagenet=""weights""


3) using tensorflow 2.0 as backend does not seem to work even with image size equal to (100, 100, 3)

These issue seems abnormal and the message does not help to understand how to solve them. Anyone know how to solve them or why they occured ?

Link to the code : https://colab.research.google.com/drive/1z40RZOqBexmniel8m9KdgSa7tSFaUUcG


Message error : 
1)

```
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1364     try:
-> 1365       return fn(*args)
   1366     except errors.OpError as e:

13 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1349       return self._call_tf_sessionrun(options, feed_dict, fetch_list,
-> 1350                                       target_list, run_metadata)
   1351 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)
   1442                                             fetch_list, target_list,
-> 1443                                             run_metadata)
   1444 

InternalError: Failed to serialize message

During handling of the above exception, another exception occurred:

InternalError                             Traceback (most recent call last)
<ipython-input-16-f1e92e5b4b78> in <module>()
      2   X_train.astype(np.float32), Y_train.astype(np.float32),
      3   batch_size = 10*8,
----> 4   epochs=5)#, validation_data=(x_test, y_test))
      5 
      6   #validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)))

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    725         max_queue_size=max_queue_size,
    726         workers=workers,
--> 727         use_multiprocessing=use_multiprocessing)
    728 
    729   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    617         validation_split=validation_split,
    618         shuffle=shuffle,
--> 619         epochs=epochs)
    620     if not dist_utils.is_distributing_by_cloning(model):
    621       with model._distribution_strategy.scope():

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in _distribution_standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, validation_split, shuffle, epochs, allow_partial_batch)
   2286 
   2287         ds = strategy.extended.experimental_make_numpy_dataset(in_tuple,
-> 2288                                                                session=session)
   2289         if shuffle:
   2290           # We want a buffer size that is larger than the batch size provided by

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py in experimental_make_numpy_dataset(self, numpy_input, session)
   1684     """"""
   1685     _require_cross_replica_or_default_context_extended(self)
-> 1686     return self._experimental_make_numpy_dataset(numpy_input, session=session)
   1687 
   1688   def _experimental_make_numpy_dataset(self, numpy_input, session):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/tpu_strategy.py in _experimental_make_numpy_dataset(self, numpy_input, session)
    247     return numpy_dataset.one_host_numpy_dataset(
    248         numpy_input, numpy_dataset.SingleDevice(self._host_device),
--> 249         session)
    250 
    251   def _experimental_distribute_dataset(self, dataset):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/numpy_dataset.py in one_host_numpy_dataset(numpy_input, colocate_with, session)
     86                       for i in numpy_flat)
     87   for v, i in zip(vars_flat, numpy_flat):
---> 88     init_var_from_numpy(v, i, session)
     89   vars_nested = nest.pack_sequence_as(numpy_input, vars_flat)
     90   return dataset_ops.Dataset.from_tensor_slices(vars_nested)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/numpy_dataset.py in init_var_from_numpy(input_var, numpy_input, session)
     70           start_placeholder: start,
     71           end_placeholder: end,
---> 72           slice_placeholder: numpy_input[start:end]})
     73       start = end
     74 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    954     try:
    955       result = self._run(None, fetches, feed_dict, options_ptr,
--> 956                          run_metadata_ptr)
    957       if run_metadata:
    958         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1178     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1179       results = self._do_run(handle, final_targets, final_fetches,
-> 1180                              feed_dict_tensor, options, run_metadata)
   1181     else:
   1182       results = []

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1357     if handle is None:
   1358       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1359                            run_metadata)
   1360     else:
   1361       return self._do_call(_prun_fn, handle, feeds, fetches)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1382                     '\nsession_config.graph_options.rewrite_options.'
   1383                     'disable_meta_optimizer = True')
-> 1384       raise type(e)(node_def, op, message)
   1385 
   1386   def _extend_graph(self):

InternalError: Failed to serialize message
```


2)
```

---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1364     try:
-> 1365       return fn(*args)
   1366     except errors.OpError as e:

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1349       return self._call_tf_sessionrun(options, feed_dict, fetch_list,
-> 1350                                       target_list, run_metadata)
   1351 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)
   1442                                             fetch_list, target_list,
-> 1443                                             run_metadata)
   1444 

NotFoundError: From /job:worker/replica:0/task:0:
2 root error(s) found.
  (0) Not found: Resource worker/block1_conv1/bias/replica_7/N10tensorflow3VarE does not exist.
	 [[{{node TPUReplicateMetadata}}]]
  (1) Not found: Resource worker/block1_conv1/bias/replica_3/N10tensorflow3VarE does not exist.
	 [[{{node TPUReplicateMetadata}}]]
0 successful operations.
7 derived errors ignored.

During handling of the above exception, another exception occurred:

NotFoundError                             Traceback (most recent call last)
<ipython-input-10-f1e92e5b4b78> in <module>()
      2   X_train.astype(np.float32), Y_train.astype(np.float32),
      3   batch_size = 10*8,
----> 4   epochs=5)#, validation_data=(x_test, y_test))
      5 
      6   #validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)))

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    725         max_queue_size=max_queue_size,
    726         workers=workers,
--> 727         use_multiprocessing=use_multiprocessing)
    728 
    729   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    668             steps_per_epoch=steps_per_epoch,
    669             validation_steps=validation_steps,
--> 670             validation_freq=validation_freq)
    671 
    672     return training_arrays.fit_loop(

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py in experimental_tpu_fit_loop(model, dataset, epochs, verbose, callbacks, initial_epoch, steps_per_epoch, val_dataset, validation_steps, validation_freq)
    241         prev_step_count = step_count
    242       try:
--> 243         _, outputs = K.batch_get_value([train_op, output_tensors])
    244       except errors.OutOfRangeError:
    245         logging.warning('Your dataset iterator ran out of data; '

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in batch_get_value(tensors)
   3183     raise RuntimeError('Cannot get value inside Tensorflow graph function.')
   3184   if tensors:
-> 3185     return get_session(tensors).run(tensors)
   3186   else:
   3187     return []

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    954     try:
    955       result = self._run(None, fetches, feed_dict, options_ptr,
--> 956                          run_metadata_ptr)
    957       if run_metadata:
    958         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1178     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1179       results = self._do_run(handle, final_targets, final_fetches,
-> 1180                              feed_dict_tensor, options, run_metadata)
   1181     else:
   1182       results = []

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1357     if handle is None:
   1358       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1359                            run_metadata)
   1360     else:
   1361       return self._do_call(_prun_fn, handle, feeds, fetches)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1382                     '\nsession_config.graph_options.rewrite_options.'
   1383                     'disable_meta_optimizer = True')
-> 1384       raise type(e)(node_def, op, message)
   1385 
   1386   def _extend_graph(self):

NotFoundError: From /job:worker/replica:0/task:0:
2 root error(s) found.
  (0) Not found: Resource worker/block1_conv1/bias/replica_7/N10tensorflow3VarE does not exist.
	 [[node TPUReplicateMetadata (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
  (1) Not found: Resource worker/block1_conv1/bias/replica_3/N10tensorflow3VarE does not exist.
	 [[node TPUReplicateMetadata (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
0 successful operations.
7 derived errors ignored.

Original stack trace for 'TPUReplicateMetadata':
  File ""/usr/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py"", line 664, in launch_instance
    app.start()
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py"", line 832, in start
    self._run_callback(self._callbacks.popleft())
  File ""/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py"", line 605, in _run_callback
    ret = callback()
  File ""/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py"", line 536, in <lambda>
    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))
  File ""/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py"", line 450, in _handle_events
    self._handle_recv()
  File ""/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py"", line 480, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py"", line 432, in _run_callback
    callback(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-10-f1e92e5b4b78>"", line 4, in <module>
    epochs=5)#, validation_data=(x_test, y_test))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 727, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 670, in fit
    validation_freq=validation_freq)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 196, in experimental_tpu_fit_loop
    initial_loop_values=initial_loop_values)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1756, in experimental_run_steps_on_iterator
    initial_loop_values)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/tpu_strategy.py"", line 334, in _experimental_run_steps_on_iterator
    replicate_outputs = rewrite_fn()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/tpu_strategy.py"", line 315, in rewrite_fn
    run_fn, replicate_inputs, device_assignment=self._device_assignment)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tpu/tpu.py"", line 639, in replicate
    maximum_shapes=maximum_shapes)[1]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tpu/tpu.py"", line 927, in split_compile_and_replicate
    num_replicas=num_replicas, use_tpu=use_tpu, **metadata_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_tpu_ops.py"", line 6105, in tpu_replicate_metadata
    name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 794, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3357, in create_op
    attrs, op_def, compute_device)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3426, in _create_op_internal
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()
```


3)

```
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
<ipython-input-10-f1e92e5b4b78> in <module>()
      2   X_train.astype(np.float32), Y_train.astype(np.float32),
      3   batch_size = 10*8,
----> 4   epochs=5)#, validation_data=(x_test, y_test))
      5 
      6   #validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)))

13 frames
/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_distributed.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    683         validation_steps=validation_steps,
    684         validation_freq=validation_freq,
--> 685         steps_name='steps_per_epoch')
    686 
    687   def evaluate(self,

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)
    142       steps_per_epoch = training_utils.infer_steps_for_dataset(
    143           inputs, steps_per_epoch, epochs=epochs, steps_name=steps_name)
--> 144     input_iterator = _get_iterator(inputs, model._distribution_strategy)
    145 
    146   # Enter tf.distribute.Strategy scope.

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py in _get_iterator(inputs, distribution_strategy)
    547   if distribution_strategy:
    548     return distributed_training_utils.get_iterator(
--> 549         inputs, distribution_strategy)
    550   return training_utils.get_iterator(inputs)
    551 

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/distribute/distributed_training_utils.py in get_iterator(dataset, distribution_strategy)
    585 def get_iterator(dataset, distribution_strategy):
    586   with distribution_strategy.scope():
--> 587     iterator = distribution_strategy.make_dataset_iterator(dataset)
    588   initialize_iterator(iterator, distribution_strategy)
    589   return iterator

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/distribute_lib.py in make_dataset_iterator(self, dataset)
    559   def make_dataset_iterator(self, dataset):
    560     """"""DEPRECATED TF 1.x ONLY.""""""
--> 561     return self._extended._make_dataset_iterator(dataset)  # pylint: disable=protected-access
    562 
    563   @doc_controls.do_not_generate_docs  # DEPRECATED: TF 1.x only

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/tpu_strategy.py in _make_dataset_iterator(self, dataset)
    225         self._input_workers,
    226         self._container_strategy(),
--> 227         split_batch_by=self._num_replicas_in_sync)
    228 
    229   def _make_input_fn_iterator(

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/input_lib.py in __init__(self, dataset, input_workers, strategy, split_batch_by, input_context)
    760         strategy,
    761         split_batch_by=split_batch_by,
--> 762         input_context=input_context)
    763     worker_iterators = _create_iterators_per_worker(
    764         dist_dataset._cloned_datasets, input_workers)  # pylint: disable=protected-access

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/input_lib.py in __init__(self, dataset, input_workers, strategy, split_batch_by, input_context)
    556         strategy,
    557         split_batch_by=split_batch_by,
--> 558         input_context=input_context)
    559 
    560   def make_one_shot_iterator(self):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/input_lib.py in __init__(self, dataset, input_workers, strategy, split_batch_by, input_context)
    518           # TODO(b/129506833): Figure out between graph cases
    519           cloned_dataset = input_ops.auto_shard_dataset(  # pylint: disable=protected-access
--> 520               cloned_dataset, len(input_workers.worker_devices), i)
    521           self._cloned_datasets.append(cloned_dataset)
    522 

/tensorflow-2.0.0/python3.6/tensorflow_core/python/distribute/input_ops.py in auto_shard_dataset(dataset, num_shards, index)
     47       return distribute._AutoShardDatasetV1(dataset, num_shards, index)
     48     else:
---> 49       return distribute._AutoShardDataset(dataset, num_shards, index)
     50   else:
     51     return dataset

/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/experimental/ops/distribute.py in __init__(self, input_dataset, num_workers, index)
     54         num_workers=num_workers,
     55         index=index,
---> 56         **self._flat_structure)
     57     super(_AutoShardDataset, self).__init__(input_dataset, variant_tensor)
     58 

/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/gen_experimental_dataset_ops.py in auto_shard_dataset(input_dataset, num_workers, index, output_types, output_shapes, name)
    169       else:
    170         message = e.message
--> 171       _six.raise_from(_core._status_to_exception(e.code, message), None)
    172   # Add nodes to the TensorFlow graph.
    173   if not isinstance(output_types, (list, tuple)):

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run AutoShardDataset: Unable to parse tensor proto
Additional GRPC error information:
{""created"":""@1573841168.053370969"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to parse tensor proto"",""grpc_status"":3} [Op:AutoShardDataset]
```"
34319,Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fa9a442b440> could not be transformed and will be executed ,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution: Ubuntu 18.06
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.4
-using spyder3 ide in anaconda
- CUDA/cuDNN version: None


**Describe the current behavior**
getting this error and the training accuracy doesnt improve


WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fa9a442b440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fa9a442b440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
**Describe the expected behavior**
well, increasing ccuracy and no error basically
**Code to reproduce the issue**

from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
import numpy as np

y_train = np.random.rand(1)
epochs = 1
x_train = np.random.rand(1,20,16)

model = Sequential()
model.add(layers.LSTM(activation='sigmoid',units = 3,batch_input_shape = (1,20,16)))
model.add(layers.Dense(2, activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
model.summary()
history = model.fit(x_train, y_train, batch_size=1, epochs=epochs)



this reproduces the error in my usecase


edit: using the solution proposed in
https://github.com/tensorflow/tensorflow/issues/32377

did not work for me ( Requirement already satisfied: gast==0.2.2 )

"
34318,ModuleNotFoundError: No module named 'tensorflow',"**System information**
- Linux Ubuntu 18.04
- TensorFlow-gpu installed from pip :
- TensorFlow-gpu version: 2.0.0

- Python version:3.6.8 
- Installed using pip
- CUDA/cuDNN version:10
- GPU model and memory: 1050 mobile

I followed the installation tutorial for tensorflow GPU, specified in
https://www.tensorflow.org/install/gpu

The command ""pip3 show tensorflow-gpu "" has the following output : 
 ```bash
Name: tensorflow-gpu
Version: 2.0.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author: Google Inc.
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /home/niccle27/.local/lib/python3.6/site-packages
Requires: tensorflow-estimator, keras-preprocessing, astor, tensorboard, keras-applications, absl-py, six, protobuf, numpy, termcolor, gast, google-pasta, opt-einsum, grpcio, wheel, wrapt
Required-by: 
```

i made sure that cuda was working properly and it does.

when importing the tensorflow package, i'm getting the following error :
 
 ```python
import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow'
```
"
34317,Parallelize input pipeline with TensorFlow2.0,"We have already implemented distributed training with `MultiWorkerMirroredStrategy` and `ParameterServerStrategy` (multi-worker on multiple machines). The problem is that every script from every worker extracts the same data set which is then sharded among the workers but we would like to directly pass to each worker only the part of data to be processed. Is it possible? 
Maybe we should execute different data queries from every machine or one of the workers should have this task and then pass the proper subsets to other workers?
"
34316,tf.function issue after replacing the optimiser,"**System information**
- Have I written custom code: no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Manjaro linux testing
- TensorFlow installed from (source or binary): pypi binary
- TensorFlow version (use command below): v1.12.1-16854-g6778662 2.1.0-dev20191028
- Python version: 3.7.4
- CUDA/cuDNN version: 10.1.243 / 7.6.4.38
- GPU model and memory: GeForce GTX 1080, 8GB

**Describe the current behavior**
I am training a model using multiple optimisers and am getting an error when the train function is decorated with @tf.function.

**Describe the expected behavior**
I expected the converted function to be invariant of the optimiser instance.

**Code to reproduce the issue**

```
import tensorflow as tf


class MyModel(tf.keras.Model):
    def __init__(self):
        super(MyModel, self).__init__()

        self.x = self.add_weight(shape=[1,], dtype=tf.float32)

    def call(self, inputs):
        return inputs * self.x

model = MyModel()
optimiser = tf.keras.optimizers.Adam(0.1)

@tf.function
def train():
    with tf.GradientTape() as tape:
        output = model([1.0])
        loss = output

    grads = tape.gradient(loss, model.trainable_variables)
    optimiser.apply_gradients(zip(grads, model.trainable_variables))


train()
print('First call ok')
optimiser = tf.keras.optimizers.Adam(0.2)
train()
print('Second call ok')
```

**Other info / logs**
```
tensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable Adam/beta_2_33 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/Adam/beta_2_33/N10tensorflow3VarE does not exist.
	 [[node Adam/Cast_3/ReadVariableOp]] [Op:__inference_train_135]
```
"
34315,Unable to use new TensorFlow Lite Android Support Library for object detection,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina 10.15.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 3XL
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below):
      From build.gradle
      api 'org.tensorflow:tensorflow-lite:2.0.0'
      api 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'
      api 'org.tensorflow:tensorflow-lite-support:0.0.0-nightly'

**Describe the current behavior**
I'm attempting to modify the current TFLiteObjectDetectionAPIModel.java from [the android object detection example](https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/app/src/main/java/org/tensorflow/lite/examples/detection/tflite/TFLiteObjectDetectionAPIModel.java) to use the experimental [TensorFlow Lite Android Support Library](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/support/java)

I seem to be loading the input and output tensor buffers and running `tflite.runForMultipleInputsOutputs` just fine. Getting a Map of labeled probabilities crashes with the error:` java.lang.IllegalArgumentException: Label number 97 mismatch the shape on axis 1`. I am using a custom quantized model and custom label file with 97 classes. I am certain that this model works, as it runs perfectly fine with the original example (with modifications to sizes of course).

**Describe the expected behavior**

I expect to get an array of labeled probabilities, but the app crashes instead.

**Code to reproduce the issue**
Here's how I set up input/output tensors:

        // Setup output tensors
        int outputTensorIndex = 0;
        int[] outputLocationShape =
                tflite.getOutputTensor(outputTensorIndex).shape();
        DataType outputLocationType = tflite.getOutputTensor(outputTensorIndex).dataType();
        outputTensorIndex++;
        int[] outputClassShape =
                tflite.getOutputTensor(outputTensorIndex).shape();
        DataType outputClassType = tflite.getOutputTensor(outputTensorIndex).dataType();
        outputTensorIndex++;
        int[] outputScoreShape =
                tflite.getOutputTensor(outputTensorIndex).shape();
        DataType outputScoreType = tflite.getOutputTensor(outputTensorIndex).dataType();
        outputTensorIndex++;
        int[] numDetectionShape =
                tflite.getOutputTensor(outputTensorIndex).shape();
        DataType numDetectionType= tflite.getOutputTensor(outputTensorIndex).dataType();
        
       // Setup input tensor
        int imageTensorIndex = 0;
        int[] imageShape = tflite.getInputTensor(imageTensorIndex).shape(); // {1, height, width, 3}
        imageSizeY = imageShape[1];
        imageSizeX = imageShape[2];
        DataType imageDataType = tflite.getInputTensor(imageTensorIndex).dataType();

        // Creates the input tensor.
        inputImageBuffer = new TensorImage(imageDataType);

        // Creates the output tensors and its processors.
        outputLocationBuffer = TensorBuffer.createFixedSize(outputLocationShape, outputLocationType);
        outputClassBuffer = TensorBuffer.createFixedSize(outputClassShape, outputClassType);
        outputScoreBuffer = TensorBuffer.createFixedSize(outputScoreShape, outputScoreType);
        numDetectionBuffer = TensorBuffer.createFixedSize(numDetectionShape, numDetectionType);

        // Creates the post processor for the output probability.
        outputLocationProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();
        outputClassProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();
        outputScoreProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();
        numDetectionProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();

        LOGGER.d(""Created a Tensorflow Lite Classifier."");
    }

And here's how I'm loading images and attempting to get a labeled probability map

        Trace.beginSection(""loadImage"");
        long startTimeForLoadImage = SystemClock.uptimeMillis();
        inputImageBuffer = loadImage(bitmap, sensorOrientation);
        long endTimeForLoadImage = SystemClock.uptimeMillis();
        Trace.endSection();
        LOGGER.v(""Timecost to load the image: "" + (endTimeForLoadImage - startTimeForLoadImage));

        // Runs the inference call.
        Trace.beginSection(""runInference"");
        long startTimeForReference = SystemClock.uptimeMillis();

        Object[] inputArray = {inputImageBuffer.getBuffer().rewind()};
        Map<Integer, Object> outputMap = new HashMap<>();
        outputMap.put(0, outputLocationBuffer.getBuffer().rewind());
        outputMap.put(1, outputClassBuffer.getBuffer().rewind());
        outputMap.put(2, outputScoreBuffer.getBuffer().rewind());
        outputMap.put(3, numDetectionBuffer.getBuffer().rewind());
        tflite.runForMultipleInputsOutputs(inputArray, outputMap);
        long endTimeForReference = SystemClock.uptimeMillis();
        Trace.endSection();
        LOGGER.v(""Timecost to run model inference: "" + (endTimeForReference - startTimeForReference));

        Map<String, Float> labeledProbability =
            new TensorLabel(labels, outputClassProcessor.process(outputClassBuffer))
                .getMapWithFloatValue();
        Trace.endSection();
        // Gets top-k results.
        return getTopKProbability(labeledProbability);


**Other info / logs**
`java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example}: java.lang.IllegalArgumentException: Label number 97 mismatch the shape on axis 1`

for the line 

`Map<String, Float> labeledProbability =
            new TensorLabel(labels, outputClassProcessor.process(outputClassBuffer))
                .getMapWithFloatValue();`
"
34314,Error when importing tensorflow,"
hello github
i have been having issues importing tensorflow
first i installed the tensorflow==1.31 and i got an error attached below while trying to import tensorflow.
someone suggested i use conda install tensorflow which i did and when trying to import tensorflow my python stops working and my kernel dies.
i was also instructed to upgrade numpy using pip install numpy --upgrade. which i also did. but on trying to import tensorflow again my computer sends a notification of python stops working and kernel dies and restarts again.
my computer is 4g Ram
please your suggestion will be needed. i am stuck"
34313,"A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x70 in tid 28007","There was a problem when calling converted custom model (LSTM.tflite) in Android Studio.
with
```Python
converter.experimental_new_converter = True
```

**System information**
model training machine
- Ubuntu 16.04 (LTS)
- GTX1080
- tensorflow 1.13.1
- Keras 2.2.4
- Python 3.6.8

model converting & loading machine

- MacOS Mojave 10.14.5
- Python 3.7.1
- tensorflow 2.0.0, tf-nightly 2.1.0.dev20191113
- Android Studio 3.4.1
- targetSdkVersion 28

Smartphone

- Android 8.0.0
- SONY SO-04J (docomo xperia)

I can convert custom LSTM model from .h5 to .tflite with following code:

```Python
import tensorflow as tf
model = tf.keras.models.load_model(""LSTM.h5"")
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
tflite_model = converter.convert()
open(""LSTM.tflite"", ""wb"").write(tflite_model)
```

Next I want to load this model (LSTM.tflite) into my Android APK.
I already have class that can perform inference using 1D-CNN custom model (1DCNN.tflite).

```Java
package iis.kmjlab.kazuimotn.sartips.others;
import android.content.res.AssetFileDescriptor;
import android.content.res.AssetManager;
import org.tensorflow.lite.Interpreter;
import java.io.FileInputStream;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;

public class TensorFlowLiteClassifier {

    private Interpreter interpreter;
    public static final String MODEL_FILE = ""1DCNN.tflite"";
    public static final int LABEL_NUM = 2;

    /**
     * Registers interpreter
     */
    private TensorFlowLiteClassifier(Interpreter interpreter) {
        this.interpreter = interpreter;
    }

    /**
     * Loads model into interpreter
     */
    public static TensorFlowLiteClassifier classifier(AssetManager assetManager, String modelPath) throws IOException {
        ByteBuffer byteBuffer = loadModelFile(assetManager, modelPath);
        Interpreter interpreter = new Interpreter(byteBuffer);
        return new TensorFlowLiteClassifier(interpreter);
    }

    /**
     * Loads model
     */
    private static MappedByteBuffer loadModelFile(AssetManager assets, String path) throws IOException {
        AssetFileDescriptor file = assets.openFd(path);
        FileInputStream stream = new FileInputStream(file.getFileDescriptor());
        FileChannel channel = stream.getChannel();
        long startOffset = file.getStartOffset();
        long declaredLength = file.getDeclaredLength();
        return channel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);
    }

    /**
     * Function that actually performs inference
     */
    public float[][] predictProbabilities(float[][] input) {
        float[][] output = new float[1][LABEL_NUM];
        interpreter.run(input, output);
        return output;
    }
}
```

When I use 1DCNN.tflite, this class works completely. However, when I change the model into LSTM.tflite, getting ERROR at this line

```Java
Interpreter interpreter = new Interpreter(byteBuffer);
```

And ERROR logcat is following
**A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x70 in tid 28007**

How can I deal with this unknown error?
After my some investigation, this error seems to occur when the prepared array is exceeded for some reason.
"
34312,Error when loading SavedModel with models.load_model() and compile=false ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0.130/7.6.3.30
- GPU model and memory: Tesla K80 with 11441MiB; GeForce GTX 1080Ti with 11441MiB

**Describe the current behavior**
When loading a model saved using `model.save('./model', save_format='tf')` without compiling it and executing an inference, using `model.predict()` the following exception is raised:

```bash
---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

<ipython-input-3-d52b49db9273> in <module>()
      1 backend.clear_session()
      2 model = models.load_model('./model', compile=False)
----> 3 model.predict(x_data, batch_size=10)

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
    907         max_queue_size=max_queue_size,
    908         workers=workers,
--> 909         use_multiprocessing=use_multiprocessing)
    910 
    911   def reset_metrics(self):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py in predict(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)
    713     batch_size = model._validate_or_infer_batch_size(batch_size, steps, x)
    714     x, _, _ = model._standardize_user_data(
--> 715         x, check_steps=True, steps_name='steps', steps=steps)
    716     return predict_loop(
    717         model,

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)
   2431     is_compile_called = False
   2432     if not self._is_compiled and self.optimizer:
-> 2433       self._compile_from_inputs(all_inputs, y_input, x, y)
   2434       is_compile_called = True
   2435 

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py in _compile_from_inputs(self, all_inputs, target, orig_inputs, orig_target)
   2659     self.compile(
   2660         optimizer=self.optimizer,
-> 2661         loss=self.loss,
   2662         metrics=self._compile_metrics,
   2663         weighted_metrics=self._compile_weighted_metrics,

AttributeError: 'Model' object has no attribute 'loss'
```

The problem is due to the load function setting the optimizer of the model with an instance of `tensorflow.python.keras.optimizer_v2.optimizer_v2.RestoredOptimizer` and, therefore, the model is tried to be compiled in:

https://github.com/tensorflow/tensorflow/blob/4ff2916c8ca78839cebcfa39e2ac939fa50eab80/tensorflow/python/keras/engine/training.py#L2320-L2322

Raising the error as there is no loss/metrics loaded previously.

**Describe the expected behavior**
The expected behaviour is that the model performs the inference without any need to be compiled and returns the result. In fact, this behaviour is meet when the model is saved with the Keras format ('model.h5') and loaded. 

**Code to reproduce the issue**
A executable notebook can be found [here](https://colab.research.google.com/drive/10ljGMdWthbZ3waalt-4vKguEyxbZzUbt)

```python
# -*- coding: utf-8 -*-

import numpy as np
import tensorflow as tf
from tensorflow.python.keras import backend, layers, models

x = layers.Input(shape=(4,))
y = layers.Dense(1, activation='softmax')(x)
model = models.Model(inputs=x, outputs=y)
model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])

x_data = np.random.random((10, 4))
y_data = np.random.random((10,))
model.fit(x_data, y_data, epochs=5, batch_size=10)
model.save('./model', save_format='tf')  # Loading this will raise an error
model.save('./model.h5', save_format='h5')  # Loading this will work

# This block will load the SavedModel without compiling and will 
# perform the inference raising an error
backend.clear_session()
model2 = models.load_model('./model', compile=False)
model2.predict(x_data, batch_size=10)

# This block will load the Keras saved model without compiling and will 
# perform the inference working as expected
backend.clear_session()
model3 = models.load_model('./model.h5', compile=False)
model3.predict(x_data, batch_size=10)
```"
34311,Batch pre-padding with Tensorflow datasets,"I have a dataset of variable-length sequences to feed an LSTM network and I want to do pre-padding in the batches, but current padded_batch function only pads at the sequences end. How can I do it?
I asked this question on stackoverflow but nobody answered me.
"
34310,tf-lite version info,"I have preinstalled TensorFlow - lite on my system, is it possible to get version information of it programmatically? If so - how?
Thanks. "
34308,Feature Request: Pass 'elapsed_secs' into LoggingHook string formatter.,"Can the tf.train.LoggingTensorHook be changed to pass the time elapsed into the string formatter?

It would be quite easy to add it to the dictionary of values already being passed to the formatter function. Currently you have to choose between your own custom string formatter, and seeing the time elapsed - I think it would be quite easy to have both with a small change to the code.

Thanks.
"
34307,"error "" 'tflite::FlatbufferModel' has not been declared ""when use Tensorflow lite C++ API","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):source
- TensorFlow version (or github SHA if from source):r1.14

i run `bazel build //tensorflow/lite:libtensorflowlite` and `bazel build //tensorflow/lite:framework`,so i get libtensorflowlite.so and libframework.so. 
Then i use the library in my own code,but i got an error:

```
main.cpp: In function ‘int main()’:
main.cpp:9:59: error: ‘tflite::FlatbufferModel’ has not been declared
  std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatbufferModel::BuildFromFile(""test1.tflite"");
                                                           ^
main.cpp:17:10: error: ‘tflite::ops’ has not been declared
  tflite::ops::builtin::BuiltinOpResolver resolver;
          ^
main.cpp:17:42: error: expected ‘;’ before ‘resolver’
  tflite::ops::builtin::BuiltinOpResolver resolver;
                                          ^
main.cpp:19:43: error: ‘resolver’ was not declared in this scope
  tflite::InterpreterBuilder(*model.get(), resolver)(&interpreter);
                                           ^
```

the command i used:
`g++  -std=c++11 -I/home/wang/work/ARM-BAZEL/tensorflow-r1.14 -I/home/wang/work/ARM-BAZEL/tensorflow-r1.14/tensorflow/lite/tools/make/downloads/flatbuffers/include main.cpp -o test -L/home/wang/work/ARM-BAZEL/tensorflow-r1.14/bazel-bin/tensorflow/lite -ltensorflowlite -lframework`

i want know where is the problem chould be ? I'm relly not familiar with how to use tensorflow lite."
34306,"tf2.0.0 using  tf.saved_model.save save model,  java SavedModelBundle load can not find ouput opt","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos7
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6


**Describe the current behavior**
python code

    X = np.array([[0,0], [0,1], [1,0], [1,1]], 'float32')
    Y = np.array([[0], [1], [1], [0]], 'int64')

    input_x = tf.keras.Input(shape=(2), name=""text"")
    dense1 = tf.keras.layers.Dense(64, activation='relu', name=""ds1"")
    dense2 = tf.keras.layers.Dense(2, name=""label"")

    x = dense1(input_x)
    x = dense2(x)
    pred = tf.reduce_mean(x, 1, name=""prediction"")

    model = tf.keras.Model(inputs=input_x, outputs=pred, name= ""test"")

    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])
    model.fit(X, Y, batch_size=1, epochs=10, verbose=0)

    print('inputs: ', [input.op.name for input in model.inputs])
    print('outputs: ', [output.op.name for output in model.outputs])

    tf.saved_model.save(model, ""./model_00"")


[java]
           String modelpath=""./model_00""
            SavedModelBundle bundle = SavedModelBundle.load(modelpath,""serve"");
            Graph graph = bundle.graph();
            
            Iterator<Operation> iter = graph.operations();
            while (iter.hasNext()) {
                Operation opt = iter.next();
                System.out.println(opt.name());
            }


can not find  output opt ??
"
34305,Behaviour of the loss function with sample_weights (keras),"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit

## Description of issue (what needs changing):
I think we need a description of how the loss is computed when (temporal) sample_weights are applied, i.e. how is the loss aggregated across samples/time-steps. As addressed in #25178, the behaviour has even changed over time in the external version of Keras from ignoring zero-values to counting them making the situation confusing. 

Even if I agree the current implementation is the right one, I think it is far from intuitive, especially when using zero-weighted zero-padding which decreases the loss value and the effective learning rate.

I am not very familiar with the structure to be followed in the build-in TF.Keras documentation, but this could be also specified elsewhere than in the `fit` method doc which is already pretty dense.

Sorry if this is specified elsewhere in the doc but I can't find it so if it exists, it should maybe be referenced in the `fit` doc.
Thanks a lot,
Emilien"
34303,two words not mached at the same time ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34302,Tensorflow 1.15 doesn't exists within pip install,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/install/pip

## Description of issue (what needs changing):
It says tensorflow 1.15 is final version for 1xx versions yet pip install 1.15 returns this

""$ pip3 install tensorflow==1.15
Collecting tensorflow==1.15
  Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1)
No matching distribution found for tensorflow==1.15
""


It should be corrected I think.
"
34301,tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if you’re using the Python API**

```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34300,Feature_columns  causes model training to be slow,"I use tf2.0 functional API to build the model, and use feature columns to process the data. I find that each step of my training takes a long time, and the CPU utilization is very low. My device is a 16 core CPU. When I don't use feature columns, I can run the model with multiple cores. I'm confused. Can someone answer this question?
![image](https://user-images.githubusercontent.com/26998046/68914950-39d7f100-079b-11ea-9f54-7d1053a5f623.png)
In a certain training, each step takes more than 100 ms, which is very slow
![image](https://user-images.githubusercontent.com/26998046/68915018-6b50bc80-079b-11ea-811c-37cb22bf237c.png)
The utilization rate of cou in the training process is very low, and it does not play the multi-core performance at all.

The result is a test when using the official feature _columns tutorial.https://www.tensorflow.org/tutorials/structured_data/feature_columns?hl=zh-CN
When I use the MNIST tutorial to run in the same environment, CPU utilization is completely multi-core performance.
Has anyone encountered this problem? Thank you very much.
"
34299,How to use Per-channel quantize in TFLite？,"Hello
from the tflite conv.cc , I can see that now tflite supports Per-channel quantize , is there any guide or doc how to use per-channel quantize when convert tf model to tflite?"
34298,could not restore weights to model with same structure  when enable_eager,"Sytem: ubuntu18.04
TF version: 2.0
Hardware: gtx1080ti and gt 840m
CUDA: 10.0
CUDNN: 7.6

```
class RetinaNet(tf.keras.Model):
    def __init__(self, config):
        super(RetinaNet, self).__init__()
        self.config = config
        self.num_classes = config['num_classes']
        self.weight_decay = config['weight_decay']
        self.mode = config['mode']
        self.batch_size = config['batch_size'] if config['mode'] == 'train' else 1
        self.lr = config['lr']

        image = tf.keras.Input(shape=[None, None, 3], batch_size=self.batch_size, dtype=tf.float32)
        self.backone = backone.model[config['backone']](
            image, config['backone_conv_trainable'], config['backone_bn_trainable'],
            weight=backone.weight[config['backone']]
        )
        self.opt = tf.keras.optimizers.SGD(self.lr, momentum=0.9)

        if config['mode'] == 'train':
            gt = tf.keras.Input(shape=[None, 5], batch_size=self.batch_size, dtype=tf.float32)
            self.model = self._build_graph(image, gt)
        else:
            self.model = self._build_graph(image)

    def _build_graph(self, image, gt=None):
        num_fpn_layers = 5
        fpn_channels = 256
        endpoints = self.backone(image)
        fpn = fpn_generator(endpoints[1:], fpn_channels, num_fpn_layers, mode='dconv')
        p3, p4, p5, p6, p7 = fpn
        dw_rate = [8., 16., 32., 64., 128.]
        anchors = [
            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],

            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],

            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],

            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],

            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],
        ]
        anchors_all = anchor_generator(
            fpn, anchors, dw_rate, flatten=True
        )
        anchors_all = tf.concat(anchors_all, axis=0)
        self.cla_head = self._cla_head(fpn_channels, 5)
        self.reg_head = self._reg_head(fpn_channels, 5)
        p3c = self.cla_head(p3)
        p3r = self.reg_head(p3)
        p4c = self.cla_head(p4)
        p4r = self.reg_head(p4)
        p5c = self.cla_head(p5)
        p5r = self.reg_head(p5)
        p6c = self.cla_head(p6)
        p6r = self.reg_head(p6)
        p7c = self.cla_head(p7)
        p7r = self.reg_head(p7)
        pc = tf.concat([p3c, p4c, p5c, p6c, p7c], axis=1)
        pr = tf.concat([p3r, p4r, p5r, p6r, p7r], axis=1)
        pc = tf.nn.sigmoid(pc)
        if self.mode == 'train':
            i = 0
            loss = tf.constant([0., 0.], dtype=tf.float32, shape=[1, 2])
            cond = lambda loss, i: tf.less(i, self.batch_size)
            body = lambda loss, i: (
                tf.add(loss, self._compute_one_image_loss(
                    tf.gather(gt, i),
                    anchors_all,
                    tf.gather(pc, i),
                    tf.gather(pr, i))
                       ),
                tf.add(i, 1)
            )
            loss, _ = tf.while_loop(cond, body, (loss, i))
            loss /= self.batch_size
            return tf.keras.Model(inputs=[image, gt], outputs=loss, name='retinanet')
        else:
            nms_score_threshold = 0.5
            nms_max_boxes = 100
            nms_iou_threshold = 0.45
            pr = pr[0, ...]
            confidence = pc[0, ...]
            y1x1y2x2 = bbox_decode(anchors_all, pr, normlization=[10., 10., 5., 5.])
            filter_mask = tf.greater_equal(confidence, nms_score_threshold)
            scores = []
            class_id = []
            bbox = []
            for i in range(self.num_classes):
                scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])
                bboxi = tf.boolean_mask(y1x1y2x2, filter_mask[:, i])
                selected_indices = tf.image.non_max_suppression(
                    bboxi, scoresi, nms_max_boxes, nms_iou_threshold,
                )
                scores.append(tf.gather(scoresi, selected_indices))
                bbox.append(tf.gather(bboxi, selected_indices))
                class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)
            bbox = tf.concat(bbox, axis=0)
            scores = tf.concat(scores, axis=0)
            class_id = tf.concat(class_id, axis=0) + 1
            detection_pred = [scores, bbox, class_id]
            return tf.keras.Model(inputs=image, outputs=detection_pred, name='retinanet')

    def _compute_one_image_loss(self, gt, anchors, pc, pr):
        slice_index = tf.argmin(gt, axis=0)[0]
        gt = tf.gather(gt, tf.range(0, slice_index, dtype=tf.int64))
        gt_bbox = gt[:, 0:4]
        label = tf.cast(gt[..., 4:5], dtype=tf.int32) - 1
        pos_threshold = 0.5
        neg_threshold = 0.4
        gaiou = bbox_iou(gt_bbox, anchors)
        pos_pc, pos_label, pos_pr, pos_gt_bbox, pos_a, neg_pc = partition_pos_neg_samples(
            gt_bbox, label, gaiou, pc, pr, anchors, pos_threshold, neg_threshold
        )
        pos_gr = bbox_encode(pos_gt_bbox, pos_a, normlization=[10., 10, 5., 5.])
        reg_loss = tf.reduce_sum(smooth_l1_loss(pos_pr-pos_gr))
        pos_label = tf.one_hot(pos_label, self.num_classes, dtype=tf.float32)
        cla_loss = focal_loss(pos_pc, pos_label, neg_pc, alpha=0.25, gamma=2.)
        reg_loss = tf.reshape(reg_loss, [1, 1])
        cla_loss = tf.reshape(cla_loss, [1, 1])
        loss = tf.concat([cla_loss, reg_loss], axis=-1)
        return loss

    def _cla_head(self, input_channels, anchors):
        x = tf.keras.Input(shape=[None, None, input_channels], dtype=tf.float32)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(x)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        pred = layers.Conv2D(self.num_classes * anchors, 3, 1, 'same', kernel_initializer='he_normal',
                             bias_initializer=tf.constant_initializer(-4.595))(relu)
        pred = tf.reshape(pred, [self.batch_size, -1, self.num_classes])
        return tf.keras.Model(inputs=x, outputs=pred, name='cla_head')

    def _reg_head(self, input_channels, anchors):
        x = tf.keras.Input(shape=[None, None, input_channels], dtype=tf.float32)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(x)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        pred = layers.Conv2D(4 * anchors, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        pred = tf.reshape(pred, [self.batch_size, -1, 4])
        return tf.keras.Model(inputs=x, outputs=pred, name='reg_head')

    def save_weights(self, filepath, overwrite=True, save_format=None):
        self.model.save_weights(filepath, overwrite, save_format)

    def load_weights(self, filepath, by_name=False):
        self.model.load_weights(filepath, by_name)
```

the save weights code is
```
config = {
    'num_classes': 20,
    'batch_size':batch_size,
    'mode': 'train',
    'lr': lr,
    'weight_decay':1e-4,
    'backone': 'resnetv1_18',
    'backone_conv_trainable': True,
    'backone_bn_trainable': True,
}
ssd = RetinaNet(config)
ssd.save_weights('saved_weights/1.tf')
```

the load weights code is
```
config = {
    'num_classes': 20,
    'batch_size':batch_size,
    'mode': 'test',
    'lr': lr,
    'weight_decay':1e-4,
    'backone': 'resnetv1_18',
    'backone_conv_trainable': True,
    'backone_bn_trainable': True,
}
ssd = RetinaNet(config)
ssd.load_weights('saved_weights/1.tf')
```


## When enable_eager
##  the weights saved under mode=='train' could not  be restored into model when mode=='test'
The error message is as follows:

```
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.engine.training.Model object at 0x7fa25076a3d0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7fa240170810>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.engine.training.Model object at 0x7fa270103250> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7fa1f35aced0>).
Traceback (most recent call last):
  File ""/home/master/workspace/objdect/test1.py"", line 23, in <module>
    ssd.load_weights('saved_weights/1.tf')
  File ""/home/master/workspace/objdect/RetinaNet.py"", line 170, in load_weights
    self.model.load_weights(filepath, by_name)
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 181, in load_weights
    return super(Model, self).load_weights(filepath, by_name)
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1149, in load_weights
    status = self._trackable_saver.restore(filepath)
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1270, in restore
    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 209, in restore
    restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 908, in _restore_from_checkpoint_position
    tensor_saveables, python_saveables))
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 289, in restore_saveables
    validated_saveables).restore(self.save_path_tensor)
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 255, in restore
    restore_ops.update(saver.restore(file_prefix))
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 102, in restore
    restored_tensors, restored_shapes=None)
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object_util.py"", line 115, in restore
    self.handle_op, self._var_shape, restored_tensor)
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 291, in shape_safe_assign_variable_handle
    shape.assert_is_compatible_with(value_tensor.shape)
  File ""/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py"", line 1115, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
ValueError: Shapes (20,) and (100,) are incompatible
```
the Shapes(20,) is the shape of reg_head, the Shapes(100,) is the shape of cla_head
Maybe the loading order is out of order

## When disable_eager
##  the weights saved under mode=='train' could  be restored into model when mode=='test' with some Warnings:
```
WARNING:tensorflow:From /home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.engine.training.Model object at 0x7f26680ae5d0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7f26408af190>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.engine.training.Model object at 0x7f266830fdd0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7f26402047d0>).

```
"
34297,tf.function hangs on ragged tensor input,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):No
- TensorFlow installed from (source or binary):Colab
- TensorFlow version (use command below):2.0.0
- Python version:3.6
- GPU model and memory:None

**Describe the current behavior**
When using tf.function with a number of for loops on a RaggedTensor, the function call hangs (I stopped waiting after half hour).
-when running the function directly (no tf.function decorator), the function executes immediately
-when converting the ragged tensor to dense tensor, the function executes immediately.

I couldn't pinpoint the exact combination of operations that causes this Autograph behavior, but I tried to reduce my code to the simplest combination that still causes this behavior.
I struggled for hours with my own code, trying to get tf.function to work, until I figured it was due to the ragged tensor + for loops + tf.function hanging the kernel

I observed similar behavior on my machine and a colab machine as well.

**Describe the expected behavior**
Should execute in a comparable time to a dense tensor.

**Code to reproduce the issue**
```
%tensorflow_version 2.x
import tensorflow as tf
import numpy as np

inp=tf.ragged.constant(np.arange(1000,dtype=np.float32).reshape(10,10,10))

@tf.function    #if not using tf.function it runs well
def ragged_example(r_tensor):
  s=tf.constant(0.0)
  for i in tf.range(10):
    inner=r_tensor[i]
    for x in inner:
      b=tf.reduce_sum(x)
      s=s+b
  return s

#inp=inp.to_tensor() #if this is uncommented, it runs well

ragged_example(inp) #this hangs
```
**Other observations**
Also noted very large memory footprint as a result (9gb and growing)"
34296,Error description is not clear with new experimental TF_lite_converter ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): `tf-nightly`


**Command used to run the converter or code if you’re using the Python API**

```
import tensorflow as tf
mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
# without the following two lines, it will throw
# ValueError: Cannot set tensor: Got value of type NOTYPE but expected type FLOAT32 for input 0, name: flatten_input 
#x_train = tf.dtypes.cast(x_train,tf.float32)
#x_test = tf.dtypes.cast(x_test,tf.float32)

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=1)
model.evaluate(x_test, y_test)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
#converter.experimental_enable_mlir_converter = True
tflite_model = converter.convert()

import numpy as np
expected = model.predict(x_test[0:1])

# Run the model with TensorFlow Lite
interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
interpreter.set_tensor(input_details[0][""index""], x_test[0:1, :, :])
interpreter.invoke()
result = interpreter.get_tensor(output_details[0][""index""])

# Assert if the result of TFLite model is consistent with the TF model.
np.testing.assert_almost_equal(expected, result)
print(""Done. The result of TensorFlow matches the result of TensorFLow Lite."")
```


**The output from the converter invocation**

`ValueError: Cannot set tensor: Got value of type NOTYPE but expected type FLOAT32 for input 0, name: flatten_input`

**Failure details**

Conversion is successful if the data type is `float32`. If the data type of input data is `float64`, then it will throw `ValueError: Cannot set tensor: Got value of type NOTYPE but expected type FLOAT32 for input 0, name: flatten_input ` which is not clear.  Most of the keras models In Tensorflow website under tutorials are with `float64` datatype. So, if the user try to convert them into tf_lite model, they will end up in this `ValueError`. I think we need to update the Error description. Instead of showing `NOTYPE`, may it is better to use `float64` or other data types that are not compatible. 

Here is the link to colab [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/86eb0abb1cda9888d87c4d7c109a48c4/untitled632.ipynb)

"
34291,Error on compiling from source,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux archlinux 5.3.11-arch1-1 x86_64 GNU/Linux

- TensorFlow installed from (source or binary): source 
- TensorFlow version: commit hash: 872b1ab23f0aac182d5b2051f45d5d003963bfe3
- Python version: 3.7.5
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): bazel 0.29.1- (@non-git)
- GCC/Compiler version (if compiling from source): gcc (GCC) 9.2.0
- CUDA/cuDNN/TensorRT version: 10.1.243-2/7.6.4.38-1/6.0.1.5-1
- GPU model and memory: nVidia RTX 2080 8GB


**Describe the problem**
Compiling with bazel fails: 
ERROR: /home/jaaq/.cache/bazel/_bazel_jaaq/c463894dd2648fc5b64eeed02cc022b5/external/grpc/BUILD:507:1: C++ compilation of rule '@grpc//:gpr_base' failed (Exit 1)

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
git clone repo
cd tensorflow
source /opt/anaconda/bin/activate
conda activate python375env
./configure (Yes on XLA JIT, CUDA, TensorRT, clang)
bazel build //tensorflow/tools/pip_package:build_pip_package
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
ERROR: /home/jaaq/.cache/bazel/_bazel_jaaq/c463894dd2648fc5b64eeed02cc022b5/external/grpc/BUILD:507:1: C++ compilation of rule '@grpc//:gpr_base' failed (Exit 1)
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: error: ambiguating new declaration of 'long int gettid()'
 static long gettid(void) { return syscall(__NR_gettid); }
             ^~~~~~
In file included from /usr/include/unistd.h:1170,
                 from external/grpc/src/core/lib/gpr/log_linux.cc:41:
/usr/include/bits/unistd_ext.h:34:16: note: old declaration '__pid_t gettid()'
 extern __pid_t gettid (void) __THROW;
                ^~~~~~
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: warning: 'long int gettid()' defined but not used [-Wunused-function]
 static long gettid(void) { return syscall(__NR_gettid); }
             ^~~~~~
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 89.815s, Critical Path: 22.19s
INFO: 1215 processes: 1215 local.
FAILED: Build did NOT complete successfully
"
34290,Brackets in directory for tf.train.CheckpointManager in TF2.0,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Debian (GCP notebook)**
- TensorFlow installed from (source or binary): **preinstalled on GCP notebook**
- TensorFlow version (use command below): **2.0.0**
- Python version: **3.5.3**
- GPU model and memory: **None**

**Describe the current behavior**
This problem concerns tf.train.CheckpointManager and tf.train.Checkpoint in TF 2.0. If the checkpoint directory contains square brackets (`[` or `]`), then loading checkpoints with tf.train.Checkpoint.restore fails. CheckpointManager will save and track checkpoints as expected but does not remove them according to `max_to_keep`.

I see that square brackets are [not recommended](https://cloud.google.com/storage/docs/naming) for Google Cloud Storage blobs, however this happens for both checkpoints stored in Google Cloud Storage and checkpoints stored locally.

As an example:
Valid checkpoints exist in `/tmp/checkpoints_[with]_bracket/` Calling
```
checkpoint_dir = '/tmp/checkpoints_[with]_bracket/'
tf.train.Checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))
```
Gives the error:
```
NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /tmp/checkpoints_[with]_bracket/ckpt-4
```

**Describe the expected behavior**

- Allow square brackets in the checkpoint path
or
- fail at CheckpointManager creation if `directory` parameter contains disallowed characters 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**[https://gist.github.com/klanderson/be46cc3e3f7e6575bd2a45450c0ac102](https://gist.github.com/klanderson/be46cc3e3f7e6575bd2a45450c0ac102)
Code works as-is. Add a bracket somewhere in the path in `Line 28` to see error**



"
34289,Couldn't quantize a model with QUANTIZED_UINT8 if output layer don't have activation,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): installed a binary with Conda
- TensorFlow version (or github SHA if from source): 1.14.0


**Command used to run the converter or code if you’re using the Python API**

```
import tensorflow as tf
from tensorflow import keras

import numpy as np
import matplotlib.pyplot as plt

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

train_images = train_images / 255.0
test_images = test_images / 255.0

def build_keras_model():
  return keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(10)
  ])

train_graph = tf.Graph()
train_sess = tf.Session(graph=train_graph)

keras.backend.set_session(train_sess)
with train_graph.as_default():
  train_model = build_keras_model()

  tf.contrib.quantize.create_training_graph(input_graph=train_graph, quant_delay=100)
  train_sess.run(tf.global_variables_initializer())

  train_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
  )
  train_model.fit(train_images, train_labels, epochs=5)

  saver = tf.train.Saver()
  saver.save(train_sess, 'checkpoints')

eval_graph = tf.Graph()
eval_sess = tf.Session(graph=eval_graph)

keras.backend.set_session(eval_sess)

with eval_graph.as_default():
  keras.backend.set_learning_phase(0)
  eval_model = build_keras_model()
  tf.contrib.quantize.create_eval_graph(input_graph=eval_graph)
  eval_graph_def = eval_graph.as_graph_def()
  saver = tf.train.Saver()
  saver.restore(eval_sess, 'checkpoints')

  frozen_graph_def = tf.graph_util.convert_variables_to_constants(
    eval_sess,
    eval_graph_def,
    [eval_model.output.op.name]
  )
  with open('frozen_model.pb', 'wb') as f:
    f.write(frozen_graph_def.SerializeToString())

converter = tf.lite.TFLiteConverter.from_frozen_graph(
  'frozen_model.pb',
  ['flatten_input'],
  ['dense_1/BiasAdd'])
converter.inference_type = tf.lite.constants.QUANTIZED_UINT8
input_arrays = converter.get_input_arrays()
converter.quantized_input_stats = {input_arrays[0] : (0, 255)}  # mean, std_dev
tflite_model = converter.convert()
open('model.tflite', 'wb').write(tflite_model)
```

**The output from the converter invocation**

```
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-18-c82690488195> in <module>
      6 input_arrays = converter.get_input_arrays()
      7 converter.quantized_input_stats = {input_arrays[0] : (0, 255)}  # mean, std_dev
----> 8 tflite_model = converter.convert()
      9 open('model.tflite', 'wb').write(tflite_model)

~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/lite/python/lite.py in convert(self)
    896           input_tensors=self._input_tensors,
    897           output_tensors=self._output_tensors,
--> 898           **converter_kwargs)
    899     else:
    900       result = _toco_convert_graph_def(

~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)
    402   data = toco_convert_protos(model_flags.SerializeToString(),
    403                              toco_flags.SerializeToString(),
--> 404                              input_data.SerializeToString())
    405   return data
    406 

~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)
    170       stderr = _try_convert_to_unicode(stderr)
    171       raise ConverterError(
--> 172           ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
    173   finally:
    174     # Must manually cleanup files.

ConverterError: TOCO failed. See console for info.
2019-11-14 14:46:19.525955: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 39 operators, 63 arrays (0 quantized)
2019-11-14 14:46:19.526224: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 39 operators, 63 arrays (0 quantized)
2019-11-14 14:46:19.527392: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 10 operators, 18 arrays (1 quantized)
2019-11-14 14:46:19.527775: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 9 operators, 17 arrays (1 quantized)
2019-11-14 14:46:19.527893: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 8 operators, 15 arrays (1 quantized)
2019-11-14 14:46:19.527982: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 8 operators, 15 arrays (1 quantized)
2019-11-14 14:46:19.528015: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 5 operators, 12 arrays (1 quantized)
2019-11-14 14:46:19.528050: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 5 operators, 12 arrays (1 quantized)
2019-11-14 14:46:19.528084: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 5 operators, 12 arrays (1 quantized)
2019-11-14 14:46:19.529767: W tensorflow/lite/toco/graph_transformations/quantize.cc:132] Constant array batch_normalization/batchnorm/mul lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.
2019-11-14 14:46:19.529796: W tensorflow/lite/toco/graph_transformations/quantize.cc:132] Constant array batch_normalization/batchnorm/sub lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.
2019-11-14 14:46:19.529847: F tensorflow/lite/toco/graph_transformations/quantize.cc:149] Array dense_1/BiasAdd does not have MinMax information, and is not a constant array. Cannot proceed with quantization.
Fatal Python error: Aborted

Current thread 0x00007f40e79dd700 (most recent call first):
  File ""/home/dojip.kim/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33 in execute
  File ""/home/dojip.kim/anaconda3/envs/tensorflow/lib/python3.6/site-packages/absl/app.py"", line 251 in _run_main
  File ""/home/dojip.kim/anaconda3/envs/tensorflow/lib/python3.6/site-packages/absl/app.py"", line 300 in run
  File ""/home/dojip.kim/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40 in run
  File ""/home/dojip.kim/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59 in main
  File ""/home/dojip.kim/anaconda3/envs/tensorflow/bin/toco_from_protos"", line 11 in <module>
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
I could quantize a model with QUNATIZED_UINT8 if output layer have activation like 'softmax'.  I want to quantize a model without the activation function for the final output. In that case, I couldn't quantize it.

2019-11-14 14:46:19.529847: F tensorflow/lite/toco/graph_transformations/quantize.cc:149] Array dense_1/BiasAdd does not have MinMax information, and is not a constant array. Cannot proceed with quantization.
Fatal Python error: Aborted

Please let me know how to quantize a model.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34287,Cannot dlopen some GPU libraries - Tensorflow2.0 ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  (using pip install tensorflow-gpu)
- TensorFlow version: 2.0
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: V100 , memory_limit: 17179869184




**Describe the problem**
I am using tensorflow2.0. The version of cuda installed on my system is cuda 10.0.
I installed tensorflow-gpu. My machine has a gpu-device available and I am trying to get tensorflow-gpu to work.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow as tf
tf.test.is_gpu_available()


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Output:
2019-11-14 22:27:38.319853: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-14 22:27:38.327036: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2019-11-14 22:27:38.328593: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560728b482f0 executing computations on platform Host. Devices:
2019-11-14 22:27:38.328624: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-14 22:27:38.330948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-14 22:27:40.529184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560728c428e0 executing computations on platform CUDA. Devices:
2019-11-14 22:27:40.529229: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0
2019-11-14 22:27:40.529242: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla V100-PCIE-16GB, Compute Capability 7.0
2019-11-14 22:27:40.531923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:86:00.0
2019-11-14 22:27:40.532794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:d8:00.0
2019-11-14 22:27:40.532945: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/singularity/3.2.0/libexec:/usr/local/singularity/3.2.0/lib:/usr/local/squashfs/4.3.0.21/lib64:/usr/local/torque-releases/torque-6.1.2-el7/lib:/.singularity.d/libs
2019-11-14 22:27:40.533020: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/singularity/3.2.0/libexec:/usr/local/singularity/3.2.0/lib:/usr/local/squashfs/4.3.0.21/lib64:/usr/local/torque-releases/torque-6.1.2-el7/lib:/.singularity.d/libs
2019-11-14 22:27:40.533090: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/singularity/3.2.0/libexec:/usr/local/singularity/3.2.0/lib:/usr/local/squashfs/4.3.0.21/lib64:/usr/local/torque-releases/torque-6.1.2-el7/lib:/.singularity.d/libs
2019-11-14 22:27:40.533159: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/singularity/3.2.0/libexec:/usr/local/singularity/3.2.0/lib:/usr/local/squashfs/4.3.0.21/lib64:/usr/local/torque-releases/torque-6.1.2-el7/lib:/.singularity.d/libs
2019-11-14 22:27:40.533228: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/singularity/3.2.0/libexec:/usr/local/singularity/3.2.0/lib:/usr/local/squashfs/4.3.0.21/lib64:/usr/local/torque-releases/torque-6.1.2-el7/lib:/.singularity.d/libs
2019-11-14 22:27:40.533294: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/singularity/3.2.0/libexec:/usr/local/singularity/3.2.0/lib:/usr/local/squashfs/4.3.0.21/lib64:/usr/local/torque-releases/torque-6.1.2-el7/lib:/.singularity.d/libs
2019-11-14 22:27:40.533364: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/singularity/3.2.0/libexec:/usr/local/singularity/3.2.0/lib:/usr/local/squashfs/4.3.0.21/lib64:/usr/local/torque-releases/torque-6.1.2-el7/lib:/.singularity.d/libs
2019-11-14 22:27:40.533381: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2019-11-14 22:27:40.533434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-14 22:27:40.533451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 
2019-11-14 22:27:40.533463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y 
2019-11-14 22:27:40.533474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N 
False
"
34286,TFLite crash (SIGABRT) while running Conv3D on Android,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Build environment is Linux Ubuntu 16.04 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Runtime environment is Samsung s8+
- TensorFlow installed from (source or binary): built from source with select-tf-ops using: 
```
bazel build --cxxopt='--std=c++11' -c opt \
 --config=android_arm --config=monolithic \
 //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops
```
- TensorFlow version: 1.15.0rc2
- Keras version: 2.2.4-tf
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version: 10.0
- GPU model and memory: not relevant

**Describe the current behavior**
I am trying to get a network (with conv3d ops) to run on my Android system using TFLite. I have followed all the steps mentioned [here](https://www.tensorflow.org/lite/guide/ops_select), and I can convert the network without issue. During runtime, I also appear to be able to load the converted tflite model without issue, however, during my call to `runForMultipleInputsOutputs()`, tflite crashes giving me a SIBABRT coming from libtensorflowlite_flex_jni.so (full stack trace below).

**Describe the expected behavior**
I expect it to not crash when running

**Code to reproduce the issue**
I made a dummy network to try and isolate the issue. I built the network using the following:
```
import tensorflow as tf
import numpy as np

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv3D(1, (4, 4, 4), input_shape=(4, 8, 8, 1), name='conv'))
model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                      optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),
                      metrics=[tf.keras.metrics.categorical_accuracy])

x = np.random.random((1, 4, 8, 8, 1))
y = np.random.random((1, 1, 5, 5, 1))
model.train_on_batch(x, y)
model.predict(x)

# Save tf.keras model in HDF5 format
keras_file = ""conv3d.h5""
tf.keras.models.save_model(model, keras_file)

# Convert the model to tflite format
converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)
converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
open(""conv3d.tflite"", ""wb"").write(tflite_model)
```

I then load and run the model on the android using ByteBuffers to hold the input/outputs. I can provide this code if requested, but I don't suspect it to be the problem as I use it for other working projects. I'm confident that this is a conv3d issue, because I have also built a **conv2d** dummy network, using the exact same build procedure + runtime environment, and it runs without crashing.

**Other info / logs**
The full android backtrace during the call to runForMultipleInputsOutputs():
```
A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
A/DEBUG: Build fingerprint: 'samsung/dream2ltexx/dream2lte:9/PPR1.180610.011/G955FXXS5DSI1:user/release-keys'
A/DEBUG: Revision: '10'
A/DEBUG: ABI: 'arm'
A/DEBUG: pid: 6774, tid: 6817, name: Thread-2  >>> com.segmentation.qussegserviceNVW <<<
A/DEBUG: signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------
A/DEBUG:     r0  00000000  r1  00001aa1  r2  00000006  r3  00000008
A/DEBUG:     r4  00001a76  r5  00001aa1  r6  b7628eac  r7  0000010c
A/DEBUG:     r8  b7629014  r9  b7628fa0  r10 b762903c  r11 e4095c70
A/DEBUG:     ip  b7628e48  sp  b7628e98  lr  e6c73e71  pc  e6c6ae62
A/DEBUG: backtrace:
A/DEBUG:     #00 pc 0001ce62  /system/lib/libc.so (abort+58)
A/DEBUG:     #01 pc 002181cd  /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/lib/arm/libtensorflowlite_flex_jni.so
A/DEBUG:     #02 pc 002213fd  /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/lib/arm/libtensorflowlite_flex_jni.so
A/DEBUG:     #03 pc 00225795  /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/lib/arm/libtensorflowlite_flex_jni.so
A/DEBUG:     #04 pc 0021fb63  /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/lib/arm/libtensorflowlite_flex_jni.so
A/DEBUG:     #05 pc 00335dcd  /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/lib/arm/libtensorflowlite_flex_jni.so
A/DEBUG:     #06 pc 00338313  /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/lib/arm/libtensorflowlite_flex_jni.so
A/DEBUG:     #07 pc 0020925b  /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/lib/arm/libtensorflowlite_flex_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+26)
A/DEBUG:     #08 pc 00415879  /system/lib/libart.so (art_quick_generic_jni_trampoline+40)
A/DEBUG:     #09 pc 00411375  /system/lib/libart.so (art_quick_invoke_stub_internal+68)
A/DEBUG:     #10 pc 003ea57b  /system/lib/libart.so (art_quick_invoke_static_stub+222)
A/DEBUG:     #11 pc 000a1627  /system/lib/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+154)
A/DEBUG:     #12 pc 001e88c9  /system/lib/libart.so (art::interpreter::ArtInterpreterToCompiledCodeBridge(art::Thread*, art::ArtMethod*, art::ShadowFrame*, unsigned short, art::JValue*)+236)
A/DEBUG:     #13 pc 001e33b7  /system/lib/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+814)
A/DEBUG:     #14 pc 003e60af  /system/lib/libart.so (MterpInvokeStatic+130)
A/DEBUG:     #15 pc 00404294  /system/lib/libart.so (ExecuteMterpImpl+14612)
A/DEBUG:     #16 pc 001aa16c  /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/base.apk_6774_6774 (deleted) (org.tensorflow.lite.NativeInterpreterWrapper.run+164)
A/DEBUG:     #17 pc 001c7b33  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.2760711098+378)
A/DEBUG:     #18 pc 001cc219  /system/lib/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+152)
A/DEBUG:     #19 pc 001e339f  /system/lib/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+790)
A/DEBUG:     #20 pc 003e50d3  /system/lib/libart.so (MterpInvokeVirtual+442)
A/DEBUG:     #21 pc 00404114  /system/lib/libart.so (ExecuteMterpImpl+14228)
A/DEBUG:     #22 pc 001a9962  /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/base.apk_6774_6774 (deleted) (org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs+10)
A/DEBUG:     #23 pc 001c7b33  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.2760711098+378)
A/DEBUG:     #24 pc 001cc15f  /system/lib/libart.so (art::interpreter::EnterInterpreterFromEntryPoint(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*)+82)
A/DEBUG:     #25 pc 003d8bb9  /system/lib/libart.so (artQuickToInterpreterBridge+880)
A/DEBUG:     #26 pc 004158ff  /system/lib/libart.so (art_quick_to_interpreter_bridge+30)
A/DEBUG:     #27 pc 0001c0fd  /dev/ashmem/dalvik-jit-code-cache_6774_6774 (deleted) (com.segmentation.qussegserviceNVW.TensorFlowSegmentRunner$SegNetRunner.segmentChunk+492)
A/DEBUG:     #28 pc 004113bb  /system/lib/libart.so (art_quick_osr_stub+42)
A/DEBUG:     #29 pc 0024d8a9  /system/lib/libart.so (art::jit::Jit::MaybeDoOnStackReplacement(art::Thread*, art::ArtMethod*, unsigned int, int, art::JValue*)+1388)
A/DEBUG:     #30 pc 003e9aab  /system/lib/libart.so (MterpMaybeDoOnStackReplacement+86)
A/DEBUG:     #31 pc 00410bf4  /system/lib/libart.so (ExecuteMterpImpl+66164)
A/DEBUG:     #32 pc 0002e7b8  /dev/ashmem/dalvik-classes2.dex extracted in memory from /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/base.apk!classes2.dex_6774_6774 (deleted) (com.segmentation.qussegserviceNVW.TensorFlowSegmentRunner$SegNetRunner.segmentChunk+76)
A/DEBUG:     #33 pc 001c7b33  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.2760711098+378)
A/DEBUG:     #34 pc 001cc219  /system/lib/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+152)
A/DEBUG:     #35 pc 001e339f  /system/lib/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+790)
A/DEBUG:     #36 pc 003e5f61  /system/lib/libart.so (MterpInvokeDirect+196)
A/DEBUG:     #37 pc 00404214  /system/lib/libart.so (ExecuteMterpImpl+14484)
A/DEBUG:     #38 pc 0002e750  /dev/ashmem/dalvik-classes2.dex extracted in memory from /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/base.apk!classes2.dex_6774_6774 (deleted) (com.segmentation.qussegserviceNVW.TensorFlowSegmentRunner$SegNetRunner.access$100)
A/DEBUG:     #39 pc 001c7b33  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.2760711098+378)
A/DEBUG:     #40 pc 001cc15f  /system/lib/libart.so (art::interpreter::EnterInterpreterFromEntryPoint(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*)+82)
A/DEBUG:     #41 pc 003d8bb9  /system/lib/libart.so (artQuickToInterpreterBridge+880)
A/DEBUG:     #42 pc 004158ff  /system/lib/libart.so (art_quick_to_interpreter_bridge+30)
A/DEBUG:     #43 pc 0001b5fd  /dev/ashmem/dalvik-jit-code-cache_6774_6774 (deleted) (com.segmentation.qussegserviceNVW.TensorFlowSegmentRunner.segmentFrame+604)
A/DEBUG:     #44 pc 00411375  /system/lib/libart.so (art_quick_invoke_stub_internal+68)
A/DEBUG:     #45 pc 003ea479  /system/lib/libart.so (art_quick_invoke_stub+224)
A/DEBUG:     #46 pc 000a1615  /system/lib/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+136)
A/DEBUG:     #47 pc 001e88c9  /system/lib/libart.so (art::interpreter::ArtInterpreterToCompiledCodeBridge(art::Thread*, art::ArtMethod*, art::ShadowFrame*, unsigned short, art::JValue*)+236)
A/DEBUG:     #48 pc 001e33b7  /system/lib/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+814)
A/DEBUG:     #49 pc 003e50d3  /system/lib/libart.so (MterpInvokeVirtual+442)
A/DEBUG:     #50 pc 00404114  /system/lib/libart.so (ExecuteMterpImpl+14228)
A/DEBUG:     #51 pc 0002edb4  /dev/ashmem/dalvik-classes2.dex extracted in memory from /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/base.apk!classes2.dex_6774_6774 (deleted) (com.segmentation.qussegserviceNVW.TensorFlowSegmentRunner.segmentCine+40)
A/DEBUG:     #52 pc 001c7b33  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.2760711098+378)
A/DEBUG:     #53 pc 001cc219  /system/lib/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+152)
A/DEBUG:     #54 pc 001e339f  /system/lib/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+790)
A/DEBUG:     #55 pc 003e5ca3  /system/lib/libart.so (MterpInvokeInterface+1010)
A/DEBUG:     #56 pc 00404314  /system/lib/libart.so (ExecuteMterpImpl+14740)
A/DEBUG:     #57 pc 00028310  /dev/ashmem/dalvik-classes2.dex extracted in memory from /data/app/com.segmentation.qussegserviceNVW-52gMpws9Z9fl4lOXs6XvOw==/base.apk!classes2.dex_6774_6774 (deleted) (com.segmentation.qussegserviceNVW.CinePlayerActivity$3$1.run+20)
A/DEBUG:     #58 pc 001c7b33  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.2760711098+378)
A/DEBUG:     #59 pc 001cc15f  /system/lib/libart.so (art::interpreter::EnterInterpreterFromEntryPoint(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*)+82)
A/DEBUG:     #60 pc 003d8bb9  /system/lib/libart.so (artQuickToInterpreterBridge+880)
A/DEBUG:     #61 pc 004158ff  /system/lib/libart.so (art_quick_to_interpreter_bridge+30)
A/DEBUG:     #62 pc 00411375  /system/lib/libart.so (art_quick_invoke_stub_internal+68)
A/DEBUG:     #63 pc 003ea479  /system/lib/libart.so (art_quick_invoke_stub+224)
A/DEBUG:     #64 pc 000a1615  /system/lib/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+136)
A/DEBUG:     #65 pc 0034b0c5  /system/lib/libart.so (art::(anonymous namespace)::InvokeWithArgArray(art::ScopedObjectAccessAlreadyRunnable const&, art::ArtMethod*, art::(anonymous namespace)::ArgArray*, art::JValue*, char const*)+52)
A/DEBUG:     #66 pc 0034be1d  /system/lib/libart.so (art::InvokeVirtualOrInterfaceWithJValues(art::ScopedObjectAccessAlreadyRunnable const&, _jobject*, _jmethodID*, jvalue*)+320)
A/DEBUG:     #67 pc 0036d203  /system/lib/libart.so (art::Thread::CreateCallback(void*)+866)
A/DEBUG:     #68 pc 00064899  /system/lib/libc.so (__pthread_start(void*)+140)
A/DEBUG:     #69 pc 0001e329  /system/lib/libc.so (__start_thread+24)
```

"
34283,copy paste error for value_embeddings = token_embedding(query_input),"Should be value_input?

Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
34282,tf-nightly: 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version: tf_nightly-2.1.0.dev20191114
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: 10.0
- GPU model and memory: NVIDIA p100

Looks like the latest nightly builds of TensorFlow require CUDA 10.1 for GPU support, is that intentional?

```
> import tensorflow as tf
```

```
2019-11-14 16:21:07.535467: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2019-11-14 16:21:07.535493: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
```"
34280,Add ExtractImagePatches op to tensorflow lite (flex) whitelist,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): 1.14 top of the tree 14 Nov2019 (last checkin 00fad90125b18b80fe054de1055770cfb8fe4ba3)


**Provide the text output from tflite_convert**

2019-11-14 17:57:00.806373: W tensorflow/lite/toco/tflite/operator.cc:2661] Op ExtractImagePatches is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-14 17:57:00.806488: W tensorflow/lite/toco/tflite/operator.cc:2661] Op ExtractImagePatches is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-14 17:57:00.806577: E tensorflow/lite/toco/toco_tooling.cc:462] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md

"
34278,speech_commands: Range cannot be empty (low >= high) unless no samples are taken,"I'm using the speech_commands example and trying to load my own set of wav files, which I've organized according to the tutorial. Here's the command I'm entering on the terminal:
python3 /Users/etc/train.py \
--data_url= \
--data_dir=/Users/etc/trial_classes \
--wanted_words=randomclass1,randomclass2 \
--sample_rate=44100

It's finding the files (so I've truncated the filepaths with ""etc"" below & above), but raises this error:

Traceback (most recent call last):
  File ""/Users/etc/speech_commands/train.py"", line 508, in <module>
    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/etc/speech_commands/train.py"", line 237, in main
    FLAGS.background_volume, time_shift_samples, 'training', sess)
  File ""/Users/etc/speech_commands/input_data.py"", line 575, in get_data
    background_index = np.random.randint(len(self.background_data))
  File ""mtrand.pyx"", line 992, in mtrand.RandomState.randint
ValueError: Range cannot be empty (low >= high) unless no samples are taken

I'm using
MacOs 10.13.6
Tensorflow version 2.0.0
Python version: 3.7.3

New to this so I appreciate the patience if I've done something dumb. Thanks!"
34277,C++ API producing incorrect model metaparams,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): 2.0 and 1.15
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

An autoencoder model consisting only of standard keras Dense layers is converted into a tflite model. This model can be loaded and inspected with the Python API. The output there is consistent with the output from the visualize.py script.
```
Input detail:  {'name': 'input_1', 'index': 1, 'shape': array([ 1, 90], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}
Output detail:  {'name': 'Identity', 'index': 0, 'shape': array([ 1, 90], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}
```
When loading the very same model with the C++ API, I get ridicolous large results for the number of inputs/outputs/nodes. 

The C++ functions that were used to inspect the model are:
```
std::unique_ptr<tflite::Interpreter> interpreter = BuildInterpreter(*model);

LOG(INFO) << ""tensors size: "" << interpreter->tensors_size() << std::endl;
LOG(INFO) << ""nodes size: "" << interpreter->nodes_size() << std::endl;
LOG(INFO) << ""inputs: "" << interpreter->inputs().size() << std::endl;
LOG(INFO) << ""input(0) name: "" << interpreter->GetInputName(0) << std::endl;
LOG(INFO) << ""outputs: "" << interpreter->outputs().size() << std::endl;
LOG(INFO) << ""output(0) name: "" << interpreter->GetOutputName(0) << std::endl;

int t_size = interpreter->tensors_size();
for (int i = 0; i < t_size; i++) {
  LOG(INFO) << i << "": "" << interpreter->tensor(i)->name << "", "" 
            << interpreter->tensor(i)->bytes << "", ""
            << interpreter->tensor(i)->type << "", ""
            << interpreter->tensor(i)->params.scale << "", ""
            << interpreter->tensor(i)->params.zero_point << std::endl;
}
std::cout << ""End of test"" << std::endl;
```
This produces the following output:
```
tensors size: 21
nodes size: 11936128518282651046
inputs: 25344
input(0) name: Identity
outputs: 18446744073709501604
output(0) name: Identity
0: Identity, 360, 1, 0, 0
1: input_1, 360, 1, 0, 0
2: model/dense/MatMul/ReadVariableOp/transpose, 3600, 9, 0.00187181, 0
3: model/dense/MatMul_bias, 160, 1, 0, 0
4: model/dense/Relu, 160, 1, 0, 0
5: model/dense_1/MatMul/ReadVariableOp/transpose, 1600, 1, 0, 0
6: model/dense_1/MatMul_bias, 40, 1, 0, 0
7: model/dense_1/Relu, 40, 1, 0, 0
8: model/dense_2/MatMul/ReadVariableOp/transpose, 1600, 1, 0, 0
9: model/dense_2/MatMul_bias, 160, 1, 0, 0
10: model/dense_2/Relu, 160, 1, 0, 0
11: model/dense_3/MatMul/ReadVariableOp/transpose, 3600, 9, 0.00208381, 0
12: model/dense_3/MatMul_bias, 360, 1, 0, 0
13: End of test
```

The code to create the tflite model to inspect can be found on my repo (https://github.com/DocDriven/tflite-cpp-api-tests). All relevant files are named `simple_ae.*`. 

I suspect the C++ API to be broken at some point, as the models seem to be fine. Same results for TF 1.x and TF2.0. Trying different models yields the exact same ridicolous values, independently from their size.
"
34276,Tensorboard callback not writing the training metrics,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from: pip
- TensorFlow version: 2.0.0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0.130
- GPU model and memory: Quadro P5000 (16Gb)

**Describe the current behavior**
When I fit a model that takes time to infer (either with a big enough data size, or enough parameters), the `TensorBoard` calback doesn't log the training metrics (or just the first few epochs), or at least they don't appear on Tensorboard.

Although I first noticed the problem on GPU, it also appears on CPU.

**Describe the expected behavior**
I would like to have the training metrics logged as well.

**Code to reproduce the issue**
```python
import os.path as op
import time

import numpy as np
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.layers import Conv2D, Input
from tensorflow.keras.models import Model

size = 512
im = Input((size, size, 1))
im_conv = Conv2D(512, 3, padding='same', activation='relu')(im)
im_conv = Conv2D(1, 3, padding='same', activation='linear')(im_conv)
model = Model(im, im_conv)
model.compile(loss='mse', optimizer='adam', metrics=['mae'])

data = np.random.rand(1, size, size, 1)

run_id = f'{int(time.time())}'
log_dir = op.join('logs', run_id)
tboard_cback = TensorBoard(
    log_dir=log_dir, 
    histogram_freq=0, 
    write_graph=False, 
    write_images=False, 
    profile_batch=2,
)

model.fit(
    x=data, 
    y=data, 
    validation_data=[data, data], 
    callbacks=[tboard_cback,], 
    epochs=100, 
    verbose=0,
);
```

**Other info / logs**
I have posted an [SO question](https://stackoverflow.com/questions/58823959/tensorboard-callback-not-writing-the-training-metrics) which didn't get too much traction, that's why I am asking here.

Here is what I observe on Tensorboard: 
![tboard_fail_mre](https://user-images.githubusercontent.com/6387497/68871144-48230000-06fc-11ea-8b7b-b4fd317877d7.png)

"
34275,"Use HParams for ""learning rate"" hyper-parameter tuning","https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams

## Description of issue (what needs changing):
In the documentation it's nowhere written how to tune learning rate hyper-parameter for different optimisation algorithms. Plus the code in file **python3.6/site-packages/tensorboard/plugins/hparams/summary_v2.py** says,
`if dtype not in (int, float, bool, str):
--> 482       raise ValueError(""Unknown dtype: %r"" % (dtype,))` 

I am trying to create HParam list 

`hp_optimizer = hp.HParam('optimizer', hp.Discrete([optimizers.Adam(learning_rate=0.001),
                                                   optimizers.Adam(learning_rate=0.0001),
                                                   optimizers.Adamax(learning_rate=0.001),
                                                   optimizers.Adamax(learning_rate=0.0001),
                                                   optimizers.SGD(learning_rate=0.01),
                                                   optimizers.SGD(learning_rate=0.001)]))`

### Clear description
How should someone tune learning rate?"
34274,"ValueError: Error when checking input: expected flatten_1_input to have 3 dimensions, but got array with shape (60000, 1)","I ran the quickstart for beginner demo on my PC, but when i run the last cell, there is a **ValueError:Error when checking input: expected flatten_1_input to have 3 dimensions, but got array with shape (60000, 1)**, but when I ran the demo in Colab， there was no problem,
could you please tell what happend about this?
![image](https://user-images.githubusercontent.com/15179180/68869687-8c31f700-0734-11ea-8fa7-92705abc7310.png)
![image](https://user-images.githubusercontent.com/15179180/68869715-9522c880-0734-11ea-80aa-31106cc90506.png)
"
34273,Custom model implementation to tensor flow lite micro speech example,"Hi everyone.

Currently I am working with tensorflow lite micro speech example for stm32f7disco board and want to try it with my own trained model. Unfortunately, the result I have for now is that replacement of generated <tiny_conv>.cc file is not enough for that since my model doesn't pass some internal chekcups. Can somebody give an instruction on how to implement custom model to this project? And to be sure about the model can you give some explanations of parameters which are used in training and generating .tflite file?
"
34272,Python program to test tensorflow speech recognition lite model,"I converted speech recognition model generated using tensorflow train.py to tflite.
Is there a python program to run speech recognition with the tflite (similar to label_wav.py) ?"
34271,WARNING:tensorflow:Entity <bound method Customized_DenseLayer.call of <__main__.Customized_DenseLayer object at 0x00000262A54DA488>> could not be transformed and will be executed as-is.,"TensorFlow installed from binary
TensorFlow version 2.0.0
Python version 3.7.4
Cuda compilation tools, release 10.0, V10.0.130
cudnn version 7.6.4
GPU model and memory: GTX1060 6G

**Code to reproduce the issue**
class Customized_DenseLayer(tf.keras.layers.Layer):
    def __init__(self, units, activation = None, **kwargs):
        self.units = units
        self.activation = tf.keras.layers.Activation(activation)
        super(Customized_DenseLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        self.kernel = self.add_weight(name = 'kernel',
                                      shape = (input_shape[-1], self.units),
                                      dtype = tf.float32,
                                      initializer = 'uniform',
                                      trainable = True)
        self.bias = self.add_weight(name = 'bias',
                                    shape = (self.units,),
                                    dtype = tf.float32,
                                    initializer = 'zeros',
                                    trainable = True)
        super(Customized_DenseLayer, self).build(input_shape)

    def call(self, inputs):
        return self.activation(inputs @ self.kernel + self.bias)

housing = fetch_california_housing()
x_train_all, x_test, y_train_all, y_test = train_test_split(
    housing.data, housing.target, random_state = 7)
x_train, x_valid, y_train, y_valid = train_test_split(
    x_train_all, y_train_all, random_state = 11)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_valid_scaled = scaler.transform(x_valid)
x_test_scaled = scaler.transform(x_test)

print(x_train_scaled.shape, y_train.shape)
print(x_valid_scaled.shape, y_valid.shape)
print(x_test_scaled.shape, y_test.shape)
print(x_train_scaled.shape[1:])
print(x_train.shape[1:])

model = tf.keras.models.Sequential()
model.add(Customized_DenseLayer(units = 30, input_shape = (8, ), activation = 'relu'))
model.add(Customized_DenseLayer(units = 1))

print(model.summary())

**Other info / logs**
WARNING:tensorflow:Entity <bound method Customized_DenseLayer.call of <__main__.Customized_DenseLayer object at 0x00000262FB272888>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Customized_DenseLayer.call of <__main__.Customized_DenseLayer object at 0x00000262FB272888>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
"
34270,tf.function should trace the additional attributes of a tensor,"Hello, I'm not sure if this should be considered as a Feature or a Bug

**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes


**Describe the feature and the current behavior/state.**
Let's consider the following code (from TF 1.8) of the [loginctensornetwork](https://github.com/logictensornetworks/logictensornetworks/blob/master/logictensornetworks.py) project

```
def And(*wffs):
    if len(wffs) == 0:
        result = tf.constant(1.0)
        result.doms = []
    else:
        cross_wffs,_ = cross_args(wffs)
        label = ""_AND_"".join([wff.name.split("":"")[0] for wff in wffs])
        result = tf.identity(F_And(cross_wffs),name=label)
        result.doms = cross_wffs.doms
    return result

def constant(label,value=None,
                 min_value=None,
                 max_value=None):
    label = ""ltn_constant_""+label
    if value is not None:
        result = tf.constant(value,name=label)
    else:
        result = tf.Variable(tf.random_uniform(
                shape=(1,len(min_value)),
                minval=min_value,
                maxval=max_value,name=label))
    result.doms = []
    return result

def cross_args(args):
    result = args[0]
    for arg in args[1:]:
        result,_ = cross_2args(result,arg)
    result_flat = tf.reshape(result,
                             (tf.reduce_prod(tf.shape(result)[:-1]),
                              tf.shape(result)[-1]))
    result_args = tf.split(result_flat,[tf.shape(arg)[-1] for arg in args],1)
    return result, result_args

def cross_2args(X,Y):
    if X.doms == [] and Y.doms == []:
        result = tf.concat([X,Y],axis=-1)
        result.doms = []
        return result,[X,Y]
    X_Y = set(X.doms) - set(Y.doms)
    Y_X = set(Y.doms) - set(X.doms)
    eX = X
    eX_doms = [x for x in X.doms]
    for y in Y_X:
        eX = tf.expand_dims(eX,0)
        eX_doms = [y] + eX_doms
    eY = Y
    eY_doms = [y for y in Y.doms]
    for x in X_Y:
        eY = tf.expand_dims(eY,-2)
        eY_doms.append(x)
    perm_eY = []
    for y in eY_doms:
        perm_eY.append(eX_doms.index(y))
    eY = tf.transpose(eY,perm=perm_eY + [len(perm_eY)])
    mult_eX = [1]*(len(eX_doms)+1)
    mult_eY = [1]*(len(eY_doms)+1)
    for i in range(len(mult_eX)-1):
        mult_eX[i] = tf.maximum(1,tf.floor_div(tf.shape(eY)[i],tf.shape(eX)[i]))
        mult_eY[i] = tf.maximum(1,tf.floor_div(tf.shape(eX)[i],tf.shape(eY)[i]))
    result1 = tf.tile(eX,mult_eX)
    result2 = tf.tile(eY,mult_eY)
    result = tf.concat([result1,result2],axis=-1)
    result1.doms = eX_doms
    result2.doms = eX_doms
    result.doms = eX_doms
    return result,[result1,result2]
```

In this project, we need to store some metainformation within every tensor for ensuring the correct behaviour of functions like And regardless of the order of the arguments. 
Migrating to Tensorflow 2.0 if I decorate a function with @tf.function this function will not return the additional doms attribute of the tensor. This attributes, as you can see in functions like cross_2args are mandatory for ensuring the correctness of the flow. 
My goal is to ensure that if a function is adding a set of attributes to a tensor before returning it, decorating the same function with tf.function should in the same way return a tensor which has the same set of additional attributes.

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Everyone who wants to add new attributes to a tensor for having meta-information about it during the forward process

**Any Other info.**"
34269,A custom RNN cell does not support a high-order state_size,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):No
TensorFlow version (use command below):2.0.0
- Python version:3.7.4

**Describe the current behavior**
Cannot have a custom RNN cell to have a high order state_size.

**Describe the expected behavior**

**Code to reproduce the issue**
```
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers

class NewCell(layers.Layer):
    def __init__(self, name=None):
        
        self.state_size = (
            tf.TensorShape([1, 2]),
            (tf.TensorShape([1, 2]), tf.TensorShape([2, 3])) # error cause by this tuple
        )
        self.output_size = (tf.TensorShape([1, 2]), )
        super().__init__(name=name)
        
    def call(self, inputs, state):
        print('everything is safe and sound!')
        return inputs, state
        
rnn = layers.RNN(NewCell())
inputs = tf.convert_to_tensor(np.random.rand(2, 1, 2))
rnn(inputs)
```

**Other info / logs**

The error message is:
> int() argument must be a string, a bytes-like object or a number, not 'TensorShape'"
34268,tf.image.non_max_suppression bug when iou_threshold=0.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): both Mac and Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
I'm running following code:
```
boxes = [[ 90., 480., 106., 496.],
         [269.33333333, 536.33333333, 282.66666667, 549.66666667],
         [382.33333333, 556.33333333, 395.66666667, 569.66666667]]
result = tf.image.non_max_suppression(boxes, [1, 1, 1], 3, iou_threshold=0.0)
    with tf.Session() as sess:
        out = sess.run([result])
        indexes = out[0]
print(len(indexes))
```
Which prints out: 1 in `tensorflow==1.15.0`.

**Describe the expected behavior**
Expected behaviour is printing 3 as in tensorflow==1.13.1.
I've found a workaround for tensorflow==1.15.0 as setting io_threshold to some very small number, eg. `iou_threshold=0.001`, but the behaviour, probably a bug when `iou_threshold=0.0` is very very unexpected.

**Code to reproduce the issue**
```
boxes = [[ 90., 480., 106., 496.],
         [269.33333333, 536.33333333, 282.66666667, 549.66666667],
         [382.33333333, 556.33333333, 395.66666667, 569.66666667]]
result = tf.image.non_max_suppression(boxes, [1, 1, 1], 3, iou_threshold=0.0)
    with tf.Session() as sess:
        out = sess.run([result])
        indexes = out[0]
print(len(indexes))
```

This seems to me probably as a bug in case when iou_threshold=0.0. The bug was not present at tensorflow==1.13.1, but it's in tensorflow==1.15.0."
34267,Invoking Interpreter from C API fails with exit code 1,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 and Android 9
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy S10
- TensorFlow installed from (source or binary): Little bit of both
- TensorFlow version: 1.14, 1.15, 2.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: Pip and source
- Bazel version (if compiling from source): 26.1, 29.1
- GCC/Compiler version (if compiling from source): 7.4
- CUDA/cuDNN version: 10.1, 7
- GPU model and memory: 1050ti and whatever is in my phone



**Describe the problem**

When I build the tflite C api (currently on 1.14 after testing tf-nightly 1.15 and 2.0 (which I found out is not ready yet?)), I get a variety of weird errors. I have a simple tflite SSD model provided from the tf model zoo, which takes a 300x300x3 float32 input and outputs the usual 4 arrays of the detection_postprocess node provided by the tflite team. 

When I feed it a float array like in the Unity example, it crashes. I can either feed it a byte array or trick it into accepting the actual float array by dividing the input_data_size argument by 4, since it believes the TFL_TensorByteSize is 270000 when it should be 1080000.

Either way, when I call TFL_InterpreterInvoke, it crashes, and I haven't been able to follow the C api code to figure out why. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

First:
```
GCHandle tensorDataHandle = GCHandle.Alloc(inputTensorData, GCHandleType.Pinned);
        IntPtr tensorDataPtr = tensorDataHandle.AddrOfPinnedObject();
        IntPtr tensor = TFL_InterpreterGetInputTensor(interpreter, inputTensorIndex);

        int tensorByteSize = TFL_TensorByteSize(tensor);
        int inputDimsSize = Buffer.ByteLength(inputTensorData);

        Debug.Log(tensorByteSize + "" | "" + inputDimsSize);
        
        ThrowIfError(TFL_TensorCopyFromBuffer(
            tensor, tensorDataPtr, Buffer.ByteLength(inputTensorData)));
```
This works with a byte array or a float array with the third argument like `Buffer.ByteLength(inputTensorData) / 4`

Then
```
ThrowIfError(TFL_InterpreterInvoke(interpreter));
```
But since both of the input methods are actually wrong, it of course crashes with error code 1. 


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I am able to load the model using the python tf.lite.Interpreter like so:
```
model = tf.compat.v2.lite.Interpreter(""/path/detecter.tflite"")
```
All of the following calls, until model.invoke, work fine too. However, I can only model.invoke if the set_tensor call before uses a copy of x, otherwise it complains about references to internal data:
```
RuntimeError: There is at least 1 reference to internal data
      in the interpreter in the form of a numpy array or slice. Be sure to
      only hold the function returned from tensor() if you are using raw
      data access.
```

So to summarize; this works:
```
x = np.random.normal(size=(1,300,300,3))
print(x)
model.set_tensor(tensor_index=175,value=np.copy(x))
model.invoke()
```
But this does not:
```
x = np.random.normal(size=(1,300,300,3))
print(x)
model.set_tensor(tensor_index=175,value=x)
model.invoke()
```

Does TFL_TensorCopyFromBuffer not take ownership of the copy and fear breaking it?

Regardless, I can't seem to find any information about this and can't find the documentation to follow it myself, so any help is appreciated.

PS. When is the 2.0 C API ready to roll out? The new converter and tf2.0 control flow ops are very appealing."
34266,Cannot convert models to the *.tflite format with GRU/GRUCells,"Despite the declared support (https://www.tensorflow.org/lite/convert/rnn), it seems, it is not possible to convert the existing TF 2.0 model with GRU/GRUCells to the *.tflite format.
Where is the problem?

Here is the sample:
from tensorflow.keras.layers import *
from tensorflow.keras import Sequential
import numpy as np
import tensorflow as tf

model = Sequential()
model.add(Input((10, 1)))
#model.add(GRU(1))
#model.add(RNN(tf.compat.v1.nn.rnn_cell.GRUCell(1)))
model.compile(loss='mean_squared_error', optimizer='adam')

X = np.random.uniform(size=(10, 10, 1))
Y = np.random.uniform(size=(10, 1))
model.fit(X, Y)

model.save('model.h5', include_optimizer=False)

And the logs:

1. For the GRU:
2019-11-13 18:31:17.808698: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Traceback (most recent call last):
  File ""/home/harry/.local/bin/toco_from_protos"", line 10, in <module>
    sys.exit(main())
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/harry/.local/lib/python3.5/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/harry/.local/lib/python3.5/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.

2. For the GRUCells:
Traceback (most recent call last):
  File ""/home/harry/.local/bin/toco"", line 10, in <module>
    sys.exit(main())
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 594, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/harry/.local/lib/python3.5/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/harry/.local/lib/python3.5/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 577, in run_main
    _convert_tf2_model(tflite_flags)
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 228, in _convert_tf2_model
    model = keras.models.load_model(flags.keras_model_file)
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/saving/save.py"", line 146, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 168, in load_model_from_hdf5
    custom_objects=custom_objects)
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/saving/model_config.py"", line 55, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/layers/serialization.py"", line 106, in deserialize
    printable_module_name='layer')
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 303, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 377, in from_config
    custom_objects=custom_objects)
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/layers/serialization.py"", line 106, in deserialize
    printable_module_name='layer')
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 303, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/layers/recurrent.py"", line 958, in from_config
    cell = deserialize_layer(config.pop('cell'), custom_objects=custom_objects)
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/layers/serialization.py"", line 106, in deserialize
    printable_module_name='layer')
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 305, in deserialize_keras_object
    return cls.from_config(cls_config)
  File ""/home/harry/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 519, in from_config
    return cls(**config)
TypeError: __init__() missing 1 required positional argument: 'units'
"
34264,API function changed from Keras 2.3.1 to Keras 2.4.2?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version : `TF 2.0.0 stable + Keras 2.4.2 `(A )and `1.13.1 +Keras 2.3.1` (B)
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

I want to do a transfer learning on MobileNet and change the input size ,i copied the code [colab](https://colab.research.google.com/drive/1s1lkOiqKgl9_MsXJtPF--oh6uXHYkNYm#scrollTo=dV7a_Jca4cgC) according to [Changing input size of pre-trained models in Keras](https://medium.com/@ckyrkou/changing-input-size-of-pre-trained-models-in-keras-3dfbe3ca3091) .Everythin goes fine on my machine **B**(TF 1.13.1 + Keras 2.3.1) ,i could got exact the same output of author namely the input size got changed,while on my another machine **A**(TF 2..0.0+ Keras 2.4.2) i have to do some change and the result of input shape stays 224x224x3 but not as excepted 130x130x3.

+ Tensorflow 1.13.1+ Keras 2.3.1 works fine

```
# work on tensorflow 1.13.1 
import keras
import numpy as np
keras.backend.clear_session()

def change_model(model, new_input_shape=(None, 40, 40, 3)):
    # replace input shape of first layer
    model._layers[0].batch_input_shape = new_input_shape

    # rebuild model architecture by exporting and importing via json
    new_model = keras.models.model_from_json(model.to_json())

    # copy weights from old model to new one
    for layer in new_model.layers:
        try:
            layer.set_weights(model.get_layer(name=layer.name).get_weights())
            print(""Loaded layer {}"".format(layer.name))
        except:
            print(""Could not transfer weights for layer {}"".format(layer.name))
    return new_model

from keras.applications.mobilenet import MobileNet
from keras.preprocessing import image
from keras.applications.mobilenet import preprocess_input,decode_predictions
import numpy as np
model = MobileNet(weights='imagenet',include_top=True,input_shape=(224, 224,3))
new_model = change_model(model,new_input_shape=(None, 130, 130, 3))
new_model.summary()
```
ouput is 130x130x3
```
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 130, 130, 3)       0
_________________________________________________________________
conv1_pad (ZeroPadding2D)    (None, 131, 131, 3)       0
_________________________________________________________________
conv1 (Conv2D)               (None, 65, 65, 32)        864
_________________________________________________________________
conv1_bn (BatchNormalization (None, 65, 65, 32)        128
...
```
+ Tensorflow 2.0.0 + Keras 2.4.2 

```
# work on Tensorflow 2.0.0 
import keras
import tensorflow as tf
from keras_applications.mobilenet import MobileNet

def change_model(model, new_input_shape=(None,40, 40, 3)):
    # replace input shape of first layer
    model._layers[0].batch_input_shape = new_input_shape
    # rebuild model architecture by exporting and importing via json
    new_model = tf.keras.models.model_from_json(model.to_json())
    # copy weights from old model to new one
    for layer in new_model.layers:
        try:
            layer.set_weights(model.get_layer(name=layer.name).get_weights())
            print(""Loaded layer {}"".format(layer.name))
        except:
            print(""Could not transfer weights for layer {}"".format(layer.name))
    return new_model

model = MobileNet(include_top=True,weights=""imagenet"",input_shape=(224,224,3),backend = tf.keras.backend, layers = tf.keras.layers, models = tf.keras.models, utils = tf.keras.utils)
new_model = change_model(model,new_input_shape=(None,130,130,3))
print(new_model.summary())
```
output stays 224x224x3

```
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         
_________________________________________________________________
conv1 (Conv2D)               (None, 112, 112, 32)      864       
_________________________________________________________________
conv1_bn (BatchNormalization (None, 112, 112, 32)      128       
_________________________________________________________________
conv1_relu (ReLU)            (None, 112, 112, 32)      0         
_________________________________________________________________
....
```

**Will this change the current api? How?**

not sure.

"
34262,train with muliple gpu get error: Out of range:  End of sequence,"I am training with tensorflow2.0 with multiple GPU. It got the following errors. But if I use only one GPU it ran without any error. My tensorflow version is `tensorflow-gpu-2.0.0`:
```
tensorflow.python.framework.errors_impl.CancelledError: 4 root error(s) found.
  (0) Cancelled:  Operation was cancelled
     [[{{node cond_6/else/_59/IteratorGetNext}}]]
  (1) Out of range:  End of sequence
     [[{{node cond_4/else/_37/IteratorGetNext}}]]
  (2) Out of range:  End of sequence
     [[{{node cond_7/else/_70/IteratorGetNext}}]]
     [[metrics/accuracy/div_no_nan/ReadVariableOp_6/_154]]
  (3) Out of range:  End of sequence
     [[{{node cond_7/else/_70/IteratorGetNext}}]]
0 successful operations.
1 derived errors ignored. [Op:__inference_distributed_function_83325]

Function call stack:
distributed_function -> distributed_function -> distributed_function -> distributed_function
````

**and this is my code:**
```
import tensorflow as tf
import tensorflow_datasets as tfds

data_name = 'uc_merced'
dataset = tfds.load(data_name)
train_data, test_data = dataset['train'], dataset['train']

def parse(img_dict):
    img = tf.image.resize_with_pad(img_dict['image'], 256, 256)
    label = img_dict['label']
    return img, label

train_data = train_data.map(parse)
train_data = train_data.batch(96)

test_data = test_data.map(parse)
test_data = test_data.batch(96)

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    model = tf.keras.applications.ResNet50(weights=None, classes=21, input_shape=(256, 256, 3))
    model.compile(optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'])


model.fit(train_data, epochs=50, verbose=2, validation_data=test_data)
model.save('model/resnet_{}.h5'.format(data_name))
```"
34260,ValueError when computing Jacobian in eager mode,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>
I'm trying to add jacobian regularization to our loss function for reduce the intputs of sensitivity.
but in tensorflow(version 1.14.0), it's hard to build the dynamic graph of jacobian regularization.
I try to use ""GradientTape()"" for get the jacobian matrix. but there is problem to get the weight parameters's gradient.  ""raise ValueError(""Tape is already recording."")"", which is means we cannot use GradientTape() to get the jacobian regularization function. I guess there is another way to get it done. That's is build the dynamic graph of jacobian regularization function expliciltly. but this could be very hard for me. Is there any way to do this convenient？


**System information**
- TensorFlow version (you are using):
tensorflow version 1.14.0
- Are you willing to contribute it (Yes/No):
No, Cause i'm not very famililar with tensorflow's framework.


**Describe the feature and the current behavior/state.**
I want to use the jacobian regurlarization to my model in tensorflow. 
**Will this change the current api? How?**
yes,
**Who will benefit with this feature?**
expert, researcher.
**Any Other info.**
"
34257,Check failed: dim_size >= 1 (0 vs. 1),"**System information** 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 12.0


**Command used to run the converter or code if you’re using the Python API**

```
bazel run --config=opt tensorflow/contrib/lite/toco:toco -- \
  --input_file=/install_bar/frozen_inference_graph_quantization.pb \
  --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \
  --output_file=./frozen_inference_graph_quantization.tflite --inference_type=FLOAT \
  --input_data_types =FLOAT --input_arrays=[""image_tensor""] \
  --output_arrays=""detection_boxes"",""detection_scores"",""detection_classes"",""num_detections"",""raw_detection_boxes"",""raw_detection_scores"" \
  --input_shapes=1,299,299,3
```

**The output from the converter invocation**

2019-11-14 02:55:54.079426: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1127] Op node missing output type attribute: SecondStagePostprocessor/map/TensorArray_2
2019-11-14 02:55:54.079449: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter
2019-11-14 02:55:54.079540: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter
2019-11-14 02:55:54.079595: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter
2019-11-14 02:55:54.079641: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter
2019-11-14 02:55:54.079742: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: LoopCond
2019-11-14 02:55:54.079824: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1127] Op node missing output type attribute: SecondStagePostprocessor/map/while/LoopCond
2019-11-14 02:55:54.079927: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayReadV3
2019-11-14 02:55:54.080043: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter
2019-11-14 02:55:54.080130: I tensorflow/contrib/lite/toco/import_tensorflow.cc:189] Unsupported data type in placeholder op: 20
2019-11-14 02:55:54.080154: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter
2019-11-14 02:55:54.080274: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayReadV3
2019-11-14 02:55:54.080337: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter
2019-11-14 02:55:54.080365: I tensorflow/contrib/lite/toco/import_tensorflow.cc:189] Unsupported data type in placeholder op: 20
2019-11-14 02:55:54.080381: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter
2019-11-14 02:55:54.080610: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayWriteV3
2019-11-14 02:55:54.080645: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1127] Op node missing output type attribute: SecondStagePostprocessor/map/while/TensorArrayWrite/TensorArrayWriteV3
2019-11-14 02:55:54.080667: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter
2019-11-14 02:55:54.080696: I tensorflow/contrib/lite/toco/import_tensorflow.cc:189] Unsupported data type in placeholder op: 20
2019-11-14 02:55:54.080727: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Exit
2019-11-14 02:55:54.080834: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArraySizeV3
2019-11-14 02:55:54.080855: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1127] Op node missing output type attribute: SecondStagePostprocessor/map/TensorArrayStack/TensorArraySizeV3
2019-11-14 02:55:54.080950: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayGatherV3
2019-11-14 02:55:54.138743: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2132 operators, 3712 arrays (0 quantized)
2019-11-14 02:55:54.229959: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1999 operators, 3467 arrays (0 quantized)
2019-11-14 02:55:54.334917: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1999 operators, 3467 arrays (0 quantized)
2019-11-14 02:55:54.385257: F tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_slice.cc:59] Check failed: dim_size >= 1 (0 vs. 1)
Aborted (core dumped)

```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34256,tensorflow java 1.15.0 failed to load native lib,"**Describe the current behavior**
```
org.tensorflow.NativeLibrary: tryLoadLibraryFailed: no tensorflow_jni in java.library.path
org.tensorflow.NativeLibrary: jniResourceName: org/tensorflow/native/linux-x86_64/libtensorflow_jni.so
org.tensorflow.NativeLibrary: frameworkResourceName: org/tensorflow/native/linux-x86_64/libtensorflow_framework.so
org.tensorflow.NativeLibrary: org/tensorflow/native/linux-x86_64/libtensorflow_framework.so not found. This is fine assuming org/tensorflow/native/linux-x86_64/libtensorflow_jni.so is not built to depend on it.
org.tensorflow.NativeLibrary: extracting native library to: /xxx/tmp/tensorflow_native_libraries-1573652659702-0/libtensorflow_jni.so
org.tensorflow.NativeLibrary: copied 154073736 bytes to /xxx/tmp/tensorflow_native_libraries-1573652659702-0/libtensorflow_jni.so
java.lang.UnsatisfiedLinkError:/xxx/tmp/tensorflow_native_libraries-1573652659702-0/libtensorflow_jni.so: libtensorflow_framework.so.1: 无法打开共享对象文件: 没有那个文件或目录
	at java.lang.ClassLoader$NativeLibrary.load(Native Method)
	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941)
	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824)
	at java.lang.Runtime.load0(Runtime.java:809)
	at java.lang.System.load(System.java:1086)
	at org.tensorflow.NativeLibrary.load(NativeLibrary.java:101)
	at org.tensorflow.TensorFlow.init(TensorFlow.java:67)
	at org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:82)
	at org.tensorflow.SavedModelBundle.<clinit>(SavedModelBundle.java:170)
```

**Describe the expected behavior**
no exceptions
"
34255,Soft Placement Fails with Estimator Multi-worker CollectiveAllReduceStrategy ,"The cpu device appears to be ignored when `SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_0` is found to be incompatible with the GPU 

- Container: tensorflow/tensorflow:2.0.0-gpu-py3
- Cuda: 10
- Env: Kubeflow (tfjob)

```python
    session_config = tf.compat.v1.ConfigProto(
        allow_soft_placement=True,
    )
    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
    run_config = tf.estimator.RunConfig(
        model_dir=flags_obj.model_dir,
        save_checkpoints_steps=flags_obj.save_checkpoint_steps,
        log_step_count_steps=flags_obj.log_step_count_steps,
        save_summary_steps=flags_obj.save_summary_steps,
        train_distribute=strategy,
        eval_distribute=strategy,
        session_config=session_config
    )
```

Logs:
```I1114 00:37:58.694102 140070930646848 main.py:253] {'logtostderr': False, 'alsologtostderr': False, 'log_dir': '', 'v': 0, 'verbosity': 0, 'stderrthreshold': 'fatal', 'showprefixforinfo': True, 'run_with_pdb': False, 'pdb_post_mortem': False, 'run_with_profiling': False, 'profile_file': None, 'use_cprofile_for_profiling': True, 'only_check_args': False, 'op_conversion_fallback_to_while_loop': False, 'test_random_seed': 301, 'test_srcdir': '', 'test_tmpdir': '/tmp/absl_testing', 'test_randomize_ordering_seed': None, 'xml_output_file': '', 'model_dir': 's3://**censor**/**censor**', 'train_batch_size': 3, 'eval_batch_size': 4, 'log_step_count_steps': 64, 'save_summary_steps': 100, 'save_checkpoint_steps': 1000, 'train_steps': 1000000, 'eval_steps': 10, 'learning_rate': 1e-05, 'train_dir': '**censor**train/', 'eval_dir': '**censor**eval/', 'epochs': 5000, 'clean': False, 'ds': 'default', 'distribution_strategy': 'default', 'ara': None, 'all_reduce_alg': None, 'num_packs': 1, 'crop_dim': [512, 512], 'learning_momentum': 0.9, 'gradient_clipping_norm': 5.0, 'gradient_summaries': False, 'weight_decay': 0.0, 'rpn_class_loss_weight': 10.0, 'rpn_bbox_loss_weight': 1.0, 'detection_class_loss_weight': 1.0, 'detection_bbox_loss_weight': 1.0, 'detection_mask_loss_weight': 1.0, 'num_classes': 7, 'backbone': 'efficientnet-b3', 'mask_shape': [28, 28], 'roi_proposals': 200, 'rpn_train_anchors_per_image': 256, 'roi_positive_ratio': 0.33, 'mini_mask_shape': [56, 56], 'backbone_strides': [4, 8, 16, 32, 64], 'fpn_classifier_fc_layer_size': 1024, 'fpn_size': 256, 'classify_pool_size': 7, 'mask_pool_size': 14, 'max_instances': 50, 'min_confidence': 0.7, 'detection_nms_threshold': 0.3, 'post_nms_rois': 2000, 'pre_nms_limit': 6000, 'rpn_nms_threshold': 0.7, 'bbox_stdev': [0.1, 0.1, 0.2, 0.2], 'anchor_scales': ['18', '36', '72', '180', '460'], 'anchor_ratios': [0.5, 1, 2], 'anchor_stride': 1, '?': False, 'help': False, 'helpshort': False, 'helpfull': False, 'helpxml': False}
I1114 00:37:58.694322 140070930646848 main.py:254] {""cluster"":{""chief"":[""**censor**-chief-0.kubeflow-jobs.svc:2222""],""worker"":[""**censor**-worker-0.kubeflow-jobs.svc:2222"",""**censor**-worker-1.kubeflow-jobs.svc:2222""]},""task"":{""type"":""chief"",""index"":0},""environment"":""cloud""}
INFO:tensorflow:Enabled multi-worker collective ops with available devices: ['/job:chief/replica:0/task:0/device:CPU:0', '/job:chief/replica:0/task:0/device:XLA_CPU:0', '/job:chief/replica:0/task:0/device:XLA_GPU:0', '/job:chief/replica:0/task:0/device:GPU:0']
I1114 00:37:58.906222 140070930646848 collective_all_reduce_strategy.py:269] Enabled multi-worker collective ops with available devices: ['/job:chief/replica:0/task:0/device:CPU:0', '/job:chief/replica:0/task:0/device:XLA_CPU:0', '/job:chief/replica:0/task:0/device:XLA_GPU:0', '/job:chief/replica:0/task:0/device:GPU:0']
INFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, task_type = 'chief', task_id = 0, num_workers = 3, local_devices = ('/job:chief/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO
I1114 00:37:58.908060 140070930646848 collective_all_reduce_strategy.py:310] Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, task_type = 'chief', task_id = 0, num_workers = 3, local_devices = ('/job:chief/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO
INFO:tensorflow:TF_CONFIG environment variable: {'cluster': {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, 'task': {'type': 'chief', 'index': 0}, 'environment': 'cloud'}
I1114 00:37:58.909245 140070930646848 run_config.py:535] TF_CONFIG environment variable: {'cluster': {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, 'task': {'type': 'chief', 'index': 0}, 'environment': 'cloud'}
INFO:tensorflow:Initializing RunConfig with distribution strategies.
I1114 00:37:58.909479 140070930646848 run_config.py:566] Initializing RunConfig with distribution strategies.
INFO:tensorflow:RunConfig initialized for Distribute Coordinator with INDEPENDENT_WORKER mode
I1114 00:37:58.909686 140070930646848 estimator_training.py:177] RunConfig initialized for Distribute Coordinator with INDEPENDENT_WORKER mode
INFO:tensorflow:Using config: {'_model_dir': 's3://**censor**/**censor**', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 64, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f649946f390>, '_device_fn': None, '_protocol': None, '_eval_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f649946f390>, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f649946fe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': 'independent_worker'}
I1114 00:37:58.909949 140070930646848 estimator.py:212] Using config: {'_model_dir': 's3://**censor**/**censor**', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 64, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f649946f390>, '_device_fn': None, '_protocol': None, '_eval_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f649946f390>, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f649946fe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': 'independent_worker'}
INFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.
I1114 00:37:58.912131 140070930646848 training.py:462] Running `train_and_evaluate` with Distribute Coordinator.
INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, task_type = 'chief', task_id = 0, environment = 'cloud', rpc_layer = 'grpc'
I1114 00:37:58.912826 140070930646848 distribute_coordinator.py:776] Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, task_type = 'chief', task_id = 0, environment = 'cloud', rpc_layer = 'grpc'
INFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, task_type = 'chief', task_id = 0, num_workers = 3, local_devices = ('/job:chief/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO
I1114 00:37:58.913650 140070930646848 collective_all_reduce_strategy.py:310] Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, task_type = 'chief', task_id = 0, num_workers = 3, local_devices = ('/job:chief/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO
INFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, task_type = 'chief', task_id = 0, num_workers = 3, local_devices = ('/job:chief/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO
I1114 00:37:58.914542 140070930646848 collective_all_reduce_strategy.py:310] Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'chief': ['**censor**-chief-0.kubeflow-jobs.svc:2222'], 'worker': ['**censor**-worker-0.kubeflow-jobs.svc:2222', '**censor**-worker-1.kubeflow-jobs.svc:2222']}, task_type = 'chief', task_id = 0, num_workers = 3, local_devices = ('/job:chief/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO
INFO:tensorflow:Updated config: {'_model_dir': 's3://**censor**/**censor**', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 64, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f6499492908>, '_device_fn': None, '_protocol': None, '_eval_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f64994943c8>, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f64994947f0>, '_task_type': 'chief', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://**censor**-chief-0.kubeflow-jobs.svc:2222', '_evaluation_master': 'grpc://**censor**-chief-0.kubeflow-jobs.svc:2222', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 3, '_distribute_coordinator_mode': 'independent_worker'}
I1114 00:37:58.915921 140070930646848 estimator_training.py:228] Updated config: {'_model_dir': 's3://**censor**/**censor**', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 64, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f6499492908>, '_device_fn': None, '_protocol': None, '_eval_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f64994943c8>, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f64994947f0>, '_task_type': 'chief', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://**censor**-chief-0.kubeflow-jobs.svc:2222', '_evaluation_master': 'grpc://**censor**-chief-0.kubeflow-jobs.svc:2222', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 3, '_distribute_coordinator_mode': 'independent_worker'}
INFO:tensorflow:The `input_fn` accepts an `input_context` which will be given by DistributionStrategy
I1114 00:37:59.079214 140070930646848 estimator.py:1111] The `input_fn` accepts an `input_context` which will be given by DistributionStrategy
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W1114 00:38:02.574301 140070930646848 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
INFO:tensorflow:Calling model_fn.
I1114 00:38:02.581103 140054211045120 estimator.py:1147] Calling model_fn.
I1114 00:38:02.781386 140054211045120 model.py:348] tracing train forward: (3, 512, 512, 3) | (3, 65472, 4) | (3, None) | (3, None, 56, 56)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
W1114 00:38:02.793168 140054211045120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
INFO:tensorflow:Collective batch_all_reduce: 389 all-reduces, num_workers = 3
I1114 00:38:21.225312 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 389 all-reduces, num_workers = 3
INFO:tensorflow:Done calling model_fn.
I1114 00:38:26.023765 140054211045120 estimator.py:1149] Done calling model_fn.
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:26.024793 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Create CheckpointSaverHook.
I1114 00:38:27.469296 140070930646848 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:all_hooks [<tensorflow_estimator.python.estimator.util.DistributedIteratorInitializerHook object at 0x7f6496df1358>, <tensorflow.python.training.basic_session_run_hooks.StopAtStepHook object at 0x7f6499494be0>, <tensorflow.python.training.basic_session_run_hooks.NanTensorHook object at 0x7f62f8076c88>, <tensorflow.python.training.basic_session_run_hooks.LoggingTensorHook object at 0x7f62d4072828>, <tensorflow.python.training.basic_session_run_hooks.StepCounterHook object at 0x7f62d424f0f0>, <tensorflow.python.training.basic_session_run_hooks.SummarySaverHook object at 0x7f62d424fcc0>, <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f62b46132b0>]
I1114 00:38:27.469497 140070930646848 monitored_session.py:408] all_hooks [<tensorflow_estimator.python.estimator.util.DistributedIteratorInitializerHook object at 0x7f6496df1358>, <tensorflow.python.training.basic_session_run_hooks.StopAtStepHook object at 0x7f6499494be0>, <tensorflow.python.training.basic_session_run_hooks.NanTensorHook object at 0x7f62f8076c88>, <tensorflow.python.training.basic_session_run_hooks.LoggingTensorHook object at 0x7f62d4072828>, <tensorflow.python.training.basic_session_run_hooks.StepCounterHook object at 0x7f62d424f0f0>, <tensorflow.python.training.basic_session_run_hooks.SummarySaverHook object at 0x7f62d424fcc0>, <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f62b46132b0>]
INFO:tensorflow:Creating chief session creator with config: device_filters: ""/job:chief/task:0""
allow_soft_placement: true
graph_options {
  rewrite_options {
    scoped_allocator_optimization: ON
    scoped_allocator_opts {
      enable_op: ""CollectiveReduce""
    }
  }
}
experimental {
  collective_group_leader: ""/job:chief/replica:0/task:0""
}

I1114 00:38:27.469661 140070930646848 distribute_coordinator.py:251] Creating chief session creator with config: device_filters: ""/job:chief/task:0""
allow_soft_placement: true
graph_options {
  rewrite_options {
    scoped_allocator_optimization: ON
    scoped_allocator_opts {
      enable_op: ""CollectiveReduce""
    }
  }
}
experimental {
  collective_group_leader: ""/job:chief/replica:0/task:0""
}

INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:33.972837 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:33.976987 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:33.988512 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:33.992657 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:34.086326 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:34.090441 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:34.102018 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:34.106123 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 3
I1114 00:38:34.117756 140070930646848 cross_device_ops.py:1107] Collective batch_all_reduce: 1 all-reduces, num_workers = 3
INFO:tensorflow:Graph was finalized.
I1114 00:38:40.463714 140070930646848 monitored_session.py:240] Graph was finalized.
INFO:tensorflow:Running local_init_op.
I1114 00:38:55.357866 140070930646848 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1114 00:38:56.174259 140070930646848 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into s3://**censor**/**censor**/model.ckpt.
I1114 00:39:17.262061 140070930646848 basic_session_run_hooks.py:606] Saving checkpoints for 0 into s3://**censor**/**censor**/model.ckpt.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: From /job:chief/replica:0/task:0:
Cannot assign a device for operation detection_class_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_0: Could not satisfy explicit device specification '/job:chief/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:chief/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[CPU] possible_devices_=[]
Const: CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  detection_class_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_0 (Const) /job:chief/replica:0/task:0/device:GPU:0

Op: Const
Node attrs: dtype=DT_STRING, value=Tensor<type: string shape: [] values: >
Registered kernels:
  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_STRING]
  device='GPU'; dtype in [DT_VARIANT]
  device='GPU'; dtype in [DT_BOOL]
  device='GPU'; dtype in [DT_COMPLEX128]
  device='GPU'; dtype in [DT_COMPLEX64]
  device='GPU'; dtype in [DT_UINT64]
  device='GPU'; dtype in [DT_INT64]
  device='GPU'; dtype in [DT_QINT32]
  device='GPU'; dtype in [DT_UINT32]
  device='GPU'; dtype in [DT_QUINT16]
  device='GPU'; dtype in [DT_QINT16]
  device='GPU'; dtype in [DT_INT16]
  device='GPU'; dtype in [DT_UINT16]
  device='GPU'; dtype in [DT_QINT8]
  device='GPU'; dtype in [DT_INT8]
  device='GPU'; dtype in [DT_UINT8]
  device='GPU'; dtype in [DT_DOUBLE]
  device='GPU'; dtype in [DT_FLOAT]
  device='GPU'; dtype in [DT_BFLOAT16]
  device='GPU'; dtype in [DT_HALF]
  device='GPU'; dtype in [DT_INT32]
  device='CPU'
  device='XLA_CPU'; dtype in [DT_UINT8, DT_QUINT8, DT_INT8, DT_QINT8, DT_INT32, DT_QINT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_BFLOAT16]
  device='XLA_GPU'; dtype in [DT_UINT8, DT_QUINT8, DT_INT8, DT_QINT8, DT_INT32, DT_QINT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_BFLOAT16]
  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_STRING]

	 [[{{node detection_class_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_0}}]]
	 [[loss_ops/detection_loss/StatefulPartitionedCall]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/opt/model/main.py"", line 307, in <module>
    absl_app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/opt/model/main.py"", line 299, in main
    run_train_and_eval(flags.FLAGS, flags.FLAGS.flag_values_dict())
  File ""/opt/model/main.py"", line 287, in run_train_and_eval
    tf.estimator.train_and_evaluate(est, train_spec, eval_spec)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 464, in train_and_evaluate
    estimator, train_spec, eval_spec, _TrainingExecutor)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/estimator_training.py"", line 290, in train_and_evaluate
    session_config=run_config.session_config)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/estimator_training.py"", line 252, in _worker_fn
    hooks=hooks)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1158, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1221, in _train_model_distributed
    self._config._train_distribute, input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1332, in _actual_train_model_distributed
    saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1410, in _train_with_estimator_spec
    estimator_spec, worker_hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1356, in _train_with_estimator_spec_distributed
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run
    raise six.reraise(*original_exc_info)
  File ""/usr/lib/python3/dist-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: From /job:chief/replica:0/task:0:
Cannot assign a device for operation detection_class_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_0: Could not satisfy explicit device specification '/job:chief/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:chief/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[CPU] possible_devices_=[]
Const: CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  detection_class_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_0 (Const) /job:chief/replica:0/task:0/device:GPU:0

Op: Const
Node attrs: dtype=DT_STRING, value=Tensor<type: string shape: [] values: >
Registered kernels:
  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_STRING]
  device='GPU'; dtype in [DT_VARIANT]
  device='GPU'; dtype in [DT_BOOL]
  device='GPU'; dtype in [DT_COMPLEX128]
  device='GPU'; dtype in [DT_COMPLEX64]
  device='GPU'; dtype in [DT_UINT64]
  device='GPU'; dtype in [DT_INT64]
  device='GPU'; dtype in [DT_QINT32]
  device='GPU'; dtype in [DT_UINT32]
  device='GPU'; dtype in [DT_QUINT16]
  device='GPU'; dtype in [DT_QINT16]
  device='GPU'; dtype in [DT_INT16]
  device='GPU'; dtype in [DT_UINT16]
  device='GPU'; dtype in [DT_QINT8]
  device='GPU'; dtype in [DT_INT8]
  device='GPU'; dtype in [DT_UINT8]
  device='GPU'; dtype in [DT_DOUBLE]
  device='GPU'; dtype in [DT_FLOAT]
  device='GPU'; dtype in [DT_BFLOAT16]
  device='GPU'; dtype in [DT_HALF]
  device='GPU'; dtype in [DT_INT32]
  device='CPU'
  device='XLA_CPU'; dtype in [DT_UINT8, DT_QUINT8, DT_INT8, DT_QINT8, DT_INT32, DT_QINT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_BFLOAT16]
  device='XLA_GPU'; dtype in [DT_UINT8, DT_QUINT8, DT_INT8, DT_QINT8, DT_INT32, DT_QINT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_BFLOAT16]
  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_STRING]

	 [[{{node detection_class_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_0}}]]
	 [[loss_ops/detection_loss/StatefulPartitionedCall]]
```
"
34253,"When the result of tf.saved_model.load goes out of scope, it invalidates models that are still in-scope","
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, a trivial change to a stock example
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- TensorFlow installed from (source or binary): binary via pip
- TensorFlow version (use command below): tensorflow-gpu 2.0.0
- Python version: 3.6.6
- CUDA/cuDNN version: 10.0 / 10.0-windows10-x64-v7.6.0.64
- GPU model and memory: GeForce GTX 1050 Ti (laptop)

**Describe the current behavior**

Loading a TF2 model built with the Keras API, and then predicting with random data follows this minimal recipe:
```
import tensorflow as tf
loaded = tf.saved_model.load('some/model')
infer = loaded.signatures['serving_default']
data = tf.constant(np.asarray(np.random.randn(my_shape), dtype=np.float32))
preds = infer(data)
```

However, if we don't keep a reference to `loaded` around or lose it some time later...
```
import tensorflow as tf
infer = tf.saved_model.load('some/model').signatures['serving_default']
data = tf.constant(np.asarray(np.random.randn(my_shape), dtype=np.float32))
preds = infer(data)
```

... it fails with this utterly confusing error about variables being potentially uninitialized (for which google searches lead down various unrelated tf 1.x related rabbit holes):
```
2019-11-13 15:37:09.423218: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Failed precondition: Error while reading resource variable batch_normalization_150/moving_mean_12513 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/batch_normalization_150/moving_mean_12513/class tensorflow::Var does not exist.
	 [[{{node StatefulPartitionedCall/model_65/model_60/batch_normalization_150/FusedBatchNormV3/ReadVariableOp}}]]
Traceback (most recent call last):
  File ""D:/DEVEL/experiments/test_load.py"", line 17, in <module>
    preds = infer(data)
  File ""C:\Users\chris\Miniconda3\envs\np2019-11-06e2\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1081, in __call__
    return self._call_impl(args, kwargs)
  File ""C:\Users\chris\Miniconda3\envs\np2019-11-06e2\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1121, in _call_impl
    return self._call_flat(args, self.captured_inputs, cancellation_manager)
  File ""C:\Users\chris\Miniconda3\envs\np2019-11-06e2\lib\site-packages\tensorflow_core\python\saved_model\load.py"", line 99, in _call_flat
    cancellation_manager)
  File ""C:\Users\chris\Miniconda3\envs\np2019-11-06e2\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""C:\Users\chris\Miniconda3\envs\np2019-11-06e2\lib\site-packages\tensorflow_core\python\eager\function.py"", line 511, in call
    ctx=ctx)
  File ""C:\Users\chris\Miniconda3\envs\np2019-11-06e2\lib\site-packages\tensorflow_core\python\eager\execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable batch_normalization_150/moving_mean_12513 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/batch_normalization_150/moving_mean_12513/class tensorflow::Var does not exist.
	 [[{{node StatefulPartitionedCall/model_65/model_60/batch_normalization_150/FusedBatchNormV3/ReadVariableOp}}]] [Op:__inference_signature_wrapper_5266]

Function call stack:
signature_wrapper
```

**Describe the expected behavior**

The `infer` object holds a reference to the data that it depends on so that it doesn't get garbage-collected.

**Code to reproduce the issue**
If you run the TF2.0 Saved Model tutorial colab notebook (https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb) up to and including the cell

```
!saved_model_cli show --dir /tmp/mobilenet/1 --tag_set serve --signature_def serving_default
```

but then you execute the following cell instead of the one that would create the variable `loaded`:

```
infer = tf.saved_model.load(""/tmp/mobilenet/1/"").signatures[""serving_default""]
print(infer.structured_outputs)
labeling = infer(tf.constant(x))[pretrained_model.output_names[0]]
decoded = imagenet_labels[np.argsort(labeling)[0,::-1][:5]+1]
print(""Result after saving and loading:\n"", decoded)
```

... then it fails with:
```
---------------------------------------------------------------------------
FailedPreconditionError                   Traceback (most recent call last)
<ipython-input-8-f42985f0118d> in <module>()
----> 1 labeling = infer(tf.constant(x))[pretrained_model.output_names[0]]
      2 
      3 decoded = imagenet_labels[np.argsort(labeling)[0,::-1][:5]+1]
      4 
      5 print(""Result after saving and loading:\n"", decoded)

6 frames
/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

FailedPreconditionError:  Error while reading resource variable conv_pw_7_bn/moving_variance_33153 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/conv_pw_7_bn/moving_variance_33153/N10tensorflow3VarE does not exist.
	 [[{{node StatefulPartitionedCall/mobilenet_1.00_224/conv_pw_7_bn/FusedBatchNormV3/ReadVariableOp_1}}]] [Op:__inference_signature_wrapper_30328]

Function call stack:
signature_wrapper
```
"
34250,Collective AllGather Fails on Polymorphic Shapes,"**System information**
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): binary whl
- TensorFlow version (use command below): `tensorflow-gpu==2.0.0`
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0 / 7.6.4
- GPU model and memory: GeForce GTX 1080 Ti


**Describe the current behavior**
```python

import numpy as np
import tensorflow as tf

from tensorflow.core.protobuf import config_pb2
from tensorflow.python.ops import collective_ops

t0 = [0, 1, 2, 3, 4, 5, 6, 7]
t1 = [10, 11, 12, 13, 14, 15, 16, 17]
expected = [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17]

group_size = 2
group_key = 1
instance_key = 123

with tf.compat.v1.Session(
        config=config_pb2.ConfigProto(device_count={'CPU': group_size})) as sess:

    with tf.device('/CPU:0'):
        in0 = tf.compat.v1.placeholder(dtype=tf.int32, shape=[None])
        c0 = collective_ops.all_gather(in0, group_size=group_size, group_key=group_key, instance_key=instance_key)
    with tf.device('/CPU:1'):
        in1 = tf.compat.v1.placeholder(dtype=tf.int32, shape=[None])
        c1 = collective_ops.all_gather(in1, group_size=group_size, group_key=group_key, instance_key=instance_key)

    # SUCCESS:
    results = sess.run([c0, c1], feed_dict={in0: t0, in1: t1})
    assert np.allclose(results[0], expected)
    assert np.allclose(results[1], expected)

    # FAIL:
    results_ = sess.run([c0, c1], feed_dict={in0: t0[1:], in1: t1[1:]})
    # > 2019-11-13 17:45:50.521948: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Inconsistent output shapes, got [14], but expected is [16].
```

In one session, if one runs the above graph second time with the feed in a size different from the first time, it will raise an error: `Inconsistent output shapes, got [14], but expected is [16].`

**Describe the expected behavior**

* The graph construction above sets the expected shapes of the placeholders as polymorphic `[None]`. However, after the first `session.run`, the collective op caches its output shape (which is `16` in our case) in ""tensorflow/tensorflow/core/kernels/collective_ops.cc"". But should it be expected that the collective op keeps its graph-defined polymorphic behavior? Specifically, in our case, should it allow a user to all gather two size `7` tensors into a size `14`? 

**Code to reproduce the issue**
See above
"
34242,Eager context seems contradicting the distributed TensorFlow concept,"**System information**
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): binary whl
- TensorFlow version (use command below): `tensorflow-gpu==2.0.0`
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0 / 7.6.4
- GPU model and memory: GeForce GTX 1080 Ti


**Describe the current behavior**
```python
import argparse

import tensorflow as tf
from tensorflow.core.protobuf.tensorflow_server_pb2 import ServerDef
from tensorflow.python.eager import context
from tensorflow.python.training.server_lib import ClusterSpec


CLUSTER_SPEC = {
    ""worker"": [
        ""localhost:14286"",
        ""localhost:14287""
    ]
}


def test():
    c = context.context()
    c.set_server_def(
        ServerDef(
            cluster=ClusterSpec(CLUSTER_SPEC).as_cluster_def(),
            job_name=FLAGS.job_name,
            task_index=FLAGS.task_index,
            protocol='grpc'
        )
    )
    print(tf.constant(3))
    print('lol')


if __name__ == ""__main__"":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        ""--job_name"",
        type=str,
    )
    parser.add_argument(
        ""--task_index"",
        type=int,
    )
    FLAGS, _ = parser.parse_known_args()
    test()
```

We refer the above code as `a.py`.
STEP 1: we launch it by
```bash
python a.py --job_name=worker --task_index=0
```
with the log
```
...
2019-11-13 13:53:38.096726: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job worker -> {0 -> localhost:14286, 1 -> localhost:14287}
2019-11-13 13:53:38.099209: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:14286
```
and it is waiting for another server as described in the `CLUSTER_SPEC`. Note that no `print` above has been executed yet.

STEP 2: we launch it as another process by
```bash
python a.py --job_name=worker --task_index=1
```
with the log
```
...
2019-11-13 14:00:01.431825: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job worker -> {0 -> localhost:14286, 1 -> localhost:14287}
2019-11-13 14:00:01.433641: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:14287
2019-11-13 14:00:01.471394: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job worker -> {0 -> localhost:14286, 1 -> localhost:14287}
tf.Tensor(3, shape=(), dtype=int32)
lol
2019-11-13 14:00:01.585211: E tensorflow/core/distributed_runtime/rpc/eager/grpc_eager_client.cc:72] Remote EagerContext with id 2379290034739913425 does not seem to exist.
```
and the first processor with the `task_index=0` hangs forever.


**Describe the expected behavior**

In TensorFlow graph mode, we know when multiple sessions talk to the same cluster (which is defined by `ClusterSpec`), everything works pretty smooth and natural. 

Should eager context behave similarly?  That is, both the above processes are expected to run naturally: print the contant and string and exited.

In other words, when multiple contexts talking to the same cluster (which is defined by `ClusterSpec`), should they know how to coordinate with each other, just as the TensorFlow core is architectured and designed before?

(Or is there any other API that could help resolve this issue?)


**Code to reproduce the issue**
See above
"
34238,Tensorflow failed to find 'TRTEngineOp' when building pip-package and libtensorflow_cc.so,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.14
- Python version: 3.6
- Installed using virtualenv? pip? conda?: Build from source
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): gcc 7.4.0
- CUDA/cuDNN version:10.0
- GPU model and memory: 2080ti 11GB

**Describe the problem**

In brief, I built tensorflow for both python (pip_package) and c++ (libtensorflow_cc.so), I want to train a model, convert it to tf-trt in python, then run it on c++. And it failed when running it on c++.

Here are the details:

I'm trying to build tensorflow python version by bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package and build c++ version by bazel build --config=opt --config=monolithic --config=cuda //tensorflow:libtensorflow_cc.so. And I want them both with tensorrt support. After building it sequentially (configure first, build_pip_package and then libtensorflow_cc.so), I find that the python version could load tensorrt successfully, but when I'm trying to run session run on c++, it gives me the error saying:

```
Check failed: status.ok() Loading error: Op type not registered 'TRTEngineOp' in binary running on my_dev_docker. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you
are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
```

Since I'm using tf 1.14 where the tensorrt has been promoted to first-class citizen from tf.contrib. So I believe that I don't need to dynatically load it in my c++ code using c api ""TF_LoadLibrary"". So I started to suspect that maybe the tensorrt support is successfully installed but not on the c++ one and I didn't find any good reference on the internet on how to enable tf-trt for tensorflow_cc.so.

The success of python tensorflow with tensorrt support is tested by running ""from tensorflow.python.compiler.tensorrt import trt_convert as trt"". Although I have to run ""export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/TensorRT-5.1.2.2/lib"" first otherwise it will say ""ImportError: libnvinfer.so.5: cannot open shared object file: No such file or directory"".

The following is the exact command:

 PYTHON_BIN_PATH=/usr/bin/python3.6 \                                                                                                                                                                                                                                              
 PYTHON_LIB_PATH=/usr/local/lib/python3.6/dist-packages \                                                                                                                                                                                                                          
 TF_ENABLE_XLA=1 \                                                                                                                                                                                                                                                                 
 TF_NEED_OPENCL_SYCL=0 \                                                                                                                                                                                                                                                           
 TF_NEED_ROCM=0 \                                                                                                                                                                                                                                                                  
 TF_NEED_CUDA=1 \                                                                                                                                                                                                                                                                  
 TF_CUDA_VERSION=10 \                                                                                                                                                                                                                                                              
 TF_CUDA_PATHS=/usr/local/cuda,/usr/lib/x86_64-linux-gnu,/usr/include \                                                                                                                                                                                                            
 CUDA_TOOLKIT_PATH=/usr/local/cuda \                                                                                                                                                                                                                                               
 CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu \                                                                                                                                                                                                                                    
 TF_CUDNN_VERSION=7 \                                                                                                                                                                                                                                                              
 TF_NEED_TENSORRT=1 \                                                                                                                                                                                                                                                              
 TF_TENSORRT_VERSION=5 \                                                                                                                                                                                                                                                           
 TENSORRT_INSTALL_PATH=/usr/local/TensorRT-5.1.2.2 \                                                                                                                                                                                                                               
 TF_NCCL_VERSION=2 \                                                                                                                                                                                                                                                               
 TF_CUDA_COMPUTE_CAPABILITIES=""6.1,7.5"" \                                                                                                                                                                                                                                          
 TF_CUDA_CLANG=0 \                                                                                                                                                                                                                                                                 
 TF_DOWNLOAD_CLANG=0 \                                                                                                                                                                                                                                                             
 GCC_HOST_COMPILER_PATH=/usr/bin/gcc \                                                                                                                                                                                                                                             
 CLANG_CUDA_COMPILER_PATH=/usr/local/clang_8.0.0/bin/clang \                                                                                                                                                                                                                       
 TF_NEED_MPI=0 \                                                                                                                                                                                                                                                                   
 CC_OPT_FLAGS=""-mavx -Wno-sign-compare"" \                                                                                                                                                                                                                                          
 TF_SET_ANDROID_WORKSPACE=0 \                                                                                                                                                                                                                                                      
 ./configure                                                                                                                                                                                                                                                                       
                                                                                                                                                                                                                                                                                   
 bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package                                                                                                                                                                                           
 ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg                                                                                                                                                                                                    
 pip3 install /tmp/tensorflow_pkg/tensorflow-1.14.0-cp36-cp36m-linux_x86_64.whl                                                                                                                                                                                                    
                                                                                                                                                                                                                                                                                   
 bazel build --config=opt --config=monolithic --config=cuda //tensorflow:libtensorflow_cc.so

**Any other info / logs**

I run the conversion in python by:

from tensorflow.python.compiler.tensorrt import trt_convert as trt
converter = trt.TrtGraphConverter(input_saved_model_dir=input_saved_model_dir)
converter.convert()
converter.save(output_saved_model_dir)

I run the converted model in c++ by:

const auto status =                                                                                                                                                                                                                                                             
       LoadSavedModel(session_options, run_options, net_param_.model_path(),                                                                                                                                                                                                       
                      {tensorflow::kSavedModelTagServe}, &bundle_, gpu_id);

And I get error message from status.error_message();

Could you kindly provide some hints on what I might be doing wrong?"
34237,Failed on runtime - image not found,"**System information**
- macOS Mojave 10.14.6
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2
- Python version: 3.7
- Installed using virtualenv? no
- Bazel version (if compiling from source): bazel release 0.29.1
- GCC/Compiler version (if compiling from source):g++ -v = Apple clang version 11.0.0 (clang-1100.0.33.12)
- CUDA/cuDNN version: none
- GPU model and memory: no gpu

**problem**
I installed Tensorflow from source and used below command to compile my cpp file, It compiled successfully
`/usr/bin/g++  /var/www/cpp/main.cpp -std=c++17 -L /Users/raza/development/tensorflow/bazel-bin/tensorflow/ -l tensorflow_framework -l tensorflow_cc -l protobuf  -I /Users/raza/development/tensorflow -I /Users/raza/development/tensorflow/bazel-bin/tensorflow -I /Users/raza/development/tensorflow/bazel-genfiles -I /Users/raza/development/tensorflow/bazel-tensorflow/external/com_google_protobuf/src -I /Users/raza/development/tensorflow/bazel-tensorflow/external/com_google_absl -I /Users/raza/development/tensorflow/bazel-tensorflow/external/eigen_archive -o /var/www/cpp/main --debug -v`

But when I run `./main` I see below error:
```
dyld: Library not loaded: @rpath/libtensorflow_framework.2.dylib
  Referenced from: /private/var/www/cpp/./main
  Reason: image not found
```

**Any other info / logs**
I see under my path I have this library ~/development/tensorflow/bazel-bin/tensorflow and also other files with similiar names: 
```
$ls
__init__.py                         core                                libtensorflow_cc.so.2.0.0           stream_executor
__init__.py.original                libtensorflow.so                    libtensorflow_framework.2.0.0.dylib tools
_api                                libtensorflow.so.2                  libtensorflow_framework.2.dylib     virtual_root.__init__.py
c                                   libtensorflow.so.2.0.0              libtensorflow_framework.dylib
cc                                  libtensorflow_cc.so                 lite
compiler                            libtensorflow_cc.so.2               python
```
and output of `otool -L libtensorflow_cc.so`
```
$ otool -L libtensorflow_cc.so
libtensorflow_cc.so:
        @rpath/libtensorflow_cc.so.2 (compatibility version 0.0.0, current version 0.0.0)
        /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 800.7.0)
        @rpath/libtensorflow_framework.2.dylib (compatibility version 0.0.0, current version 0.0.0)
        /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1281.0.0)
        /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1673.126.0)
        /System/Library/Frameworks/Security.framework/Versions/A/Security (compatibility version 1.0.0, current version 59306.41.2)
        /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit (compatibility version 1.0.0, current version 275.0.0)
        /System/Library/Frameworks/Foundation.framework/Versions/C/Foundation (compatibility version 300.0.0, current version 1673.126.0)
        /usr/lib/libobjc.A.dylib (compatibility version 1.0.0, current version 228.0.0)
```

and
```
$otool -L libtensorflow_framework.2.dylib
libtensorflow_framework.2.dylib:
        @rpath/libtensorflow_framework.2.dylib (compatibility version 0.0.0, current version 0.0.0)
        /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 800.7.0)
        /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1673.126.0)
        /System/Library/Frameworks/Security.framework/Versions/A/Security (compatibility version 1.0.0, current version 59306.41.2)
        /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1281.0.0)
        /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit (compatibility version 1.0.0, current version 275.0.0)
        /System/Library/Frameworks/Foundation.framework/Versions/C/Foundation (compatibility version 300.0.0, current version 1673.126.0)
        /usr/lib/libobjc.A.dylib (compatibility version 1.0.0, current version 228.0.0)
```"
34235,tf.keras.backend.gradients error in eager mode,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): n/a
- Python version: 3.6.8
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: Cuda compilation tools, release 10.0, V10.0.130
- GPU model and memory: Tesla P100

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Usage of tf.keras.backend.gradients in tensorflow 2.0 gives the following error :

RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.

The entire error is as below : 

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-55-a2847ee8d0c4> in <module>()
     69         ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))
     70 
---> 71 vis_img_in_filter()

3 frames
<ipython-input-55-a2847ee8d0c4> in vis_img_in_filter(img, layer_name)
     30 
     31         # compute the gradient of the input picture wrt this loss
---> 32         grads = K.gradients(loss, model.input)[0]
     33 
     34         # normalization trick: we normalize the gradient

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in gradients(loss, variables)
   3795   """"""
   3796   return gradients_module.gradients(
-> 3797       loss, variables, colocate_gradients_with_ops=True)
   3798 
   3799 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_impl.py in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)
    156         ys, xs, grad_ys, name, colocate_gradients_with_ops,
    157         gate_gradients, aggregation_method, stop_gradients,
--> 158         unconnected_gradients)
    159   # pylint: enable=protected-access
    160 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    503   """"""Implementation of gradients().""""""
    504   if context.executing_eagerly():
--> 505     raise RuntimeError(""tf.gradients is not supported when eager execution ""
    506                        ""is enabled. Use tf.GradientTape instead."")
    507   if src_graph is None:

RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.


**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34234,Checkpoint managers overwrite not owned checkpoints,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Manjaro linux testing
- TensorFlow installed from: pypi binary
- TensorFlow version (use command below): v1.12.1-16854-g6778662 2.1.0-dev20191028
- Python version: 3.7.4

**Describe the current behavior**
A `tf.train.CheckpointManager` erases checkpoints in its directory path that were not written by it.
This is a different behaviour from `tf.train.Saver` in TF1.

**Describe the expected behavior**
Do not remove checkpoints that are not owned by a CheckpointManager instance.
In the code below, I expected to have checkpoints 1, 2, 4, 5 at the end. Instead, only 4 and 5 survived.

**Code to reproduce the issue**
```
import tensorflow as tf

var = tf.Variable(initial_value=12)

checkpoint = tf.train.Checkpoint(var=var)
manager = tf.train.CheckpointManager(
    checkpoint=checkpoint,
    directory='./delete_me/',
    max_to_keep=2)

manager.save(0)
manager.save(1)
manager.save(2)

manager2 = tf.train.CheckpointManager(
    checkpoint=checkpoint,
    directory='./delete_me/',
    max_to_keep=2)

manager2.save(3)
manager2.save(4)
manager2.save(5)
#  Why were 1 and 2 deleted by manager2 ?
```

**Other info / logs**

"
34233,"Bad performance in Keras: It diverges if sample_weight is not added to train_in_batch but sample_weight_mode=""temporal"" is in Model.compile. ","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab, with the latest packages.
- TensorFlow installed from (source or binary): Provided by Google Colab.
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.x

**Describe the current behavior**
This might not be a bug, but a change has happened in the recent days in the Keras API that has led my models to either divergence to NaNs or reduced performance. Let me explain (long explanation):

For the last 3 months, I have been training a Dense U-net to solve the problem from 'Digest Challenge- Conference MICCAI 2019':  **https://digestpath2019.grand-challenge.org/Home/**
I have done many experiments, using Google Colab and Tensorflow 2.0 with integrated Keras. I never specify the version of the packages, so I use whatever Google Colab loads by default. And for months that was perfectly fine. But one week ago, on 7th November 2019, something was changed in the Keras API that all my models went crazy.

To give some context, this dataset contains histopathology images, i.e. images of the human colon where cancer cells are present. The dataset is divided into two parts: Negative images, where all tissue is healthy, and Positive images, where cancer tissue is present. Thus, there are two classes of pixels: cancer and non-cancer. The goal is to do segmentation of the cancer tissue. The graph below show the accuracy in the training set (in blue) and in the validation set, where the Positive images (in red) and Negative images (in green) are displayed separately. Usually, the 12 non-stop hours that Google Colab provides allows for 40 iterations. So the following day I load the weights and keep training.

Since these images are huge, I take patches, build my own batch (trying to balance the classes), and use Keras function _train_on_batch_ for training. Sometimes, I have used the option of _sample_weight_ from _train_on_batch_ to weight the classes even further or simply to play with the weights ...

```   tLoss = model.train_on_batch(batch_data, batch_label, sample_weight=batch_weight)```
adding the option sample_weight_mode=""temporal"" in compile() ...
```    
model.compile(optimizer=nadam, 
             sample_weight_mode=""temporal"",
             loss= 'binary_crossentropy', 
             metrics=['binary_accuracy'])
```
So far so good!
Now, in the past, I have sometimes forgotten to remove the line _sample_weight_mode=""temporal""_ when I was **NOT** using _sample_weight_ in _train_on_batch_, yet there were NO changes in the performance (this is, either removing or not that line in _compile()_ gave the same performance if no actual weighting was introduced in _train_on_batch_ ... or at least I do not remember observing any difference, but I cannot ensure this statement). 

This was like that until a week ago! Suddenly, if I am NOT using _sample_weight_ but I have the line _sample_weight_mode=""temporal""_ in compile(), the network diverges to a fixed loss-value and an accuracy of 0.5 to both classes (sometimes it is not straight forward... maybe after some iterations).

Then I discovered that I had to remove that line to avoid this. And that makes sense, so it would not be an issue. The problem is that, suddenly, the performance has been reduced a lot (in the Positive images, red line). In the following graph, you could see how the accuracy was going quite well, reaching a plateau in both types of images (Positives and Negatives), until one day that I load the model to keep training and this situation happens (on iteration 175). Since then, the network cannot reach the performance that was obtained before.

![Accuracy_Validation2019 11 09](https://user-images.githubusercontent.com/52449827/68773542-0b87d380-062c-11ea-8c61-8d468eca45b7.png)

So, to summarize, I was training using _train_on_batch_ with NO input argument _sample_weight_ but WITH the line _sample_weight_mode=""temporal""_ in compile() (from iteration 0 until iteration 175 in the graph). It went well. At one point in time, that setting made the network to diverge (and I highlight that I did NOT change my code whatsoever, simply load the network and keep training). Once I removed the line _sample_weight_mode=""temporal""_ in compile(), the network did not diverge but performance decreased (from iteration 175 forward in the graph).
I have replicated this in other old networks (and in new networks trained from scratch) and the same situation happens.

Is this a bug? I am not sure!
My hypotheses: 
- Some kind of weighting was internally done before, which was corrected recently, leading to a decrease in my current performance. In this case, I would be interested in knowing what was changed.
- It is a new bug introduced recently.


**Code to reproduce the issue**
See Jupyter Notebook: https://drive.google.com/open?id=1gMnrIe3WBRyEpGumisMMP8ZqqTm5XtX1
The link to the dataset is within the Notebook.
"
34232,"use tensorflow inference on CPU and get error ""undefined symbol: _ZN10tensorflow10DEVICE_CPUE""","I use tensorflow to inference lstm crf model on CPU, and I compile a lib use tensorflow C++ API, depend on tensorflow source code.
my compile environment is GCC 4.8.5, tensorflow 1.12.0, bazel 0.15.0

when I load the so lib, it report an error: undefined symbol: _ZN10tensorflow10DEVICE_CPUE, anybody knows why? or if I must provide more information?"
34231,@tf.function slower the GPU performance?,"    import time
    import tensorflow as tf
    @tf.function #Commenting out this line makes a huge difference in GPU performance
    def measure(x, steps):
      tf.matmul(x, x)
      start = time.time()
      for i in range(steps):
        x = tf.matmul(x, x)
      end = time.time()
      return end - start
    
    shape = (1000, 1000)
    steps = 2000
    #print(""Time to multiply a {} matrix by itself {} times:"".format(shape, steps))
    
    # Run on CPU:
    with tf.device(""/cpu:0""):
      print(""CPU: {} secs"".format(measure(tf.random.normal(shape), steps)))
    
    # Run on GPU, if available:
    if tf.test.is_gpu_available():
      with tf.device(""/gpu:0""):
        print(""GPU: {} secs"".format(measure(tf.random.normal(shape), steps)))

GPU:1080ti
CPU:2990wx

when use @tf.function，results below：
CPU: 1.223414659500122 secs
GPU: 1.223414659500122 secs

when don't use @tf.function
CPU: 6.363093614578247 secs
GPU: 0.25109028816223145 secs

why 4x slower ?
when should we use  ""@tf.function"" instead of  ""with tf.device(""/gpu:0""):"""
34230,Android - Posenet is slow/laggy,"**System information**
- I'm using the posenet example
- Samsung J7 Pro running Android 9

**Describe the current behavior**
The preview is slow/laggy. The interpreter takes on avarage 300ms when using GPU and 400ms when using CPU

**Describe the expected behavior**
The preview should display the frames smoothly

**Code to reproduce the issue**
I'm running the posenet example application

**Other info / logs**
This issue is not present in the Tensorflow Detect example. 
I tried reducing the preview size, but the issue remains

    org.tensorflow.lite.examples.posenet I/posenet: Interpreter took 305,41 ms
    org.tensorflow.lite.examples.posenet I/posenet: Scaling to [-1,1] took 104,03 ms

Please let me know if you need more info.
"
34229,"after graph_transforms with pb file , something went error ","## Enviroment
**GPU Type**: Tesla T4
**Nvidia Driver Version**: 418.87.01
**CUDA Version**: 10.1.243
**CUDNN Version**: 7.6.3
**Python Version**: 3.7.4
**TensorFlow Version**: 1.14.1 
**Bazel Version**: 0.24.1
**Operating System Version**: Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-142-generic x86_64)


## Tools

**graph_transforms**
It's a toolkit in tensorflow original code (tensorflow/tools/graph_transforms)

## Step

### 1. build

```bash
bazel build tensorflow/tools/graph_transforms:transform_graph
```

### 2. transform pb 

```bash
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=my.pb \
--out_graph=out.pb \
--inputs='inputs' \
--outputs='BiasAdd' \
--transforms='
add_default_attributes
strip_unused_nodes(type=float)
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
fold_batch_norms
fold_old_batch_norms
round_weights(num_steps=256)
quantize_weights
quantize_nodes
strip_unused_nodes
sort_by_execution_order'
```

### 3. test origin pb file i.e. **my.pb**, it's OK

### 4. test output pb file i.e. **out.pb** , it went error:

```bash
(0) Invalid argument: requested_output_max must be >= requested_output_min, but got -nan and 0
	 [[{{node Tacotron-2/inference/decoder/while/CustomDecoderStep/mul/eightbit/requantize}}]]
	 [[Tacotron-2/inference/decoder/while/CustomDecoderStep/decoder_LSTM/decoder_LSTM/multi_rnn_cell/cell_0/decoder_LSTM_1/add/_545]]

(1) Invalid argument: requested_output_max must be >= requested_output_min, but got -nan and 0
	 [[{{node Tacotron-2/inference/decoder/while/CustomDecoderStep/mul/eightbit/requantize}}]]
``` 

## Additional 

I used the following code to test if pb file worked:
```python
def pb2inference(args):
    tf.reset_default_graph()
    my_graph_def = tf.GraphDef()
    with tf.gfile.GFile(args.pb, 'rb') as fid:
        serialized_graph = fid.read()
        my_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(my_graph_def, name = '')

    my_graph = tf.get_default_graph()

    inputs = my_graph.get_tensor_by_name('inputs:0')
    out = my_graph.get_tensor_by_name('BiasAdd:0')

    with tf.Session(graph=my_graph) as sess:
        feed_dict = {inputs:seq}
        out= sess.run(out, feed_dict = feed_dict)
```

It worked in my.pb, but got error in out.pb. In addition, the transform process has no warning or error.
"
34228,TFLite_Detection_PostProcess,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34224,Rejection resampling with multi-label output,"### Description

I was reading the about the experimental rejection sampling method and I was wondering. What if I have multi-label binary classes? E.g. [1, 0, ,0, 1, 0, 0, 0, 0, 0, 0]. If I want to even the distribution of each label with `target_dist=[0.1] * 10 ` what is the expected behaviour?

#### URL(s) with the issue: [Rejection resampling Docs](https://www.tensorflow.org/api_docs/python/tf/data/experimental/rejection_resample)

Thanks in advance!


"
34222,ubuntu  cuda10.1 build error. Linking of rule '//tensorflow/python:gen_logging_ops_py_wrappers_cc' failed (Exit 1),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Ubuntu 18.04
- TensorFlow installed from (source or binary):
- TensorFlow version:  v2.0.0-rc2
- Python version: 3.7
- Installed using conda
- Bazel version (if compiling from source):0.29.1
- GCC/Compiler version (if compiling from source): 7.4
- CUDA/cuDNN version: cuda 10.1  cuDNN 7.6.5
- GPU model and memory:  nvida RTX2060， memory 6GB

compile config：
build --action_env PYTHON_BIN_PATH=""/home/ubuntu/.conda/envs/tensorflow-gpu/bin/python""
build --action_env PYTHON_LIB_PATH=""/home/ubuntu/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages""
build --python_path=""/home/ubuntu/.conda/envs/tensorflow-gpu/bin/python""
build:xla --define with_xla_support=true
build --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""7.5""
build --action_env LD_LIBRARY_PATH=""/home/ubuntu/ThirdpartyLibrary/ode/ode-build/lib:/usr/local/lib:/usr/local/lib/boost:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/x86_64-linux-gnu-gcc-7""
build --config=cuda
build:opt --copt=-march=native
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_tag_filters=-benchmark-test,-no_oss,-oss_serial
test --build_tag_filters=-benchmark-test,-no_oss
test --test_tag_filters=-gpu
test --build_tag_filters=-gpu
build --action_env TF_CONFIGURE_IOS=""0""

use build opt：
bazel build --config=opt --config=v2 --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --verbose_failures //tensorflow/tools/pip_package:build_pip_package

error info：
external/com_google_absl/absl/types/optional.h(425): warning: expression has no effect
          detected during instantiation of ""const T &absl::optional<T>::operator*() const & [with T=stream_executor::dnn::AlgorithmDesc]"" 
./tensorflow/stream_executor/dnn.h(804): here

external/com_google_absl/absl/types/optional.h(425): warning: expression has no effect
          detected during instantiation of ""const T &absl::optional<T>::operator*() const & [with T=size_t]"" 
./tensorflow/stream_executor/dnn.h(858): here

INFO: From Compiling tensorflow/core/kernels/slice_op_gpu.cu.cc:
external/com_google_absl/absl/strings/string_view.h(495): warning: expression has no effect

external/com_google_absl/absl/strings/string_view.h(495): warning: expression has no effect

ERROR: /home/ubuntu/ThirdpartyLibrary/tensorflow/tensorflow/tensorflow/python/BUILD:2444:1: Linking of rule '//tensorflow/python:gen_logging_ops_py_wrappers_cc' failed (Exit 1)
bazel-out/host/bin/tensorflow/core/libop_gen_lib.a(op_gen_lib.o): In function `google::protobuf::internal::ArenaStringPtr::CreateInstance(google::protobuf::Arena*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*)':
op_gen_lib.cc:(.text._ZN6google8protobuf8internal14ArenaStringPtr14CreateInstanceEPNS0_5ArenaEPKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE[_ZN6google8protobuf8internal14ArenaStringPtr14CreateInstanceEPNS0_5ArenaEPKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE]+0x36): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
op_gen_lib.cc:(.text._ZN6google8protobuf8internal14ArenaStringPtr14CreateInstanceEPNS0_5ArenaEPKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE[_ZN6google8protobuf8internal14ArenaStringPtr14CreateInstanceEPNS0_5ArenaEPKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE]+0xc0): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
bazel-out/host/bin/tensorflow/core/libop_gen_lib.a(op_gen_lib.o): In function `tensorflow::(anonymous namespace)::MergeArg(tensorflow::ApiDef_Arg*, tensorflow::ApiDef_Arg const&)':
op_gen_lib.cc:(.text._ZN10tensorflow12_GLOBAL__N_18MergeArgEPNS_10ApiDef_ArgERKS1_+0x4c): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'
op_gen_lib.cc:(.text._ZN10tensorflow12_GLOBAL__N_18MergeArgEPNS_10ApiDef_ArgERKS1_+0x77): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'
bazel-out/host/bin/tensorflow/core/libop_gen_lib.a(op_gen_lib.o): In function `tensorflow::WordWrap[abi:cxx11](absl::string_view, absl::string_view, int)':
op_gen_lib.cc:(.text._ZN10tensorflow8WordWrapB5cxx11EN4absl11string_viewES1_i+0x10a): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, tensorflow::strings::AlphaNum const&)'
op_gen_lib.cc:(.text._ZN10tensorflow8WordWrapB5cxx11EN4absl11string_viewES1_i+0x20f): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, tensorflow::strings::AlphaNum const&)'
op_gen_lib.cc:(.text._ZN10tensorflow8WordWrapB5cxx11EN4absl11string_viewES1_i+0x299): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, tensorflow::strings::AlphaNum const&)'
op_gen_lib.cc:(.text._ZN10tensorflow8WordWrapB5cxx11EN4absl11string_viewES1_i+0x2c6): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, tensorflow::strings::AlphaNum const&)'
bazel-out/host/bin/tensorflow/core/libop_gen_lib.a(op_gen_lib.o): In function `tensorflow::PBTxtFromMultiline[abi:cxx11](absl::string_view)':
op_gen_lib.cc:(.text._ZN10tensorflow18PBTxtFromMultilineB5cxx11EN4absl11string_viewE+0x199): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
op_gen_lib.cc:(.text._ZN10tensorflow18PBTxtFromMultilineB5cxx11EN4absl11string_viewE+0x229): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, tensorflow::strings::AlphaNum const&)'
op_gen_lib.cc:(.text._ZN10tensorflow18PBTxtFromMultilineB5cxx11EN4absl11string_viewE+0x350): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, tensorflow::strings::AlphaNum const&)'
op_gen_lib.cc:(.text._ZN10tensorflow18PBTxtFromMultilineB5cxx11EN4absl11string_viewE+0x4a4): undefined reference to `tensorflow::strings::internal::AppendPieces(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, std::initializer_list<absl::string_view>)'
op_gen_lib.cc:(.text._ZN10tensorflow18PBTxtFromMultilineB5cxx11EN4absl11string_viewE+0x540): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*, tensorflow::strings::AlphaNum const&)'
bazel-out/host/bin/tensorflow/core/libop_gen_lib.a(op_gen_lib.o): In function `tensorflow::Status tensorflow::errors::FailedPrecondition<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)':
op_gen_lib.cc:
....
...
....
`tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)'
logging_ops.cc:(.text.startup._Z41__static_initialization_and_destruction_0ii.constprop.69+0x1217): undefined reference to `tensorflow::OpDefBuilder::SetIsStateful()'
logging_ops.cc:(.text.startup._Z41__static_initialization_and_destruction_0ii.constprop.69+0x1235): undefined reference to `tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)'
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 7445.735s, Critical Path: 194.55s
INFO: 10220 processes: 10220 local.
FAILED: Build did NOT complete successfully



"
34221,Got different result if train Keras model eagerly,"**Problem**

I got unexpected result while trying to train a simple Keras model in eagerly mode (so I can debug).  The problem is reproducible on local machine and Colab.  

**Describe the current behavior**
   Same keras model trained in eager mode, but got different result compared to non-eager mode.
   The model didn't convergent.

**Describe the expected behavior**
   Result should not depend on eagerly mode On or Off.

**Code to reproduce the issue**
  [Colab notebook that reproduce problem ](https://colab.research.google.com/drive/1kzCj9vzrOuUnl90eo8pRoJvoeNwqVPP_) 

```
import tensorflow as tf
import tensorflow_datasets as tfds

## model don't work if uncomment following line
# tf.config.experimental_run_functions_eagerly(True)

TRAIN_DATASET = tfds.load(name=""cifar10"")['train']

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(32,32, 3)),
    tf.keras.layers.Dense(10, activation='softmax'),
])

BATCH_SIZE = 50

model.compile(loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])

train_set = TRAIN_DATASET.map(lambda item: (item['image'], item['label'])).batch(BATCH_SIZE)
model.fit(train_set, epochs = 5)
 ```

**Other info / logs**
Correct Output:
``` 
Epoch 1/5
1000/1000 [==============================] - 19s 19ms/step - loss: 330.7991 - accuracy: 0.1935
Epoch 2/5
1000/1000 [==============================] - 15s 15ms/step - loss: 299.7854 - accuracy: 0.2237
Epoch 3/5
1000/1000 [==============================] - 15s 15ms/step - loss: 292.7084 - accuracy: 0.2317
```

Output in eagerly mode
```
Epoch 1/5
1000/1000 [==============================] - 30s 30ms/step - loss: 14.5070 - accuracy: 0.0999
Epoch 2/5
1000/1000 [==============================] - 28s 28ms/step - loss: 14.5060 - accuracy: 0.1000
Epoch 3/5
1000/1000 [==============================] - 28s 28ms/step - loss: 14.5060 - accuracy: 0.1000
```
"
34219,STM32F7-Disco Hello World example fails to build,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
NAME=""Ubuntu""
VERSION=""18.04.3 LTS (Bionic Beaver)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 18.04.3 LTS""
VERSION_ID=""18.04""

- TensorFlow installed from (source or binary): Source
- TensorFlow version: Latest
- Python version: 2.7.15+
- Installed using virtualenv? pip? conda?: No, git
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version: 
- GPU model and memory: Genuine Intel(R) CPU T2400  @ 1.83GHz / 2Gb mem



**Describe the problem**
I am attempting to build the Hello World example for the STM32F7-Disco from the following link but it is failing to build as see below.
Example link:
[https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/hello_world](url)

**Build Error**

```
:~/developement/tensor-lite-mcu/tensorflow$ make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_hello_world_mbed_project
tensorflow/lite/experimental/micro/tools/make/download_and_extract.sh ""https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.11.0.tar.gz"" ""02c64880acb89dbd57eebacfd67200d8"" tensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers 
downloading https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.11.0.tar.gz
tensorflow/lite/experimental/micro/tools/make/download_and_extract.sh ""https://github.com/ARM-software/CMSIS_5/archive/01c7adb7685da540be9297b5a93e6640ea3333ce.zip"" ""3dec53cc74f1d5d79036952137be5d5e"" tensorflow/lite/experimental/micro/tools/make/downloads/cmsis 
downloading https://github.com/ARM-software/CMSIS_5/archive/01c7adb7685da540be9297b5a93e6640ea3333ce.zip
tensorflow/lite/experimental/micro/tools/make/download_and_extract.sh ""https://github.com/AmbiqMicro/TFLiteMicro_CustCMSIS/archive/8f63966c5692e6a3a83956efd2e4aed77c4c9949.zip"" ""4fb327201034ee0a820b72de1e807d27"" tensorflow/lite/experimental/micro/tools/make/downloads/CMSIS_ext 
downloading https://github.com/AmbiqMicro/TFLiteMicro_CustCMSIS/archive/8f63966c5692e6a3a83956efd2e4aed77c4c9949.zip
tensorflow/lite/experimental/micro/tools/make/download_and_extract.sh ""https://github.com/mborgerding/kissfft/archive/v130.zip"" ""438ba1fef5783cc5f5f201395cc477ca"" tensorflow/lite/experimental/micro/tools/make/downloads/kissfft patch_kissfft
downloading https://github.com/mborgerding/kissfft/archive/v130.zip
Finished patching kissfft
tensorflow/lite/experimental/micro/tools/make/download_and_extract.sh ""https://storage.googleapis.com/download.tensorflow.org/data/tf_lite_micro_person_data_grayscale_2019_11_07.zip"" ""e6430de25aa92bcb807d07278a1b5b90"" tensorflow/lite/experimental/micro/tools/make/downloads/person_model_grayscale 
downloading https://storage.googleapis.com/download.tensorflow.org/data/tf_lite_micro_person_data_grayscale_2019_11_07.zip
make: *** No rule to make target 'tensorflow/lite/experimental/micro/tools/make/gen/mbed_cortex-m4/prj/hello_world/mbed/third_party/gemmlowp/fixedpoint/fixedpoint.h', needed by 'generate_hello_world_mbed_project'.  Stop.
```

"
34217,Incorrect predictions occur when using a custom quantized model,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: STM32F746 Discovery kit
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.0.0
- Python version:3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.0
- GPU model and memory:Quadro P4000 8GB

This is a issue with TensorFlow Lite for Microcontrollers. Incorrect predictions occur when my ClassifyHeartbeats ( https://github.com/on-device-ai/ClassifyHeartbeats/tree/quantized_model/ ) project uses the quantized model; however, if I use a no quantized model, it is normal predictions."
34216,Cmake issue with cuDNN; Docker container doesn't seem to have cuDNN?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): Docker, `docker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu-py3`

- TensorFlow version: 2.0.0
- Python version: 3.6.8 
- Installed using virtualenv? pip? conda?: Docker
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130

cudNN: does not seem to come with Docker image. I am trying to use

`sudo docker cp libcudnn7_7.6.5.32-1+cuda10.0_amd64.deb [container ID]:/ && sudo docker cp libcudnn7-dev_7.6.5.32-1+cuda10.0_amd64.deb [container ID]:/ && sudo docker cp libcudnn7-doc_7.6.5.32-1+cuda10.0_amd64.deb [container ID]:/` on the host then

`dpkg -i libcudnn7_7.6.5.32-1+cuda10.0_amd64.deb && dpkg -i libcudnn7-dev_7.6.5.32-1+cuda10.0_amd64.deb && dpkg -i libcudnn7-doc_7.6.5.32-1+cuda10.0_amd64.deb`

- GPU model and memory: RTX 2060 6GB



**Describe the problem**

If I don't install cuDNN manually, dlib compiles ""successfully"" but will not use CUDA. If I install cudNN via dpkg, I get this error during the build:

-- Using CMake version: 3.10.2
-- Compiling dlib version: 19.18.99
-- Found system copy of libpng: /usr/lib/x86_64-linux-gnu/libpng.so;/usr/lib/x86_64-linux-gnu/libz.so
-- Found system copy of libjpeg: /usr/lib/x86_64-linux-gnu/libjpeg.so
-- Looking for cuDNN install...
-- Found cuDNN: /usr/lib/x86_64-linux-gnu/libcudnn.so
-- Enabling CUDA support for dlib.  DLIB WILL USE CUDA
-- C++11 activated.
CMake Error: The following variables are used in this project, but they are set to NOTFOUND.
Please set them or make sure they are set and tested correctly in the CMake files:
CUDA_cublas_LIBRARY (ADVANCED)
    linked by target ""dlib"" in directory /home/project/dlib/dlib
CUDA_curand_LIBRARY (ADVANCED)
    linked by target ""dlib"" in directory /home/project/dlib/dlib
CUDA_cusolver_LIBRARY (ADVANCED)
    linked by target ""dlib"" in directory /home/project/dlib/dlib

-- Configuring incomplete, errors occurred!
See also ""/home/project/dlib/build/CMakeFiles/CMakeOutput.log"".
See also ""/home/project/dlib/build/CMakeFiles/CMakeError.log"".
root@c7f1e218bc6f:/home/project/dlib/build# 

I also tried

`sudo docker cp cudnn-10.0-linux-x64-v7.6.5.32.tgz [c7f1e218bc6f]:/ `

`tar -xzvf cudnn-10.0-linux-x64-v7.6.5.32.tgz && cp cuda/include/cudnn.h /usr/local/cuda/include && cp cuda/lib64/libcudnn* /usr/local/cuda/lib64 && chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*`

`export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/include
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64`

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`sudo docker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu-py3 #run container`

`python -c ""import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))"" #hello world`
note: this^ runs just fine.

`sudo docker cp libcudnn7_7.6.5.32-1+cuda10.0_amd64.deb [container ID]:/ && sudo docker cp libcudnn7-dev_7.6.5.32-1+cuda10.0_amd64.deb [container ID]:/ && sudo docker cp libcudnn7-doc_7.6.5.32-1+cuda10.0_amd64.deb [container ID]:/`

`dpkg -i libcudnn7_7.6.5.32-1+cuda10.0_amd64.deb && dpkg -i libcudnn7-dev_7.6.5.32-1+cuda10.0_amd64.deb && dpkg -i libcudnn7-doc_7.6.5.32-1+cuda10.0_amd64.deb`

`apt update && apt upgrade && apt install git cmake libx11-dev nano
cd home && mkdir project && cd project 
git clone https://github.com/davisking/dlib.git #setup dlib`

`cd dlib && mkdir build; cd build; cmake ..; cmake --build .`





**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

CMakeOutput.log: https://pastebin.com/QC1kdejw
CMakeError.log: https://pastebin.com/JfQc02Qb
"
34215,build tf2.0 with gcc4.8.5,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
```
[tensorflow]$ gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/4.8.5/lto-wrapper
Target: x86_64-redhat-linux
Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux
Thread model: posix
gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC) 
[tensorflow]$ g++ -v
Using built-in specs.
COLLECT_GCC=g++
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/4.8.5/lto-wrapper
Target: x86_64-redhat-linux
Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux
Thread model: posix
gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC) 
```

I change the std++14 to std++11 in tensorflow/.bazelrc, and compile with bazel build -s -c opt //tensorflow:libtensorflow_cc.so

**Other info / logs**
```
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/external/aws/_objs/aws/DeleteBucketMetricsConfigurationRequest.pic.d '-frandom-seed=bazel-out/k8-opt/bin/external/aws/_objs/aws/DeleteBucketMetricsConfigurationRequest.pic.o' -fPIC -DCURL_STATICLIB -DPLATFORM_LINUX -DENABLE_CURL_CLIENT -DENABLE_NO_ENCRYPTION -iquote external/aws -iquote bazel-out/k8-opt/bin/external/aws -iquote external/curl -iquote bazel-out/k8-opt/bin/external/curl -iquote external/zlib_archive -iquote bazel-out/k8-opt/bin/external/zlib_archive -iquote external/boringssl -iquote bazel-out/k8-opt/bin/external/boringssl -isystem external/aws/aws-cpp-sdk-core/include -isystem bazel-out/k8-opt/bin/external/aws/aws-cpp-sdk-core/include -isystem external/aws/aws-cpp-sdk-s3/include -isystem bazel-out/k8-opt/bin/external/aws/aws-cpp-sdk-s3/include -isystem external/curl/include -isystem bazel-out/k8-opt/bin/external/curl/include -isystem external/zlib_archive -isystem bazel-out/k8-opt/bin/external/zlib_archive -isystem external/boringssl/src/include -isystem bazel-out/k8-opt/bin/external/boringssl/src/include '-std=c++11' '-DAWS_SDK_VERSION_MAJOR=1' '-DAWS_SDK_VERSION_MINOR=5' '-DAWS_SDK_VERSION_PATCH=8' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/aws/aws-cpp-sdk-s3/source/model/DeleteBucketMetricsConfigurationRequest.cpp -o bazel-out/k8-opt/bin/external/aws/_objs/aws/DeleteBucketMetricsConfigurationRequest.pic.o)
ERROR: /home/odin/ethanzhanghui/.cache/bazel/_bazel_ethanzhanghui/6fbeba4478bcebc2af8a7fbe84821865/external/llvm/BUILD.bazel:3399:1: C++ compilation of rule '@llvm//:support' failed (Exit 1)
In file included from external/llvm/include/llvm/ADT/ArrayRef.h:15:0,
                 from external/llvm/include/llvm/ADT/DenseMapInfo.h:16,
                 from external/llvm/include/llvm/ADT/DenseMap.h:16,
                 from external/llvm/include/llvm/ADT/DenseSet.h:16,
                 from external/llvm/lib/Support/DynamicLibrary.cpp:15:
external/llvm/include/llvm/ADT/STLExtras.h:555:49: error: 'std::index_sequence' has not been declared
   template <size_t... Ns> value_type deref(std::index_sequence<Ns...>) const {
                                                 ^
external/llvm/include/llvm/ADT/STLExtras.h:555:63: error: expected ',' or '...' before '<' token
   template <size_t... Ns> value_type deref(std::index_sequence<Ns...>) const {
                                                               ^
external/llvm/include/llvm/ADT/STLExtras.h:560:36: error: 'std::index_sequence' has not been declared
   decltype(iterators) tup_inc(std::index_sequence<Ns...>) const {
                                    ^
external/llvm/include/llvm/ADT/STLExtras.h:560:50: error: expected ',' or '...' before '<' token
   decltype(iterators) tup_inc(std::index_sequence<Ns...>) const {
                                                  ^
external/llvm/include/llvm/ADT/STLExtras.h:565:36: error: 'std::index_sequence' has not been declared
   decltype(iterators) tup_dec(std::index_sequence<Ns...>) const {
                                    ^
external/llvm/include/llvm/ADT/STLExtras.h:565:50: error: expected ',' or '...' before '<' token
   decltype(iterators) tup_dec(std::index_sequence<Ns...>) const {
                                                  ^
external/llvm/include/llvm/ADT/STLExtras.h: In member function 'llvm::detail::zip_common<ZipType, Iters>::value_type llvm::detail::zip_common<ZipType, Iters>::operator*()':
external/llvm/include/llvm/ADT/STLExtras.h:572:41: error: 'index_sequence_for' is not a member of 'std'
   ^
external/llvm/include/llvm/ADT/STLExtras.h: In member function 'llvm::concat_iterator<ValueT, IterTs>& llvm::concat_iterator<ValueT, IterTs>::operator++()':
external/llvm/include/llvm/ADT/STLExtras.h:897:15: error: 'index_sequence_for' is not a member of 'std'
     increment(std::index_sequence_for<IterTs...>());
               ^
external/llvm/include/llvm/ADT/STLExtras.h:897:45: error: expected primary-expression before '...' token
     increment(std::index_sequence_for<IterTs...>());
                                             ^
external/llvm/include/llvm/ADT/STLExtras.h: In member function 'ValueT& llvm::concat_iterator<ValueT, IterTs>::operator*() const':
external/llvm/include/llvm/ADT/STLExtras.h:902:16: error: 'index_sequence_for' is not a member of 'std'
     return get(std::index_sequence_for<IterTs...>());
                ^
external/llvm/include/llvm/ADT/STLExtras.h:902:46: error: expected primary-expression before '...' token
     return get(std::index_sequence_for<IterTs...>());
                                              ^
external/llvm/include/llvm/ADT/STLExtras.h:902:52: error: there are no arguments to 'get' that depend on a template parameter, so a declaration of 'get' must be available [-fpermissive]
     return get(std::index_sequence_for<IterTs...>());
                                                    ^
external/llvm/include/llvm/ADT/STLExtras.h:902:52: note: (if you use '-fpermissive', G++ will accept your code, but allowing the use of an undeclared name is deprecated)
external/llvm/include/llvm/ADT/STLExtras.h: At global scope:
external/llvm/include/llvm/ADT/STLExtras.h:926:52: error: 'std::index_sequence' has not been declared
   template <size_t... Ns> iterator begin_impl(std::index_sequence<Ns...>) {
                                                    ^
external/llvm/include/llvm/ADT/STLExtras.h:926:66: error: expected ',' or '...' before '<' token
   template <size_t... Ns> iterator begin_impl(std::index_sequence<Ns...>) {
                                                                  ^
external/llvm/include/llvm/ADT/STLExtras.h:929:50: error: 'std::index_sequence' has not been declared
   template <size_t... Ns> iterator end_impl(std::index_sequence<Ns...>) {
                                                  ^
external/llvm/include/llvm/ADT/STLExtras.h:929:64: error: expected ',' or '...' before '<' token
   template <size_t... Ns> iterator end_impl(std::index_sequence<Ns...>) {
                                                                ^
external/llvm/include/llvm/ADT/STLExtras.h: In member function 'llvm::detail::concat_range<ValueT, RangeTs>::iterator llvm::detail::concat_range<ValueT, RangeTs>::begin()':
external/llvm/include/llvm/ADT/STLExtras.h:938:40: error: 'index_sequence_for' is not a member of 'std'
   iterator begin() { return begin_impl(std::index_sequence_for<RangeTs...>{}); }
                                        ^
external/llvm/include/llvm/ADT/STLExtras.h:938:71: error: expected primary-expression before '...' token
   iterator begin() { return begin_impl(std::index_sequence_for<RangeTs...>{}); }
                                                                       ^
external/llvm/include/llvm/ADT/STLExtras.h: In member function 'llvm::detail::concat_range<ValueT, RangeTs>::iterator llvm::detail::concat_range<ValueT, RangeTs>::end()':
external/llvm/include/llvm/ADT/STLExtras.h:939:36: error: 'index_sequence_for' is not a member of 'std'
   iterator end() { return end_impl(std::index_sequence_for<RangeTs...>{}); }
                                    ^
external/llvm/include/llvm/ADT/STLExtras.h:939:67: error: expected primary-expression before '...' token
   iterator end() { return end_impl(std::index_sequence_for<RangeTs...>{}); }
                                                                   ^
external/llvm/include/llvm/ADT/STLExtras.h: At global scope:
external/llvm/include/llvm/ADT/STLExtras.h:1507:46: error: 'std::index_sequence' has not been declared
 auto apply_tuple_impl(F &&f, Tuple &&t, std::index_sequence<I...>)
                                              ^
external/llvm/include/llvm/ADT/STLExtras.h:1507:60: error: expected ',' or '...' before '<' token
 auto apply_tuple_impl(F &&f, Tuple &&t, std::index_sequence<I...>)
                                                            ^
external/llvm/include/llvm/ADT/STLExtras.h:1520:5: error: 'make_index_sequence' is not a member of 'std'
     std::make_index_sequence<
     ^
external/llvm/include/llvm/ADT/STLExtras.h:1520:5: error: 'make_index_sequence' is not a member of 'std'
external/llvm/include/llvm/ADT/STLExtras.h:1521:66: error: expected primary-expression before '{' token
         std::tuple_size<typename std::decay<Tuple>::type>::value>{})) {
                                                                  ^
external/llvm/include/llvm/ADT/STLExtras.h:1521:66: error: expected ')' before '{' token
external/llvm/include/llvm/ADT/STLExtras.h: In function 'decltype (llvm::detail::apply_tuple_impl(forward<F>(f), forward<Tuple>(t), ((<expression error> < std::tuple_size<typename std::decay<_Tp2>::type>::value) > <expression error>))) llvm::apply_tuple(F&&, Tuple&&)':
external/llvm/include/llvm/ADT/STLExtras.h:1522:19: error: expected type-specifier
   using Indices = std::make_index_sequence<
                   ^
external/llvm/include/llvm/ADT/STLExtras.h:1526:35: error: 'Indices' was not declared in this scope
                                   Indices{});
                                   ^
Target //tensorflow:libtensorflow_cc.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 7.772s, Critical Path: 5.70s
INFO: 138 processes: 138 local.
FAILED: Build did NOT complete successfully
```
"
34214,Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED,"

**System information**
- OS Platform and Distribution ( Linux Ubuntu 16.04):
- TensorFlow installed from (pip):
- TensorFlow version: 1.14.0 gpu
- Python version: 3.6.4
- Installed using virtualenv? pip? also have anaconda
- CUDA/cuDNN version: cuda 10.0 ,cudnn how to know the version ?
- GPU model and memory:
GPU RTX 2080 10989MiB

```
Train on 15285 samples, validate on 3822 samples
Epoch 1/100
2019-11-13 11:58:28.507273: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-11-13 11:58:28.790550: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-13 11:58:28.791219: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2019-11-13 11:58:28.791275: E tensorflow/stream_executor/cuda/cuda_dnn.cc:337] Possibly insufficient driver version: 410.48.0
2019-11-13 11:58:28.791290: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2019-11-13 11:58:28.791312: E tensorflow/stream_executor/cuda/cuda_dnn.cc:337] Possibly insufficient driver version: 410.48.0
Traceback (most recent call last):
  File ""main_ResNet.py"", line 229, in <module>
    shuffle=True)
  File ""/./anaconda3/lib/python3.6/site-packages/keras/engine/training.py"", line 1239, in fit
    validation_freq=validation_freq)
  File ""/./anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py"", line 196, in fit_loop
    outs = fit_function(ins_batch)
  File ""/./anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py"", line 3292, in __call__
    run_metadata=self.run_metadata)
  File ""/./anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1458, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node conv2d_1/convolution}}]]
	 [[Mean/_417]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node conv2d_1/convolution}}]]
0 successful operations.
0 derived errors ignored.

```

any advice or suggestion will be appriciated.
Thx
"
34213,MultiWorkerMirroredStrategy distribution error BaseCollectiveExecutor::StartAbort Invalid argument: Lower bound check fail for input 1 from node Mkl2Tf/_30 to node scoped_allocator_concat_1_1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no-ish, [keras multi-worker mirrored example](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora Server 31
- TensorFlow installed from (source or binary): source (master branch, commit 73a34133f6a414a03e54971f4975584c3d6251cc), identical on both machines
- TensorFlow version (use command below): v1.12.1-17924-g73a34133f6 2.0.0
- Python version: 3.7.5
- Bazel version (if compiling from source): 1.1.0
- GCC/Compiler version (if compiling from source): GCC 9.2.1
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Crashes at model.fit

**Describe the expected behavior**
Not, crash?

**Code to reproduce the issue**
Exact code used
[Node0](https://pastebin.com/CtTjs146)
[Node1](https://pastebin.com/5LtGA6Hd)

**Other info / logs**
Logs from run
[Node0](https://pastebin.com/HQAQwtBg)
[Node1](https://pastebin.com/ZFUjWkzf)

To compile on Fedora 31 I did need to use a grpc version patch, this patch can be found [here](https://github.com/tensorflow/tensorflow/issues/33758#issuecomment-547867642) in issue #33758. It consists of running this command before compiling tensorflow.
```
curl -L https://github.com/tensorflow/tensorflow/compare/master...hi-ogawa:grpc-backport-pr-18950.patch | git apply
```

bazel configured with Python 3 directory, and default otherwise.
bazel build command used is as follows
```
bazel build --config=mkl --config=opt //tensorflow/tools/pip_package:build_pip_package
```"
34211,No gradient defined error when training Sequential model restored from SavedModel with `tf.keras.models.load_model`,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **macOS  10.15.1**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.0.0**
- Python version: **3.7.3**
- CUDA/cuDNN version: **none**
- GPU model and memory: **none**, **(MacBook pro iCore i7, 16 GB)**


**Describe the current behavior**
When training a Sequential model (Embedding + LSTM + Dense layer) restored from SavedModel with load_model(`model = tf.keras.models.load_model('imodel_saved')`, I am getting  the following error : `LookupError: No gradient defined for operation 'while' (op type: While)`.

I am able to train the same model, if the model was previously saved in `h5` format (`tf.keras.models.save_model(model, 'imdb_model', include_optimizer=True, save_format='h5` ). However it should work with `save_format='tf`` as well. It works for other models (e.g. convolutional model) but not for this specific model:

```
model = Sequential()
model.add(Embedding(20000, 128))
model.add(LSTM(128))
model.add(Dense(1, activation='sigmoid'))
```


**Describe the expected behavior**
We should be able to train the model when restored from SavedModel.

**Code to reproduce the issue**

First run this script to define and save the Sequential model:
```
import numpy as np

import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Embedding
from tensorflow.keras.layers import LSTM

model = Sequential()
model.add(Embedding(20000, 128))
model.add(LSTM(128))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

tf.keras.models.save_model(model, 
                          'imdb_model', 
                           include_optimizer=True, 
                           save_format='tf')
```

Then run the following script to restore the model and train it on the IMDB dataset:
```
import tensorflow as tf

from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing import sequence

(x_train, y_train), _ = imdb.load_data(num_words=20000)
x_train = sequence.pad_sequences(x_train, maxlen=80)

model = tf.keras.models.load_model('imdb_model')

model.fit(x_train, y_train, epochs=1)
```


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
    forward_function, backwards_function = self.forward_backward(len(doutputs))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 582, in forward_backward
    forward, backward = self._construct_forward_backward(num_doutputs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 629, in _construct_forward_backward
    func_graph=backwards_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 619, in _backprop_function
    src_graph=self._func_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 679, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 350, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 679, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 715, in _registered_grad_fn
    return self._rewrite_forward_and_call_backward(op, *doutputs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 661, in _rewrite_forward_and_call_backward
    forward_function, backwards_function = self.forward_backward(len(doutputs))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 582, in forward_backward
    forward, backward = self._construct_forward_backward(num_doutputs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 629, in _construct_forward_backward
    func_graph=backwards_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 619, in _backprop_function
    src_graph=self._func_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 637, in _GradientsHelper
    (op.name, op.type))
LookupError: No gradient defined for operation 'while' (op type: While)
 yanndupis@yanns-MBP  ~/Documents/dropoutlabs/project-cowbay/example/medical-symptoms   model-training ● ? ⍟1 
 yanndupis@yanns-MBP  ~/Documents/dropoutlabs/project-cowbay/example/medical-symptoms   model-training ● ? ⍟1  clear
 yanndupis@yanns-MBP  ~/Documents/dropoutlabs/project-cowbay/example/medical-symptoms   model-training ● ? ⍟1  python train_model.py

2019-11-12 17:36:48.074011: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-12 17:36:48.086305: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff129c9cae0 executing computations on platform Host. Devices:
2019-11-12 17:36:48.086321: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
Train on 25000 samples
   32/25000 [..............................] - ETA: 1:28Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 2383, in get_attr
    c_api.TF_OperationGetAttrValueProto(self._c_op, name, buf)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 345, in _MaybeCompile
    xla_compile = op.get_attr(""_XlaCompile"")
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 2387, in get_attr
    raise ValueError(str(e))
ValueError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 2383, in get_attr
    c_api.TF_OperationGetAttrValueProto(self._c_op, name, buf)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 345, in _MaybeCompile
    xla_compile = op.get_attr(""_XlaCompile"")
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 2387, in get_attr
    raise ValueError(str(e))
ValueError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 621, in _GradientsHelper
    grad_fn = ops.get_gradient_function(op)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 2541, in get_gradient_function
    return _gradient_registry.lookup(op_type)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/registry.py"", line 97, in lookup
    ""%s registry has no entry for: %s"" % (self._name, name))
LookupError: gradient registry has no entry for: While

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train_model.py"", line 11, in <module>
    model.fit(x_train, y_train, epochs=1)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 73, in distributed_function
    per_replica_function, args=(model, x, y, sample_weights))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 760, in experimental_run_v2
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1787, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 2132, in _call_for_each_replica
    return fn(*args, **kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 292, in wrapper
    return func(*args, **kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 264, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 311, in train_on_batch
    output_loss_metrics=output_loss_metrics))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 268, in _process_single_batch
    grads = tape.gradient(scaled_total_loss, trainable_weights)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py"", line 1014, in gradient
    unconnected_gradients=unconnected_gradients)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py"", line 76, in imperative_grad
    compat.as_str(unconnected_gradients.value))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 738, in _backward_function
    return self._rewrite_forward_and_call_backward(call_op, *args)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 661, in _rewrite_forward_and_call_backward
    forward_function, backwards_function = self.forward_backward(len(doutputs))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 582, in forward_backward
    forward, backward = self._construct_forward_backward(num_doutputs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 629, in _construct_forward_backward
    func_graph=backwards_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 619, in _backprop_function
    src_graph=self._func_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 679, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 350, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 679, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 715, in _registered_grad_fn
    return self._rewrite_forward_and_call_backward(op, *doutputs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 661, in _rewrite_forward_and_call_backward
    forward_function, backwards_function = self.forward_backward(len(doutputs))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 582, in forward_backward
    forward, backward = self._construct_forward_backward(num_doutputs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 629, in _construct_forward_backward
    func_graph=backwards_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 619, in _backprop_function
    src_graph=self._func_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 679, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 350, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 679, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 715, in _registered_grad_fn
    return self._rewrite_forward_and_call_backward(op, *doutputs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 661, in _rewrite_forward_and_call_backward
    forward_function, backwards_function = self.forward_backward(len(doutputs))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 582, in forward_backward
    forward, backward = self._construct_forward_backward(num_doutputs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 629, in _construct_forward_backward
    func_graph=backwards_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 619, in _backprop_function
    src_graph=self._func_graph)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 637, in _GradientsHelper
    (op.name, op.type))
LookupError: No gradient defined for operation 'while' (op type: While)

"
34210,TFLiteConverter - GetOpWithOutput error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): `pip install tf-nightly`
- TensorFlow version (use command below): 2.1.0-dev20191111
- Python version: 3.6.8

**Describe the current behavior**
I'm trying to convert a BERT keras model imported from the `transformers` library. Using the `convert()` method from the `TFLiteConverter`, the following `GetOpWithOutput` error happens, no matter the values used passed to `allow_custom_ops` or `target_spec.supported_ops`:

`tensorflow/lite/toco/tooling_util.cc:935] Check failed: GetOpWithOutput(model, output_array) Specified output array ""Identity"" is not produced by any op in this graph`

**Describe the expected behavior**
The TFLiteConverter should convert the model and return the tflite version

**Code to reproduce the issue**
https://colab.research.google.com/drive/16kWs2ji8xrgjSuLftXknDqEh2VixDR4R

**Other info / logs**
The same `bert-large-uncased-whole-word-masking-finetuned-squad` model imported from the `transformers` library works perfectly when used directly on a QA task without TFLite conversion.

Also, the conversion of the DistilBERT model from the same library and using the same steps works correctly with `converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS]`."
34207,Error in the document of tf.keras.layers.Dense,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense 

## Description of issue (what needs changing):
The tf.keras.layers.Dense can actually take input_shape as function input, but it is not shown in this document.
In addition, the example of this document has the function ""Dense"", but I tried on my Googlecolab and it is not defined in tensorflow2. "
34205,C installation still suggests 1.14.0 download,"## URL(s) with the issue:

https://www.tensorflow.org/install/lang_c

## Description of issue (what needs changing):

The download instructions link to 1.14.0 libraries rather than 1.15.0; the 1.15.0 libraries appear to exist and 1.15.0 is a release according to https://github.com/tensorflow/tensorflow/releases
"
34203,RuntimeError: `merge_call` called while defining a new graph or a tf.function -- Update non-trainable variable with assign under mirrored strategy scope and tf.function decorator,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Gentoo
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary, pip
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
My purpose is to record some hidden results that no need to compute gradient but is used for the next batch. The demo code is given below.
Under the mirrored strategy context, it fails to update non-trainable variable with assign method
within fn with tf.function decorator. If remove tf.function, it works well. If
re-assign `self.record = record` within tf.function, then will hit another error:
`TypeError: An op outside of the function building code is being passed`, same error like [this](https://github.com/tensorflow/tensorflow/issues/32889). I'm aware we have to do some all_reduce-like operations to merge the results from all replicas before update any variable.
I tried something like `tf.distribute.get_replica_context().merge_call()`, but the doc is really unclear how to implement it, the source code of tensorflow also can not be found any useful example.

**Describe the expected behavior**
under strategy and tf.function context, updating a non-trainable variable with assign method
should work


**Code to reproduce the issue**
```
import numpy as np
import tensorflow as tf

class MyLayer(tf.keras.layers.Layer):
  def __init__(self):
    super(MyLayer, self).__init__()

  def build(self, input_shape):
    self.w = self.add_weight(""w"", shape=[], dtype=tf.float32, initializer=tf.constant_initializer(np.random.uniform()))

    # record some hidden results used by next batch
    self.record = self.add_weight(""record"", shape=[],
                                  dtype=tf.float32,
                                  trainable=False,
                                  aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA,
                                  initializer=tf.constant_initializer(np.random.uniform()))

  def call(self, x):
    record = self.record + self.w
    y = x*self.w + record

    # Hit TypeError: An op outside of the function building code is being passed a ""Graph"" tensor
    #self.record = record

    # Hit RuntimeError: `merge_call` called while defining a new graph or a tf.function
    self.record.assign(record)
    return y


class Net(tf.keras.Model):
  def __init__(self):
    super(Net, self).__init__()
    self.my_layer = MyLayer()

  def call(self, x):
    y = self.my_layer(x)
    y = y + tf.random.normal(shape=[])
    return y

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    net = Net()
    n_samples = 1000
    xs = np.random.uniform(size=[n_samples])

    #It works well without tf.function
    @tf.function
    def train_step(x):
        y = net(x)
        return y
    for i in range(n_samples):
        x = xs[i]
       

    # if no tf.distribute.strategy was used, it also works well no matter tf.function is used or not

        y = strategy.experimental_run_v2(train_step, args=(x,))
```

**Other info / logs**

```
 test4.py:50 train_step  *
        y = net(x)
    /usr/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:891 __call__
        outputs = self.call(cast_inputs, *args, **kwargs)
    test4.py:28 call  *
        self.record.assign(record+0.1)
    /usr/lib64/python3.6/site-packages/tensorflow_core/python/distribute/values.py:1036 assign
        return self._assign_func(f=assign_fn, *args, **kwargs)
    /usr/lib64/python3.6/site-packages/tensorflow_core/python/distribute/values.py:1024 _assign_func
        merge_fn, args=args, kwargs=kwargs)
    /usr/lib64/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py:1917 merge_call
        return self._merge_call(merge_fn, args, kwargs)
    /usr/lib64/python3.6/site-packages/tensorflow_core/python/distribute/mirrored_strategy.py:940 _merge_call
        ""`merge_call` called while defining a new graph or a tf.function. ""

RuntimeError: `merge_call` called while defining a new graph or a tf.function. 
This can often happen if the function `fn` passed to `strategy.experimental_run()` 
is decorated with `@tf.function` (or contains a nested `@tf.function`), 
and `fn` contains a synchronization point, such as aggregating gradients. 
This behavior is not yet supported. Instead, please wrap the entire call `strategy.experimental_run(fn)` in a `@tf.function`, 
and avoid nested `tf.function`s that may potentially cross a synchronization boundary.
```"
34201,keras.backend.function with learning phase gives AttributeError,"I'm using the following script from the keras docu page to get the output of an intermediate layer in training phase:
``` python
from tensorflow.keras import backend as K

K.function([model.layers[0].input, K.learning_phase()],
           [model.layers[1].output])
```

Which throws this error:
``` python
AttributeError                            Traceback (most recent call last)
<ipython-input-2-d35d4dbf76cf> in <module>
      2
      3 K.function([model.layers[0].input, K.learning_phase()],
----> 4            [model.layers[1].output])

/home/woody/capn/mppi013h/conda_envs/orca_cpu_env/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py in function(inputs, outputs, updates, name, **kwargs)
   3771       raise ValueError('Session keyword arguments are not support during '
   3772                        'eager execution. You passed: %s' % (kwargs,))
-> 3773     return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)
   3774
   3775   if kwargs:

/home/woody/capn/mppi013h/conda_envs/orca_cpu_env/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py in __init__(self, inputs, outputs, updates, name)
   3668             add_sources=True,
   3669             handle_captures=True,
-> 3670             base_graph=source_graph)
   3671
   3672         inputs = [lifted_map[i] for i in inputs]

/home/woody/capn/mppi013h/conda_envs/orca_cpu_env/lib/python3.6/site-packages/tensorflow_core/python/eager/lift_to_graph.py in lift_to_graph(tensors, graph, sources, disallowed_placeholders, add_sources, handle_captures, base_graph, op_map)
    247   # Check that the initializer does not depend on any placeholders.
    248   sources = object_identity.ObjectIdentitySet(sources or [])
--> 249   visited_ops = set([x.op for x in sources])
    250   op_outputs = collections.defaultdict(set)
    251

/home/woody/capn/mppi013h/conda_envs/orca_cpu_env/lib/python3.6/site-packages/tensorflow_core/python/eager/lift_to_graph.py in <listcomp>(.0)
    247   # Check that the initializer does not depend on any placeholders.
    248   sources = object_identity.ObjectIdentitySet(sources or [])
--> 249   visited_ops = set([x.op for x in sources])
    250   op_outputs = collections.defaultdict(set)
    251

AttributeError: 'int' object has no attribute 'op'
``` 
Using this simple model:
``` python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation

model = Sequential()
model.add(Dense(32, input_dim=784))
model.add(Activation('relu'))
``` 
If I use keras instead of tensorflow.keras, it works fine. 

- TensorFlow version: 2.0.0
- Python version: 3.6.8
`
"
34200,OutOfRangeError when training estimator with filter in the input_fn,"**System information**
- Have I written custom code: YES
- OS Platform and Distribution: WINDOWS 10, 64-bits
- TensorFlow installed from (source or binary): conda install -c anaconda tensorflow-gpu
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.5
- CUDA/cuDNN version: from conda installation
- GPU model and memory: NVIDIA GE Force 730M, 4.8GB

**Describe the current behavior**
OutOfRangeError when training estimator with filter in the input_fn
When I remove the `.filter(lambda x: x['label'] == 0)` in the `input_fn`, everything works fine.
The same error appears if I use:
`tf.estimator.train_and_evaluate(KMeansEstimator, train_spec_kmeans, eval_spec_kmeans)`
or
`KMeansEstimator.train(input_fn = lambda: input_fn(data_files) , max_steps=10)`

**Describe the expected behavior**
No error during the training with the filtered dataset in the `input_fn` of the estimator

**Code to reproduce the issue**
tfrecords_path is the path to mnist dataset as TFRecords files with the features described bellow:
```
def parser(record):
    features={
            'label': tf.io.FixedLenFeature([], tf.int64),
            'height': tf.io.FixedLenFeature([], tf.int64),
            'width': tf.io.FixedLenFeature([], tf.int64),
            'depth': tf.io.FixedLenFeature([], tf.int64),
            'image_raw': tf.io.FixedLenFeature([], tf.string)
            }
    parsed = tf.io.parse_single_example(record, features)
    feats = tf.io.decode_raw(parsed['image_raw'], tf.float64)
    return {'image': feats, 'label': parsed['label']}

def input_fn(tfrecords_path):
    dataset = (
        tf.data.TFRecordDataset(tfrecords_path)
        .map(
            map_func=parser,
            num_parallel_calls=int(multiprocessing.cpu_count() * 0.75)
            )
        .filter(lambda x: x['label'] == 0)
        .batch(1024)
        .prefetch(1024)
     )
    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)
    batch_feats = iterator.get_next()
    return batch_feats

train_spec_kmeans = tf.estimator.TrainSpec(input_fn = lambda: input_fn(data_files) , max_steps=10)
eval_spec_kmeans = tf.estimator.EvalSpec(input_fn = lambda: input_fn(data_files) )

KMeansEstimator = tf.compat.v1.estimator.experimental.KMeans(
    num_clusters=number_of_clusters,
    feature_columns = [tf.feature_column.numeric_column(
        key='image',
        dtype=tf.float64,
        shape=(784,)
    )],
    use_mini_batch=True)

tf.estimator.train_and_evaluate(KMeansEstimator, train_spec_kmeans, eval_spec_kmeans)
```

**Other info / logs**
```
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1160, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1194, in _train_model_default
    saving_listeners)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1489, in _train_with_estimator_spec
    log_step_count_steps=log_step_count_steps) as mon_sess:
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 584, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 1014, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 725, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 1207, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 1212, in _create_session
    return self._sess_creator.create_session()
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 885, in create_session
    hook.after_create_session(self.tf_sess, self.coord)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\canned\kmeans.py"", line 105, in after_create_session
    session.run(self._init_op)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\client\session.py"", line 956, in run
    run_metadata_ptr)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\client\session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\client\session.py"", line 1359, in _do_run
    run_metadata)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\client\session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.OutOfRangeError: 2 root error(s) found.
  (0) Out of range: End of sequence
         [[node IteratorGetNext (defined at C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\framework\ops.py:1751) ]]
         [[Shape_1/_37]]
  (1) Out of range: End of sequence
         [[node IteratorGetNext (defined at C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\framework\ops.py:1751) ]]
0 successful operations.
0 derived errors ignored.

Original stack trace for 'IteratorGetNext':
  File "".\main.py"", line 144, in <module>
    tf.compat.v1.app.run()
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File "".\main.py"", line 136, in main
    launch_training_testing()
  File "".\main.py"", line 100, in launch_training_testing
    km_ckpt, kmeans = train_test.train_quantizers(FLAGS)
  File ""C:\Users\CUI\ML\Decentralized_class_V1_tf2\src\model\train_test_tf2TFR.py"", line 334, in train_quantizers
    km_ckpt, kmeans = label_train_quantizers(label, q_c, kmeans, km_ckpt, config)
  File ""C:\Users\CUI\ML\Decentralized_class_V1_tf2\src\model\train_test_tf2TFR.py"", line 296, in label_train_quantizers
    kmeans[label][q_c].train(input_fn = lambda: kmtrain_input_fn(tfr_train_files) , max_steps=config.km_steps)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1160, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1187, in _train_model_default
    input_fn, ModeKeys.TRAIN))
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1024, in _get_features_and_labels_from_input_fn
    self._call_input_fn(input_fn, mode))
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_estimator\python\estimator\util.py"", line 65, in parse_input_fn_result
    result = iterator.get_next()
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py"", line 426, in get_next
    name=name)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\ops\gen_dataset_ops.py"", line 2500, in iterator_get_next
    output_shapes=output_shapes, name=name)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3360, in create_op
    attrs, op_def, compute_device)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3429, in _create_op_internal
    op_def=op_def)
  File ""C:\Users\CUI\.conda\envs\py3tf2_0\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1751, in __init__
    self._traceback = tf_stack.extract_stack()
```
"
34199,Named dictionary outputs in tf.keras.Model do not work,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): any
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6.5

**Describe the current behavior**
Using a custom model with named outputs does not work in TF2.

**Describe the expected behavior**
While using tuples for multi output model works fine, using a dictionary fails. Dict inputs and outputs seem to be allowed in the code (and in the tf.keras documentation), however the functionality seem not to be functional yet.

**Code to reproduce the issue**
https://colab.research.google.com/gist/kpe/501901b5197675818a2e8a0e0bc8f3a6/keras-named-output-dict.ipynb

```python
%tensorflow_version 2.x
import tensorflow as tf


max_seq_len    = 8
channels_count = 11

class MultiOutputModel(tf.keras.Model):
    def __init__(self):
        super(MultiOutputModel, self).__init__()
        self.dense_a = tf.keras.layers.Dense(3)
        self.dense_b = tf.keras.layers.Dense(4)
        
    def call(self, inputs):
        seq = inputs[""F""]
        out_a = self.dense_a(seq)
        out_b = self.dense_b(seq)
        return {""A"": out_a, ""B"": out_b}
    
def ds_gen():
    while True:
        inputs  = {""F"": tf.random.uniform((max_seq_len, channels_count))}
        outputs = {""A"": tf.random.uniform((), minval=0, maxval=3, dtype=tf.int32), 
                   ""B"": tf.random.uniform((), minval=0, maxval=4, dtype=tf.int32)}
        yield inputs, outputs
        
ds = tf.data.Dataset.from_generator(ds_gen, 
                                    output_types=({""F"": tf.float32}, 
                                                  {""A"": tf.int32, ""B"":tf.int32}), 
                                    output_shapes=({""F"": tf.TensorShape([max_seq_len, channels_count])}, 
                                                   {""A"":tf.TensorShape([]), ""B"":tf.TensorShape([])}))
# check dataset - a (features, labels) tuple
for inp, out in ds.batch(8).take(1):
    for ndx, (name, val) in enumerate(inp.items()):
        print(""features {}: {}: {}"".format(ndx, name, val.shape), val.dtype)
    for ndx, (name, val) in enumerate(out.items()):
        print(""  labels {}: {}: {}"".format(ndx, name, val.shape), val.dtype)
    
model = MultiOutputModel()

def features_only(feat, lab):
    return feat

pred = model.predict(ds.map(features_only).batch(8).take(1))
print("" prediction:"", type(pred))
for ndx, out in enumerate(pred):
    print("" pred out {}: {}"".format(ndx, out.shape), out.dtype)

model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss={""A"": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                    ""B"": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),})

model.predict({""seq"": tf.constant([[2],[1]])})
model.fit(ds.batch(1))
```

The output from the above code is:
```
features 0: F: (8, 8, 11) <dtype: 'float32'>
  labels 0: A: (8,) <dtype: 'int32'>
  labels 1: B: (8,) <dtype: 'int32'>
 prediction: <class 'list'>
 pred out 0: (8, 8, 3) float32
 pred out 1: (8, 8, 4) float32
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-28-948267c0fc05> in <module>()
     49 model.compile(optimizer=tf.keras.optimizers.Adam(),
     50               loss={""A"": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
---> 51                     ""B"": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),})
     52 
     53 model.fit(ds.batch(8))

3 frames
/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/utils/generic_utils.py in check_for_unexpected_keys(name, input_dict, expected_values)
    589     raise ValueError('Unknown entries in {} dictionary: {}. Only expected '
    590                      'following keys: {}'.format(name, list(unknown),
--> 591                                                  expected_values))
    592 
    593 

ValueError: Unknown entries in loss dictionary: ['A', 'B']. Only expected following keys: ['output_1', 'output_2']
```"
34198,Not found: Op type not registered 'BatchMatMulV2',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04
- TensorFlow version (use command below): 1.13.1  (docker build inside)
- Docker  tensorrtserver:19.06-py3
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:  CUDA Version 10.1.243 / 7.6.3
- GPU model and memory: T4 16G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I am using tensorrt-inference-server to deploy my tensorflow savedmodel files( tf version : 1.11.1).

the config.pbtxt 

`name: ""jingjing""
platform: ""tensorflow_savedmodel""
max_batch_size: 0
input [
  {
    name: ""inputs""
    data_type: TYPE_INT32
    dims: [ -1]
  },
  {
    name: ""input_lengths""
    data_type: TYPE_INT32
    dims: [ -1 ]
  },
  {
    name: ""split_infos""
    data_type: TYPE_INT32
    dims: [ 1, -1 ]
  }
]
output [
  {
    name: ""linear_wav_outputs""
    data_type: TYPE_FP32
    dims: [ -1 ]
  }
]
version_policy: { all { }}`
when trying to run the tensorrt inference server , errors will occur like below :
`failed to load 'jingjing' version 1: Not found: Op type not registered 'BatchMatMulV2' in binary running on fa60ca095bbf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`

and when curl 
``id: ""inference:0""
version: ""1.3.0""
uptime_ns: 16498837986
model_status {
  key: ""jingjing""
  value {
    config {
      name: ""jingjing""
      platform: ""tensorflow_savedmodel""
      version_policy {
        all {
        }
      }
      max_batch_size: 1
      input {
        name: ""inputs""
        data_type: TYPE_INT32
        dims: -1
        dims: -1
      }
      input {
        name: ""input_lengths""
        data_type: TYPE_INT32
        dims: -1
      }
      input {
        name: ""split_infos""
        data_type: TYPE_INT32
        dims: 1
        dims: -1
      }
      output {
        name: ""linear_wav_outputs""
        data_type: TYPE_FP32
        dims: -1
      }
      instance_group {
        name: ""jingjing""
        count: 1
        gpus: 0
        kind: KIND_GPU
      }
      default_model_filename: ""model.savedmodel""
    }
    version_status {
      key: 1
      value {
        ready_state: MODEL_UNAVAILABLE
      }
    }
    version_status {
      key: 2
      value {
        ready_state: MODEL_UNAVAILABLE
      }
    }
    version_status {
      key: 3
      value {
        ready_state: MODEL_UNAVAILABLE
      }
    }
    version_status {
      key: 4
      value {
        ready_state: MODEL_UNAVAILABLE
      }
    }
  }
}
ready_state: SERVER_READY``

**Describe the expected behavior**

the ready_state of model should be MODEL_READY

**Code to reproduce the issue**
`docker run --rm --gpus ""device=3"" --shm-size=1g --ulimit memlock=-1 \
--ulimit stack=67108864 -p8000:8000 -p8001:8001 -p8002:8002 \
-v/home/yichao.li/models:/models nvcr.io/nvidia/tensorrtserver:19.06-py3 \
trtserver --model-store=/models &`

please help to solve the "" Op type not registered 'BatchMatMulV2'"" issue
"
34197,Building Tensorflow 1.13 for python 3.8 fails on nullptr conversion.,"**System information**
- OS Platform and Distribution: Centos 7
- TensorFlow installed from : source
- TensorFlow version: 1.13.2
- Python version: 3.8.0
- Bazel version : 0.21.0
- GCC/Compiler version : gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39) 
- CUDA/cuDNN version: 9.1/7.0
- GPU model and memory: 1080ti



**Describe the problem**

When attempting to build the tensorflow branch r1.13 targeting python 3.8 the build fails with the following error:

ndarray_tensor_bridge.cc:108:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization
 };

This error occurs in three files that I found: bfloat16.cc, ndarray_tensor_bridge.cc, pywrap_tfe_src.cc

This appears to be the same problem fixed in issue #33543 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I am willing to provide more details, but this appears to be the exact same issue. I am including the git diff from the version that compiled and works for me.

```patch
diff --git a/tensorflow/python/eager/pywrap_tfe_src.cc b/tensorflow/python/eager/pywrap_tfe_src.cc
index 9ce500b..726c4c5 100644
--- a/tensorflow/python/eager/pywrap_tfe_src.cc
+++ b/tensorflow/python/eager/pywrap_tfe_src.cc
@@ -1216,7 +1216,7 @@ static PyTypeObject TFE_Py_Tape_Type = {
     sizeof(TFE_Py_Tape),                          /* tp_basicsize */
     0,                                            /* tp_itemsize */
     &TFE_Py_Tape_Delete,                          /* tp_dealloc */
-    nullptr,                                      /* tp_print */
+    NULL,                                         /* tp_print */
     nullptr,                                      /* tp_getattr */
     nullptr,                                      /* tp_setattr */
     nullptr,                                      /* tp_reserved */
diff --git a/tensorflow/python/lib/core/bfloat16.cc b/tensorflow/python/lib/core/bfloat16.cc
index fde3a83..e0da0f4 100644
--- a/tensorflow/python/lib/core/bfloat16.cc
+++ b/tensorflow/python/lib/core/bfloat16.cc
@@ -317,7 +317,7 @@ PyTypeObject PyBfloat16_Type = {
     sizeof(PyBfloat16),                        // tp_basicsize
     0,                                         // tp_itemsize
     nullptr,                                   // tp_dealloc
-    nullptr,                                   // tp_print
+    NULL,                                      // tp_print
     nullptr,                                   // tp_getattr
     nullptr,                                   // tp_setattr
     nullptr,                                   // tp_compare / tp_reserved
diff --git a/tensorflow/python/lib/core/ndarray_tensor_bridge.cc b/tensorflow/python/lib/core/ndarray_tensor_bridge.cc
index 0d58385..43ab92c 100644
--- a/tensorflow/python/lib/core/ndarray_tensor_bridge.cc
+++ b/tensorflow/python/lib/core/ndarray_tensor_bridge.cc
@@ -86,7 +86,7 @@ PyTypeObject TensorReleaserType = {
     0,                                /* tp_itemsize */
     /* methods */
     TensorReleaser_dealloc,      /* tp_dealloc */
-    nullptr,                     /* tp_print */
+    NULL,                        /* tp_print */
     nullptr,                     /* tp_getattr */
     nullptr,                     /* tp_setattr */
     nullptr,                     /* tp_compare */
```
"
34196,Keras fails to combine predicted variable-sized sequences,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-17764-gae26958 2.1.0-dev20191111
- Python version: Google Colab py3
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: Google Colab
- GPU model and memory: Google Colab

**Describe the current behavior**
Exception raised (from numpy concatenate) when predicting sequence labels with variable sequence length batches.

**Describe the expected behavior**
There should be no error, as in fit/evaluate methods work fine.

**Code to reproduce the issue**
https://colab.research.google.com/drive/1IPIkj5PlUWKCpuTm9NWM5BLO_suL5VI3

**Other info / logs**
```python
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-23-e5e9890a3d75> in <module>()
----> 1 model.predict(get_dataset(labels=False))

5 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
    972         max_queue_size=max_queue_size,
    973         workers=workers,
--> 974         use_multiprocessing=use_multiprocessing)
    975 
    976   def reset_metrics(self):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in predict(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    496         model, ModeKeys.PREDICT, x=x, batch_size=batch_size, verbose=verbose,
    497         steps=steps, callbacks=callbacks, max_queue_size=max_queue_size,
--> 498         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
    499 
    500 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in _model_iteration(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    473               mode=mode,
    474               training_context=training_context,
--> 475               total_epochs=1)
    476           cbks.make_logs(model, epoch_logs, result, mode)
    477 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    185 
    186   # End of an epoch.
--> 187   aggregator.finalize()
    188   return aggregator.results
    189 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in finalize(self)
    349   def finalize(self):
    350     for result in self.results:
--> 351       result.finalize()
    352     self.results = [i.results for i in self.results]
    353     self.results = nest.pack_sequence_as(self._structure, self.results)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in finalize(self)
    187 
    188     else:
--> 189       self.results = np.concatenate(self.results, axis=0)
    190 
    191     if isinstance(self.results, ops.EagerTensor):

<__array_function__ internals> in concatenate(*args, **kwargs)

ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 7 and the array at index 1 has size 9
```"
34195,Problem with the Run API  in  C++,"Hello, I have a problem with the Run API in C++ with the following code:

```
std::unique_ptr<tensorflow::Tensor> out_t;
std::vector<Tensor> res;
std::string entry_name = ""name"";
std::string target_ops_name = ""ops_name"";     
TF_CHECK_OK(session.Run({{entry_name, *out_t}},{target_ops_name},{},&res));
```
NB: I have 2 Output tensors with the corresponding names (WithOpName(...)) ""name"" and ""ops_name"". 

I receive the following compilation error when I compile my project in bazel.
```
error: no matching function for call to 'tensorflow::ClientSession::Run(<brace-enclosed initializer list>, <brace-enclosed initializer list>, <brace-enclosed initializer list>, std::vector<tensorflow::Tensor>*)'
         TF_CHECK_OK(session.Run({{entry_name, *out_t}},{target_ops_name},{},&res));

```
I use the latest version of tensorflow compiled with bazel. Would be glad if someone could give my hints on what the problem could be. Thanks.
"
34194,tf.size() has no documentation,"https://www.tensorflow.org/api_docs/python/tf/size

Example: ""Returns the number of elements in the tensor. It equals the length of the flattened tensor."""
34193,[TF-TRT] [Tensorflow1.14] [InceptionV3] INT8 Top1 accuracy has a big drop compared to original.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Nvidia NGC docker 19.10
- TensorFlow version (use command below): 1.14
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.5.0
- GPU model and memory: TitanXp 12GB

**Describe the current behavior**

My environment is based on NVidia NGC docker 19.10 [[NGC]](https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow/tags) , which uses Tensorflow 1.14, TensorRT6, CUDA10.1.

I tried to quantize a normal InceptionV3 155 classes classification model to FP32/FP16/INT8 and test the Top1 accuracy over a dataset of 17000 images. It turns out that the Top1 class accuracy of FP32 and FP16 is exactly 100% identical with the original InceptionV3 model. However, the INT8 quantized model is much different with original model, Top1 miss rate is 5037/17000=29.6%. 

The INT8 model is calibrated by randomly selected 1000 imaged from image dataset. So I'm confused whether it's a TF-TRT bug? Do you have experimental record of INT8 Top1 miss accuracy?

My TF-TRT conversion script:

```
from tensorflow.python.compiler.tensorrt import trt_convert as trt
from tensorflow.python.framework import importer as importer

prebuilt_graph_path = ""frozen_graph.pb""
frozen_graph = tf.GraphDef()
if os.path.isfile(prebuilt_graph_path):
    with tf.gfile.GFile(prebuilt_graph_path, ""rb"") as f:
        frozen_graph.ParseFromString(f.read())

converter = trt.TrtGraphConverter(
    input_graph_def=frozen_graph,
    nodes_blacklist=[""InceptionV3/Logits/SpatialSqueeze""],
    max_batch_size=16,
    max_workspace_size_bytes=1<<20,
    precision_mode=""INT8"",
    minimum_segment_size=2,
    is_dynamic_op=False
    )

# Conversion                                                                                                                      
frozen_graph = converter.convert()

# Calibration                                                                                                                     
calibrate_dir = 'calibrate_set'
calibrate_image_list = []
for filename in glob.glob(calibrate_dir+'/*.jpg'):
    im=Image.open(filename)
    img=img.resize((299, 299), Image.NEAREST)
    image=np.array(img, dtype=float)
    image=(image-127)/128
    calibrate_image_list.append(image)

class CalibrationData(object):
    def __init__(self):
        self.pointer = 0
        self.data = calibrate_image_list

    def next(self):
        self.now = self.pointer
        self.pointer += 16
        print(""Calibration data length: {}, Calibrate on seg: {}~{}"".format(len(self.data), self.now, self.pointer-1))
        return {'Placeholder:0': np.array(self.data[self.now : self.pointer])}

frozen_graph = converter.calibrate(
    fetch_names=[""InceptionV3/Logits/SpatialSqueeze""],
    num_runs=10,                                             
    feed_dict_fn=CalibrationData().next
)

with tf.gfile.GFile(""converted_int8.pb"", ""wb"") as f:
    f.write(frozen_graph.SerializeToString())
```



**Describe the expected behavior**
    For the InceptionV3 model, the Top1 miss rate of TF-TRT INT8 quantized model shall be smaller than 3~5% after calibration, however, I got Top1 miss rate >29%

**Code to reproduce the issue**


**Other info / logs**

"
34192,Bug in function estimator_train when 'evaluator' included in TF_CONFIG ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): rc1.13
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.0/7.6
- GPU model and memory: Run in GPU


**Describe the current behavior**

with the following configurations:

 `os.environ['TF_CONFIG'] = json.dumps({""cluster"": {""evaluator"": [""10.0.26.2:4000""], ""ps"": [""10.0.26.2:5000""], ""worker"": [""10.0.26.2:6000""]}, ""rpc_layer"": ""grpc"", ""task"": {""index"": ""0"", ""type"": ""worker""})`

Running estimator.train(), the output from the command line is

```
Traceback (most recent call last):
  ...
    model_estimator.train(input_fn=lambda: input_fn(image_ids=train_id), steps=global_step)
  File ""/home/zxy/steel/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 405, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/zxy/steel/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1169, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File ""/home/zxy/steel/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1227, in _train_model_distributed
    hooks)
  File ""/home/zxy/steel/lib/python3.6/site-packages/tensorflow/python/distribute/estimator_training.py"", line 304, in estimator_train
    if 'evaluator' in cluster_spec:
TypeError: argument of type 'ClusterSpec' is not iterable
```


**Describe the expected behavior**

When calling estimator.train with 'evaluator' included in RunConfig, a ValueError should be reported. The following is the fragment code in estimator_training.py. 
    
    if 'evaluator' in cluster_spec:
        raise ValueError(""'evaluator' job is not supported if you don't use ""
                         '`train_and_evaluate`')

Here the value of cluster_spec is like ClusterSpec({'evaluator': ['10.0.26.2:4000'], 'ps': ['10.0.26.2:5000'], 'worker': ['10.0.26.2:6000']})

if 'evaluator' in cluster_spec.jobs which is the way it should be.


"
34191,TF2.1 build from source failure,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: `No`
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: `Linux Ubuntu 18.0.4`
- **Python version tried**: `3.6/3.7`
- **gcc/g++**: `7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1)`
- **TensorFlow installed from (source or binary)**: `source`
- **TensorFlow version (use command below)**: `2.1`
git clone https://github.com/tensorflow/tensorflow tensorflow  -b r2.1
- **Bazel version (if compiling from source)**: `0.29.1`
Build label: 0.29.1
Build target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Sep 10 13:44:39 2019 (1568123079)
- **CUDA/cuDNN version**: `V10.1.243/7.6.1`
- **GPU model and memory**: `GeForce GTX 1080 TX 12Gb`
- **Exact command to reproduce**:

> bazel build --linkopt='-lrt' --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-mavx --copt=-msse4.1 --copt=-msse4.2 --config=noaws --config=nohdfs --config=nonccl --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --config=cuda -k //tensorflow/tools/pip_package:build_pip_package --verbose_failures 2>&1 | tee bazel.log


### Describe the problem
Failed to build from source TF2.1 with CUDA (though able to builf TF2.0 without a problem)

### Source code / logs

Config (all default options except enabling CUDA):

(base) sergey@sergey-Bionic:~/tensorflow$ ./configure
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
You have bazel 0.29.1 installed.
Please specify the location of python. [Default is /home/sergey/anaconda3/bin/python]: 


Found possible Python library paths:
  /home/sergey/anaconda3/lib/python3.6/site-packages
Please input the desired Python library path to use.  Default is [/home/sergey/anaconda3/lib/python3.6/site-packages]

Do you wish to build TensorFlow with XLA JIT support? [Y/n]: 
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: 
No TensorRT support will be enabled for TensorFlow.

Found CUDA 10.1 in:
    /usr/local/cuda/lib64
    /usr/local/cuda/include
Found cuDNN 7 in:
    /usr/lib64
    /usr/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1]: 


Do you want to use clang as CUDA compiler? [y/N]: 
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.


### Example of Bazel error messages:

> ERROR: /home/sergey/tensorflow/tensorflow/python/BUILD:2640:1: Couldn't build file tensorflow/python/gen_tpu_ops_py_wrappers_cc: Linking of rule '//tensorflow/python:gen_tpu_ops_py_wrappers_cc' failed (Exit 1)
--
bazel-out/host/bin/tensorflow/core/protobuf/tpu/libtpu_embedding_output_layout_proto_cc.lo(tpu_embedding_output_layout.pb.o):(.data.rel.ro._ZTVN10tensorflow3tpu24TPUEmbeddingOutputLayoutE[_ZTVN10tensorflow3tpu24TPUEmbeddingOutputLayoutE]+0x60): undefined reference to `google::protobuf::Message::CheckTypeAndMergeFrom(google::protobuf::MessageLite const&)'
bazel-out/host/bin/tensorflow/core/protobuf/tpu/libtpu_embedding_output_layout_proto_cc.lo(tpu_embedding_output_layout.pb.o):(.data.rel.ro._ZTVN10tensorflow3tpu24TPUEmbeddingOutputLayoutE[_ZTVN10tensorflow3tpu24TPUEmbeddingOutputLayoutE]+0x80): undefined reference to `google::protobuf::MessageLite::SerializeWithCachedSizesToArray(unsigned char*) const'
bazel-out/host/bin/tensorflow/core/protobuf/tpu/libtpu_embedding_output_layout_proto_cc.lo(tpu_embedding_output_layout.pb.o):(.data.rel.ro._ZTVN10tensorflow3tpu24TPUEmbeddingOutputLayoutE[_ZTVN10tensorflow3tpu24TPUEmbeddingOutputLayoutE]+0xb0): undefined reference to `google::protobuf::Message::DiscardUnknownFields()'
bazel-out/host/bin/tensorflow/core/protobuf/tpu/libtpu_embedding_output_layout_proto_cc.lo(tpu_embedding_output_layout.pb.o):(.data.rel.ro._ZTVN10tensorflow3tpu24TPUEmbeddingOutputLayoutE[_ZTVN10tensorflow3tpu24TPUEmbeddingOutputLayoutE]+0xb8): undefined reference to `google::protobuf::Message::SpaceUsedLong() const'
collect2: error: ld returned 1 exit status
ERROR: /home/sergey/tensorflow/tensorflow/python/BUILD:2359:1: Couldn't build file tensorflow/python/gen_checkpoint_ops_py_wrappers_cc: Linking of rule '//tensorflow/python:gen_checkpoint_ops_py_wrappers_cc' failed (Exit 1)
--
bazel-out/host/bin/tensorflow/core/libcheckpoint_ops_op_lib.lo(checkpoint_ops.o): In function `__static_initialization_and_destruction_0(int, int) [clone .constprop.45]':
checkpoint_ops.cc:(.text.startup._Z41__static_initialization_and_destruction_0ii.constprop.45+0x19b): undefined reference to `tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)'
checkpoint_ops.cc:(.text.startup._Z41__static_initialization_and_destruction_0ii.constprop.45+0x3ff): undefined reference to `tensorflow::OpDefBuilder::SetIsStateful()'
checkpoint_ops.cc:(.text.startup._Z41__static_initialization_and_destruction_0ii.constprop.45+0x424): undefined reference to `tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)'
collect2: error: ld returned 1 exit status
ERROR: /home/sergey/tensorflow/tensorflow/python/BUILD:2339:1: Couldn't build file tensorflow/python/gen_audio_ops_py_wrappers_cc: Linking of rule '//tensorflow/python:gen_audio_ops_py_wrappers_cc' failed (Exit 1)
--
audio_ops.cc:(.text.startup._Z41__static_initialization_and_destruction_0ii.constprop.63+0x140): undefined reference to `tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)'
audio_ops.cc:(.text.startup._Z41__static_initialization_and_destruction_0ii.constprop.63+0x250): undefined reference to `tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)'
audio_ops.cc:(.text.startup._Z41__static_initialization_and_destruction_0ii.constprop.63+0x386): undefined reference to `tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)'
audio_ops.cc:(.text.startup._Z41__static_initialization_and_destruction_0ii.constprop.63+0x562): undefined reference to `tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)'
collect2: error: ld returned 1 exit status

### Full bazel error log see attached.
[bazel_error.l og](https://github.com/tensorflow/models/files/3834933/bazel_error.log)
 "
34190,TypeError: Parameter to MergeFrom() must be instance of same class: expected tensorboard.SummaryMetadata got tensorflow.SummaryMetadata.,"Hey, I'm trying to use Hyperparameter tuning with the HParams Dashboard. Trying to follow the guidelines on https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams 
although I'm using Pytorch instead of a Keras model. 

To start with I'm only focusing on one hyperparameter (lambda_L1), following the tutorial this is what I've got:   

```
HP_LAMBDA_L1 = hp.HParam('lambda_L1', hp.IntInterval(0, 200))

""""""""Preparations for HP tuning""""""
train_writer = tf.summary.create_file_writer(opt.log_dir) 
with train_writer.as_default():
    hp.hparams_config(
        hparams=[HP_LAMBDA_L1],
        metrics=[hp.Metric('accuracy', display_name='Accuracy')],  # TODO
    )

""""""For each run, log an hparams summary with the hyperparameters and final accuracy:""""""
def run(run_dir, hparams):
    with tf.summary.create_file_writer(run_dir).as_default():
        hp.hparams(hparams)  # record the values used in this trial
        mse_accuracy = train_model(hparams)
        tf.summary.scalar('accuracy', mse_accuracy, step=1)

run_num = 0
for lambda_L1 in np.linspace(HP_LAMBDA_L1.domain.min_value,
                                 HP_LAMBDA_L1.domain.max_value, 5,):
    hparams = {
        HP_LAMBDA_L1: lambda_L1
    }
    run_name = ""run-%d"" % run_num
    print('--- Starting trial: %s' % run_name)
    print({h.name: hparams[h] for h in hparams})
    run('logs/test_lambdaL1/' + run_name, hparams)
    run_num += 1
```
The `train_model()  ` is in Pytorch. I'm using `!pip install -q tensorflow==2.0.0-alpha0 ` in Google colab wich hasn't given me any trubles before. 

The error I've got: 

`Traceback (most recent call last):
  File ""/content/drive/My Drive/Colab Notebooks/pix2pix_HPtuning/train_tb_HPtuning.py"", line 69, in <module>
    metrics=[hp.Metric('accuracy', display_name='Accuracy')],  # TODO
  File ""/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/hparams/summary_v2.py"", line 135, in hparams_config
    time_created_secs=time_created_secs,
  File ""/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/hparams/summary_v2.py"", line 177, in hparams_config_pb
    plugin_data_pb2.HParamsPluginData(experiment=experiment),
  File ""/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/hparams/summary_v2.py"", line 250, in _summary_pb
    summary.value.add(tag=tag, metadata=summary_metadata)
TypeError: Parameter to MergeFrom() must be instance of same class: expected tensorboard.SummaryMetadata got tensorflow.SummaryMetadata.`

Does anyone know how to solve the issue?
"
34189,ValueError: Unknown layer: DenseFeatures for tensorflow2.0,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Mac
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):N
- TensorFlow version (use command below):2.0.0(stable)
- Python version:3.7.3
- Bazel version (if compiling from source):Y/N
- GCC/Compiler version (if compiling from source):Y/N
- CUDA/cuDNN version:N
- GPU model and memory:N

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
loading a saved .h5 model which includes a DenseFeatures Layer fails:
ValueError: Unknown layer: DenseFeatures

**Describe the expected behavior**
model is loading, and i can use the pre_trained model for online service

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
import pandas as pd

# pip install -q tensorflow==2.0.0-alpha0
import tensorflow as tf
from tensorflow import feature_column
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split

URL = 'https://storage.googleapis.com/applied-dl/heart.csv'
dataframe = pd.read_csv(URL)
train, test = train_test_split(dataframe, test_size=0.2)
train, val = train_test_split(train, test_size=0.2)

# A utility method to create a tf.data dataset from a Pandas Dataframe
def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  labels = dataframe.pop('target')
  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  return ds

feature_columns = []

# numeric cols
for header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']:
  feature_columns.append(feature_column.numeric_column(header))

feature_layer = tf.keras.layers.DenseFeatures(feature_columns)

batch_size = 32
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)

model = tf.keras.Sequential([
  feature_layer,
  layers.Dense(128, activation='relu'),
  layers.Dense(128, activation='relu'),
  layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy')

model.fit(train_ds, 
          validation_data=val_ds, 
          epochs=5)


model.save('my_model.h5')
from tensorflow import keras
new_model = keras.models.load_model('my_model.h5')



**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

    ValueError: ('We expected a dictionary here. Instead we got: ', <tf.Tensor 'Placeholder:0' shape=(None,) dtype=float32>)

"
34188,TF2.0 GPU - Segmentation fault - Object Detection,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: Python 3.7.5
- CUDA/cuDNN version: 10.0.130/7.6.2
- GPU model and memory: GeForce 940MX / 2004MiB

**Describe the current behavior**
When I try to run [this](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) example, a segmentation fault happens during inference. I just formatted my Ubuntu 18.04 and did a clean install.

**Describe the expected behavior**
The images marked with the boxes.

**Code to reproduce the issue**
```
...
# Run inference
  output_dict = model(input_tensor)
...
```

**Other info / logs**
```
2019-11-12 04:53:51.925933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-12 04:53:51.935688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-12 04:53:51.935937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 1.189
pciBusID: 0000:01:00.0
2019-11-12 04:53:51.936117: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-12 04:53:51.937181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-12 04:53:51.938180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-12 04:53:51.938498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-12 04:53:51.939671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-12 04:53:51.940624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-12 04:53:51.943488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-12 04:53:51.943615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-12 04:53:51.944225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-12 04:53:51.944738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-12 04:53:53.716082: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-12 04:53:53.741945: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz
2019-11-12 04:53:53.742225: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe34207b30 executing computations on platform Host. Devices:
2019-11-12 04:53:53.742249: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-12 04:53:53.792897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-12 04:53:53.793392: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe33fa3880 executing computations on platform CUDA. Devices:
2019-11-12 04:53:53.793424: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce 940MX, Compute Capability 5.0
2019-11-12 04:53:53.793636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-12 04:53:53.794038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 1.189
pciBusID: 0000:01:00.0
2019-11-12 04:53:53.794108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-12 04:53:53.794141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-12 04:53:53.794163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-12 04:53:53.794182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-12 04:53:53.794203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-12 04:53:53.794224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-12 04:53:53.794245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-12 04:53:53.794346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-12 04:53:53.794887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-12 04:53:53.795348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-12 04:53:53.795437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-12 04:53:53.796297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-12 04:53:53.796327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-12 04:53:53.796337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-12 04:53:53.796644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-12 04:53:53.796975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-12 04:53:53.797255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1306 MB memory) -> physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)
2019-11-12 04:54:11.319157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-12 04:54:12.995202: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-12 04:54:13.169311: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-12 04:54:13.328776: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-12 04:54:13.366495: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
2019-11-12 04:54:13.786988: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-11-12 04:54:13.848769: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Segmentation fault (core dumped)
```"
34187,SparseCategoricalAccuracy() & InvalidArgumentError,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Win10**
- TensorFlow version (use command below): **2.0.0**
- Python version: **3.7.5**

When I try to run the following code, an error occurs,
```python
import numpy as np
import tensorflow as tf
class MNISTLoader():
    def __init__(self):
        mnist = tf.keras.datasets.mnist
        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()
        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)
        self.test_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)
        self.train_label = self.train_label.astype(np.int32)
        self.test_label = self.test_label.astype(np.int32)
        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]
    
    def get_batch(self, batch_size):
        index = np.random.randint(0, np.shape(self.train_data)[0], batch_size)
        return self.train_data[index, :], self.train_label[index]

class MLP(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.flatten = tf.keras.layers.Flatten()
        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)
        self.dense2 = tf.keras.layers.Dense(units=10)
        
    def call(self, inputs):
        x = self.flatten(inputs)
        x = self.dense1(x)
        x = self.dense2(x)
        output = tf.nn.softmax(x)
        return output

num_epochs = 5
batch_size = 50
learning_rate = 0.001
model = MLP()
data_loader = MNISTLoader()
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

num_batches = int(data_loader.num_train_data // batch_size * num_epochs)
for batch_index in range(num_batches):
    X, y = data_loader.get_batch(batch_size)
    with tf.GradientTape() as tape:
        y_pred = model(X)
        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)
        loss = tf.reduce_mean(loss)
        print(""batch %d: loss %f"" % (batch_index, loss.numpy()))
    grads = tape.gradient(loss, model.variables)
    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))

sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()
num_batches = int(data_loader.num_test_data // batch_size)
for batch_index in range(num_batches):
    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size
    y_pred = model.predict(data_loader.test_data[start_index: end_index])
    y_true = data_loader.test_label[start_index: end_index]
    #y_true = y_true.reshape(-1,1)
    sparse_categorical_accuracy.update_state(y_true=y_true, y_pred=y_pred)
    if batch_index == 1:
        print(""y_pred"", y_pred.shape)
        print(y_pred)
        print(""y_true"", y_true.shape)
        print(y_true)
print(""test accuracy: %f"" % sparse_categorical_accuracy.result())

```
**Describe the current behavior**  

The information is as follows:  
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-15-e321ee460d57> in <module>
      6     y_true = data_loader.test_label[start_index: end_index]
      7     #y_true = y_true.reshape(-1,1)
----> 8     sparse_categorical_accuracy.update_state(y_true=y_true, y_pred=y_pred)
      9 
     10     if batch_index == 1:

D:\software\Anaconda3\envs\tensorflow2.0\lib\site-packages\tensorflow_core\python\keras\utils\metrics_utils.py in decorated(metric_obj, *args, **kwargs)
     73 
     74     with tf_utils.graph_context_for_symbolic_tensors(*args, **kwargs):
---> 75       update_op = update_state_fn(*args, **kwargs)
     76     if update_op is not None:  # update_op will be None in eager execution.
     77       metric_obj.add_update(update_op)

D:\software\Anaconda3\envs\tensorflow2.0\lib\site-packages\tensorflow_core\python\keras\metrics.py in update_state(self, y_true, y_pred, sample_weight)
    579         y_pred, y_true)
    580 
--> 581     matches = self._fn(y_true, y_pred, **self._fn_kwargs)
    582     return super(MeanMetricWrapper, self).update_state(
    583         matches, sample_weight=sample_weight)

D:\software\Anaconda3\envs\tensorflow2.0\lib\site-packages\tensorflow_core\python\keras\metrics.py in sparse_categorical_accuracy(y_true, y_pred)
   2784     y_pred = math_ops.cast(y_pred, K.dtype(y_true))
   2785 
-> 2786   return math_ops.cast(math_ops.equal(y_true, y_pred), K.floatx())
   2787 
   2788 

D:\software\Anaconda3\envs\tensorflow2.0\lib\site-packages\tensorflow_core\python\util\dispatch.py in wrapper(*args, **kwargs)
    178     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    179     try:
--> 180       return target(*args, **kwargs)
    181     except (TypeError, ValueError):
    182       # Note: convert_to_eager_tensor currently raises a ValueError, not a

D:\software\Anaconda3\envs\tensorflow2.0\lib\site-packages\tensorflow_core\python\ops\math_ops.py in equal(x, y, name)
   1304     A `Tensor` of type bool with the same size as that of x or y.
   1305   """"""
-> 1306   return gen_math_ops.equal(x, y, name=name)
   1307 
   1308 

D:\software\Anaconda3\envs\tensorflow2.0\lib\site-packages\tensorflow_core\python\ops\gen_math_ops.py in equal(x, y, incompatible_shape_error, name)
   3617       else:
   3618         message = e.message
-> 3619       _six.raise_from(_core._status_to_exception(e.code, message), None)
   3620   # Add nodes to the TensorFlow graph.
   3621   if incompatible_shape_error is None:

D:\software\Anaconda3\envs\tensorflow2.0\lib\site-packages\six.py in raise_from(value, from_value)

InvalidArgumentError: Incompatible shapes: [0] vs. [50] [Op:Equal]
I don't know why this happens. I have checked the API and tried to reshape the `y_true`, it doesn't work either.
"
34186,How to use golang to implement python's tf.train.Example().serializetostring.,"I'm trying to  using the python training model, deploy services with golang. However, the following problems arise when using golang for prediction.

predict with python:
```
    def predict_np(self):
        predict_fn = self.get_predict_fn(self.np_path)
        inputs = np.array([[6.4, 3.2, 4.5, 1.5], [6.4, 3.2, 4.5, 1.5]])
        for item in inputs:
            examples = []
            feature = {""your_input"": tf.train.Feature(float_list=tf.train.FloatList(value=item))}
            example = tf.train.Example(features=tf.train.Features(feature=feature))
            examples.append(example.SerializeToString())
            print(type(example.SerializeToString()))
            predictions = predict_fn({""inputs"": examples})
            print(predictions)
```
it works ok.

predict with golang
```
package main

import (
	""fmt""
	tg ""github.com/galeone/tfgo""
	""github.com/gogo/protobuf/proto""
	tf ""github.com/tensorflow/tensorflow/tensorflow/go""
	""github.com/tensorflow/tensorflow/tensorflow/go/core/example""
	""loadEstimator/train""
)

func main() {
	data := [][]float32{{6.4, 3.2, 4.5, 1.5}, {6.4, 3.2, 4.5, 1.5}}
	columnsName := []string{""a"", ""b"", ""c"", ""d""}
	for _, item := range data {
		// npData:numpy data like in python {""inputs"":[6.4,3.2,4.5,1.5]}
		npData := make(map[string][]float32)
		npData[""your_input""] = item
		predictNP(npData)
	}

}

func loadModeSavedPB(path string) (model *tg.Model) {
	model = tg.LoadModel(path, []string{""serve""}, nil)
	return
}

func predictNP(data map[string][]float32) {
	pdModePath := ""./static/1""
	model := loadModeSavedPB(pdModePath)
	sequence := sequenceNP(data)
	fmt.Println(sequence)
	fakeInput, _ := tf.NewTensor([]string{sequence})
	results := model.Exec([]tf.Output{
		model.Op(""dnn/head/Tile"", 0),
	}, map[tf.Output]*tf.Tensor{
		model.Op(""input_example_tensor"", 0): fakeInput,
	})
	predictions := results[0].Value().([][]float32)
	fmt.Println(predictions)
}

func sequenceNP(featureInfo map[string][]float32) (seq string) {
	feature := make(map[string]*example.Feature)
	for k, v := range featureInfo {
		valFormat := train.Float32ToFeature(v)
		feature[k] = valFormat
	}
	Features := example.Features{Feature: feature}
	myExample := example.Example{Features: &Features}
	seq = proto.MarshalTextString(&myExample)
	return
}

```


```
package train

import ""github.com/tensorflow/tensorflow/tensorflow/go/core/example""
func Float32ToFeature(value []float32) (exampleFeature *example.Feature) {
	floatList := example.FloatList{Value: value}
	featureFloatList := example.Feature_FloatList{FloatList: &floatList}
	exampleFeature = &example.Feature{Kind: &featureFloatList}
	return
}
```

There is an error
```
2019-11-12 11:42:05.021196: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at example_parsing_ops.cc:144 : Invalid argument: Could not parse example input, value: 'features: <
  feature: <
    key: ""your_input""
    value: <
      float_list: <
        value: 6.4
        value: 3.2
        value: 4.5
        value: 1.5
      >
    >
  >
>
'
panic: Could not parse example input, value: 'features: <
  feature: <
    key: ""your_input""
    value: <
      float_list: <
        value: 6.4
        value: 3.2
        value: 4.5
        value: 1.5
      >
    >
  >
>
'
	 [[{{node ParseExample/ParseExample}}]]
```

i'm using `proto.MarshalTextString(&myExample)`  in golang,and using 
`
example = tf.train.Example(features=tf.train.Features(feature=feature))
examples.append(example.SerializeToString())
`
in python.
I am not sure whether serialization in these two languages is equivalent, and if not, how can I implement `SerializeToString` in golang? pls
"
34185,TF-TRT optimized graph get wrong results when using batch size <=7,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.2
- GPU model and memory:Tesla T4 with 15001MiB memory

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When using TF-TRT optimized graph to do inference, it only works as expected when batch size >=7(I tested batch size from 1-16). And the result is completely wrong when batch size <7
**Describe the expected behavior**
Small batch size should also give me the correct result since my original un-optimized graph can handle small batch size.
**Code to reproduce the issue**
Setup according to  https://github.com/tensorflow/tensorrt/tree/master/tftrt/examples/object_detection:
```
# in path/to/tftrt/examples/object_detection/
import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt
import cv2
from collections import namedtuple
from PIL import Image
import numpy as np
import time
import json
import subprocess
import os
import glob
from tftrt.examples.object_detection.graph_utils import force_nms_cpu as f_force_nms_cpu
from tftrt.examples.object_detection.graph_utils import replace_relu6 as f_replace_relu6
from tftrt.examples.object_detection.graph_utils import remove_assert as f_remove_assert

def optimize_model(frozen_graph,
                   use_trt=True,
                   force_nms_cpu=True,
                   replace_relu6=True,
                   remove_assert=True,
                   precision_mode='FP32',
                   minimum_segment_size=2,
                   max_workspace_size_bytes=1 << 32,
                   maximum_cached_engines=100,
                   calib_images_dir=None,
                   num_calib_images=None,
                   calib_batch_size=1,
                   calib_image_shape=None,
                   output_path=None):
    #same function copied from  path/to/tftrt/examples/object_detection/object_detection.py#L328
    pass
# optimized a customed frozen graph
frozen_graph_path = 'path/to/frozen_graph.pb'
frozen_graph = tf.GraphDef()
with open(frozen_graph_path, 'rb') as f:
    frozen_graph.ParseFromString(f.read())
frozen_graph = optimize_model(
    frozen_graph,
    force_nms_cpu=False,
    replace_relu6=True,
    remove_assert=True,
    use_trt=True,
    precision_mode=""FP16"",
    max_workspace_size_bytes=17179869184,
    output_path='./trt_frozen_graph.pb'
)

# run inference
frozen_graph_path = './trt_frozen_graph.pb'
frozen_graph = tf.GraphDef()
with open(frozen_graph_path, 'rb') as f:
    frozen_graph.ParseFromString(f.read())

# images = [bs, h, w, 3]
INPUT_NAME = 'input'
BOXES_NAME = 'output/boxes'
CLASSES_NAME = 'output/labels'
SCORES_NAME = 'output/scores'
NUM_DETECTIONS_NAME = 'output/num_detections'
with tf.Graph().as_default() as tf_graph:
    with tf.Session(config=tf_config) as tf_sess:
        tf.import_graph_def(frozen_graph, name='')
        tf_input = tf_graph.get_tensor_by_name(INPUT_NAME + ':0')
        tf_boxes = tf_graph.get_tensor_by_name(BOXES_NAME + ':0')
        tf_classes = tf_graph.get_tensor_by_name(CLASSES_NAME + ':0')
        tf_scores = tf_graph.get_tensor_by_name(SCORES_NAME + ':0')
        tf_num_detections = tf_graph.get_tensor_by_name(
            NUM_DETECTIONS_NAME + ':0')
        boxes, classes, scores, num_detections = tf_sess.run(
                    [tf_boxes, tf_classes, tf_scores, tf_num_detections],
                    feed_dict={tf_input: batch_images})
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
My frozen graph can be download at https://drive.google.com/open?id=1s_laMhRw8GC6I9brQjn6apKTfhWe734J
```
WARNING:tensorflow:From /notebooks/tensorrt/tftrt/examples/object_detection/graph_utils.py:31: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.
WARNING:tensorflow:From /notebooks/tensorrt/tftrt/examples/object_detection/graph_utils.py:31: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

INFO:tensorflow:Linked TensorRT version: (6, 0, 1)
INFO:tensorflow:Loaded TensorRT version: (6, 0, 1)
INFO:tensorflow:Running against TensorRT version 6.0.1
graph_size(MB)(native_tf): 54.5
graph_size(MB)(trt): 106.0
num_nodes(native_tf): 10992
num_nodes(tftrt_total): 10156
num_nodes(trt_only): 290
time(s) (trt_conversion): 15.8726
```
"
34184,How to apply feature extraction in tensorflow (not use tf.keras),"I want to apply feature extraction with pre-trained model (VGG16) by removing the last layer and replacing other FC layer (less classes).
I don't want to use tf.keras. How to deal it?
Help me!
Thanks a lot!"
34183,How to add custom ops to Tensorflow Lite Swift/ObjC ? ,"I can't find any straight forwards docs on how to add a custom op to tensorflow lite, swift/objc. I see the docs for adding to the c++ lib, but it seems unclear how to add them to the swift pods? 

Does anyone have any pointers? "
34182,Can't load optimizer weights after adding layer without parameters,"**MODEL A**:
```python
ipt = Input(batch_shape=(32, 240, 4))
x1  = Conv1D(16, 20,  strides=200, padding='same')(ipt)
x1  = BatchNormalization()(x1)
x2  = Conv1D(16, 200, strides=120, padding='same')(ipt)
x2  = BatchNormalization()(x2) # ...
```
**MODEL B**:
```python
ipt = Input(batch_shape=(32, 250, 4))
x1  = Conv1D(16, 20,  strides=200)(ipt)
x1  = BatchNormalization()(x1)
x2  = Conv1D(16, 200, strides=120)(ipt)
x2  = BatchNormalization()(x2) # ...
```
<hr>
The two have identical weight shapes - however, A's optimizer `weights` _cannot_ be loaded onto B, as B has a different build order (images & code below). 

This is a tiny snippet of a much larger model which needs its `timesteps` parameter changed every X epochs, and `ZeroPadding1D` appears to _change layer build order_ whenever it's used; this doesn't affect _model_ weights, as they're mapped via a dictionary - whereas optimizer weights are mapped sequentially, list-to-list.

Reproducible in both TF1 & TF2, and w/ `keras` & `tf.keras` imports. What's the problem, and how to fix? [Relevant SO](https://stackoverflow.com/questions/58811292/why-does-zeropadding-change-optimizer-weights-order)


<hr>

**Environment**: Win-10 OS, CUDA 10.0.130, cuDNN 7.6.0, Python 3.7.4, GTX 1070

**Observations**:

 - Swaps any other layer, not just `BatchNormalization` - and any _number of layers_ before `concatenate`; optimizer weights end up being simply swapped in `.get_weights()`
 - Can change `strides` instead of `batch_shape[1]`
 - Can use `MaxPooling1D` w/ `strides > 1`
 - `padding='valid'` leads to `ZeroPadding1D`, but it _doesn't_ change build order (don't know why)


<hr>

**`model_A.summary()`**:

```python
Layer (type)                    Output Shape         Param #     Connected to     
==================================================================================
input_1 (InputLayer)            [(32, 240, 4)]       0                            
__________________________________________________________________________________
conv1d (Conv1D)                 (32, 2, 16)          1296        input_1[0][0]    
__________________________________________________________________________________
conv1d_1 (Conv1D)               (32, 2, 16)          12816       input_1[0][0]    
__________________________________________________________________________________
bn_1 (BatchNormalization)       (32, 2, 16)          64          conv1d[0][0]     
__________________________________________________________________________________
bn_2 (BatchNormalization)       (32, 2, 16)          64          conv1d_1[0][0]   
__________________________________________________________________________________
concatenate (Concatenate)       (32, 2, 32)          0           bn_1[0][0]       
                                                                 bn_2[0][0]       
__________________________________________________________________________________
gap_0 (GlobalAveragePooling1D)  (32, 32)             0           concatenate[0][0]
__________________________________________________________________________________
dense (Dense)                   (32, 1)              33          gap_0[0][0]      
```

**`model_B.summary()`** _(note the swapped layers)_

```python
input_2 (InputLayer)            [(32, 250, 4)]       0                               
_____________________________________________________________________________________
conv1d_2 (Conv1D)               (32, 2, 16)          1296        input_2[0][0]       
_____________________________________________________________________________________
bn_1 (BatchNormalization)       (32, 2, 16)          64          conv1d_2[0][0]      
_____________________________________________________________________________________
conv1d_3 (Conv1D)               (32, 3, 16)          12816       input_2[0][0]       
_____________________________________________________________________________________
zero_padding1d (ZeroPadding1D)  (32, 3, 16)          0           bn_1[0][0]          
_____________________________________________________________________________________
bn_2 (BatchNormalization)       (32, 3, 16)          64          conv1d_3[0][0]      
_____________________________________________________________________________________
concatenate_1 (Concatenate)     (32, 3, 32)          0           zero_padding1d[0][0]
                                                                 bn_2[0][0]          
_____________________________________________________________________________________
gap_0 (GlobalAveragePooling1D)  (32, 32)             0           concatenate_1[0][0] 
_____________________________________________________________________________________
dense_1 (Dense)                 (32, 1)              33          gap_0[0][0]  
```

<hr>

**Minimally reproducible code**:

```python
# also works with `from keras`
from tensorflow.keras.layers import Input, Conv1D, ZeroPadding1D, concatenate
from tensorflow.keras.layers import BatchNormalization, Dense, GlobalAveragePooling1D
from tensorflow.keras.models import Model
import numpy as np

def make_model(batch_shape):
    ipt = Input(batch_shape=batch_shape)

    x1  = Conv1D(16, 20,  strides=200, padding='same')(ipt)
    x1  = BatchNormalization()(x1)
    x2  = Conv1D(16, 200, strides=120, padding='same')(ipt)
    x2  = BatchNormalization()(x2)

    x1, x2 = zero_pad(x1, x2)
    preout = concatenate([x1, x2])
    preout = GlobalAveragePooling1D()(preout)
    out    = Dense(1)(preout)

    model  = Model(ipt, out)
    model.compile('adam', 'mse')
    return model 

def zero_pad(x1, x2):
    diff = int(x2.shape[1]) - int(x1.shape[1])
    if   diff > 0:
        x1 = ZeroPadding1D((diff, 0))(x1)
    elif diff < 0:
        x2 = ZeroPadding1D((abs(diff), 0))(x2)
    return x1, x2
    
def make_data(batch_shape):
    return (np.random.randn(*batch_shape), 
            np.random.randint(0, 2, (batch_shape[0], 1)))

batch_shape_A = (32, 240, 4)
batch_shape_B = (32, 250, 4)
batch_shape_C = (32, 240, 4)
model_A  = make_model(batch_shape_A)
model_B  = make_model(batch_shape_B)
model_C  = make_model(batch_shape_C) # 'control group'
x_A, y_A = make_data(batch_shape_A)
x_B, y_B = make_data(batch_shape_B)
x_C, y_C = make_data(batch_shape_C)

model_A.train_on_batch(x_A, y_A)
model_B.train_on_batch(x_B, y_B)
model_C.train_on_batch(x_C, y_C)

optimizer_weights_A = model_A.optimizer.get_weights()

model_C.optimizer.set_weights(optimizer_weights_A)
print(""model_C optimizer weights set successfully"")

model_B.optimizer.set_weights(optimizer_weights_A)
print(""model_B optimizer weights set successfully"") # will not print
```
**Output**:
```python
model_C optimizer weights set successfully

ValueError: Optimizer weight shape (16,) not compatible with provided 
weight shape (200, 4, 16)
```"
34181,"transformer model for mobile crashes in iPhone XS, XR and 11 series","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): iOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone XS, XR, iPhone 11 series
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.5.1
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.5.4
- GCC/Compiler version (if compiling from source): 4.8.5 20150623
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I have transformer model trained with tensorflow==1.5.1. Frozen graph is optimized and further quantized for mobile usage. Together with quantized model, I have tensorflow==1.5.1 library built for ios via `./tensorflow/contrib/makefile/build_all_ios.sh`. 

Models from iPhone 6 up to 9 all works fine, but iPhone XS, XR and beyond crashes during inference (inference is equivalent to running `m_pSession->Run`) . When running the model N times, it randomly emits error as below : 

```
# ./tensorflow/core/framework/function.cc:855
Invalid argument: Retval[0] does not have value

# this function is called from : 
./tensorflow/core/common_runtime/direct_session.cc:630
```

**Describe the expected behavior**
inference should not crash, as it does not in other iOS devices

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
// Initialize a session
Status status = NewSession(SessionOptions(), &m_pSession);
    
// Read binary proto file
GraphDef graph_def;
status = ReadBinaryProto(Env::Default(), model_file_path, &graph_def);

// Create session
status = m_pSession->Create(graph_def);

// Setup inputs and outputs
string input_op_name = TENSORFLOW_INPUT_OP;
string input_length_op_name = TENSORFLOW_INPUT_LENGTH_OP;
Tensor input_tensor(DT_INT32, TensorShape({1, inputWordCnt}));
Tensor input_length_tensor(DT_INT32, TensorShape({1}));

// inputWordArray is a vector with source words to translate
auto input_tensor_mapped = input_tensor.tensor<int, 2>();
for(int i=0; i<inputWordCnt; i++) {
    input_tensor_mapped(0, i) = inputWordArray[i];
}
auto input_length_tensor_mapped = input_length_tensor.tensor<int, 1>();
input_length_tensor_mapped(0) = inputWordCnt;

std::vector<Tensor> output_tensors;

// Do Translate!
Status run_status = m_pSession->Run({{input_op_name, input_tensor},
                                     {input_length_op_name, input_length_tensor}},
                                     {TENSORFLOW_ONEBEST_OUTPUT_OP, TENSORFLOW_ATTENTION_MAP_OUTPUT_OP},
                                     {},
                                     &output_tensors);
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I intentionally added `std::cout` to track the value of `rets_`, and as you can see from the below, `rets_.[i]has_val` suddenly has value 0 in random chance.

```
[tensorflow | function.cc] rets_.size() = 2
[tensorflow | function.cc] i = 0
[tensorflow | function.cc] rets = 0x170a01c40
[tensorflow | function.cc] rets.size() = 0
[tensorflow | function.cc] rets_.[i]has_val = 1
[tensorflow | function.cc] rets_[i].val) = Tensor<type: int32 shape: [1,53] values: [0 1 14]...>
[tensorflow | function.cc] i = 1
[tensorflow | function.cc] rets = 0x170a01c40
[tensorflow | function.cc] rets.size() = 1
[tensorflow | function.cc] rets_.[i]has_val = 1
[tensorflow | function.cc] rets_[i].val) = Tensor<type: int32 shape: [1,53] values: [1 15939 0]...>

[tensorflow | function.cc] rets_.size() = 2
[tensorflow | function.cc] i = 0
[tensorflow | function.cc] rets = 0x170029c40
[tensorflow | function.cc] rets.size() = 0
[tensorflow | function.cc] rets_.[i]has_val = 0
[tensorflow | function.cc] rets_[i].val) = Tensor<type: float shape: [0] values: >
[tensorflow_inference.cpp] Running model failed: Invalid argument: Retval[0] does not have value
```

Error occurs due to accessing a missing value, which should not be missing in the first place.
Is iPhone XS/XR interrupting the memory values of tensorflow ops?"
34178,Bug with tf.function and complex variables,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): installed from conda using `conda install tensorflow==2.0`
- TensorFlow version (use command below): 2.0.0
- Python version: Python 3.6.0 :: Continuum Analytics, Inc.
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: using CPU only
- GPU model and memory: using CPU only

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When running following code:
```
import tensorflow as tf
import numpy as np

@tf.function
def fn():
    some_variable = tf.cast(1.0, tf.complex64)
    T = 1j * np.eye(8, dtype=np.complex64)
    return tf.convert_to_tensor(T)

fn().numpy()
```
I got incorrect output:
```
array([[0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
       [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
       [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
       [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
       [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
       [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
       [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
       [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j]],
      dtype=complex64)
```

I have installed fresh conda enviroment with python 3.6 and tensorflow 2.0.0. GPU 
is disabled with ` export CUDA_VISIBLE_DEVICES=""-1""`

**Describe the expected behavior**

The output should be following:
```
array([[0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],
       [0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],
       [0.+0.j, 0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],
       [0.+0.j, 0.+0.j, 0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],
       [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j],
       [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j],
       [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+1.j, 0.+0.j],
       [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+1.j]],
      dtype=complex64)
```

I got correct output for following versions of the function:
```
@tf.function
def fn():
    T = 1j * np.eye(8, dtype=np.complex64)
    return tf.convert_to_tensor(T)
```
and (when tf.function is removed)
```
def fn():
    some_variable = tf.cast(1.0, tf.complex64)
    T = 1j * np.eye(8, dtype=np.complex64)
    return tf.convert_to_tensor(T)
```
and when I use small value for np.eye
```
@tf.function
def fn():
    some_variable = tf.cast(1.0, tf.complex64)
    T = 1j * np.eye(7, dtype=np.complex64)
    return tf.convert_to_tensor(T)
```

Can you reproduce my error ? 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

As above. 

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

The fragment of the output of `conda list` command:
```
tensorflow                2.0.0           gpu_py36h6b29c10_0  
tensorflow-addons         0.5.0                     <pip>
tensorflow-base           2.0.0           gpu_py36h0ec5d1f_0  
tensorflow-estimator      2.0.0              pyh2649769_0  
tensorflow-probability    0.8.0                     <pip>
```
"
34176,tf.Identity messes determinism (initialization order changed?),"### System information
- **OS Platform and Distribution** : Linux Ubuntu 16.04.6 
- **TensorFlow installed from** : PIP (binary)
- **TensorFlow version**: tensorflow-gpu==1.14.0
- **Python version**: 2.7.12
- **GPU model and memory**: No relevant : the issue occurs both on GPU and CPU
- **Exact command to reproduce**: `python test_script.py` (test_script is provided in the source code section below)

### Describe the problem
I am expecting the function below to be deterministic no matter the value of the `use_identity_op` parameter, though it is not :  
```python
def my_graph(use_identity_op) :
   """"""Dummy function for testing
   
   :param use_identity_op: whether to apply the identity operator to the 
   a variable or not
   :type use_identity_op: bool
   :return: a dummy vector
   :rtype: list(float)
   """"""
   tf.compat.v1.reset_default_graph()
   tf.compat.v1.set_random_seed(32)
   a = tf.compat.v1.get_variable('my_a', [5], initializer=None)
   if use_identity_op : 
        a = tf.identity(a)
   b = tf.compat.v1.get_variable('my_b', [5], initializer=None)
   c = a + b
   session = tf.compat.v1.Session()
   session.run(tf.compat.v1.global_variables_initializer())
   return session.run(c).tolist()
```

### Source code / logs
Here is the complete test_case (i.e `test_script.py`) : 
```python
import tensorflow as tf
import unittest

def my_graph(use_identity_op) :
   """"""Dummy function for testing
   
   :param use_identity_op: whether to apply the identity operator to the 
   a variable or not
   :type use_identity_op: bool
   :return: a dummy vector
   :rtype: list(float)
   """"""
   tf.compat.v1.reset_default_graph()
   tf.compat.v1.set_random_seed(32)
   a = tf.compat.v1.get_variable('my_a', [5], initializer=None)
   if use_identity_op : 
        a = tf.identity(a)
   b = tf.compat.v1.get_variable('my_b', [5], initializer=None)
   c = a + b
   session = tf.compat.v1.Session()
   session.run(tf.compat.v1.global_variables_initializer())
   return session.run(c).tolist()

class TestTFIdentity(unittest.TestCase): 
   def test_my_graph_is_deterministic_CPU(self):
      
      with tf.device('/device:CPU:0'):
         #The 3 calls below should be equivalent.

         run1 = my_graph(use_identity_op=False)
         run2 = my_graph(use_identity_op=False)
         self.assertEqual(run1, run2)
         
         run3 = my_graph(use_identity_op=True)
         #This fails though I feel it shouldn't 
         self.assertEqual(run1, run3)

if __name__ == '__main__':
    unittest.main()
```

And here is the result log : 
```bash
======================================================================
FAIL: test_my_graph_is_deterministic_GPU (__main__.TestTFIdentity)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""test_TF.py"", line 36, in test_my_graph_is_deterministic_CPU
    self.assertEqual(run1, run3)
AssertionError: Lists differ: [-0.948743462562561, -0.324153... != [-0.10568153858184814, 0.36630...

First differing element 0:
-0.948743462562561
-0.10568153858184814

- [-0.948743462562561,
-  -0.324153870344162,
-  -0.7790395617485046,
-  -1.0308094024658203,
-  1.3954466581344604]
+ [-0.10568153858184814,
+  0.36630767583847046,
+  -1.0092220306396484,
+  -0.11402678489685059,
+  0.6194109916687012]

----------------------------------------------------------------------
Ran 1 test in 0.699s
```
"
34174,Performance regression with obj. det model from 1.14 to 1.15,"2.7x slowdown on a nearly-off-the-shelf tensorflow object detection API model (differences and pipeline config below) when going from 1.14 to 1.15.  The regression is _not_ present in 2.0.

This is a fine-tuned SSD mobilenets FPN coco config, with the only changes being:

Fixed size input of 1024x1024
Single class detection
 model draws from layers 2-5 instead of 3-6 and so is a fair bit larger than one might otherwise expect.

I've attached my pipeline.config to reproduce the bug.

I'm just running natively in TF with my own inference pipeline, doing the obvious feed_dict to get data in:

```
            out = sess.run(
                [
                    sess.graph.get_tensor_by_name(node) for node in [
                        'num_detections:0', 'detection_scores:0',
                        'detection_boxes:0', 'detection_classes:0'
                    ]
                ],
                feed_dict={'image_tensor:0': img_batch})
```
[pipeline.config.txt](https://github.com/tensorflow/tensorflow/files/3833314/pipeline.config.txt)

**System information**
Running on Ubuntu 18.04, Xeon, Titan V GPU, 12GB

Comparing between TF 1.14-GPU and 1.15 with conda/pip.
```
python 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)
[GCC 7.3.0] on linux
```

CUDA 10.0
CuDNN 7.6

**Describe the current behavior**

2.7x slower in 1.15. :-)

**Describe the expected behavior**

**Code to reproduce the issue**

See attached pipeline.config (would need to specify some training/testing tfrecord)


**Other info / logs**
This issue is related to an issue on tensorflow/serving:  https://github.com/tensorflow/serving/issues/1469

"
34171,Bug in LSTMBlockCellBpropWithCUDA when using peephole connections,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

- TensorFlow installed from (source or binary):
Source
- TensorFlow version (use command below):
r2.0
- Python version:
3.6.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
9.0/7.4
- GPU model and memory:
Quadro M2200

**Describe the current behavior**
In the backward propagation of the LSTM GPU code, there's a [broadcast operation included in the gradient computation](https://github.com/tensorflow/tensorflow/blob/722b96b22926dbc05881c35cb63fd342c6843112/tensorflow/core/kernels/rnn/lstm_ops_gpu.cu.cc#L398) of `cs_prev_grad` involving `wci` and `wcf`
```c++
  if (use_peephole) {
    Eigen::array<Eigen::DenseIndex, 2> p_shape({1, cell_size});
    Eigen::array<Eigen::DenseIndex, 2> p_broadcast_shape({batch_size, 1});
    cs_prev_grad.device(d) =
        cs_prev_grad + di * wci.reshape(p_shape).broadcast(p_broadcast_shape) +
        df * wcf.reshape(p_shape).broadcast(p_broadcast_shape);
    wci_grad.device(d) = (di * cs_prev).sum(Eigen::array<int, 1>({0}));
    wcf_grad.device(d) = (df * cs_prev).sum(Eigen::array<int, 1>({0}));
    wco_grad.device(d) = (do_ * cs).sum(Eigen::array<int, 1>({0}));
  }
}
```
Just before this code, the [GPU kernel](https://github.com/tensorflow/tensorflow/blob/722b96b22926dbc05881c35cb63fd342c6843112/tensorflow/core/kernels/rnn/lstm_ops_gpu.cu.cc#L358) `lstm_gates_bprop` is launched which calculates the gradient of `cs_prev_grad` using `wcf` and `wci`

```c++
__global__ void lstm_gates_bprop(
    const T* cs_prev,  // [batch_size, cell_size]
    const T* h_prev,   // [batch_size, cell_size]
    const T* w,        // [input_size + cell_size, 4 * cell_size]
    const T* wci,      // [cell_size]
    const T* wcf,      // [cell_size]
    const T* wco,      // [cell_size]
    const T* b,        // [4 * cell_size]
    const T* i,        // [batch_size, cell_size]
    const T* cs,       // [batch_size, cell_size]
    const T* f,        // [batch_size, cell_size]
    const T* o,        // [batch_size, cell_size]
    const T* ci,       // [batch_size, cell_size]
    const T* co,       // [batch_size, cell_size]
    const T* cs_grad,  // [batch_size, cell_size]
    const T* h_grad,   // [batch_size, cell_size]
    T* do_,            // [batch_size, cell_size]
    T* dcs,            // [batch_size, cell_size]
    T* dci,            // [batch_size, cell_size]
    T* df,             // [batch_size, cell_size]
    T* di,             // [batch_size, cell_size]
    T* dgates,         // [input_size + cell_size, 4 * cell_size]
    T* cs_prev_grad,   // [batch_size, cell_size]
    const int batch_size, const int cell_size, const bool use_peephole) {
  const int batch_id = blockIdx.x * blockDim.x + threadIdx.x;
  const int act_id = blockIdx.y * blockDim.y + threadIdx.y;

  if (batch_id >= batch_size || act_id >= cell_size) return;

  const int gid = batch_id * cell_size * 4 + act_id;
  const int cid = batch_id * cell_size + act_id;

  // bunch of code

  dgates[gid + 0 * cell_size] = di_local;
  dgates[gate_c_offset(gate_layout, cell_size)] = dci_local;
  dgates[gate_f_offset(gate_layout, cell_size)] = df_local;
  dgates[gid + 3 * cell_size] = do_local;

  cs_prev_grad[cid] = dcs_local * f_local;
  if (use_peephole) {
    cs_prev_grad[cid] += di_local * wci[act_id] + df_local * wcf[act_id];
  }
```

**Describe the expected behavior**
Unless I misunderstand, the gradient when using peephole connections is incorrect. The peephole gradient should be taken into account _either_ in the GPU kernel _or_ by the eigen computation, but not both.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34169,unable to run hello_world on stm32f7 (tflite micro),"**System information**
- OS Platform and Distribution: Windows 10
- GCC/Compiler version (if compiling from source): arm-none-eabi-gcc.exe (GNU Tools for ARM Embedded Processors 6-2017-q2-update) 6.3.1 20170620 (release) [ARM/embedded-6-branch revision 249437]

**Describe the problem**
I successfully build the mbed.bin file and can transfer it to the STM devkit via ST-LINK V2. However, nothing shows up on D1 (rx pin of adafruit-ft232h-breakout) that is connected to pin PA2 (tx pin of devkit). 

In the profiles/develop.json, I am using the ""-std=gnu++14"" cxx flag for GCC_ARM. I am unable to compile using ""-std=c++11"" nor ""-std=c++14"".

I also don't have an lcd screen attached to the devkit.

Any idea why I'm not seeing any output?

Thanks.








"
34166,py_function documentation example gives error,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/py_function

## Description of issue (what needs changing):

### Clear description

The following is the code example on the documentation page does not execute:

```python
def log_huber(x, m):
  if tf.abs(x) <= m:
    return x**2
  else:
    return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))

x = tf.compat.v1.placeholder(tf.float32)
m = tf.compat.v1.placeholder(tf.float32)

y = tf.py_function(func=log_huber, inp=[x, m], Tout=tf.float32)
dy_dx = tf.gradients(y, x)[0]

with tf.compat.v1.Session() as sess:
  # The session executes `log_huber` eagerly. Given the feed values below,
  # it will take the first branch, so `y` evaluates to 1.0 and
  # `dy_dx` evaluates to 2.0.
  y, dy_dx = sess.run([y, dy_dx], feed_dict={x: 1.0, m: 2.0})
```

Running this code returns the following error:

```python
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-174-af2c7dfc03d9> in <module>()
      5         return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))
      6 
----> 7 x = tf.compat.v1.placeholder(tf.float32)
      8 m = tf.compat.v1.placeholder(tf.float32)
      9 

~/anaconda2/envs/berttf2/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py in placeholder(dtype, shape, name)
   2625   """"""
   2626   if context.executing_eagerly():
-> 2627     raise RuntimeError(""tf.placeholder() is not compatible with ""
   2628                        ""eager execution."")
   2629 

RuntimeError: tf.placeholder() is not compatible with eager execution.
```"
34165,tf.keras.backend.sqrt(tf.constant(-1.0)) is 0 which is misleading and tf.sqrt(tf.constant(-1.0)) is 'nan' which is the way it should be.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 1.15
- Python version: 3.7
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: No
- GPU model and memory: Run in CPU
**Describe the current behavior**
tf.keras.backend.sqrt(tf.constant(-1.0)) returns 0 as clip_by_value is being done in the source code (Which is highly misleading, as can be seen only in the source and not in the function document) whereas tf.sqrt(tf.constant(-1.0)) returns 'nan' which is the expected behavior of any sqrt function. This causes some bugs which are very difficult to track. 

**Describe the expected behavior**
Make sqrt functions return only the expected behavior and remove the clip_by_value.

**Code to reproduce the issue**
import tensorflow as tf
tf.enable_eager_execution()

tf.keras.backend.sqrt(tf.constant(-1.0)).numpy()
tf.sqrt(tf.constant(-1.0)).numpy()


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34163,Do not get performance improvement on tf.matmul when building with AVX2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- TensorFlow version (use command below): v1.14
- Python version: 3.6.5
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 8.3.1

**Describe the current behavior**
Run the benchmarking tests for `tf.matmul` operation under different TensorFlow packages: 
1. **the pip package v1.14 released by Tensorflow.** 
   This package is not compiled with AVX2 as indicated by this log info `tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA`
2. **built the TensorFlow package with AVX2 from source** using the command `bazel build -c opt --copt=-march=native //tensorflow/tools/pip_package:build_pip_package`.

However, there is no big performance difference between the above two packages:
1. tensorflow-v1.14-cpu
    8192 x 8192 matmul took: **1.54 sec, 713.30 G ops/sec**

2. build from source with AVX2
    8192 x 8192 matmul took: **1.60 sec, 687.73 G ops/sec**

**Describe the expected behavior**
The benchmark with the second package should be faster than the first one.

**Code to reproduce the issue**
Borrow the benchmark code from [here](https://stackoverflow.com/a/41810634/3471050).
```Python
import os
import sys
import tensorflow as tf
import time

n = 8192
dtype = tf.float32

matrix1 = tf.Variable(tf.ones((n, n), dtype=dtype))
matrix2 = tf.Variable(tf.ones((n, n), dtype=dtype))
product = tf.matmul(matrix1, matrix2)


# avoid optimizing away redundant nodes
config = tf.ConfigProto(graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)))
sess = tf.Session(config=config)

import os
import sys
import tensorflow as tf
import time

n = 8192
dtype = tf.float32

matrix1 = tf.Variable(tf.ones((n, n), dtype=dtype))
matrix2 = tf.Variable(tf.ones((n, n), dtype=dtype))
product = tf.matmul(matrix1, matrix2)


# avoid optimizing away redundant nodes
config = tf.ConfigProto(graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)))
sess = tf.Session(config=config)


sess.run(tf.global_variables_initializer())
iters = 10

# pre-warming
sess.run(product.op)

start = time.time()
for i in range(iters):
  sess.run(product.op)
end = time.time()
ops = n**3 + (n-1)*n**2 # n^2*(n-1) additions, n^3 multiplications
elapsed = (end - start)
rate = iters*ops/elapsed/10**9
print('\n %d x %d matmul took: %.2f sec, %.2f G ops/sec' % (n, n,
                                                            elapsed/iters,
                                                            rate,))
```
"
34159,"Unresolved external symbol, C++, Windows 7, TensorFlow 2.0","**System information**
- Have I written custom code: No
- OS Platform and Distribution: Windows 7 Enterprise
- TensorFlow installed from: Source
- TensorFlow version: 2.0
- Python version: 3.6.8
- Bazel version: 0.26.1
- GCC/Compiler version: VS2017 15.7.5
- GPU model and memory: Intel HD 530

[edit]
The build was based on commit 1cf0898dd4331baf93fe77205550f2c2e6c90ee5 from the r2.0 branch.
[/edit]

I tried to build the shared C++ library on Windows 7 for TensorFlow 2 with the recommended version of bazel and I was quite happy that it seems to be a lot more straightforward now (previously I was only able to build 1.6 with cmake).

However, the problem that now occurs when I try to use TensorFlow in a program. I have custom written code but for the time being I only tried to run a few simple examples.

This small program

```
#define NOMINMAX
#define COMPILER_MSVC
#include ""tensorflow/core/platform/logging.h""

int main(int argc, char * argv[])
{
  LOG(ERROR) << ""test"";
}
```

compiles and works without problems but when I try to run the [example trainer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/tutorials/example_trainer.cc) the program compiles but fails to link with the following errors:
```
1>  main.obj : error LNK2019: unresolved external symbol """"public: __cdecl tensorflow::Operation::Operation(class tensorflow::Node *)"" (??0Operation@tensorflow@@QEAA@PEAVNode@1@@Z)"" in function """"public: __cdecl tensorflow::Input::Input<int,void>(int const &)"" (??$?0HX@Input@tensorflow@@QEAA@AEBH@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: __cdecl tensorflow::Input::Initializer::Initializer(class std::initializer_list<struct tensorflow::Input::Initializer> const &)"" (??0Initializer@Input@tensorflow@@QEAA@AEBV?$initializer_list@UInitializer@Input@tensorflow@@@std@@@Z)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: __cdecl tensorflow::Scope::~Scope(void)"" (??1Scope@tensorflow@@QEAA@XZ)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: static class tensorflow::Scope __cdecl tensorflow::Scope::NewRootScope(void)"" (?NewRootScope@Scope@tensorflow@@SA?AV12@XZ)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > __cdecl tensorflow::Scope::GetUniqueNameForOp(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?GetUniqueNameForOp@Scope@tensorflow@@QEBA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV34@@Z)"" in function """"class tensorflow::Output __cdecl tensorflow::ops::Const<float>(class tensorflow::Scope const &,struct tensorflow::Input::Initializer const &)"" (??$Const@M@ops@tensorflow@@YA?AVOutput@1@AEBVScope@1@AEBUInitializer@Input@1@@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: void __cdecl tensorflow::Scope::UpdateStatus(class tensorflow::Status)const "" (?UpdateStatus@Scope@tensorflow@@QEBAXVStatus@2@@Z)"" in function """"class tensorflow::Output __cdecl tensorflow::ops::Const<float>(class tensorflow::Scope const &,struct tensorflow::Input::Initializer const &)"" (??$Const@M@ops@tensorflow@@YA?AVOutput@1@AEBVScope@1@AEBUInitializer@Input@1@@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: void __cdecl tensorflow::Scope::UpdateBuilder(class tensorflow::NodeBuilder *)const "" (?UpdateBuilder@Scope@tensorflow@@QEBAXPEAVNodeBuilder@2@@Z)"" in function """"class tensorflow::Output __cdecl tensorflow::ops::Const<float>(class tensorflow::Scope const &,struct tensorflow::Input::Initializer const &)"" (??$Const@M@ops@tensorflow@@YA?AVOutput@1@AEBVScope@1@AEBUInitializer@Input@1@@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: bool __cdecl tensorflow::Scope::ok(void)const "" (?ok@Scope@tensorflow@@QEBA_NXZ)"" in function """"class tensorflow::Output __cdecl tensorflow::ops::Const<float>(class tensorflow::Scope const &,struct tensorflow::Input::Initializer const &)"" (??$Const@M@ops@tensorflow@@YA?AVOutput@1@AEBVScope@1@AEBUInitializer@Input@1@@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: class tensorflow::Graph * __cdecl tensorflow::Scope::graph(void)const "" (?graph@Scope@tensorflow@@QEBAPEAVGraph@2@XZ)"" in function """"class tensorflow::Output __cdecl tensorflow::ops::Const<float>(class tensorflow::Scope const &,struct tensorflow::Input::Initializer const &)"" (??$Const@M@ops@tensorflow@@YA?AVOutput@1@AEBVScope@1@AEBUInitializer@Input@1@@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: class tensorflow::Status __cdecl tensorflow::Scope::ToGraphDef(class tensorflow::GraphDef *)const "" (?ToGraphDef@Scope@tensorflow@@QEBA?AVStatus@2@PEAVGraphDef@2@@Z)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: class tensorflow::Status __cdecl tensorflow::Scope::DoShapeInference(class tensorflow::Node *)const "" (?DoShapeInference@Scope@tensorflow@@QEBA?AVStatus@2@PEAVNode@2@@Z)"" in function """"class tensorflow::Output __cdecl tensorflow::ops::Const<float>(class tensorflow::Scope const &,struct tensorflow::Input::Initializer const &)"" (??$Const@M@ops@tensorflow@@YA?AVOutput@1@AEBVScope@1@AEBUInitializer@Input@1@@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"private: class tensorflow::Scope __cdecl tensorflow::Scope::WithOpNameImpl(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?WithOpNameImpl@Scope@tensorflow@@AEBA?AV12@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"class tensorflow::Output __cdecl tensorflow::ops::Const(class tensorflow::Scope const &,struct tensorflow::Input::Initializer const &)"" (?Const@ops@tensorflow@@YA?AVOutput@2@AEBVScope@2@AEBUInitializer@Input@2@@Z)"" in function """"class tensorflow::Output __cdecl tensorflow::ops::Const<float>(class tensorflow::Scope const &,struct tensorflow::Input::Initializer const &)"" (??$Const@M@ops@tensorflow@@YA?AVOutput@1@AEBVScope@1@AEBUInitializer@Input@1@@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"struct tensorflow::NodeBuilder::NodeOut __cdecl tensorflow::ops::AsNodeOut(class tensorflow::Scope const &,class tensorflow::Input const &)"" (?AsNodeOut@ops@tensorflow@@YA?AUNodeOut@NodeBuilder@2@AEBVScope@2@AEBVInput@2@@Z)"" in function """"class tensorflow::Output __cdecl tensorflow::ops::Const<float>(class tensorflow::Scope const &,struct tensorflow::Input::Initializer const &)"" (??$Const@M@ops@tensorflow@@YA?AVOutput@1@AEBVScope@1@AEBUInitializer@Input@1@@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: __cdecl tensorflow::ops::Div::Div(class tensorflow::Scope const &,class tensorflow::Input,class tensorflow::Input)"" (??0Div@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@1@Z)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: __cdecl tensorflow::ops::MatMul::MatMul(class tensorflow::Scope const &,class tensorflow::Input,class tensorflow::Input)"" (??0MatMul@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@1@Z)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: __cdecl tensorflow::ops::Sqrt::Sqrt(class tensorflow::Scope const &,class tensorflow::Input)"" (??0Sqrt@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@@Z)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: __cdecl tensorflow::ops::Square::Square(class tensorflow::Scope const &,class tensorflow::Input)"" (??0Square@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@@Z)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: __cdecl tensorflow::ops::Sum::Sum(class tensorflow::Scope const &,class tensorflow::Input,class tensorflow::Input)"" (??0Sum@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@1@Z)"" in function """"class tensorflow::GraphDef __cdecl tensorflow::example::CreateGraphDef(void)"" (?CreateGraphDef@example@tensorflow@@YA?AVGraphDef@2@XZ)"".
1>  main.obj : error LNK2019: unresolved external symbol """"public: __cdecl tensorflow::SessionOptions::SessionOptions(void)"" (??0SessionOptions@tensorflow@@QEAA@XZ)"" in function """"void __cdecl tensorflow::example::ConcurrentSteps(struct tensorflow::example::Options const *,int)"" (?ConcurrentSteps@example@tensorflow@@YAXPEBUOptions@12@H@Z)"".
1>  main.obj : error LNK2019: unresolved external symbol """"class tensorflow::Session * __cdecl tensorflow::NewSession(struct tensorflow::SessionOptions const &)"" (?NewSession@tensorflow@@YAPEAVSession@1@AEBUSessionOptions@1@@Z)"" in function """"void __cdecl tensorflow::example::ConcurrentSteps(struct tensorflow::example::Options const *,int)"" (?ConcurrentSteps@example@tensorflow@@YAXPEBUOptions@12@H@Z)"".
1>  main.obj : error LNK2001: unresolved external symbol """"const tensorflow::GraphDef::`vftable'"" (??_7GraphDef@tensorflow@@6B@)"".
```

Now I read [here](https://github.com/tensorflow/tensorflow/issues/30647) in a post by [gunan](https://github.com/gunan) that this has to do with the fact that not all symbols are exported, however, I am not sure whether this is the case here since I find it strange that compiling a tensorflow .lib and .dll without any custom changes results in a library that is not able to compile/work with official example code.
Am I missing something?

Cheers"
34158,Loss and metrics differ with masking or sample weights,"Update on Jan 8, 2021: I updated the title from ""Metrics incorrect for RNN with mask"" as I discovered more information that widens the scope of this issue. See comment on that date.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **n/a**
- TensorFlow installed from (source or binary): **binary (conda)**
- TensorFlow version (use command below): **2.0.0**
- Python version: **3.6.8**
- Bazel version (if compiling from source): **n/a**
- GCC/Compiler version (if compiling from source): **n/a**
- CUDA/cuDNN version: **10.0.130 / 7.6.0**
- GPU model and memory: **1080 Ti**

**Describe the current behavior**
I am training an RNN (GRU) where my varying-length sequences are right-padded with 0s and a mask is applied. _Many_ sequences are more than half 0s (padding). I compile the model with a loss of `'mean_squared_error'` and a metric of `'mean_squared_error'`, but the output is different when the mask is in effect.
```
model.compile(optimizer=keras.optimizers.RMSprop(),
              loss='mean_squared_error',
              metrics=['mean_squared_error'])
```
Or equivalently:
```
model.compile(optimizer=keras.optimizers.RMSprop(),
              loss=keras.losses.MeanSquaredError(),
              metrics=[keras.metrics.MeanSquaredError()])
```

Example output (note the different values for `loss` vs. `mean_squared_error` for both training and validation):
```
Epoch 1/50
210328/210328 [==============================] - 610s 3ms/sample - loss: 4.5338e-06 - mean_squared_error: 1.1923e-05 - val_loss: 2.5456e-06 - val_mean_squared_error: 6.7928e-06
Epoch 2/50
210328/210328 [==============================] - 525s 2ms/sample - loss: 2.1835e-06 - mean_squared_error: 5.7421e-06 - val_loss: 2.2920e-06 - val_mean_squared_error: 6.1160e-06
Epoch 3/50
210328/210328 [==============================] - 513s 2ms/sample - loss: 1.9939e-06 - mean_squared_error: 5.2437e-06 - val_loss: 2.2535e-06 - val_mean_squared_error: 6.0133e-06
...
Epoch 50/50
210328/210328 [==============================] - 527s 3ms/sample - loss: 1.5595e-06 - mean_squared_error: 4.1011e-06 - val_loss: 1.7867e-06 - val_mean_squared_error: 4.7677e-06
```

When I disable the masking, I get the following output:
```
Epoch 1/3
210328/210328 [==============================] - 516s 2ms/sample - loss: 7.1682e-06 - mean_squared_error: 7.1682e-06 - val_loss: 6.7091e-06 - val_mean_squared_error: 6.7091e-06
Epoch 2/3
210328/210328 [==============================] - 434s 2ms/sample - loss: 5.9133e-06 - mean_squared_error: 5.9133e-06 - val_loss: 6.7091e-06 - val_mean_squared_error: 6.7091e-06
Epoch 3/3
210328/210328 [==============================] - 442s 2ms/sample - loss: 5.9085e-06 - mean_squared_error: 5.9085e-06 - val_loss: 6.7073e-06 - val_mean_squared_error: 6.7073e-06
```
Without the mask, the values for `loss` and `mean_squared_error` agree. For the validation set, the values are not really improving and the value of 6.7e-06 seems to be what you get when you evaluate on the 0s that would otherwise be ignored by the masking. Comparing the values between the runs suggests that the `mean_squared_error` calculations are not using the mask when it is in effect, but the `loss` calculations do use the mask. (We'd expect lower values when we correctly ignore irrelevant time steps.)

**Describe the expected behavior**
The values for `loss` and `mean_squared_error` should agree and both use the masking.

**Code to reproduce the issue**
I don't have full code and data to share since my model and data are proprietary.

**Other info / logs**
I can't think of any relevant logs.
"
34157,Keras fails to feed ragged/sparse inputs with correct input placeholder,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, custom subclassed model
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-17764-gae26958 2.1.0-dev20191111
- Python version: Google Colab py3
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: Google Colab
- GPU model and memory: Google Colab

**Describe the current behavior**
Error raised when trying to feed ragged/sparse tensors to model with tf.data.Dataset

**Describe the expected behavior**
There should be no error

**Code to reproduce the issue**
https://colab.research.google.com/drive/1Ysbe9uxWLn1eFWNMax9SAHewHMrXwG-R

**Other info / logs**
```python
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-4-ed795b275880> in <module>()
----> 1 sparse_model = MyModel(False)
      2 sparse_input = my_dataset(False)
      3 
      4 sparse_model.compile(optimizer='Adam', loss='mse')
      5 sparse_model.fit(sparse_input)

13 frames
<ipython-input-2-45855ec3bda4> in __init__(self, ragged_on, **kwargs)
     13     outputs = tf.keras.layers.GlobalAveragePooling1D()(dense)
     14 
---> 15     super(MyModel, self).__init__(inputs=inputs, outputs=outputs)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in __init__(self, *args, **kwargs)
    144 
    145   def __init__(self, *args, **kwargs):
--> 146     super(Model, self).__init__(*args, **kwargs)
    147     _keras_api_gauge.get_cell('model').set(True)
    148     # initializing _distribution_strategy here since it is possible to call

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py in __init__(self, *args, **kwargs)
    167         'inputs' in kwargs and 'outputs' in kwargs):
    168       # Graph network
--> 169       self._init_graph_network(*args, **kwargs)
    170     else:
    171       # Subclassed network

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py in _init_graph_network(self, inputs, outputs, name, **kwargs)
    270 
    271     if any(not hasattr(tensor, '_keras_history') for tensor in self.outputs):
--> 272       base_layer_utils.create_keras_history(self._nested_outputs)
    273 
    274     self._base_init(name=name, **kwargs)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in create_keras_history(tensors)
    185     keras_tensors: The Tensors found that came from a Keras Layer.
    186   """"""
--> 187   _, created_layers = _create_keras_history_helper(tensors, set(), [])
    188   return created_layers
    189 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    245           else:
    246             with ops.init_scope():
--> 247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
    249           layer_inputs, processed_ops, created_layers)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in __call__(self, inputs)
   3725         value = math_ops.cast(value, tensor.dtype)
   3726       converted_inputs.append(value)
-> 3727     outputs = self._graph_fn(*converted_inputs)
   3728 
   3729     # EagerTensor.numpy() will often make a copy to ensure memory safety.

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   1527       TypeError: For invalid positional/keyword argument combinations.
   1528     """"""
-> 1529     return self._call_impl(args, kwargs)
   1530 
   1531   def _call_impl(self, args, kwargs, cancellation_manager=None):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _call_impl(self, args, kwargs, cancellation_manager)
   1567       raise TypeError(""Keyword arguments {} unknown. Expected {}."".format(
   1568           list(kwargs.keys()), list(self._arg_keywords)))
-> 1569     return self._call_flat(args, self.captured_inputs, cancellation_manager)
   1570 
   1571   def _filtered_call(self, args, kwargs):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1668       # No tape is watching; skip to running the function.
   1669       return self._build_call_outputs(self._inference_function.call(
-> 1670           ctx, args, cancellation_manager=cancellation_manager))
   1671     forward_backward = self._select_forward_and_backward_functions(
   1672         args,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    521               inputs=args,
    522               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 523               ctx=ctx)
    524         else:
    525           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError:  You must feed a value for placeholder tensor 'data/values' with dtype float and shape [?]
	 [[node data/values (defined at <ipython-input-2-45855ec3bda4>:15) ]] [Op:__inference_keras_scratch_graph_22]

Function call stack:
keras_scratch_graph
```"
34156,"Distributed training with TensorFlow2.0 not working: ""Aborting RingReduce with Invalid argument: Shape mismatch in the collective instance 106.""","We trying to build a multi-worker strategy based on tutorials: [Multi-worker training with Keras](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) and [distributed training with TF2](https://github.com/lambdal/TensorFlow2-tutorial/blob/master/05-distributed-training/worker.py). The code works with this configurations: 
- first node:
`os.environ['TF_CONFIG'] = json.dumps({ 'cluster': {  'worker': [""localhost:5006"",""localhost:5007""] },  'task': {'type': 'worker', 'index': 0}})`
- second node:
`os.environ['TF_CONFIG'] = json.dumps({ 'cluster': {  'worker': [""localhost:5006"",""localhost:5007""] },  'task': {'type': 'worker', 'index': 1}})`.

Then we tried to run the code from two devices with the following system information:
- OS: Linux Mint 19.1 Cinnamon, Cinnamon Version: 4.0.10
- python version: 3.6.8
- tensorflow version: 2.1.0

with the following configurations:
- on the first device:
`os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""10.0.0.109:6006"",""10.0.0.148:6006""]
    },
    'task': {'type': 'worker', 'index': 0}
})`
- on the second device:
`os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""10.0.0.109:6006"",""10.0.0.148:6006""]
    },
    'task': {'type': 'worker', 'index': 1}
})`.

The devices can navigate into each other through ssh without password. We report the used script and the [link](https://docs.aws.amazon.com/en_us/forecast/latest/dg/getting-started.html#gs-upload-data-to-s3) to the source data set.
Script:
```
def create_dataframe(data, time_field):
    data['time'] = pd.to_datetime(data[time_field])
    data = data.drop(columns=[time_field])
    data.sort_values('time')
    data = data.reset_index(drop=True)
    data.set_index('time', inplace=True)
    return data

def aggregate(df, freq , field, aggregation):
    df_count = df.groupby(pd.Grouper(level='time', freq=freq))[field].agg(aggregation)
    df_count.dropna(inplace=True)
    df_count = df_count.to_frame().reset_index()
    df = df.reset_index()
    df_count.set_index('time', inplace=True)
    return df_count

def split_sequence(sequence, n_steps):
    X, y = list(), list()
    for i in range(len(sequence)):
        end_ix = i + n_steps
        if end_ix > len(sequence)-1:
            break
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return array(X), array(y)

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

df=pd.read_csv(""/path/to/electricityusagedata.csv"")

df = create_dataframe(df, 'dt')
dfy = aggregate(df,freq = '1h', field = 'value', aggregation = 'mean')
n_steps = 10
n_features=1
value=df['value']

X, y = split_sequence(dfy.value, n_steps)

Xtrain = X.reshape(X.shape[0], X.shape[1], n_features)

with strategy.scope():

	inputs = tf.keras.layers.Input(shape=(n_steps, n_features))
	layer = tf.keras.layers.Dense(5, activation='relu')(inputs)
	layer = tf.keras.layers.Dense(1)(layer)

	lstm_stacked = tf.keras.Model(inputs=inputs, outputs=layer)
	lstm_stacked.compile(optimizer=tf.keras.optimizers.Adam(),loss=tf.keras.losses.MeanSquaredError())
	lstm_stacked.summary()

lstm_stacked.fit(Xtrain,y,epochs=10)
```

The complete output from the command line is
```
2019-11-11 11:44:33.962245: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory
2019-11-11 11:44:33.962282: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2019-11-11 11:44:34.962335: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2019-11-11 11:44:34.962374: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-11 11:44:34.962394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (keypartner): /proc/driver/nvidia/version does not exist
2019-11-11 11:44:34.962620: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-11 11:44:34.991840: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294830000 Hz
2019-11-11 11:44:34.992692: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x57231a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-11 11:44:34.992737: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-11 11:44:35.000579: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> localhost:6006, 1 -> 10.0.0.148:6006}
2019-11-11 11:44:35.001075: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:6006
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 10, 1)]           0         
_________________________________________________________________
dense (Dense)                (None, 10, 5)             10        
_________________________________________________________________
dense_1 (Dense)              (None, 10, 1)             6         
=================================================================
Total params: 16
Trainable params: 16
Non-trainable params: 0
_________________________________________________________________
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.
2019-11-11 11:45:04.330943: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:428] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: ""FlatMapDataset/_9""
op: ""FlatMapDataset""
input: ""PrefetchDataset/_8""
attr {
  key: ""Targuments""
  value {
    list {
    }
  }
}
attr {
  key: ""f""
  value {
    func {
      name: ""__inference_Dataset_flat_map_slice_batch_indices_173""
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
attr {
  key: ""output_types""
  value {
    list {
      type: DT_INT64
    }
  }
}
. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
Train on 8750 samples
Epoch 1/10
2019-11-11 11:45:07.181787: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Invalid argument: Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.
Additional GRPC error information:
{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}
	 [[{{node scoped_allocator_1_1_CollectiveReduce}}]]
Additional GRPC error information:
{""created"":""@1573469107.181701406"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.\nAdditional GRPC error information:\n{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}\n\t [[{{node scoped_allocator_1_1_CollectiveReduce}}]]"",""grpc_status"":3}
2019-11-11 11:45:07.181854: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.
Additional GRPC error information:
{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}
	 [[{{node scoped_allocator_1_1_CollectiveReduce}}]]
Additional GRPC error information:
{""created"":""@1573469107.181701406"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.\nAdditional GRPC error information:\n{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}\n\t [[{{node scoped_allocator_1_1_CollectiveReduce}}]]"",""grpc_status"":3}
2019-11-11 11:45:07.181990: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Cancelled: [_Derived_]Cancelled
Additional GRPC error information:
{""created"":""@1573469107.181911798"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}
2019-11-11 11:45:07.182013: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]Cancelled
Additional GRPC error information:
{""created"":""@1573469107.181911798"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}
2019-11-11 11:45:07.182077: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at collective_ops.cc:253 : Invalid argument: Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.
Additional GRPC error information:
{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}
	 [[{{node scoped_allocator_1_1_CollectiveReduce}}]]
Additional GRPC error information:
{""created"":""@1573469107.181701406"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.\nAdditional GRPC error information:\n{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}\n\t [[{{node scoped_allocator_1_1_CollectiveReduce}}]]"",""grpc_status"":3}
2019-11-11 11:45:07.182133: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.
Additional GRPC error information:
{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}
	 [[{{node scoped_allocator_1_1_CollectiveReduce}}]]
Additional GRPC error information:
{""created"":""@1573469107.181701406"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.\nAdditional GRPC error information:\n{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}\n\t [[{{node scoped_allocator_1_1_CollectiveReduce}}]]"",""grpc_status"":3}
	 [[scoped_allocator_1_1_CollectiveReduce]]
2019-11-11 11:45:07.182123: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at collective_ops.cc:253 : Cancelled: [_Derived_]Cancelled
Additional GRPC error information:
{""created"":""@1573469107.181911798"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}
  32/8750 [..............................] - ETA: 12:56Traceback (most recent call last):
  File ""worker1.py"", line 91, in <module>
    lstm_stacked.fit(Xtrain,y,epochs=10)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 792, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 790, in fit
    *args, **kwargs)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 777, in wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 772, in _worker_fn
    return method(model, **kwargs)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 340, in fit
    total_epochs=epochs)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 127, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 632, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2341, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1589, in _filtered_call
    self.captured_inputs)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1670, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 523, in call
    ctx=ctx)
  File ""/home/keypartner/my_tutorial_env/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError:  Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.
Additional GRPC error information:
{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}
	 [[{{node scoped_allocator_1_1_CollectiveReduce}}]]
Additional GRPC error information:
{""created"":""@1573469107.181701406"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op.\nAdditional GRPC error information:\n{""created"":""@1573469107.160620334"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Shape mismatch in the collective instance 106. Op at device /job:worker/replica:0/task:1/device:CPU:0 expected shape [49] but another member in the group expected shape [64]. This is likely due to different input shapes at different members of the collective op."",""grpc_status"":3}\n\t [[{{node scoped_allocator_1_1_CollectiveReduce}}]]"",""grpc_status"":3}
	 [[scoped_allocator_1_1_CollectiveReduce]] [Op:__inference_distributed_function_843]

Function call stack:
distributed_function

2019-11-11 11:45:07.262512: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled

```
We are wondering why the multi devices example doesn't work meanwhile it works on multi threads at localhost.
"
34155,BERT-joint TF1 baseline fails on TPU training,"BERT-joint baseline script [https://github.com/google-research/language/tree/master/language/question_answering/bert_joint#training-our-model](url)
 fails on TPU training with:

E1111 11:25:56.709489 140509220771584 error_handling.py:81] Closing session due to error From /job:worker/replica:0/task:0:
End of sequence
	 [[node input_pipeline_task0/while/IteratorGetNext (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
2019-11-11 11:26:03.693223: W tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:157] RPC failed with status = ""Unavailable: Socket closed"" and grpc_error_string = ""{""created"":""@1573471563.693073061"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Socket closed"",""grpc_status"":14}"", maybe retrying the RPC
2019-11-11 11:26:03.693329: W tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:157] RPC failed with status = ""Unavailable: Socket closed"" and grpc_error_string = ""{""created"":""@1573471563.693032484"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Socket closed"",""grpc_status"":14}"", maybe retrying the RPC
ERROR:tensorflow:Error recorded from outfeed: Step was cancelled by an explicit call to `Session::Close()`.
E1111 11:26:17.120502 140509233358592 error_handling.py:75] Error recorded from outfeed: Step was cancelled by an explicit call to `Session::Close()`.
INFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. This error may also occur due to a gRPC failure caused by high memory or network bandwidth usage in the parameter servers. If this error occurs repeatedly, try increasing the number of parameter servers assigned to the job. Error: Session c3d5a74e41ee70e5 is not found.
I1111 11:26:17.120874 140510448183168 monitored_session.py:1269] An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. This error may also occur due to a gRPC failure caused by high memory or network bandwidth usage in the parameter servers. If this error occurs repeatedly, try increasing the number of parameter servers assigned to the job. Error: Session c3d5a74e41ee70e5 is not found.
ERROR:tensorflow:


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No custom code - this is google provided example
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Google Colab default
- TensorFlow version (use command below):
print(tf.GIT_VERSION, tf.VERSION)
v1.15.0-0-g590d6eef7e 1.15.0
- Python version: 3.6.8 (default, Oct  7 2019, 12:59:55) 
[GCC 8.3.0]
Using TPU




**Code to reproduce the issue**
https://github.com/google-research/language/blob/master/language/question_answering/bert_joint/run_nq.py
"
34154,tf.nn.moments with keras causes Invalid tape state,"### System information
- Have I written custom code: yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from : binary
- TensorFlow version: v1.12.1-8709-gddde447 2.0.0-dev20190813
- Python version: 3.6

Also reproducable with cuda 10.0 cudnn 7.something / GTX-1070 but I doubt it's a GPU issue...

### Current Behaviour
Using output of `tf.nn.moments` causes `Invalid tape state` when training keras models in manual loops (i.e. not using `fit`).

### Expected Behaviour
`mean, var = tf.nn.moments(x, axes, keepdims=True)` (and use thereafter) should be equivalent to 
```
mean = tf.reduce_mean(x, axis=axes, keepdims=True)
xs = x - mean
var = tf.reduce_mean(xs**2, axis=axes, keepdims=True)
```

# Code
```python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf


def normalize_manual(x):
    mean = tf.reduce_mean(x, axis=-1, keepdims=True)
    x = x - mean
    var = tf.reduce_mean(tf.square(x), axis=-1, keepdims=True)
    return x / (tf.sqrt(var + 1e-6))


def normalize_with_moments(x):
    mean, var = tf.nn.moments(x, [-1], keepdims=True)
    x = x - mean
    return x / tf.sqrt(var + 1e-6)


def run_model_custom(normalize=normalize_with_moments):
    inp = tf.keras.layers.Input(shape=(8,))
    x = inp
    x = tf.keras.layers.Dense(8)(x)
    x = normalize(x)
    out = tf.squeeze(tf.keras.layers.Dense(1)(x), axis=-1)
    model = tf.keras.Model(inputs=inp, outputs=out)

    x = tf.random.normal(shape=((100, 8)))
    y = tf.random.normal(shape=((100,)))
    dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(5)

    for x, y in dataset.take(1):
        with tf.GradientTape() as tape:
            out = model(x)
            tape.gradient(out, model.trainable_weights)
        break
    print('passed run_model_custom with {}'.format(normalize.__name__))


def train_model_fit(normalize=normalize_with_moments):
    inp = tf.keras.layers.Input(shape=(8,))
    x = inp
    x = tf.keras.layers.Dense(8)(x)
    x = normalize(x)
    out = tf.squeeze(tf.keras.layers.Dense(1)(x), axis=-1)
    model = tf.keras.Model(inputs=inp, outputs=out)

    x = tf.random.normal(shape=((100, 8)))
    y = tf.random.normal(shape=((100,)))
    dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(5)
    model.compile(optimizer=tf.keras.optimizers.SGD(), loss='mse')
    model.fit(dataset, epochs=1, steps_per_epoch=2)
    print('passed train_model_fit with {}'.format(normalize.__name__))


def compute_graph_tf(normalize=normalize_with_moments):
    x = tf.random.normal((10, 5))
    with tf.GradientTape() as tape:
        layer = tf.keras.layers.Dense(2)
        y = layer(x)
        y = tf.reduce_sum(normalize(y))
        tape.gradient(y, layer.trainable_weights)
    print('passed compute_graph_tf with {}'.format(normalize.__name__))


run_model_custom(normalize_with_moments)  # <----- fails

###########
# the below work
###########
train_model_fit(normalize_with_moments)
compute_graph_tf(normalize_with_moments)
run_model_custom(normalize_manual)
train_model_fit(normalize_manual)
compute_graph_tf(normalize_manual)
```

# Logs
```
Traceback (most recent call last):
  File ""norm_grad.py"", line 67, in <module>
    run_model_custom(normalize_with_moments)  # <----- fails
  File ""norm_grad.py"", line 36, in run_model_custom
    tape.gradient(out, model.trainable_weights)
  File "".../python3.6/site-packages/tensorflow_core/python/eager/backprop.py"", line 1008, in gradient
    unconnected_gradients=unconnected_gradients)
  File "".../python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py"", line 76, in imperative_grad
    compat.as_str(unconnected_gradients.value))
tensorflow.python.framework.errors_impl.InternalError: Invalid tape state.
```"
34153,tf.data.experimental.choose_from_datasets freezes if one of the datasets is empty,"**System information**
- TensorFlow version (you are using): 1.14.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

`tf.data.experimental.choose_from_datasets` freezes if one of the datasets is empty. This can happen for instance, when splitting the dataset into classes, recombining them using this function and one of the classes is not present in the input data. 

**Will this change the current api? How?**
No

**Who will benefit with this feature?**

Anyone using complicated input pipelines. 

**Any Other info.**
"
34152,Can't train a model using Java in Windows,"I know training a model is currently not supported for Java.

I was just wondering when this is likely to be available?"
34151,Cannot import 'GradientDescentOptimizer',"
![image](https://user-images.githubusercontent.com/3198940/68577281-bb353800-04aa-11ea-8a50-0a48d2ad0974.png)

I use train.GradientDescentOptimizer and tf.optimizers.GradientDescentOptimizer, which not work. So I read the doc but only search GradientDescentOptimizer  in tf.compat.v1.train.GradientDescentOptimizer"
34150,TensorFlow Lite Op Request,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.14.6
- TensorFlow installed from (source or binary): 2.0
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```bash
TensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, EQUAL, FLOOR, FULLY_CONNECTED, LESS, LOGICAL_AND, LOGISTIC, MAX_POOL_2D, MUL, RESHAPE, REVERSE_V2, SPLIT, TANH, TRANSPOSE. Here is a list of operators for which you will need custom implementations: CTC_BEAM_SEARCH_DECODER, LoopCond, RandomUniform, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArrayV3, TensorArrayWriteV3.
```

Also, please include a link to a GraphDef or the model if possible.
The model comes from this repository : https://github.com/MaybeShewill-CV/CRNN_Tensorflow

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34148,issues in importing keras ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):win 7 64 bit
- TensorFlow installed from (source or binary): installed using anaconda prompt
- TensorFlow version (or github SHA if from source): 1:13;1

DESCRIPTION : I run it using CPU , I have installed using the this command : conda install -c conda-forge keras in conda prompt

Python 3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]
Type ""copyright"", ""credits"" or ""license"" for more information.

IPython 7.6.1 -- An enhanced Interactive Python.
CODE:

from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense

LOG:

from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
Using TensorFlow backend.
Traceback (most recent call last):

  File ""<ipython-input-1-d43c180dcd07>"", line 1, in <module>
    from keras.models import Sequential

  File ""C:\Users\User\Anaconda3\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils

  File ""C:\Users\User\Anaconda3\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils

  File ""C:\Users\User\Anaconda3\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K

  File ""C:\Users\User\Anaconda3\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon

  File ""C:\Users\User\Anaconda3\lib\site-packages\keras\backend\load_backend.py"", line 90, in <module>
    from .tensorflow_backend import *

  File ""C:\Users\User\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf

  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import

  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow

  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)

ImportError: Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\User\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\User\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed with error code -1073741795


Failed to load the native TensorFlow runtime.
Also, please include a link to a GraphDef or the model if possible.


"
34147,How to get training time per epoch using TPUEstimator?,"I know with Keras you can set verbose levels (0,1,2) to see training time per each epoch; however, I can't seem to figure out how to get a ""verbose"" feature working when trying to use the TPUEstimator. I'm using v1.14
"
34146,"Have install future module, but still can not find builtins when Building from source","<em>

**System information**
- OS Platform and Distribution (Linux Ubuntu 16.04, kerenl: Linux dell 4.15.0-54-generic):
- Mobile device (not)
- TensorFlow installed from: source
- TensorFlow version: master branch, git clone https://github.com/tensorflow/tensorflow.git
- Python version: 2.7.12
- Installed using virtualenv? pip? conda?: 
- Bazel version: 0.29.1
- GCC/Compiler version:  5.4.0
- CUDA/cuDNN version:  CUDA 9.0, cuDNN 7.3.1
- GPU model and memory: GeForce GT 730

**Configure info**

> 
	jxl@dell:~/third_softwares/tensorflow$ ./configure
	WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
	You have bazel 0.29.1 installed.
	Please specify the location of python. [Default is /usr/bin/python]: 

	Found possible Python library paths:
	  /opt/ros/kinetic/lib/python2.7/dist-packages
	  /usr/lib/python2.7/dist-packages
	  /usr/local/lib/python2.7/dist-packages
	  /home/jxl/kalibr_ws/devel/lib/python2.7/dist-packages
	  /home/jxl/third_softwares/Autoware/ros/install/rslidar_pointcloud/lib/python2.7/dist-packages
	Please input the desired Python library path to use.  Default is [/opt/ros/kinetic/lib/python2.7/dist-packages]

	Do you wish to build TensorFlow with XLA JIT support? [Y/n]: n
	No XLA JIT support will be enabled for TensorFlow.

	Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n
	No OpenCL SYCL support will be enabled for TensorFlow.

	Do you wish to build TensorFlow with ROCm support? [y/N]: n
	No ROCm support will be enabled for TensorFlow.

	Do you wish to build TensorFlow with CUDA support? [y/N]: y
	CUDA support will be enabled for TensorFlow.

	Do you wish to build TensorFlow with TensorRT support? [y/N]: n
	No TensorRT support will be enabled for TensorFlow.

	Found CUDA 9.0 in:
	    /usr/local/cuda/lib64
	    /usr/local/cuda/include
	Found cuDNN 7 in:
	    /usr/lib/x86_64-linux-gnu
	    /usr/include

	Please specify a list of comma-separated CUDA compute capabilities you want to build with.
	You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
	Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5]: 

	Do you want to use clang as CUDA compiler? [y/N]: n
	nvcc will be used as CUDA compiler.

	Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 

	Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 

	Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
	Not configuring the WORKSPACE for Android builds.

	Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
		--config=mkl         	# Build with MKL support.
		--config=monolithic  	# Config for mostly static monolithic build.
		--config=ngraph      	# Build with Intel nGraph support.
		--config=numa        	# Build with NUMA support.
		--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
		--config=v2          	# Build TensorFlow 2.x instead of 1.x.
	Preconfigured Bazel build configs to DISABLE default on features:
		--config=noaws       	# Disable AWS S3 filesystem support.
		--config=nogcp       	# Disable GCP support.
		--config=nohdfs      	# Disable HDFS support.
		--config=nonccl      	# Disable NVIDIA NCCL support.
	Configuration finished
	jxl@dell:~/third_softwares/tensorflow$ 


**Describe the problem**
> 
	jxl@dell:~/third_softwares/tensorflow$ sudo pip  install future
	[sudo] jxl 的密码： 
	/usr/local/lib/python2.7/dist-packages/pip/_vendor/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.
	  warnings.warn(warning, RequestsDependencyWarning)
	DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support
	Requirement already satisfied: future in /home/jxl/.local/lib/python2.7/site-packages (0.18.2)
	jxl@dell:~/third_softwares/tensorflow$ 

	jxl@dell:~/third_softwares/tensorflow$ bazel build --config=opt --config=cuda  --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0""   //tensorflow/tools/pip_package:build_pip_package
	Starting local Bazel server and connecting to it...
	WARNING: The following configs were expanded more than once: [cuda, using_cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
	INFO: Options provided by the client:
	  Inherited 'common' options: --isatty=1 --terminal_columns=231
	INFO: Reading rc options for 'build' from /home/jxl/third_softwares/tensorflow/.bazelrc:
	  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --announce_rc --define=grpc_no_ares=true --incompatible_remove_legacy_whole_archive --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --config=v2
	INFO: Reading rc options for 'build' from /home/jxl/third_softwares/tensorflow/.tf_configure.bazelrc:
	  'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=/usr/bin/python --action_env PYTHON_LIB_PATH=/opt/ros/kinetic/lib/python2.7/dist-packages --python_path=/usr/bin/python --action_env PYTHONPATH=/home/jxl/kalibr_ws/devel/lib/python2.7/dist-packages:/opt/ros/kinetic/lib/python2.7/dist-packages:/home/jxl/third_softwares/Autoware/ros/install/rslidar_pointcloud/lib/python2.7/dist-packages --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.5 --action_env LD_LIBRARY_PATH=/home/jxl/kalibr_ws/devel/lib:/opt/ros/kinetic/lib:/opt/ros/kinetic/lib/x86_64-linux-gnu:/home/jxl/third_softwares/ssdcaffe/distribute/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/gcc-5 --config=cuda --action_env TF_CONFIGURE_IOS=0
	INFO: Found applicable config definition build:v2 in file /home/jxl/third_softwares/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
	INFO: Found applicable config definition build:cuda in file /home/jxl/third_softwares/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
	INFO: Found applicable config definition build:using_cuda in file /home/jxl/third_softwares/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
	INFO: Found applicable config definition build:opt in file /home/jxl/third_softwares/tensorflow/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true
	INFO: Found applicable config definition build:cuda in file /home/jxl/third_softwares/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
	INFO: Found applicable config definition build:using_cuda in file /home/jxl/third_softwares/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
	DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
	DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at /home/jxl/.cache/bazel/_bazel_jxl/630c8d4015ad0c22430bd92a914b2e86/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
	 - /home/jxl/.cache/bazel/_bazel_jxl/630c8d4015ad0c22430bd92a914b2e86/external/bazel_toolchains/repositories/repositories.bzl:37:9
	 - /home/jxl/third_softwares/tensorflow/WORKSPACE:37:1
	DEBUG: /home/jxl/.cache/bazel/_bazel_jxl/630c8d4015ad0c22430bd92a914b2e86/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:5: 
	Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
	Traceback (most recent call last):
	  File ""/home/jxl/.cache/bazel/_bazel_jxl/630c8d4015ad0c22430bd92a914b2e86/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 32, in <module>
	    from builtins import bytes  # pylint: disable=redefined-builtin
	ImportError: No module named builtins
	INFO: Call stack for the definition of repository 'local_config_git' which is a git_configure (rule definition at /home/jxl/third_softwares/tensorflow/third_party/git/git_configure.bzl:66:17):
	 - /home/jxl/third_softwares/tensorflow/tensorflow/workspace.bzl:74:5
	 - /home/jxl/third_softwares/tensorflow/WORKSPACE:19:1
	ERROR: An error occurred during the fetch of repository 'local_config_git':
	   Traceback (most recent call last):
		File ""/home/jxl/third_softwares/tensorflow/third_party/git/git_configure.bzl"", line 64
			_fail(result.stderr)
		File ""/home/jxl/third_softwares/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
			fail((""%sGit Configuration Error:%s %...)))
	Git Configuration Error: Traceback (most recent call last):
	  File ""/home/jxl/.cache/bazel/_bazel_jxl/630c8d4015ad0c22430bd92a914b2e86/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 32, in <module>
	    from builtins import bytes  # pylint: disable=redefined-builtin
	ImportError: No module named builtins





"
34144,Tensorflow 2.0 too slow when minimizing a custom cost function,"**System information**
- OS : Windows 10
- TensorFlow version: v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version: 3.7.4

I have a code that looks like the following, where I want to minimize a custom cost function with respect to parameters w. However, when running the code, it appears to me that it is very slow (like more than 30 times slower) compared to the same code implemented without tensorflow (by explicitly defining a function that gives the gradient of the cost).

I am not sure if it's a problem with tf or if I am doing something wrong and unnecessarily re-computing the tf graph each time. I posted this issue on stackoverflow and have been advised to open an issue here.

In the following code, I am using a simple dummy cost function just as an example to show the big difference in performance.

**Code with Tensorflow:**

```
import numpy as np
import tensorflow as tf
import time

class ExampleTF:
    def __init__(self, n=100, m=10):
        Z = np.random.randn(n, m)
        self.Z = tf.convert_to_tensor(Z, dtype=tf.float32)
        self.w = tf.Variable(np.ones((m, 1)), dtype=tf.float32)

    # =====================================
    def cost(self, P):
        # This is a simple dummy cost function just as an example
        return tf.reduce_sum((self.Z @ self.w) - P)

    # =====================================
    def optimize_w(self, cost_func, parameters, lr=0.01, iterations=2000):
        optimizer = tf.optimizers.Adam(lr)
        for _ in range(iterations):
            optimizer.minimize(cost_func, var_list=parameters)

    # =====================================
    def update(self, P):
        P = tf.convert_to_tensor(P, dtype=tf.float32)

        self.optimize_w(
            cost_func = lambda: self.cost(P),
            parameters = [self.w]
        )

        #print(""===> cost:"", self.cost(P).numpy())
        #print(""w:"", self.w.numpy().reshape(-1)[:10])

# =====================================
n, m = 1000, 100
ex_tf = ExampleTF(n, m)
for _ in range(50):
    P = np.random.uniform(size=n).reshape((-1, 1))

    start = time.time()
    ex_tf.update(P)
    elapsed = time.time() - start

    print(""elapsed time:"", elapsed)
```

**Code without Tensorflow (just numpy) :**

```
import numpy as np
import tensorflow as tf
import time

class ExampleNonTF:
    def __init__(self, n=100, m=10):
        self.Z = np.random.randn(n, m)
        self.w = np.ones((m, 1))

    # =====================================
    def cost(self, P):
        # This is a simple dummy cost function just as an example
        return np.sum(self.Z @ self.w - P)

    # =====================================
    def gradient_cost(self, P):
        # This is the gradient of the dummy cost function with respect to self.w
        return np.sum(self.Z, axis=0).reshape(self.w.shape)

    # =====================================
    def optimize_w(self, P, lr=0.01, iterations=2000): # This is the ADAM optimizer
        avg_grad1 = 0; avg_grad2 = 0
        beta1 = 0.9; beta2 = 0.999; eps = 1e-07
        for itr in range(iterations):
            grad = self.gradient_cost(P)
            avg_grad1 = beta1 * avg_grad1 + (1 - beta1) * grad
            avg_grad2 = (beta2 * avg_grad2 + (1 - beta2) * (grad ** 2))
            avg_grad1_corr = avg_grad1 / (1 - beta1 ** (itr + 1))
            avg_grad2_corr = avg_grad2 / (1 - beta2 ** (itr + 1))
            self.w = self.w - lr * (avg_grad1_corr / (np.sqrt(avg_grad2_corr) + eps))

    # =====================================
    def update(self, P):
        self.optimize_w(P)

        #print(""===> cost:"", self.cost(P))
        #print(""w:"", self.w.reshape(-1)[:10])

# =====================================
n, m = 1000, 100
ex_nontf = ExampleNonTF(n, m)
for _ in range(50):
    P = np.random.uniform(size=n).reshape((-1, 1))

    start = time.time()
    ex_nontf.update(P)
    elapsed = time.time() - start

    print(""elapsed time:"", elapsed)
```"
34143,Unable to convert .pb to .tflite ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10
- TensorFlow installed from (source or binary): python -m pip install tensorflow==1.15
- TensorFlow version (or github SHA if from source): 1.15

I am currently trying to convert .pb file from export_tflite_ssd_graph.py into a .tflite file and encountered these error:

>2019-11-11 06:45:44.042588: F tensorflow/lite/toco/tooling_util.cc:935] Check failed: GetOpWithOutput(model, output_array) Specified output array ""'TFLite_Detection_PostProcess'"" is not produced by any op in this graph. Is it a typo? This should not happen. If you trigger this error please send a bug report (with code to reporduce this error), to the TensorFlow Lite team.
Fatal Python error: Aborted


This is what i try to run
```
tflite_convert --output_file=C:/tensorflow1/models/research/object_detection/inference_graph/detect.tflite --graph_def_file=C:/tensorflow1/models/research/object_detection/inference_graph/tflite_graph.pb --inference_type=FLOAT --inference_input_type=QUANTIZED_UINT8 --input_arrays=normalized_input_image_tensor --input_shapes=1,300,300,3 --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --mean_values=128 --std_dev_values=128 --change_concat_input_ranges=false --allow_custom_ops
```


Link is the full traceback:
https://pastebin.com/xJ1vZGmd

I've also check from https://stackoverflow.com/questions/52918051/how-to-convert-pb-to-tflite-format  and confirm that the output array is TFLite_Detection_PostProcess
```
output name =
TFLite_Detection_PostProcess

Input name =
normalized_input_image_tensor
```
"
34142,Combining packages from different channels,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
- TensorFlow installed from (source or binary):
conda (using conda-forge)
- TensorFlow version:
1.13.2
- Python version:
2.7.15
- Installed using virtualenv? pip? conda?:
conda
- GCC/Compiler version (if compiling from source):
4.8.3

**Describe the problem**
I am trying to get a running tensorflow 1.13.2 combined with ROOT (in particular root, root_numpy, and rootpy) in a conda environment. The issue is that there is no one conda channel that contains all of those packages at once but I need to combine two channels. I tried different orders of installing the packages but whenever I start using the second channel, I get this error: (in this case, I first installed all the root stuff, which worked and then added tensorflow)
```
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/anja/anaconda3/envs/new_try/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/home/anja/anaconda3/envs/new_try/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/anja/anaconda3/envs/new_try/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/anja/anaconda3/envs/new_try/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/anja/anaconda3/envs/new_try/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/anja/anaconda3/envs/new_try/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: /home/anja/anaconda3/envs/new_try/lib/python2.7/site-packages/tensorflow/python/../../../../libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/anja/anaconda3/envs/new_try/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
```"
34141,input_shape to build method is None when calling compute_output_shape on layer with overridden build method,"**System information**
custom code to reproduce is included below.

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04.3

- TensorFlow installed from (source or binary):
pip install tensorflow-gpu

- TensorFlow version (use command below):
v2.0.0-rc2-26-g64c3d38 2.0.0

- Python version:
3.6.8

**Describe the current behavior**
build method called with input_shape = None

**Describe the expected behavior**
Build method called with correct input shape

**Code to reproduce the issue**

```
import tensorflow as tf

class MyLayer(tf.keras.layers.Layer):
    def build(self, input_shape):

        if input_shape is None:
            print('error: input shape is none')
        else:
            print('build:', input_shape)

        super().build(input_shape)

    def call(self, inputs):
        print('call:', inputs.shape)

        return inputs * 2

def main():

    l = MyLayer()

    inp = tf.keras.Input(shape=(5, 5, 1))
    l.compute_output_shape((None, 5, 5, 1))

    o = l(inp)

    print(""input_shape:"", l.input_shape)
    print(""count_params:"", l.count_params())
    print('output:', o.shape)

if __name__=='__main__':
    main()
```

**Other info / logs**

When run, program prints this: 
```
error: input shape is none
call: (None, 5, 5, 1)
call: (None, 5, 5, 1)
input_shape: (None, 5, 5, 1)
count_params: 0
output: (None, 5, 5, 1)
```

Looking at the code for compute_output_shape, I noticed that it calls self._mabye_build method, but this method expects actual tensors as inputs, not tensor shapes. So it fumbes and passes in a None. 

Suggested code to fix:
at https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L620

replace _maybe_build with _maybe_build_from_shapes:
(should probably adjust _maybe_build to call this method also)
```
def _maybe_build_with_shapes(self, inputshapes):
    # Check input assumptions set before layer building, e.g. input rank.
    if not self.built:

      # Only call `build` if the user has manually overridden the build method.
      if not hasattr(self.build, '_is_default'):
        # Any setup work performed only once should happen in an `init_scope`
        # to avoid creating symbolic Tensors that will later pollute any eager
        # operations.
        with tf_utils.maybe_init_scope(self):
          self.build(input_shapes)
      # We must set self.built since user defined build functions are not
      # constrained to set self.built.
      self.built = True

```
I don't know what the code at the end of maybe_build is doing, so don't know if it belongs in this method or should just stay in _maybe_build:

```
    # Optionally load weight values specified at layer instantiation.
    if getattr(self, '_initial_weights', None) is not None:
      self.set_weights(self._initial_weights)
      self._initial_weights = None
```"
34140,[tf2.0] Can not load keras saved model with customized loss function,"I run tensorflow.keras on colab.research.google.com. 

In tf2.0, I trained a model with a customized loss function named Loss, then saved it by keras.Model.save().
When I try loading it by 
`keras.models.load_model( 'filename', custom_objects = { 'Loss': Loss } )`
It raises:
> /tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_utils.py in get_loss_function(loss)
>    1092   return losses.LossFunctionWrapper(
>    1093       loss_fn,
> -> 1094       name=loss_fn.__name__,
>    1095       reduction=losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE)
>    1096 
> 
> AttributeError: 'Loss' object has no attribute '__name__'

Even to set Loss.__name__ = 'xxx' before calling load_model does not help.

If set the 'compile' param to True for load_model, it may load successfully. But the loaded model can not work on evaluating or predicting.

To load the files saved by keras of tf1.5 is all OK. The model is trained by the same customized loss function. The model is saved to a file by tf1.5, while to a path by tf2.0.

How can I solve it?"
34139,Only one GPU is used during .fit() validation phase,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow version (use command below): 2.0.0

**Describe the current behavior**

During validation phase of Keras' `.fit()`, only one GPU is used (while all GPUs are used during the training phase).

**Code to reproduce the issue**
This issue can be easily reproduced using the code of [this official tutorial](https://www.tensorflow.org/tutorials/distribute/keras), by feeding the validation dataset `eval_dataset` to `model.fit()`.
"
34136,TensorRT Segmentation Fault During Conversion,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**
  Yes, the code I'm running is taken from [here](https://github.com/qubvel/efficientnet). I used the script [here](https://github.com/aaroey/tensorflow/blob/tftrt20/tftrt20/test.py) provided by @aaroey and replaced **mobilenet** by **efficientnet**
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**
Ubuntu 16.04.3 LTS
**- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:**
**- TensorFlow installed from (source or binary):**
**- TensorFlow version (use command below):**
v2.0.0-rc2-26-g64c3d38 2.0.0
**- Python version:**
Python 3.5.2
**- Bazel version (if compiling from source):**
Not Applicable
**- GCC/Compiler version (if compiling from source):**
**- CUDA/cuDNN version:** 
CUDA: 10.0; CuDNN: 7.6.4
**- GPU model and memory:**
Tesla M60 (AWS)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Running the script attached above and provided by @aaroey with efficientnet give segmentation fault

**Describe the expected behavior**
Running the same script provided above as is run smoothly

**Code to reproduce the issue**
Run the following code:

`import datetime
import numpy as np
import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt

msgs = []
inp = np.random.random_sample([1, 224, 224, 3]).astype(np.float32)
inpconst = tf.constant(inp)


def run_and_time(saved_model_dir, ref_result=None):
  """"""Helper method to measure the running time of a SavedModel.""""""
  NUM_RUNS = 100
  root = tf.saved_model.load(saved_model_dir)
  concrete_func = root.signatures[""serving_default""]
  result = None
  for _ in range(2):  # warm up
    concrete_func(input_1=inpconst)

  start_time = datetime.datetime.now()
  for i in range(NUM_RUNS):
    result = concrete_func(input_1=inpconst)
  end_time = datetime.datetime.now()

  elapsed = end_time - start_time
  result = result[list(result.keys())[0]]

  msgs.append(""------> time for %d runs: %s"" % (NUM_RUNS, str(elapsed)))
  if ref_result is not None:
    msgs.append(
        ""------> max diff: %s"" % str(np.max(np.abs(result - ref_result))))
  return result



saved_model_dir = ""/tmp/efficientnet.original""

import efficientnet.tfkeras as efn
model = efn.EfficientNetB0(weights='imagenet')
tf.saved_model.save(model, saved_model_dir)


params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(
    precision_mode='FP16',
    is_dynamic_op=True,
    minimum_segment_size=10)

converter = trt.TrtGraphConverterV2(
    input_saved_model_dir=saved_model_dir,
    conversion_params=params)

converter.convert()
saved_model_dir_trt = ""/tmp/efficientnet.trt""
converter.save(saved_model_dir_trt)
ref_result = run_and_time(saved_model_dir)
run_and_time(saved_model_dir_trt, ref_result)
for m in msgs:
  print(m)`


**Other info / logs**
using GDB:

gdb python
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1
Copyright (C) 2016 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type ""show copying""
and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...(no debugging symbols found)...done.
(gdb) run effi.py 
Starting program: /home/ubuntu/tf20/bin/python effi.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7ffff43e0700 (LWP 7815)]
[New Thread 0x7ffff3bdf700 (LWP 7816)]
[New Thread 0x7fffef3de700 (LWP 7817)]
[New Thread 0x7fffecbdd700 (LWP 7818)]
[New Thread 0x7fffea3dc700 (LWP 7819)]
[New Thread 0x7fffe7bdb700 (LWP 7820)]
[New Thread 0x7fffe53da700 (LWP 7821)]
[New Thread 0x7fffe2bd9700 (LWP 7822)]
[New Thread 0x7fffe03d8700 (LWP 7823)]
[New Thread 0x7fffddbd7700 (LWP 7824)]
[New Thread 0x7fffdd3d6700 (LWP 7825)]
[New Thread 0x7fffdabd5700 (LWP 7826)]
[New Thread 0x7fffda3d4700 (LWP 7827)]
[New Thread 0x7fffd5bd3700 (LWP 7828)]
[New Thread 0x7fffd33d2700 (LWP 7829)]
[Thread 0x7fffdd3d6700 (LWP 7825) exited]
[Thread 0x7fffddbd7700 (LWP 7824) exited]
[Thread 0x7fffe03d8700 (LWP 7823) exited]
[Thread 0x7fffe2bd9700 (LWP 7822) exited]
[Thread 0x7fffd5bd3700 (LWP 7828) exited]
[Thread 0x7fffda3d4700 (LWP 7827) exited]
[Thread 0x7fffdabd5700 (LWP 7826) exited]
[Thread 0x7fffe53da700 (LWP 7821) exited]
[Thread 0x7fffe7bdb700 (LWP 7820) exited]
[Thread 0x7fffd33d2700 (LWP 7829) exited]
[Thread 0x7fffea3dc700 (LWP 7819) exited]
[Thread 0x7fffecbdd700 (LWP 7818) exited]
[Thread 0x7fffef3de700 (LWP 7817) exited]
[Thread 0x7ffff3bdf700 (LWP 7816) exited]
[Thread 0x7ffff43e0700 (LWP 7815) exited]
[New Thread 0x7fffd33d2700 (LWP 7833)]
[New Thread 0x7fffd5bd3700 (LWP 7834)]
[New Thread 0x7fffda3d4700 (LWP 7835)]
[New Thread 0x7fffdabd5700 (LWP 7836)]
[New Thread 0x7fff7b306700 (LWP 7837)]
[New Thread 0x7fff78b05700 (LWP 7838)]
[New Thread 0x7fff76304700 (LWP 7839)]
[New Thread 0x7fff73b03700 (LWP 7840)]
[New Thread 0x7fff73302700 (LWP 7841)]
[New Thread 0x7fff70b01700 (LWP 7842)]
[New Thread 0x7fff6e300700 (LWP 7843)]
[New Thread 0x7fff6daff700 (LWP 7844)]
[New Thread 0x7fff672fe700 (LWP 7845)]
[New Thread 0x7fff64afd700 (LWP 7846)]
[New Thread 0x7fff642fc700 (LWP 7847)]
2019-11-10 08:50:49.862529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
[New Thread 0x7fff52cd2700 (LWP 7848)]
2019-11-10 08:50:49.866720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:50:49.867387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775
pciBusID: 0000:00:1e.0
2019-11-10 08:50:49.872638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-10 08:50:49.879677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-10 08:50:49.885164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-10 08:50:49.889850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-10 08:50:49.898681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-10 08:50:49.907196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-10 08:50:49.916626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-10 08:50:49.916725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:50:49.917360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:50:49.918021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-10 08:50:49.918338: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[New Thread 0x7fff52257700 (LWP 7849)]
[New Thread 0x7fff51a56700 (LWP 7850)]
[New Thread 0x7fff51255700 (LWP 7851)]
[New Thread 0x7fff50a54700 (LWP 7852)]
[New Thread 0x7fff0d9c1700 (LWP 7853)]
[New Thread 0x7fff0d1c0700 (LWP 7854)]
[New Thread 0x7fff0c9bf700 (LWP 7855)]
[New Thread 0x7ffeeffff700 (LWP 7856)]
[New Thread 0x7ffee7fff700 (LWP 7857)]
[New Thread 0x7ffeef7fe700 (LWP 7858)]
[New Thread 0x7ffeeeffd700 (LWP 7859)]
[New Thread 0x7ffeee7fc700 (LWP 7860)]
[New Thread 0x7ffeedffb700 (LWP 7861)]
[New Thread 0x7ffeed7fa700 (LWP 7862)]
[New Thread 0x7ffeecff9700 (LWP 7863)]
[New Thread 0x7ffee77fe700 (LWP 7864)]
[New Thread 0x7ffee6ffd700 (LWP 7865)]
[New Thread 0x7ffee67fc700 (LWP 7866)]
[New Thread 0x7ffee5ffb700 (LWP 7867)]
2019-11-10 08:50:49.927704: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300095000 Hz
[Thread 0x7ffee67fc700 (LWP 7866) exited]
[New Thread 0x7ffee67fc700 (LWP 7868)]
[New Thread 0x7ffee57fa700 (LWP 7869)]
[New Thread 0x7ffee4ff9700 (LWP 7870)]
[New Thread 0x7ffeaffff700 (LWP 7871)]
[New Thread 0x7ffeaf7fe700 (LWP 7872)]
[New Thread 0x7ffeaeffd700 (LWP 7873)]
[New Thread 0x7ffeae7fc700 (LWP 7874)]
[New Thread 0x7ffeadffb700 (LWP 7875)]
[New Thread 0x7ffead7fa700 (LWP 7876)]
[New Thread 0x7ffeacff9700 (LWP 7877)]
[New Thread 0x7ffe8ffff700 (LWP 7878)]
[New Thread 0x7ffe8f7fe700 (LWP 7879)]
[New Thread 0x7ffe8effd700 (LWP 7880)]
[New Thread 0x7ffe8e7fc700 (LWP 7881)]
[New Thread 0x7ffe8dffb700 (LWP 7882)]
[New Thread 0x7ffe8d7fa700 (LWP 7883)]
2019-11-10 08:50:49.929881: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5181b90 executing computations on platform Host. Devices:
2019-11-10 08:50:49.929908: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
[New Thread 0x7ffe8cff9700 (LWP 7884)]
[New Thread 0x7ffe6ffff700 (LWP 7885)]
[New Thread 0x7ffe6f7fe700 (LWP 7886)]
[New Thread 0x7ffe6effd700 (LWP 7887)]
[New Thread 0x7ffe6e7fc700 (LWP 7888)]
2019-11-10 08:50:49.991708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:50:49.992298: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x51c4a30 executing computations on platform CUDA. Devices:
2019-11-10 08:50:49.992329: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla M60, Compute Capability 5.2
[Thread 0x7ffe6f7fe700 (LWP 7886) exited]
2019-11-10 08:50:49.992513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:50:49.993023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775
pciBusID: 0000:00:1e.0
2019-11-10 08:50:49.993088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-10 08:50:49.993123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-10 08:50:49.993156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-10 08:50:49.993185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-10 08:50:49.993214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-10 08:50:49.993241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-10 08:50:49.993307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-10 08:50:49.993392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:50:49.993922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:50:49.994402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-10 08:50:49.994475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-10 08:50:49.995502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-10 08:50:49.995527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-10 08:50:49.995545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-10 08:50:49.995994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:50:49.996530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:50:49.997043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7162 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2)
[New Thread 0x7ffe6f7fe700 (LWP 7889)]
[New Thread 0x7ffe6dffb700 (LWP 7890)]
[New Thread 0x7ffe6d7fa700 (LWP 7891)]
[New Thread 0x7ffe6cff9700 (LWP 7892)]
[New Thread 0x7ffe4ffff700 (LWP 7893)]
[New Thread 0x7ffe4f7fe700 (LWP 7894)]
[New Thread 0x7ffe4effd700 (LWP 7895)]
[New Thread 0x7ffe4e7fc700 (LWP 7896)]
[New Thread 0x7ffe4dffb700 (LWP 7897)]
[New Thread 0x7ffe4d7fa700 (LWP 7898)]
[New Thread 0x7ffe4cff9700 (LWP 7899)]
[New Thread 0x7ffe2ffff700 (LWP 7900)]
[New Thread 0x7ffe2f7fe700 (LWP 7901)]
[New Thread 0x7ffe2effd700 (LWP 7902)]
[New Thread 0x7ffe2e7fc700 (LWP 7903)]
[New Thread 0x7ffe2dffb700 (LWP 7904)]
[New Thread 0x7ffe2d7fa700 (LWP 7905)]
[New Thread 0x7ffe2cff9700 (LWP 7906)]
[New Thread 0x7ffe07a4e700 (LWP 7907)]
[New Thread 0x7ffdf2027700 (LWP 7908)]
[Thread 0x7ffdf2027700 (LWP 7908) exited]
2019-11-10 08:51:09.523160: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING: Logging before flag parsing goes to stderr.
W1110 08:51:22.750380 140737353942784 deprecation.py:506] From /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2019-11-10 08:51:28.819439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.5
[New Thread 0x7ffdf2027700 (LWP 7909)]
[New Thread 0x7ffdd5d34700 (LWP 7910)]
[New Thread 0x7ffdcffff700 (LWP 7911)]
[Thread 0x7ffdcffff700 (LWP 7911) exited]
[Thread 0x7ffdd5d34700 (LWP 7910) exited]
[Thread 0x7ffdf2027700 (LWP 7909) exited]
[New Thread 0x7ffdcffff700 (LWP 7912)]
[New Thread 0x7ffdd5d34700 (LWP 7913)]
[New Thread 0x7ffdf2027700 (LWP 7914)]
[Thread 0x7ffdd5d34700 (LWP 7913) exited]
[Thread 0x7ffdcffff700 (LWP 7912) exited]
[Thread 0x7ffdf2027700 (LWP 7914) exited]
[New Thread 0x7ffdf2027700 (LWP 7915)]
[New Thread 0x7ffdd5d34700 (LWP 7916)]
[New Thread 0x7ffdcffff700 (LWP 7917)]
[Thread 0x7ffdcffff700 (LWP 7917) exited]
[Thread 0x7ffdf2027700 (LWP 7915) exited]
[Thread 0x7ffdd5d34700 (LWP 7916) exited]
[New Thread 0x7ffdcffff700 (LWP 7918)]
[New Thread 0x7ffdd5d34700 (LWP 7919)]
[New Thread 0x7ffdf2027700 (LWP 7920)]
[Thread 0x7ffdf2027700 (LWP 7920) exited]
[Thread 0x7ffdcffff700 (LWP 7918) exited]
[Thread 0x7ffdd5d34700 (LWP 7919) exited]
[New Thread 0x7ffdf2027700 (LWP 7921)]
[New Thread 0x7ffdd5d34700 (LWP 7922)]
[New Thread 0x7ffdcffff700 (LWP 7923)]
[Thread 0x7ffdd5d34700 (LWP 7922) exited]
[Thread 0x7ffdf2027700 (LWP 7921) exited]
[Thread 0x7ffdcffff700 (LWP 7923) exited]
[New Thread 0x7ffdcffff700 (LWP 7924)]
[New Thread 0x7ffdd5d34700 (LWP 7925)]
[New Thread 0x7ffdf2027700 (LWP 7926)]
[Thread 0x7ffdf2027700 (LWP 7926) exited]
[Thread 0x7ffdcffff700 (LWP 7924) exited]
[Thread 0x7ffdd5d34700 (LWP 7925) exited]
[New Thread 0x7ffdf2027700 (LWP 7927)]
[New Thread 0x7ffdd5d34700 (LWP 7928)]
[New Thread 0x7ffdcffff700 (LWP 7929)]
[Thread 0x7ffdcffff700 (LWP 7929) exited]
[Thread 0x7ffdf2027700 (LWP 7927) exited]
[Thread 0x7ffdd5d34700 (LWP 7928) exited]
[New Thread 0x7ffdcffff700 (LWP 7930)]
[New Thread 0x7ffdd5d34700 (LWP 7931)]
[New Thread 0x7ffdf2027700 (LWP 7932)]
[Thread 0x7ffdf2027700 (LWP 7932) exited]
[Thread 0x7ffdcffff700 (LWP 7930) exited]
[Thread 0x7ffdd5d34700 (LWP 7931) exited]
[New Thread 0x7ffdf2027700 (LWP 7933)]
[New Thread 0x7ffdd5d34700 (LWP 7934)]
[New Thread 0x7ffdcffff700 (LWP 7935)]
[Thread 0x7ffdcffff700 (LWP 7935) exited]
[Thread 0x7ffdf2027700 (LWP 7933) exited]
[Thread 0x7ffdd5d34700 (LWP 7934) exited]
[New Thread 0x7ffdcffff700 (LWP 7936)]
[New Thread 0x7ffdd5d34700 (LWP 7937)]
[New Thread 0x7ffdf2027700 (LWP 7938)]
[Thread 0x7ffdf2027700 (LWP 7938) exited]
[Thread 0x7ffdd5d34700 (LWP 7937) exited]
[Thread 0x7ffdcffff700 (LWP 7936) exited]
[New Thread 0x7ffdf2027700 (LWP 7939)]
[New Thread 0x7ffdd5d34700 (LWP 7940)]
[New Thread 0x7ffdcffff700 (LWP 7941)]
[Thread 0x7ffdcffff700 (LWP 7941) exited]
[Thread 0x7ffdf2027700 (LWP 7939) exited]
[Thread 0x7ffdd5d34700 (LWP 7940) exited]
[New Thread 0x7ffdcffff700 (LWP 7942)]
[New Thread 0x7ffdd5d34700 (LWP 7943)]
[New Thread 0x7ffdf2027700 (LWP 7944)]
[Thread 0x7ffdf2027700 (LWP 7944) exited]
[Thread 0x7ffdcffff700 (LWP 7942) exited]
[Thread 0x7ffdd5d34700 (LWP 7943) exited]
[New Thread 0x7ffdf2027700 (LWP 7945)]
[New Thread 0x7ffdd5d34700 (LWP 7946)]
[New Thread 0x7ffdcffff700 (LWP 7947)]
[Thread 0x7ffdcffff700 (LWP 7947) exited]
[Thread 0x7ffdf2027700 (LWP 7945) exited]
[Thread 0x7ffdd5d34700 (LWP 7946) exited]
[New Thread 0x7ffdcffff700 (LWP 7948)]
[New Thread 0x7ffdd5d34700 (LWP 7949)]
[New Thread 0x7ffdf2027700 (LWP 7950)]
[Thread 0x7ffdf2027700 (LWP 7950) exited]
[Thread 0x7ffdcffff700 (LWP 7948) exited]
[Thread 0x7ffdd5d34700 (LWP 7949) exited]
[New Thread 0x7ffdf2027700 (LWP 7951)]
[New Thread 0x7ffdd5d34700 (LWP 7952)]
[New Thread 0x7ffdcffff700 (LWP 7953)]
[Thread 0x7ffdcffff700 (LWP 7953) exited]
[Thread 0x7ffdf2027700 (LWP 7951) exited]
[Thread 0x7ffdd5d34700 (LWP 7952) exited]
[New Thread 0x7ffdcffff700 (LWP 7954)]
[New Thread 0x7ffdd5d34700 (LWP 7955)]
[New Thread 0x7ffdf2027700 (LWP 7956)]
[Thread 0x7ffdf2027700 (LWP 7956) exited]
[Thread 0x7ffdcffff700 (LWP 7954) exited]
[Thread 0x7ffdd5d34700 (LWP 7955) exited]
[New Thread 0x7ffdf2027700 (LWP 7957)]
[New Thread 0x7ffdd5d34700 (LWP 7958)]
[New Thread 0x7ffdcffff700 (LWP 7959)]
[Thread 0x7ffdcffff700 (LWP 7959) exited]
[Thread 0x7ffdf2027700 (LWP 7957) exited]
[Thread 0x7ffdd5d34700 (LWP 7958) exited]
[New Thread 0x7ffdcffff700 (LWP 7960)]
[New Thread 0x7ffdd5d34700 (LWP 7961)]
[New Thread 0x7ffdf2027700 (LWP 7962)]
[Thread 0x7ffdf2027700 (LWP 7962) exited]
[Thread 0x7ffdcffff700 (LWP 7960) exited]
[Thread 0x7ffdd5d34700 (LWP 7961) exited]
[New Thread 0x7ffdf2027700 (LWP 7963)]
[New Thread 0x7ffdd5d34700 (LWP 7964)]
[New Thread 0x7ffdcffff700 (LWP 7965)]
[Thread 0x7ffdcffff700 (LWP 7965) exited]
[Thread 0x7ffdf2027700 (LWP 7963) exited]
[Thread 0x7ffdd5d34700 (LWP 7964) exited]
[New Thread 0x7ffdcffff700 (LWP 7966)]
[New Thread 0x7ffdd5d34700 (LWP 7967)]
[New Thread 0x7ffdf2027700 (LWP 7968)]
[Thread 0x7ffdf2027700 (LWP 7968) exited]
[Thread 0x7ffdcffff700 (LWP 7966) exited]
[Thread 0x7ffdd5d34700 (LWP 7967) exited]
[New Thread 0x7ffdf2027700 (LWP 7969)]
[New Thread 0x7ffdd5d34700 (LWP 7970)]
[New Thread 0x7ffdcffff700 (LWP 7971)]
[Thread 0x7ffdcffff700 (LWP 7971) exited]
[Thread 0x7ffdf2027700 (LWP 7969) exited]
[Thread 0x7ffdd5d34700 (LWP 7970) exited]
[New Thread 0x7ffdcffff700 (LWP 7972)]
[New Thread 0x7ffdd5d34700 (LWP 7973)]
[New Thread 0x7ffdf2027700 (LWP 7974)]
[Thread 0x7ffdf2027700 (LWP 7974) exited]
[Thread 0x7ffdcffff700 (LWP 7972) exited]
[Thread 0x7ffdd5d34700 (LWP 7973) exited]
[New Thread 0x7ffdf2027700 (LWP 7975)]
[New Thread 0x7ffdd5d34700 (LWP 7976)]
[New Thread 0x7ffdcffff700 (LWP 7977)]
[Thread 0x7ffdcffff700 (LWP 7977) exited]
[Thread 0x7ffdf2027700 (LWP 7975) exited]
[Thread 0x7ffdd5d34700 (LWP 7976) exited]
[New Thread 0x7ffdcffff700 (LWP 7978)]
[New Thread 0x7ffdd5d34700 (LWP 7979)]
[New Thread 0x7ffdf2027700 (LWP 7980)]
[Thread 0x7ffdf2027700 (LWP 7980) exited]
[Thread 0x7ffdcffff700 (LWP 7978) exited]
[Thread 0x7ffdd5d34700 (LWP 7979) exited]
[New Thread 0x7ffdf2027700 (LWP 7981)]
[New Thread 0x7ffdd5d34700 (LWP 7982)]
[New Thread 0x7ffdcffff700 (LWP 7983)]
[Thread 0x7ffdcffff700 (LWP 7983) exited]
[Thread 0x7ffdf2027700 (LWP 7981) exited]
[Thread 0x7ffdd5d34700 (LWP 7982) exited]
[New Thread 0x7ffdcffff700 (LWP 7984)]
[New Thread 0x7ffdd5d34700 (LWP 7985)]
[New Thread 0x7ffdf2027700 (LWP 7986)]
[Thread 0x7ffdf2027700 (LWP 7986) exited]
[Thread 0x7ffdcffff700 (LWP 7984) exited]
[Thread 0x7ffdd5d34700 (LWP 7985) exited]
[New Thread 0x7ffdf2027700 (LWP 7987)]
[New Thread 0x7ffdd5d34700 (LWP 7988)]
[New Thread 0x7ffdcffff700 (LWP 7989)]
[Thread 0x7ffdcffff700 (LWP 7989) exited]
[Thread 0x7ffdf2027700 (LWP 7987) exited]
[Thread 0x7ffdd5d34700 (LWP 7988) exited]
[New Thread 0x7ffdcffff700 (LWP 7990)]
[New Thread 0x7ffdd5d34700 (LWP 7991)]
[New Thread 0x7ffdf2027700 (LWP 7992)]
[Thread 0x7ffdf2027700 (LWP 7992) exited]
[Thread 0x7ffdcffff700 (LWP 7990) exited]
[Thread 0x7ffdd5d34700 (LWP 7991) exited]
[New Thread 0x7ffdf2027700 (LWP 7993)]
[New Thread 0x7ffdd5d34700 (LWP 7994)]
[New Thread 0x7ffdcffff700 (LWP 7995)]
[Thread 0x7ffdcffff700 (LWP 7995) exited]
[Thread 0x7ffdd5d34700 (LWP 7994) exited]
[Thread 0x7ffdf2027700 (LWP 7993) exited]
[New Thread 0x7ffdcffff700 (LWP 7996)]
[New Thread 0x7ffdd5d34700 (LWP 7997)]
[New Thread 0x7ffdf2027700 (LWP 7998)]
[Thread 0x7ffdd5d34700 (LWP 7997) exited]
[Thread 0x7ffdcffff700 (LWP 7996) exited]
[Thread 0x7ffdf2027700 (LWP 7998) exited]
[New Thread 0x7ffdf2027700 (LWP 7999)]
[New Thread 0x7ffdd5d34700 (LWP 8000)]
[New Thread 0x7ffdcffff700 (LWP 8001)]
[Thread 0x7ffdcffff700 (LWP 8001) exited]
[Thread 0x7ffdf2027700 (LWP 7999) exited]
[Thread 0x7ffdd5d34700 (LWP 8000) exited]
[New Thread 0x7ffdcffff700 (LWP 8002)]
[New Thread 0x7ffdd5d34700 (LWP 8003)]
[New Thread 0x7ffdf2027700 (LWP 8004)]
[Thread 0x7ffdd5d34700 (LWP 8003) exited]
[Thread 0x7ffdcffff700 (LWP 8002) exited]
[Thread 0x7ffdf2027700 (LWP 8004) exited]
[New Thread 0x7ffdf2027700 (LWP 8005)]
[New Thread 0x7ffdd5d34700 (LWP 8006)]
[New Thread 0x7ffdcffff700 (LWP 8007)]
[Thread 0x7ffdcffff700 (LWP 8007) exited]
[Thread 0x7ffdf2027700 (LWP 8005) exited]
[Thread 0x7ffdd5d34700 (LWP 8006) exited]
[New Thread 0x7ffdcffff700 (LWP 8008)]
[New Thread 0x7ffdd5d34700 (LWP 8009)]
[New Thread 0x7ffdf2027700 (LWP 8010)]
[Thread 0x7ffdf2027700 (LWP 8010) exited]
[Thread 0x7ffdcffff700 (LWP 8008) exited]
[Thread 0x7ffdd5d34700 (LWP 8009) exited]
[New Thread 0x7ffdf2027700 (LWP 8011)]
[New Thread 0x7ffdd5d34700 (LWP 8012)]
[New Thread 0x7ffdcffff700 (LWP 8013)]
[Thread 0x7ffdcffff700 (LWP 8013) exited]
[Thread 0x7ffdf2027700 (LWP 8011) exited]
[Thread 0x7ffdd5d34700 (LWP 8012) exited]
[New Thread 0x7ffdcffff700 (LWP 8014)]
[New Thread 0x7ffdd5d34700 (LWP 8015)]
[New Thread 0x7ffdf2027700 (LWP 8016)]
[Thread 0x7ffdf2027700 (LWP 8016) exited]
[Thread 0x7ffdcffff700 (LWP 8014) exited]
[Thread 0x7ffdd5d34700 (LWP 8015) exited]
[New Thread 0x7ffdf2027700 (LWP 8017)]
[New Thread 0x7ffdd5d34700 (LWP 8018)]
[New Thread 0x7ffdcffff700 (LWP 8019)]
[Thread 0x7ffdd5d34700 (LWP 8018) exited]
[Thread 0x7ffdf2027700 (LWP 8017) exited]
[Thread 0x7ffdcffff700 (LWP 8019) exited]
[New Thread 0x7ffdcffff700 (LWP 8020)]
[New Thread 0x7ffdd5d34700 (LWP 8021)]
[New Thread 0x7ffdf2027700 (LWP 8022)]
[Thread 0x7ffdf2027700 (LWP 8022) exited]
[Thread 0x7ffdcffff700 (LWP 8020) exited]
[Thread 0x7ffdd5d34700 (LWP 8021) exited]
[New Thread 0x7ffdf2027700 (LWP 8023)]
[New Thread 0x7ffdd5d34700 (LWP 8024)]
[New Thread 0x7ffdcffff700 (LWP 8025)]
[Thread 0x7ffdcffff700 (LWP 8025) exited]
[Thread 0x7ffdf2027700 (LWP 8023) exited]
[Thread 0x7ffdd5d34700 (LWP 8024) exited]
[New Thread 0x7ffdcffff700 (LWP 8026)]
[New Thread 0x7ffdd5d34700 (LWP 8027)]
[New Thread 0x7ffdf2027700 (LWP 8028)]
[Thread 0x7ffdd5d34700 (LWP 8027) exited]
[Thread 0x7ffdcffff700 (LWP 8026) exited]
[Thread 0x7ffdf2027700 (LWP 8028) exited]
[New Thread 0x7ffdf2027700 (LWP 8029)]
[New Thread 0x7ffdd5d34700 (LWP 8030)]
[New Thread 0x7ffdcffff700 (LWP 8031)]
[Thread 0x7ffdcffff700 (LWP 8031) exited]
[Thread 0x7ffdf2027700 (LWP 8029) exited]
[Thread 0x7ffdd5d34700 (LWP 8030) exited]
[New Thread 0x7ffdcffff700 (LWP 8032)]
[New Thread 0x7ffdd5d34700 (LWP 8033)]
[New Thread 0x7ffdf2027700 (LWP 8034)]
[Thread 0x7ffdd5d34700 (LWP 8033) exited]
[Thread 0x7ffdcffff700 (LWP 8032) exited]
[Thread 0x7ffdf2027700 (LWP 8034) exited]
[New Thread 0x7ffdf2027700 (LWP 8035)]
[New Thread 0x7ffdd5d34700 (LWP 8036)]
[New Thread 0x7ffdcffff700 (LWP 8037)]
[Thread 0x7ffdcffff700 (LWP 8037) exited]
[Thread 0x7ffdf2027700 (LWP 8035) exited]
[Thread 0x7ffdd5d34700 (LWP 8036) exited]
[New Thread 0x7ffdcffff700 (LWP 8038)]
[New Thread 0x7ffdd5d34700 (LWP 8039)]
[New Thread 0x7ffdf2027700 (LWP 8040)]
[Thread 0x7ffdf2027700 (LWP 8040) exited]
[Thread 0x7ffdcffff700 (LWP 8038) exited]
[Thread 0x7ffdd5d34700 (LWP 8039) exited]
[New Thread 0x7ffdf2027700 (LWP 8041)]
[New Thread 0x7ffdd5d34700 (LWP 8042)]
[New Thread 0x7ffdcffff700 (LWP 8043)]
[Thread 0x7ffdcffff700 (LWP 8043) exited]
[Thread 0x7ffdf2027700 (LWP 8041) exited]
[Thread 0x7ffdd5d34700 (LWP 8042) exited]
[New Thread 0x7ffdcffff700 (LWP 8044)]
[New Thread 0x7ffdd5d34700 (LWP 8045)]
[New Thread 0x7ffdf2027700 (LWP 8046)]
[Thread 0x7ffdf2027700 (LWP 8046) exited]
[Thread 0x7ffdcffff700 (LWP 8044) exited]
[Thread 0x7ffdd5d34700 (LWP 8045) exited]
[New Thread 0x7ffdf2027700 (LWP 8047)]
[New Thread 0x7ffdd5d34700 (LWP 8048)]
[New Thread 0x7ffdcffff700 (LWP 8049)]
[Thread 0x7ffdd5d34700 (LWP 8048) exited]
[Thread 0x7ffdf2027700 (LWP 8047) exited]
[Thread 0x7ffdcffff700 (LWP 8049) exited]
[New Thread 0x7ffdcffff700 (LWP 8050)]
[New Thread 0x7ffdd5d34700 (LWP 8051)]
[New Thread 0x7ffdf2027700 (LWP 8052)]
[Thread 0x7ffdf2027700 (LWP 8052) exited]
[Thread 0x7ffdcffff700 (LWP 8050) exited]
[Thread 0x7ffdd5d34700 (LWP 8051) exited]
[New Thread 0x7ffdf2027700 (LWP 8053)]
[New Thread 0x7ffdd5d34700 (LWP 8054)]
[New Thread 0x7ffdcffff700 (LWP 8055)]
[Thread 0x7ffdcffff700 (LWP 8055) exited]
[Thread 0x7ffdf2027700 (LWP 8053) exited]
[Thread 0x7ffdd5d34700 (LWP 8054) exited]
[New Thread 0x7ffdcffff700 (LWP 8056)]
[New Thread 0x7ffdd5d34700 (LWP 8057)]
[New Thread 0x7ffdf2027700 (LWP 8058)]
[Thread 0x7ffdf2027700 (LWP 8058) exited]
[Thread 0x7ffdcffff700 (LWP 8056) exited]
[Thread 0x7ffdd5d34700 (LWP 8057) exited]
[New Thread 0x7ffdf2027700 (LWP 8059)]
[New Thread 0x7ffdd5d34700 (LWP 8060)]
[New Thread 0x7ffdcffff700 (LWP 8061)]
[Thread 0x7ffdcffff700 (LWP 8061) exited]
[Thread 0x7ffdf2027700 (LWP 8059) exited]
[Thread 0x7ffdd5d34700 (LWP 8060) exited]
[New Thread 0x7ffdcffff700 (LWP 8062)]
[New Thread 0x7ffdd5d34700 (LWP 8063)]
[New Thread 0x7ffdf2027700 (LWP 8064)]
[Thread 0x7ffdf2027700 (LWP 8064) exited]
[Thread 0x7ffdcffff700 (LWP 8062) exited]
[Thread 0x7ffdd5d34700 (LWP 8063) exited]
[New Thread 0x7ffdf2027700 (LWP 8065)]
[New Thread 0x7ffdd5d34700 (LWP 8066)]
[New Thread 0x7ffdcffff700 (LWP 8067)]
[Thread 0x7ffdcffff700 (LWP 8067) exited]
[Thread 0x7ffdf2027700 (LWP 8065) exited]
[Thread 0x7ffdd5d34700 (LWP 8066) exited]
[New Thread 0x7ffdcffff700 (LWP 8068)]
[New Thread 0x7ffdd5d34700 (LWP 8069)]
[New Thread 0x7ffdf2027700 (LWP 8070)]
[Thread 0x7ffdf2027700 (LWP 8070) exited]
[Thread 0x7ffdcffff700 (LWP 8068) exited]
[Thread 0x7ffdd5d34700 (LWP 8069) exited]
[New Thread 0x7ffdf2027700 (LWP 8071)]
[New Thread 0x7ffdd5d34700 (LWP 8072)]
[New Thread 0x7ffdcffff700 (LWP 8073)]
[Thread 0x7ffdcffff700 (LWP 8073) exited]
[Thread 0x7ffdf2027700 (LWP 8071) exited]
[Thread 0x7ffdd5d34700 (LWP 8072) exited]
[New Thread 0x7ffdcffff700 (LWP 8074)]
[New Thread 0x7ffdd5d34700 (LWP 8075)]
[New Thread 0x7ffdf2027700 (LWP 8076)]
[Thread 0x7ffdf2027700 (LWP 8076) exited]
[Thread 0x7ffdcffff700 (LWP 8074) exited]
[Thread 0x7ffdd5d34700 (LWP 8075) exited]
[New Thread 0x7ffdf2027700 (LWP 8077)]
[New Thread 0x7ffdd5d34700 (LWP 8078)]
[New Thread 0x7ffdcffff700 (LWP 8079)]
[Thread 0x7ffdcffff700 (LWP 8079) exited]
[Thread 0x7ffdf2027700 (LWP 8077) exited]
[Thread 0x7ffdd5d34700 (LWP 8078) exited]
[New Thread 0x7ffdcffff700 (LWP 8080)]
[New Thread 0x7ffdd5d34700 (LWP 8081)]
[New Thread 0x7ffdf2027700 (LWP 8082)]
[Thread 0x7ffdf2027700 (LWP 8082) exited]
[Thread 0x7ffdcffff700 (LWP 8080) exited]
[Thread 0x7ffdd5d34700 (LWP 8081) exited]
[New Thread 0x7ffdf2027700 (LWP 8083)]
[New Thread 0x7ffdd5d34700 (LWP 8084)]
[New Thread 0x7ffdcffff700 (LWP 8085)]
[Thread 0x7ffdcffff700 (LWP 8085) exited]
[Thread 0x7ffdf2027700 (LWP 8083) exited]
[Thread 0x7ffdd5d34700 (LWP 8084) exited]
[New Thread 0x7ffdcffff700 (LWP 8086)]
[New Thread 0x7ffdd5d34700 (LWP 8087)]
[New Thread 0x7ffdf2027700 (LWP 8088)]
[Thread 0x7ffdf2027700 (LWP 8088) exited]
[Thread 0x7ffdcffff700 (LWP 8086) exited]
[Thread 0x7ffdd5d34700 (LWP 8087) exited]
[New Thread 0x7ffdf2027700 (LWP 8089)]
[New Thread 0x7ffdd5d34700 (LWP 8090)]
[New Thread 0x7ffdcffff700 (LWP 8091)]
[Thread 0x7ffdcffff700 (LWP 8091) exited]
[Thread 0x7ffdd5d34700 (LWP 8090) exited]
[Thread 0x7ffdf2027700 (LWP 8089) exited]
[New Thread 0x7ffdcffff700 (LWP 8092)]
[New Thread 0x7ffdd5d34700 (LWP 8093)]
[New Thread 0x7ffdf2027700 (LWP 8094)]
[Thread 0x7ffdf2027700 (LWP 8094) exited]
[Thread 0x7ffdcffff700 (LWP 8092) exited]
[Thread 0x7ffdd5d34700 (LWP 8093) exited]
[New Thread 0x7ffdf2027700 (LWP 8095)]
[New Thread 0x7ffdd5d34700 (LWP 8096)]
[New Thread 0x7ffdcffff700 (LWP 8097)]
[Thread 0x7ffdcffff700 (LWP 8097) exited]
[Thread 0x7ffdf2027700 (LWP 8095) exited]
[Thread 0x7ffdd5d34700 (LWP 8096) exited]
[New Thread 0x7ffdcffff700 (LWP 8098)]
[New Thread 0x7ffdd5d34700 (LWP 8099)]
[New Thread 0x7ffdf2027700 (LWP 8100)]
[Thread 0x7ffdf2027700 (LWP 8100) exited]
[Thread 0x7ffdcffff700 (LWP 8098) exited]
[Thread 0x7ffdd5d34700 (LWP 8099) exited]
[New Thread 0x7ffdf2027700 (LWP 8101)]
[New Thread 0x7ffdd5d34700 (LWP 8102)]
[New Thread 0x7ffdcffff700 (LWP 8103)]
[Thread 0x7ffdcffff700 (LWP 8103) exited]
[Thread 0x7ffdf2027700 (LWP 8101) exited]
[Thread 0x7ffdd5d34700 (LWP 8102) exited]
[New Thread 0x7ffdcffff700 (LWP 8104)]
[New Thread 0x7ffdd5d34700 (LWP 8105)]
[New Thread 0x7ffdf2027700 (LWP 8106)]
[Thread 0x7ffdf2027700 (LWP 8106) exited]
[Thread 0x7ffdcffff700 (LWP 8104) exited]
[Thread 0x7ffdd5d34700 (LWP 8105) exited]
[New Thread 0x7ffdf2027700 (LWP 8107)]
[New Thread 0x7ffdd5d34700 (LWP 8108)]
[New Thread 0x7ffdcffff700 (LWP 8109)]
[Thread 0x7ffdcffff700 (LWP 8109) exited]
[Thread 0x7ffdf2027700 (LWP 8107) exited]
[Thread 0x7ffdd5d34700 (LWP 8108) exited]
[New Thread 0x7ffdcffff700 (LWP 8110)]
[New Thread 0x7ffdd5d34700 (LWP 8111)]
[New Thread 0x7ffdf2027700 (LWP 8112)]
[Thread 0x7ffdf2027700 (LWP 8112) exited]
[Thread 0x7ffdcffff700 (LWP 8110) exited]
[Thread 0x7ffdd5d34700 (LWP 8111) exited]
[New Thread 0x7ffdf2027700 (LWP 8113)]
[New Thread 0x7ffdd5d34700 (LWP 8114)]
[New Thread 0x7ffdcffff700 (LWP 8115)]
[Thread 0x7ffdcffff700 (LWP 8115) exited]
[Thread 0x7ffdf2027700 (LWP 8113) exited]
[Thread 0x7ffdd5d34700 (LWP 8114) exited]
[New Thread 0x7ffdcffff700 (LWP 8116)]
[New Thread 0x7ffdd5d34700 (LWP 8117)]
[New Thread 0x7ffdf2027700 (LWP 8118)]
[Thread 0x7ffdf2027700 (LWP 8118) exited]
[Thread 0x7ffdcffff700 (LWP 8116) exited]
[Thread 0x7ffdd5d34700 (LWP 8117) exited]
[New Thread 0x7ffdf2027700 (LWP 8119)]
[New Thread 0x7ffdd5d34700 (LWP 8120)]
[New Thread 0x7ffdcffff700 (LWP 8121)]
[Thread 0x7ffdcffff700 (LWP 8121) exited]
[Thread 0x7ffdf2027700 (LWP 8119) exited]
[Thread 0x7ffdd5d34700 (LWP 8120) exited]
[New Thread 0x7ffdcffff700 (LWP 8122)]
[New Thread 0x7ffdd5d34700 (LWP 8123)]
[New Thread 0x7ffdf2027700 (LWP 8124)]
[Thread 0x7ffdf2027700 (LWP 8124) exited]
[Thread 0x7ffdcffff700 (LWP 8122) exited]
[Thread 0x7ffdd5d34700 (LWP 8123) exited]
[New Thread 0x7ffdf2027700 (LWP 8125)]
[New Thread 0x7ffdd5d34700 (LWP 8126)]
[New Thread 0x7ffdcffff700 (LWP 8127)]
[Thread 0x7ffdcffff700 (LWP 8127) exited]
[Thread 0x7ffdf2027700 (LWP 8125) exited]
[Thread 0x7ffdd5d34700 (LWP 8126) exited]
[New Thread 0x7ffdcffff700 (LWP 8128)]
[New Thread 0x7ffdd5d34700 (LWP 8129)]
[New Thread 0x7ffdf2027700 (LWP 8130)]
[Thread 0x7ffdf2027700 (LWP 8130) exited]
[Thread 0x7ffdcffff700 (LWP 8128) exited]
[Thread 0x7ffdd5d34700 (LWP 8129) exited]
[New Thread 0x7ffdf2027700 (LWP 8131)]
[New Thread 0x7ffdd5d34700 (LWP 8132)]
[New Thread 0x7ffdcffff700 (LWP 8133)]
[Thread 0x7ffdcffff700 (LWP 8133) exited]
[Thread 0x7ffdf2027700 (LWP 8131) exited]
[Thread 0x7ffdd5d34700 (LWP 8132) exited]
[New Thread 0x7ffdcffff700 (LWP 8134)]
[New Thread 0x7ffdd5d34700 (LWP 8135)]
[New Thread 0x7ffdf2027700 (LWP 8136)]
[Thread 0x7ffdf2027700 (LWP 8136) exited]
[Thread 0x7ffdcffff700 (LWP 8134) exited]
[Thread 0x7ffdd5d34700 (LWP 8135) exited]
[New Thread 0x7ffdf2027700 (LWP 8137)]
[New Thread 0x7ffdd5d34700 (LWP 8138)]
[New Thread 0x7ffdcffff700 (LWP 8139)]
[Thread 0x7ffdcffff700 (LWP 8139) exited]
[Thread 0x7ffdf2027700 (LWP 8137) exited]
[Thread 0x7ffdd5d34700 (LWP 8138) exited]
[New Thread 0x7ffdcffff700 (LWP 8140)]
[New Thread 0x7ffdd5d34700 (LWP 8141)]
[New Thread 0x7ffdf2027700 (LWP 8142)]
[Thread 0x7ffdf2027700 (LWP 8142) exited]
[Thread 0x7ffdcffff700 (LWP 8140) exited]
[Thread 0x7ffdd5d34700 (LWP 8141) exited]
[New Thread 0x7ffdf2027700 (LWP 8143)]
[New Thread 0x7ffdd5d34700 (LWP 8144)]
[New Thread 0x7ffdcffff700 (LWP 8145)]
[Thread 0x7ffdcffff700 (LWP 8145) exited]
[Thread 0x7ffdf2027700 (LWP 8143) exited]
[Thread 0x7ffdd5d34700 (LWP 8144) exited]
[New Thread 0x7ffdcffff700 (LWP 8146)]
[New Thread 0x7ffdd5d34700 (LWP 8147)]
[New Thread 0x7ffdf2027700 (LWP 8148)]
[Thread 0x7ffdf2027700 (LWP 8148) exited]
[Thread 0x7ffdcffff700 (LWP 8146) exited]
[Thread 0x7ffdd5d34700 (LWP 8147) exited]
[New Thread 0x7ffdf2027700 (LWP 8149)]
[New Thread 0x7ffdd5d34700 (LWP 8150)]
[New Thread 0x7ffdcffff700 (LWP 8151)]
[Thread 0x7ffdcffff700 (LWP 8151) exited]
[Thread 0x7ffdf2027700 (LWP 8149) exited]
[Thread 0x7ffdd5d34700 (LWP 8150) exited]
[New Thread 0x7ffdcffff700 (LWP 8152)]
[New Thread 0x7ffdd5d34700 (LWP 8153)]
[New Thread 0x7ffdf2027700 (LWP 8154)]
[Thread 0x7ffdf2027700 (LWP 8154) exited]
[Thread 0x7ffdcffff700 (LWP 8152) exited]
[Thread 0x7ffdd5d34700 (LWP 8153) exited]
[New Thread 0x7ffdf2027700 (LWP 8155)]
[New Thread 0x7ffdd5d34700 (LWP 8156)]
[New Thread 0x7ffdcffff700 (LWP 8157)]
[Thread 0x7ffdcffff700 (LWP 8157) exited]
[Thread 0x7ffdf2027700 (LWP 8155) exited]
[Thread 0x7ffdd5d34700 (LWP 8156) exited]
[New Thread 0x7ffdcffff700 (LWP 8158)]
[New Thread 0x7ffdd5d34700 (LWP 8159)]
[New Thread 0x7ffdf2027700 (LWP 8160)]
[Thread 0x7ffdf2027700 (LWP 8160) exited]
[Thread 0x7ffdcffff700 (LWP 8158) exited]
[Thread 0x7ffdd5d34700 (LWP 8159) exited]
[New Thread 0x7ffdf2027700 (LWP 8161)]
[New Thread 0x7ffdd5d34700 (LWP 8162)]
[New Thread 0x7ffdcffff700 (LWP 8163)]
[Thread 0x7ffdcffff700 (LWP 8163) exited]
[Thread 0x7ffdf2027700 (LWP 8161) exited]
[Thread 0x7ffdd5d34700 (LWP 8162) exited]
[New Thread 0x7ffdcffff700 (LWP 8164)]
[New Thread 0x7ffdd5d34700 (LWP 8165)]
[New Thread 0x7ffdf2027700 (LWP 8166)]
[Thread 0x7ffdf2027700 (LWP 8166) exited]
[Thread 0x7ffdcffff700 (LWP 8164) exited]
[Thread 0x7ffdd5d34700 (LWP 8165) exited]
[New Thread 0x7ffdf2027700 (LWP 8167)]
[New Thread 0x7ffdd5d34700 (LWP 8168)]
[New Thread 0x7ffdcffff700 (LWP 8169)]
[Thread 0x7ffdcffff700 (LWP 8169) exited]
[Thread 0x7ffdf2027700 (LWP 8167) exited]
[Thread 0x7ffdd5d34700 (LWP 8168) exited]
[New Thread 0x7ffdcffff700 (LWP 8170)]
[New Thread 0x7ffdd5d34700 (LWP 8171)]
[New Thread 0x7ffdf2027700 (LWP 8172)]
[Thread 0x7ffdf2027700 (LWP 8172) exited]
[Thread 0x7ffdcffff700 (LWP 8170) exited]
[Thread 0x7ffdd5d34700 (LWP 8171) exited]
[New Thread 0x7ffdf2027700 (LWP 8173)]
[New Thread 0x7ffdd5d34700 (LWP 8174)]
[New Thread 0x7ffdcffff700 (LWP 8175)]
[Thread 0x7ffdcffff700 (LWP 8175) exited]
[Thread 0x7ffdf2027700 (LWP 8173) exited]
[Thread 0x7ffdd5d34700 (LWP 8174) exited]
[New Thread 0x7ffdcffff700 (LWP 8176)]
[New Thread 0x7ffdd5d34700 (LWP 8177)]
[New Thread 0x7ffdf2027700 (LWP 8178)]
[Thread 0x7ffdf2027700 (LWP 8178) exited]
[Thread 0x7ffdcffff700 (LWP 8176) exited]
[Thread 0x7ffdd5d34700 (LWP 8177) exited]
[New Thread 0x7ffdf2027700 (LWP 8179)]
[New Thread 0x7ffdd5d34700 (LWP 8180)]
[New Thread 0x7ffdcffff700 (LWP 8181)]
[Thread 0x7ffdcffff700 (LWP 8181) exited]
[Thread 0x7ffdf2027700 (LWP 8179) exited]
[Thread 0x7ffdd5d34700 (LWP 8180) exited]
[New Thread 0x7ffdcffff700 (LWP 8182)]
[New Thread 0x7ffdd5d34700 (LWP 8183)]
[New Thread 0x7ffdf2027700 (LWP 8184)]
[Thread 0x7ffdf2027700 (LWP 8184) exited]
[Thread 0x7ffdcffff700 (LWP 8182) exited]
[Thread 0x7ffdd5d34700 (LWP 8183) exited]
[New Thread 0x7ffdf2027700 (LWP 8185)]
[New Thread 0x7ffdd5d34700 (LWP 8186)]
[New Thread 0x7ffdcffff700 (LWP 8187)]
[Thread 0x7ffdcffff700 (LWP 8187) exited]
[Thread 0x7ffdf2027700 (LWP 8185) exited]
[Thread 0x7ffdd5d34700 (LWP 8186) exited]
[New Thread 0x7ffdcffff700 (LWP 8188)]
[New Thread 0x7ffdd5d34700 (LWP 8189)]
[New Thread 0x7ffdf2027700 (LWP 8190)]
[Thread 0x7ffdf2027700 (LWP 8190) exited]
[Thread 0x7ffdcffff700 (LWP 8188) exited]
[Thread 0x7ffdd5d34700 (LWP 8189) exited]
[New Thread 0x7ffdf2027700 (LWP 8191)]
[New Thread 0x7ffdd5d34700 (LWP 8192)]
[New Thread 0x7ffdcffff700 (LWP 8193)]
[Thread 0x7ffdcffff700 (LWP 8193) exited]
[Thread 0x7ffdf2027700 (LWP 8191) exited]
[Thread 0x7ffdd5d34700 (LWP 8192) exited]
[New Thread 0x7ffdcffff700 (LWP 8194)]
[New Thread 0x7ffdd5d34700 (LWP 8195)]
[New Thread 0x7ffdf2027700 (LWP 8196)]
[Thread 0x7ffdf2027700 (LWP 8196) exited]
[Thread 0x7ffdcffff700 (LWP 8194) exited]
[Thread 0x7ffdd5d34700 (LWP 8195) exited]
[New Thread 0x7ffdf2027700 (LWP 8197)]
[New Thread 0x7ffdd5d34700 (LWP 8198)]
[New Thread 0x7ffdcffff700 (LWP 8199)]
[Thread 0x7ffdcffff700 (LWP 8199) exited]
[Thread 0x7ffdf2027700 (LWP 8197) exited]
[Thread 0x7ffdd5d34700 (LWP 8198) exited]
[New Thread 0x7ffdcffff700 (LWP 8200)]
[New Thread 0x7ffdd5d34700 (LWP 8201)]
[New Thread 0x7ffdf2027700 (LWP 8202)]
[Thread 0x7ffdf2027700 (LWP 8202) exited]
[Thread 0x7ffdcffff700 (LWP 8200) exited]
[Thread 0x7ffdd5d34700 (LWP 8201) exited]
[New Thread 0x7ffdf2027700 (LWP 8203)]
[New Thread 0x7ffdd5d34700 (LWP 8204)]
[New Thread 0x7ffdcffff700 (LWP 8205)]
[Thread 0x7ffdcffff700 (LWP 8205) exited]
[Thread 0x7ffdf2027700 (LWP 8203) exited]
[Thread 0x7ffdd5d34700 (LWP 8204) exited]
[New Thread 0x7ffdcffff700 (LWP 8206)]
[New Thread 0x7ffdd5d34700 (LWP 8207)]
[New Thread 0x7ffdf2027700 (LWP 8208)]
[Thread 0x7ffdf2027700 (LWP 8208) exited]
[Thread 0x7ffdcffff700 (LWP 8206) exited]
[Thread 0x7ffdd5d34700 (LWP 8207) exited]
[New Thread 0x7ffdf2027700 (LWP 8209)]
[New Thread 0x7ffdd5d34700 (LWP 8210)]
[New Thread 0x7ffdcffff700 (LWP 8211)]
[Thread 0x7ffdcffff700 (LWP 8211) exited]
[Thread 0x7ffdf2027700 (LWP 8209) exited]
[Thread 0x7ffdd5d34700 (LWP 8210) exited]
[New Thread 0x7ffdcffff700 (LWP 8212)]
[New Thread 0x7ffdd5d34700 (LWP 8213)]
[New Thread 0x7ffdf2027700 (LWP 8214)]
[Thread 0x7ffdf2027700 (LWP 8214) exited]
[Thread 0x7ffdcffff700 (LWP 8212) exited]
[Thread 0x7ffdd5d34700 (LWP 8213) exited]
[New Thread 0x7ffdf2027700 (LWP 8215)]
[New Thread 0x7ffdd5d34700 (LWP 8216)]
[New Thread 0x7ffdcffff700 (LWP 8217)]
[Thread 0x7ffdcffff700 (LWP 8217) exited]
[Thread 0x7ffdf2027700 (LWP 8215) exited]
[Thread 0x7ffdd5d34700 (LWP 8216) exited]
[New Thread 0x7ffdcffff700 (LWP 8218)]
[New Thread 0x7ffdd5d34700 (LWP 8219)]
[New Thread 0x7ffdf2027700 (LWP 8220)]
[Thread 0x7ffdf2027700 (LWP 8220) exited]
[Thread 0x7ffdcffff700 (LWP 8218) exited]
[Thread 0x7ffdd5d34700 (LWP 8219) exited]
[New Thread 0x7ffdf2027700 (LWP 8221)]
[New Thread 0x7ffdd5d34700 (LWP 8222)]
[New Thread 0x7ffdcffff700 (LWP 8223)]
[Thread 0x7ffdcffff700 (LWP 8223) exited]
[Thread 0x7ffdf2027700 (LWP 8221) exited]
[Thread 0x7ffdd5d34700 (LWP 8222) exited]
[New Thread 0x7ffdcffff700 (LWP 8224)]
[New Thread 0x7ffdd5d34700 (LWP 8225)]
[New Thread 0x7ffdf2027700 (LWP 8226)]
[Thread 0x7ffdf2027700 (LWP 8226) exited]
[Thread 0x7ffdcffff700 (LWP 8224) exited]
[Thread 0x7ffdd5d34700 (LWP 8225) exited]
[New Thread 0x7ffdf2027700 (LWP 8227)]
[New Thread 0x7ffdd5d34700 (LWP 8228)]
[New Thread 0x7ffdcffff700 (LWP 8229)]
[Thread 0x7ffdcffff700 (LWP 8229) exited]
[Thread 0x7ffdf2027700 (LWP 8227) exited]
[Thread 0x7ffdd5d34700 (LWP 8228) exited]
[New Thread 0x7ffdcffff700 (LWP 8230)]
[New Thread 0x7ffdd5d34700 (LWP 8231)]
[New Thread 0x7ffdf2027700 (LWP 8232)]
[Thread 0x7ffdf2027700 (LWP 8232) exited]
[Thread 0x7ffdcffff700 (LWP 8230) exited]
[Thread 0x7ffdd5d34700 (LWP 8231) exited]
[New Thread 0x7ffdf2027700 (LWP 8233)]
[New Thread 0x7ffdd5d34700 (LWP 8234)]
[New Thread 0x7ffdcffff700 (LWP 8235)]
[Thread 0x7ffdcffff700 (LWP 8235) exited]
[Thread 0x7ffdf2027700 (LWP 8233) exited]
[Thread 0x7ffdd5d34700 (LWP 8234) exited]
[New Thread 0x7ffdcffff700 (LWP 8236)]
[New Thread 0x7ffdd5d34700 (LWP 8237)]
[New Thread 0x7ffdf2027700 (LWP 8238)]
[Thread 0x7ffdf2027700 (LWP 8238) exited]
[Thread 0x7ffdcffff700 (LWP 8236) exited]
[Thread 0x7ffdd5d34700 (LWP 8237) exited]
[New Thread 0x7ffdf2027700 (LWP 8239)]
[New Thread 0x7ffdd5d34700 (LWP 8240)]
[New Thread 0x7ffdcffff700 (LWP 8241)]
[Thread 0x7ffdcffff700 (LWP 8241) exited]
[Thread 0x7ffdf2027700 (LWP 8239) exited]
[Thread 0x7ffdd5d34700 (LWP 8240) exited]
[New Thread 0x7ffdcffff700 (LWP 8242)]
[New Thread 0x7ffdd5d34700 (LWP 8243)]
[New Thread 0x7ffdf2027700 (LWP 8244)]
[Thread 0x7ffdf2027700 (LWP 8244) exited]
[Thread 0x7ffdcffff700 (LWP 8242) exited]
[Thread 0x7ffdd5d34700 (LWP 8243) exited]
[New Thread 0x7ffdf2027700 (LWP 8245)]
[New Thread 0x7ffdd5d34700 (LWP 8246)]
[New Thread 0x7ffdcffff700 (LWP 8247)]
[Thread 0x7ffdcffff700 (LWP 8247) exited]
[Thread 0x7ffdf2027700 (LWP 8245) exited]
[Thread 0x7ffdd5d34700 (LWP 8246) exited]
[New Thread 0x7ffdcffff700 (LWP 8248)]
[New Thread 0x7ffdd5d34700 (LWP 8249)]
[New Thread 0x7ffdf2027700 (LWP 8250)]
[Thread 0x7ffdf2027700 (LWP 8250) exited]
[Thread 0x7ffdcffff700 (LWP 8248) exited]
[Thread 0x7ffdd5d34700 (LWP 8249) exited]
[New Thread 0x7ffdf2027700 (LWP 8251)]
[New Thread 0x7ffdd5d34700 (LWP 8252)]
[New Thread 0x7ffdcffff700 (LWP 8253)]
[Thread 0x7ffdcffff700 (LWP 8253) exited]
[Thread 0x7ffdf2027700 (LWP 8251) exited]
[Thread 0x7ffdd5d34700 (LWP 8252) exited]
[New Thread 0x7ffdcffff700 (LWP 8254)]
[New Thread 0x7ffdd5d34700 (LWP 8255)]
[New Thread 0x7ffdf2027700 (LWP 8256)]
[Thread 0x7ffdf2027700 (LWP 8256) exited]
[Thread 0x7ffdcffff700 (LWP 8254) exited]
[Thread 0x7ffdd5d34700 (LWP 8255) exited]
[New Thread 0x7ffdf2027700 (LWP 8257)]
[New Thread 0x7ffdd5d34700 (LWP 8258)]
[New Thread 0x7ffdcffff700 (LWP 8259)]
[Thread 0x7ffdcffff700 (LWP 8259) exited]
[Thread 0x7ffdf2027700 (LWP 8257) exited]
[Thread 0x7ffdd5d34700 (LWP 8258) exited]
[New Thread 0x7ffdcffff700 (LWP 8260)]
[New Thread 0x7ffdd5d34700 (LWP 8261)]
[New Thread 0x7ffdf2027700 (LWP 8262)]
[Thread 0x7ffdf2027700 (LWP 8262) exited]
[Thread 0x7ffdcffff700 (LWP 8260) exited]
[Thread 0x7ffdd5d34700 (LWP 8261) exited]
[New Thread 0x7ffdf2027700 (LWP 8263)]
[New Thread 0x7ffdd5d34700 (LWP 8264)]
[New Thread 0x7ffdcffff700 (LWP 8265)]
[Thread 0x7ffdcffff700 (LWP 8265) exited]
[Thread 0x7ffdf2027700 (LWP 8263) exited]
[Thread 0x7ffdd5d34700 (LWP 8264) exited]
[New Thread 0x7ffdcffff700 (LWP 8266)]
[New Thread 0x7ffdd5d34700 (LWP 8267)]
[New Thread 0x7ffdf2027700 (LWP 8268)]
[Thread 0x7ffdf2027700 (LWP 8268) exited]
[Thread 0x7ffdcffff700 (LWP 8266) exited]
[Thread 0x7ffdd5d34700 (LWP 8267) exited]
[New Thread 0x7ffdf2027700 (LWP 8269)]
[New Thread 0x7ffdd5d34700 (LWP 8270)]
[New Thread 0x7ffdcffff700 (LWP 8271)]
[Thread 0x7ffdcffff700 (LWP 8271) exited]
[Thread 0x7ffdf2027700 (LWP 8269) exited]
[Thread 0x7ffdd5d34700 (LWP 8270) exited]
[New Thread 0x7ffdcffff700 (LWP 8272)]
[New Thread 0x7ffdd5d34700 (LWP 8273)]
[New Thread 0x7ffdf2027700 (LWP 8274)]
[Thread 0x7ffdf2027700 (LWP 8274) exited]
[Thread 0x7ffdcffff700 (LWP 8272) exited]
[Thread 0x7ffdd5d34700 (LWP 8273) exited]
[New Thread 0x7ffdf2027700 (LWP 8275)]
[New Thread 0x7ffdd5d34700 (LWP 8276)]
[New Thread 0x7ffdcffff700 (LWP 8277)]
[Thread 0x7ffdcffff700 (LWP 8277) exited]
[Thread 0x7ffdf2027700 (LWP 8275) exited]
[Thread 0x7ffdd5d34700 (LWP 8276) exited]
[New Thread 0x7ffdcffff700 (LWP 8278)]
[New Thread 0x7ffdd5d34700 (LWP 8279)]
[New Thread 0x7ffdf2027700 (LWP 8280)]
[Thread 0x7ffdf2027700 (LWP 8280) exited]
[Thread 0x7ffdcffff700 (LWP 8278) exited]
[Thread 0x7ffdd5d34700 (LWP 8279) exited]
[New Thread 0x7ffdf2027700 (LWP 8281)]
[New Thread 0x7ffdd5d34700 (LWP 8282)]
[New Thread 0x7ffdcffff700 (LWP 8283)]
[Thread 0x7ffdcffff700 (LWP 8283) exited]
[Thread 0x7ffdf2027700 (LWP 8281) exited]
[Thread 0x7ffdd5d34700 (LWP 8282) exited]
[New Thread 0x7ffdcffff700 (LWP 8284)]
[New Thread 0x7ffdd5d34700 (LWP 8285)]
[New Thread 0x7ffdf2027700 (LWP 8286)]
[Thread 0x7ffdf2027700 (LWP 8286) exited]
[Thread 0x7ffdcffff700 (LWP 8284) exited]
[Thread 0x7ffdd5d34700 (LWP 8285) exited]
[New Thread 0x7ffdf2027700 (LWP 8287)]
[New Thread 0x7ffdd5d34700 (LWP 8288)]
[New Thread 0x7ffdcffff700 (LWP 8289)]
[Thread 0x7ffdcffff700 (LWP 8289) exited]
[Thread 0x7ffdf2027700 (LWP 8287) exited]
[Thread 0x7ffdd5d34700 (LWP 8288) exited]
[New Thread 0x7ffdcffff700 (LWP 8290)]
[New Thread 0x7ffdd5d34700 (LWP 8291)]
[New Thread 0x7ffdf2027700 (LWP 8292)]
[Thread 0x7ffdf2027700 (LWP 8292) exited]
[Thread 0x7ffdcffff700 (LWP 8290) exited]
[Thread 0x7ffdd5d34700 (LWP 8291) exited]
[New Thread 0x7ffdf2027700 (LWP 8293)]
[New Thread 0x7ffdd5d34700 (LWP 8294)]
[New Thread 0x7ffdcffff700 (LWP 8295)]
[Thread 0x7ffdcffff700 (LWP 8295) exited]
[Thread 0x7ffdf2027700 (LWP 8293) exited]
[Thread 0x7ffdd5d34700 (LWP 8294) exited]
[New Thread 0x7ffdcffff700 (LWP 8296)]
[New Thread 0x7ffdd5d34700 (LWP 8297)]
[New Thread 0x7ffdf2027700 (LWP 8298)]
[Thread 0x7ffdf2027700 (LWP 8298) exited]
[Thread 0x7ffdcffff700 (LWP 8296) exited]
[Thread 0x7ffdd5d34700 (LWP 8297) exited]
[New Thread 0x7ffdf2027700 (LWP 8299)]
[New Thread 0x7ffdd5d34700 (LWP 8300)]
[New Thread 0x7ffdcffff700 (LWP 8301)]
[Thread 0x7ffdcffff700 (LWP 8301) exited]
[Thread 0x7ffdf2027700 (LWP 8299) exited]
[Thread 0x7ffdd5d34700 (LWP 8300) exited]
[New Thread 0x7ffdcffff700 (LWP 8302)]
[New Thread 0x7ffdd5d34700 (LWP 8303)]
[New Thread 0x7ffdf2027700 (LWP 8304)]
[Thread 0x7ffdf2027700 (LWP 8304) exited]
[Thread 0x7ffdcffff700 (LWP 8302) exited]
[Thread 0x7ffdd5d34700 (LWP 8303) exited]
[New Thread 0x7ffdf2027700 (LWP 8305)]
[New Thread 0x7ffdd5d34700 (LWP 8306)]
[New Thread 0x7ffdcffff700 (LWP 8307)]
[Thread 0x7ffdcffff700 (LWP 8307) exited]
[Thread 0x7ffdf2027700 (LWP 8305) exited]
[Thread 0x7ffdd5d34700 (LWP 8306) exited]
[New Thread 0x7ffdcffff700 (LWP 8308)]
[New Thread 0x7ffdd5d34700 (LWP 8309)]
[New Thread 0x7ffdf2027700 (LWP 8310)]
[Thread 0x7ffdf2027700 (LWP 8310) exited]
[Thread 0x7ffdcffff700 (LWP 8308) exited]
[Thread 0x7ffdd5d34700 (LWP 8309) exited]
[New Thread 0x7ffdf2027700 (LWP 8311)]
[New Thread 0x7ffdd5d34700 (LWP 8312)]
[New Thread 0x7ffdcffff700 (LWP 8313)]
[Thread 0x7ffdcffff700 (LWP 8313) exited]
[Thread 0x7ffdf2027700 (LWP 8311) exited]
[Thread 0x7ffdd5d34700 (LWP 8312) exited]
[New Thread 0x7ffdcffff700 (LWP 8314)]
[New Thread 0x7ffdd5d34700 (LWP 8315)]
[New Thread 0x7ffdf2027700 (LWP 8316)]
[Thread 0x7ffdf2027700 (LWP 8316) exited]
[Thread 0x7ffdcffff700 (LWP 8314) exited]
[Thread 0x7ffdd5d34700 (LWP 8315) exited]
[New Thread 0x7ffdf2027700 (LWP 8317)]
[New Thread 0x7ffdd5d34700 (LWP 8318)]
[New Thread 0x7ffdcffff700 (LWP 8319)]
[Thread 0x7ffdcffff700 (LWP 8319) exited]
[Thread 0x7ffdf2027700 (LWP 8317) exited]
[Thread 0x7ffdd5d34700 (LWP 8318) exited]
[New Thread 0x7ffdcffff700 (LWP 8320)]
[New Thread 0x7ffdd5d34700 (LWP 8321)]
[New Thread 0x7ffdf2027700 (LWP 8322)]
[Thread 0x7ffdf2027700 (LWP 8322) exited]
[Thread 0x7ffdcffff700 (LWP 8320) exited]
[Thread 0x7ffdd5d34700 (LWP 8321) exited]
[New Thread 0x7ffdf2027700 (LWP 8323)]
[New Thread 0x7ffdd5d34700 (LWP 8324)]
[New Thread 0x7ffdcffff700 (LWP 8325)]
[Thread 0x7ffdcffff700 (LWP 8325) exited]
[Thread 0x7ffdf2027700 (LWP 8323) exited]
[Thread 0x7ffdd5d34700 (LWP 8324) exited]
[New Thread 0x7ffdcffff700 (LWP 8326)]
[New Thread 0x7ffdd5d34700 (LWP 8327)]
[New Thread 0x7ffdf2027700 (LWP 8328)]
[Thread 0x7ffdf2027700 (LWP 8328) exited]
[Thread 0x7ffdcffff700 (LWP 8326) exited]
[Thread 0x7ffdd5d34700 (LWP 8327) exited]
[New Thread 0x7ffdf2027700 (LWP 8329)]
[New Thread 0x7ffdd5d34700 (LWP 8330)]
[New Thread 0x7ffdcffff700 (LWP 8331)]
[Thread 0x7ffdcffff700 (LWP 8331) exited]
[Thread 0x7ffdf2027700 (LWP 8329) exited]
[Thread 0x7ffdd5d34700 (LWP 8330) exited]
[New Thread 0x7ffdcffff700 (LWP 8332)]
[New Thread 0x7ffdd5d34700 (LWP 8333)]
[New Thread 0x7ffdf2027700 (LWP 8334)]
[Thread 0x7ffdf2027700 (LWP 8334) exited]
[Thread 0x7ffdcffff700 (LWP 8332) exited]
[Thread 0x7ffdd5d34700 (LWP 8333) exited]
[New Thread 0x7ffdf2027700 (LWP 8335)]
[New Thread 0x7ffdd5d34700 (LWP 8336)]
[New Thread 0x7ffdcffff700 (LWP 8337)]
[Thread 0x7ffdcffff700 (LWP 8337) exited]
[Thread 0x7ffdf2027700 (LWP 8335) exited]
[Thread 0x7ffdd5d34700 (LWP 8336) exited]
[New Thread 0x7ffdcffff700 (LWP 8338)]
[New Thread 0x7ffdd5d34700 (LWP 8339)]
[New Thread 0x7ffdf2027700 (LWP 8340)]
[Thread 0x7ffdf2027700 (LWP 8340) exited]
[Thread 0x7ffdcffff700 (LWP 8338) exited]
[Thread 0x7ffdd5d34700 (LWP 8339) exited]
[New Thread 0x7ffdf2027700 (LWP 8341)]
[New Thread 0x7ffdd5d34700 (LWP 8342)]
[New Thread 0x7ffdcffff700 (LWP 8343)]
[Thread 0x7ffdcffff700 (LWP 8343) exited]
[Thread 0x7ffdf2027700 (LWP 8341) exited]
[Thread 0x7ffdd5d34700 (LWP 8342) exited]
[New Thread 0x7ffdcffff700 (LWP 8344)]
[New Thread 0x7ffdd5d34700 (LWP 8345)]
[New Thread 0x7ffdf2027700 (LWP 8346)]
[Thread 0x7ffdf2027700 (LWP 8346) exited]
[Thread 0x7ffdcffff700 (LWP 8344) exited]
[Thread 0x7ffdd5d34700 (LWP 8345) exited]
[New Thread 0x7ffdf2027700 (LWP 8347)]
[New Thread 0x7ffdd5d34700 (LWP 8348)]
[New Thread 0x7ffdcffff700 (LWP 8349)]
[Thread 0x7ffdcffff700 (LWP 8349) exited]
[Thread 0x7ffdf2027700 (LWP 8347) exited]
[Thread 0x7ffdd5d34700 (LWP 8348) exited]
[New Thread 0x7ffdcffff700 (LWP 8350)]
[New Thread 0x7ffdd5d34700 (LWP 8351)]
[New Thread 0x7ffdf2027700 (LWP 8352)]
[Thread 0x7ffdf2027700 (LWP 8352) exited]
[Thread 0x7ffdcffff700 (LWP 8350) exited]
[Thread 0x7ffdd5d34700 (LWP 8351) exited]
[New Thread 0x7ffdf2027700 (LWP 8353)]
[New Thread 0x7ffdd5d34700 (LWP 8354)]
[New Thread 0x7ffdcffff700 (LWP 8355)]
[Thread 0x7ffdcffff700 (LWP 8355) exited]
[Thread 0x7ffdf2027700 (LWP 8353) exited]
[Thread 0x7ffdd5d34700 (LWP 8354) exited]
[New Thread 0x7ffdcffff700 (LWP 8356)]
[New Thread 0x7ffdd5d34700 (LWP 8357)]
[New Thread 0x7ffdf2027700 (LWP 8358)]
[Thread 0x7ffdf2027700 (LWP 8358) exited]
[Thread 0x7ffdcffff700 (LWP 8356) exited]
[Thread 0x7ffdd5d34700 (LWP 8357) exited]
[New Thread 0x7ffdf2027700 (LWP 8359)]
[New Thread 0x7ffdd5d34700 (LWP 8360)]
[New Thread 0x7ffdcffff700 (LWP 8361)]
[Thread 0x7ffdcffff700 (LWP 8361) exited]
[Thread 0x7ffdf2027700 (LWP 8359) exited]
[Thread 0x7ffdd5d34700 (LWP 8360) exited]
[New Thread 0x7ffdcffff700 (LWP 8362)]
[New Thread 0x7ffdd5d34700 (LWP 8363)]
[New Thread 0x7ffdf2027700 (LWP 8364)]
[Thread 0x7ffdf2027700 (LWP 8364) exited]
[Thread 0x7ffdcffff700 (LWP 8362) exited]
[Thread 0x7ffdd5d34700 (LWP 8363) exited]
[New Thread 0x7ffdf2027700 (LWP 8365)]
[New Thread 0x7ffdd5d34700 (LWP 8366)]
[New Thread 0x7ffdcffff700 (LWP 8367)]
[Thread 0x7ffdcffff700 (LWP 8367) exited]
[Thread 0x7ffdf2027700 (LWP 8365) exited]
[Thread 0x7ffdd5d34700 (LWP 8366) exited]
[New Thread 0x7ffdcffff700 (LWP 8368)]
[New Thread 0x7ffdd5d34700 (LWP 8369)]
[New Thread 0x7ffdf2027700 (LWP 8370)]
[Thread 0x7ffdf2027700 (LWP 8370) exited]
[Thread 0x7ffdcffff700 (LWP 8368) exited]
[Thread 0x7ffdd5d34700 (LWP 8369) exited]
[New Thread 0x7ffdf2027700 (LWP 8371)]
[New Thread 0x7ffdd5d34700 (LWP 8372)]
[New Thread 0x7ffdcffff700 (LWP 8373)]
[Thread 0x7ffdcffff700 (LWP 8373) exited]
[Thread 0x7ffdf2027700 (LWP 8371) exited]
[Thread 0x7ffdd5d34700 (LWP 8372) exited]
[New Thread 0x7ffdcffff700 (LWP 8374)]
[New Thread 0x7ffdd5d34700 (LWP 8375)]
[New Thread 0x7ffdf2027700 (LWP 8376)]
[Thread 0x7ffdf2027700 (LWP 8376) exited]
[Thread 0x7ffdcffff700 (LWP 8374) exited]
[Thread 0x7ffdd5d34700 (LWP 8375) exited]
[New Thread 0x7ffdf2027700 (LWP 8377)]
[New Thread 0x7ffdd5d34700 (LWP 8378)]
[New Thread 0x7ffdcffff700 (LWP 8379)]
[Thread 0x7ffdcffff700 (LWP 8379) exited]
[Thread 0x7ffdf2027700 (LWP 8377) exited]
[Thread 0x7ffdd5d34700 (LWP 8378) exited]
[New Thread 0x7ffdcffff700 (LWP 8380)]
[New Thread 0x7ffdd5d34700 (LWP 8381)]
[New Thread 0x7ffdf2027700 (LWP 8382)]
[Thread 0x7ffdf2027700 (LWP 8382) exited]
[Thread 0x7ffdcffff700 (LWP 8380) exited]
[Thread 0x7ffdd5d34700 (LWP 8381) exited]
[New Thread 0x7ffdf2027700 (LWP 8383)]
[New Thread 0x7ffdd5d34700 (LWP 8384)]
[New Thread 0x7ffdcffff700 (LWP 8385)]
[Thread 0x7ffdcffff700 (LWP 8385) exited]
[Thread 0x7ffdf2027700 (LWP 8383) exited]
[Thread 0x7ffdd5d34700 (LWP 8384) exited]
[New Thread 0x7ffdcffff700 (LWP 8386)]
[New Thread 0x7ffdd5d34700 (LWP 8387)]
[New Thread 0x7ffdf2027700 (LWP 8388)]
[Thread 0x7ffdf2027700 (LWP 8388) exited]
[Thread 0x7ffdcffff700 (LWP 8386) exited]
[Thread 0x7ffdd5d34700 (LWP 8387) exited]
[New Thread 0x7ffdf2027700 (LWP 8389)]
[New Thread 0x7ffdd5d34700 (LWP 8390)]
[New Thread 0x7ffdcffff700 (LWP 8391)]
[Thread 0x7ffdcffff700 (LWP 8391) exited]
[Thread 0x7ffdf2027700 (LWP 8389) exited]
[Thread 0x7ffdd5d34700 (LWP 8390) exited]
[New Thread 0x7ffdcffff700 (LWP 8392)]
[New Thread 0x7ffdd5d34700 (LWP 8393)]
[New Thread 0x7ffdf2027700 (LWP 8394)]
[Thread 0x7ffdf2027700 (LWP 8394) exited]
[Thread 0x7ffdcffff700 (LWP 8392) exited]
[Thread 0x7ffdd5d34700 (LWP 8393) exited]
[New Thread 0x7ffdf2027700 (LWP 8395)]
[New Thread 0x7ffdd5d34700 (LWP 8396)]
[New Thread 0x7ffdcffff700 (LWP 8397)]
[Thread 0x7ffdcffff700 (LWP 8397) exited]
[Thread 0x7ffdf2027700 (LWP 8395) exited]
[Thread 0x7ffdd5d34700 (LWP 8396) exited]
[New Thread 0x7ffdcffff700 (LWP 8398)]
[New Thread 0x7ffdd5d34700 (LWP 8399)]
[New Thread 0x7ffdf2027700 (LWP 8400)]
[Thread 0x7ffdf2027700 (LWP 8400) exited]
[Thread 0x7ffdcffff700 (LWP 8398) exited]
[Thread 0x7ffdd5d34700 (LWP 8399) exited]
[New Thread 0x7ffdf2027700 (LWP 8401)]
[New Thread 0x7ffdd5d34700 (LWP 8402)]
[New Thread 0x7ffdcffff700 (LWP 8403)]
[Thread 0x7ffdcffff700 (LWP 8403) exited]
[Thread 0x7ffdf2027700 (LWP 8401) exited]
[Thread 0x7ffdd5d34700 (LWP 8402) exited]
[New Thread 0x7ffdcffff700 (LWP 8404)]
[New Thread 0x7ffdd5d34700 (LWP 8405)]
[New Thread 0x7ffdf2027700 (LWP 8406)]
[Thread 0x7ffdf2027700 (LWP 8406) exited]
[Thread 0x7ffdcffff700 (LWP 8404) exited]
[Thread 0x7ffdd5d34700 (LWP 8405) exited]
[New Thread 0x7ffdf2027700 (LWP 8407)]
[New Thread 0x7ffdd5d34700 (LWP 8408)]
[New Thread 0x7ffdcffff700 (LWP 8409)]
[Thread 0x7ffdcffff700 (LWP 8409) exited]
[Thread 0x7ffdf2027700 (LWP 8407) exited]
[Thread 0x7ffdd5d34700 (LWP 8408) exited]
[New Thread 0x7ffdcffff700 (LWP 8410)]
[New Thread 0x7ffdd5d34700 (LWP 8411)]
[New Thread 0x7ffdf2027700 (LWP 8412)]
[Thread 0x7ffdf2027700 (LWP 8412) exited]
[Thread 0x7ffdcffff700 (LWP 8410) exited]
[Thread 0x7ffdd5d34700 (LWP 8411) exited]
[New Thread 0x7ffdf2027700 (LWP 8413)]
[New Thread 0x7ffdd5d34700 (LWP 8414)]
[New Thread 0x7ffdcffff700 (LWP 8415)]
[Thread 0x7ffdcffff700 (LWP 8415) exited]
[Thread 0x7ffdf2027700 (LWP 8413) exited]
[Thread 0x7ffdd5d34700 (LWP 8414) exited]
[New Thread 0x7ffdcffff700 (LWP 8416)]
[New Thread 0x7ffdd5d34700 (LWP 8417)]
[New Thread 0x7ffdf2027700 (LWP 8418)]
[Thread 0x7ffdf2027700 (LWP 8418) exited]
[Thread 0x7ffdcffff700 (LWP 8416) exited]
[Thread 0x7ffdd5d34700 (LWP 8417) exited]
[New Thread 0x7ffdf2027700 (LWP 8419)]
[New Thread 0x7ffdd5d34700 (LWP 8420)]
[New Thread 0x7ffdcffff700 (LWP 8421)]
[Thread 0x7ffdcffff700 (LWP 8421) exited]
[Thread 0x7ffdf2027700 (LWP 8419) exited]
[Thread 0x7ffdd5d34700 (LWP 8420) exited]
[New Thread 0x7ffdcffff700 (LWP 8422)]
[New Thread 0x7ffdd5d34700 (LWP 8423)]
[New Thread 0x7ffdf2027700 (LWP 8424)]
[Thread 0x7ffdf2027700 (LWP 8424) exited]
[Thread 0x7ffdcffff700 (LWP 8422) exited]
[Thread 0x7ffdd5d34700 (LWP 8423) exited]
[New Thread 0x7ffdf2027700 (LWP 8425)]
[New Thread 0x7ffdd5d34700 (LWP 8426)]
[New Thread 0x7ffdcffff700 (LWP 8427)]
[Thread 0x7ffdcffff700 (LWP 8427) exited]
[Thread 0x7ffdf2027700 (LWP 8425) exited]
[Thread 0x7ffdd5d34700 (LWP 8426) exited]
[New Thread 0x7ffdcffff700 (LWP 8428)]
[New Thread 0x7ffdd5d34700 (LWP 8429)]
[New Thread 0x7ffdf2027700 (LWP 8430)]
[Thread 0x7ffdf2027700 (LWP 8430) exited]
[Thread 0x7ffdcffff700 (LWP 8428) exited]
[Thread 0x7ffdd5d34700 (LWP 8429) exited]
[New Thread 0x7ffdf2027700 (LWP 8431)]
[New Thread 0x7ffdd5d34700 (LWP 8432)]
[New Thread 0x7ffdcffff700 (LWP 8433)]
[Thread 0x7ffdcffff700 (LWP 8433) exited]
[Thread 0x7ffdf2027700 (LWP 8431) exited]
[Thread 0x7ffdd5d34700 (LWP 8432) exited]
[New Thread 0x7ffdcffff700 (LWP 8434)]
[New Thread 0x7ffdd5d34700 (LWP 8435)]
[New Thread 0x7ffdf2027700 (LWP 8436)]
[Thread 0x7ffdf2027700 (LWP 8436) exited]
[Thread 0x7ffdcffff700 (LWP 8434) exited]
[Thread 0x7ffdd5d34700 (LWP 8435) exited]
[New Thread 0x7ffdf2027700 (LWP 8437)]
[New Thread 0x7ffdd5d34700 (LWP 8438)]
[New Thread 0x7ffdcffff700 (LWP 8439)]
[Thread 0x7ffdcffff700 (LWP 8439) exited]
[Thread 0x7ffdf2027700 (LWP 8437) exited]
[Thread 0x7ffdd5d34700 (LWP 8438) exited]
[New Thread 0x7ffdcffff700 (LWP 8440)]
[New Thread 0x7ffdd5d34700 (LWP 8441)]
[New Thread 0x7ffdf2027700 (LWP 8442)]
[Thread 0x7ffdf2027700 (LWP 8442) exited]
[Thread 0x7ffdcffff700 (LWP 8440) exited]
[Thread 0x7ffdd5d34700 (LWP 8441) exited]
[New Thread 0x7ffdf2027700 (LWP 8443)]
[New Thread 0x7ffdd5d34700 (LWP 8444)]
[New Thread 0x7ffdcffff700 (LWP 8445)]
[Thread 0x7ffdcffff700 (LWP 8445) exited]
[Thread 0x7ffdf2027700 (LWP 8443) exited]
[Thread 0x7ffdd5d34700 (LWP 8444) exited]
[New Thread 0x7ffdcffff700 (LWP 8446)]
[New Thread 0x7ffdd5d34700 (LWP 8447)]
[New Thread 0x7ffdf2027700 (LWP 8448)]
[Thread 0x7ffdf2027700 (LWP 8448) exited]
[Thread 0x7ffdcffff700 (LWP 8446) exited]
[Thread 0x7ffdd5d34700 (LWP 8447) exited]
[New Thread 0x7ffdf2027700 (LWP 8449)]
[New Thread 0x7ffdd5d34700 (LWP 8450)]
[New Thread 0x7ffdcffff700 (LWP 8451)]
[Thread 0x7ffdcffff700 (LWP 8451) exited]
[Thread 0x7ffdf2027700 (LWP 8449) exited]
[Thread 0x7ffdd5d34700 (LWP 8450) exited]
[New Thread 0x7ffdcffff700 (LWP 8452)]
[New Thread 0x7ffdd5d34700 (LWP 8453)]
[New Thread 0x7ffdf2027700 (LWP 8454)]
[Thread 0x7ffdf2027700 (LWP 8454) exited]
[Thread 0x7ffdcffff700 (LWP 8452) exited]
[Thread 0x7ffdd5d34700 (LWP 8453) exited]
[New Thread 0x7ffdf2027700 (LWP 8455)]
[New Thread 0x7ffdd5d34700 (LWP 8456)]
[New Thread 0x7ffdcffff700 (LWP 8457)]
[Thread 0x7ffdcffff700 (LWP 8457) exited]
[Thread 0x7ffdf2027700 (LWP 8455) exited]
[Thread 0x7ffdd5d34700 (LWP 8456) exited]
[New Thread 0x7ffdcffff700 (LWP 8458)]
[New Thread 0x7ffdd5d34700 (LWP 8459)]
[New Thread 0x7ffdf2027700 (LWP 8460)]
[Thread 0x7ffdf2027700 (LWP 8460) exited]
[Thread 0x7ffdcffff700 (LWP 8458) exited]
[Thread 0x7ffdd5d34700 (LWP 8459) exited]
[New Thread 0x7ffdf2027700 (LWP 8461)]
[New Thread 0x7ffdd5d34700 (LWP 8462)]
[New Thread 0x7ffdcffff700 (LWP 8463)]
[Thread 0x7ffdcffff700 (LWP 8463) exited]
[Thread 0x7ffdf2027700 (LWP 8461) exited]
[Thread 0x7ffdd5d34700 (LWP 8462) exited]
[New Thread 0x7ffdcffff700 (LWP 8464)]
[New Thread 0x7ffdd5d34700 (LWP 8465)]
[New Thread 0x7ffdf2027700 (LWP 8466)]
[Thread 0x7ffdf2027700 (LWP 8466) exited]
[Thread 0x7ffdcffff700 (LWP 8464) exited]
[Thread 0x7ffdd5d34700 (LWP 8465) exited]
[New Thread 0x7ffdf2027700 (LWP 8467)]
[New Thread 0x7ffdd5d34700 (LWP 8468)]
[New Thread 0x7ffdcffff700 (LWP 8469)]
[Thread 0x7ffdcffff700 (LWP 8469) exited]
[Thread 0x7ffdf2027700 (LWP 8467) exited]
[Thread 0x7ffdd5d34700 (LWP 8468) exited]
[New Thread 0x7ffdcffff700 (LWP 8470)]
[New Thread 0x7ffdd5d34700 (LWP 8471)]
[New Thread 0x7ffdf2027700 (LWP 8472)]
[Thread 0x7ffdf2027700 (LWP 8472) exited]
[Thread 0x7ffdcffff700 (LWP 8470) exited]
[Thread 0x7ffdd5d34700 (LWP 8471) exited]
[New Thread 0x7ffdf2027700 (LWP 8473)]
[New Thread 0x7ffdd5d34700 (LWP 8474)]
[New Thread 0x7ffdcffff700 (LWP 8475)]
[Thread 0x7ffdcffff700 (LWP 8475) exited]
[Thread 0x7ffdf2027700 (LWP 8473) exited]
[Thread 0x7ffdd5d34700 (LWP 8474) exited]
[New Thread 0x7ffdcffff700 (LWP 8476)]
[New Thread 0x7ffdd5d34700 (LWP 8477)]
[New Thread 0x7ffdf2027700 (LWP 8478)]
[Thread 0x7ffdf2027700 (LWP 8478) exited]
[Thread 0x7ffdcffff700 (LWP 8476) exited]
[Thread 0x7ffdd5d34700 (LWP 8477) exited]
[New Thread 0x7ffdf2027700 (LWP 8479)]
[New Thread 0x7ffdd5d34700 (LWP 8480)]
[New Thread 0x7ffdcffff700 (LWP 8481)]
[Thread 0x7ffdcffff700 (LWP 8481) exited]
[Thread 0x7ffdf2027700 (LWP 8479) exited]
[Thread 0x7ffdd5d34700 (LWP 8480) exited]
[New Thread 0x7ffdcffff700 (LWP 8482)]
[New Thread 0x7ffdd5d34700 (LWP 8483)]
[New Thread 0x7ffdf2027700 (LWP 8484)]
[Thread 0x7ffdf2027700 (LWP 8484) exited]
[Thread 0x7ffdcffff700 (LWP 8482) exited]
[Thread 0x7ffdd5d34700 (LWP 8483) exited]
[New Thread 0x7ffdf2027700 (LWP 8485)]
[New Thread 0x7ffdd5d34700 (LWP 8486)]
[New Thread 0x7ffdcffff700 (LWP 8487)]
[Thread 0x7ffdcffff700 (LWP 8487) exited]
[Thread 0x7ffdf2027700 (LWP 8485) exited]
[Thread 0x7ffdd5d34700 (LWP 8486) exited]
[New Thread 0x7ffdcffff700 (LWP 8488)]
[New Thread 0x7ffdd5d34700 (LWP 8489)]
[New Thread 0x7ffdf2027700 (LWP 8490)]
[Thread 0x7ffdf2027700 (LWP 8490) exited]
[Thread 0x7ffdcffff700 (LWP 8488) exited]
[Thread 0x7ffdd5d34700 (LWP 8489) exited]
[New Thread 0x7ffdf2027700 (LWP 8491)]
[New Thread 0x7ffdd5d34700 (LWP 8492)]
[New Thread 0x7ffdcffff700 (LWP 8493)]
[Thread 0x7ffdcffff700 (LWP 8493) exited]
[Thread 0x7ffdf2027700 (LWP 8491) exited]
[Thread 0x7ffdd5d34700 (LWP 8492) exited]
[New Thread 0x7ffdcffff700 (LWP 8494)]
[New Thread 0x7ffdd5d34700 (LWP 8495)]
[New Thread 0x7ffdf2027700 (LWP 8496)]
[Thread 0x7ffdf2027700 (LWP 8496) exited]
[Thread 0x7ffdcffff700 (LWP 8494) exited]
[Thread 0x7ffdd5d34700 (LWP 8495) exited]
[New Thread 0x7ffdf2027700 (LWP 8497)]
[New Thread 0x7ffdd5d34700 (LWP 8498)]
[New Thread 0x7ffdcffff700 (LWP 8499)]
[Thread 0x7ffdcffff700 (LWP 8499) exited]
[Thread 0x7ffdf2027700 (LWP 8497) exited]
[Thread 0x7ffdd5d34700 (LWP 8498) exited]
[New Thread 0x7ffdcffff700 (LWP 8500)]
[New Thread 0x7ffdd5d34700 (LWP 8501)]
[New Thread 0x7ffdf2027700 (LWP 8502)]
[Thread 0x7ffdf2027700 (LWP 8502) exited]
[Thread 0x7ffdcffff700 (LWP 8500) exited]
[Thread 0x7ffdd5d34700 (LWP 8501) exited]
[New Thread 0x7ffdf2027700 (LWP 8503)]
[New Thread 0x7ffdd5d34700 (LWP 8504)]
[New Thread 0x7ffdcffff700 (LWP 8505)]
[Thread 0x7ffdcffff700 (LWP 8505) exited]
[Thread 0x7ffdf2027700 (LWP 8503) exited]
[Thread 0x7ffdd5d34700 (LWP 8504) exited]
[New Thread 0x7ffdcffff700 (LWP 8506)]
[New Thread 0x7ffdd5d34700 (LWP 8507)]
[New Thread 0x7ffdf2027700 (LWP 8508)]
[Thread 0x7ffdf2027700 (LWP 8508) exited]
[Thread 0x7ffdcffff700 (LWP 8506) exited]
[Thread 0x7ffdd5d34700 (LWP 8507) exited]
[New Thread 0x7ffdf2027700 (LWP 8509)]
[New Thread 0x7ffdd5d34700 (LWP 8510)]
[New Thread 0x7ffdcffff700 (LWP 8511)]
[Thread 0x7ffdcffff700 (LWP 8511) exited]
[Thread 0x7ffdf2027700 (LWP 8509) exited]
[Thread 0x7ffdd5d34700 (LWP 8510) exited]
[New Thread 0x7ffdcffff700 (LWP 8512)]
[New Thread 0x7ffdd5d34700 (LWP 8513)]
[New Thread 0x7ffdf2027700 (LWP 8514)]
[Thread 0x7ffdf2027700 (LWP 8514) exited]
[Thread 0x7ffdcffff700 (LWP 8512) exited]
[Thread 0x7ffdd5d34700 (LWP 8513) exited]
[New Thread 0x7ffdf2027700 (LWP 8515)]
[New Thread 0x7ffdd5d34700 (LWP 8516)]
[New Thread 0x7ffdcffff700 (LWP 8517)]
[Thread 0x7ffdcffff700 (LWP 8517) exited]
[Thread 0x7ffdf2027700 (LWP 8515) exited]
[Thread 0x7ffdd5d34700 (LWP 8516) exited]
[New Thread 0x7ffdcffff700 (LWP 8518)]
[New Thread 0x7ffdd5d34700 (LWP 8519)]
[New Thread 0x7ffdf2027700 (LWP 8520)]
[Thread 0x7ffdf2027700 (LWP 8520) exited]
[Thread 0x7ffdcffff700 (LWP 8518) exited]
[Thread 0x7ffdd5d34700 (LWP 8519) exited]
[New Thread 0x7ffdf2027700 (LWP 8521)]
[New Thread 0x7ffdd5d34700 (LWP 8522)]
[New Thread 0x7ffdcffff700 (LWP 8523)]
[Thread 0x7ffdcffff700 (LWP 8523) exited]
[Thread 0x7ffdf2027700 (LWP 8521) exited]
[Thread 0x7ffdd5d34700 (LWP 8522) exited]
[New Thread 0x7ffdcffff700 (LWP 8524)]
[New Thread 0x7ffdd5d34700 (LWP 8525)]
[New Thread 0x7ffdf2027700 (LWP 8526)]
[Thread 0x7ffdf2027700 (LWP 8526) exited]
[Thread 0x7ffdcffff700 (LWP 8524) exited]
[Thread 0x7ffdd5d34700 (LWP 8525) exited]
[New Thread 0x7ffdf2027700 (LWP 8527)]
[New Thread 0x7ffdd5d34700 (LWP 8528)]
[New Thread 0x7ffdcffff700 (LWP 8529)]
[Thread 0x7ffdcffff700 (LWP 8529) exited]
[Thread 0x7ffdf2027700 (LWP 8527) exited]
[Thread 0x7ffdd5d34700 (LWP 8528) exited]
[New Thread 0x7ffdcffff700 (LWP 8530)]
[New Thread 0x7ffdd5d34700 (LWP 8531)]
[New Thread 0x7ffdf2027700 (LWP 8532)]
[Thread 0x7ffdf2027700 (LWP 8532) exited]
[Thread 0x7ffdcffff700 (LWP 8530) exited]
[Thread 0x7ffdd5d34700 (LWP 8531) exited]
[New Thread 0x7ffdf2027700 (LWP 8533)]
[New Thread 0x7ffdd5d34700 (LWP 8534)]
[New Thread 0x7ffdcffff700 (LWP 8535)]
[Thread 0x7ffdcffff700 (LWP 8535) exited]
[Thread 0x7ffdf2027700 (LWP 8533) exited]
[Thread 0x7ffdd5d34700 (LWP 8534) exited]
[New Thread 0x7ffdcffff700 (LWP 8536)]
[New Thread 0x7ffdd5d34700 (LWP 8537)]
[New Thread 0x7ffdf2027700 (LWP 8538)]
[Thread 0x7ffdf2027700 (LWP 8538) exited]
[Thread 0x7ffdcffff700 (LWP 8536) exited]
[Thread 0x7ffdd5d34700 (LWP 8537) exited]
[New Thread 0x7ffdf2027700 (LWP 8539)]
[New Thread 0x7ffdd5d34700 (LWP 8540)]
[New Thread 0x7ffdcffff700 (LWP 8541)]
[Thread 0x7ffdcffff700 (LWP 8541) exited]
[Thread 0x7ffdf2027700 (LWP 8539) exited]
[Thread 0x7ffdd5d34700 (LWP 8540) exited]
[New Thread 0x7ffdcffff700 (LWP 8542)]
[New Thread 0x7ffdd5d34700 (LWP 8543)]
[New Thread 0x7ffdf2027700 (LWP 8544)]
[Thread 0x7ffdf2027700 (LWP 8544) exited]
[Thread 0x7ffdcffff700 (LWP 8542) exited]
[Thread 0x7ffdd5d34700 (LWP 8543) exited]
[New Thread 0x7ffdf2027700 (LWP 8545)]
[New Thread 0x7ffdd5d34700 (LWP 8546)]
[New Thread 0x7ffdcffff700 (LWP 8547)]
[Thread 0x7ffdcffff700 (LWP 8547) exited]
[Thread 0x7ffdf2027700 (LWP 8545) exited]
[Thread 0x7ffdd5d34700 (LWP 8546) exited]
[New Thread 0x7ffdcffff700 (LWP 8548)]
[New Thread 0x7ffdd5d34700 (LWP 8549)]
[New Thread 0x7ffdf2027700 (LWP 8550)]
[Thread 0x7ffdf2027700 (LWP 8550) exited]
[Thread 0x7ffdcffff700 (LWP 8548) exited]
[Thread 0x7ffdd5d34700 (LWP 8549) exited]
[New Thread 0x7ffdf2027700 (LWP 8551)]
[New Thread 0x7ffdd5d34700 (LWP 8552)]
[New Thread 0x7ffdcffff700 (LWP 8553)]
[Thread 0x7ffdcffff700 (LWP 8553) exited]
[Thread 0x7ffdf2027700 (LWP 8551) exited]
[Thread 0x7ffdd5d34700 (LWP 8552) exited]
[New Thread 0x7ffdcffff700 (LWP 8554)]
[New Thread 0x7ffdd5d34700 (LWP 8555)]
[New Thread 0x7ffdf2027700 (LWP 8556)]
[Thread 0x7ffdf2027700 (LWP 8556) exited]
[Thread 0x7ffdcffff700 (LWP 8554) exited]
[Thread 0x7ffdd5d34700 (LWP 8555) exited]
[New Thread 0x7ffdf2027700 (LWP 8557)]
[New Thread 0x7ffdd5d34700 (LWP 8558)]
[New Thread 0x7ffdcffff700 (LWP 8559)]
[Thread 0x7ffdcffff700 (LWP 8559) exited]
[Thread 0x7ffdf2027700 (LWP 8557) exited]
[Thread 0x7ffdd5d34700 (LWP 8558) exited]
[New Thread 0x7ffdcffff700 (LWP 8560)]
[New Thread 0x7ffdd5d34700 (LWP 8561)]
[New Thread 0x7ffdf2027700 (LWP 8562)]
[Thread 0x7ffdf2027700 (LWP 8562) exited]
[Thread 0x7ffdcffff700 (LWP 8560) exited]
[Thread 0x7ffdd5d34700 (LWP 8561) exited]
[New Thread 0x7ffdf2027700 (LWP 8563)]
[New Thread 0x7ffdd5d34700 (LWP 8564)]
[New Thread 0x7ffdcffff700 (LWP 8565)]
[Thread 0x7ffdcffff700 (LWP 8565) exited]
[Thread 0x7ffdf2027700 (LWP 8563) exited]
[Thread 0x7ffdd5d34700 (LWP 8564) exited]
[New Thread 0x7ffdcffff700 (LWP 8566)]
[New Thread 0x7ffdd5d34700 (LWP 8567)]
[New Thread 0x7ffdf2027700 (LWP 8568)]
[Thread 0x7ffdf2027700 (LWP 8568) exited]
[Thread 0x7ffdcffff700 (LWP 8566) exited]
[Thread 0x7ffdd5d34700 (LWP 8567) exited]
[New Thread 0x7ffdf2027700 (LWP 8569)]
[New Thread 0x7ffdd5d34700 (LWP 8570)]
[New Thread 0x7ffdcffff700 (LWP 8571)]
[Thread 0x7ffdcffff700 (LWP 8571) exited]
[Thread 0x7ffdf2027700 (LWP 8569) exited]
[Thread 0x7ffdd5d34700 (LWP 8570) exited]
[New Thread 0x7ffdcffff700 (LWP 8572)]
[New Thread 0x7ffdd5d34700 (LWP 8573)]
[New Thread 0x7ffdf2027700 (LWP 8574)]
[Thread 0x7ffdf2027700 (LWP 8574) exited]
[Thread 0x7ffdcffff700 (LWP 8572) exited]
[Thread 0x7ffdd5d34700 (LWP 8573) exited]
[New Thread 0x7ffdf2027700 (LWP 8575)]
[New Thread 0x7ffdd5d34700 (LWP 8576)]
[New Thread 0x7ffdcffff700 (LWP 8577)]
[Thread 0x7ffdcffff700 (LWP 8577) exited]
[Thread 0x7ffdf2027700 (LWP 8575) exited]
[Thread 0x7ffdd5d34700 (LWP 8576) exited]
[New Thread 0x7ffdcffff700 (LWP 8578)]
[New Thread 0x7ffdd5d34700 (LWP 8579)]
[New Thread 0x7ffdf2027700 (LWP 8580)]
[Thread 0x7ffdf2027700 (LWP 8580) exited]
[Thread 0x7ffdcffff700 (LWP 8578) exited]
[Thread 0x7ffdd5d34700 (LWP 8579) exited]
[New Thread 0x7ffdf2027700 (LWP 8581)]
[New Thread 0x7ffdd5d34700 (LWP 8582)]
[New Thread 0x7ffdcffff700 (LWP 8583)]
[Thread 0x7ffdcffff700 (LWP 8583) exited]
[Thread 0x7ffdf2027700 (LWP 8581) exited]
[Thread 0x7ffdd5d34700 (LWP 8582) exited]
[New Thread 0x7ffdcffff700 (LWP 8584)]
[New Thread 0x7ffdd5d34700 (LWP 8585)]
[New Thread 0x7ffdf2027700 (LWP 8586)]
[Thread 0x7ffdf2027700 (LWP 8586) exited]
[Thread 0x7ffdcffff700 (LWP 8584) exited]
[Thread 0x7ffdd5d34700 (LWP 8585) exited]
[New Thread 0x7ffdf2027700 (LWP 8587)]
[New Thread 0x7ffdd5d34700 (LWP 8588)]
[New Thread 0x7ffdcffff700 (LWP 8589)]
[Thread 0x7ffdcffff700 (LWP 8589) exited]
[Thread 0x7ffdf2027700 (LWP 8587) exited]
[Thread 0x7ffdd5d34700 (LWP 8588) exited]
[New Thread 0x7ffdcffff700 (LWP 8590)]
[New Thread 0x7ffdd5d34700 (LWP 8591)]
[New Thread 0x7ffdf2027700 (LWP 8592)]
[Thread 0x7ffdf2027700 (LWP 8592) exited]
[Thread 0x7ffdcffff700 (LWP 8590) exited]
[Thread 0x7ffdd5d34700 (LWP 8591) exited]
[New Thread 0x7ffdf2027700 (LWP 8593)]
[New Thread 0x7ffdd5d34700 (LWP 8594)]
[New Thread 0x7ffdcffff700 (LWP 8595)]
[Thread 0x7ffdcffff700 (LWP 8595) exited]
[Thread 0x7ffdf2027700 (LWP 8593) exited]
[Thread 0x7ffdd5d34700 (LWP 8594) exited]
[New Thread 0x7ffdcffff700 (LWP 8596)]
[New Thread 0x7ffdd5d34700 (LWP 8597)]
[New Thread 0x7ffdf2027700 (LWP 8598)]
[Thread 0x7ffdf2027700 (LWP 8598) exited]
[Thread 0x7ffdcffff700 (LWP 8596) exited]
[Thread 0x7ffdd5d34700 (LWP 8597) exited]
[New Thread 0x7ffdf2027700 (LWP 8599)]
[New Thread 0x7ffdd5d34700 (LWP 8600)]
[New Thread 0x7ffdcffff700 (LWP 8601)]
[Thread 0x7ffdcffff700 (LWP 8601) exited]
[Thread 0x7ffdf2027700 (LWP 8599) exited]
[Thread 0x7ffdd5d34700 (LWP 8600) exited]
[New Thread 0x7ffdcffff700 (LWP 8602)]
[New Thread 0x7ffdd5d34700 (LWP 8603)]
[New Thread 0x7ffdf2027700 (LWP 8604)]
[Thread 0x7ffdf2027700 (LWP 8604) exited]
[Thread 0x7ffdcffff700 (LWP 8602) exited]
[Thread 0x7ffdd5d34700 (LWP 8603) exited]
[New Thread 0x7ffdf2027700 (LWP 8605)]
[New Thread 0x7ffdd5d34700 (LWP 8606)]
[New Thread 0x7ffdcffff700 (LWP 8607)]
[Thread 0x7ffdcffff700 (LWP 8607) exited]
[Thread 0x7ffdf2027700 (LWP 8605) exited]
[Thread 0x7ffdd5d34700 (LWP 8606) exited]
[New Thread 0x7ffdcffff700 (LWP 8608)]
[New Thread 0x7ffdd5d34700 (LWP 8609)]
[New Thread 0x7ffdf2027700 (LWP 8610)]
[Thread 0x7ffdf2027700 (LWP 8610) exited]
[Thread 0x7ffdcffff700 (LWP 8608) exited]
[Thread 0x7ffdd5d34700 (LWP 8609) exited]
[New Thread 0x7ffdf2027700 (LWP 8611)]
[New Thread 0x7ffdd5d34700 (LWP 8612)]
[New Thread 0x7ffdcffff700 (LWP 8613)]
[Thread 0x7ffdcffff700 (LWP 8613) exited]
[Thread 0x7ffdf2027700 (LWP 8611) exited]
[Thread 0x7ffdd5d34700 (LWP 8612) exited]
[New Thread 0x7ffdcffff700 (LWP 8614)]
[New Thread 0x7ffdd5d34700 (LWP 8615)]
[New Thread 0x7ffdf2027700 (LWP 8616)]
[Thread 0x7ffdf2027700 (LWP 8616) exited]
[Thread 0x7ffdd5d34700 (LWP 8615) exited]
[Thread 0x7ffdcffff700 (LWP 8614) exited]
[New Thread 0x7ffdf2027700 (LWP 8617)]
[New Thread 0x7ffdd5d34700 (LWP 8618)]
[New Thread 0x7ffdcffff700 (LWP 8619)]
[Thread 0x7ffdcffff700 (LWP 8619) exited]
[Thread 0x7ffdf2027700 (LWP 8617) exited]
[Thread 0x7ffdd5d34700 (LWP 8618) exited]
[New Thread 0x7ffdcffff700 (LWP 8620)]
[New Thread 0x7ffdd5d34700 (LWP 8621)]
[New Thread 0x7ffdf2027700 (LWP 8622)]
[Thread 0x7ffdf2027700 (LWP 8622) exited]
[Thread 0x7ffdcffff700 (LWP 8620) exited]
[Thread 0x7ffdd5d34700 (LWP 8621) exited]
[New Thread 0x7ffdf2027700 (LWP 8623)]
[New Thread 0x7ffdd5d34700 (LWP 8624)]
[New Thread 0x7ffdcffff700 (LWP 8625)]
[Thread 0x7ffdcffff700 (LWP 8625) exited]
[Thread 0x7ffdf2027700 (LWP 8623) exited]
[Thread 0x7ffdd5d34700 (LWP 8624) exited]
[New Thread 0x7ffdcffff700 (LWP 8626)]
[New Thread 0x7ffdd5d34700 (LWP 8627)]
[New Thread 0x7ffdf2027700 (LWP 8628)]
[Thread 0x7ffdf2027700 (LWP 8628) exited]
[Thread 0x7ffdcffff700 (LWP 8626) exited]
[Thread 0x7ffdd5d34700 (LWP 8627) exited]
[New Thread 0x7ffdf2027700 (LWP 8629)]
[New Thread 0x7ffdd5d34700 (LWP 8630)]
[New Thread 0x7ffdcffff700 (LWP 8631)]
[Thread 0x7ffdcffff700 (LWP 8631) exited]
[Thread 0x7ffdf2027700 (LWP 8629) exited]
[Thread 0x7ffdd5d34700 (LWP 8630) exited]
[New Thread 0x7ffdcffff700 (LWP 8632)]
[New Thread 0x7ffdd5d34700 (LWP 8633)]
[New Thread 0x7ffdf2027700 (LWP 8634)]
[Thread 0x7ffdf2027700 (LWP 8634) exited]
[Thread 0x7ffdcffff700 (LWP 8632) exited]
[Thread 0x7ffdd5d34700 (LWP 8633) exited]
[New Thread 0x7ffdf2027700 (LWP 8635)]
[New Thread 0x7ffdd5d34700 (LWP 8636)]
[New Thread 0x7ffdcffff700 (LWP 8637)]
[Thread 0x7ffdcffff700 (LWP 8637) exited]
[Thread 0x7ffdf2027700 (LWP 8635) exited]
[Thread 0x7ffdd5d34700 (LWP 8636) exited]
[New Thread 0x7ffdcffff700 (LWP 8638)]
[New Thread 0x7ffdd5d34700 (LWP 8639)]
[New Thread 0x7ffdf2027700 (LWP 8640)]
[Thread 0x7ffdf2027700 (LWP 8640) exited]
[Thread 0x7ffdcffff700 (LWP 8638) exited]
[Thread 0x7ffdd5d34700 (LWP 8639) exited]
[New Thread 0x7ffdf2027700 (LWP 8641)]
[New Thread 0x7ffdd5d34700 (LWP 8642)]
[New Thread 0x7ffdcffff700 (LWP 8643)]
[Thread 0x7ffdcffff700 (LWP 8643) exited]
[Thread 0x7ffdf2027700 (LWP 8641) exited]
[Thread 0x7ffdd5d34700 (LWP 8642) exited]
[New Thread 0x7ffdcffff700 (LWP 8644)]
[New Thread 0x7ffdd5d34700 (LWP 8645)]
[New Thread 0x7ffdf2027700 (LWP 8646)]
[Thread 0x7ffdf2027700 (LWP 8646) exited]
[Thread 0x7ffdcffff700 (LWP 8644) exited]
[Thread 0x7ffdd5d34700 (LWP 8645) exited]
[New Thread 0x7ffdf2027700 (LWP 8647)]
[New Thread 0x7ffdd5d34700 (LWP 8648)]
[New Thread 0x7ffdcffff700 (LWP 8649)]
[Thread 0x7ffdcffff700 (LWP 8649) exited]
[Thread 0x7ffdf2027700 (LWP 8647) exited]
[Thread 0x7ffdd5d34700 (LWP 8648) exited]
[New Thread 0x7ffdcffff700 (LWP 8650)]
[New Thread 0x7ffdd5d34700 (LWP 8651)]
[New Thread 0x7ffdf2027700 (LWP 8652)]
[Thread 0x7ffdf2027700 (LWP 8652) exited]
[Thread 0x7ffdcffff700 (LWP 8650) exited]
[Thread 0x7ffdd5d34700 (LWP 8651) exited]
[New Thread 0x7ffdf2027700 (LWP 8653)]
[New Thread 0x7ffdd5d34700 (LWP 8654)]
[New Thread 0x7ffdcffff700 (LWP 8655)]
[Thread 0x7ffdcffff700 (LWP 8655) exited]
[Thread 0x7ffdf2027700 (LWP 8653) exited]
[Thread 0x7ffdd5d34700 (LWP 8654) exited]
[New Thread 0x7ffdcffff700 (LWP 8656)]
[New Thread 0x7ffdd5d34700 (LWP 8657)]
[New Thread 0x7ffdf2027700 (LWP 8658)]
[Thread 0x7ffdf2027700 (LWP 8658) exited]
[Thread 0x7ffdcffff700 (LWP 8656) exited]
[Thread 0x7ffdd5d34700 (LWP 8657) exited]
[New Thread 0x7ffdf2027700 (LWP 8659)]
[New Thread 0x7ffdd5d34700 (LWP 8660)]
[New Thread 0x7ffdcffff700 (LWP 8661)]
[Thread 0x7ffdcffff700 (LWP 8661) exited]
[Thread 0x7ffdf2027700 (LWP 8659) exited]
[Thread 0x7ffdd5d34700 (LWP 8660) exited]
[New Thread 0x7ffdcffff700 (LWP 8662)]
[New Thread 0x7ffdd5d34700 (LWP 8663)]
[New Thread 0x7ffdf2027700 (LWP 8664)]
[Thread 0x7ffdf2027700 (LWP 8664) exited]
[Thread 0x7ffdcffff700 (LWP 8662) exited]
[Thread 0x7ffdd5d34700 (LWP 8663) exited]
[New Thread 0x7ffdf2027700 (LWP 8665)]
[New Thread 0x7ffdd5d34700 (LWP 8666)]
[New Thread 0x7ffdcffff700 (LWP 8667)]
[Thread 0x7ffdcffff700 (LWP 8667) exited]
[Thread 0x7ffdf2027700 (LWP 8665) exited]
[Thread 0x7ffdd5d34700 (LWP 8666) exited]
[New Thread 0x7ffdcffff700 (LWP 8668)]
[New Thread 0x7ffdd5d34700 (LWP 8669)]
[New Thread 0x7ffdf2027700 (LWP 8670)]
[Thread 0x7ffdf2027700 (LWP 8670) exited]
[Thread 0x7ffdcffff700 (LWP 8668) exited]
[Thread 0x7ffdd5d34700 (LWP 8669) exited]
[New Thread 0x7ffdf2027700 (LWP 8671)]
[New Thread 0x7ffdd5d34700 (LWP 8672)]
[New Thread 0x7ffdcffff700 (LWP 8673)]
[Thread 0x7ffdcffff700 (LWP 8673) exited]
[Thread 0x7ffdf2027700 (LWP 8671) exited]
[Thread 0x7ffdd5d34700 (LWP 8672) exited]
[New Thread 0x7ffdcffff700 (LWP 8674)]
[New Thread 0x7ffdd5d34700 (LWP 8675)]
[New Thread 0x7ffdf2027700 (LWP 8676)]
[Thread 0x7ffdf2027700 (LWP 8676) exited]
[Thread 0x7ffdcffff700 (LWP 8674) exited]
[Thread 0x7ffdd5d34700 (LWP 8675) exited]
[New Thread 0x7ffdf2027700 (LWP 8677)]
[New Thread 0x7ffdd5d34700 (LWP 8678)]
[New Thread 0x7ffdcffff700 (LWP 8679)]
[Thread 0x7ffdcffff700 (LWP 8679) exited]
[Thread 0x7ffdf2027700 (LWP 8677) exited]
[Thread 0x7ffdd5d34700 (LWP 8678) exited]
[New Thread 0x7ffdcffff700 (LWP 8680)]
[New Thread 0x7ffdd5d34700 (LWP 8681)]
[New Thread 0x7ffdf2027700 (LWP 8682)]
[Thread 0x7ffdf2027700 (LWP 8682) exited]
[Thread 0x7ffdcffff700 (LWP 8680) exited]
[Thread 0x7ffdd5d34700 (LWP 8681) exited]
[New Thread 0x7ffdf2027700 (LWP 8683)]
[New Thread 0x7ffdd5d34700 (LWP 8684)]
[New Thread 0x7ffdcffff700 (LWP 8685)]
[Thread 0x7ffdcffff700 (LWP 8685) exited]
[Thread 0x7ffdf2027700 (LWP 8683) exited]
[Thread 0x7ffdd5d34700 (LWP 8684) exited]
[New Thread 0x7ffdcffff700 (LWP 8686)]
[New Thread 0x7ffdd5d34700 (LWP 8687)]
[New Thread 0x7ffdf2027700 (LWP 8688)]
[Thread 0x7ffdf2027700 (LWP 8688) exited]
[Thread 0x7ffdcffff700 (LWP 8686) exited]
[Thread 0x7ffdd5d34700 (LWP 8687) exited]
[New Thread 0x7ffdf2027700 (LWP 8689)]
[New Thread 0x7ffdd5d34700 (LWP 8690)]
[New Thread 0x7ffdcffff700 (LWP 8691)]
[Thread 0x7ffdcffff700 (LWP 8691) exited]
[Thread 0x7ffdf2027700 (LWP 8689) exited]
[Thread 0x7ffdd5d34700 (LWP 8690) exited]
[New Thread 0x7ffdcffff700 (LWP 8692)]
[New Thread 0x7ffdd5d34700 (LWP 8693)]
[New Thread 0x7ffdf2027700 (LWP 8694)]
[Thread 0x7ffdf2027700 (LWP 8694) exited]
[Thread 0x7ffdcffff700 (LWP 8692) exited]
[Thread 0x7ffdd5d34700 (LWP 8693) exited]
[New Thread 0x7ffdf2027700 (LWP 8695)]
[New Thread 0x7ffdd5d34700 (LWP 8696)]
[New Thread 0x7ffdcffff700 (LWP 8697)]
[Thread 0x7ffdcffff700 (LWP 8697) exited]
[Thread 0x7ffdf2027700 (LWP 8695) exited]
[Thread 0x7ffdd5d34700 (LWP 8696) exited]
[New Thread 0x7ffdcffff700 (LWP 8698)]
[New Thread 0x7ffdd5d34700 (LWP 8699)]
[New Thread 0x7ffdf2027700 (LWP 8700)]
[Thread 0x7ffdf2027700 (LWP 8700) exited]
[Thread 0x7ffdcffff700 (LWP 8698) exited]
[Thread 0x7ffdd5d34700 (LWP 8699) exited]
[New Thread 0x7ffdf2027700 (LWP 8701)]
[New Thread 0x7ffdd5d34700 (LWP 8702)]
[New Thread 0x7ffdcffff700 (LWP 8703)]
[Thread 0x7ffdcffff700 (LWP 8703) exited]
[Thread 0x7ffdf2027700 (LWP 8701) exited]
[Thread 0x7ffdd5d34700 (LWP 8702) exited]
[New Thread 0x7ffdcffff700 (LWP 8704)]
[New Thread 0x7ffdd5d34700 (LWP 8705)]
[New Thread 0x7ffdf2027700 (LWP 8706)]
[Thread 0x7ffdf2027700 (LWP 8706) exited]
[Thread 0x7ffdcffff700 (LWP 8704) exited]
[Thread 0x7ffdd5d34700 (LWP 8705) exited]
[New Thread 0x7ffdf2027700 (LWP 8707)]
[New Thread 0x7ffdd5d34700 (LWP 8708)]
[New Thread 0x7ffdcffff700 (LWP 8709)]
[Thread 0x7ffdcffff700 (LWP 8709) exited]
[Thread 0x7ffdf2027700 (LWP 8707) exited]
[Thread 0x7ffdd5d34700 (LWP 8708) exited]
[New Thread 0x7ffdcffff700 (LWP 8710)]
[New Thread 0x7ffdd5d34700 (LWP 8711)]
[New Thread 0x7ffdf2027700 (LWP 8712)]
[Thread 0x7ffdf2027700 (LWP 8712) exited]
[Thread 0x7ffdcffff700 (LWP 8710) exited]
[Thread 0x7ffdd5d34700 (LWP 8711) exited]
[New Thread 0x7ffdf2027700 (LWP 8713)]
[New Thread 0x7ffdd5d34700 (LWP 8714)]
[New Thread 0x7ffdcffff700 (LWP 8715)]
[Thread 0x7ffdcffff700 (LWP 8715) exited]
[Thread 0x7ffdf2027700 (LWP 8713) exited]
[Thread 0x7ffdd5d34700 (LWP 8714) exited]
[New Thread 0x7ffdcffff700 (LWP 8716)]
[New Thread 0x7ffdd5d34700 (LWP 8717)]
[New Thread 0x7ffdf2027700 (LWP 8718)]
[Thread 0x7ffdf2027700 (LWP 8718) exited]
[Thread 0x7ffdcffff700 (LWP 8716) exited]
[Thread 0x7ffdd5d34700 (LWP 8717) exited]
[New Thread 0x7ffdf2027700 (LWP 8719)]
[New Thread 0x7ffdd5d34700 (LWP 8720)]
[New Thread 0x7ffdcffff700 (LWP 8721)]
[Thread 0x7ffdcffff700 (LWP 8721) exited]
[Thread 0x7ffdf2027700 (LWP 8719) exited]
[Thread 0x7ffdd5d34700 (LWP 8720) exited]
[New Thread 0x7ffdcffff700 (LWP 8722)]
[New Thread 0x7ffdd5d34700 (LWP 8723)]
[New Thread 0x7ffdf2027700 (LWP 8724)]
[Thread 0x7ffdf2027700 (LWP 8724) exited]
[Thread 0x7ffdcffff700 (LWP 8722) exited]
[Thread 0x7ffdd5d34700 (LWP 8723) exited]
[New Thread 0x7ffdf2027700 (LWP 8725)]
[New Thread 0x7ffdd5d34700 (LWP 8726)]
[New Thread 0x7ffdcffff700 (LWP 8727)]
[Thread 0x7ffdcffff700 (LWP 8727) exited]
[Thread 0x7ffdf2027700 (LWP 8725) exited]
[Thread 0x7ffdd5d34700 (LWP 8726) exited]
[New Thread 0x7ffdcffff700 (LWP 8728)]
[New Thread 0x7ffdd5d34700 (LWP 8729)]
[New Thread 0x7ffdf2027700 (LWP 8730)]
[Thread 0x7ffdf2027700 (LWP 8730) exited]
[Thread 0x7ffdcffff700 (LWP 8728) exited]
[Thread 0x7ffdd5d34700 (LWP 8729) exited]
[New Thread 0x7ffdf2027700 (LWP 8731)]
[New Thread 0x7ffdd5d34700 (LWP 8732)]
[New Thread 0x7ffdcffff700 (LWP 8733)]
[Thread 0x7ffdcffff700 (LWP 8733) exited]
[Thread 0x7ffdf2027700 (LWP 8731) exited]
[Thread 0x7ffdd5d34700 (LWP 8732) exited]
[New Thread 0x7ffdcffff700 (LWP 8734)]
[New Thread 0x7ffdd5d34700 (LWP 8735)]
[New Thread 0x7ffdf2027700 (LWP 8736)]
[Thread 0x7ffdf2027700 (LWP 8736) exited]
[Thread 0x7ffdcffff700 (LWP 8734) exited]
[Thread 0x7ffdd5d34700 (LWP 8735) exited]
[New Thread 0x7ffdf2027700 (LWP 8737)]
[New Thread 0x7ffdd5d34700 (LWP 8738)]
[New Thread 0x7ffdcffff700 (LWP 8739)]
[Thread 0x7ffdcffff700 (LWP 8739) exited]
[Thread 0x7ffdf2027700 (LWP 8737) exited]
[Thread 0x7ffdd5d34700 (LWP 8738) exited]
[New Thread 0x7ffdcffff700 (LWP 8740)]
[New Thread 0x7ffdd5d34700 (LWP 8741)]
[New Thread 0x7ffdf2027700 (LWP 8742)]
[Thread 0x7ffdf2027700 (LWP 8742) exited]
[Thread 0x7ffdcffff700 (LWP 8740) exited]
[Thread 0x7ffdd5d34700 (LWP 8741) exited]
[New Thread 0x7ffdf2027700 (LWP 8743)]
[New Thread 0x7ffdd5d34700 (LWP 8744)]
[New Thread 0x7ffdcffff700 (LWP 8745)]
[Thread 0x7ffdcffff700 (LWP 8745) exited]
[Thread 0x7ffdf2027700 (LWP 8743) exited]
[Thread 0x7ffdd5d34700 (LWP 8744) exited]
[New Thread 0x7ffdcffff700 (LWP 8746)]
[New Thread 0x7ffdd5d34700 (LWP 8747)]
[New Thread 0x7ffdf2027700 (LWP 8748)]
[Thread 0x7ffdf2027700 (LWP 8748) exited]
[Thread 0x7ffdcffff700 (LWP 8746) exited]
[Thread 0x7ffdd5d34700 (LWP 8747) exited]
[New Thread 0x7ffdf2027700 (LWP 8749)]
[New Thread 0x7ffdd5d34700 (LWP 8750)]
[New Thread 0x7ffdcffff700 (LWP 8751)]
[Thread 0x7ffdcffff700 (LWP 8751) exited]
[Thread 0x7ffdf2027700 (LWP 8749) exited]
[Thread 0x7ffdd5d34700 (LWP 8750) exited]
[New Thread 0x7ffdcffff700 (LWP 8752)]
[New Thread 0x7ffdd5d34700 (LWP 8753)]
[New Thread 0x7ffdf2027700 (LWP 8754)]
[Thread 0x7ffdf2027700 (LWP 8754) exited]
[Thread 0x7ffdcffff700 (LWP 8752) exited]
[Thread 0x7ffdd5d34700 (LWP 8753) exited]
[New Thread 0x7ffdf2027700 (LWP 8755)]
[New Thread 0x7ffdd5d34700 (LWP 8756)]
[New Thread 0x7ffdcffff700 (LWP 8757)]
[Thread 0x7ffdcffff700 (LWP 8757) exited]
[Thread 0x7ffdf2027700 (LWP 8755) exited]
[Thread 0x7ffdd5d34700 (LWP 8756) exited]
[New Thread 0x7ffdcffff700 (LWP 8758)]
[New Thread 0x7ffdd5d34700 (LWP 8759)]
[New Thread 0x7ffdf2027700 (LWP 8760)]
[Thread 0x7ffdf2027700 (LWP 8760) exited]
[Thread 0x7ffdcffff700 (LWP 8758) exited]
[Thread 0x7ffdd5d34700 (LWP 8759) exited]
[New Thread 0x7ffdf2027700 (LWP 8761)]
[New Thread 0x7ffdd5d34700 (LWP 8762)]
[New Thread 0x7ffdcffff700 (LWP 8763)]
[Thread 0x7ffdcffff700 (LWP 8763) exited]
[Thread 0x7ffdf2027700 (LWP 8761) exited]
[Thread 0x7ffdd5d34700 (LWP 8762) exited]
[New Thread 0x7ffdcffff700 (LWP 8764)]
[New Thread 0x7ffdd5d34700 (LWP 8765)]
[New Thread 0x7ffdf2027700 (LWP 8766)]
[Thread 0x7ffdf2027700 (LWP 8766) exited]
[Thread 0x7ffdcffff700 (LWP 8764) exited]
[Thread 0x7ffdd5d34700 (LWP 8765) exited]
[New Thread 0x7ffdf2027700 (LWP 8767)]
[New Thread 0x7ffdd5d34700 (LWP 8768)]
[New Thread 0x7ffdcffff700 (LWP 8769)]
[Thread 0x7ffdcffff700 (LWP 8769) exited]
[Thread 0x7ffdf2027700 (LWP 8767) exited]
[Thread 0x7ffdd5d34700 (LWP 8768) exited]
[New Thread 0x7ffdcffff700 (LWP 8770)]
[New Thread 0x7ffdd5d34700 (LWP 8771)]
[New Thread 0x7ffdf2027700 (LWP 8772)]
[Thread 0x7ffdf2027700 (LWP 8772) exited]
[Thread 0x7ffdcffff700 (LWP 8770) exited]
[Thread 0x7ffdd5d34700 (LWP 8771) exited]
[New Thread 0x7ffdf2027700 (LWP 8773)]
[New Thread 0x7ffdd5d34700 (LWP 8774)]
[New Thread 0x7ffdcffff700 (LWP 8775)]
[Thread 0x7ffdcffff700 (LWP 8775) exited]
[Thread 0x7ffdf2027700 (LWP 8773) exited]
[Thread 0x7ffdd5d34700 (LWP 8774) exited]
[New Thread 0x7ffdcffff700 (LWP 8776)]
[New Thread 0x7ffdd5d34700 (LWP 8777)]
[New Thread 0x7ffdf2027700 (LWP 8778)]
[Thread 0x7ffdf2027700 (LWP 8778) exited]
[Thread 0x7ffdcffff700 (LWP 8776) exited]
[Thread 0x7ffdd5d34700 (LWP 8777) exited]
[New Thread 0x7ffdf2027700 (LWP 8779)]
[New Thread 0x7ffdd5d34700 (LWP 8780)]
[New Thread 0x7ffdcffff700 (LWP 8781)]
[Thread 0x7ffdcffff700 (LWP 8781) exited]
[Thread 0x7ffdf2027700 (LWP 8779) exited]
[Thread 0x7ffdd5d34700 (LWP 8780) exited]
[New Thread 0x7ffdcffff700 (LWP 8782)]
[New Thread 0x7ffdd5d34700 (LWP 8783)]
[New Thread 0x7ffdf2027700 (LWP 8784)]
[Thread 0x7ffdf2027700 (LWP 8784) exited]
[Thread 0x7ffdcffff700 (LWP 8782) exited]
[Thread 0x7ffdd5d34700 (LWP 8783) exited]
[New Thread 0x7ffdf2027700 (LWP 8785)]
[New Thread 0x7ffdd5d34700 (LWP 8786)]
[New Thread 0x7ffdcffff700 (LWP 8787)]
[Thread 0x7ffdcffff700 (LWP 8787) exited]
[Thread 0x7ffdf2027700 (LWP 8785) exited]
[Thread 0x7ffdd5d34700 (LWP 8786) exited]
[New Thread 0x7ffdcffff700 (LWP 8788)]
[New Thread 0x7ffdd5d34700 (LWP 8789)]
[New Thread 0x7ffdf2027700 (LWP 8790)]
[Thread 0x7ffdf2027700 (LWP 8790) exited]
[Thread 0x7ffdcffff700 (LWP 8788) exited]
[Thread 0x7ffdd5d34700 (LWP 8789) exited]
[New Thread 0x7ffdf2027700 (LWP 8791)]
[New Thread 0x7ffdd5d34700 (LWP 8792)]
[New Thread 0x7ffdcffff700 (LWP 8793)]
[Thread 0x7ffdcffff700 (LWP 8793) exited]
[Thread 0x7ffdf2027700 (LWP 8791) exited]
[Thread 0x7ffdd5d34700 (LWP 8792) exited]
[New Thread 0x7ffdcffff700 (LWP 8794)]
[New Thread 0x7ffdd5d34700 (LWP 8795)]
[New Thread 0x7ffdf2027700 (LWP 8796)]
[Thread 0x7ffdf2027700 (LWP 8796) exited]
[Thread 0x7ffdcffff700 (LWP 8794) exited]
[Thread 0x7ffdd5d34700 (LWP 8795) exited]
[New Thread 0x7ffdf2027700 (LWP 8797)]
[New Thread 0x7ffdd5d34700 (LWP 8798)]
[New Thread 0x7ffdcffff700 (LWP 8799)]
[Thread 0x7ffdcffff700 (LWP 8799) exited]
[Thread 0x7ffdf2027700 (LWP 8797) exited]
[Thread 0x7ffdd5d34700 (LWP 8798) exited]
[New Thread 0x7ffdcffff700 (LWP 8800)]
[New Thread 0x7ffdd5d34700 (LWP 8801)]
[New Thread 0x7ffdf2027700 (LWP 8802)]
[Thread 0x7ffdf2027700 (LWP 8802) exited]
[Thread 0x7ffdcffff700 (LWP 8800) exited]
[Thread 0x7ffdd5d34700 (LWP 8801) exited]
[New Thread 0x7ffdf2027700 (LWP 8803)]
[New Thread 0x7ffdd5d34700 (LWP 8804)]
[New Thread 0x7ffdcffff700 (LWP 8805)]
[Thread 0x7ffdcffff700 (LWP 8805) exited]
[Thread 0x7ffdf2027700 (LWP 8803) exited]
[Thread 0x7ffdd5d34700 (LWP 8804) exited]
[New Thread 0x7ffdcffff700 (LWP 8806)]
[New Thread 0x7ffdd5d34700 (LWP 8807)]
[New Thread 0x7ffdf2027700 (LWP 8808)]
[Thread 0x7ffdf2027700 (LWP 8808) exited]
[Thread 0x7ffdd5d34700 (LWP 8807) exited]
[Thread 0x7ffdcffff700 (LWP 8806) exited]
[New Thread 0x7ffdf2027700 (LWP 8809)]
[New Thread 0x7ffdd5d34700 (LWP 8810)]
[New Thread 0x7ffdcffff700 (LWP 8811)]
[Thread 0x7ffdcffff700 (LWP 8811) exited]
[Thread 0x7ffdf2027700 (LWP 8809) exited]
[Thread 0x7ffdd5d34700 (LWP 8810) exited]
[New Thread 0x7ffdcffff700 (LWP 8812)]
[New Thread 0x7ffdd5d34700 (LWP 8813)]
[New Thread 0x7ffdf2027700 (LWP 8814)]
[Thread 0x7ffdf2027700 (LWP 8814) exited]
[Thread 0x7ffdcffff700 (LWP 8812) exited]
[Thread 0x7ffdd5d34700 (LWP 8813) exited]
[New Thread 0x7ffdf2027700 (LWP 8815)]
[New Thread 0x7ffdd5d34700 (LWP 8816)]
[New Thread 0x7ffdcffff700 (LWP 8817)]
[Thread 0x7ffdcffff700 (LWP 8817) exited]
[Thread 0x7ffdf2027700 (LWP 8815) exited]
[Thread 0x7ffdd5d34700 (LWP 8816) exited]
[New Thread 0x7ffdcffff700 (LWP 8818)]
[New Thread 0x7ffdd5d34700 (LWP 8819)]
[New Thread 0x7ffdf2027700 (LWP 8820)]
[Thread 0x7ffdf2027700 (LWP 8820) exited]
[Thread 0x7ffdcffff700 (LWP 8818) exited]
[Thread 0x7ffdd5d34700 (LWP 8819) exited]
[New Thread 0x7ffdf2027700 (LWP 8821)]
[New Thread 0x7ffdd5d34700 (LWP 8822)]
[New Thread 0x7ffdcffff700 (LWP 8823)]
[Thread 0x7ffdcffff700 (LWP 8823) exited]
[Thread 0x7ffdf2027700 (LWP 8821) exited]
[Thread 0x7ffdd5d34700 (LWP 8822) exited]
[New Thread 0x7ffdcffff700 (LWP 8824)]
[New Thread 0x7ffdd5d34700 (LWP 8825)]
[New Thread 0x7ffdf2027700 (LWP 8826)]
[Thread 0x7ffdf2027700 (LWP 8826) exited]
[Thread 0x7ffdcffff700 (LWP 8824) exited]
[Thread 0x7ffdd5d34700 (LWP 8825) exited]
[New Thread 0x7ffdf2027700 (LWP 8827)]
[New Thread 0x7ffdd5d34700 (LWP 8828)]
[New Thread 0x7ffdcffff700 (LWP 8829)]
[Thread 0x7ffdcffff700 (LWP 8829) exited]
[Thread 0x7ffdf2027700 (LWP 8827) exited]
[Thread 0x7ffdd5d34700 (LWP 8828) exited]
[New Thread 0x7ffdcffff700 (LWP 8830)]
[New Thread 0x7ffdd5d34700 (LWP 8831)]
[New Thread 0x7ffdf2027700 (LWP 8832)]
[Thread 0x7ffdf2027700 (LWP 8832) exited]
[Thread 0x7ffdcffff700 (LWP 8830) exited]
[Thread 0x7ffdd5d34700 (LWP 8831) exited]
[New Thread 0x7ffdf2027700 (LWP 8833)]
[New Thread 0x7ffdd5d34700 (LWP 8834)]
[New Thread 0x7ffdcffff700 (LWP 8835)]
[Thread 0x7ffdcffff700 (LWP 8835) exited]
[Thread 0x7ffdf2027700 (LWP 8833) exited]
[Thread 0x7ffdd5d34700 (LWP 8834) exited]
[New Thread 0x7ffdcffff700 (LWP 8836)]
[New Thread 0x7ffdd5d34700 (LWP 8837)]
[New Thread 0x7ffdf2027700 (LWP 8838)]
[Thread 0x7ffdf2027700 (LWP 8838) exited]
[Thread 0x7ffdcffff700 (LWP 8836) exited]
[Thread 0x7ffdd5d34700 (LWP 8837) exited]
[New Thread 0x7ffdf2027700 (LWP 8839)]
[New Thread 0x7ffdd5d34700 (LWP 8840)]
[New Thread 0x7ffdcffff700 (LWP 8841)]
[Thread 0x7ffdcffff700 (LWP 8841) exited]
[Thread 0x7ffdf2027700 (LWP 8839) exited]
[Thread 0x7ffdd5d34700 (LWP 8840) exited]
[New Thread 0x7ffdcffff700 (LWP 8842)]
[New Thread 0x7ffdd5d34700 (LWP 8843)]
[New Thread 0x7ffdf2027700 (LWP 8844)]
[Thread 0x7ffdf2027700 (LWP 8844) exited]
[Thread 0x7ffdcffff700 (LWP 8842) exited]
[Thread 0x7ffdd5d34700 (LWP 8843) exited]
[New Thread 0x7ffdf2027700 (LWP 8845)]
[New Thread 0x7ffdd5d34700 (LWP 8846)]
[New Thread 0x7ffdcffff700 (LWP 8847)]
[Thread 0x7ffdcffff700 (LWP 8847) exited]
[Thread 0x7ffdf2027700 (LWP 8845) exited]
[Thread 0x7ffdd5d34700 (LWP 8846) exited]
[New Thread 0x7ffdcffff700 (LWP 8848)]
[New Thread 0x7ffdd5d34700 (LWP 8849)]
[New Thread 0x7ffdf2027700 (LWP 8850)]
[Thread 0x7ffdf2027700 (LWP 8850) exited]
[Thread 0x7ffdcffff700 (LWP 8848) exited]
[Thread 0x7ffdd5d34700 (LWP 8849) exited]
2019-11-10 08:51:40.041023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:40.041373: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
[New Thread 0x7ffdf2027700 (LWP 8851)]
[New Thread 0x7ffdd5d34700 (LWP 8852)]
2019-11-10 08:51:40.041879: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
[New Thread 0x7ffdcffff700 (LWP 8853)]
[New Thread 0x7ffdd5533700 (LWP 8854)]
[Thread 0x7ffdd5d34700 (LWP 8852) exited]
[Thread 0x7ffdf2027700 (LWP 8851) exited]
[New Thread 0x7ffdd5d34700 (LWP 8855)]
[New Thread 0x7ffdf2027700 (LWP 8856)]
[New Thread 0x7ffdd4d32700 (LWP 8857)]
2019-11-10 08:51:40.043093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:40.043334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775
pciBusID: 0000:00:1e.0
2019-11-10 08:51:40.043393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-10 08:51:40.043418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-10 08:51:40.043439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-10 08:51:40.043456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-10 08:51:40.043476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-10 08:51:40.043490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-10 08:51:40.043506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-10 08:51:40.043563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:40.043824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:40.044044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-10 08:51:40.232781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-10 08:51:40.232845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-10 08:51:40.232866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-10 08:51:40.233149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:40.233473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:40.233707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7162 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2)
[New Thread 0x7ffdcf7fe700 (LWP 8858)]
[New Thread 0x7ffdceffd700 (LWP 8859)]
[New Thread 0x7ffdce7fc700 (LWP 8860)]
[New Thread 0x7ffdcdffb700 (LWP 8861)]
[New Thread 0x7ffdcd7fa700 (LWP 8862)]
[New Thread 0x7ffdccff9700 (LWP 8863)]
[New Thread 0x7ffda7fff700 (LWP 8864)]
[New Thread 0x7ffda77fe700 (LWP 8865)]
[New Thread 0x7ffda6ffd700 (LWP 8866)]
[New Thread 0x7ffda67fc700 (LWP 8867)]
[New Thread 0x7ffda5ffb700 (LWP 8868)]
[New Thread 0x7ffda57fa700 (LWP 8869)]
[New Thread 0x7ffda4ff9700 (LWP 8870)]
[New Thread 0x7ffd87fff700 (LWP 8871)]
[New Thread 0x7ffd877fe700 (LWP 8872)]
[New Thread 0x7ffd86ffd700 (LWP 8873)]
2019-11-10 08:51:40.320845: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-10 08:51:40.320889: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 1676 nodes (1362), 3172 edges (2858), time = 50.794ms.
2019-11-10 08:51:40.320900: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.832ms.
[New Thread 0x7ffd867fc700 (LWP 8874)]
[Thread 0x7ffdd5533700 (LWP 8854) exited]
[Thread 0x7ffdcffff700 (LWP 8853) exited]
[Thread 0x7ffd867fc700 (LWP 8874) exited]
[Thread 0x7ffda57fa700 (LWP 8869) exited]
[Thread 0x7ffda7fff700 (LWP 8864) exited]
[Thread 0x7ffdcdffb700 (LWP 8861) exited]
[Thread 0x7ffdcf7fe700 (LWP 8858) exited]
[Thread 0x7ffd86ffd700 (LWP 8873) exited]
[Thread 0x7ffda6ffd700 (LWP 8866) exited]
[Thread 0x7ffdceffd700 (LWP 8859) exited]
[Thread 0x7ffda4ff9700 (LWP 8870) exited]
[Thread 0x7ffda5ffb700 (LWP 8868) exited]
[Thread 0x7ffdccff9700 (LWP 8863) exited]
[Thread 0x7ffdcd7fa700 (LWP 8862) exited]
[Thread 0x7ffdce7fc700 (LWP 8860) exited]
[Thread 0x7ffd877fe700 (LWP 8872) exited]
[Thread 0x7ffda77fe700 (LWP 8865) exited]
[Thread 0x7ffd87fff700 (LWP 8871) exited]
[Thread 0x7ffda67fc700 (LWP 8867) exited]
[Thread 0x7ffdd5d34700 (LWP 8855) exited]
[Thread 0x7ffdd4d32700 (LWP 8857) exited]
Run TRT optimizer in Grappler to convert the graph

2019-11-10 08:51:41.984437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:41.984749: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
[New Thread 0x7ffdd4d32700 (LWP 8875)]
[New Thread 0x7ffdd5d34700 (LWP 8876)]
2019-11-10 08:51:41.985406: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
[New Thread 0x7ffd86ffd700 (LWP 8877)]
[New Thread 0x7ffd877fe700 (LWP 8878)]
[Thread 0x7ffdd5d34700 (LWP 8876) exited]
[Thread 0x7ffdd4d32700 (LWP 8875) exited]
[New Thread 0x7ffdd5d34700 (LWP 8879)]
[New Thread 0x7ffdd4d32700 (LWP 8880)]
2019-11-10 08:51:41.986303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:41.986526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775
pciBusID: 0000:00:1e.0
2019-11-10 08:51:41.986594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-10 08:51:41.986621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-10 08:51:41.986645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-10 08:51:41.986667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-10 08:51:41.986690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-10 08:51:41.986712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-10 08:51:41.986736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-10 08:51:41.986788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:41.987035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:41.987240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-10 08:51:41.987279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-10 08:51:41.987294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-10 08:51:41.987301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-10 08:51:41.987447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:41.987699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-10 08:51:41.987917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7162 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2)
[New Thread 0x7ffdd5533700 (LWP 8881)]
[New Thread 0x7ffdcffff700 (LWP 8882)]
[New Thread 0x7ffdcf7fe700 (LWP 8883)]
[New Thread 0x7ffdceffd700 (LWP 8884)]
[New Thread 0x7ffdce7fc700 (LWP 8885)]
[New Thread 0x7ffdcdffb700 (LWP 8886)]
[New Thread 0x7ffdcd7fa700 (LWP 8887)]
[New Thread 0x7ffdccff9700 (LWP 8888)]
[New Thread 0x7ffda7fff700 (LWP 8889)]
[New Thread 0x7ffda77fe700 (LWP 8890)]
[New Thread 0x7ffda6ffd700 (LWP 8891)]
[New Thread 0x7ffda67fc700 (LWP 8892)]
[New Thread 0x7ffda5ffb700 (LWP 8893)]
[New Thread 0x7ffda57fa700 (LWP 8894)]
[New Thread 0x7ffda4ff9700 (LWP 8895)]
[New Thread 0x7ffd87fff700 (LWP 8896)]
[New Thread 0x7ffd867fc700 (LWP 8897)]
[New Thread 0x7ffd85ffb700 (LWP 8898)]
[New Thread 0x7ffd857fa700 (LWP 8899)]
[New Thread 0x7ffd84ff9700 (LWP 8900)]
[New Thread 0x7ffd67fff700 (LWP 8901)]
[New Thread 0x7ffd677fe700 (LWP 8902)]
[New Thread 0x7ffd66ffd700 (LWP 8903)]
[New Thread 0x7ffd667fc700 (LWP 8904)]
[New Thread 0x7ffd65ffb700 (LWP 8905)]
[New Thread 0x7ffd657fa700 (LWP 8906)]
[New Thread 0x7ffd64ff9700 (LWP 8907)]
[New Thread 0x7ffd47fff700 (LWP 8908)]
[New Thread 0x7ffd477fe700 (LWP 8909)]
[New Thread 0x7ffd46ffd700 (LWP 8910)]
[New Thread 0x7ffd467fc700 (LWP 8911)]
[New Thread 0x7ffd45ffb700 (LWP 8912)]
[New Thread 0x7ffd457fa700 (LWP 8913)]
[New Thread 0x7ffd44ff9700 (LWP 8914)]
[New Thread 0x7ffd27fff700 (LWP 8915)]
[New Thread 0x7ffd277fe700 (LWP 8916)]
[New Thread 0x7ffd26ffd700 (LWP 8917)]
[New Thread 0x7ffd267fc700 (LWP 8918)]
[New Thread 0x7ffd25ffb700 (LWP 8919)]
[New Thread 0x7ffd257fa700 (LWP 8920)]
[New Thread 0x7ffd24ff9700 (LWP 8921)]
[New Thread 0x7ffd07fff700 (LWP 8922)]
[New Thread 0x7ffd077fe700 (LWP 8923)]
[New Thread 0x7ffd06ffd700 (LWP 8924)]
[New Thread 0x7ffd067fc700 (LWP 8925)]
[New Thread 0x7ffd05ffb700 (LWP 8926)]
[New Thread 0x7ffd057fa700 (LWP 8927)]
[New Thread 0x7ffd04ff9700 (LWP 8928)]
2019-11-10 08:51:42.597091: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 70 ops of 7 different types in the graph that are not converted to TensorRT: Identity, Placeholder, NoOp, Pack, Shape, StridedSlice, Reshape, (For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops).
2019-11-10 08:51:42.982417: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:633] Number of TensorRT candidate segments: 17
2019-11-10 08:51:43.059702: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_0 added for segment 0 consisting of 41 nodes succeeded.
2019-11-10 08:51:43.060007: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_1 added for segment 1 consisting of 41 nodes succeeded.
2019-11-10 08:51:43.060271: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_2 added for segment 2 consisting of 43 nodes succeeded.
2019-11-10 08:51:43.060530: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_3 added for segment 3 consisting of 41 nodes succeeded.
2019-11-10 08:51:43.060768: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_4 added for segment 4 consisting of 43 nodes succeeded.
2019-11-10 08:51:43.061007: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_5 added for segment 5 consisting of 41 nodes succeeded.
2019-11-10 08:51:43.061313: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_6 added for segment 6 consisting of 43 nodes succeeded.
2019-11-10 08:51:43.061518: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_7 added for segment 7 consisting of 43 nodes succeeded.
2019-11-10 08:51:43.061728: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_8 added for segment 8 consisting of 41 nodes succeeded.
2019-11-10 08:51:43.061976: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_9 added for segment 9 consisting of 43 nodes succeeded.
2019-11-10 08:51:43.062207: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_10 added for segment 10 consisting of 43 nodes succeeded.
2019-11-10 08:51:43.062447: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_11 added for segment 11 consisting of 41 nodes succeeded.
2019-11-10 08:51:43.062683: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_12 added for segment 12 consisting of 43 nodes succeeded.
2019-11-10 08:51:43.062900: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_13 added for segment 13 consisting of 43 nodes succeeded.
2019-11-10 08:51:43.063120: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node StatefulPartitionedCall/efficientnet-b0/TRTEngineOp_14 added for segment 14 consisting of 43 nodes succeeded.
2019-11-10 08:51:43.063297: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:734] TensorRT node TRTEngineOp_15 added for segment 15 consisting of 40 nodes succeeded.

Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
0x00007fff8bb8b820 in tensorflow::Node::name() const () from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/../libtensorflow_framework.so.2
(gdb) bt
#0  0x00007fff8bb8b820 in tensorflow::Node::name() const () from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/../libtensorflow_framework.so.2
#1  0x00007fff919b8186 in tensorflow::tensorrt::convert::UpdateToEngineNode(std::vector<tensorflow::tensorrt::convert::EngineInfo, std::allocator<tensorflow::tensorrt::convert::EngineInfo> > const&, unsigned long, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> > const&, bool, std::string const&, tensorflow::Node**, int*) ()
   from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#2  0x00007fff919ba270 in tensorflow::tensorrt::convert::CreateTRTNode(tensorflow::tensorrt::convert::ConversionParams const&, std::vector<tensorflow::tensorrt::convert::EngineInfo, std::allocator<tensorflow::tensorrt::convert::EngineInfo> > const&, int, int, tensorflow::Graph*, nvinfer1::IGpuAllocator*, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >*) ()
   from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#3  0x00007fff919bf334 in tensorflow::tensorrt::convert::ConvertAfterShapes(tensorflow::tensorrt::convert::ConversionParams const&) ()
   from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#4  0x00007fff919f7b06 in tensorflow::tensorrt::convert::TRTOptimizationPass::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#5  0x00007fff94d674ac in tensorflow::grappler::MetaOptimizer::RunOptimizer(tensorflow::grappler::GraphOptimizer*, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*, tensorflow::grappler::MetaOptimizer::GraphOptimizationResult*) () from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#6  0x00007fff94d68695 in tensorflow::grappler::MetaOptimizer::OptimizeGraph(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#7  0x00007fff94d6a050 in tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#8  0x00007fff8eda048f in TF_OptimizeGraph(GCluster, tensorflow::ConfigProto const&, tensorflow::MetaGraphDef const&, bool, std::string const&, TF_Status*) ()
   from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#9  0x00007fff8eda77c4 in _wrap_TF_OptimizeGraph () from /home/ubuntu/tf20/lib/python3.5/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#10 0x00000000004ea10f in PyCFunction_Call ()
#11 0x0000000000536d94 in PyEval_EvalFrameEx ()
#12 0x000000000053fc97 in ?? ()
#13 0x000000000053b83f in PyEval_EvalFrameEx ()
#14 0x000000000053b294 in PyEval_EvalFrameEx ()
#15 0x000000000053fc97 in ?? ()
#16 0x000000000053b83f in PyEval_EvalFrameEx ()
#17 0x000000000053fc97 in ?? ()
#18 0x00000000005409bf in PyEval_EvalCode ()
#19 0x000000000060cb42 in ?? ()
#20 0x000000000060efea in PyRun_FileExFlags ()
#21 0x000000000060f7dc in PyRun_SimpleFileExFlags ()
#22 0x0000000000640256 in Py_Main ()
#23 0x00000000004d0001 in main ()
(gdb) 


"
34135,Failed to load delegate from libedgetpu.so.1.0,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Raspbian
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
Raspberry Pi
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version:
- Python version:
3.5
- Installed using virtualenv? pip? conda?:
pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the problem**
 libedgetpu.so.1.0 fails to load for certain user.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
  interpreter = Interpreter(args.model, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])

It works perfectly for the user I can sudo. But I want to use the library with a different user (that cannot do sudo). I found in another issue that I need to add this user to the plugdev group. Which I did with the following command:
sudo usermod -aG plugdev [your username] 
This did not solve the problem.

**Any other info / logs**
    interpreter = Interpreter(args.model, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])
  File ""/home/certain-user/.local/lib/python3.5/site-packages/tflite_runtime/interpreter.py"", line 168, in load_delegate
    library, str(e)))
ValueError: Failed to load delegate from libedgetpu.so.1.0
"
34133,logits and labels must have the same first dimension,"**System information**
- MAC OS 10.14.6
- Tensorflow 1.14

**Working model**
```python
input_layer=Input(shape=(X.shape[1],))
model=Embedding(input_dim=len(vocab)+1,output_dim=32,input_length=X.shape[1])(input_layer)
model = Bidirectional(LSTM(units = 50, return_sequences=True, recurrent_dropout=0.2))(model)
output_layer= Dense(3, activation=""softmax"")(model)

model = Model(input_layer,output_layer)
model.compile(optimizer=""adam"", loss=""sparse_categorical_crossentropy"", metrics=[""acc""])
model.summary()
```

**Trying to create same model with tf-lite layers of bi-directional LSTM**

```python

import os
os.environ['TF_ENABLE_CONTROL_FLOW_V2'] = '1'
import tensorflow as tf
import numpy as np
from tensorflow.lite.experimental.examples.lstm.rnn import bidirectional_dynamic_rnn

def build_LSTM_layer(num_layers):
    lstm_layers=[]
    for i in range(num_layers):
        lstm_layers.append(tf.lite.experimental.nn.TFLiteLSTMCell(num_units=50,name='rnn{}'.format(i),forget_bias=1.0))
    final_lstm_layer=tf.keras.layers.StackedRNNCells(lstm_layers)
    return final_lstm_layer
def build_bidirectional(inputs,num_layers,use_dynamic_rnn=True):
    lstm_inputs=transposed_inp=tf.transpose(inputs,[1,0,2])
    outputs,output_states=bidirectional_dynamic_rnn(build_LSTM_layer(num_layers),build_LSTM_layer(num_layers),lstm_inputs,dtype=""float"",time_major=True)
    fw_lstm_output,bw_lstm_output=outputs
    final_out=tf.concat([fw_lstm_output,bw_lstm_output],axis=2)
    
    final_out=tf.unstack(final_out,axis=0)
   
    resultant_out=final_out[-1]
    
    return resultant_out

tf.reset_default_graph()

model_tf = tf.keras.models.Sequential([
  tf.keras.layers.Input(shape=(X.shape[1],), name='input'),  
  tf.keras.layers.Embedding(input_dim=len(vocab)+1,output_dim=32,input_length=X.shape[1]),
  tf.keras.layers.Lambda(build_bidirectional, arguments={'num_layers' : 2, 'use_dynamic_rnn': True}),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(3, activation=tf.nn.softmax, name='output')
])
model_tf.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])
model_tf.summary()
```


**Inputs are token sequence and output should be NER tags which i get from keras model but not from above model**
```python
X.shape = (30, 16)
y.shape = (30, 16, 1)

I/P = array([[15., 10., 38.,  4., 32., 57., 39.,  0.,  0.,  0.,  0.,  0.,  0., 0.,  0.,  0.],...])
O/P = array([[[1.],[1.],[1.],[1.],[2.],[1.],[1.],[0.],[0.],[0.],
         [0.],[0.],[0.],[0.],[0.],[0.]],...])
```




**Output logs**
```Error
Epoch 1/10
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-503-89e5191da57e> in <module>
      2 train_x,test_x,train_y,test_y = train_test_split(X,y,test_size=0.2)
      3 
----> 4 history = model_tf.fit(train_x,train_y,epochs=10,batch_size=3)

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    778           validation_steps=validation_steps,
    779           validation_freq=validation_freq,
--> 780           steps_name='steps_per_epoch')
    781 
    782   def evaluate(self,

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)
    361 
    362         # Get outputs.
--> 363         batch_outs = f(ins_batch)
    364         if not isinstance(batch_outs, list):
    365           batch_outs = [batch_outs]

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in __call__(self, inputs)
   3290 
   3291     fetched = self._callable_fn(*array_vals,
-> 3292                                 run_metadata=self.run_metadata)
   3293     self._call_fetch_callbacks(fetched[-len(self._fetches):])
   3294     output_structure = nest.pack_sequence_as(

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py in __call__(self, *args, **kwargs)
   1456         ret = tf_session.TF_SessionRunCallable(self._session._session,
   1457                                                self._handle, args,
-> 1458                                                run_metadata_ptr)
   1459         if run_metadata:
   1460           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [3,3] and labels shape [48]
	 [[{{node loss/output_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]
```
"
34132,BatchNorm doesn't work in custom Model or Layer.,"**System information**
-Windows10
- TensorFlow: 2.0.0
- Python version: 3.7

**Describe the current behavior**

`InaccessibleTensorError: The tensor 'Tensor(""batch_normalization/batch_normalization_trainable:0"", dtype=bool)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=build_graph, id=3078774714504); accessed from: FuncGraph(name=keras_graph, id=3077450685512).`

**Code to reproduce the issue**


```
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU

def get_norm(norm_type):
    if norm_type == ""batch"":
        return BatchNormalization()
    else:
        raise ValueError(f""Unrecognized norm_type {norm_type}"")

class Discriminator(Model):
    def __init__(self,
                 base_filters=32,
                 lrelu_alpha=0.2,
                 pad_type=""same"",
                 norm_type=""batch""):
        super(Discriminator, self).__init__(name=""Discriminator"")
        # 1------------------------------------------
        self.conv1 = Conv2D(
                filters=base_filters, # 32
                kernel_size=3,     
                padding=pad_type
                )
        self.relu1 = LeakyReLU(alpha=lrelu_alpha)
        
        # 2-------------------------------------------
        self.conv2a = Conv2D(
                filters=base_filters*2, # 64
                strides=2,
                kernel_size=3, 
                padding=pad_type
                )
        self.relu2a = LeakyReLU(alpha=lrelu_alpha)
        self.conv2b = Conv2D(
                filters=base_filters*4, # 128
                kernel_size=3, 
                padding=pad_type
                )
        self.norm2 = get_norm(norm_type)
        self.relu2b = LeakyReLU(alpha=lrelu_alpha)
        
        # 3-----------------------------------------------
        self.conv3a = Conv2D(
                filters=base_filters*4, # 128
                strides=2,
                kernel_size=3, 
                padding=pad_type
                )
        self.relu3a = LeakyReLU(alpha=lrelu_alpha)
        self.conv3b = Conv2D(
                filters=base_filters*8, # 256
                kernel_size=3, 
                padding=pad_type
                )
        self.norm3 = get_norm(norm_type)
        self.relu3b = LeakyReLU(alpha=lrelu_alpha)
        
        # 4----------------------------------------------
        self.conv4 = Conv2D(
                filters=base_filters*8, # 256
                kernel_size=3, 
                padding=pad_type
                )
        self.norm4 = get_norm(norm_type)
        self.relu4 = LeakyReLU(alpha=lrelu_alpha)
        
        # final--------------------------------------------
        self.conv_final = Conv2D(
                filters=1, # 256
                kernel_size=3, 
                padding=pad_type
                )

    def build(self, input_shape):
        super(Discriminator, self).build(input_shape)

    def call(self, input_tensor, training=False):
        # 1---------------------------------------------------
        x = self.conv1(input_tensor, training=training)
        x = self.relu1(x, training=training)
        
        # 2--------------------------------------------------
        x = self.conv2a(x, training=training)
        x = self.relu2a(x, training=training)
        x = self.conv2b(x, training=training)
        x = self.norm2(x, training=training)
        x = self.relu2b(x, training=training)
        
        # 3------------------------------------------------
        x = self.conv3a(x, training=training)
        x = self.relu3a(x, training=training)
        x = self.conv3b(x, training=training)
        x = self.norm3(x, training=training)
        x = self.relu3b(x, training=training)
        
        # 4-------------------------------------------------
        x = self.conv4(x, training=training)
        x = self.norm4(x, training=training)
        x = self.relu4(x, training=training)
        
        # final--------------------------------------------
        x = self.conv_final(x, training=training)
        
        return x

if __name__ == ""__main__"":
    import numpy as np

    shape = (1, 128, 128, 3)
    nx = np.random.rand(*shape).astype(np.float32)
    t = tf.keras.Input(shape=nx.shape[1:], batch_size=nx.shape[0])

    #tf.keras.backend.clear_session()
    d = Discriminator()
    out = d(t)
    d.summary()
    print(f""Input  Shape: {t.shape}"")
    print(f""Output Shape: {out.shape}"")
```
"
34131,Negative sampling / candidate sampling with Keras API,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

It looks like TF Keras has no built in functions to do candidate sampling like in TF 1.0. As far as I can tell, the official keras word2vec example doesn't have negative sampling https://www.tensorflow.org/tutorials/text/word_embeddings even though it's an integral part for producing quality word embeddings. 

**Will this change the current api? How?**

The original tensorflow losses had options for negative sampling, including different distributions to select from. So perhaps some new loss functions and candidate sampling options will need to be added. 

**Who will benefit with this feature?**

Anyone who is training embedding models. 


"
34129,Looking for a simple gray scale and threshold function in tflite with flutter,"Hey everybody,
I know it's a wrong place to ask this question but I couldn't anywhere else active like GitHub, so here it goes.
I'm creating a flutter app that needs to get the stream of the frames from the camera and do some image processing on it, actually, just turning it into grayscale and do a threshold operation.
I couldn't find any library that can do that in Flutter.
I used to do these operations with Opencv and numpy in python, but with flutter, it's a whole other story.
I thought that maybe flutter ""tflite"" has this feature in it.

Thanks a lot and I'm sorry to post this question here."
34128,Exponential decay - missing argument step(),"I am facing the below error while using the exponential decay in Adam optimizer - 

**Code** 

`lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate = 0.0001,
    decay_steps=100000,
    decay_rate=0.96,
    staircase=True)

model = sm.Unet(
    'resnet50', 
    classes=4,
    input_shape=(320, 480, 3),
    activation='sigmoid'
)
model.compile(optimizer = Adam(lr = lr_schedule) ,  loss      = bce_dice_loss, metrics   = [dice_coef])
`

**Error** 
TypeError: __call__() missing 1 required positional argument: 'step'

What am I missing?
Please suggest."
34127,Impossible to use tf.keras.callbacks.ModelCheckpoint in distributed training,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow version (use command below): 2.0.0

**Describe the current behavior**
It is not possible to use `tf.keras.callbacks.ModelCheckpoint` in distributed training:
`RuntimeError: `add_update` was called in a cross-replica context. This is not expected. If you require this feature, please file an issue.`

**Code to reproduce the issue**
See [this Colab notebook](https://colab.research.google.com/drive/11CmG16-x9z-MMKoSeKaEKZ0zrnBdeMMV)."
34124,[Docs] Doc example of DeviceSpec doesn't work with tf 2.0,"Doc link: https://www.tensorflow.org/api_docs/python/tf/DeviceSpec
```python
import tensorflow as tf
device_spec = tf.DeviceSpec(job=""ps"", device_type=""CPU"", device_index=0)
with tf.device(device_spec):
  pass
```
Got error:
```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/context.py in __enter__(self)
   1508     try:
-> 1509       new_device_name, new_device_spec = _device_parsing_cache[cache_key]
   1510     except TypeError:

KeyError: ('', <tensorflow.python.framework.device_spec.DeviceSpecV2 object at 0x7f34c74de528>)

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/context.py in __enter__(self)
   1517         if not isinstance(new_device_name, six.string_types):
   1518           raise ValueError(""Expecting a string device name. Got %s(%s)"" %
-> 1519                            (type(new_device_name), new_device_name))
   1520         device_spec = pydev.DeviceSpec.from_string(new_device_name)
   1521         if old_device_name:

ValueError: Expecting a string device name. Got <class 'tensorflow.python.framework.device_spec.DeviceSpecV2'>(<tensorflow.python.framework.device_spec.DeviceSpecV2 object at 0x7f34c74de528>)
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 2.0.0
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34123,How can I know that the accuracy is good or not using RMSE for regression tasks?,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.13.1
- Python version:3.4.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:9.0/7.4
- GPU model and memory:Nvidia Geforce 840m



**Describe the current behavior**
Hello, 
My question is very simple, I have trained a model for regression task ( detect eye region with landmarks ) using training dataset of 160000 images and evaluate it after 50000 steps using eval_mse that based on `tf.metrics.root_mean_squared_error`.
I would like to know how can I know that the accuracy is good by viewing the value of the RMSE using the `Eval_mode` and `Tensorboard`

That was some screenshots:
![losse](https://user-images.githubusercontent.com/19480228/68531460-91e1a400-0312-11ea-8352-380751600678.PNG)

![graphhh](https://user-images.githubusercontent.com/19480228/68531464-9908b200-0312-11ea-822c-987a88f1528b.PNG)


How can I understand the value of the `eval_mse` and the scalar of the RMSE?


"
34122,Build failed on matrix_square_root_op using GCC 7.4.0 and Ubuntu 18.04,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
`
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=18.04
DISTRIB_CODENAME=bionic
DISTRIB_DESCRIPTION=""Ubuntu 18.04.3 LTS""
NAME=""Ubuntu""
VERSION=""18.04.3 LTS (Bionic Beaver)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 18.04.3 LTS""
VERSION_ID=""18.04""
HOME_URL=""https://www.ubuntu.com/""
SUPPORT_URL=""https://help.ubuntu.com/""
BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic
`

- TensorFlow installed from (source or binary):
Tensorflow github hash: ce0b9aa347979cfbe4291440a3aeeb7af3dda41d
- TensorFlow version:
2.0

- Python version:
Python 3.6.8

- Installed using virtualenv? pip? conda?:
Building

- Bazel version (if compiling from source):
bazel 0.29.1

- GCC/Compiler version (if compiling from source):
`
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 7.4.0-1ubuntu1~18.04.1' --with-bugurl=file:///usr/share/doc/gcc-7/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++ --prefix=/usr --with-gcc-major-version-only --program-suffix=-7 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) 
`

- CUDA/cuDNN version:
NA

- GPU model and memory:
NA

**Describe the problem**

I'm attempting to build Tensorflow from source to enable AVX2 and FMA instructions. I get the following error, which appears to be a compiler bug???

/projects/tensorflow/tensorflow/core/kernels/BUILD:3559:1: C++ compilation of rule '//tensorflow/core/kernels:matrix_square_root_op' failed (Exit 4)
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-7/README.Bugs> for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.


"
34120,The latest version(2.0.0) of TensorFlow import protobuf error,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.0.0
- Python version:3.6.0
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

v2.0.0-rc2-26-g64c3d382ca 2.0.0

**Describe the current behavior**

Importing tensorflow gives me following error.
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""E:\ProgramData\Anaconda3\envs\ai\lib\site-packages\tensorflow\__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""E:\ProgramData\Anaconda3\envs\ai\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""E:\ProgramData\Anaconda3\envs\ai\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""E:\ProgramData\Anaconda3\envs\ai\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""E:\ProgramData\Anaconda3\envs\ai\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""E:\ProgramData\Anaconda3\envs\ai\lib\site-packages\tensorflow_core\python\__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""E:\ProgramData\Anaconda3\envs\ai\lib\site-packages\tensorflow_core\core\framework\graph_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""E:\ProgramData\Anaconda3\envs\ai\lib\site-packages\google\protobuf\descriptor.py"", line 47, in <module>
    from google.protobuf.pyext import _message
ImportError: DLL load failed: 找不到指定的程序。
```
**Solution**
I already found a solution to this problem. It is related to the pip package protobuf 3.6.0. I solved this problem by issuing following commands:
```
pip uninstall protobuf
pip install protobuf==3.6.0
```
**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
import tensorflow
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34119,TF2.0 Calling set_session before fit_generator causes training to freeze when using multiprocessing,"**System information**
- Have I written custom code: No
- OS Platform and Distribution: Linux Ubuntu 16.04
- Mobile device if the issue happens on mobile device: N/A
- TensorFlow installed from: binary
- TensorFlow version: v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6
- Bazel version: N/A
- GCC/Compiler version: N/A
- CUDA/cuDNN version: 10.0 / 7
- GPU model and memory: GTX 1080Ti

**Describe the current behavior**
I am trying to modify TF session parameters in combination with Keras (e.g. the allowed GPU memory) and use `set_session()` to store these parameters. However, if `set_session()` is called  before `fit_generator()`, it causes the training to freeze when using multiprocessing. To reproduce the error use the following code. The Colab gist to reproduce the error can be found [here](https://colab.research.google.com/gist/moberweger/2553560a5deeb2eaa5e3cfc23516ef34/untitled217.ipynb). The colab execution of the code in question is not responding, so I stopped executing after 10 min, which ultimately gives me the error. This problems seems to occur also in 1.14, but not 1.15 !? as indicated in #33973. The gist might work when executed the first time, but the error can be reproduce after running the script a few times.

**Describe the expected behavior**
No freeze should occur.

**Code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf
import tensorflow.keras.backend as K
from tensorflow.keras.layers import Input, Conv2D
from tensorflow.keras.models import Model
from tensorflow.keras.utils import Sequence


def get_model(input_shape, output_shape, compile_batch_size):
    assert K.image_data_format() == 'channels_last'
    m_input = Input(shape=input_shape, batch_size=compile_batch_size)
    m_output = Conv2D(output_shape[-1], 1, activation=None)(m_input)
    model = Model(inputs=m_input, outputs=m_output)
    return model


class DataGenerator(Sequence):
    def __init__(self, batch_size, image_size, num_batches):
        assert K.image_data_format() == 'channels_last'

        self.batch_size = batch_size
        self.image_size = image_size
        self.num_batches = num_batches
        self.on_epoch_end()

    def __len__(self):
        assert self.num_batches > 0
        return self.num_batches

    def __getitem__(self, index):
        return np.zeros((self.batch_size,) + self.image_size).astype('float32'), np.zeros(
            (self.batch_size,) + self.image_size).astype('float32')

    def on_epoch_end(self):
        pass


if __name__ == '__main__':
    print(tf.version.GIT_VERSION, tf.version.VERSION)

    # set to True to trigger infinite wait
    if True:
        # limit GPU memory
        config = tf.compat.v1.ConfigProto()
        config.gpu_options.allow_growth = True
        config.gpu_options.per_process_gpu_memory_fraction = 0.5
        tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))

    inp_shape = (128, 64, 2)
    outp_shape = (128, 64, 2)
    batch_size = 16

    gen = DataGenerator(batch_size, inp_shape, 10)
    model = get_model(inp_shape, outp_shape, batch_size)
    model.summary()
    model.compile(loss=[""mse""], optimizer=""adam"", metrics=[""accuracy""])
    model.fit_generator(gen, steps_per_epoch=10, epochs=5, workers=2, use_multiprocessing=True)
```

**Other info / logs**
```
Traceback (most recent call last)

<ipython-input-4-26fa57f6f7f8> in <module>()
     55     model.summary()
     56     model.compile(loss=[""mse""], optimizer=""adam"", metrics=[""accuracy""])
---> 57     model.fit_generator(gen, steps_per_epoch=10, epochs=5, workers=2, use_multiprocessing=True)

7 frames

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1295         shuffle=shuffle,
   1296         initial_epoch=initial_epoch,
-> 1297         steps_name='steps_per_epoch')
   1298 
   1299   def evaluate_generator(self,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
    219     step = 0
    220     while step < target_steps:
--> 221       batch_data = _get_next_batch(generator)
    222       if batch_data is None:
    223         if is_dataset:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py in _get_next_batch(generator)
    361   """"""Retrieves the next batch of input data.""""""
    362   try:
--> 363     generator_output = next(generator)
    364   except (StopIteration, errors.OutOfRangeError):
    365     return None

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/data_utils.py in get(self)
    777     try:
    778       while self.is_running():
--> 779         inputs = self.queue.get(block=True).get()
    780         self.queue.task_done()
    781         if inputs is not None:

/usr/lib/python3.6/multiprocessing/pool.py in get(self, timeout)
    636 
    637     def get(self, timeout=None):
--> 638         self.wait(timeout)
    639         if not self.ready():
    640             raise TimeoutError

/usr/lib/python3.6/multiprocessing/pool.py in wait(self, timeout)
    633 
    634     def wait(self, timeout=None):
--> 635         self._event.wait(timeout)
    636 
    637     def get(self, timeout=None):

/usr/lib/python3.6/threading.py in wait(self, timeout)
    549             signaled = self._flag
    550             if not signaled:
--> 551                 signaled = self._cond.wait(timeout)
    552             return signaled
    553 

/usr/lib/python3.6/threading.py in wait(self, timeout)
    293         try:    # restore state no matter what (e.g., KeyboardInterrupt)
    294             if timeout is None:
--> 295                 waiter.acquire()
    296                 gotit = True
    297             else:
```
"
34118,An strange error about `tf.estimator.BoostedTreesClassifier`,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
    * no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
    * windows 10 and Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
    * source
- TensorFlow version (use command below):
    * Tensorflow-gpu 2.0 and tensorflow2.0
- Python version:
    * python 3.6 and python 3.7
- Bazel version (if compiling from source):
    * no
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
    * cuda10
- GPU model and memory:
    * GTX 1060 6G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I run the [boosted_trees_model_understanding tutorials](https://tensorflow.google.cn/tutorials/estimator/boosted_trees_model_understanding?hl=en), but it  high probability will run error, and my python will shutdown! I need to say, **that doesn`t run error every times**, but nearly 90%+ will run error. And this is the most strange things. 
![1](https://user-images.githubusercontent.com/15049049/68524375-293dfb80-0301-11ea-9bdc-9e3ca0684f03.png)
![2](https://user-images.githubusercontent.com/15049049/68524377-2c38ec00-0301-11ea-9f1f-ff9d64fd55c1.png)
![3](https://user-images.githubusercontent.com/15049049/68524378-2d6a1900-0301-11ea-8ff2-76eb6f0ca940.png)

**Describe the expected behavior**
It should run like the  [boosted_trees_model_understanding tutorials](https://tensorflow.google.cn/tutorials/estimator/boosted_trees_model_understanding?hl=en)
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python 
from __future__ import absolute_import, division, print_function, unicode_literals

import numpy as np
import pandas as pd
from IPython.display import clear_output

# Load dataset.
dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')
dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')
y_train = dftrain.pop('survived')
y_eval = dfeval.pop('survived')

import tensorflow as tf
tf.random.set_seed(123)

fc = tf.feature_column
CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',
                       'embark_town', 'alone']
NUMERIC_COLUMNS = ['age', 'fare']

def one_hot_cat_column(feature_name, vocab):
    return tf.feature_column.indicator_column(
        tf.feature_column.categorical_column_with_vocabulary_list(feature_name,
                                                 vocab))
feature_columns = []
for feature_name in CATEGORICAL_COLUMNS:
    # Need to one-hot encode categorical features.
    vocabulary = dftrain[feature_name].unique()
    feature_columns.append(one_hot_cat_column(feature_name, vocabulary))

for feature_name in NUMERIC_COLUMNS:
    feature_columns.append(tf.feature_column.numeric_column(feature_name,
                                           dtype=tf.float32))

# Use entire batch since this is such a small dataset.
NUM_EXAMPLES = len(y_train)

def make_input_fn(X, y, n_epochs=None, shuffle=True):
    def input_fn():
        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))
        if shuffle:
            dataset = dataset.shuffle(NUM_EXAMPLES)
        # For training, cycle thru dataset as many times as need (n_epochs=None).
        dataset = dataset.repeat(n_epochs)
        # In memory training doesn't use batching.
        dataset = dataset.batch(NUM_EXAMPLES)
        return dataset
    return input_fn

# Training and evaluation input functions.
train_input_fn = make_input_fn(dftrain, y_train)
eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)

params = {
  'n_trees': 50,
  'max_depth': 3,
  'n_batches_per_layer': 1,
  # You must enable center_bias = True to get DFCs. This will force the model to
  # make an initial prediction before using any features (e.g. use the mean of
  # the training labels for regression or log odds for classification when
  # using cross entropy loss).
  'center_bias': True
}

est = tf.estimator.BoostedTreesClassifier(feature_columns, **params)
# Train model.
est.train(train_input_fn, max_steps=100)

# Evaluation.
results = est.evaluate(eval_input_fn)
clear_output()
print(pd.Series(results))
```

but if i test [boosted_trees tutorials](https://tensorflow.google.cn/tutorials/estimator/boosted_trees?hl=en), and just the param changed. It will run fluently:
```python
n_batches = 1
est = tf.estimator.BoostedTreesClassifier(feature_columns,
                                          n_batches_per_layer=n_batches)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Error information on my win10 1903 computer with tensorflow-gpu 2.0
```python
2019-11-09 15:16:16.038790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
WARNING:tensorflow:Using temporary folder as model directory: C:\Users\sha\AppData\Local\Temp\tmp4qz0t419
WARNING:tensorflow:From C:\Users\sha\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_estimator\python\estimator\canned\boosted_trees.py:369: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From C:\Users\sha\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From C:\Users\sha\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\training\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2019-11-09 15:16:17.766728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2019-11-09 15:16:19.033200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:01:00.0
2019-11-09 15:16:19.033405: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-11-09 15:16:19.034037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
WARNING:tensorflow:From C:\Users\sha\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\feature_column\feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From C:\Users\sha\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_estimator\python\estimator\canned\boosted_trees.py:214: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From C:\Users\sha\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_estimator\python\estimator\canned\head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
2019-11-09 15:16:19.632757: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-11-09 15:16:19.931364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:01:00.0
2019-11-09 15:16:19.931565: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-11-09 15:16:19.932914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-09 15:16:20.627630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-09 15:16:20.627777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-09 15:16:20.627863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-09 15:16:20.628605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4708 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.

Process finished with exit code -1073740940 (0xC0000374)
```"
34117,Build failure: undefined reference to protobuf symbols,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3
- Python version:  Tried with python 3.7.3 and python 3.8
- Installed using virtualenv? pip? conda?: conda python 3.7.3 and virtualenv python 3.8
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: CUDA 10.0 and cuDNN 7.6.5
- GPU model and memory: Nvidia RTX 2080 Ti

**Describe the problem**
Build fails most of the way in to build.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout -b mybranch         (make up a branch to checkout head)
bazel build --config=opt --config=cuda --config=v2 --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/tools/pip_package:build_pip_package

Here is the last part of the terminal's output (attached text file):
[tensorflow_build_fails.txt](https://github.com/tensorflow/tensorflow/files/3826936/tensorflow_build_fails.txt)

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34116,ImportError: DLL load failed TF 1.13,"
**System information**
- win 10 x64  18362 (1903):
- pc:
- VS community tensorflow-gpu 1.13.1:
- tensorflow-gpu 1.13.1:
- Python 3.7:
- pip in VS community:
- all version 9.0 10.1/cudnn-10.1-windows10-x64-v7.6.5.32:
- 1060 6gb:
```

```
> 
> Using TensorFlow backend.
> Traceback (most recent call last):
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\imp.py"", line 242, in load_module
>     return load_dynamic(name, filename, file)
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\imp.py"", line 342, in load_dynamic
>     return _load(spec)
> ImportError: DLL load failed: Не найден указанный модуль.
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\ptvsd_launcher.py"", line 119, in <module>
>     vspd.debug(filename, port_num, debug_id, debug_options, run_as)
>   File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\debugger.py"", line 39, in debug
>     run()
>   File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\__main__.py"", line 316, in run_file
>     runpy.run_path(target, run_name='__main__')
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\runpy.py"", line 263, in run_path
>     pkg_name=pkg_name, script_name=fname)
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\runpy.py"", line 96, in _run_module_code
>     mod_name, mod_spec, pkg_name, script_name)
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\runpy.py"", line 85, in _run_code
>     exec(code, run_globals)
>   File ""C:\Users\sc20k\source\repos\Test yay\Test yay\Test_yay.py"", line 1, in <module>
>     from imageai.Detection import VideoObjectDetection
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\imageai\Detection\__init__.py"", line 2, in <module>
>     from imageai.Detection.keras_retinanet.models.resnet import resnet50_retinanet
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\imageai\Detection\keras_retinanet\models\resnet.py"", line 19, in <module>
>     import keras
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\keras\__init__.py"", line 3, in <module>
>     from . import utils
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
>     from . import conv_utils
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
>     from .. import backend as K
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
>     from .load_backend import epsilon
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\keras\backend\load_backend.py"", line 90, in <module>
>     from .tensorflow_backend import *
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
>     import tensorflow as tf
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
>     from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
>     from tensorflow.python import pywrap_tensorflow
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
>     raise ImportError(msg)
> ImportError: Traceback (most recent call last):
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\imp.py"", line 242, in load_module
>     return load_dynamic(name, filename, file)
>   File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\imp.py"", line 342, in load_dynamic
>     return _load(spec)
> ImportError: DLL load failed: Не найден указанный модуль.
> 
> 
> Failed to load the native TensorFlow runtime.
> 
> See https://www.tensorflow.org/install/errors
> 
> for some common reasons and solutions.  Include the entire stack trace
> above this error message when asking for help.
> 
> 
```

```"
34115,"Run Time series forecasting Tutorials , the warning raised. W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I try to run Time series forecasting Tutorials . the code was exactly same as the github shows.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
NONE
- TensorFlow installed from (source or binary):
source 
- TensorFlow version (use command below):
Tensorflow 2.0 stable version
- Python version:
py 3.7
- Bazel version (if compiling from source):
NONE
- GCC/Compiler version (if compiling from source):
NONE
- CUDA/cuDNN version:
NONE
- GPU model and memory:
NONE
You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
when I try to run the Time series forecasting Tutorials , the warning raised .
I don
2019-11-09 11:05:44.540408: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_2511_2996' and '__inference___backward_standard_lstm_2511_2996_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_3085' both implement 'lstm_b5a954a4-22ab-43b7-aa70-42d55d0dde61' but their signatures do not match.
**Describe the expected behavior**
how to solve this warning ?
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
the same as Tutorial. https://tensorflow.google.cn/tutorials/structured_data/time_series
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34114,Named dictionary inputs and outputs for tf.keras.Model,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

**feature request:**

If the user passes in dictionaries for the `inputs` or `outputs` argument during `tf.keras.Model` initialization, preserve the dictionary datatype in `tf.keras.Model.inputs` and `tf.keras.Model.outputs` (i.e. avoid normalizing these arguments to lists). 

This would allow us to refer to inputs and outputs by name rather than by indices in a list.

**current behavior/background:**

`tf.keras.Model` allows us to construct a `Model` with `inputs` and `outputs` arguments that are passed in as dictionaries of tensors. This is a very nice feature because it  allows you to evaluate a model by passing in dictionaries of named data, and to refer to outputs using their named outputs.

However, if one wants to *extend* a model by attaching more layers to a given output, we lose all of the naming information given to us during the model initialization. This is because the `inputs` and `outputs` arguments are always ""flattened"" to lists and assigned to `Model.outputs` and `Model.inputs` regardless if the user passed in a dictionary or not for these arguments.

As a result of losing this naming information, we have to fall back to using integer based indexing to retrieve the output tensor of interest that we want to extend. While not the end of the world, this is more error prone since layer ordering may move around due to changes in the initial model.

In the following example, I illustrate how defining, and extending a model with new layers currently works:

```python
from tensorflow.keras import Model
from tensorflow.keras.layers import Input, Dense

def create_base_model():
    # create initial model
    a = Input([10], dtype=tf.float32)
    b = Dense(4)(a)
    c = Dense(8)(b)
    model = Model(inputs={'a': a}, outputs={'b': b, 'c': c})
    return model

def extend_base_model(model):
    # create a new model to attach additional layers to tensor ""c""
    c = model.outputs[-2]
    d = Dense(16)(c)
    
    # notice here, since model.inputs and model.outputs are flattened to a lists,
    # we lose all naming information
    new_model = Model(inputs=model.inputs, outputs=model.outputs+[d])
    return new_model
    
base = create_base_model()
model = extend_base_model(base)

# we lose all naming information in the inputs and outputs given by the base model
# outputs: [<tensor>, <tensor> ,  <tensor>]
model(tf.zeros([1, 10], dtype=tf.float32))
```

If the feature request was adopted, here's how defining, extending, and executing models could work:

```python
from tensorflow.keras import Model
from tensorflow.keras.layers import Input, Dense

def create_base_model():
    # create initial model
    a = Input([10], dtype=tf.float32)
    b = Dense(4)(a)
    c = Dense(8)(b)
    model = Model(inputs={'a': a}, outputs={'b': b, 'c': c})
    return model

def extend_base_model(model):
    # create a new model to attach additional layers to tensor ""c""
    c = model.outputs[""c""]
    d = Dense(16)(c)
    
    new_model = Model(inputs=model.inputs, outputs={'d': d, **model.outputs})
    return new_model
    
base = create_base_model()
model = extend_base_model(base)

# we preserve all naming information in the inputs and outputs given by the base model
# outputs {""b"": <tensor>, ""c"": <tensor> , ""d"": <tensor>}
model({""a"": tf.zeros([1, 10], dtype=tf.float32))
```

**Will this change the current api? How?**

Yes, it will change `Model.input` and `Model.output` data types *if* the user passes in a dictionary for these arguments during initialization. 

current behavior:

```python
a = Input([10], dtype=tf.float32)
b = Dense(4)(a)
model = Model(inputs={'a': a}, outputs={'b': b})
type(model.inputs)  # list
type(model.outputs) # list
```

new behavior:

```python
a = Input([10], dtype=tf.float32)
b = Dense(4)(a)
model = Model(inputs={'a': a}, outputs={'b': b})
type(model.inputs)  # dict
type(model.outputs) # dict
```

**Who will benefit with this feature?**

People designing and developing models will be able to more easily and clearly expose output tensors for downstream users to access. 

Downstream users who need to extend a pre-defined models will more easily be able to access tensors using their named outputs.

**Any Other info.**

Not sure if this is the right way to implement this, but it looks like the `_nested_outputs` and `_nested_inputs` variables listed below preserve the data types of the inputs and outputs arguments that were initially passed into the Model constructor.

https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/keras/engine/network.py#L264-L265
"
34113,Decoding JPEGs much slower on Windows,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.15.0 GPU
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0/7.6.5
- GPU model and memory: 2080 Ti

My input pipeline is much slower on Windows than Linux.  On Linux, I'm using 10% of my CPU (Threadripper 2950x), to parse 1000 640x480 images per second.  On Windows, I'm using 85% of my CPU to parse 300 640x480 images per second.  I found [this TODO](https://github.com/tensorflow/tensorflow/blob/4b628e8a154c4fbd74ed13d3284fb887a5103e41/tensorflow/core/lib/jpeg/jpeg_mem.cc#L438), which suggests that the issue is that the windows builds of Tensorflow don't use libjpeg-turbo.  I dug a little and found [this issue](https://github.com/tensorflow/tensorflow/issues/4807) and [this PR](https://github.com/tensorflow/tensorflow/pull/5547), which covers the discussion of using libjpeg-turbo, but neither mention any issues with Windows.

Is it possible to use libjpeg-turbo on Windows?"
34112,"DatasetVariantWrapper ""No unary variant device copy function found""","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (but running on an official image)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04, running the Ubuntu 18.04 tensorflow-gpu Docker image provided by GCloud
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): tensorflow-gpu-2.0.0
- Python version: 3.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 10.0
- GPU model and memory: P100 x1

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I'm running Tensorflow on GCloud using the gcr.io/deeplearning-platform-release/tf2-gpu.2-0 image. I'm attempting to train a subclassed tf.keras.Model. 

I can train my image both on my local machine and GCloud, provided the --runtime=nvidia arg is NOT provided. When I add that argument, the GCloud image fails with the following error:

tensorflow.python.framework.errors_impl.InternalError:  No unary variant device copy function found for direction: 1 and Variant type_index: tensorflow::data::(anonymous namespace)::DatasetVariantWrapper
	 [[{{node MapDataset/_8}}]] [Op:__inference_get_input_516]


**Describe the expected behavior**

I expect TensorFlow to continue to run successfully when using the --runtime=nvidia arg, i.e. enabling CUDA.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

Because I have no understanding of the origin of this internal error, I am not sure how to create such a minimal case. Please advise.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Full failing log:

  File ""/home/zoobot/zoobot/estimators/run_estimator.py"", line 33, in run_estimator
    train_dataset = input_utils.get_input(config=config.train_config)
  File ""/root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/eager/def_function.py"", line 526, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""/root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""/root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File ""/root/miniconda3/lib/python3.5/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError:  No unary variant device copy function found for direction: 1 and Variant type_index: tensorflow::data::(anonymous namespace)::DatasetVariantWrapper
	 [[{{node MapDataset/_8}}]] [Op:__inference_get_input_516]

Full successful log, without using --runtime=nvidia:

2019-11-08 23:34:49.753010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-08 23:34:59.531666: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64
2019-11-08 23:34:59.531739: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-08 23:34:59.531778: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
2019-11-08 23:34:59.532239: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-08 23:34:59.540322: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-11-08 23:34:59.540738: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cf105c9a70 executing computations on platform Host. Devices:
2019-11-08 23:34:59.540776: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False
WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False
2019-11-08 23:35:37.148322: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-11-08 23:35:37.148432: E tensorflow/core/platform/default/device_tracer.cc:70] CUDA error: <unknown>
...
Epoch 1/100
..."
34111,How can I visualize the `learning_rate` metrics on Tensorboard?,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.13.1
- Python version:3.6.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:9.0/7.4
- GPU model and memory:Nvidia Geforce 840m



**Describe the current behavior**

I'm trying to visualize the `learning_rate` on Tensorboard using Estimator mode ( not Keras ).
I'm testing many solutions proposed on StackOverflow and on Github. But I didn't get any results.
I have tried also `tf.summary.scalar()` and `learning_rate_fn` functions, but any of those solutions doesn't work for me.
I really search for a solution to my problem 

that was some of my code 
```python
 # Calculate loss using mean squared error.
    label_tensor = tf.convert_to_tensor(labels, dtype=tf.float32)
    loss = tf.losses.mean_squared_error(
        labels=label_tensor, predictions=logits)
    tf.identity(loss, name='loss')
    tf.summary.scalar('loss', loss)

    # Create train hook list to visualize loss , accuracy and global_steps
    # Configure the train OP for TRAIN mode.

    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.AdamOptimizer(learning_rate=0.001) # Reducing the learning rate value from 0.001 to 0.0001
        train_op = optimizer.minimize(
            loss=loss,
            global_step=tf.train.get_global_step()
            )
        
    rmse_metrics = tf.metrics.root_mean_squared_error(labels=label_tensor,predictions=logits)
    metrics = {'eval_mse': rmse_metrics}	
    tf.identity(rmse_metrics[1], name='root_mean_squared_error')
    tf.summary.scalar('root_mean_squared_error', rmse_metrics[1])
    learning_rate=
    tf.identity(learning_rate, name='learning_rate')
    tf.summary.scalar('learning_rate',learning_rate)

    #return tf.estimator.EstimatorSpec(
     #   mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)
    return tf.estimator.EstimatorSpec(
        mode=mode,
        loss=loss,
        train_op=train_op,
        eval_metric_ops=metrics,
        export_outputs={'marks': tf.estimator.export.RegressionOutput(logits)})
    
```

Anyone can help me?




"
34107,huge amount of memory usage in load_model (tf 2.0),"Hi, I retrained a Inception + DenseLayer(512) using keras in tf 2.0.

When I load this model with tf 1.14, it uses something around 4G of GPU memory. But, when I'm doing the same with tf 2.0 it uses more than 25Gb of memory!!
This is correctly? That is some other config to load the model now?

I'm using an ec2 with a tesla v100 and cuda 10.1 



**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.14 and 2.0 (different environments)
- Python version: 3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla V100 

"
34103,Repeating numbers in uniform random Tensor created on GPU,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
Source
- TensorFlow version (use command below):
r1.12
- Python version:
3.6.6
- Bazel version (if compiling from source):
0.15.1
- GCC/Compiler version (if compiling from source):

- CUDA/cuDNN version:
9.0/7.4
- GPU model and memory:
Quadro M2200 4GiB

**Describe the current behavior**
I need to generate a tensor of uniform randoms inside a custom op. I basically copy the code for generating a tensor for zeros as is done [here](https://github.com/tensorflow/tensorflow/blob/5b900cfe4b3b848f577315a0dde09a729f770e95/tensorflow/contrib/rnn/kernels/lstm_ops.h#L31)

```c++
template <typename Device, typename T>
struct TensorRandom {
  void operator()(const Device& d, typename TTypes<T>::Flat t) {
    t.device(d) = t.random(); // this is my only change to the TensorZeros function
  }
};
```

Inside my kernel I have something like the following

```c++
TensorShape my_shape({N, H, W});
Tensor* random_mat;
OP_REQUIRES_OK(ctx, ctx->allocate_output(""random_mat"", my_shape, &random_mat));
const Device& device = ctx->eigen_device<Device>(); // this will be a gpu
functor::TensorRandom<Device, T>()(device, random_mat.flat<T>());

VLOG(1) << ""Random Mat "" << random_mat.shape().DebugString()
              << random_mat.SummarizeValue(N * H * W);
```

When I compile this and run my op (which I've defined in the python api) I get something like this for (N,H,W)=(2,4,2)

```
Random Mat: (2,4,2) [[[0.93335256, 0.53328224],
        [0.18036943, 0.12565934],
        [0.93335256, 0.53328224],
        [0.042617  , 0.61869474]],

       [[0.93335256, 0.53328224],
        [0.70387461, 0.88239244],
        [0.93335256, 0.53328224],
        [0.76217792, 0.65087953]]]
```

Notice the first value is repeated every 4 elements. The second value is also repeated every 4 values. The rest are seemingly random.

**Describe the expected behavior**
I would expect the output to be random. Instead, the first and second value are always repeated every fourth element. 

**Code to reproduce the issue**
See above. Only way I was able to test was by also creating the python bindings for the Op

**Other info / logs**
This issue occurs for all shapes of tensor I have tried. I've also checked the tensor is indeed aligned. I'm using single precision floating point numbers. I _highly_ suspect this is a GPU specific problem. If there is a better way to generate a random Tensor I'd be happy to use that as well"
34102,Download link for PoseNet tflite doesn't work,"Pose Net download link from https://www.tensorflow.org/lite/models/pose_estimation/overview
doesn't work.

https://storage.googleapis.com/download.tensorflow.org/models/tflite/posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite"
34101,batch_gather_nd op <del>Size Op</del> missing for Tensorflow Lite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
- TensorFlow installed from (source or binary): binary docker latest
- TensorFlow version (or github SHA if from source):v2.0.0-rc2-26-g64c3d38 2.0.0

Any model using `batch_gather_nd` (`gather_nd` when `batch!=0` and input tensor has indefinite batch dimension) will rely on `Size` op (`batch_gather_nd`->`meshgrid`->`size`->`Size`) when the batch dim is -1 (unspecified). Lack of `Size` op renders `gather_nd` op useless in many cases.

Another possible fix here: decouple `batch_gather_nd` from `Size`. (Is that possible?)

Here I used a monkey patch here to solve the problem: when batch dimension is 1, do not call `meshgrid` and directly use the `range` above the line since `range` does not rely on `size`.
```
    mesh_list = meshgrid(*dim_ranges, indexing=""ij"") if dim_ranges else []
```
changed into
```
    if len(dim_ranges)==0:
      mesh_list = [] 
    elif len(dim_ranges)==1:
      mesh_list = dim_ranges
    else:
      mesh_list = meshgrid(*dim_ranges, indexing=""ij"") if dim_ranges else []
```
That might be helpful if anyone want to use `batch_gather_nd` on tensorflow lite.

Update: I am wrong here. `batch_gather_nd` is not supported in tensorflow lite at all. The reason lies in that `batch_gather_nd` used `range` with indefinite length, which makes the dimension of the output empty; however `range` is used later and `tile`d and `concatenated` etc, however in the eyes of tensorflow optimizer, the shape is always [] so they are noop and any operation related are noop, effectively makes shape of every tensor related empty (`shape=[]`). So it is the `batch_gather_nd` op that is missing

Update: I have just noticed that Tensorflow Lite will always generate code for batch=1, so a fast solution is: set a export_lite flag in keras model definition part and make the lambda layer for batch_gather_nd act specially when exporting for tensorflow lite - return the tensor as if batch=1 even when batch=None actually.
So the problem remained for tensorflow devs here is: support the harmonious implementation of batch_gather_nd between tensorflow and tensorflow lite; or natively provide a GatherNd layer in keras that works correctly in tensorflow lite.

Summary:

Expected behavior: using gather_nd when batch=1 should generate correct graph when a keras model is exported into tensorflow lite

Actual behavior: batch_gather_nd fails to generate correct dimension for its output in tensorflow lite.

Reproduce: To reproduce behavior, use gather_nd in one lambda layer (with batch=1) and export the model into tensorflow lite

Problem: gather_nd should be specially dealt with in exporting process.

Monkey patch in user code: in the gather_nd function in your Lambda layer, check out whether you are exporting into a tensorflow lite binary. If an exporting is in progress, take as if the dim is 1 and keep the `batch_dims=0`. When `arg=[params,indices]`, simply `gather_nd(arg[0][0], arg[1])` will do the job.

Solution: make a dedicated GatherNd layer in keras who can correctly handle the different behavior between tensorflow and tensorflow lite."
34100,many proto files lack go_package,"**System information**
- OS Platform and Distribution: Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.15.0
- Python version: N/A
- Installed using virtualenv? pip? conda?: release .tar.gz
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**

As noted in https://github.com/golang/protobuf/issues/984, a number of `*.proto` files lack `go_version` statements. 

The commands:

```bash
protoc \
       -I./github.com/tensorflow/tensorflow \
       --go_out=plugins=grpc:./ \
       ./github.com/tensorflow/tensorflow/tensorflow/core/framework/*.proto
protoc \
       -I./github.com/tensorflow/tensorflow \
       --go_out=plugins=grpc:./ \
       ./github.com/tensorflow/tensorflow/tensorflow/core/protobuf/{saver,saved_model,struct,trackable_object_graph,saved_object_graph,meta_graph}.proto
```

give the error:

```bash
2019/11/07 14:43:01 protoc-gen-go: error:inconsistent package import paths: ""github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf"", ""tensorflow/core/protobuf""
```

I have worked around this locally by adding `go_package` statements to the following files so everything is emitted into `github.com/tensorflow/tensorflow/tensorflow/go/core`:

* tensorflow/core/protobuf/saved_object_graph.proto
* tensorflow/core/protobuf/struct.proto
* tensorflow/core/protobuf/trackable_object_graph.proto

```
option go_package = ""github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf"";
```

A number of other `*.proto` files also appear to lack `go_package`; not sure if they all need update:

```
$ grep -L go_package $(find tensorflow/core -name ""*.proto"")
tensorflow/core/kernels/boosted_trees/boosted_trees.proto
tensorflow/core/util/test_log.proto
tensorflow/core/util/memmapped_file_system.proto
tensorflow/core/util/saved_tensor_slice.proto
tensorflow/core/util/example_proto_fast_parsing_test.proto
tensorflow/core/util/event.proto
tensorflow/core/grappler/costs/op_performance_data.proto
tensorflow/core/profiler/tfprof_options.proto
tensorflow/core/profiler/tfprof_output.proto
tensorflow/core/profiler/profiler_analysis.proto
tensorflow/core/profiler/tfprof_log.proto
tensorflow/core/profiler/op_profile.proto
tensorflow/core/profiler/profiler_service.proto
tensorflow/core/profiler/profile.proto
tensorflow/core/protobuf/trace_events.proto
tensorflow/core/protobuf/conv_autotuning.proto
tensorflow/core/protobuf/autotuning.proto
tensorflow/core/protobuf/graph_debug_info.proto
tensorflow/core/protobuf/eager_service.proto
tensorflow/core/protobuf/replay_log.proto
tensorflow/core/protobuf/transport_options.proto
tensorflow/core/protobuf/tpu/compilation_result.proto
tensorflow/core/protobuf/tpu/optimization_parameters.proto
tensorflow/core/protobuf/tpu/tpu_embedding_output_layout.proto
tensorflow/core/protobuf/tpu/topology.proto
tensorflow/core/protobuf/tpu/tpu_embedding_configuration.proto
tensorflow/core/protobuf/tpu/dynamic_padding.proto
tensorflow/core/protobuf/data/experimental/snapshot.proto
tensorflow/core/debug/debug_service.proto
tensorflow/core/debug/debugger_event_metadata.proto
```

Closely related to https://github.com/tensorflow/tensorflow/issues/16282, https://github.com/tensorflow/tensorflow/issues/30093 and a few other issues/PRs that attempt to incrementally add `go_package` statements."
34099,Warning when using fit_generator,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit_generator
https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict_generator

## Description of issue (what needs changing):

### Clear description

I have had pain debugging here so it would be better if the documentation mentions the fallacy here.

My experience is: I used ctypes C++ to generate training data into a fixed numpy buffer and the generator merely invoked C++ method and return the same buffer in each iteration (with different content obviously). This is problematic as the internal implementation of `fit_generator` will iterate in advance. The correct usage is to make a copy of the buffer each time iterator is iterated

The document should probably mention explicitly that the method does not make deep copy of the return values of the generator on its generation, so e.g. **it is probably not a good idea to share a same numpy buffer across different batches - if one want to yield from same buffer due to certain reasons, one good practice is to make a `nparray.copy()` before `yield`**.

"
34098,Seemingly unavailable datatypes for Ops.,"In [`training_ops.cc:640`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/training_ops.cc#L640) I see many registrations for Ops, which have datatypes only supported for non-Windows.

For example:
```cpp
#define REGISTER_KERNELS(D, T)                                                \
  REGISTER_KERNEL_BUILDER(                                                    \
      Name(""ApplyGradientDescent"").Device(DEVICE_##D).TypeConstraint<T>(""T""), \
      ApplyGradientDescentOp<D##Device, T>);                                  \
  REGISTER_KERNEL_BUILDER(Name(""ResourceApplyGradientDescent"")                \
                              .Device(DEVICE_##D)                             \
                              .HostMemory(""var"")                              \
                              .TypeConstraint<T>(""T""),                        \
                          ApplyGradientDescentOp<D##Device, T>);
#define REGISTER_CPU_KERNELS(T) REGISTER_KERNELS(CPU, T);

TF_CALL_half(REGISTER_CPU_KERNELS);
TF_CALL_bfloat16(REGISTER_CPU_KERNELS);
TF_CALL_float(REGISTER_CPU_KERNELS);
TF_CALL_double(REGISTER_CPU_KERNELS);
#ifndef PLATFORM_WINDOWS
TF_CALL_complex64(REGISTER_CPU_KERNELS);
TF_CALL_complex128(REGISTER_CPU_KERNELS);
#endif
```
Seeing this, we quickly switched and ran our code on a Linux build, hoping the Op would be available for complex128, but it turns out also on Linux, it's not, as indicated by following error:
```
NotFoundError: No registered 'ResourceApplyGradientDescent' OpKernel for 'GPU' devices compatible with node {{node ResourceApplyGradientDescent}}
	 (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_COMPLEX64, use_locking=true
	.  Registered:  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]
  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_HALF]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_HALF]
  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]
 [Op:ResourceApplyGradientDescent]
```
This TensorFlow 2.0 version was installed with `pip install tensorflow-gpu`, minutes ago. Let's say I'm currently interested in having access to the `ApplyGradientDescent` with complex128 for CPU.

Currently compiling TensorFlow myself, to test this. However, the actual questions are:
 - Why are these not supported on Windows?
 - Why are these seemingly not available on a pip-installed TensorFlow version on Linux? Is this an issue with the build process of the pip-release of TensorFlow for Linux?
 - Any recommendations on how to proceed? (I'm currently compiling TensorFlow from source on Linux, hoping for the Op to be available)."
34097,python/keras/engine/network.py:layers took great deal of prediction time on deep networks when using methods like predict_on_batch,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary, docker
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0


**Describe the current behavior**

When I am using keras and profiling with cProfile, I found that seemly innocent `@property`s of `network.py` become performance bottleneck.

```
  @property
  def dynamic(self):
    if self._is_graph_network:
      return any(layer.dynamic for layer in self.layers)
    return self._dynamic or any(layer.dynamic for layer in self.layers)
  @property
  def layers(self):
    return trackable_layer_utils.filter_empty_layer_containers(
        self._layers)
```

The functions are called fairly frequently without caching the results, and as a result I see them along with related functions (`filter_empty_layer_containers` for example) took inproportional amount of cpu cycles when gpu is hungry. It does not seem right to call the functions again and again when their values are fixed, and they are using 2/3 of the training time. (When will anyone train a network whose dynamicness and number of layers are constantly fluctuating?)

Anyone may try with standard deep resnet with predict_generator/fit_generator and find out whether they are most time consuming.
"
34096,Cannot load saved model fitted via csv dataset,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
I load data from a csv file to create the dataset for fitting my model. After saving the model, I can't load it again. I get the following error message:
`ValueError: ('We expected a dictionary here. Instead we got: ', <tf.Tensor 'Placeholder:0' shape=(None,) dtype=float32>)`

**Describe the expected behavior**
The program should load the model.

**Code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow import keras

dataset: tf.data.Dataset = tf.data.experimental.make_csv_dataset('xor.csv', 4, label_name='result')
columns = [tf.feature_column.numeric_column('a'), tf.feature_column.numeric_column('b')]
input_column = keras.layers.DenseFeatures(columns)
layers = [input_column,
          keras.layers.Dense(4, activation='relu'),
          keras.layers.Dense(2)]
model = keras.Sequential(layers)
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])
model.fit(dataset, steps_per_epoch=4, epochs=2000)
keras.models.save_model(model, 'test_model.h5')
# model.save('test_model.h5')
model = keras.models.load_model('test_model.h5')
```
xor.csv:
```
a,b,result
0,0,0
0,1,1
1,0,1
1,1,0
```

**Other info / logs**
```
Traceback (most recent call last):
...
  File ""main.py"", line 76, in main
    model = keras.models.load_model('test_model.h5')
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 146, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 168, in load_model_from_hdf5
    custom_objects=custom_objects)
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py"", line 55, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py"", line 106, in deserialize
    printable_module_name='layer')
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 303, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 380, in from_config
    model.build(build_input_shape)
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 260, in build
    super(Sequential, self).build(input_shape)
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 682, in build
    self.call(x, **kwargs)
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 281, in call
    outputs = layer(inputs, **kwargs)
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 778, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/.../lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:
    /.../lib/python3.7/site-packages/tensorflow_core/python/feature_column/dense_features.py:129 call
        features)
    ValueError: ('We expected a dictionary here. Instead we got: ', <tf.Tensor 'Placeholder:0' shape=(None,) dtype=float32>)
```
"
34095,"An op called ""int"" appears in Tensorflow","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
The dependency ""@com_google_ortools//ortools/constraint_solver:cp"" was introduced in the tensorflow/compiler/xla/service/cpu:cpu_compiler deps
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.14.0
- Python version: python 3.6.8
- Bazel version (if compiling from source): 0.25.1
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version: non
- GPU model and memory: non


**Describe the current behavior**
I am trying to re-develop xla. When I introduce ""@com_google_ortools//ortools/constraint_solver:cp"" dependency in the tensorflow/compiler/xla/service/cpu:cpu_compiler deps, the source code can be passed and passed. Pip is installed normally, but once the tensorflow interface is called, an op registration error named ""int"" is thrown.
This is the change of tensorflow/compiler/xla/service/cpu:cpu_compiler
```
cc_library(
    name = ""cpu_compiler"",
    srcs = [""cpu_compiler.cc""],
    hdrs = [""cpu_compiler.h""],
    deps = [
        "":compiler_functor"",
        "":buffer_info_util"",
        "":conv_canonicalization"",
        "":cpu_executable"",
        "":cpu_hlo_support_checker"",
        "":cpu_instruction_fusion"",
        "":cpu_layout_assignment"",
        "":cpu_options"",
        "":disassembler"",
        "":dot_op_emitter"",
        "":ir_emission_utils"",
        "":ir_emitter"",
        "":parallel_task_assignment"",
        "":simple_orc_jit"",
        ""@com_google_absl//absl/memory"",
        ""@com_google_absl//absl/strings"",
        "":target_machine_features"",
        ""@com_google_absl//absl/types:span"",
        ""//tensorflow/compiler/xla/service:copy_insertion"",
        ""//tensorflow/compiler/xla/service:hlo_casting_utils"",
        ""//tensorflow/compiler/xla/service:dump"",
        ""//tensorflow/compiler/xla/service:map_inliner"",
        ""//tensorflow/compiler/xla/service:hlo_get_dimension_size_rewriter"",
        ""//tensorflow/compiler/xla/service:conditional_to_select"",
        ""//tensorflow/compiler/xla/service:scatter_expander"",
        ""//tensorflow/compiler/xla/service:slice_sinker"",
        ""//tensorflow/compiler/xla:cpu_function_runtime"",
        ""//tensorflow/compiler/xla:literal"",
        ""//tensorflow/compiler/xla:protobuf_util"",
        ""//tensorflow/compiler/xla:status_macros"",
        ""//tensorflow/compiler/xla:statusor"",
        ""//tensorflow/compiler/xla:types"",
        ""//tensorflow/compiler/xla:util"",
        ""//tensorflow/compiler/xla:xla_data_proto"",
        ""//tensorflow/compiler/xla/service:algebraic_simplifier"",
        ""//tensorflow/compiler/xla/service:batch_dot_simplification"",
        ""//tensorflow/compiler/xla/service:batchnorm_expander"",
        ""//tensorflow/compiler/xla/service:buffer_assignment"",
        ""//tensorflow/compiler/xla/service:buffer_liveness"",
        ""//tensorflow/compiler/xla/service:call_inliner"",
        ""//tensorflow/compiler/xla/service:cholesky_expander"",
        ""//tensorflow/compiler/xla/service:conditional_simplifier"",
        ""//tensorflow/compiler/xla/service:convolution_group_converter"",
        ""//tensorflow/compiler/xla/service:dot_decomposer"",
        ""//tensorflow/compiler/xla/service:dynamic_index_splitter"",
        ""//tensorflow/compiler/xla/service:executable"",
        ""//tensorflow/compiler/xla/service:flatten_call_graph"",
        ""//tensorflow/compiler/xla/service:hlo"",
        ""//tensorflow/compiler/xla/service:hlo_constant_folding"",
        ""//tensorflow/compiler/xla/service:hlo_cse"",
        ""//tensorflow/compiler/xla/service:hlo_dce"",
        ""//tensorflow/compiler/xla/service:hlo_element_type_converter"",
        ""//tensorflow/compiler/xla/service:hlo_ordering"",
        ""//tensorflow/compiler/xla/service:hlo_pass"",
        ""//tensorflow/compiler/xla/service:hlo_pass_pipeline"",
        ""//tensorflow/compiler/xla/service:hlo_proto"",
        ""//tensorflow/compiler/xla/service:hlo_proto_util"",
        ""//tensorflow/compiler/xla/service:hlo_memory_scheduler"",
        ""//tensorflow/compiler/xla/service:hlo_subcomputation_unification"",
        ""//tensorflow/compiler/xla/service:hlo_verifier"",
        ""//tensorflow/compiler/xla/service:indexed_array_analysis"",
        ""//tensorflow/compiler/xla/service:llvm_compiler"",
        ""//tensorflow/compiler/xla/service:reduce_precision_insertion"",
        ""//tensorflow/compiler/xla/service:reshape_mover"",
        ""//tensorflow/compiler/xla/service:rng_expander"",
        ""//tensorflow/compiler/xla/service:sort_simplifier"",
        ""//tensorflow/compiler/xla/service:transpose_folding"",
        ""//tensorflow/compiler/xla/service:triangular_solve_expander"",
        ""//tensorflow/compiler/xla/service:tuple_simplifier"",
        ""//tensorflow/compiler/xla/service:while_loop_constant_sinking"",
        ""//tensorflow/compiler/xla/service:while_loop_invariant_code_motion"",
        ""//tensorflow/compiler/xla/service:while_loop_simplifier"",
        ""//tensorflow/compiler/xla/service:zero_sized_hlo_elimination"",
        ""//tensorflow/compiler/xla/service/llvm_ir:llvm_util"",  # fixdeps: keep
        ""//tensorflow/core:lib"",  # fixdeps: keep
        ""//tensorflow/core:stream_executor_no_cuda"",
        ""@llvm//:aarch64_code_gen"",  # fixdeps: keep
        ""@llvm//:aarch64_disassembler"",  # fixdeps: keep
        ""@llvm//:arm_code_gen"",  # fixdeps: keep
        ""@llvm//:arm_disassembler"",  # fixdeps: keep
        ""@llvm//:core"",
        ""@llvm//:mc"",  # fixdeps: keep
        ""@llvm//:object"",
        ""@llvm//:support"",
        ""@llvm//:target"",  # fixdeps: keep
        ""@llvm//:x86_code_gen"",  # fixdeps: keep
        ""@llvm//:x86_disassembler"",  # fixdeps: keep
        ""@com_google_ortools//ortools/constraint_solver:cp"",
    ] + select({
        ""//tensorflow:linux_ppc64le"": [
            ""@llvm//:powerpc_disassembler"",
            ""@llvm//:powerpc_code_gen"",
        ],
        ""//conditions:default"": [
        ],
    }),
    alwayslink = True,  # Contains compiler registration
)
```

This is where the introduction of ortools depends on third_party/ortools/workspace.bzl.

```
load(""//third_party:repo.bzl"", ""third_party_http_archive"")
load(""@bazel_tools//tools/build_defs/repo:http.bzl"", ""http_archive"")
load(""@bazel_tools//tools/build_defs/repo:git.bzl"", ""git_repository"", ""new_git_repository"")

def repo():
    git_repository(
        name = ""com_google_protobuf_cc"",
        commit = ""0974557"",  # release v3.8.0
        remote = ""https://github.com/protocolbuffers/protobuf.git"",
    )

    http_archive(
        name = ""com_google_ortools"",
        urls = [
            ""http://mirror.tensorflow.org/github.com/google/or-tools/archive/v7.2.tar.gz"",
            ""https://github.com/google/or-tools/archive/v7.2.tar.gz"",
        ],
        sha256 = ""13a4de5dba1f64e2e490394f8f63fe0a301ee55466ef65fe309ffd5100358ea8"",
        strip_prefix = ""or-tools-7.2"",
        build_file = ""//third_party/ortools:BUILD.bazel"",
        patch_cmds = [
            ""find  -name 'BUILD' -print0 | xargs -0 sed -i 's/com_google_protobuf_cc/com_google_protobuf/g'"",
        ],
    )

    http_archive(
        name = ""com_github_glog_glog"",
        urls = [
            ""http://mirror.tensorflow.org/github.com/google/glog/archive/v0.4.0.tar.gz"",
            ""https://github.com/google/glog/archive/v0.4.0.tar.gz"",
        ],
        sha256 = ""f28359aeba12f30d73d9e4711ef356dc842886968112162bc73002645139c39c"",
        strip_prefix = ""glog-0.4.0"",
        #        build_file = ""//com_github_glog_glog:BUILD"",
        patch_cmds = [
            ""mkdir glog_internal && mkdir build && cd build && cmake .. && cp config.h ../glog_internal && cp config.h ../src"",
            ""sed -i 's/:config_h/src\/config.h/g' bazel/glog.bzl"",
        ],
    )

```

**This is the running environment and error information after installing the Tensorflow source code.
```
Python 3.6.8 (default, Oct  7 2019, 12:59:55) 
[GCC 8.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/ubuntu/.virtualenvs/run/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
>>> tf.Graph
<class 'tensorflow.python.framework.ops.Graph'>
>>> tf.Graph()
2019-11-08 09:13:06.526896: F tensorflow/core/framework/op.cc:200] Non-OK-status: RegisterAlreadyLocked(deferred_[i]) status: Invalid argument: Invalid name: int (Did you use CamelCase?); in OpDef: name: ""int"" input_arg { name: ""int"" description: ""int"" type: DT_FLOAT type_attr: ""int"" number_attr: ""int"" type_list_attr: ""int"" } input_arg { name: ""int"" description: ""int"" type: DT_FLOAT type_attr: ""int"" number_attr: ""int"" type_list_attr: ""int"" } attr { name: ""int"" type: ""int"" default_value { i: -1 } description: ""int"" has_minimum: true minimum: -1 } attr { name: ""int"" type: ""int"" default_value { s: """" } description: ""int"" } attr { name: ""int"" type: ""int"" description: ""int"" } attr { name: ""int"" type: ""int"" description: ""int"" } summary: ""int"" description: ""int"" is_stateful: true
Aborted (core dumped)
```
"
34094,"When i try run the  `tf.keras.layers.Bidirectional` on my windows system, it turns out CancelledError!  ","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
    * no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
    * windows 10 1903
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
    * source 
- TensorFlow version (use command below):
    * tensorflow-gpu 2.0
- Python version:
    * Python 3.6.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
    * cuda10
- GPU model and memory:
    * gtx1060 6G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

this is my model, from the [tutorials](https://tensorflow.google.cn/tutorials/text/text_classification_rnn?hl=en):
```python
embedding_dim=16

model = keras.Sequential([
    layers.Embedding(encoder.vocab_size, embedding_dim),
    layers.Bidirectional(tf.keras.layers.LSTM(32)),
    layers.Dense(1, activation='sigmoid')
])
```

but it train error on my computer:
```python
---------------------------------------------------------------------------
CancelledError                            Traceback (most recent call last)
<ipython-input-11-35c641747dc0> in <module>
      6     train_batches,
      7     epochs=10,
----> 8     validation_data=test_batches, validation_steps=20,verbose=2)

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--> 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--> 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---> 86                               distributed_function(input_fn))
     87 
     88   return execution_function

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    485       # In this case we have created variables on the first call, so we run the
    486       # defunned version which is guaranteed to never create variables.
--> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    488     elif self._stateful_fn is not None:
    489       # Release the lock early so that multiple threads can perform the call

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   1821     """"""Calls a graph function specialized to the inputs.""""""
   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 
   1825   @property

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1139          if isinstance(t, (ops.Tensor,
   1140                            resource_variable_ops.BaseResourceVariable))),
-> 1141         self.captured_inputs)
   1142 
   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1222     if executing_eagerly:
   1223       flat_outputs = forward_function.call(
-> 1224           ctx, args, cancellation_manager=cancellation_manager)
   1225     else:
   1226       gradient_name = self._delayed_rewrite_functions.register()

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    509               inputs=args,
    510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 511               ctx=ctx)
    512         else:
    513           outputs = execute.execute_with_cancellation(

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

c:\users\sha\anaconda3\envs\tensorflow2\lib\site-packages\six.py in raise_from(value, from_value)

CancelledError:  [_Derived_]RecvAsync is cancelled.
	 [[{{node Adam/Adam/update/AssignSubVariableOp/_41}}]]
	 [[Reshape_11/_38]] [Op:__inference_distributed_function_15971]

Function call stack:
distributed_function

```
**Describe the expected behavior**
It should train fluently, and i try on Google cloab, it try fluently, but it train error on my computer. 
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
the code
```python
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

import tensorflow_datasets as tfds
# tfds.disable_progress_bar()
(train_data, test_data), info = tfds.load(
    'imdb_reviews/subwords8k', 
    split = (tfds.Split.TRAIN, tfds.Split.TEST), 
    with_info=True, as_supervised=True)
encoder = info.features['text'].encoder
padded_shapes = ([None],())
train_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)
test_batches = test_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)

embedding_dim=16

model = keras.Sequential([
    layers.Embedding(encoder.vocab_size, embedding_dim,mask_zero=True),
    layers.Bidirectional(tf.keras.layers.LSTM(32)),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_batches,
    epochs=10,
    validation_data=test_batches, validation_steps=20,verbose=2)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

the error information is showed above 
"
34093,[TF2.0] GradientTape.gradient raise SystemError when calling embedding_column layer multiple times with tf.function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tf-nightly-gpu-2.0-preview
- TensorFlow version (use command below): v1.12.1-14959-g9663619 2.0.0-dev20191002
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cudatoolkit=10.0.130  cudnn=7.6.4
- GPU model and memory:

**Describe the current behavior**
When calling a ```tf.keras.layers.DenseFeatures``` layer created from ```tf.feature_column.embedding_column``` multiple times and calculate the gradients with ```GradientTape.gradient```, using ```@tf.function``` may cause ```GradientTape.gradient``` raise ```SystemError```, depends on the number of times we call the same layer( error raise if we call it more than 4 times ).

Without ```@tf.function```, everything is fine. 

**Describe the expected behavior**
The gradients should be calculated well regardless of how many times we call the layer within a ```@tf.function```.

**Code to reproduce the issue**
```python
import tensorflow as tf


ft_col_numeric = tf.feature_column.numeric_column(""test_input"")
ft_col_buk     = tf.feature_column.bucketized_column(ft_col_numeric, boundaries=[1, 3, 5, 7])
ft_col_embed   = tf.feature_column.embedding_column(ft_col_buk, dimension=4)
ft_embed_layer = tf.keras.layers.DenseFeatures(ft_col_embed)

# crash when the call number is greater than 4
LAYER_CALL_NUM = 5

@tf.function
def run(inputs):
    with tf.GradientTape() as tape:
        res_list = []
        for i in range(LAYER_CALL_NUM):
            x = ft_embed_layer(inputs)
            res_list.append(x)
        y = tf.reduce_sum(sum(res_list))
    weights = ft_embed_layer.trainable_variables
    gradients = tape.gradient(y, weights)
    return gradients

test_input = tf.constant([0, 2, 4, 6, 8])
inputs = { ""test_input"" : test_input }
run(inputs)
```

**Other info / logs**
```
Traceback (most recent call last):
  File ""test.py"", line 26, in <module>
    run(inputs)
  File ""/home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 553, in __call__
    result = self._call(*args, **kwds)
  File ""/home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 599, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 492, in _initialize
    *args, **kwds))
  File ""/home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2320, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2628, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2517, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 943, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 434, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 933, in wrapper
    raise e.ag_error_metadata.to_exception(e)
tensorflow.python.autograph.impl.api.StagingError: in converted code:

    test.py:21 run  *
        gradients = tape.gradient(y, weights)
    /home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:1023 gradient
        unconnected_gradients=unconnected_gradients)
    /home/user/anaconda3/envs/tf2_nt_last/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py:76 imperative_grad
        compat.as_str(unconnected_gradients.value))

    SystemError: <built-in function TFE_Py_TapeGradient> returned a result with an error set
```
"
34091,Failed to run the unit test of bonus_tests,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos7.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0 master branch, commit-id:af019188adc704569b7cce51e50eba489af1a725 
- Python version: 3.6
- Bazel version (if compiling from source): 0.27.1
- GCC/Compiler version (if compiling from source): 6.3
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
After build from source code:
```
bazel --output_user_root=$build_dir build --config=v2 //tensorflow/tools/pip_package:build_pip_package 
```

I run the unit test:
```
bazel --output_user_root=$build_dir test //tensorflow/core/kernels:bonus_tests
```
It failed with the error message:

_ERROR: no such target '//tensorflow/core/kernels:bonus_tests': target 'bonus_tests' not declared in package 'tensorflow/core/kernels' (did you mean 'loss_test'?) defined by /home/lesliefang/debug_failrunbonus_tests/tensorflow/tensorflow/core/kernels/BUILD
INFO: Elapsed time: 0.382s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
FAILED: Build did NOT complete successfully (0 packages loaded)_


**Describe the expected behavior**
The unit test should run successfully.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
As the description above.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34090,ResourceScatterNdUpdate bug in graph mode and tape.gradient(),"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.0.130
- GPU model and memory: GeForce RTX 2080 Ti

**Describe the current behavior**
Running the code gets the following error:
```
 ValueError: The inner -1 dimensions of input.shape=[] must match the inner 1 dimensions of updates.shape=[4,20]: Shapes must be equal rank, but are 0 and 1 for 'ResourceScatterNdUpdate' (op: 'ResourceScatterNdUpdate') with input shapes: [], [4,1], [4,20].
```
There is no error if running the code without @tf.function decoration, or without using while_loop, or without using tape.gradient()

**Describe the expected behavior**
Code should run without error

**Code to reproduce the issue**
```python
import tensorflow as tf

def main():
    dim = 20
    capacity = 256
    batch_size = 4
    buffer = tf.Variable(
            initial_value=tf.zeros((capacity, dim)),
            trainable=False)
    w = tf.Variable(
        initial_value=tf.zeros(()), trainable=True)

    def _loop_body(loss):
        loss += w.value()
        indices = tf.range(batch_size)
        indices = tf.expand_dims(indices, axis=-1)
        # Error disappears if running buffer.scatter_nd_update inside tf.cond
        # tf.cond(tf.shape(indices)[0] > 0, lambda:
        buffer.scatter_nd_update(indices, tf.zeros(shape=(batch_size, dim))),
        # lambda: buffer.value())
        return [loss]

    # Error disappears if @tf.function is removed
    @tf.function
    def _loop():
        unroll_length = 10
        loss = tf.zeros(())
        with tf.GradientTape() as tape:
            [loss] = tf.while_loop(
                cond=lambda *_: True,
                body=_loop_body,
                loop_vars=[loss],
                back_prop=True,
                maximum_iterations=unroll_length)
            # Error disappears if removing the previous while_loop()
            # and uncomment the following line
            # [loss] = _loop_body(loss)
        # Error disappears if removing tape.gradient()
        tape.gradient(loss, w)
        w.assign_add(loss)

    _loop()

if __name__ == '__main__':
    main()
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Full error message:
```
Traceback (most recent call last):
  File ""scatter_nd_bug.py"", line 45, in <module>
    main()
  File ""scatter_nd_bug.py"", line 42, in main
    _loop()
  File ""/home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""/home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 905, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    scatter_nd_bug.py:39 _loop  *
        tape.gradient(loss, w)
    /home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:1014 gradient
        unconnected_gradients=unconnected_gradients)
    /home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py:76 imperative_grad
        compat.as_str(unconnected_gradients.value))
    /home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:138 _gradient_function
        return grad_fn(mock_op, *out_grads)
    /home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py:336 _WhileGrad
        body_graph = _get_graph(while_op, ""body"")
    /home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py:557 _get_graph
        func_graph = function_def_to_graph.function_def_to_graph(fdef, input_shapes)
    /home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/function_def_to_graph.py:65 function_def_to_graph
        importer.import_graph_def_for_function(graph_def, name="""")
    /home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py:412 import_graph_def_for_function
        graph_def, validate_colocation_constraints=False, name=name)
    /home/weixu/venvs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py:505 _import_graph_def_internal
        raise ValueError(str(e))

    ValueError: The inner -1 dimensions of input.shape=[] must match the inner 1 dimensions of updates.shape=[4,20]: Shapes must be equal rank, but are 0 and 1 for 'ResourceScatterNdUpdate' (op: 'ResourceScatterNdUpdate') with input shapes: [], [4,1], [4,20].
```"
34088,metrics = ['accuracy'] and metrics = [tf.metrics.Accuracy()] produces different results,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: v2.0.0-rc2-26-g64c3d38 2.0.0
- **Python version**: Python 3.6.8
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
Declaring metrics as a list of tensorflow.python.keras.metrics.BinaryAccuracy or tensorflow.python.keras.metrics.Accuracy produces an error. Declaring the metrics as a string list works as expected.

### Source code / logs

Below is the source that can reproduce the issue.

```
import tensorflow as tf
import numpy as np

np.random.seed(1)
tf.random.set_seed(1)
BATCH_SIZE = 32

#Import mnist dataset as numpy arrays
(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()#Import
x_train = x_train / 255.0 #normalizing
y_train = y_train.astype(dtype='float32')
x_train = x_train.astype(dtype='float32')

x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]*x_train.shape[2]))#Reshaping the 2D picture

##############################################################################################
#THIS BLOCK CREATES A DATASET FROM THE NUMPY ARRAYS. IT WILL BE USED FOR THE CASE OF TF.DATA DATASET INPUTS
tfdata_dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))
tfdata_dataset_train = tfdata_dataset_train.batch(BATCH_SIZE).repeat()
##############################################################################################

#Create model
keras_model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(512, activation=tf.nn.relu),
    tf.keras.layers.Dropout(0.2, seed=1),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])

metrics = [tf.metrics.Accuracy()]
#metrics = ['accuracy']

#Compile the model
keras_model.compile(optimizer=tf.keras.optimizers.Adam(),
                    loss=tf.keras.losses.sparse_categorical_crossentropy,
                    metrics=metrics)


#Train with tf.data datasets
keras_training_history = keras_model.fit(tfdata_dataset_train,
                epochs=1,
                steps_per_epoch=60000//BATCH_SIZE
                )
########################
```

### Output using metrics=['accuracy']

```
2019-11-07 21:47:17.874727: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz
2019-11-07 21:47:17.875199: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49747e0 executing computations on platform Host. Devices:
2019-11-07 21:47:17.875253: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-07 21:47:17.876808: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.
2019-11-07 21:47:18.324898: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.
Train for 1875 steps
2019-11-07 21:47:18.992644: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.
1875/1875 [==============================] - 26s 14ms/step - loss: 0.2265 - accuracy: 0.9329
```
### Output using metrics = [tf.metrics.Accuracy()]

```
2019-11-07 21:51:01.199548: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz
2019-11-07 21:51:01.200090: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a91560 executing computations on platform Host. Devices:
2019-11-07 21:51:01.200143: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-07 21:51:01.201813: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.
2019-11-07 21:51:01.721895: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.
Train for 1875 steps
2019-11-07 21:51:02.375751: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.
   1/1875 [..............................] - ETA: 23:32Traceback (most recent call last):
  File ""bug.py"", line 41, in <module>
    steps_per_epoch=60000//BATCH_SIZE
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 73, in distributed_function
    per_replica_function, args=(model, x, y, sample_weights))
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 760, in experimental_run_v2
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1787, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 2132, in _call_for_each_replica
    return fn(*args, **kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 292, in wrapper
    return func(*args, **kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 264, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 315, in train_on_batch
    model, outs, targets, sample_weights=sample_weights, masks=masks)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 74, in _eager_metrics_fn
    skip_target_masks=model._prepare_skip_target_masks())
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2063, in _handle_metrics
    target, output, output_mask))
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2014, in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 1067, in call_metric_function
    return metric_fn(y_true, y_pred, sample_weight=weights)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py"", line 193, in __call__
    replica_local_fn, *args, **kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py"", line 1135, in call_replica_local_fn
    return fn(*args, **kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py"", line 176, in replica_local_fn
    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py"", line 75, in decorated
    update_op = update_state_fn(*args, **kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py"", line 581, in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py"", line 2750, in accuracy
    y_pred.shape.assert_is_compatible_with(y_true.shape)
  File ""/home/developer/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py"", line 1115, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
ValueError: Shapes (None, 10) and (None, 1) are incompatible
```

"
34087,[TF 2.0] Add batched gradient function to GradientTape,"**System information**
- TensorFlow version (you are using): 2.0.0



**Describe the feature and the current behavior/state.**
There should be a feature for batched gradient computation in GradientTape similar to batched_jacobian.

**Will this change the current api? How?**
`GradientTape.batched_gradient` would exist.

**Who will benefit with this feature?**
If someone wants to compute the second derivative of an output w.r.t. the input. Here is an example:
Let's assume `x=(x_1, x_2, x_3)` and we have some function (network) which gives us a scalar output for every x `f(x)=y`. Computing the second derivative of the `f(x)` w.r.t. `x_i` `(d^2f(x)/dx_i^2)` involves either a gradient computation + jacobian computation or a gradient computation + loop:
1. solution with jacobian:
```
with tf.GradientTape(True) as g:
  g.watch(x)
  with tf.GradientTape() as gg:
    gg.watch(x)
    y = f(x)
  dy_dx = gg.gradient(y, x)
d2y_dx2 = g.jacobian(y, x) # here some filtering is requires to get only the diagonal elements
```
2. solution with loop of gradients:
```
with tf.GradientTape(True) as g:
  x_i = [x[i] for i in range(len(x))]
  [g.watch(_x) for _x in x_i]
  x = tf.stack(x_i, 0)
  with tf.GradientTape() as gg:
    gg.watch(x)
    y = f(x)
  dy_dx = gg.gradient(y, x)
  dy_dx_i = [dy_dx[i] for i in range(len(dy_dx))]
d2y_dx2 = tf.stack([g.gradient(grad, _x) for grad, _x in zip(dy_dx_i, x_i)])
```

The first solution is expensive due to the jacobian computation and for the second one, one has to split up the tensor before and after and loop over gradient computation."
34086,"tf.distriubte.strategy() doesn't support multiple input, multiple input will report an error:TypeError: int() argument must be a string, a bytes-like object or a number, not 'tuple'","Hi,I find a bug.I have found that the workaround those not work if the model has multiple inputs. The following code fails:

import numpy as np
import tensorflow as tf
#strategy = tf.distribute.MirroredStrategy()
strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

def generator():
    while True:
        yield [np.ones([10, 10], np.float32), np.ones([10, 10], np.float32)], np.ones([10, 1], np.float32)
with strategy.scope():
    inputA = tf.keras.layers.Input(shape=(10,))
    inputB = tf.keras.layers.Input(shape=(10,))
    output = tf.keras.layers.Concatenate()([inputA, inputB])
    output = tf.keras.layers.Dense(1, input_shape=(10,), activation=""relu"")(output)
    model = tf.keras.models.Model(inputs=[inputA, inputB], outputs=output)
    model.compile('Adam', 'mae')
    model.fit(generator(), steps_per_epoch=1000, epochs=10)

The error is as follows：
TypeError: int() argument must be a string, a bytes-like object or a number, not 'tuple'
How can I solve this problem?"
34085,"Tensorflow fails to build due to "" no such package '@keras_applications_archive// BUILD file not found in directory ''""","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source (latest)
- TensorFlow version: 2.0.0
- Python version: 3.7.4
- Installed using virtualenv? pip? conda?: miniconda
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): 8.2.0
- CUDA/cuDNN version: 10.1/7.6
- GPU model and memory: V100

Yesterday, 11-6-19 I was able to successfully build tensorflow from source using the install script that I wrote here:
https://gist.github.com/AmericanEnglish/5c522541f1c4a648c24db344477608f4#file-install-sh

However as of today I now receive this error:
```
ERROR: /home/user/tests/tensorflowTest/fromsource/fresh/tensorflow/tensorflow/python/keras/BUILD:19:1: no such package '@keras_applications_archive//': BUILD file not found in directory '' of external repository @keras_applications_archive and referenced by '//tensorflow/python/keras:keras'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@keras_applications_archive//': BUILD file not found in directory '' of external repository @keras_applications_archive
INFO: Elapsed time: 5.218s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (80 packages loaded, 146 targets configured)
```


**Provide the exact sequence of commands / steps that you executed before running into the problem**
See the above mentioned gist. I've further consolidated a lot of commands into module loads via lmod. The loading of CUDA 10.1 and cuDNN are done via the lmod system.


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I should mention that my miniconda environment has keras_applications and keras_preprocessing installed as per the tensorflow build from source guide."
34084,[Codelab] Update digit classifier Android app to target API level 29,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Android Studio version: 3.5

**Describe the problem**
The Android app package available from https://codelabs.developers.google.com/codelabs/digit-classifier-tflite/index.html?index=..%2F..index#2 has a targetSdkVersion of ""28"". This should be updated to ""29"".

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1. Download codelab ZIP file
2. Open the Android Studio project: lite/codelabs/digit_classifier/android/start/
3. View the project's app/build.gradle file.
"
34083,Can't find tensorflow.examples.tutorial,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): None
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): v1.12.1-17556-g63c45aacf3 2.0.0
- Python version: Python 3.7.4
- Bazel version (if compiling from source):0.27.1
- GCC/Compiler version (if compiling from source):7.4.0
- CUDA/cuDNN version: V10.1.243
- GPU model and memory: GP107GL [Quadro P1000]  -- 4031MiB 

**Describe the current behavior**
```
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError:  No module named 'tensorflow.examples'
```
As the error sugests, can't find the module. Am I missing something while generating the wheel package from bazel? 

**Describe the expected behavior**
Is there in the source code repo, hence should work. No monkey-fixes please. I have tried local copying the directory, but then some other tensorflow module is missing (tensorflow.contrib and goes on).  

**Code to reproduce the issue**
`python -c 'from tensorflow.examples.tutorials import input_data'`


**Other info / logs**
`bazel build --verbose_failures  --config=monolithic //tensorflow/tools/pip_package:build_pip_package`
Command I used to create the wheel package from tensorflow source.
"
34082,--config=rocm build works with bazel `0.26.1` but has link errors with `0.29.1`,"We are trying to figure out why the `--config=rocm` TF build breaks (link errors) with bazel version `0.29.1`, but works fine with `0.26.1`.

How do we get a better understanding of what changed on the bazel side, to introduce the build errors, and how to fix them?

thanks

-------------------

/cc @whchung @parallelo @sunway513 "
34080,Can't apply map on Dataset,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Manjaro
- TensorFlow installed from (source or binary): pip repository, binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7.4
- CUDA/cuDNN version: N/A (CPU)
- GPU model and memory: N/A (CPU)

**Describe the current behavior**
Trying to apply a function to any dataset (created either from `from_tensor_slices` or `from_generator`) returns the following error : 

> TypeError: Failed to convert object of type <class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'> to Tensor. Contents: <_VariantDataset shapes: (2,), types: tf.int64>. Consider casting elements to a supported type.

**Describe the expected behavior**
The operation should return no error.

**Code to reproduce the issue**
```
import numpy as np
import tensorflow as tf

@tf.function
def expand(x):
    return tf.expand_dims(x, axis = 2)

m = np.array([[1, 1],
              [1, 1]])
ds = tf.data.Dataset.from_tensor_slices(m)
ds = ds.apply(expand)
```
**Note:** Try to apply any other function would returns the same error.

**Other info / logs**
Full stack trace : 

> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-72-07c8595ab9d1> in <module>
>       9                  [1, 1]])
>      10 ds = tf.data.Dataset.from_tensor_slices(m)
> ---> 11 ds = ds.apply(expand)
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in apply(self, transformation_func)
>    1367           dataset.
>    1368     """"""
> -> 1369     dataset = transformation_func(self)
>    1370     if not isinstance(dataset, DatasetV2):
>    1371       raise TypeError(
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
>     455 
>     456     tracing_count = self._get_tracing_count()
> --> 457     result = self._call(*args, **kwds)
>     458     if tracing_count == self._get_tracing_count():
>     459       self._call_counter.called_without_tracing()
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
>     501       # This is the first call of __call__, so we have to initialize.
>     502       initializer_map = object_identity.ObjectIdentityDictionary()
> --> 503       self._initialize(args, kwds, add_initializers_to=initializer_map)
>     504     finally:
>     505       # At this point we know that the initialization is complete (or less
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
>     406     self._concrete_stateful_fn = (
>     407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
> --> 408             *args, **kwds))
>     409 
>     410     def invalid_creator_scope(*unused_args, **unused_kwds):
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
>    1846     if self.input_signature:
>    1847       args, kwargs = None, None
> -> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)
>    1849     return graph_function
>    1850 
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
>    2148         graph_function = self._function_cache.primary.get(cache_key, None)
>    2149         if graph_function is None:
> -> 2150           graph_function = self._create_graph_function(args, kwargs)
>    2151           self._function_cache.primary[cache_key] = graph_function
>    2152         return graph_function, args, kwargs
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
>    2039             arg_names=arg_names,
>    2040             override_flat_arg_shapes=override_flat_arg_shapes,
> -> 2041             capture_by_value=self._capture_by_value),
>    2042         self._function_attributes,
>    2043         # Tell the ConcreteFunction to clean up its graph once it goes out of
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
>     913                                           converted_func)
>     914 
> --> 915       func_outputs = python_func(*func_args, **func_kwargs)
>     916 
>     917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
>     356         # __wrapped__ allows AutoGraph to swap in a converted function. We give
>     357         # the function a weak reference to itself to avoid a reference cycle.
> --> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)
>     359     weak_wrapped_fn = weakref.ref(wrapped_fn)
>     360 
> 
> /usr/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
>     903           except Exception as e:  # pylint:disable=broad-except
>     904             if hasattr(e, ""ag_error_metadata""):
> --> 905               raise e.ag_error_metadata.to_exception(e)
>     906             else:
>     907               raise
> 
> TypeError: in converted code:
> 
>     <ipython-input-72-07c8595ab9d1>:6 expand  *
>         return tf.expand_dims(x, axis = 2)
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper
>         return target(*args, **kwargs)
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:325 expand_dims_v2
>         return gen_array_ops.expand_dims(input, axis, name)
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:2465 expand_dims
>         ""ExpandDims"", input=input, dim=axis, name=name)
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:530 _apply_op_helper
>         raise err
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:527 _apply_op_helper
>         preferred_dtype=default_dtype)
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1296 internal_convert_to_tensor
>         ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py:286 _constant_tensor_conversion_function
>         return constant(v, dtype=dtype, name=name)
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py:227 constant
>         allow_broadcast=True)
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py:265 _constant_impl
>         allow_broadcast=allow_broadcast))
>     /usr/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:545 make_tensor_proto
>         ""supported type."" % (type(values), values))
> 
>     TypeError: Failed to convert object of type <class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'> to Tensor. Contents: <_VariantDataset shapes: (2,), types: tf.int64>. Consider casting elements to a supported type.
> 


"
34078,Example custom training loop failed when using tf.train.MomentumOptimizer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): None
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): On google codelab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): On google codelab
- TensorFlow version (use command below): 1.15.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: Run on cpu.
- GPU model and memory: Run on cpu.

docs/site/en/r1/tutorials/distribute/training_loops.ipynb

I run tensorflow/docs/blob/master/site/en/r1/tutorials/distribute/training_loops.ipynb using google colab and changing the optimizer to tf.train.MomentumOptimizer() and it gives me the following error:

```
InternalError: Invalid variable reference. [[node Momentum/update_0_7/update_dense_1/bias/ResourceApplyMomentum (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
```

**Describe the expected behavior**
I was expecting the custom training loop can be run using different optimizers.

**Code to reproduce the issue**
Please goto training_loops.ipynb and open google colab from there.
"
34075,Building TensorFlow 2 with bazel fails,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (Windows 10):
- TensorFlow installed from (source):
- TensorFlow version: 2.0 (master branch on 07 Nov 2019, to be exact)
- Python version: 3.7
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source):  8.1.0
- CUDA/cuDNN version: 10.0/7
- GPU model and memory: GeForce GTX 1050 15.88 GB RAM



Trying to compile TF 2.0 with Bazel, ends up in a failure.
I am struggling this isssue for quite a while, looked it up online, but havn't found any solution. Several running configuration (with or w/o Cuda, with or w/o creating zip file, etc) eventually leading to the same failure.

My actions:
1. git checkout master (in the TF git repo)
2. bazel clean
3. configure (all defaults except for python path and Cuda)
4. bazel build --config=cuda --define=no_tensorflow_py_deps=true tensorflow:tensorflow_cc.dll

Failure message:
ERROR: C:/users/shahar/git/tensorflow/tensorflow/core/BUILD:2537:1: Executing genrule //tensorflow/core:version_info_gen failed (Exit 5)
LAUNCHER ERROR: Cannot launch process: ""C:/Program Files/WindowsApps/PythonSoftwareFoundation.Python.3.7_3.7.1520.0_x64__qbz5n2kfra8p0/python.exe"" C:\users\shahar\_bazel_shahar\duchsbgv\execroot\org_tensorflow\bazel-out\x64_windows-opt\bin\tensorflow\tools\git\gen_git_source.zip --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref bazel-out/x64_windows-opt/bin/tensorflow/core/util/version_info.cc --git_tag_override=
Reason: (error: 5): Access is denied.

What am i doing wrong?"
34074,build failed from source on windows 10,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10

- TensorFlow version:
1.14
- Python version:
3.5.4
- Bazel version (if compiling from source):
0.24.1

- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
CUDA10.0 & cuDNN7
- GPU model and memory:
GeForce GTX1050Ti
CPU:
i7-7700HQ

- Command
I've tried 
```
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
```
and 
```
bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
```
none of them works.

**Describe the problem**

I just follow the instructions of [https://www.tensorflow.org/install/source_windows](url), but it doesn't work.

**Error Log**
```
ERROR: D:/libs/tensorflow/tensorflow/BUILD:745:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 127): bash.exe failed: error executing command
  cd C:/users/donke/_bazel_donkey/4aoyooqm/execroot/org_tensorflow
  SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Users\donke\.dnx\bin;C:\Program Files\Microsoft DNX\Dnvm\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;D:\dev\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\CMake\bin;C:\Program Files\MATLAB\R2016a\runtime\win64;C:\Program Files\MATLAB\R2016a\bin;C:\Program Files\MATLAB\R2016a\polyspace\bin;D:\dev\x86\vc14\bin;C:\Program Files\nodejs\;D:\mysql-8.0.16-winx64\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extras\CUPTI\libx64;C:\Program Files\Git\cmd;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\msys64\usr\bin;C:\Users\donke\AppData\Local\Programs\Python\Python35;C:\Users\donke\AppData\Local\Programs\Python\Python35\Scripts;C:\Program Files\dotnet\;C:\Users\donke\AppData\Local\Microsoft\WindowsApps;C:\Users\donke\AppData\Roaming\npm;C:\msys64\usr\bin;
    SET PYTHON_BIN_PATH=C:/Users/donke/AppData/Local/Programs/Python/Python35/python.exe
    SET PYTHON_LIB_PATH=C:/Users/donke/AppData/Local/Programs/Python/Python35/lib/site-packages
    SET TF_CONFIGURE_IOS=0
    SET TF_DOWNLOAD_CLANG=0
    SET TF_NEED_CUDA=0
    SET TF_NEED_OPENCL_SYCL=0
    SET TF_NEED_ROCM=0
  C:/msys64/usr/bin/bash.exe bazel-out/x64_windows-opt/genfiles/tensorflow/tf_python_api_gen_v1.genrule_script.sh
Execution platform: @bazel_tools//platforms:host_platform
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 18.207s, Critical Path: 1.84s
INFO: 1 process: 1 local.
FAILED: Build did NOT complete successfully
```"
34073,Problem with fit_generator when using a generator for training and a fixed set for validation.,"**System information**
- I have written custom code. Code is available here as a Google Colab notebook: https://drive.google.com/open?id=1xp5LES0HiEEPWozrD4HR5DPPa-dce1mH
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): The code was run in Google Colab, with the version of all packages defined by Google Colab at this date (07 Nov 2019). 
- TensorFlow version: 2.0.0
- Python version: 3.6.7

**Describe the current behavior**
The provided code, originally written by Xifeng Guo for Keras with Tensorflow 1.2 as backend, was updated to run in Tensorflow 2.0. The code builds a Capsule Network as defined by Hinton's paper  'Dynamic Routing Between Capsules'. It is trained/tested with MNIST dataset.

The code gives two options: either training with model.fit (it works perfectly) or with model.fit_generator, where a generator makes only shifting augmentation (the problem is here!). 
This part of the code remained as it was originally written by Mr. Guo, as I think it does not need to be updated (see below, where the part of model.fit was commented out). Note that in the original implementation of CapsNets there is an encoder (x is input, y is output) and a decoder (y is input, x is output), thus the input of the network is x=[x_train, y_train] and the output is y=[y_train, x_train]. 



    """"""
    # Training without data augmentation:
    model.fit([x_train, y_train], [y_train, x_train], 
              batch_size=args.batch_size, 
              epochs=args.epochs,
              validation_data=[[x_test, y_test], [y_test, x_test]], 
              callbacks=[log, tb, checkpoint, lr_decay])
    """"""

    # Begin: Training with data augmentation ----------------------------------#
    def train_generator(x, y, batch_size, shift_fraction=0.):
      train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,
                                          height_shift_range=shift_fraction)  
      generator = train_datagen.flow(x, y, batch_size=batch_size)
      while True:
        x_batch, y_batch = generator.next()
        yield ([x_batch, y_batch], [y_batch, x_batch])

    # Training with data augmentation. If shift_fraction=0 then no augmentation.
    model.fit_generator(generator=train_generator(x_train, y_train, 
                                                  args.batch_size, 
                                                  args.shift_fraction),
                        steps_per_epoch=5, #int(y_train.shape[0] / args.batch_size),
                        epochs=args.epochs,
                        validation_data=[[x_test, y_test], [y_test, x_test]],
                        callbacks=[log, tb, checkpoint, lr_decay])
    # End: Training with data augmentation ------------------------------------#

If fit_generator is used (with the indicated generator), there is a problem when the function ends generating training samples and starts using the validation set to test the model, giving this error:

> ValueError: could not broadcast input array from shape (100,28,28,1) into shape (100)

Remember that the MNIST dataset contains gray-scale images of 28x28 pixels, and the batch_size here is 100 images.

Interestingly, if I change the validation_data line from ...

> validation_data=[[x_test, y_test], [y_test, x_test]],

... to a generator with no augmentation...

> validation_data=train_generator(x_test, y_test, args.batch_size)

... it works perfectly.
And, again, if I do not use the fit_generator but the model.fit, it also works fine.

**Describe the expected behavior**
As described, fit_generator should be able to deal with validation_data correctly.

**Code to reproduce the issue**
The issue can be easily reproducible in the following notebook (just run all the cells!). I have reduced the steps_per_epoch=5 to go fast to the point where the code breaks.
https://drive.google.com/open?id=1xp5LES0HiEEPWozrD4HR5DPPa-dce1mH"
34072,AttributeError: 'Module' object has no attribute 'app',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.5
- TensorFlow version (use command below): Tensorflow for poets 2
- Python version: 2.7.17

**Describe the current behavior**
I tried to run the training for ""tensorflow for poets 2"" and it shows me this:
```
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/Users/fabian/tensorflow-for-poets-2/scripts/retrain.py"", line 1326, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
AttributeError: 'module' object has no attribute 'app'
```


I'm not so familiar with coding, but is there a way to resolve this problem?
Thanks"
34071,[Bug] Wrong device placement for tf.constant with int32,"Colab example: https://colab.research.google.com/drive/1iCyTZhKzco4CjxY17g37jKG9GS35-NGb
Remember to use GPU instance

When dtype is int32, tf.constant didn't place tensor on gpu but cpu.

```python
with tf.device(""/gpu:0""):
  a = tf.constant([0,1], dtype=tf.float32)
print(a.device)
# '/job:localhost/replica:0/task:0/device:GPU:0'

with tf.device(""/gpu:0""):
  b = tf.constant([0,1], dtype=tf.int32)
print(b.device)
# '/job:localhost/replica:0/task:0/device:CPU:0'
```




**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.0.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:
"
34070,Keras named inputs lost with SavedModel format,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Google Colab, TF 2.0**

**Describe the current behavior**
If I define a Keras model with named inputs (`Input(name=""x_embedding"")`), I can use a Dict as input with the original model or after saving to h5, but not with the new SavedModel format: The name of my input layer is changed from `x_embedding` to `input_1`.

**Describe the expected behavior**
The model loaded from SavedModel should keep the named inputs.

**Code to reproduce the issue**
https://colab.research.google.com/drive/19ICXHeL4tzAN9z1LCi-3Su8l5X2_NhxM

```python
try:
  %tensorflow_version 2.x
except Exception:
  pass
  
import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model

input_seq = Input(shape=(1,), name=""x_embedding"")
model = Model(inputs=input_seq, outputs=input_seq)
model.compile(optimizer=""adam"", loss=""sparse_categorical_crossentropy"")

x = {""x_embedding"": np.array([0.1] * 100)}
y = np.array([0] * 100)

model.fit(x,y)

# Works with original model
res = model.evaluate(x,y)
print(""model.evaluate ="", res)

# Works with h5 model
model.save(""my_h5Model.h5"", save_format=""h5"")
model2 = load_model(""my_h5Model.h5"")
res = model2.evaluate(x,y)
print(""model2.evaluate ="", res)

# Doesn't work with SavedModel format
model.save(""my_SavedModel"", save_format=""tf"")
model3 = load_model(""my_SavedModel"")
res = model3.evaluate(x,y)
print(""model3.evaluate ="", res)

# Work with SavedModel format if I rename x_embedding -> input_1
x2 = {""input_1"": np.array([0.1] * 100)}
res = model3.evaluate(x2,y)
print(""model3.evaluate ="", res)
```
**Other info / logs**
`ValueError: No data provided for ""input_1"". Need data for each key in: ['input_1']`"
34069,InternalError:  Blas GEMM launch failed,"**System information**
- Uusing a stock example script provided in TensorFlow (first guide with mnist dataset), so code is 100% right. And this problem haunts me in every model :(
- OS Platform: Windows 10
- TensorFlow installed from (source or binary): pip3 install tensorflow-gpu . And i have a quustion here: shouild i install keras? I think its already in tf 2.0
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.5
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: GTX 1060 3GB


**Describe the problem**
I train the model described in the guides on the official tf website, so there can be no problems with the code. When I start learning the model, I have a bug from below. This happens not only on this code, but also on others. I have the latest versions of cuda and cudnn, visual studio 2017.

**Interesting**
On one of the sites I saw a solution to the problem as follows: conda update --all. Indeed, after this command and reboot I can train the model, but only ONCE, the next model will be with the same error.

**Code to reproduce the issue**
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=10)

**Error Log**
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
<ipython-input-10-41cd0b44e416> in <module>
      2 
      3 model.fit(partial_train_data, partial_train_targets,
----> 4         epochs=num_epochs, batch_size=1, verbose=0)

~\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

~\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--> 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

~\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--> 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

~\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---> 86                               distributed_function(input_fn))
     87 
     88   return execution_function

~\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

~\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    518         # Lifting succeeded, so variables are initialized and we can run the
    519         # stateless function.
--> 520         return self._stateless_fn(*args, **kwds)
    521     else:
    522       canon_args, canon_kwds = \

~\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   1821     """"""Calls a graph function specialized to the inputs.""""""
   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 
   1825   @property

~\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1139          if isinstance(t, (ops.Tensor,
   1140                            resource_variable_ops.BaseResourceVariable))),
-> 1141         self.captured_inputs)
   1142 
   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1222     if executing_eagerly:
   1223       flat_outputs = forward_function.call(
-> 1224           ctx, args, cancellation_manager=cancellation_manager)
   1225     else:
   1226       gradient_name = self._delayed_rewrite_functions.register()

~\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    509               inputs=args,
    510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 511               ctx=ctx)
    512         else:
    513           outputs = execute.execute_with_cancellation(

~\Anaconda3\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~\Anaconda3\lib\site-packages\six.py in raise_from(value, from_value)

InternalError:  Blas GEMM launch failed : a.shape=(1, 13), b.shape=(13, 64), m=1, n=64, k=13
	 [[node sequential/dense/MatMul (defined at C:\Users\Gera\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:1751) ]] [Op:__inference_distributed_function_785]

Function call stack:
distributed_function"
34068,TF2 keras.models.load_model fails with custom metrics (both h5 and tf format),"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- TensorFlow installed from (source or binary): pip install tensorflow==2.0.0-beta1
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

**Describe the current behavior**

I have a custom metric in my model and using `tf.keras.models.load_model` with `compile=True` after saving it results in an error in almost all cases, whereas I use the `custom_objects` argument according to [the documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/models/load_model).

I tried to pass my custom metric with two strategies: by passing a custom function `custom_accuracy` to the `tf.keras.Model.compile` method, or by subclassing the `MeanMetricWrapper` class and giving an instance of my subclass named `CustomAccuracy` to `tf.keras.Model.compile`.

I also tried the two different saving format available: h5 and tf. Here are my results:

- with tf format:
    - with custom function: 
    fail with `ValueError` message `Unknown metric function:custom_accuracy`
    - with subclassed metric:
    fail with `ValueError` message `Unknown metric function: CustomAccuracy`
- with h5 format:
    - with custom function: 
    success
    - with subclassed metric:
    fail with `TypeError` message `must be str, not ABCMeta`

Note that given the complete error logs (see below), the error with h5 format and subclassed metric is in fact the same as the error with the tf format. The `TypeError` occurs when the code tries to raise the `ValueError`.

**Describe the expected behavior**

This should not fail in any case, except if I am using the `custom_objects` argument wrong. The documentation could be a little expanded on that matter by the way.

**Code to reproduce the issue**
```
import tensorflow as tf

print('Using Tensorflow version {} (git version {})'.format(tf.version.VERSION, tf.version.GIT_VERSION))

from tensorflow.python.keras.metrics import MeanMetricWrapper
from tensorflow.python.keras.metrics import accuracy

def custom_accuracy(y_true, y_pred):
    return accuracy(y_true, y_pred)

class CustomAccuracy(MeanMetricWrapper):

    def __init__(self, **kwargs):
        super(CustomAccuracy, self).__init__(custom_accuracy, **kwargs)
        
def make_model():
    inp = tf.keras.Input(shape=(2,))
    x = tf.keras.layers.Dense(4)(inp)
    return tf.keras.Model(inp, x)


for save_format in ['tf', 'h5']:
    
    print(""\nTrying with save_format='{}':\n"".format(save_format))
    
    model_with_function = make_model()
    model_with_function.compile(loss='mse', metrics=[custom_accuracy])
    model_with_function.save('/tmp/model_with_function' + '.' + save_format, 
                             save_format=save_format)
    
    try:
        new_model = tf.keras.models.load_model('/tmp/model_with_function' + '.' + save_format, 
                                               custom_objects={'custom_accuracy': custom_accuracy}, 
                                               compile=True)
        print(""model_with_function loaded with the following metrics:"")
        print(new_model.metrics)
    except Exception as e:
        print(""model_with_function not loaded with the following error:"")
        print(type(e))
        print(e)
        
    model_with_subclass = make_model()
    model_with_subclass.compile(loss='mse', metrics=[CustomAccuracy()])
    model_with_subclass.save('/tmp/model_with_subclass' + '.' + save_format, 
                             save_format=save_format)
    
    try:
        new_model = tf.keras.models.load_model('/tmp/model_with_subclass' + '.' + save_format, 
                                               custom_objects={'CustomAccuracy': CustomAccuracy}, 
                                               compile=True)
        print(""model_with_subclass loaded with the following metrics:"")
        print(new_model.metrics)
    except Exception as e:
        print(""model_with_subclass not loaded with the following error:"")
        print(type(e))
        print(e)
```

**Other info / logs**
The logs are the same in the 3 error cases (to get them with the code above, just add `raise`at the end of the `except` blocks):
```
<ipython-input-14-ac0a72b492dc> in <module>
     48         new_model = tf.keras.models.load_model('/tmp/model_with_subclass' + '.' + save_format, 
     49                                                custom_objects={'CustomAccuracy': CustomAccuracy},
---> 50                                                compile=True)
     51         print(""model_with_function loaded with the following metrics:"")
     52         print(new_model.metrics)

/path/to/tensorflow_core/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    148   if isinstance(filepath, six.string_types):
    149     loader_impl.parse_saved_model(filepath)
--> 150     return saved_model_load.load(filepath, compile)
    151 
    152   raise IOError(

/path/to/tensorflow_core/python/keras/saving/saved_model/load.py in load(path, compile)
     91     if model._training_config is not None:  # pylint: disable=protected-access
     92       model.compile(**saving_utils.compile_args_from_training_config(
---> 93           model._training_config))  # pylint: disable=protected-access
     94 
     95   return model

/path/to/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/path/to/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    354     with K.get_graph().as_default():
    355       # Save all metric attributes per output of the model.
--> 356       self._cache_output_metric_attributes(metrics, weighted_metrics)
    357 
    358       # Set metric attributes on model.

/path/to/tensorflow_core/python/keras/engine/training.py in _cache_output_metric_attributes(self, metrics, weighted_metrics)
   1899         output_shapes.append(output.shape.as_list())
   1900     self._per_output_metrics = training_utils.collect_per_output_metric_info(
-> 1901         metrics, self.output_names, output_shapes, self.loss_functions)
   1902     self._per_output_weighted_metrics = (
   1903         training_utils.collect_per_output_metric_info(

/path/to/tensorflow_core/python/keras/engine/training_utils.py in collect_per_output_metric_info(metrics, output_names, output_shapes, loss_fns, is_weighted)
    811     metrics_dict = OrderedDict()
    812     for metric in metrics:
--> 813       metric_name = get_metric_name(metric, is_weighted)
    814       metric_fn = get_metric_function(
    815           metric, output_shape=output_shapes[i], loss_fn=loss_fns[i])

/path/to/tensorflow_core/python/keras/engine/training_utils.py in get_metric_name(metric, weighted)
    985       return metric
    986 
--> 987     metric = metrics_module.get(metric)
    988     return metric.name if hasattr(metric, 'name') else metric.__name__
    989   else:

/path/to/tensorflow_core/python/keras/metrics.py in get(identifier)
   2855 def get(identifier):
   2856   if isinstance(identifier, dict):
-> 2857     return deserialize(identifier)
   2858   elif isinstance(identifier, six.string_types):
   2859     return deserialize(str(identifier))

/path/to/tensorflow_core/python/keras/metrics.py in deserialize(config, custom_objects)
   2849       module_objects=globals(),
   2850       custom_objects=custom_objects,
-> 2851       printable_module_name='metric function')
   2852 
   2853 

/path/to/tensorflow_core/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    178     config = identifier
    179     (cls, cls_config) = class_and_config_for_serialized_keras_object(
--> 180         config, module_objects, custom_objects, printable_module_name)
    181 
    182     if hasattr(cls, 'from_config'):

/path/to/tensorflow_core/python/keras/utils/generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)
    163     cls = module_objects.get(class_name)
    164     if cls is None:
--> 165       raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
    166   return (cls, config['config'])
    167 
```

"
34067,TF.distribute.MirroredStrategy() crashes ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Progress Linux 5+ (engywuck-backports) (Linux Debian Buster)
- TensorFlow installed from (source or binary): binary (problem happens from source aswell)
- TensorFlow version (use command below): v1.12.1-16854-g6778662 2.1.0-dev20191028
- Python version: Python 3.7.3
- CUDA/cuDNN version: 10.0/7.0
- GPU model and memory: 2x Asus GeForxe RTX 2080 Ti, Compute Capability 7.5, No NVLink

**Describe the current behavior**
Since we are not allowed to share our data, I tried to reproduce our problem with a dataset from tensorflow_datasets.
The current code might not make much sense, but I am able to deliver a reproducible code with it. 
Training on only one-gpu  works without a problem, with tf.distribute.MirroredStrategy() it crashes (see dump).

What we already tried:
- build tensorflow from source
- build tensorflow from source against cuda10.1
- using tensorflow via pip: tensorflow-gpu

**Describe the expected behavior**
Tf.distribute.MirroredStrategy() should lead to similar Results like training on one-gpu only.

**Code to reproduce the issue**
I tried to reproduce the problem using google-colab. but since only one gpu is provided, it is not really reproducible.
I tried it with two virtual GPUs, but it didn't lead to similar behavior like our problem.
https://colab.research.google.com/drive/1hmqt9KdWoheKajkHl_J6dJgoHneKoJP3

On my set-up i use following code:
``` python
# -*- coding: utf-8 -*-

import numpy as np
from tensorflow.keras.applications.resnet50 import ResNet50
import tensorflow as tf
import tensorflow_datasets as tfds

LENGTH_DATASET = 17509
NUM_CLASSES = 9
IMG_SHAPE = (256, 256, 3)
BATCH_SIZE = 32


def mymap_func(features):
    return features[""image""], features[""label""]


AUTOTUNE = tf.data.experimental.AUTOTUNE

# create input pipeline
dataset = tfds.load(name=""deep_weeds"", split=""train"")
dataset = dataset.map(mymap_func,
                      num_parallel_calls=tf.data.experimental.AUTOTUNE)
dataset = dataset.cache()
dataset = dataset.shuffle(buffer_size=LENGTH_DATASET, seed=42,
                          reshuffle_each_iteration=True)
dataset = dataset.batch(batch_size=BATCH_SIZE, drop_remainder=True).repeat()
dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)


# create model
img_width, img_height = 270, 270

shape, classes = (img_width, img_height, 1), 3

strategy = tf.distribute.MirroredStrategy()
print(""Number of devices in strategy: {}"".format(strategy.num_replicas_in_sync))

with strategy.scope():

  model = ResNet50(include_top=True,
                       weights=None,
                       input_tensor=None,
                       input_shape=IMG_SHAPE,
                       pooling=None,
                       classes=NUM_CLASSES)

  model.compile(optimizer=tf.optimizers.Adam(),
                    loss='sparse_categorical_crossentropy',
                    metrics=[""accuracy""])

train_steps = np.ceil(LENGTH_DATASET / BATCH_SIZE)
history = model.fit(
        x=dataset,
        epochs=10,
        verbose=1,
        steps_per_epoch=train_steps,
        use_multiprocessing=False,
        workers=8)
```

**Other info / logs**

python dump of above script
``` bash
python src/test/multi_gpu_training_colab.py 
2019-11-07 10:44:52.905250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-07 10:44:52.950697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:86:00.0
2019-11-07 10:44:52.951317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Found device 1 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:af:00.0
2019-11-07 10:44:52.951554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-07 10:44:52.952809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-07 10:44:52.953947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-07 10:44:52.954263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-07 10:44:52.955764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-07 10:44:52.956986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-07 10:44:52.960430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-07 10:44:52.962770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1674] Adding visible gpu devices: 0, 1
2019-11-07 10:44:52.963103: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 10:44:53.001056: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
2019-11-07 10:44:53.008873: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5460110 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-07 10:44:53.008905: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-07 10:44:53.233141: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5521500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2019-11-07 10:44:53.233177: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-11-07 10:44:53.233185: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-11-07 10:44:53.234101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:86:00.0
2019-11-07 10:44:53.234646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Found device 1 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:af:00.0
2019-11-07 10:44:53.234685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-07 10:44:53.234699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-07 10:44:53.234711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-07 10:44:53.234723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-07 10:44:53.234736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-07 10:44:53.234748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-07 10:44:53.234760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-07 10:44:53.237620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1674] Adding visible gpu devices: 0, 1
2019-11-07 10:44:53.237669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-07 10:44:53.239881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1087] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-07 10:44:53.239900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1093]      0 1 
2019-11-07 10:44:53.239912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1106] 0:   N N 
2019-11-07 10:44:53.239922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1106] 1:   N N 
2019-11-07 10:44:53.242394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1232] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10312 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:86:00.0, compute capability: 7.5)
2019-11-07 10:44:53.243757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1232] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10312 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:af:00.0, compute capability: 7.5)
Number of devices in strategy: 2
Train for 548.0 steps
Epoch 1/10
2019-11-07 10:45:11.764680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-07 10:45:13.747993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-07 10:45:15.307911: E tensorflow/stream_executor/cuda/cuda_driver.cc:948] failed to synchronize the stop event: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered
2019-11-07 10:45:15.307949: E tensorflow/stream_executor/gpu/gpu_timer.cc:55] Internal: Error destroying CUDA event: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered
2019-11-07 10:45:15.307957: E tensorflow/stream_executor/gpu/gpu_timer.cc:60] Internal: Error destroying CUDA event: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered
2019-11-07 10:45:15.307992: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered
2019-11-07 10:45:15.308001: E tensorflow/stream_executor/stream.cc:5452] Internal: Failed to enqueue async memset operation: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered
2019-11-07 10:45:15.308017: W tensorflow/core/kernels/gpu_utils.cc:68] Failed to check cudnn convolutions for out-of-bounds reads and writes with an error message: 'Failed to load in-memory CUBIN: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered'; skipping this check. This only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2019-11-07 10:45:15.308032: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered
2019-11-07 10:45:15.308044: I tensorflow/stream_executor/stream.cc:4963] [stream=0x62f2a40,impl=0x62f1230] did not memzero GPU location; source: 0x7fcf977fbfd0
2019-11-07 10:45:15.308500: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: cuDNN launch failure : input shape([16,3,262,262]) filter shape([7,7,3,64])
         [[{{node replica_1/resnet50/conv1_conv/Conv2D}}]]
         [[loss/mul/_10]]
2019-11-07 10:45:15.308571: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: cuDNN launch failure : input shape([16,3,262,262]) filter shape([7,7,3,64])
         [[{{node replica_1/resnet50/conv1_conv/Conv2D}}]]
         [[metrics/accuracy/div_no_nan/AddN_1/_32]]
2019-11-07 10:45:15.308780: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: cuDNN launch failure : input shape([16,3,262,262]) filter shape([7,7,3,64])
         [[{{node replica_1/resnet50/conv1_conv/Conv2D}}]]
2019-11-07 10:45:15.332853: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-11-07 10:45:15.333219: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
  1/548 [..............................] - ETA: 2:39:09Traceback (most recent call last):
  File ""src/test/multi_gpu_training_colab.py"", line 81, in <module>
    workers=8)
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 778, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 338, in fit
    total_epochs=epochs)
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 632, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2339, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1589, in _filtered_call
    self.captured_inputs)
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1670, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 521, in call
    ctx=ctx)
  File ""/home/sam2/workspace/python_venvs/tf-2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.
  (0) Internal:  cuDNN launch failure : input shape([16,3,262,262]) filter shape([7,7,3,64])
         [[node replica_1/resnet50/conv1_conv/Conv2D (defined at usr/lib/python3.7/threading.py:917) ]]
         [[loss/mul/_10]]
  (1) Internal:  cuDNN launch failure : input shape([16,3,262,262]) filter shape([7,7,3,64])
         [[node replica_1/resnet50/conv1_conv/Conv2D (defined at usr/lib/python3.7/threading.py:917) ]]
0 successful operations.
1 derived errors ignored. [Op:__inference_distributed_function_36243]

Function call stack:
distributed_function -> distributed_function

2019-11-07 10:45:15.777040: I tensorflow/stream_executor/stream.cc:1990] [stream=0x5ab9030,impl=0x62f1330] did not wait for [stream=0x62f2a40,impl=0x62f1230]
2019-11-07 10:45:15.777095: I tensorflow/stream_executor/stream.cc:4938] [stream=0x5ab9030,impl=0x62f1330] did not memcpy host-to-device; source: 0x7fcf8007e000
2019-11-07 10:45:15.777129: E tensorflow/stream_executor/stream.cc:332] Error recording event in stream: Error recording CUDA event: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.
2019-11-07 10:45:15.777161: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered
2019-11-07 10:45:15.777181: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
```
The device interconnect matrix seems a bit odd, but we don't know if thats an issue for a distributed strategy:
```
2019-11-07 10:44:53.239881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1087] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-07 10:44:53.239900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1093]      0 1 
2019-11-07 10:44:53.239912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1106] 0:   N N 
2019-11-07 10:44:53.239922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1106] 1:   N N 
```
It seems the low level drivers work fine, see the dumps of nvidia-smi, nvidia-smi topo, cuda deviceQuery and NCCL All reduce test.
[nvidia_smi_topo.txt](https://github.com/tensorflow/tensorflow/files/3818892/nvidia_smi_topo.txt)
[nvidia_smi.txt](https://github.com/tensorflow/tensorflow/files/3818894/nvidia_smi.txt)
[nccl_allreduce.txt](https://github.com/tensorflow/tensorflow/files/3818895/nccl_allreduce.txt)
[cuda_device_query.txt](https://github.com/tensorflow/tensorflow/files/3818897/cuda_device_query.txt)


"
34066,TF2.0 distributed training fails after adding an embedding layer,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): somewhat
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Try to train with `MultiWorkerMirroredStrategy` a simple model with and without an Embedding layer. In the former case the distribute training fails (see below). The following code is executed on two workers with `TF_CONFIG={""cluster"": {""worker"": [""localhost:65535"",""localhost:65532""]}, ""task"": {""index"": 0, ""type"": ""worker""}}` and `TF_CONFIG={""cluster"": {""worker"": [""localhost:65535"",""localhost:65532""]}, ""task"": {""index"": 1, ""type"": ""worker""}}`, respectively.

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import losses
import numpy as np

batch_size = 32

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

NUM_WORKERS = strategy.num_replicas_in_sync
GLOBAL_BATCH_SIZE = batch_size * NUM_WORKERS
N_CAT = 47

def some_func(*args: tf.Tensor):
    tensor_dict_x, tensor_dict_y = {}, {}

    for index in range(1):
        tensor_dict_x[
            f""input_{index+1}""
        ] = tf.expand_dims(args[index], axis=-1)
        tensor_dict_y[
            f""dense""
        ] = tf.expand_dims(args[index], axis=-1)

    return tensor_dict_x, tensor_dict_y

def read_data():
    train_data = np.random.randint(1,N_CAT, size=9000)
    val_data = np.random.randint(1,N_CAT, size=999)

    dataset_train = (tf.data.Dataset.from_tensor_slices(train_data)
                     .prefetch(-1)
                     .map(map_func=some_func)
                     .batch(batch_size=GLOBAL_BATCH_SIZE)
                     .shuffle(1000)
                     .repeat())
    dataset_val = (tf.data.Dataset.from_tensor_slices(val_data)
                   .prefetch(-1)
                   .map(map_func=some_func)
                   .batch(batch_size=GLOBAL_BATCH_SIZE)
                   .shuffle(1000)
                   .repeat())

    return dataset_train, dataset_val

with strategy.scope():
    optimizer = Adam(lr=0.1)
    loss = losses.sparse_categorical_crossentropy
    model = build_and_compile_model(optimizer, loss)

dataset_train, dataset_val = read_data()
model.fit(x=dataset_train,
          epochs=5,
          steps_per_epoch=9000//batch_size,
          validation_data=dataset_val,
          validation_steps=999//batch_size,
)
```

where `build_and_compile_model`:
```
def build_and_compile_model(optimizer, loss):
    my_input = tf.keras.layers.Input(shape=(1,))
    my_dense = tf.keras.layers.Dense(N_CAT)(my_input)

    model = tf.keras.Model(my_input, my_dense)

    model.compile(optimizer=optimizer,loss=loss)

    return model
```
The above case works fine with the output:
```
2019-11-07 09:23:57.387629: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-07 09:23:57.410325: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz
2019-11-07 09:23:57.411228: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562e2c78c6a0 executing computations on platform Host. Devices:
2019-11-07 09:23:57.411241: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-07 09:23:57.413306: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65535, 1 -> localhost:65532}
2019-11-07 09:23:57.414734: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:65535
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.
2019-11-07 09:24:09.204390: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:400] Cannot find shardable dataset, adding a shard node at the end of the dataset instead. This may have performance implications.
Train for 281 steps, validate for 31 steps
Epoch 1/5
2019-11-07 09:24:09.208710: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:400] Cannot find shardable dataset, adding a shard node at the end of the dataset instead. This may have performance implications.
281/281 [==============================] - 4s 13ms/step - loss: 15.9838 - val_loss: 16.1050
Epoch 2/5
281/281 [==============================] - 1s 3ms/step - loss: 16.0496 - val_loss: 16.1015
Epoch 3/5
281/281 [==============================] - 1s 3ms/step - loss: 16.0210 - val_loss: 16.1007
Epoch 4/5
281/281 [==============================] - 1s 3ms/step - loss: 16.0517 - val_loss: 16.0995
Epoch 5/5
281/281 [==============================] - 1s 3ms/step - loss: 16.0147 - val_loss: 16.0992
2019-11-07 09:24:16.090800: W tensorflow/core/common_runtime/eager/context.cc:290] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.

Process finished with exit code 0
```

However, adding just one `Embedding` layer so that `build_and_compile_model` now is:
```
def build_and_compile_model(optimizer, loss):

    my_input = tf.keras.layers.Input(shape=(1,))
    emb_layer = tf.keras.layers.Embedding(N_CAT,5)
    emb_inp = emb_layer(my_input)
    my_dense = tf.keras.layers.Dense(N_CAT)(emb_inp)

    model = tf.keras.Model(my_input, my_dense)

    model.compile(optimizer=optimizer,loss=loss)

    return model
```

leads to the error:
```
2019-11-07 09:26:45.812362: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-07 09:26:45.834388: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz
2019-11-07 09:26:45.835018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ea66430da0 executing computations on platform Host. Devices:
2019-11-07 09:26:45.835032: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-07 09:26:45.836899: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job worker -> {0 -> localhost:65535, 1 -> localhost:65532}
2019-11-07 09:26:45.838638: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:65535
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.
2019-11-07 09:26:50.351284: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:400] Cannot find shardable dataset, adding a shard node at the end of the dataset instead. This may have performance implications.
Train for 281 steps, validate for 31 steps
Epoch 1/5
2019-11-07 09:26:50.355581: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:400] Cannot find shardable dataset, adding a shard node at the end of the dataset instead. This may have performance implications.
  1/281 [..............................] - ETA: 9:05 - loss: 9.83752019-11-07 09:26:52.321935: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingGather with Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.321956: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.321966: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.321971: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.321976: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingGather with Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.321996: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.322010: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.322017: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.322045: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Cancelled: [_Derived_]Cancelled
Additional GRPC error information:
{""created"":""@1573115212.321980682"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}
2019-11-07 09:26:52.322051: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]Cancelled
Additional GRPC error information:
{""created"":""@1573115212.321980682"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}
2019-11-07 09:26:52.322053: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:125 : Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.322054: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:234 : Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.322101: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
	 [[Adam/allreduce_1/CollectiveGather]]
2019-11-07 09:26:52.322097: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:125 : Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
2019-11-07 09:26:52.322123: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:234 : Cancelled: [_Derived_]Cancelled
Additional GRPC error information:
{""created"":""@1573115212.321980682"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}
2019-11-07 09:26:52.322108: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:234 : Internal: [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[{{node Adam/allreduce_1/CollectiveGather_1}}]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[{{node Adam/allreduce_1/CollectiveGather_1}}]]"",""grpc_status"":13}
Traceback (most recent call last):
  File "".../.PyCharmCE2019.2/config/scratches/scratch_4.py"", line 71, in <module>
    validation_steps=999//batch_size,
  File "".../lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File .../lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 789, in fit
    *args, **kwargs)
  File "".../lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 776, in wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File "".../lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File "".../mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File "".../mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 771, in _worker_fn
    return method(model, **kwargs)
  File "".../mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File "".../mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File "".../mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File "".../mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File "".../mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 487, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "".../mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/.../mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File "".../lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File "".../lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File "".../lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError:  [_Derived_]Inconsistent output shapes, got [16], but expected is [64].
	 [[node Adam/allreduce_1/CollectiveGather_1 (defined at /miniconda3/envs/mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]
Additional GRPC error information:
{""created"":""@1573115212.321897522"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""[_Derived_]Inconsistent output shapes, got [16], but expected is [64].\n\t [[node Adam/allreduce_1/CollectiveGather_1 (defined at /miniconda3/envs/mostly-engine-tf20-p374/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]"",""grpc_status"":13}
	 [[Adam/allreduce_1/CollectiveGather]] [Op:__inference_distributed_function_888]

Function call stack:
distributed_function

2019-11-07 09:26:52.540347: W tensorflow/core/common_runtime/eager/context.cc:290] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.

Process finished with exit code 1
```"
34064,Work group size selection in OpenGL,"


**System information**
- TensorFlow version (you are using): v2.0.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Hi, I am running tensorflow lite v2.0.0 on my Mali-G72 and Adreno 630 GPUs. I have read some of the tf lite source codes in order to see how you make use of OpenGL. 

In /tensorflow/tensorflow/lite/delegates/gpu/gl/workgroups/calculator_from_metadata.cc, I noticed you are trying to choose a proper work group size. However, it seems it did not really use calculator_from_metadata but to use default_calculator_ when running on my GPUs. Intuitively, I believe that the choice of work group size influences the performance and a choice from calculator_from_metadata should be better. But calculator_from_metadata is not working because there is not any data saved in the vector workgroups_. 
Have you finished this part, yet? I would appreciate it if you can share any information about this.


"
34062,BatchNorm generates NaN moving_variance on GPU with fused set to True for some inputs,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: the one on Colab


**Describe the current behavior**

I have an input of shape (1, 1, 1, num_channels), and I run it through a tf.keras.layers.BatchNormalization in training mode.

When running on CPU (fused or not) or GPU (not fused), the batch norm has the expected moving_variance of [0.99, 0.99 ...]

When running on GPU with fused=True, the moving_variance is [nan, nan, ...]

**Describe the expected behavior**

The moving variance should not be nan

**Code to reproduce the issue**
Check this [gist](https://colab.research.google.com/gist/jnd77/38ae530b17ee84e7b3907e3010c8529a/untitled0.ipynb)

**Other info / logs**
It works fine on CPU.
"
34060,undefined reference to `absl::M,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34059,Using Cuda 10 and getting ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,"I am running an instance of tensorflow and am having the issue of ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory

Is this because I am using CUDA version 10.1. Not quite sure how to proceed

**Code: sudo python2 train.py --hypes hypes/overfeat_rezoom.json --logdir output/ --gpu 0**

Traceback (most recent call last):
  File ""train.py"", line 4, in <module>
    import tensorflow.contrib.slim as slim
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
**ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory**

Failed to load the native TensorFlow runtime.

**System information**
- OS Platform and Distribution:  Linux Ubuntu 18.04:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.4.1
- Python version: 2.7.15+
- Installed using: pip
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla V100
"
34058,CheckNumerics takes long time,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34057,"TFLite Micro, bugfix for MicroAllocator::AllocateTensors()","Latest master:
tensorflow/lite/experimental/micro/micro_allocator.cc

`MicroAllocator::AllocateTensors()`

```
    for (size_t n = 0; n < op->outputs()->size(); ++n) {
      const int tensor_index = op->outputs()->Get(n);
      TensorInfo* current = &tensor_info[tensor_index];
      if ((current->first_created == -1) || (current->first_created > i)) {
        current->first_created = i;
      }
```

The operations list is iterated in reverse so need to change:
```(current->first_created > i)```
 to 
```(current->first_created < i)```



"
34056,"TFLite Micro allocator, need to set quantized_dimension","In the latest master, 

tensorflow/lite/experimental/micro/micro_allocator.cc

In `InitializeRuntimeTensor()` near line 365, need to add:

```
quantization->quantized_dimension = src_quantization->quantized_dimension();
```
"
34055,model.reset_states() does not work for bidirectional-RNNs in tf.keras.,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **YES**.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **macOS 10.14.6**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.0.0**
- Python version: **3.7.4**
- GPU model and memory: **none (MacBook Pro, Core i5, Iris Graphics 6100, 1.5 GB)**

**Describe the current behavior**
State handling in RNNs with a Bidirectional wrapper has changed in tf.keras from keras with TF 1.x.  In the old keras with TF 1.x, using `stateful=True` in a bidi-RNN had no effect -- i.e., all bidi-RNN models behaved as if  `stateful=False`.  Therefore `model.reset_states()` did not do anything.

In the new tf.keras, `stateful=True` in a bidi-RNN does have an effect -- the fwd-RNN is stateful and the bwd-RNN is stateful.  This is a good change IMO -- even though stateful bidi-RNNs are unusual, this is the best way to implement.  However, in tf.keras, the `model.reset_states()` does not do anything for bidi-RNN models (SimpleRNN, GRU, LSTM).  

**Describe the expected behavior**

For the minimal example script provided below, here is the output:

```
FWD::
non_stateful: [ 1.   -0.5   0.25]
stateful: [ 1.   -0.5   0.25]
delta: [0. 0. 0.]
BWD::
non_stateful: [1. 0. 0.]
stateful: [1. 0. 0.]
delta: [0. 0. 0.]
FWD::
non_stateful: [ 1.   -0.5   0.25]
stateful: [ 0.875   -0.4375   0.21875]
delta: [-0.125    0.0625  -0.03125]
BWD::
non_stateful: [1. 0. 0.]
stateful: [ 0.875  0.25  -0.5  ]
delta: [-0.125  0.25  -0.5  ]

** RESETING STATES in STATEFUL MODEL **

FWD::
non_stateful: [ 1.   -0.5   0.25]
stateful: [ 0.890625   -0.4453125   0.22265625]
delta: [-0.109375    0.0546875  -0.02734375]
BWD::
non_stateful: [1. 0. 0.]
stateful: [ 0.890625  0.21875  -0.4375  ]
delta: [-0.109375  0.21875  -0.4375  ]
```

The results after the **STATE RESET**  should be the same as the first set of results -- i.e., the last (third) set of results should produce the same result for the stateful and non-stateful models (same as the first set of results).  

**Code to reproduce the issue**

```python
import numpy as np
TF2 = True
if TF2:
	### currently, there is a bug in tf.keras: model.reset_states() does not work
	from tensorflow.keras.layers import Input, Dense, SimpleRNN, GRU, LSTM, Bidirectional
	from tensorflow.keras.models import Model
else:
	### in the old keras, bidi-RNNs with stateful=True behave smae as stateful=False
	from keras.layers import Input, Dense, SimpleRNN, GRU, LSTM, Bidirectional
	from keras.models import Model

sequence_length = 3
feature_dim = 1
features_in = Input(batch_shape=(1, sequence_length, feature_dim)) 

rnn_out = Bidirectional( SimpleRNN(1, activation=None, use_bias=False, return_sequences=True, return_state=False, stateful=False))(features_in)
stateless_model = Model(inputs=[features_in], outputs=[rnn_out])

stateful_rnn_out = Bidirectional( SimpleRNN(1, activation=None, use_bias=False, return_sequences=True, return_state=False, stateful=True))(features_in)
stateful_model = Model(inputs=features_in, outputs=stateful_rnn_out)

toy_weights = [ np.asarray([[1.0]], dtype=np.float32), np.asarray([[-0.5]], dtype=np.float32), np.asarray([[1.0]], dtype=np.float32), np.asarray([[-0.5]], dtype=np.float32)]

stateless_model.set_weights(toy_weights)
stateful_model.set_weights(toy_weights)

x_in = np.zeros(sequence_length)
x_in[0] = 1
x_in = x_in.reshape( (1, sequence_length, feature_dim) )

def print_bidi_out(non_stateful_out, stateful_out):
	fb = ['FWD::', 'BWD::']

	for i in range(2):
		print(fb[i])
		print(f'non_stateful: {non_stateful_out.T[i]}')
		print(f'stateful: {stateful_out.T[i]}')
		print(f'delta: {stateful_out.T[i]-non_stateful_out.T[i]}')


non_stateful_out = stateless_model.predict(x_in).reshape((sequence_length,2))
stateful_out = stateful_model.predict(x_in).reshape((sequence_length,2))
print_bidi_out(non_stateful_out, stateful_out)

non_stateful_out = stateless_model.predict(x_in).reshape((sequence_length,2))
stateful_out = stateful_model.predict(x_in).reshape((sequence_length,2))
print_bidi_out(non_stateful_out, stateful_out)

print('\n** RESETING STATES in STATEFUL MODEL **\n')
stateful_model.reset_states()
non_stateful_out = stateless_model.predict(x_in).reshape((sequence_length,2))
stateful_out = stateful_model.predict(x_in).reshape((sequence_length,2))
print_bidi_out(non_stateful_out, stateful_out)
```
"
34053,How to use hub.KerasLayer without the Sequential API,"I don't know if its a bug.
I'm following this tutorial https://www.tensorflow.org/tutorials/keras/text_classification_with_hub which is working fine.
I'm trying to replace the sequential model: 
```
model = tf.keras.Sequential()
model.add(hub_layer)
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
```
by:

```
class model(tf.keras.Model):
    def __init__(self, hub_layer):
        super().__init__()
        self.embedding = hub_layer
        self.dense1 = layers.Dense(16, activation='relu')
        self.dense2 = layers.Dense(1, activation='sigmoid')
    def call(self, x):
        x = self.embedding(x)
        x = self.dense1(x)
        return self.dense2(x)
```
Which is throwing:
```
ValueError: Python inputs incompatible with input_signature:
      inputs: (
        Tensor(""input_1_35:0"", shape=(None, 1), dtype=string))
      input_signature: (
        TensorSpec(shape=(None,), dtype=tf.string, name=None))
```
I didn't change anything else.
If this a bug or I'm doing something wrong ? The second model should act exactly like the first one.
"
34047,ResourceApplyGradientDescent happens on CPU?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA Version: 10.1
```bash
tf-docker /opt/project/src > nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130
```
- GPU model and memory: GeForce GTX 1050, 4042MiB

I use the official tensorflow docker image: `tensorflow/tensorflow:2.0.0-gpu-py3`

**Describe the current behavior**
I experience fluctuating GPU utilization when I train a simple language model on artificial data using a custom training loop.
![Peek 2019-11-06 17-01](https://user-images.githubusercontent.com/2678217/68315470-197fa680-00b8-11ea-936d-b2c588259558.gif)

**Describe the expected behavior**
I would expect to get GPU utilization more stable at 100% (or very close to it), since the model is very simple and I expect all (heavy) ops to be able to run on the GPU.

**Code to reproduce the issue**
```python
import tensorflow as tf
#tf.debugging.set_log_device_placement(True)

VOCAB_SIZE = 32000
BATCH_SIZE = 20
LEARNING_RATE = 0.001

class SimpleModel(tf.keras.Model):
    def __init__(self, target_vocab_size):
        super(SimpleModel, self).__init__()
        self.d_model = 1024
        self.embedding = tf.keras.layers.Embedding(target_vocab_size, self.d_model)
        self.body = tf.keras.layers.Dense(self.d_model)

    def call(self, input, training):
        # input shape: (batch, seq_len)
        x = self.embedding(input)  # (batch, seq_len, d_model)
        x = self.body(x)
        logits = tf.matmul(x, self.embedding.embeddings, transpose_b=True)
        return logits


def get_dataset():
    ds = tf.data.Dataset.from_tensor_slices(tf.random.uniform((1000, 20), 0, VOCAB_SIZE, dtype=tf.int64))
    ds = ds.padded_batch(BATCH_SIZE, padded_shapes=[None])
    ds = ds.repeat()
    ds = ds.prefetch(2)
    return ds


def train(ds, model, optimizer):

    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

    def calculate_loss(real, pred):
        loss_ = loss_object(real, pred)
        return tf.reduce_mean(loss_)

    @tf.function
    def train_step(batch):
        tar_inp = batch[:, :-1]
        tar_real = batch[:, 1:]

        with tf.GradientTape() as tape:
            logits = model(tar_inp, True)
            loss = calculate_loss(tar_real, logits)

        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        return None

    #tf.summary.trace_on(graph=True, profiler=True)

    for i, batch in enumerate(ds):
        _ = train_step(batch)

        #if i == 10:
        #   tf.summary.trace_export(name=""model_trace"", step=0, profiler_outdir=""/tmp/profiling/5"")
        #   break


if __name__ == ""__main__"":
    ds = get_dataset()
    model = SimpleModel(VOCAB_SIZE)
    optimizer = tf.keras.optimizers.SGD(LEARNING_RATE)

    train(ds, model, optimizer)
```

**Other info / logs**
When inspecting the trace in Tensorboard I see two memcpys happening between training steps (green and blue boxes):
![Screenshot from 2019-11-06 17-16-15](https://user-images.githubusercontent.com/2678217/68316249-7039b000-00b9-11ea-9b44-88f3f58fa5e1.png)

Zooming in between two steps, I also see a ResourceApplyGradientDescent op happening on the CPU:
![Screenshot from 2019-11-06 17-19-48](https://user-images.githubusercontent.com/2678217/68316446-c73f8500-00b9-11ea-863a-b050eddeab8d.png)

Are ResourceApply* ops supposed to happen on the host (CPU)?"
34045,`==` fails where `tf.equal` works when using tf.data.Dataset.from_generator + @tf.function (TF 2.0),"
""=="" works in my `augment` function (with `@tf.function` decorator) , but `tf.equal` works.

tensorflow version : 2.0.0-beta1
python version : python3.6

**Minimal reproducable example**
Just chuck this in a `ŧest.py` file and run `python3.6 test.py`:
```
import tensorflow as tf
# tf.__version__ yields 2
import tensorflow_hub as hub
import numpy as np

@tf.function
def augment(x, y):
    tf.print(tf.where(tf.equal(y, 0))) # works
    # tf.print(tf.where(y == 0)) # doesn't work for some reason
    return tf.data.Dataset.from_tensors((x, y))

def gen():
    for i in range(400):
        yield np.zeros(shape=(299, 299, 3)), np.zeros(shape=(6,))

dataset = tf.data.Dataset.from_generator(gen, (tf.int64, tf.int64), (tf.TensorShape([299,299,3]), tf.TensorShape([6])))

class Trainer:
    def __init__(self, batch_size):
        self.input_shape = [299, 299, 3]
        self.model = self.create_model()
        self.dataset = dataset
        self.dataset_size = self._get_dataset_size()
        split_point = int(0.8 * self.dataset_size)
        self.batch_size = batch_size
        self.train_ds = self.dataset.take(split_point).flat_map(augment).repeat().batch(self.batch_size)
        self.train_ds_size = split_point

        self.validation_ds = self.dataset.skip(split_point).repeat().batch(self.batch_size)
        self.validation_ds_size = self.dataset_size - split_point
        assert self.validation_ds_size + self.train_ds_size == self.dataset_size

    def create_model(self):
        model = tf.keras.Sequential()
        model.add(hub.KerasLayer(""https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4"",
                                 output_shape=[2048],
                                 input_shape=self.input_shape,
                                 trainable=False))
        model.add(tf.keras.layers.Dense(units=6, activation=""softmax""))
        model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])
        return model

    def _get_dataset_size(self):
        dataset_length = [i for i, _ in enumerate(self.dataset)][-1] + 1
        return dataset_length

    def train(self, epochs):
        callbacks = [
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2),
            # tf.keras.callbacks.ModelCheckpoint('./model.h5', save_best_only=True),
            # tf.keras.callbacks.TensorBoard(log_dir='./logs', write_graph=True)
        ]

        self.model.fit(self.train_ds,
                       epochs=epochs,
                       steps_per_epoch=self.train_ds_size // self.batch_size,
                       validation_data=self.validation_ds,
                       validation_steps=self.validation_ds_size // self.batch_size,
                       verbose=2,
                       callbacks=callbacks)
trainer = Trainer(3)
trainer.train(epochs=2)
```"
34043,Unsupported numpy type: NPY_LONGLONG,"**System information**
Linux Mint 19
Dell XPS 7590 laptop
Python 3.7.4 Anaconda
Tensorflow version: v2.0.0-rc2-26-g64c3d38 2.0.0 (pip tensorflow-gpu with GPU disabled)
Numpy version: 1.17.3

**Describe the current behavior**
Tensorflow 2.0 raises a ValueError if a Numpy array of type np.longlong is converted to a tf.Tensor.

**Describe the expected behavior**
A np.array(dtype=np.longlong) should automatically convert to tf.Tensor(dtype=np.int64), as was the case in Tensorflow 1.15.

**Code to reproduce the issue**
```python
>>> import numpy as np
>>> import tensorflow as tf
>>> x = np.ones(10, dtype=np.longlong)
>>> x_tf = tf.convert_to_tensor(x)
Traceback (most recent call last):
  File ""/home/wibble/.conda/envs/drum-model/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-24-31172ca6f870>"", line 1, in <module>
    tf.constant(x)
  File ""/home/wibble/.conda/envs/drum-model/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 227, in constant
    allow_broadcast=True)
  File ""/home/wibble/.conda/envs/drum-model/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 235, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/home/wibble/.conda/envs/drum-model/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 96, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: Failed to convert a NumPy array to a Tensor (Unsupported numpy type: NPY_LONGLONG).
```
"
34042,Error building 1.13,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.13
- Python version: 2.7
- Installed using virtualenv? pip? conda?: Pip
- Bazel version (if compiling from source): 0.21
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version: 10.0
- GPU model and memory: NVIDIA GeForce RTX 2080 TI (x2), 32GB RAM



**Describe the problem**
Error when trying to build Tensor Flow 1.13

**Provide the exact sequence of commands / steps that you executed before running into the problem**
sudo bazel build --config=opt --config=cuda --incompatible_strict_action_env=false //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

`ERROR: /home/issa/Downloads/tensorflow/tensorflow/BUILD:579:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)
Traceback (most recent call last):
  File ""/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 63, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py"", line 52, in <module>
    from tensorflow.python.framework.importer import import_graph_def
  File ""/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/importer.py"", line 28, in <module>
    from tensorflow.python.framework import function
  File ""/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/function.py"", line 36, in <module>
    from tensorflow.python.ops import resource_variable_ops
  File ""/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py"", line 39, in <module>
    from tensorflow.python.ops import variables
  File ""/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py"", line 133, in <module>
    ""* `ONLY_FIRST_TOWER`: Deprecated alias for `ONLY_FIRST_REPLICA`.\n  "")
AttributeError: attribute '__doc__' of 'type' objects is not writable
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2121.083s, Critical Path: 421.25s
INFO: 10541 processes: 10541 local.
FAILED: Build did NOT complete successfully
`
"
34041,"Training with TPU model.fit error, while GPU works well","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):No
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):Using Colab
- TensorFlow version (use command below):v2.0.0-rc2-26-g64c3d38
- Python version:3.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:TPU

**Describe the current behavior**
Doing a transfer learning with InceptionV3 model on a medium-sized dataset (tfds, CatsVsDogs).
For the same code, when training with GPU, the code runs smoothly.
Switching to TPU produces this (And often other various) errors

```
InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run DatasetCardinality: Unable to parse tensor proto
Additional GRPC error information:
{""created"":""@1573042445.409490969"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to parse tensor proto"",""grpc_status"":3} [Op:DatasetCardinality]
```

**Describe the expected behavior**
TPU training should run similarly to GPU training (without errors in this case)

**Code to reproduce the issue**
Please find the Colab gist to reproduce the issue [""https://gist.github.com/MikeOfZen/abadf58b9c68acd1b33c6e39af7b3f7a.js""](url)

**Other info / logs**
*The issue occurs in both TF 1.15 and 2.0 versions.
Attempting to use .take() to provide cardinality to the dataset didn't help (I've used it successfully to solve a similar issue before)

Overall, I've gotten a number of various odd errors when trying to do TPU training.
Specifically, if caching for this dataset is enabled (should be ~25Gb) all sorts of wild errors pop up from the TPU side, probably due to OOM or buffer overflows.
"
34040,tf.keras.model_to_estimator() fails with custom loss/custom metrics,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.4 
- TensorFlow installed from (source or binary): binary
```
numpy                              1.17.2     
numpydoc                           0.9.1      
protobuf                           3.9.2      
tensorflow                         2.0.0      
tensorflow-addons                  0.6.0      
tensorflow-estimator               2.0.0      
tensorflow-serving-api             2.0.0    
python                             3.7.4
```
**Describe the current behavior**
I am using a custom loss function that requires extra input (the number of words in the sentence). When compiling the model, the InputLayer used in the custom loss function does not get transferred into the new graph. Since the function is stateful, I receive the following error:
```Traceback (most recent call last):
  File ""/src/automated-document-processing/nlp-tfx/bugreport.py"", line 93, in <module>
    estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=params[""eval_dir""])
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/estimator/__init__.py"", line 166, in model_to_estimator_v2
    use_v2_estimator=True)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py"", line 576, in model_to_estimator
    config, save_object_ckpt)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py"", line 381, in _save_first_checkpoint
    custom_objects)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py"", line 227, in _clone_and_build_model
    optimizer_config=optimizer_config)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py"", line 679, in clone_and_build_model
    target_tensors=target_tensors)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 373, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1653, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1713, in _prepare_total_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py"", line 221, in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
  File ""/src/automated-document-processing/nlp-tfx/bugreport.py"", line 80, in CRFLoss
    transition_params=transition_params,
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_addons/text/crf.py"", line 196, in crf_log_likelihood
    transition_params)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_addons/text/crf.py"", line 68, in crf_sequence_score
    return _multi_seq_fn()
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_addons/text/crf.py"", line 59, in _multi_seq_fn
    unary_scores = crf_unary_score(tag_indices, sequence_lengths, inputs)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_addons/text/crf.py"", line 232, in crf_unary_score
    sequence_lengths, maxlen=tf.shape(tag_indices)[1], dtype=tf.float32)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 3568, in sequence_mask
    with ops.name_scope(name, ""SequenceMask"", [lengths, maxlen]):
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 6337, in __enter__
    g_from_inputs = _get_graph_from_inputs(self._values)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 5982, in _get_graph_from_inputs
    _assert_same_graph(original_graph_element, graph_element)
  File ""/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 5917, in _assert_same_graph
    (item, original_item))
ValueError: Tensor(""loss/myscores_loss/strided_slice_3:0"", shape=(), dtype=int32) must be from the same graph as Tensor(""nwords:0"", shape=(None,), dtype=int32).
```

**Describe the expected behavior**
Allow custom stateful loss/metrics functions in `model_to_estimator` or update the documentation that it is not supported. 

**Code to reproduce the issue**
```from typing import Any, Dict

import tensorflow as tf


from typing import Text, Tuple, List, Dict, Any, Union

import numpy as np
import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow.python.ops import math_ops


def _split_iob_tag(tag: Text) -> Tuple[Text, Union[Text, None]]:
    """"""Handle tags <pad>, <unk>, O, B-foo, and I-foo.""""""
    if tag[:2] not in [""B-"", ""I-""]:
        return (tag, None)
    return tuple(tag.split(""-"", maxsplit=2))  # type: ignore


def iob_transition_params(tags: List[Text]) -> tf.constant:
    """"""Return transition matrix suitable for tf.contrib.crf.crf_decode.""""""
    mat = np.zeros((len(tags), len(tags)))
    for i, i_tag in enumerate(tags):
        i_type, i_name = _split_iob_tag(i_tag)
        for j, j_tag in enumerate(tags):
            j_type, j_name = _split_iob_tag(j_tag)
            if (i_type == ""O"" and j_type == ""I"") or (
                i_type in [""B"", ""I""] and j_type == ""I"" and i_name != j_name
            ):
                mat[i][j] = -np.inf
    return tf.constant(mat, dtype=tf.float32)


if __name__ == ""__main__"":
    params: Dict[str, Any] = {
        ""dim"": 300,
        ""dropout"": 0.5,
        ""batch_size"": 3,
        ""buffer"": 15000,
        ""lstm_size"": 10,
        ""eval_dir"": ""../results/"",
        ""saved_model_dir"": ""../final_model/"",
        ""training_data"": ""some_data"",
        ""window_length"": 512,
        ""embedding_dimension"": 300,
    }

    tags = {'I-tag1', 'B-tag1','I-tag2', 'B-tag2','I-tag3', 'B-tag3', 'O'}

    dropout = params[""dropout""]

    embeddings = tf.keras.Input(
        shape=(params[""window_length""], params[""embedding_dimension""],),
        dtype=tf.float32,
        name=""embedding_sequence"",
    )
    nwords = tf.keras.Input(shape=(), dtype=tf.int32, name=""nwords"",)
    lstm_cell_fw = tf.keras.layers.LSTM(params[""lstm_size""], return_sequences=True)(
        embeddings
    )
    output = tf.keras.layers.Dropout(rate=dropout)(lstm_cell_fw)
    logits = tf.keras.layers.Dense(len(tags), name=""myscores"")(output)

    # CRF
    transition_params = iob_transition_params(tags)

    def custom_loss(seqlen):
        def CRFLoss(y_true, y_pred):
            y_true = math_ops.cast(y_true, tf.int32)
            y_true = tf.reshape(y_true, [-1, 512])

            log_likelihood, _ = tfa.text.crf.crf_log_likelihood(
                inputs=y_pred,
                tag_indices=y_true,
                sequence_lengths=seqlen,
                transition_params=transition_params,
            )

            return tf.reduce_mean(-log_likelihood)

        return CRFLoss

    model = tf.keras.Model(
        inputs=[embeddings, nwords], outputs=logits, name=""ner_simple""
    )

    model.compile(optimizer=""adam"", loss=custom_loss(nwords), metrics=[""accuracy""])
    estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=params[""eval_dir""])
```
**Other info / logs**
Related to https://github.com/netrack/keras-metrics/issues/39
"
34039,tf.data.Dataset fixed size batching with subsequent map() under tf.distribute.MirroredStrategy leads to a crash,"**System information**
The same environment as in https://github.com/tensorflow/tensorflow/issues/33531

**Code to reproduce the issue**

It took me a few **weeks** of debugging to reproduce! **IMPORTANT: I DO NOT THINK IT WILL REPRODUCE IN COLAB, YOU NEED AT LEAST 2 GPUS.**

```python
#!/usr/bin/env python3
import sys
import tensorflow as tf

def main():
    strategy = tf.distribute.MirroredStrategy()
    batch_size = 12
    features_shape = 372, 558, 3
    labels = 10
    sample = tf.random.uniform(features_shape)

    def batch_print(b, l):
        tf.print(""shape"", b.shape, tf.shape(b))
        tf.print(b[10])  # <<< crash here
        return b, l

    ds_train = tf.data.Dataset.from_tensors([sample]).map(lambda s: (tf.squeeze(s), tf.ones((labels,)))) \
        .repeat().batch(batch_size, drop_remainder=True).map(batch_print)
    ds_val = tf.data.Dataset.from_tensors([sample]).map(lambda s: (tf.squeeze(s), tf.ones((labels,)))) \
        .repeat().batch(batch_size, drop_remainder=True).take(10)

    import tensorflow_core.python.keras.backend
    original_input = tensorflow_core.python.keras.layers.Input

    def create_input(*args, **kwargs):
        return original_input(*args, batch_size=batch_size, **kwargs)

    # monkey-patch the input layer to ensure the fixed tensor shape
    tensorflow_core.python.keras.layers.Input = create_input

    with strategy.scope():
        model = tf.keras.applications.DenseNet121(
            weights=None, input_shape=features_shape, classes=labels)
        model.build((batch_size,) + features_shape)
        model.summary()
        optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)
        cross_entropy = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)
        model.compile(optimizer=optimizer, loss=cross_entropy, metrics=[""accuracy""])
    model.fit(ds_train, validation_data=ds_val, epochs=1, steps_per_epoch=100)


if __name__ == ""__main__"":
    sys.exit(main())
```

As you see, I am feeding a `tf.data.Dataset` pipeline to a Keras model under `tf.distribute.MirroredStrategy`. In my case, there are 4 GPUs. Here is the log which indicates a crash:

<details>
<summary>Full log</summary>
<pre>
2019-11-06 11:09:37.077575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3
2019-11-06 11:09:37.077858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutorwith strength 1 edge matrix:
2019-11-06 11:09:37.077880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3
2019-11-06 11:09:37.077894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y N N
2019-11-06 11:09:37.077904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N N N
2019-11-06 11:09:37.077914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   N N N Y
2019-11-06 11:09:37.077923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   N N Y N
2019-11-06 11:09:37.084775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
2019-11-06 11:09:37.086075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 10470 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)
2019-11-06 11:09:37.087140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:2 with 10470 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)
2019-11-06 11:09:37.088126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:3 with 10470 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Model: ""densenet121""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(3, 372, 558, 3)]   0
__________________________________________________________________________________________________
zero_padding2d (ZeroPadding2D)  (3, 378, 564, 3)     0           input_1[0][0]
__________________________________________________________________________________________________
conv1/conv (Conv2D)             (3, 186, 279, 64)    9408        zero_padding2d[0][0]
__________________________________________________________________________________________________
conv1/bn (BatchNormalization)   (3, 186, 279, 64)    256         conv1/conv[0][0]
__________________________________________________________________________________________________
conv1/relu (Activation)         (3, 186, 279, 64)    0           conv1/bn[0][0]
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (3, 188, 281, 64)    0           conv1/relu[0][0]
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (3, 93, 140, 64)     0           zero_padding2d_1[0][0]
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (3, 93, 140, 64)     256         pool1[0][0]
__________________________________________________________________________________________________
conv2_block1_0_relu (Activation (3, 93, 140, 64)     0           conv2_block1_0_bn[0][0]
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (3, 93, 140, 128)    8192        conv2_block1_0_relu[0][0]
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block1_1_conv[0][0]
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (3, 93, 140, 128)    0           conv2_block1_1_bn[0][0]
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block1_1_relu[0][0]
__________________________________________________________________________________________________
conv2_block1_concat (Concatenat (3, 93, 140, 96)     0           pool1[0][0]
                                                                 conv2_block1_2_conv[0][0]
__________________________________________________________________________________________________
conv2_block2_0_bn (BatchNormali (3, 93, 140, 96)     384         conv2_block1_concat[0][0]
__________________________________________________________________________________________________
conv2_block2_0_relu (Activation (3, 93, 140, 96)     0           conv2_block2_0_bn[0][0]
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (3, 93, 140, 128)    12288       conv2_block2_0_relu[0][0]
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block2_1_conv[0][0]
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (3, 93, 140, 128)    0           conv2_block2_1_bn[0][0]
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block2_1_relu[0][0]
__________________________________________________________________________________________________
conv2_block2_concat (Concatenat (3, 93, 140, 128)    0           conv2_block1_concat[0][0]
                                                                 conv2_block2_2_conv[0][0]
__________________________________________________________________________________________________
conv2_block3_0_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block2_concat[0][0]
__________________________________________________________________________________________________
conv2_block3_0_relu (Activation (3, 93, 140, 128)    0           conv2_block3_0_bn[0][0]
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (3, 93, 140, 128)    16384       conv2_block3_0_relu[0][0]
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block3_1_conv[0][0]
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (3, 93, 140, 128)    0           conv2_block3_1_bn[0][0]
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block3_1_relu[0][0]
__________________________________________________________________________________________________
conv2_block3_concat (Concatenat (3, 93, 140, 160)    0           conv2_block2_concat[0][0]
                                                                 conv2_block3_2_conv[0][0]
__________________________________________________________________________________________________
conv2_block4_0_bn (BatchNormali (3, 93, 140, 160)    640         conv2_block3_concat[0][0]
__________________________________________________________________________________________________
conv2_block4_0_relu (Activation (3, 93, 140, 160)    0           conv2_block4_0_bn[0][0]
__________________________________________________________________________________________________
conv2_block4_1_conv (Conv2D)    (3, 93, 140, 128)    20480       conv2_block4_0_relu[0][0]
__________________________________________________________________________________________________
conv2_block4_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block4_1_conv[0][0]
__________________________________________________________________________________________________
conv2_block4_1_relu (Activation (3, 93, 140, 128)    0           conv2_block4_1_bn[0][0]
__________________________________________________________________________________________________
conv2_block4_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block4_1_relu[0][0]
__________________________________________________________________________________________________
conv2_block4_concat (Concatenat (3, 93, 140, 192)    0           conv2_block3_concat[0][0]
                                                                 conv2_block4_2_conv[0][0]
__________________________________________________________________________________________________
conv2_block5_0_bn (BatchNormali (3, 93, 140, 192)    768         conv2_block4_concat[0][0]
__________________________________________________________________________________________________
conv2_block5_0_relu (Activation (3, 93, 140, 192)    0           conv2_block5_0_bn[0][0]
__________________________________________________________________________________________________
conv2_block5_1_conv (Conv2D)    (3, 93, 140, 128)    24576       conv2_block5_0_relu[0][0]
__________________________________________________________________________________________________
conv2_block5_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block5_1_conv[0][0]
__________________________________________________________________________________________________
conv2_block5_1_relu (Activation (3, 93, 140, 128)    0           conv2_block5_1_bn[0][0]
__________________________________________________________________________________________________
conv2_block5_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block5_1_relu[0][0]
__________________________________________________________________________________________________
conv2_block5_concat (Concatenat (3, 93, 140, 224)    0           conv2_block4_concat[0][0]
                                                                 conv2_block5_2_conv[0][0]
__________________________________________________________________________________________________
conv2_block6_0_bn (BatchNormali (3, 93, 140, 224)    896         conv2_block5_concat[0][0]
__________________________________________________________________________________________________
conv2_block6_0_relu (Activation (3, 93, 140, 224)    0           conv2_block6_0_bn[0][0]
__________________________________________________________________________________________________
conv2_block6_1_conv (Conv2D)    (3, 93, 140, 128)    28672       conv2_block6_0_relu[0][0]
__________________________________________________________________________________________________
conv2_block6_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block6_1_conv[0][0]
__________________________________________________________________________________________________
conv2_block6_1_relu (Activation (3, 93, 140, 128)    0           conv2_block6_1_bn[0][0]
__________________________________________________________________________________________________
conv2_block6_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block6_1_relu[0][0]
__________________________________________________________________________________________________
conv2_block6_concat (Concatenat (3, 93, 140, 256)    0           conv2_block5_concat[0][0]
                                                                 conv2_block6_2_conv[0][0]
__________________________________________________________________________________________________
pool2_bn (BatchNormalization)   (3, 93, 140, 256)    1024        conv2_block6_concat[0][0]
__________________________________________________________________________________________________
pool2_relu (Activation)         (3, 93, 140, 256)    0           pool2_bn[0][0]
__________________________________________________________________________________________________
pool2_conv (Conv2D)             (3, 93, 140, 128)    32768       pool2_relu[0][0]
__________________________________________________________________________________________________
pool2_pool (AveragePooling2D)   (3, 46, 70, 128)     0           pool2_conv[0][0]
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (3, 46, 70, 128)     512         pool2_pool[0][0]
__________________________________________________________________________________________________
conv3_block1_0_relu (Activation (3, 46, 70, 128)     0           conv3_block1_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (3, 46, 70, 128)     16384       conv3_block1_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block1_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (3, 46, 70, 128)     0           conv3_block1_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block1_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block1_concat (Concatenat (3, 46, 70, 160)     0           pool2_pool[0][0]
                                                                 conv3_block1_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block2_0_bn (BatchNormali (3, 46, 70, 160)     640         conv3_block1_concat[0][0]
__________________________________________________________________________________________________
conv3_block2_0_relu (Activation (3, 46, 70, 160)     0           conv3_block2_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (3, 46, 70, 128)     20480       conv3_block2_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block2_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (3, 46, 70, 128)     0           conv3_block2_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block2_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block2_concat (Concatenat (3, 46, 70, 192)     0           conv3_block1_concat[0][0]
                                                                 conv3_block2_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block3_0_bn (BatchNormali (3, 46, 70, 192)     768         conv3_block2_concat[0][0]
__________________________________________________________________________________________________
conv3_block3_0_relu (Activation (3, 46, 70, 192)     0           conv3_block3_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (3, 46, 70, 128)     24576       conv3_block3_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block3_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (3, 46, 70, 128)     0           conv3_block3_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block3_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block3_concat (Concatenat (3, 46, 70, 224)     0           conv3_block2_concat[0][0]
                                                                 conv3_block3_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block4_0_bn (BatchNormali (3, 46, 70, 224)     896         conv3_block3_concat[0][0]
__________________________________________________________________________________________________
conv3_block4_0_relu (Activation (3, 46, 70, 224)     0           conv3_block4_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (3, 46, 70, 128)     28672       conv3_block4_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block4_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (3, 46, 70, 128)     0           conv3_block4_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block4_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block4_concat (Concatenat (3, 46, 70, 256)     0           conv3_block3_concat[0][0]
                                                                 conv3_block4_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block5_0_bn (BatchNormali (3, 46, 70, 256)     1024        conv3_block4_concat[0][0]
__________________________________________________________________________________________________
conv3_block5_0_relu (Activation (3, 46, 70, 256)     0           conv3_block5_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block5_1_conv (Conv2D)    (3, 46, 70, 128)     32768       conv3_block5_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block5_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block5_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block5_1_relu (Activation (3, 46, 70, 128)     0           conv3_block5_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block5_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block5_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block5_concat (Concatenat (3, 46, 70, 288)     0           conv3_block4_concat[0][0]
                                                                 conv3_block5_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block6_0_bn (BatchNormali (3, 46, 70, 288)     1152        conv3_block5_concat[0][0]
__________________________________________________________________________________________________
conv3_block6_0_relu (Activation (3, 46, 70, 288)     0           conv3_block6_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block6_1_conv (Conv2D)    (3, 46, 70, 128)     36864       conv3_block6_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block6_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block6_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block6_1_relu (Activation (3, 46, 70, 128)     0           conv3_block6_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block6_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block6_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block6_concat (Concatenat (3, 46, 70, 320)     0           conv3_block5_concat[0][0]
                                                                 conv3_block6_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block7_0_bn (BatchNormali (3, 46, 70, 320)     1280        conv3_block6_concat[0][0]
__________________________________________________________________________________________________
conv3_block7_0_relu (Activation (3, 46, 70, 320)     0           conv3_block7_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block7_1_conv (Conv2D)    (3, 46, 70, 128)     40960       conv3_block7_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block7_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block7_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block7_1_relu (Activation (3, 46, 70, 128)     0           conv3_block7_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block7_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block7_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block7_concat (Concatenat (3, 46, 70, 352)     0           conv3_block6_concat[0][0]
                                                                 conv3_block7_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block8_0_bn (BatchNormali (3, 46, 70, 352)     1408        conv3_block7_concat[0][0]
__________________________________________________________________________________________________
conv3_block8_0_relu (Activation (3, 46, 70, 352)     0           conv3_block8_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block8_1_conv (Conv2D)    (3, 46, 70, 128)     45056       conv3_block8_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block8_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block8_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block8_1_relu (Activation (3, 46, 70, 128)     0           conv3_block8_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block8_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block8_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block8_concat (Concatenat (3, 46, 70, 384)     0           conv3_block7_concat[0][0]
                                                                 conv3_block8_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block9_0_bn (BatchNormali (3, 46, 70, 384)     1536        conv3_block8_concat[0][0]
__________________________________________________________________________________________________
conv3_block9_0_relu (Activation (3, 46, 70, 384)     0           conv3_block9_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block9_1_conv (Conv2D)    (3, 46, 70, 128)     49152       conv3_block9_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block9_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block9_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block9_1_relu (Activation (3, 46, 70, 128)     0           conv3_block9_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block9_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block9_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block9_concat (Concatenat (3, 46, 70, 416)     0           conv3_block8_concat[0][0]
                                                                 conv3_block9_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block10_0_bn (BatchNormal (3, 46, 70, 416)     1664        conv3_block9_concat[0][0]
__________________________________________________________________________________________________
conv3_block10_0_relu (Activatio (3, 46, 70, 416)     0           conv3_block10_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block10_1_conv (Conv2D)   (3, 46, 70, 128)     53248       conv3_block10_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block10_1_bn (BatchNormal (3, 46, 70, 128)     512         conv3_block10_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block10_1_relu (Activatio (3, 46, 70, 128)     0           conv3_block10_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block10_2_conv (Conv2D)   (3, 46, 70, 32)      36864       conv3_block10_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block10_concat (Concatena (3, 46, 70, 448)     0           conv3_block9_concat[0][0]
                                                                 conv3_block10_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block11_0_bn (BatchNormal (3, 46, 70, 448)     1792        conv3_block10_concat[0][0]
__________________________________________________________________________________________________
conv3_block11_0_relu (Activatio (3, 46, 70, 448)     0           conv3_block11_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block11_1_conv (Conv2D)   (3, 46, 70, 128)     57344       conv3_block11_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block11_1_bn (BatchNormal (3, 46, 70, 128)     512         conv3_block11_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block11_1_relu (Activatio (3, 46, 70, 128)     0           conv3_block11_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block11_2_conv (Conv2D)   (3, 46, 70, 32)      36864       conv3_block11_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block11_concat (Concatena (3, 46, 70, 480)     0           conv3_block10_concat[0][0]
                                                                 conv3_block11_2_conv[0][0]
__________________________________________________________________________________________________
conv3_block12_0_bn (BatchNormal (3, 46, 70, 480)     1920        conv3_block11_concat[0][0]
__________________________________________________________________________________________________
conv3_block12_0_relu (Activatio (3, 46, 70, 480)     0           conv3_block12_0_bn[0][0]
__________________________________________________________________________________________________
conv3_block12_1_conv (Conv2D)   (3, 46, 70, 128)     61440       conv3_block12_0_relu[0][0]
__________________________________________________________________________________________________
conv3_block12_1_bn (BatchNormal (3, 46, 70, 128)     512         conv3_block12_1_conv[0][0]
__________________________________________________________________________________________________
conv3_block12_1_relu (Activatio (3, 46, 70, 128)     0           conv3_block12_1_bn[0][0]
__________________________________________________________________________________________________
conv3_block12_2_conv (Conv2D)   (3, 46, 70, 32)      36864       conv3_block12_1_relu[0][0]
__________________________________________________________________________________________________
conv3_block12_concat (Concatena (3, 46, 70, 512)     0           conv3_block11_concat[0][0]
                                                                 conv3_block12_2_conv[0][0]
__________________________________________________________________________________________________
pool3_bn (BatchNormalization)   (3, 46, 70, 512)     2048        conv3_block12_concat[0][0]
__________________________________________________________________________________________________
pool3_relu (Activation)         (3, 46, 70, 512)     0           pool3_bn[0][0]
__________________________________________________________________________________________________
pool3_conv (Conv2D)             (3, 46, 70, 256)     131072      pool3_relu[0][0]
__________________________________________________________________________________________________
pool3_pool (AveragePooling2D)   (3, 23, 35, 256)     0           pool3_conv[0][0]
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (3, 23, 35, 256)     1024        pool3_pool[0][0]
__________________________________________________________________________________________________
conv4_block1_0_relu (Activation (3, 23, 35, 256)     0           conv4_block1_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (3, 23, 35, 128)     32768       conv4_block1_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block1_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (3, 23, 35, 128)     0           conv4_block1_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block1_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block1_concat (Concatenat (3, 23, 35, 288)     0           pool3_pool[0][0]
                                                                 conv4_block1_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block2_0_bn (BatchNormali (3, 23, 35, 288)     1152        conv4_block1_concat[0][0]
__________________________________________________________________________________________________
conv4_block2_0_relu (Activation (3, 23, 35, 288)     0           conv4_block2_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (3, 23, 35, 128)     36864       conv4_block2_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block2_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (3, 23, 35, 128)     0           conv4_block2_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block2_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block2_concat (Concatenat (3, 23, 35, 320)     0           conv4_block1_concat[0][0]
                                                                 conv4_block2_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block3_0_bn (BatchNormali (3, 23, 35, 320)     1280        conv4_block2_concat[0][0]
__________________________________________________________________________________________________
conv4_block3_0_relu (Activation (3, 23, 35, 320)     0           conv4_block3_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (3, 23, 35, 128)     40960       conv4_block3_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block3_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (3, 23, 35, 128)     0           conv4_block3_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block3_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block3_concat (Concatenat (3, 23, 35, 352)     0           conv4_block2_concat[0][0]
                                                                 conv4_block3_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block4_0_bn (BatchNormali (3, 23, 35, 352)     1408        conv4_block3_concat[0][0]
__________________________________________________________________________________________________
conv4_block4_0_relu (Activation (3, 23, 35, 352)     0           conv4_block4_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (3, 23, 35, 128)     45056       conv4_block4_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block4_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (3, 23, 35, 128)     0           conv4_block4_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block4_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block4_concat (Concatenat (3, 23, 35, 384)     0           conv4_block3_concat[0][0]
                                                                 conv4_block4_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block5_0_bn (BatchNormali (3, 23, 35, 384)     1536        conv4_block4_concat[0][0]
__________________________________________________________________________________________________
conv4_block5_0_relu (Activation (3, 23, 35, 384)     0           conv4_block5_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (3, 23, 35, 128)     49152       conv4_block5_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block5_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (3, 23, 35, 128)     0           conv4_block5_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block5_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block5_concat (Concatenat (3, 23, 35, 416)     0           conv4_block4_concat[0][0]
                                                                 conv4_block5_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block6_0_bn (BatchNormali (3, 23, 35, 416)     1664        conv4_block5_concat[0][0]
__________________________________________________________________________________________________
conv4_block6_0_relu (Activation (3, 23, 35, 416)     0           conv4_block6_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (3, 23, 35, 128)     53248       conv4_block6_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block6_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (3, 23, 35, 128)     0           conv4_block6_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block6_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block6_concat (Concatenat (3, 23, 35, 448)     0           conv4_block5_concat[0][0]
                                                                 conv4_block6_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block7_0_bn (BatchNormali (3, 23, 35, 448)     1792        conv4_block6_concat[0][0]
__________________________________________________________________________________________________
conv4_block7_0_relu (Activation (3, 23, 35, 448)     0           conv4_block7_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block7_1_conv (Conv2D)    (3, 23, 35, 128)     57344       conv4_block7_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block7_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block7_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block7_1_relu (Activation (3, 23, 35, 128)     0           conv4_block7_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block7_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block7_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block7_concat (Concatenat (3, 23, 35, 480)     0           conv4_block6_concat[0][0]
                                                                 conv4_block7_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block8_0_bn (BatchNormali (3, 23, 35, 480)     1920        conv4_block7_concat[0][0]
__________________________________________________________________________________________________
conv4_block8_0_relu (Activation (3, 23, 35, 480)     0           conv4_block8_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block8_1_conv (Conv2D)    (3, 23, 35, 128)     61440       conv4_block8_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block8_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block8_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block8_1_relu (Activation (3, 23, 35, 128)     0           conv4_block8_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block8_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block8_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block8_concat (Concatenat (3, 23, 35, 512)     0           conv4_block7_concat[0][0]
                                                                 conv4_block8_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block9_0_bn (BatchNormali (3, 23, 35, 512)     2048        conv4_block8_concat[0][0]
__________________________________________________________________________________________________
conv4_block9_0_relu (Activation (3, 23, 35, 512)     0           conv4_block9_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block9_1_conv (Conv2D)    (3, 23, 35, 128)     65536       conv4_block9_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block9_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block9_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block9_1_relu (Activation (3, 23, 35, 128)     0           conv4_block9_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block9_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block9_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block9_concat (Concatenat (3, 23, 35, 544)     0           conv4_block8_concat[0][0]
                                                                 conv4_block9_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block10_0_bn (BatchNormal (3, 23, 35, 544)     2176        conv4_block9_concat[0][0]
__________________________________________________________________________________________________
conv4_block10_0_relu (Activatio (3, 23, 35, 544)     0           conv4_block10_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block10_1_conv (Conv2D)   (3, 23, 35, 128)     69632       conv4_block10_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block10_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block10_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block10_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block10_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block10_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block10_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block10_concat (Concatena (3, 23, 35, 576)     0           conv4_block9_concat[0][0]
                                                                 conv4_block10_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block11_0_bn (BatchNormal (3, 23, 35, 576)     2304        conv4_block10_concat[0][0]
__________________________________________________________________________________________________
conv4_block11_0_relu (Activatio (3, 23, 35, 576)     0           conv4_block11_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block11_1_conv (Conv2D)   (3, 23, 35, 128)     73728       conv4_block11_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block11_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block11_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block11_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block11_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block11_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block11_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block11_concat (Concatena (3, 23, 35, 608)     0           conv4_block10_concat[0][0]
                                                                 conv4_block11_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block12_0_bn (BatchNormal (3, 23, 35, 608)     2432        conv4_block11_concat[0][0]
__________________________________________________________________________________________________
conv4_block12_0_relu (Activatio (3, 23, 35, 608)     0           conv4_block12_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block12_1_conv (Conv2D)   (3, 23, 35, 128)     77824       conv4_block12_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block12_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block12_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block12_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block12_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block12_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block12_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block12_concat (Concatena (3, 23, 35, 640)     0           conv4_block11_concat[0][0]
                                                                 conv4_block12_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block13_0_bn (BatchNormal (3, 23, 35, 640)     2560        conv4_block12_concat[0][0]
__________________________________________________________________________________________________
conv4_block13_0_relu (Activatio (3, 23, 35, 640)     0           conv4_block13_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block13_1_conv (Conv2D)   (3, 23, 35, 128)     81920       conv4_block13_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block13_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block13_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block13_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block13_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block13_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block13_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block13_concat (Concatena (3, 23, 35, 672)     0           conv4_block12_concat[0][0]
                                                                 conv4_block13_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block14_0_bn (BatchNormal (3, 23, 35, 672)     2688        conv4_block13_concat[0][0]
__________________________________________________________________________________________________
conv4_block14_0_relu (Activatio (3, 23, 35, 672)     0           conv4_block14_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block14_1_conv (Conv2D)   (3, 23, 35, 128)     86016       conv4_block14_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block14_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block14_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block14_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block14_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block14_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block14_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block14_concat (Concatena (3, 23, 35, 704)     0           conv4_block13_concat[0][0]
                                                                 conv4_block14_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block15_0_bn (BatchNormal (3, 23, 35, 704)     2816        conv4_block14_concat[0][0]
__________________________________________________________________________________________________
conv4_block15_0_relu (Activatio (3, 23, 35, 704)     0           conv4_block15_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block15_1_conv (Conv2D)   (3, 23, 35, 128)     90112       conv4_block15_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block15_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block15_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block15_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block15_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block15_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block15_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block15_concat (Concatena (3, 23, 35, 736)     0           conv4_block14_concat[0][0]
                                                                 conv4_block15_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block16_0_bn (BatchNormal (3, 23, 35, 736)     2944        conv4_block15_concat[0][0]
__________________________________________________________________________________________________
conv4_block16_0_relu (Activatio (3, 23, 35, 736)     0           conv4_block16_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block16_1_conv (Conv2D)   (3, 23, 35, 128)     94208       conv4_block16_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block16_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block16_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block16_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block16_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block16_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block16_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block16_concat (Concatena (3, 23, 35, 768)     0           conv4_block15_concat[0][0]
                                                                 conv4_block16_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block17_0_bn (BatchNormal (3, 23, 35, 768)     3072        conv4_block16_concat[0][0]
__________________________________________________________________________________________________
conv4_block17_0_relu (Activatio (3, 23, 35, 768)     0           conv4_block17_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block17_1_conv (Conv2D)   (3, 23, 35, 128)     98304       conv4_block17_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block17_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block17_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block17_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block17_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block17_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block17_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block17_concat (Concatena (3, 23, 35, 800)     0           conv4_block16_concat[0][0]
                                                                 conv4_block17_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block18_0_bn (BatchNormal (3, 23, 35, 800)     3200        conv4_block17_concat[0][0]
__________________________________________________________________________________________________
conv4_block18_0_relu (Activatio (3, 23, 35, 800)     0           conv4_block18_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block18_1_conv (Conv2D)   (3, 23, 35, 128)     102400      conv4_block18_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block18_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block18_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block18_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block18_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block18_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block18_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block18_concat (Concatena (3, 23, 35, 832)     0           conv4_block17_concat[0][0]
                                                                 conv4_block18_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block19_0_bn (BatchNormal (3, 23, 35, 832)     3328        conv4_block18_concat[0][0]
__________________________________________________________________________________________________
conv4_block19_0_relu (Activatio (3, 23, 35, 832)     0           conv4_block19_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block19_1_conv (Conv2D)   (3, 23, 35, 128)     106496      conv4_block19_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block19_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block19_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block19_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block19_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block19_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block19_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block19_concat (Concatena (3, 23, 35, 864)     0           conv4_block18_concat[0][0]
                                                                 conv4_block19_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block20_0_bn (BatchNormal (3, 23, 35, 864)     3456        conv4_block19_concat[0][0]
__________________________________________________________________________________________________
conv4_block20_0_relu (Activatio (3, 23, 35, 864)     0           conv4_block20_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block20_1_conv (Conv2D)   (3, 23, 35, 128)     110592      conv4_block20_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block20_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block20_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block20_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block20_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block20_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block20_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block20_concat (Concatena (3, 23, 35, 896)     0           conv4_block19_concat[0][0]
                                                                 conv4_block20_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block21_0_bn (BatchNormal (3, 23, 35, 896)     3584        conv4_block20_concat[0][0]
__________________________________________________________________________________________________
conv4_block21_0_relu (Activatio (3, 23, 35, 896)     0           conv4_block21_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block21_1_conv (Conv2D)   (3, 23, 35, 128)     114688      conv4_block21_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block21_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block21_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block21_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block21_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block21_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block21_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block21_concat (Concatena (3, 23, 35, 928)     0           conv4_block20_concat[0][0]
                                                                 conv4_block21_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block22_0_bn (BatchNormal (3, 23, 35, 928)     3712        conv4_block21_concat[0][0]
__________________________________________________________________________________________________
conv4_block22_0_relu (Activatio (3, 23, 35, 928)     0           conv4_block22_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block22_1_conv (Conv2D)   (3, 23, 35, 128)     118784      conv4_block22_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block22_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block22_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block22_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block22_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block22_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block22_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block22_concat (Concatena (3, 23, 35, 960)     0           conv4_block21_concat[0][0]
                                                                 conv4_block22_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block23_0_bn (BatchNormal (3, 23, 35, 960)     3840        conv4_block22_concat[0][0]
__________________________________________________________________________________________________
conv4_block23_0_relu (Activatio (3, 23, 35, 960)     0           conv4_block23_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block23_1_conv (Conv2D)   (3, 23, 35, 128)     122880      conv4_block23_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block23_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block23_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block23_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block23_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block23_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block23_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block23_concat (Concatena (3, 23, 35, 992)     0           conv4_block22_concat[0][0]
                                                                 conv4_block23_2_conv[0][0]
__________________________________________________________________________________________________
conv4_block24_0_bn (BatchNormal (3, 23, 35, 992)     3968        conv4_block23_concat[0][0]
__________________________________________________________________________________________________
conv4_block24_0_relu (Activatio (3, 23, 35, 992)     0           conv4_block24_0_bn[0][0]
__________________________________________________________________________________________________
conv4_block24_1_conv (Conv2D)   (3, 23, 35, 128)     126976      conv4_block24_0_relu[0][0]
__________________________________________________________________________________________________
conv4_block24_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block24_1_conv[0][0]
__________________________________________________________________________________________________
conv4_block24_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block24_1_bn[0][0]
__________________________________________________________________________________________________
conv4_block24_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block24_1_relu[0][0]
__________________________________________________________________________________________________
conv4_block24_concat (Concatena (3, 23, 35, 1024)    0           conv4_block23_concat[0][0]
                                                                 conv4_block24_2_conv[0][0]
__________________________________________________________________________________________________
pool4_bn (BatchNormalization)   (3, 23, 35, 1024)    4096        conv4_block24_concat[0][0]
__________________________________________________________________________________________________
pool4_relu (Activation)         (3, 23, 35, 1024)    0           pool4_bn[0][0]
__________________________________________________________________________________________________
pool4_conv (Conv2D)             (3, 23, 35, 512)     524288      pool4_relu[0][0]
__________________________________________________________________________________________________
pool4_pool (AveragePooling2D)   (3, 11, 17, 512)     0           pool4_conv[0][0]
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (3, 11, 17, 512)     2048        pool4_pool[0][0]
__________________________________________________________________________________________________
conv5_block1_0_relu (Activation (3, 11, 17, 512)     0           conv5_block1_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (3, 11, 17, 128)     65536       conv5_block1_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block1_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (3, 11, 17, 128)     0           conv5_block1_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block1_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block1_concat (Concatenat (3, 11, 17, 544)     0           pool4_pool[0][0]
                                                                 conv5_block1_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block2_0_bn (BatchNormali (3, 11, 17, 544)     2176        conv5_block1_concat[0][0]
__________________________________________________________________________________________________
conv5_block2_0_relu (Activation (3, 11, 17, 544)     0           conv5_block2_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (3, 11, 17, 128)     69632       conv5_block2_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block2_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (3, 11, 17, 128)     0           conv5_block2_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block2_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block2_concat (Concatenat (3, 11, 17, 576)     0           conv5_block1_concat[0][0]
                                                                 conv5_block2_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block3_0_bn (BatchNormali (3, 11, 17, 576)     2304        conv5_block2_concat[0][0]
__________________________________________________________________________________________________
conv5_block3_0_relu (Activation (3, 11, 17, 576)     0           conv5_block3_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (3, 11, 17, 128)     73728       conv5_block3_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block3_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (3, 11, 17, 128)     0           conv5_block3_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block3_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block3_concat (Concatenat (3, 11, 17, 608)     0           conv5_block2_concat[0][0]
                                                                 conv5_block3_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block4_0_bn (BatchNormali (3, 11, 17, 608)     2432        conv5_block3_concat[0][0]
__________________________________________________________________________________________________
conv5_block4_0_relu (Activation (3, 11, 17, 608)     0           conv5_block4_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block4_1_conv (Conv2D)    (3, 11, 17, 128)     77824       conv5_block4_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block4_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block4_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block4_1_relu (Activation (3, 11, 17, 128)     0           conv5_block4_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block4_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block4_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block4_concat (Concatenat (3, 11, 17, 640)     0           conv5_block3_concat[0][0]
                                                                 conv5_block4_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block5_0_bn (BatchNormali (3, 11, 17, 640)     2560        conv5_block4_concat[0][0]
__________________________________________________________________________________________________
conv5_block5_0_relu (Activation (3, 11, 17, 640)     0           conv5_block5_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block5_1_conv (Conv2D)    (3, 11, 17, 128)     81920       conv5_block5_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block5_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block5_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block5_1_relu (Activation (3, 11, 17, 128)     0           conv5_block5_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block5_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block5_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block5_concat (Concatenat (3, 11, 17, 672)     0           conv5_block4_concat[0][0]
                                                                 conv5_block5_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block6_0_bn (BatchNormali (3, 11, 17, 672)     2688        conv5_block5_concat[0][0]
__________________________________________________________________________________________________
conv5_block6_0_relu (Activation (3, 11, 17, 672)     0           conv5_block6_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block6_1_conv (Conv2D)    (3, 11, 17, 128)     86016       conv5_block6_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block6_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block6_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block6_1_relu (Activation (3, 11, 17, 128)     0           conv5_block6_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block6_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block6_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block6_concat (Concatenat (3, 11, 17, 704)     0           conv5_block5_concat[0][0]
                                                                 conv5_block6_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block7_0_bn (BatchNormali (3, 11, 17, 704)     2816        conv5_block6_concat[0][0]
__________________________________________________________________________________________________
conv5_block7_0_relu (Activation (3, 11, 17, 704)     0           conv5_block7_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block7_1_conv (Conv2D)    (3, 11, 17, 128)     90112       conv5_block7_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block7_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block7_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block7_1_relu (Activation (3, 11, 17, 128)     0           conv5_block7_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block7_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block7_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block7_concat (Concatenat (3, 11, 17, 736)     0           conv5_block6_concat[0][0]
                                                                 conv5_block7_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block8_0_bn (BatchNormali (3, 11, 17, 736)     2944        conv5_block7_concat[0][0]
__________________________________________________________________________________________________
conv5_block8_0_relu (Activation (3, 11, 17, 736)     0           conv5_block8_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block8_1_conv (Conv2D)    (3, 11, 17, 128)     94208       conv5_block8_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block8_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block8_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block8_1_relu (Activation (3, 11, 17, 128)     0           conv5_block8_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block8_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block8_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block8_concat (Concatenat (3, 11, 17, 768)     0           conv5_block7_concat[0][0]
                                                                 conv5_block8_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block9_0_bn (BatchNormali (3, 11, 17, 768)     3072        conv5_block8_concat[0][0]
__________________________________________________________________________________________________
conv5_block9_0_relu (Activation (3, 11, 17, 768)     0           conv5_block9_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block9_1_conv (Conv2D)    (3, 11, 17, 128)     98304       conv5_block9_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block9_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block9_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block9_1_relu (Activation (3, 11, 17, 128)     0           conv5_block9_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block9_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block9_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block9_concat (Concatenat (3, 11, 17, 800)     0           conv5_block8_concat[0][0]
                                                                 conv5_block9_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block10_0_bn (BatchNormal (3, 11, 17, 800)     3200        conv5_block9_concat[0][0]
__________________________________________________________________________________________________
conv5_block10_0_relu (Activatio (3, 11, 17, 800)     0           conv5_block10_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block10_1_conv (Conv2D)   (3, 11, 17, 128)     102400      conv5_block10_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block10_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block10_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block10_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block10_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block10_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block10_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block10_concat (Concatena (3, 11, 17, 832)     0           conv5_block9_concat[0][0]
                                                                 conv5_block10_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block11_0_bn (BatchNormal (3, 11, 17, 832)     3328        conv5_block10_concat[0][0]
__________________________________________________________________________________________________
conv5_block11_0_relu (Activatio (3, 11, 17, 832)     0           conv5_block11_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block11_1_conv (Conv2D)   (3, 11, 17, 128)     106496      conv5_block11_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block11_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block11_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block11_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block11_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block11_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block11_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block11_concat (Concatena (3, 11, 17, 864)     0           conv5_block10_concat[0][0]
                                                                 conv5_block11_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block12_0_bn (BatchNormal (3, 11, 17, 864)     3456        conv5_block11_concat[0][0]
__________________________________________________________________________________________________
conv5_block12_0_relu (Activatio (3, 11, 17, 864)     0           conv5_block12_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block12_1_conv (Conv2D)   (3, 11, 17, 128)     110592      conv5_block12_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block12_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block12_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block12_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block12_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block12_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block12_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block12_concat (Concatena (3, 11, 17, 896)     0           conv5_block11_concat[0][0]
                                                                 conv5_block12_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block13_0_bn (BatchNormal (3, 11, 17, 896)     3584        conv5_block12_concat[0][0]
__________________________________________________________________________________________________
conv5_block13_0_relu (Activatio (3, 11, 17, 896)     0           conv5_block13_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block13_1_conv (Conv2D)   (3, 11, 17, 128)     114688      conv5_block13_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block13_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block13_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block13_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block13_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block13_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block13_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block13_concat (Concatena (3, 11, 17, 928)     0           conv5_block12_concat[0][0]
                                                                 conv5_block13_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block14_0_bn (BatchNormal (3, 11, 17, 928)     3712        conv5_block13_concat[0][0]
__________________________________________________________________________________________________
conv5_block14_0_relu (Activatio (3, 11, 17, 928)     0           conv5_block14_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block14_1_conv (Conv2D)   (3, 11, 17, 128)     118784      conv5_block14_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block14_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block14_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block14_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block14_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block14_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block14_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block14_concat (Concatena (3, 11, 17, 960)     0           conv5_block13_concat[0][0]
                                                                 conv5_block14_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block15_0_bn (BatchNormal (3, 11, 17, 960)     3840        conv5_block14_concat[0][0]
__________________________________________________________________________________________________
conv5_block15_0_relu (Activatio (3, 11, 17, 960)     0           conv5_block15_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block15_1_conv (Conv2D)   (3, 11, 17, 128)     122880      conv5_block15_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block15_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block15_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block15_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block15_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block15_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block15_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block15_concat (Concatena (3, 11, 17, 992)     0           conv5_block14_concat[0][0]
                                                                 conv5_block15_2_conv[0][0]
__________________________________________________________________________________________________
conv5_block16_0_bn (BatchNormal (3, 11, 17, 992)     3968        conv5_block15_concat[0][0]
__________________________________________________________________________________________________
conv5_block16_0_relu (Activatio (3, 11, 17, 992)     0           conv5_block16_0_bn[0][0]
__________________________________________________________________________________________________
conv5_block16_1_conv (Conv2D)   (3, 11, 17, 128)     126976      conv5_block16_0_relu[0][0]
__________________________________________________________________________________________________
conv5_block16_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block16_1_conv[0][0]
__________________________________________________________________________________________________
conv5_block16_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block16_1_bn[0][0]
__________________________________________________________________________________________________
conv5_block16_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block16_1_relu[0][0]
__________________________________________________________________________________________________
conv5_block16_concat (Concatena (3, 11, 17, 1024)    0           conv5_block15_concat[0][0]
                                                                 conv5_block16_2_conv[0][0]
__________________________________________________________________________________________________
bn (BatchNormalization)         (3, 11, 17, 1024)    4096        conv5_block16_concat[0][0]
__________________________________________________________________________________________________
relu (Activation)               (3, 11, 17, 1024)    0           bn[0][0]
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (3, 1024)            0           relu[0][0]
__________________________________________________________________________________________________
fc1000 (Dense)                  (3, 10)              10250       avg_pool[0][0]
==================================================================================================
Total params: 7,047,754
Trainable params: 6,964,106
Non-trainable params: 83,648
__________________________________________________________________________________________________
Train for 100 steps, validate for 10 steps
2019-11-06 11:12:15.235702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamiclibrary libcublas.so.10.0
shape TensorShape([12, 372, 558, 3]) [12 372 558 3]
2019-11-06 11:12:15.481528: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.
shape TensorShape([12, 372, 558, 3]) [12 372 558 3]
2019-11-06 11:12:15.485747: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.
shape TensorShape([12, 372, 558, 3]) [12 372 558 3]
2019-11-06 11:12:15.488817: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.
2019-11-06 11:12:15.489183: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
         [[Identity_4/_188]]
2019-11-06 11:12:15.489398: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
shape TensorShape([12, 372, 558, 3]) [12 372 558 3]
2019-11-06 11:12:15.494247: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.
2019-11-06 11:12:15.887854: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
         [[replica_2/metrics/accuracy/AssignAddVariableOp_1/_39]]
  1/100 [..............................] - ETA: 3:57:11Traceback (most recent call last):
  File ""/user/vmarkovtsev/images/efficientoffice/efficientoffice/shape_bug.py"", line 45, in <module>
    sys.exit(main())
  File ""/user/vmarkovtsev/images/efficientoffice/efficientoffice/shape_bug.py"", line 41, in main
    model.fit(ds_train, validation_data=ds_val, epochs=1, steps_per_epoch=100)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: 4 root error(s) found.
  (0) Invalid argument:   slice index 10 of dimension 0 out of bounds.
         [[node strided_slice (defined at /local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
         [[Identity_4/_188]]
  (1) Invalid argument:   slice index 10 of dimension 0 out of bounds.
         [[node strided_slice (defined at /local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
  (2) Cancelled:
  (3) Cancelled:
0 successful operations.
1 derived errors ignored. [Op:__inference_distributed_function_166689]

Function call stack:
distributed_function -> distributed_function -> distributed_function -> distributed_function -> distributed_function ->distributed_function
</pre>
</details>

This is how the log ends - the crash:

```
Train for 100 steps, validate for 10 steps
2019-11-06 11:12:15.235702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamiclibrary libcublas.so.10.0
shape TensorShape([12, 372, 558, 3]) [12 372 558 3]
2019-11-06 11:12:15.481528: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.
shape TensorShape([12, 372, 558, 3]) [12 372 558 3]
2019-11-06 11:12:15.485747: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.
shape TensorShape([12, 372, 558, 3]) [12 372 558 3]
2019-11-06 11:12:15.488817: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.
2019-11-06 11:12:15.489183: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
         [[Identity_4/_188]]
2019-11-06 11:12:15.489398: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
shape TensorShape([12, 372, 558, 3]) [12 372 558 3]
2019-11-06 11:12:15.494247: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.
2019-11-06 11:12:15.887854: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
         [[replica_2/metrics/accuracy/AssignAddVariableOp_1/_39]]
  1/100 [..............................] - ETA: 3:57:11Traceback (most recent call last):
  File ""/user/vmarkovtsev/images/efficientoffice/efficientoffice/shape_bug.py"", line 45, in <module>
    sys.exit(main())
  File ""/user/vmarkovtsev/images/efficientoffice/efficientoffice/shape_bug.py"", line 41, in main
    model.fit(ds_train, validation_data=ds_val, epochs=1, steps_per_epoch=100)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: 4 root error(s) found.
  (0) Invalid argument:   slice index 10 of dimension 0 out of bounds.
         [[node strided_slice (defined at /local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
         [[Identity_4/_188]]
  (1) Invalid argument:   slice index 10 of dimension 0 out of bounds.
         [[node strided_slice (defined at /local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext_2]]
  (2) Cancelled:
  (3) Cancelled:
0 successful operations.
1 derived errors ignored. [Op:__inference_distributed_function_166689]

Function call stack:
distributed_function -> distributed_function -> distributed_function -> distributed_function -> distributed_function ->distributed_function
```

This is why the bug is so spicy: both the static and dynamic shapes are 12, but if you try to access an element under index 3+ (3 = 12 / 4), you crash. I am really interested in why.

If you remove `drop_remainder=True`, the code works."
34038,TF 2.0 distribution strategy throws invalid argument error,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): somewhat
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): DGX
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/z
- TensorFlow installed from (source or binary): docker image
- TensorFlow version (use command below): 2.0
- Python version: 3.6
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version:  10.1
- GPU model and memory:  Telsa V100-SXM2

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
From the [docs](https://www.tensorflow.org/guide/gpu#with_tfdistributestrategy):

```python
tf.debugging.set_log_device_placement(True)

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
  inputs = tf.keras.layers.Input(shape=(1,))
  predictions = tf.keras.layers.Dense(1)(inputs)
  model = tf.keras.models.Model(inputs=inputs, outputs=predictions)
  model.compile(loss='mse',
                optimizer=tf.keras.optimizers.SGD(learning_rate=0.2))

```

I adapted this (I hope correctly for multiple gpus)

```python
gpus = tf.config.experimental.list_physical_devices('GPU')
gpus_to_use = gpus[-3:]

if gpus:
    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
    try:
        tf.config.experimental.set_visible_devices(gpus_to_use, 'GPU')
        for gpu in gpus_to_use:
            tf.config.experimental.set_memory_growth(gpu, True)        
            gb = 1024
            tf.config.experimental.set_virtual_device_configuration(
                gpu,
                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12*gb)]
            )
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
    except RuntimeError as e:
        # Virtual devices must be set before GPUs have been initialized
        print(e)
```
which prints `8 Physical GPUs, 3 Logical GPUs` as expected

Then, calling just this line:
```python
strategy = tf.distribute.MirroredStrategy()
```
throws:
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-18-2f6e99f3473c> in <module>
----> 1 strategy = tf.distribute.MirroredStrategy()

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in __init__(self, devices, cross_device_ops)
    354   def __init__(self, devices=None, cross_device_ops=None):
    355     extended = MirroredExtended(
--> 356         self, devices=devices, cross_device_ops=cross_device_ops)
    357     super(MirroredStrategy, self).__init__(extended)
    358 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in __init__(self, container_strategy, devices, cross_device_ops)
    394                      ""any local devices."")
    395     self._cross_device_ops = cross_device_ops
--> 396     self._initialize_strategy(devices)
    397 
    398     # TODO(b/128995245): Enable last partial batch support in graph mode.

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in _initialize_strategy(self, devices)
    408         ""No duplicates allowed in `devices` argument: %s"" % (devices,))
    409     if _is_device_list_local(devices):
--> 410       self._initialize_local(devices)
    411     else:
    412       self._initialize_multi_worker(devices)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in _initialize_local(self, devices)
    418     self._input_workers = input_lib.InputWorkers(self._device_map)
    419     self._inferred_cross_device_ops = None if self._cross_device_ops else (
--> 420         cross_device_ops_lib.choose_the_best(devices))
    421     self._host_input_device = numpy_dataset.SingleDevice(""/cpu:0"")
    422 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py in choose_the_best(devices, session_config)
   1194   """"""
   1195   requested_devices = set([device_util.canonicalize(d) for d in devices])
-> 1196   machine_devices = device_lib.list_local_devices(session_config=session_config)
   1197   using_devices = set()
   1198   for d in machine_devices:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/device_lib.py in list_local_devices(session_config)
     39   return [
     40       _convert(s)
---> 41       for s in pywrap_tensorflow.list_devices(session_config=session_config)
     42   ]

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py in list_devices(session_config)
   2247     return ListDevicesWithSessionConfig(session_config.SerializeToString())
   2248   else:
-> 2249     return ListDevices()
   2250 
   2251 

InvalidArgumentError: device CUDA:0 not supported by XLA service
	while setting up XLA_GPU_JIT device number 0
```

**Describe the expected behavior**

It just works as in the docs

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
See above. Docker image `tensorflow/tensorflow:2.0.0-gpu-py3-jupyter` with `nvidia-docker`

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34037,Support key mapping in TFRecord,"**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
For multiple features situation like recommendation, names of features will take a lot of spaces in tfrecord files. A simple solution is replacing name by feature's index. Do this compression automatically needs change tfrecord file. Support a user-specific option maybe better.

**Will this change the current api? How?**
Add a key mapping parameter to `tf.data.TFRecordDataset`, `tf.io.TFRecordWriter` and `tf.data.FixedLengthRecordDataset`.

**Who will benefit with this feature?**
Save disk space for industry situations.

**Any Other info.**
"
34036,Please let load_weights load only weights as its name describes,"

**System information**
- TensorFlow version (you are using): 2.0.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current confusing/bad behavior/state.**

Look at the end of [this tutorial](https://www.tensorflow.org/guide/keras/save_and_serialize):

```
# Recreate the model
new_model = get_model()
new_model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=keras.optimizers.RMSprop())

# This initializes the variables used by the optimizers,
# as well as any stateful metric variables
new_model.train_on_batch(x_train[:1], y_train[:1])

# Load the state of the old model
new_model.load_weights('path_to_my_weights')

# Check that the model state has been preserved
new_predictions = new_model.predict(x_test)
np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)

# The optimizer state is preserved as well,
# so you can resume training where you left off
new_first_batch_loss = new_model.train_on_batch(x_train[:64], y_train[:64])
assert first_batch_loss == new_first_batch_loss
```

Look more closely:

```
# Load the state of the old model
new_model.load_weights('path_to_my_weights')
# The optimizer state is preserved as well
```

I'm sorry, but, are you serious? Why on earth do you think it's a good idea to let a **load_weights** function restore anything other than the **WEIGHTS** of the model? Is this deep learning from 3019? Maybe it's a documentation issue?

If you mean to give the users the option to save or load other variables in addition to the model's weights, please create new functions, e.g. **save_variables()** and **load_variables()**.

**Will this change the current api? How?**
Yes, in a good way.

**Who will benefit with this feature?**
Everybody.
"
34035,Issues converting recurrent ML-Agents model to TFLite (Tensorflow 1.15),"Hi

I have been tryingt to convert a frozen graph def created by [ML-Agents](https://github.com/Unity-Technologies/ml-agents) to TFLite. However, there is an input variable to the model, which is defined by:

```
self.sequence_length = tf.placeholder(
            shape=None, dtype=tf.int32, name=""sequence_length""
        )
```

which seems to cause problems in the conversion.

If I convert without passing shapes the following happens:

```
tflite_convert --output_file=model.tflite --graph_def_file=unity/ml-agents/models/ppo-0/RoverLearning/frozen_graph_def.pb --input_arrays=vector_observation,epsilon,recurrent_in,sequence_length --output_arrays=action
```

```
2019-11-05 13:59:21.589574: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-05 13:59:21.602134: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2bf9e7280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-05 13:59:21.602151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""/Users/dwright/anaconda3/envs/mlagents/bin/tflite_convert"", line 8, in <module>
    sys.exit(main())
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 515, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 511, in run_main
    _convert_tf1_model(tflite_flags)
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 199, in _convert_tf1_model
    output_data = converter.convert()
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 898, in convert
    self._set_batch_size(batch_size=1)
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 1032, in _set_batch_size
    shape = tensor.shape.as_list()
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py"", line 1171, in as_list
    raise ValueError(""as_list() is not defined on an unknown TensorShape."")
ValueError: as_list() is not defined on an unknown TensorShape.
```
I added some debut messages to `lite.py` and found that the issue is with the variable `sequence_length`


If I pass the shapes to the command like this: 

```
tflite_convert --output_file=model.tflite --graph_def_file=unity/ml-agents/models/ppo-0/RoverLearning/frozen_graph_def.pb --input_arrays=vector_observation,epsilon,recurrent_in,sequence_length --output_arrays=action --input_shapes=1,7:1,2:7,40:1
```

I get a similar error:

```
2019-11-05 14:25:44.658772: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-05 14:25:44.677569: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee79ed3960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-05 14:25:44.677591: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-05 14:25:44.741840: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-05 14:25:44.741948: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-05 14:25:44.819310: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize
2019-11-05 14:25:44.819337: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 304 nodes (-81), 371 edges (-83), time = 56.212ms.
2019-11-05 14:25:44.819342: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 304 nodes (0), 371 edges (0), time = 8.713ms.
Traceback (most recent call last):
  File ""/Users/dwright/anaconda3/envs/mlagents/bin/tflite_convert"", line 8, in <module>
    sys.exit(main())
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 515, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 511, in run_main
    _convert_tf1_model(tflite_flags)
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 199, in _convert_tf1_model
    output_data = converter.convert()
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 983, in convert
    **converter_kwargs)
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2019-11-05 14:25:46.811578: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.811623: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.811639: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.811649: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.811675: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.811685: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.811695: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.811705: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.811986: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812009: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812022: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812033: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812378: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-05 14:25:46.812411: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-05 14:25:46.812433: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-05 14:25:46.812448: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-05 14:25:46.812468: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812497: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-05 14:25:46.812507: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-05 14:25:46.812525: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812544: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812559: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812567: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-05 14:25:46.812580: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812588: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-05 14:25:46.812613: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2019-11-05 14:25:46.812631: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812640: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-05 14:25:46.812661: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2019-11-05 14:25:46.812680: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812694: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812708: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812724: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-05 14:25:46.812751: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond
2019-11-05 14:25:46.812763: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond
2019-11-05 14:25:46.812864: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2019-11-05 14:25:46.812928: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2019-11-05 14:25:46.812951: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2019-11-05 14:25:46.813037: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2019-11-05 14:25:46.813111: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2019-11-05 14:25:46.813301: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2019-11-05 14:25:46.816417: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 185 operators, 322 arrays (0 quantized)
2019-11-05 14:25:46.818204: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 103 operators, 180 arrays (0 quantized)
2019-11-05 14:25:46.819853: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 103 operators, 180 arrays (0 quantized)
2019-11-05 14:25:46.819987: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1616] Check failed: *packed_shape == shape All input arrays to Pack operators must have the same shape. Input ""sequence_length"" is different.
Fatal Python error: Aborted

Current thread 0x0000000111d5b5c0 (most recent call first):
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52 in execute
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py"", line 250 in _run_main
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py"", line 299 in run
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40 in run
  File ""/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89 in main
  File ""/Users/dwright/anaconda3/envs/mlagents/bin/toco_from_protos"", line 8 in <module>
```

Any help is highly appreciated! "
34034,"TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. ","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary):source
- TensorFlow version (or github SHA if from source):1.15.0


**Provide the text output from tflite_convert**

2019-11-06 14:51:12.818885: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
WARNING:tensorflow:From /home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
2019-11-06 14:51:14.238827: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-06 14:51:14.239039: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-06 14:51:14.342213: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize
2019-11-06 14:51:14.342263: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2019-11-06 14:51:14.342276: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-06 14:51:17.338864: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-11-06 14:51:17.338999: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-06 14:51:17.758703: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize
2019-11-06 14:51:17.758752: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1632 nodes (-1290), 2168 edges (-1454), time = 256.269ms.
2019-11-06 14:51:17.758768: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1632 nodes (0), 2168 edges (0), time = 73.402ms.
Traceback (most recent call last):
  File ""tflite_converter.py"", line 40, in <module>
    tflite_model_quant = converter.convert()
  File ""/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 983, in convert
    **converter_kwargs)
  File ""/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2019-11-06 14:51:20.478994: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479075: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479089: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479101: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479122: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479135: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479196: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.479212: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479236: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.479245: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479256: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479270: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479279: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479287: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479299: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479309: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479320: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2019-11-06 14:51:20.479334: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479345: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond
2019-11-06 14:51:20.479366: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2019-11-06 14:51:20.479425: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2019-11-06 14:51:20.479439: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2019-11-06 14:51:20.479472: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ParseSingleExample
2019-11-06 14:51:20.479499: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2019-11-06 14:51:20.479541: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.479552: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479564: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.479574: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479586: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.479595: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479606: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479622: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479632: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479642: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479654: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479664: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479673: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479685: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479695: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.479707: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2019-11-06 14:51:20.479726: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.479740: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond
2019-11-06 14:51:20.479763: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2019-11-06 14:51:20.479776: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2019-11-06 14:51:20.479804: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2019-11-06 14:51:20.479817: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2019-11-06 14:51:20.479827: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2019-11-06 14:51:20.479846: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2019-11-06 14:51:20.479875: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2019-11-06 14:51:20.479889: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2019-11-06 14:51:20.479917: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2019-11-06 14:51:20.479984: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeRaw
2019-11-06 14:51:20.480005: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2019-11-06 14:51:20.480058: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg
2019-11-06 14:51:20.480074: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2019-11-06 14:51:20.480086: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2019-11-06 14:51:20.480138: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2019-11-06 14:51:20.480161: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg
2019-11-06 14:51:20.480195: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodePng
2019-11-06 14:51:20.480262: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2019-11-06 14:51:20.480284: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeGif
2019-11-06 14:51:20.480303: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeBmp
2019-11-06 14:51:20.480349: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2019-11-06 14:51:20.481401: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481417: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481430: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481441: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481453: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481463: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481473: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481483: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481495: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481504: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481515: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481525: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481536: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481546: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481557: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481566: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481577: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481587: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481598: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2019-11-06 14:51:20.481607: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481618: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481633: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481644: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481653: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2019-11-06 14:51:20.481665: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481675: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481685: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2019-11-06 14:51:20.481696: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481706: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481716: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2019-11-06 14:51:20.481727: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481737: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481746: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481756: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481766: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481777: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481787: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481797: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481808: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481823: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481833: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481844: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481855: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481865: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481877: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481886: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481896: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481907: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481917: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-11-06 14:51:20.481929: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2019-11-06 14:51:20.481943: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481955: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481967: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.481998: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.482011: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond
2019-11-06 14:51:20.482039: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2019-11-06 14:51:20.482053: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2019-11-06 14:51:20.482065: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2019-11-06 14:51:20.482077: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2019-11-06 14:51:20.482089: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2019-11-06 14:51:20.482462: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2019-11-06 14:51:20.482478: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2019-11-06 14:51:20.482490: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2019-11-06 14:51:20.482502: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2019-11-06 14:51:20.482513: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2019-11-06 14:51:20.482524: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2019-11-06 14:51:20.482534: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2019-11-06 14:51:20.482544: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2019-11-06 14:51:20.482555: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2019-11-06 14:51:20.482565: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2019-11-06 14:51:20.482612: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2019-11-06 14:51:20.482629: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2019-11-06 14:51:20.482642: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2019-11-06 14:51:20.482655: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2019-11-06 14:51:20.482667: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2019-11-06 14:51:20.482680: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2019-11-06 14:51:20.482691: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2019-11-06 14:51:20.482749: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV5
2019-11-06 14:51:20.482798: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2019-11-06 14:51:20.482893: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2019-11-06 14:51:20.482945: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2019-11-06 14:51:20.483080: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2019-11-06 14:51:20.483096: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2019-11-06 14:51:20.483113: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2019-11-06 14:51:20.483125: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2019-11-06 14:51:20.509188: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1122 operators, 2035 arrays (0 quantized)
2019-11-06 14:51:20.575870: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1085 operators, 1966 arrays (0 quantized)
2019-11-06 14:51:20.648615: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1085 operators, 1966 arrays (0 quantized)
2019-11-06 14:51:20.729953: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 583 operators, 1191 arrays (0 quantized)
2019-11-06 14:51:20.751767: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 583 operators, 1191 arrays (0 quantized)
2019-11-06 14:51:20.769313: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 583 operators, 1191 arrays (0 quantized)
2019-11-06 14:51:20.801282: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 896 bytes, theoretical optimal value: 896 bytes.
2019-11-06 14:51:20.804680: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 4600257
2019-11-06 14:51:20.806064: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeRaw is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806081: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806102: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806111: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806120: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806131: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806141: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806150: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodePng is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806161: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeGif is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806343: W tensorflow/lite/toco/tflite/operator.cc:2706] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806600: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeRaw is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806614: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806635: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806644: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806653: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806664: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806674: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806684: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodePng is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806696: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeGif is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.806892: W tensorflow/lite/toco/tflite/operator.cc:2706] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-11-06 14:51:20.807143: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGICAL_OR, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TOPK_V2, TRANSPOSE, UNPACK, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.
Traceback (most recent call last):
  File ""/home/mannam-pc/.local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/mannam-pc/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/mannam-pc/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGICAL_OR, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TOPK_V2, TRANSPOSE, UNPACK, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.


Also, please include a link to a GraphDef or the model if possible.

https://drive.google.com/drive/folders/1gamFb0Lr6vJV7wYwHXJIhbFjk-jg_cpj?usp=sharing

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Here is my source code :

https://drive.google.com/open?id=1EbJjiK6EAGqKhzrCXFBTZOuHcR6OiBdQ
"
34033,how to use tensorflow lite gpu delegate in android object detection ? ,"private Interpreter tfLite;
public static Classifier create(
      final AssetManager assetManager,
      final String modelFilename,
      final String labelFilename,
      final int inputSize,
      final boolean isQuantized)
      throws IOException 
{
        -------------------------
      try {
          GpuDelegate delegate = new GpuDelegate();
          Interpreter.Options options = (new Interpreter.Options()).addDelegate(delegate);
          /*d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename));*/
         d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename), options);
        while (true) {
           writeToInput(input);
           d.tfLite.run(input, output);
           readFromOutput(output);
      }
       delegate.close();
       -------------------------
}
   what does it means for input and output ? how to transmit parameter  input and out ? "
34032,build tensorflow com_google_protobuf//:protobuf_lite' failed ,"                                                                     ^
tensorflow/python/framework/python_op_gen_internal.cc:565:48: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < params_with_default.size(); ++i) {
                                                ^
ERROR: /home/lid/.cache/bazel/_bazel_root/61773a13f73ad6653303d056b5da0c0b/external/com_google_protobuf/BUILD:106:1: C++ compilation of rule '@com_google_protobuf//:protobuf_lite' failed (Exit 1): arm-linux-gnueabi-gcc failed: error executing command 
  (cd /home/lid/.cache/bazel/_bazel_root/61773a13f73ad6653303d056b5da0c0b/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PWD=/proc/self/cwd \
  /sources/toolchain/gcc-linaro-4.9.4-2017.01-x86_64_arm-linux-gnueabi/bin/arm-linux-gnueabi-gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -isystem /usr/include -isystem /usr/include/arm-linux-gnueabi -MD -MF bazel-out/armeabi-opt/bin/external/com_google_protobuf/_objs/protobuf_lite/strutil.pic.d '-frandom-seed=bazel-out/armeabi-opt/bin/external/com_google_protobuf/_objs/protobuf_lite/strutil.pic.o' -fPIC -iquote external/com_google_protobuf -iquote bazel-out/armeabi-opt/genfiles/external/com_google_protobuf -iquote bazel-out/armeabi-opt/bin/external/com_google_protobuf -isystem external/com_google_protobuf/src -isystem bazel-out/armeabi-opt/genfiles/external/com_google_protobuf/src -isystem bazel-out/armeabi-opt/bin/external/com_google_protobuf/src '-march=armv7-a' '-mfpu=neon-vfpv4' '-mfloat-abi=hard' -O3 '-std=c++11' '-DS_IREAD=S_IRUSR' '-DS_IWRITE=S_IWUSR' -funsafe-math-optimizations -ftree-vectorize -fomit-frame-pointer -DRASPBERRY_PI -DHAVE_PTHREAD -DHAVE_ZLIB -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -Wno-write-strings -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -no-canonical-prefixes -fno-canonical-system-headers -c external/com_google_protobuf/src/google/protobuf/stubs/strutil.cc -o bazel-out/armeabi-opt/bin/external/com_google_protobuf/_objs/protobuf_lite/strutil.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
In file included from /usr/include/bits/byteswap.h:35:0,
                 from /usr/include/endian.h:60,
                 from /usr/include/bits/waitstatus.h:64,
                 from /usr/include/stdlib.h:42,
                 from external/com_google_protobuf/src/google/protobuf/stubs/strutil.h:36,
                 from external/com_google_protobuf/src/google/protobuf/stubs/strutil.cc:33:
external/com_google_protobuf/src/google/protobuf/stubs/port.h: In function 'int google::protobuf::Base64EscapeInternal(const unsigned char*, int, char*, int, const char*, bool)':
external/com_google_protobuf/src/google/protobuf/stubs/port.h:380:45: error: invalid 'asm': invalid operand for code 'w'
   static uint16 ToHost16(uint16 x) { return bswap_16(x); }
                                             ^
external/com_google_protobuf/src/google/protobuf/stubs/port.h:380:45: error: invalid 'asm': invalid operand for code 'w'
   static uint16 ToHost16(uint16 x) { return bswap_16(x); }
                                             ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1203.894s, Critical Path: 62.17s
INFO: 901 processes: 901 local.
FAILED: Build did NOT complete successfully
lid@lid-VirtualBox:~/cc_work/tensorflow-on-arm-2.0.0/build_tensorflow$ 
"
34031,How to add android_sdk_repository rule into workspace.bzl?,"I build tensorflow without android. Now i want to add android_sdk_repository and android_ndk rule into workspace.bzl so that i can build the apk.

I've tried adding :
android_sdk_repository(
name = ""androidsdk"",
// Set the path to the directory the Android SDK was unzipped into.
path = ""/home/shaurya/Android/Sdk"",
// Set the API level of the installed SDK Platform.
api_level = 28,
// Set the version of the build tools (a directory inside build-tools)
build_tools_version=""28.0.2""
)
into workspace.bzl inside tensorflow but i'm getting this error :name 'android_sdk_repository' is not defined need help."
34030,how to assign a different gpu to each session in a process .,"tensorflow c API：I want to create multiple sessions for different models in a process, how to assign a different gpu to each session.
"
