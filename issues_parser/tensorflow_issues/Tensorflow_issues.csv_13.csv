Issue Number,Issue Title,Issue Body
49806,saved model predict function call leads to OOM,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.4 64-bit
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.0
- Python version: 3.7.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 11.0, cuDNN 8.0.4.30
- GPU model and memory: NVIDIA GeForce GTX 1660 Ti (6 GB)

**Describe the current behavior**
I am trying to load a saved model (h5 file=3.8MB) using the setup described above and then use the model.predict on a numpy array of size `(45000, 32, 32, 3)` and `float32` datatype and I get a OOM memory error. 

I have set the memory growth option:
for gpu in tf.config.experimental.list_physical_devices('GPU'):
    tf.config.experimental.set_memory_growth(gpu, True)

**Describe the expected behavior**
while training the same model with dataset does not cause an error, the predict function. So, I am not sure what is happening. Th

**Standalone code to reproduce the issue**
https://github.com/rajatsaxena/test/blob/main/Similarity-CIFAR10-car.ipynb"
49797,cmake always building debug library,"when i type cmake --build . -j
all compilation is always set to debug mode

even after run release.sh or type cmake -DCMAKE_BUILD_TYPE=Release .
i build it on windows 7

i need solution to set release mode, iam trying to build from visual studio 2017, but compiler error
i was trying to using cmake-gui, but hang

cmake-gui = hang
cmake-cli = success
build using cmake-cli = success
build using visual studio 2017 = fail

question ?
how to compile release mode, what argument need to append to this cmake --build . -j command"
49769,tensorflow lite x64 minimal build,"i do all intruction that described in this link [https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal](url)

i success build tensorflow lite, but its win32

how to change to x64"
49767,BERT model not using GPU for training,"I am following [this tutorial](https://www.tensorflow.org/text/tutorials/classify_text_with_bert) to use BERT for an NLP competition on Kaggle. 

I have created the model based on the tutorial but using the Kaggle data for training. But when I try to train with GPU enabled it still uses CPU only. I tried running my code and Colab with GPU enabled and there also the GPU is not being used, so it's not a Kaggle specific issue.

So far I have tried the small models [2/128](https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2) and [8/512](https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8) and both are using CPU only while the GPU sits on 0% utilization and 2MB memory use.

The TF version is 2.5.0 which gives this warning when importing the libraries:

```
/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.5.0 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  UserWarning,
```
But downgrading TF gives other errors that I am not able to resolve so I haven't tried running on older versions yet.
Any help is appreciated, thanks in advance."
49766,The finish project is crashing in the device.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No , the finish project only.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Realme 7
- TensorFlow installed from (source or binary): Used google colab
- TensorFlow version (use command below): 2.5.0
- Python version: 3.7.10 (Used google colab )
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Colab free GPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The ""finish"" app given in ""Build a handwritten digit classifier app with TensorFlow Lite "" tutorial is crashing everytime in the device.
I am facing the problem from trying to build the ""finish"" app from this :
https://developer.android.com/codelabs/digit-classifier-tflite?authuser=1#2

And then trying to build project from the folder below :
lite/codelabs/digit_classifier/android/finish/

Android Studio Version :
4.2.1

**Describe the expected behavior**
The app ""finish"" should recognize text digits.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.



I am using the device realme RMX2151 ,it is built fine but while opening the app it is directly crashing. Can anyone suggest any fix to it or anyone found this issue earlier ??"
49761,Keras spectral normalization (SN) function has stopped working,"Something must have happened to Keras overnight because suddenly two Keras features have stopped working. I already reported the ```from keras.utils import plot_model```  bug. Now there's another. ```spectral_normalization.py``` is a function that takes a keras layer as input and implements the SN regularization algorithm. Since this morning it throws an ```AssertionError```.
```
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py(50)__init__()
     48 
     49   def __init__(self, layer, **kwargs):
---> 50     assert isinstance(layer, Layer)
     51     self.layer = layer
     52     super(Wrapper, self).__init__(**kwargs)
```
Of course, I can just not use spectral normalization, but it makes a HUGE difference in model stability. Thanks."
49754,"Cloning a model with the ""Add"" layer - Custom mask layers require a config and must override get_config","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04.5 TLS (Google Colab)
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.5.0

**Description**

If the model with the ""Add"" layer is a part of another model, then when I try to clone it, the following warning appears:

```
CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
```

This warning appeared only in version 2.5.0

**Code**

```
import tensorflow as tf
from tensorflow.keras.layers import Input, Add
from tensorflow.keras.models import Model

input1 = Input(1)
input2 = Input(1)
x = Add()([input1, input2])
model_a = Model([input1, input2], x)

input3 = Input(1)
input4 = Input(1)
x = model_a([input3, input4])
model_b = Model([input3, input4], x)

model_b_clone = tf.keras.models.clone_model(model_b)
```

**Output**

```
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  category=CustomMaskWarning)
```


"
49740,precompile model executable binaries,"Hello,

I'd like to ask you if there is the possibility to have aka ML compiler and execution engine for ARM MCUs (Cortex-M). Is it somehow possible to use for this TF-micro? Is there another way to prepare executable ML code (model) for Cortex-M devices with TensorFlow? As of now, I can get with TF-Lite-Micro as close as possible to MCU ARM Cortex-M class devices and leverage CMSIS-NN optimized kernels for this."
49738,No description about forcing zero output for mask in Bidirectional,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional

## Description of issue (what needs changing):

### Clear description

```python
import tensorflow as tf

lstm = tf.keras.layers.LSTM(4, return_sequences=True)
bi = tf.keras.layers.Bidirectional(lstm)

x = tf.random.normal([1,4,16])
mask = tf.constant([[True, True, True, False]])

print(lstm(x, mask=mask))
print(bi(x, mask=mask))
```

```
tf.Tensor(
[[[ 0.01245601  0.38689056  0.01844893 -0.0718843 ]
  [ 0.14610071  0.23905458  0.39626616 -0.17714866]
  [-0.00543382 -0.06880241  0.04203304 -0.08996341]
  [-0.00543382 -0.06880241  0.04203304 -0.08996341]]], shape=(1, 4, 4), dtype=float32)
tf.Tensor(
[[[-0.24271122  0.05120631 -0.06832076 -0.5101022   0.3812662
    0.44380718 -0.07919203  0.07195219]
  [-0.16884208  0.18173794 -0.0029141  -0.13847476  0.08567893
    0.2971174   0.15979137  0.01258926]
  [-0.11614764  0.17977336 -0.20486659 -0.0677676   0.40112934
    0.27802816 -0.20526664  0.1625048 ]
  [ 0.          0.          0.          0.          0.
    0.          0.          0.        ]]], shape=(1, 4, 8), dtype=float32)
```

https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/python/keras/layers/wrappers.py#L492-L498
When we use `tf.keras.layers.Bidirectional` with `return_sequences=True`, The output for masked sequences become zero because **force_zero_output_for_mask** internally. However, there is no description that the masked timestep should be zero with `return_sequences=True` in Bidirectional layer documentation.
Without `Bidirectional`, `zero_output_for_mask` is false by default. Many of people hardly expect the output of masked timestep is zero. So I think this is very confused and easy to misunderstand.

I think the fact that it forces zero oputput for mask internally should be added to the Bidirectional document.

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style

Yes I may be able to add document about this."
49737,TimeseriesGenerator with multi-step outputs native support,"**System information**
- TensorFlow version: 2.5.0
- Are you willing to contribute it: No (sorry)

**Describe the feature and the current behavior/state.**

The feature is a new parameter in the TimeseriesGenerator API, which allows multi-step outputs. So, like the `length` parameter, perhaps a new `output_length` can refer to the length of the outputs (targets).

I know that it is possible to prepare the target sequence to have multiple steps, but it is not a friendly process for everyone. In addition, there is the repository [time_series_generator](https://github.com/krypton-unite/time_series_generator) that implements this functionality separately from TF.

**Will this change the current api? How?**

Yes. Adding a new parameter in TimeseriesGenerator API.

**Who will benefit with this feature?**

Everyone who handles time series and need multi-step outputs out of the box."
49734,can't import plot_model from keras.utils,"When I run this line of code on google colab (with or without the GPU),

```from keras.utils import plot_model```

I get the following error:

""cannot import name 'plot_model' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)""

When I went to bed last night the code worked. This morning it doesn't. What happened and what can I do? Thanks in advance.

"
49733,Magic_wand example on Arduino Nano 33: 'class LSM9DS1Class' has no member named 'setContinuousMode' ,"@tensorflow/micro

**System information**
Windows 10
Arduino 1.8.12 IDE
Arduino Nano 33 BLE Sense

**Describe the problem**
When trying Magic_wand example from https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/magic_wand 
during compilation, the IDE reports the following error:

```
arduino_accelerometer_handler.cpp:50:7: error: 'class LSM9DS1Class' has no member named 'setContinuousMode'
   IMU.setContinuousMode();
```

**Please provide the exact sequence of commands/steps when you ran into the problem**
I have followed the steps in the documentation to fix v1.0.0 of the driver. LSM9DS1.cpp looks as follows:

```
int LSM9DS1Class::begin()
{
  _wire->begin();

  // reset
  writeRegister(LSM9DS1_ADDRESS, LSM9DS1_CTRL_REG8, 0x05);
  writeRegister(LSM9DS1_ADDRESS_M, LSM9DS1_CTRL_REG2_M, 0x0c);

  delay(10);

  if (readRegister(LSM9DS1_ADDRESS, LSM9DS1_WHO_AM_I) != 0x68) {
    end();

    return 0;
  }

  if (readRegister(LSM9DS1_ADDRESS_M, LSM9DS1_WHO_AM_I) != 0x3d) {
    end();

    return 0;
  }

  writeRegister(LSM9DS1_ADDRESS, LSM9DS1_CTRL_REG1_G, 0x78); // 119 Hz, 2000 dps, 16 Hz BW
  writeRegister(LSM9DS1_ADDRESS, LSM9DS1_CTRL_REG6_XL, 0x70); // 119 Hz, 4G

  writeRegister(LSM9DS1_ADDRESS_M, LSM9DS1_CTRL_REG1_M, 0xb4); // Temperature compensation enable, medium performance, 20 Hz
  writeRegister(LSM9DS1_ADDRESS_M, LSM9DS1_CTRL_REG2_M, 0x00); // 4 Gauss
  writeRegister(LSM9DS1_ADDRESS_M, LSM9DS1_CTRL_REG3_M, 0x00); // Continuous conversion mode

  // Enable FIFO (see docs https://www.st.com/resource/en/datasheet/DM00103319.pdf)
  writeRegister(LSM9DS1_ADDRESS, 0x23, 0x02);
  // Set continuous mode
  writeRegister(LSM9DS1_ADDRESS, 0x2E, 0xC0);
  
  return 1;
}
```

and 

```
int LSM9DS1Class::accelerationAvailable()
{
  //if (readRegister(LSM9DS1_ADDRESS, LSM9DS1_STATUS_REG) & 0x01) {
  //  return 1;
  //}
  // Read FIFO_SRC. If any of the rightmost 8 bits have a value, there is data
  if (readRegister(LSM9DS1_ADDRESS, 0x2F) & 63) {
    return 1;
  }
  return 0;
}
```

I also tried to use v1.1.0. In that case, no error during compilation and upload, but the Arduino Nano does not seem to run the code properly (no flashing LED, no serial port output). 

I have tried both approaches (v.1.0.0 modified, and v.1.1.0 unmodified) several times, including multiple resets and long waits of the Arduino Nano after upload. "
49732,Can't convert saved model to TFLite format,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- TensorFlow installation (pip package or built from source): pip 
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0

### 2. Code

I am trying to convert my saved model to TFlite format
```

loaded_model = tf.keras.models.load_model(model_path)
# loaded_model.summary()

converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)
litemodel = converter.convert()
with open('model.tflite', 'wb') as f:
    f.write(litemodel)
```

Output error:
```
WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named ""keras_metadata.pb"" in the SavedModel directory.
WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named ""keras_metadata.pb"" in the SavedModel directory.
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:1061: UserWarning: mrcnn.fpn is not loaded, but a Lambda layer uses it. It may cause errors.
  , UserWarning)
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:1061: UserWarning: mrcnn.inference is not loaded, but a Lambda layer uses it. It may cause errors.
  , UserWarning)
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:1061: UserWarning: mrcnn.rpn is not loaded, but a Lambda layer uses it. It may cause errors.
  , UserWarning)
WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.
WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  category=CustomMaskWarning)
INFO:tensorflow:Assets written to: /tmp/tmpw8wqnnco/assets
INFO:tensorflow:Assets written to: /tmp/tmpw8wqnnco/assets
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    293                                                  debug_info_str,
--> 294                                                  enable_mlir_converter)
    295       return model_str

5 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
     37       debug_info_str,
---> 38       enable_mlir_converter)
     39 

Exception: /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/load.py:152:0: error: 'tf.TensorListReserve' op requires element_shape to be 1D tensor during TF Lite transformation pass
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py:206:0: note: called from
<ipython-input-12-cead14d55f93>:2:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py:537:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:208:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py:399:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py:233:0: note: called from
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/load.py:152:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py:206:0: note: called from
<ipython-input-12-cead14d55f93>:2:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py:537:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:208:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py:399:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py:233:0: note: called from


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
<ipython-input-12-cead14d55f93> in <module>()
      4 
      5 converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)
----> 6 litemodel = converter.convert()
      7 with open(r'/content/drive/MyDrive/Model (Segmentation TFlite)/segmentation_model.tflite', 'wb') as f:
      8     f.write(litemodel)

/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py in convert(self)
   1056 
   1057     result = super(TFLiteKerasModelConverterV2,
-> 1058                    self).convert(graph_def, input_tensors, output_tensors)
   1059     self._increase_conversion_success_metric(result)
   1060     return result

/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py in convert(self, graph_def, input_tensors, output_tensors)
    784         input_tensors=input_tensors,
    785         output_tensors=output_tensors,
--> 786         **converter_kwargs)
    787 
    788     if self.experimental_new_quantizer:

/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    701       input_data.SerializeToString(),
    702       debug_info_str=debug_info_str,
--> 703       enable_mlir_converter=enable_mlir_converter)
    704   return data
    705 

/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    295       return model_str
    296     except Exception as e:
--> 297       raise ConverterError(str(e))
    298 
    299   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/load.py:152:0: error: 'tf.TensorListReserve' op requires element_shape to be 1D tensor during TF Lite transformation pass
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py:206:0: note: called from
<ipython-input-12-cead14d55f93>:2:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py:537:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:208:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py:399:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py:233:0: note: called from
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/load.py:152:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py:206:0: note: called from
<ipython-input-12-cead14d55f93>:2:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from
/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py:537:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py:208:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py:399:0: note: called from
/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py:233:0: note: called from
```

I have also tried directly using the `tf.lite.TFLiteConverter.from_saved_model` to convert, but getting a different error with that:
```
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    293                                                  debug_info_str,
--> 294                                                  enable_mlir_converter)
    295       return model_str

4 frames
Exception: <unknown>:0: error: loc(callsite(callsite(""mask_rcnn/mrcnn_detection/map/TensorArrayV2_1@__inference__wrapped_model_8467"" at ""StatefulPartitionedCall@__inference_signature_wrapper_26893"") at ""StatefulPartitionedCall"")): 'tf.TensorListReserve' op requires element_shape to be 1D tensor during TF Lite transformation pass
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""mask_rcnn/mrcnn_detection/map/TensorArrayV2_1@__inference__wrapped_model_8467"" at ""StatefulPartitionedCall@__inference_signature_wrapper_26893"") at ""StatefulPartitionedCall"")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    295       return model_str
    296     except Exception as e:
--> 297       raise ConverterError(str(e))
    298 
    299   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: <unknown>:0: error: loc(callsite(callsite(""mask_rcnn/mrcnn_detection/map/TensorArrayV2_1@__inference__wrapped_model_8467"" at ""StatefulPartitionedCall@__inference_signature_wrapper_26893"") at ""StatefulPartitionedCall"")): 'tf.TensorListReserve' op requires element_shape to be 1D tensor during TF Lite transformation pass
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""mask_rcnn/mrcnn_detection/map/TensorArrayV2_1@__inference__wrapped_model_8467"" at ""StatefulPartitionedCall@__inference_signature_wrapper_26893"") at ""StatefulPartitionedCall"")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
```

The saved model is a simple MaskRCNN model. 
I have tried this on a WSL Ubuntu 18.04 Shell as well as Google Colab, but not able to work out the error.
Sorry, if I am missing something trivial in this the conversion. 
"
49730,Model.fit stuck if uses MirroredStrategy with 10 GPUs,"**System information**
- Have I written custom code: No
- OS Platform and Distribution:: Linux Ubuntu 16.04
- TensorFlow installed from: pip
- TensorFlow version: 2.4.1
- Python version: 3.8.7
- CUDA/cuDNN version: 11.0.228 / 8.0.4
- GPU model and memory: GTX 1080Ti 11GB

**Describe the current behavior**
I've a machine with 10x GPU and I'm trying to use all the power using MirroredStrategy. When I run model.fit the program stucks or is really slow. If I use only first gpu (GPU:0) the learning process is fast as expected. I use a generator that read samples from a HDF5 file format. The process with 1 GPU takes 80s for first epoch and than 20s for the others. When using MirroredStrategy the process stucks or takes 2/3 mins to run.

**Describe the expected behavior**
At least the same time as if running with only 1 GPU

**Standalone code to reproduce the issue**
You can use variable `use_strategy ` to enable or not MirroredStrategy.
```
import random

from tensorflow import keras
import tensorflow as tf
import numpy as np

use_strategy = True
class Generator(tf.keras.utils.Sequence):
    def __init__(self):
        print(""GENERATED"")
        self.samples = np.random.rand(100000, 5, 20)
        self.labels = np.random.randint(2, size=(100000, 1))
        self.indices = list(range(0, 100000))
        random.Random().shuffle(self.indices)

    def __len__(self):
        return 100000

    def __getitem__(self, idx):
        return self.samples[self.indices[idx]], self.labels[self.indices[idx]]

physical_devices = tf.config.list_physical_devices('GPU')
for device in physical_devices:
    tf.config.experimental.set_memory_growth(device, True)

if use_strategy:
    strategy = tf.distribute.MirroredStrategy()
    num_gpu = strategy.num_replicas_in_sync
else:
    num_gpu = 1
    
d = tf.data.Dataset.from_generator(Generator,
                                   output_signature=(tf.TensorSpec(shape=(5, 20)), tf.TensorSpec(shape=(1,))))
d = d.batch(32*num_gpu).prefetch(tf.data.AUTOTUNE).cache()

if use_strategy:
    options = tf.data.Options()
    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
    d = d.with_options(options)

    with strategy.scope():
        model = keras.models.Sequential()
        model.add(keras.layers.Conv1D(32, kernel_size=1, strides=1, activation=""relu"", padding=""same"", input_shape=(5, 20)))
        model.add(keras.layers.MaxPooling1D(pool_size=3, padding=""same""))
        model.add(keras.layers.Conv1D(64, kernel_size=1, strides=1, activation=""relu"", padding=""same"", input_shape=(5, 20)))
        model.add(keras.layers.MaxPooling1D(pool_size=3, padding=""same""))
        model.add(keras.layers.Flatten())
        model.add(keras.layers.Dense(1024, activation=""relu""))
        model.add(keras.layers.Dense(1, activation=""softmax""))
        model.compile(
            optimizer=keras.optimizers.Adam(0.003),
            loss=""categorical_crossentropy"",
            metrics=[""accuracy""],
        )
else:
    model = keras.models.Sequential()
    model.add(keras.layers.Conv1D(32, kernel_size=1, strides=1, activation=""relu"", padding=""same"", input_shape=(5, 20)))
    model.add(keras.layers.MaxPooling1D(pool_size=3, padding=""same""))
    model.add(keras.layers.Conv1D(64, kernel_size=1, strides=1, activation=""relu"", padding=""same"", input_shape=(5, 20)))
    model.add(keras.layers.MaxPooling1D(pool_size=3, padding=""same""))
    model.add(keras.layers.Flatten())
    model.add(keras.layers.Dense(1024, activation=""relu""))
    model.add(keras.layers.Dense(1, activation=""softmax""))
    model.compile(
        optimizer=keras.optimizers.Adam(0.003),
        loss=""categorical_crossentropy"",
        metrics=[""accuracy""],
    )

model.fit(d, epochs=5)
```

**Other info / logs** 
This is an output with `use_strategy = False`
```
2021-05-26 11:50:33.912438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 11:50:35.657549: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-26 11:50:35.658587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-05-26 11:50:41.023529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.024948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.026395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties:
pciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.027791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties:
pciBusID: 0000:07:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.029170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties:
pciBusID: 0000:08:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.030585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties:
pciBusID: 0000:0b:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.031954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties:
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.033335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties:
pciBusID: 0000:0d:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.034735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 8 with properties:
pciBusID: 0000:0e:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.036114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 9 with properties:
pciBusID: 0000:0f:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:41.036139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 11:50:41.038966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-26 11:50:41.039009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-26 11:50:41.040262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-26 11:50:41.040558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-26 11:50:41.044146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-26 11:50:41.044346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-26 11:50:41.076938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
2021-05-26 11:50:41.082129: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-26 11:50:41.086016: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-26 11:50:43.498811: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 0 and 9, status: Internal: failed to enable peer access from 0x618ae70 to 0x9163340: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.518689: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 1 and 9, status: Internal: failed to enable peer access from 0x6750470 to 0x9163340: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.536020: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 2 and 9, status: Internal: failed to enable peer access from 0x6c72680 to 0x9163340: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.547585: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 3 and 9, status: Internal: failed to enable peer access from 0x719d4c0 to 0x9163340: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.560961: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 4 and 9, status: Internal: failed to enable peer access from 0x76d1cf0 to 0x9163340: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.567989: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 5 and 9, status: Internal: failed to enable peer access from 0x7c0ebb0 to 0x9163340: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.572534: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 6 and 9, status: Internal: failed to enable peer access from 0x8154b50 to 0x9163340: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.576183: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 7 and 9, status: Internal: failed to enable peer access from 0x86a3c50 to 0x9163340: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.576448: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 8 and 9, status: Internal: failed to enable peer access from 0x8bfd120 to 0x9163340: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.576651: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 0, status: Internal: failed to enable peer access from 0x9163340 to 0x618ae70: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.576844: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 1, status: Internal: failed to enable peer access from 0x9163340 to 0x6750470: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.577034: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 2, status: Internal: failed to enable peer access from 0x9163340 to 0x6c72680: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.577243: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 3, status: Internal: failed to enable peer access from 0x9163340 to 0x719d4c0: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.577432: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 4, status: Internal: failed to enable peer access from 0x9163340 to 0x76d1cf0: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.577612: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 5, status: Internal: failed to enable peer access from 0x9163340 to 0x7c0ebb0: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.577789: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 6, status: Internal: failed to enable peer access from 0x9163340 to 0x8154b50: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.577966: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 7, status: Internal: failed to enable peer access from 0x9163340 to 0x86a3c50: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.578144: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 8, status: Internal: failed to enable peer access from 0x9163340 to 0x8bfd120: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 11:50:43.581287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.583663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.585870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties:
pciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.590771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties:
pciBusID: 0000:07:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.592978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties:
pciBusID: 0000:08:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.597939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties:
pciBusID: 0000:0b:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.600146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties:
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.602322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties:
pciBusID: 0000:0d:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.604462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 8 with properties:
pciBusID: 0000:0e:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.607100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 9 with properties:
pciBusID: 0000:0f:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 11:50:43.607193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 11:50:43.607356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-26 11:50:43.607421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-26 11:50:43.607482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-26 11:50:43.607540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-26 11:50:43.607596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-26 11:50:43.607656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-26 11:50:43.607718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-26 11:50:43.664208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
2021-05-26 11:50:43.664293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 11:50:48.133740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-26 11:50:48.133793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 4 5 6 7 8 9
2021-05-26 11:50:48.133804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y Y Y Y Y Y Y
2021-05-26 11:50:48.133810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y Y Y Y Y Y Y
2021-05-26 11:50:48.133815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y Y Y Y Y Y Y
2021-05-26 11:50:48.133823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N Y Y Y Y Y Y
2021-05-26 11:50:48.133845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 4:   Y Y Y Y N Y Y Y Y Y
2021-05-26 11:50:48.133868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 5:   Y Y Y Y Y N Y Y Y Y
2021-05-26 11:50:48.133878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 6:   Y Y Y Y Y Y N Y Y Y
2021-05-26 11:50:48.133885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 7:   Y Y Y Y Y Y Y N Y Y
2021-05-26 11:50:48.133893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 8:   Y Y Y Y Y Y Y Y N Y
2021-05-26 11:50:48.133900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 9:   Y Y Y Y Y Y Y Y Y N
2021-05-26 11:50:48.152300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10271 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
2021-05-26 11:50:48.161298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10271 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)
2021-05-26 11:50:48.169676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10271 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)
2021-05-26 11:50:48.175658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10271 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)
2021-05-26 11:50:48.183729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10271 MB memory) -> physical GPU (device: 4, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)
2021-05-26 11:50:48.192600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 10271 MB memory) -> physical GPU (device: 5, name: GeForce GTX 1080 Ti, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2021-05-26 11:50:48.201611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 10271 MB memory) -> physical GPU (device: 6, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)
2021-05-26 11:50:48.211137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 10271 MB memory) -> physical GPU (device: 7, name: GeForce GTX 1080 Ti, pci bus id: 0000:0d:00.0, compute capability: 6.1)
2021-05-26 11:50:48.217026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:8 with 10271 MB memory) -> physical GPU (device: 8, name: GeForce GTX 1080 Ti, pci bus id: 0000:0e:00.0, compute capability: 6.1)
2021-05-26 11:50:48.229431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:9 with 10271 MB memory) -> physical GPU (device: 9, name: GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0, compute capability: 6.1)
2021-05-26 11:50:48.446515: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-26 11:50:48.447341: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz
Epoch 1/5
2021-05-26 11:50:49.157305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
GENERATED
2021-05-26 11:50:49.610821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-26 11:50:49.614300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
3125/3125 [==============================] - 35s 10ms/step - loss: 0.0000e+00 - accuracy: 0.4967
Epoch 2/5
3125/3125 [==============================] - 13s 4ms/step - loss: 0.0000e+00 - accuracy: 0.4967
Epoch 3/5
3125/3125 [==============================] - 13s 4ms/step - loss: 0.0000e+00 - accuracy: 0.4967
Epoch 4/5
3125/3125 [==============================] - 13s 4ms/step - loss: 0.0000e+00 - accuracy: 0.4967
Epoch 5/5
3125/3125 [==============================] - 13s 4ms/step - loss: 0.0000e+00 - accuracy: 0.4967
```

This is an output with `use_strategy = True`
```
2021-05-26 12:00:10.570133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 12:00:12.355013: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-26 12:00:12.356136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-05-26 12:00:17.816965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.818449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.819861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties:
pciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.821265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties:
pciBusID: 0000:07:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.822701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties:
pciBusID: 0000:08:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.824115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties:
pciBusID: 0000:0b:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.825524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties:
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.826935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties:
pciBusID: 0000:0d:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.828344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 8 with properties:
pciBusID: 0000:0e:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.829788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 9 with properties:
pciBusID: 0000:0f:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:17.829811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 12:00:17.832797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-26 12:00:17.832845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-26 12:00:17.834196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-26 12:00:17.837631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-26 12:00:17.838391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-26 12:00:17.838609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-26 12:00:17.864974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
2021-05-26 12:00:17.867972: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-26 12:00:17.872954: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-26 12:00:19.976176: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 0 and 9, status: Internal: failed to enable peer access from 0x68a9e70 to 0x9882170: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:19.993878: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 1 and 9, status: Internal: failed to enable peer access from 0x6e6f490 to 0x9882170: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.009534: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 2 and 9, status: Internal: failed to enable peer access from 0x7391670 to 0x9882170: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.022940: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 3 and 9, status: Internal: failed to enable peer access from 0x78bc490 to 0x9882170: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.035994: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 4 and 9, status: Internal: failed to enable peer access from 0x7df0c90 to 0x9882170: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.042246: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 5 and 9, status: Internal: failed to enable peer access from 0x832db50 to 0x9882170: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.049801: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 6 and 9, status: Internal: failed to enable peer access from 0x8873ab0 to 0x9882170: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.052185: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 7 and 9, status: Internal: failed to enable peer access from 0x8dc2bc0 to 0x9882170: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.052495: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 8 and 9, status: Internal: failed to enable peer access from 0x931c060 to 0x9882170: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.055092: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 0, status: Internal: failed to enable peer access from 0x9882170 to 0x68a9e70: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.055349: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 1, status: Internal: failed to enable peer access from 0x9882170 to 0x6e6f490: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.055538: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 2, status: Internal: failed to enable peer access from 0x9882170 to 0x7391670: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.055722: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 3, status: Internal: failed to enable peer access from 0x9882170 to 0x78bc490: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.055902: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 4, status: Internal: failed to enable peer access from 0x9882170 to 0x7df0c90: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.056074: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 5, status: Internal: failed to enable peer access from 0x9882170 to 0x832db50: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.056246: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 6, status: Internal: failed to enable peer access from 0x9882170 to 0x8873ab0: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.056420: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 7, status: Internal: failed to enable peer access from 0x9882170 to 0x8dc2bc0: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.056593: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1677] Unable to enable peer access between device ordinals 9 and 8, status: Internal: failed to enable peer access from 0x9882170 to 0x931c060: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2021-05-26 12:00:20.059009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.061213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.063382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties:
pciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.065544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties:
pciBusID: 0000:07:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.070266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties:
pciBusID: 0000:08:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.074928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties:
pciBusID: 0000:0b:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.077085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties:
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.079152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties:
pciBusID: 0000:0d:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.081209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 8 with properties:
pciBusID: 0000:0e:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.083240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 9 with properties:
pciBusID: 0000:0f:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-05-26 12:00:20.083289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 12:00:20.083342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-26 12:00:20.083378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-26 12:00:20.083402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-26 12:00:20.083426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-26 12:00:20.083451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-26 12:00:20.083475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-26 12:00:20.083500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-26 12:00:20.129612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
2021-05-26 12:00:20.129683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 12:00:24.578650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-26 12:00:24.578701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 4 5 6 7 8 9
2021-05-26 12:00:24.578718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y Y Y Y Y Y Y
2021-05-26 12:00:24.578725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y Y Y Y Y Y Y
2021-05-26 12:00:24.578737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y Y Y Y Y Y Y
2021-05-26 12:00:24.578779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N Y Y Y Y Y Y
2021-05-26 12:00:24.578791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 4:   Y Y Y Y N Y Y Y Y Y
2021-05-26 12:00:24.578802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 5:   Y Y Y Y Y N Y Y Y Y
2021-05-26 12:00:24.578812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 6:   Y Y Y Y Y Y N Y Y Y
2021-05-26 12:00:24.578822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 7:   Y Y Y Y Y Y Y N Y Y
2021-05-26 12:00:24.578832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 8:   Y Y Y Y Y Y Y Y N Y
2021-05-26 12:00:24.578839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 9:   Y Y Y Y Y Y Y Y Y N
2021-05-26 12:00:24.594625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10271 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
2021-05-26 12:00:24.600899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10271 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)
2021-05-26 12:00:24.607133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10271 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)
2021-05-26 12:00:24.613263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10271 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)
2021-05-26 12:00:24.619044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10271 MB memory) -> physical GPU (device: 4, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)
2021-05-26 12:00:24.625345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 10271 MB memory) -> physical GPU (device: 5, name: GeForce GTX 1080 Ti, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2021-05-26 12:00:24.631179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 10271 MB memory) -> physical GPU (device: 6, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)
2021-05-26 12:00:24.636911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 10271 MB memory) -> physical GPU (device: 7, name: GeForce GTX 1080 Ti, pci bus id: 0000:0d:00.0, compute capability: 6.1)
2021-05-26 12:00:24.643134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:8 with 10271 MB memory) -> physical GPU (device: 8, name: GeForce GTX 1080 Ti, pci bus id: 0000:0e:00.0, compute capability: 6.1)
2021-05-26 12:00:24.649300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:9 with 10271 MB memory) -> physical GPU (device: 9, name: GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0, compute capability: 6.1)
2021-05-26 12:00:25.017011: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-26 12:00:25.018083: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz
Epoch 1/5
2021-05-26 12:00:38.830859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-26 12:00:39.152138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
GENERATED
2021-05-26 12:00:41.550966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8

<-- STUCKED HERE 
```"
49729,Error run tf-mlir-translate,"when i run bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate  --graphdef-to-mlir hand_detect_global.pb -o /tmp/mlir_hand_detect.mlir                    

it says 
2021-05-26 17:00:11.917161: E tensorflow/core/framework/op_kernel.cc:1693] OpKernel ('op: ""Fact"" device_type: ""CPU"" label: ""sergey""') for unknown op: Fact
2021-05-26 17:00:11.917564: E tensorflow/core/framework/op_kernel.cc:1693] OpKernel ('op: ""Fact"" device_type: ""CPU"" label: ""Sergey""') for unknown op: Fact
2021-05-26 17:00:11.917573: E tensorflow/core/framework/op_kernel.cc:1693] OpKernel ('op: ""Fact"" device_type: ""GPU"" host_memory_arg: ""fact""') for unknown op: Fact

but , i print the op in the pb, can't find Fact op, so i dont know why give me this error"
49728,Error on Google Colab but not on local machine,"9 hours ago I ran some code on Google Colab which ran totally fine, this morning I get the following error trying to run the exact same code:

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-6-4472585283ee> in <module>()
     11 #Model on top
     12 x = base_model.output
---> 13 x = Flatten()(x)
     14 x = Dense(128, activation='relu')(x)
     15 x = Dropout(0.5)(x)

5 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
     96       dtype = dtypes.as_dtype(dtype).as_datatype_enum
     97   ctx.ensure_initialized()
---> 98   return ops.EagerTensor(value, ctx.device_name, dtype)
     99 
    100 

ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.
```


The exact same code runs totally fine on local runtime"
49727,Performance of using dicts in tf.data.Dataset.from_generator,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 21.04, Colab
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.1 and 2.5.0
- Python version: 3.7

Using dicts as input structure for a `tf.data.Dataset.from_generator` is significantly (>40%) slower than using tuples. Wrapping the nested dict structure in `tf.nest.flatten` and `tf.nest.pack_sequence_as` is only a bit (<10%) slower than using plain tuples.

Maybe consider to ""speed-up"" the use of nested structures such as dicts, e.g. by internally flatten and ""unflatten"" the input.

See the attached colab code. I included some additional benchmark results on my machines.

https://colab.research.google.com/drive/12pGU80HJXFSh7lqhdsWaTyeeHyWwovPe?usp=sharing
"
49726,ParameterServerStrategy worker removing code change,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): No 


Hi, I'm working on dynamic worker adding and removing for ParameterServerStrategy. I noticed that one change in Worker class is necessary to remove worker while training. 
The change is here:
`cluster_coordinator.py`   
```python
class Worker:
  [...]
  def _process_queue(self):
    """"""Function running in a worker thread to process closure queues.""""""
    self._maybe_delay()
    while self._should_worker_thread_run:
      closure = self._cluster._closure_queue.get()  # pylint: disable=protected-access
      if not self._should_worker_thread_run:
        closure.mark_cancelled()
        return
      if closure is None:
        return
      self._process_closure(closure)
      # To properly stop the worker and preemption threads, it is important that
      # `ClusterCoordinator` object is not held onto so its `__del__` can be
      # called. By removing the reference to the `closure` that has already been
      # processed, we ensure that the `closure` object is released, while
      # getting the next `closure` at above `self._cluster._closure_queue.get()`
      # call.
      del closure
  [...]
```

Could someone commit it? I'm not familiar with tensorflow contribute requirements, so I think somebody else could do this faster. Thanks in advance."
49725,Dtype error when using Mixed Precision and building EfficientNetB0 Model,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- TensorFlow installed from (source or binary): Colab
- TensorFlow version (use command below): 2.5.0
- Python version: python 3.7
- GPU model and memory: Tesla T4

**Error**
`TypeError: Input 'y' of 'Sub' Op has type float16 that does not match type float32 of argument 'x'`

**Current behaviour**

While using Mixed Precision and building a Keras Functional API model (EfficientNet B0), it shows the below error

<img width=""935"" alt=""image"" src=""https://user-images.githubusercontent.com/57211163/119546314-6669c180-bdb1-11eb-918f-3cb13d225759.png"">
<img width=""1248"" alt=""image"" src=""https://user-images.githubusercontent.com/57211163/119546338-6c5fa280-bdb1-11eb-844d-91175160e6e5.png"">

**Describe the expected behaviour**
The Global Policy I set in the previous cell was `mixed_float16`. The problem works fine when running on `tensorflow 2.4.1` so the bug is with `tensorflow 2.5.0`


You can reproduce the same error using the below notebook :
https://colab.research.google.com/drive/1TfNZSIJ_I7IZI35RsGFnTdj-6beMHV2_?usp=sharing
"
49724,Wrong warning message for tf.data.experimental.enable.debug_mode(),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 pro 64 bit 21H1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.3 update 1, 8.2.0
- GPU model and memory: RTX 2060 super 8GB

**Describe the current behavior**
When trying to access tensor.numpy inside a tf.data function, Tensorflow reports tensor object has no numpy attribute. A warning message is given: 
C:\Program Files\Python38\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.
However, this warning message is wrong. The ""tf.data.experimental.enable.debug_mode()"" does not exist as a function.
**Describe the expected behavior**
The correct command is 'tf.data.experimental.enable_debug_mode()', thus there is a typo that replaced the underscore after enable to be a dot. I have not checked thoroughly in the entire repo for any other occurrence of the same typo.
**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): yes, fix typo.
https://github.com/tensorflow/tensorflow/pull/49825

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
As this is a simple typo issue, I don't think an example is needed. Here is a permalink to the line in the source code that has the typo.
https://github.com/tensorflow/tensorflow/blob/dc487160e67bdb9b4bb317e0922e3ae3eb513c43/tensorflow/python/data/ops/dataset_ops.py#L3918"
49723,Variables not found in tf 2.5 when calling fit(),"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Colab run on Windows 10
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: N/A
-   **TensorFlow installed from (source or binary)**:  \*
-   **TensorFlow version (use command below)**:  2.5
-   **Python version**: 3.7.10
-   **Bazel version (if compiling from source)**: \*
-   **GCC/Compiler version (if compiling from source)**: \*
-   **CUDA/cuDNN version**: \*
-   **GPU model and memory**: \*
-   **Exact command to reproduce**: see below

\*: For all such information, I am using Google Colab as is, without any modification.


### Description of the problem
I believe this is a problem with tf 2.5, as I was running all codes with no issue for the past few months with tf 2.4.1. The problem happened all of sudden and I came to notice a sudden change in the tf version to 2.5. As the later is the only change, I beleive it must be the reason.

I am building a training model using keras api, everything is straightforward, with Adam chosen as an optimizer. The error happens once I call mdl.fit()

### Source code:
For reference, this is a VAE model. To reproduce, create a colab file and paste the following code as is.
```
seq_shape = (34,4,1)
batch_size = 512
latent_dim = 2

input_seq = keras.Input(shape=seq_shape)
x = layers.Conv2D(80, (5,1),activation='relu')(input_seq)
shape_before_flattening = K.int_shape(x)
x = layers.Flatten()(x)

x = layers.Dense(80,activation='relu')(x)
x = layers.Dense(40,activation='relu')(x)
dense3 = layers.Dense(latent_dim)
z_mean = dense3(x)
z_log_var = layers.Dense(latent_dim)(x)
z = layers.Lambda(sampling)([z_mean, z_log_var])

decoder_input = layers.Input(K.int_shape(z)[1:])
x = layers.Dense(40,activation='relu')(decoder_input)
x = layers.Dense(80,activation='relu')(x)
x = layers.Dense(np.prod(shape_before_flattening[1:]),activation='relu')(x)
x = layers.Reshape(shape_before_flattening[1:])(x)
x = layers.Conv2DTranspose(1, (5,1),activation='sigmoid')(x)
decoder = Model(decoder_input, x)

z_decoded = decoder(z)  
vae = Model(input_seq, z_decoded)


vae.compile(optimizer='adam',loss=[vae_loss])
x = np.ones((100,34,4,1))
vae.fit(x=x,y=x,batch_size=batch_size,shuffle=True,epochs=100)

```
To run the above, the following two functions are needed:
```
def vae_loss(x, z_decoded):
    x = K.flatten(x)
    z_decoded = K.flatten(z_decoded)
    xent_loss =  keras.metrics.binary_crossentropy(x, z_decoded)
    kl_loss =  1e-3 * -0.5 * K.mean( 
    1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)
    return K.mean(xent_loss + kl_loss)

def sampling(args):
    z_mean, z_log_var = args
    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),
    mean=0., stddev=1.)
    return z_mean + K.exp(z_log_var) * epsilon

```
These are all the needed imports:
```
import tensorflow.compat.v1.keras.backend as K
import tensorflow as tf
tf.compat.v1.disable_eager_execution()
import keras
from keras import layers
from keras import backend as K
from keras.models import Model
import numpy as np
```
### Logs
This is the error message I get:

> FailedPreconditionError: 2 root error(s) found.
>   (0) Failed precondition: Could not find variable training_4/Adam/learning_rate. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/training_4/Adam/learning_rate/N10tensorflow3VarE does not exist.
> 	 [[{{node training_4/Adam/Identity/ReadVariableOp}}]]
>   (1) Failed precondition: Could not find variable training_4/Adam/learning_rate. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/training_4/Adam/learning_rate/N10tensorflow3VarE does not exist.
> 	 [[{{node training_4/Adam/Identity/ReadVariableOp}}]]
> 	 [[_arg_input_15_0_0/_359]]
> 0 successful operations.
> 0 derived errors ignored.

Lastly, I noticed that the reported error changes every time I call vae.fit(). The shown log reports not finding leraning_rate, in other instances it was beta_1, beta_2, or the iteration number. 
### Things I already tried:

- Using 'rmsprop' instead of 'adam': did not work. Gives the same error, with differences in the details.
- `from tensorflow.keras.optimizers import Adam`: The error persists


Thanks,"
49706,"ValueError: Shapes (None, 10, 10) and (None, 10) are incompatible","**System information**
- Have I written custom code (link bellow):
- On Google Colab using TF 2.x

Before today, my code can run without any problem. But suddenly today some error occur. 

`ValueError                                Traceback (most recent call last)
<ipython-input-37-91d03c49a48b> in <module>()
      2                          batch_size=128,
      3                          epochs=40,
----> 4                          validation_data=(x_val, y_val))

9 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    984           except Exception as e:  # pylint:disable=broad-except
    985             if hasattr(e, ""ag_error_metadata""):
--> 986               raise e.ag_error_metadata.to_exception(e)
    987             else:
    988               raise

ValueError: in user code:

    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:830 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:813 run_step  *
        outputs = model.train_step(data)
    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:771 train_step  *
        loss = self.compiled_loss(
    /usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py:201 __call__  *
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    /usr/local/lib/python3.7/dist-packages/keras/losses.py:142 __call__  *
        losses = call_fn(y_true, y_pred)
    /usr/local/lib/python3.7/dist-packages/keras/losses.py:246 call  *
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper  **
        return target(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/keras/losses.py:1631 categorical_crossentropy
        y_true, y_pred, from_logits=from_logits)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/keras/backend.py:4827 categorical_crossentropy
        target.shape.assert_is_compatible_with(output.shape)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with
        raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))

    ValueError: Shapes (None, 10, 10) and (None, 10) are incompatible`


link for colab : https://colab.research.google.com/drive/14CCxoPOE3cDGIsz8Ua6XeF-Rl9zM4KRe?usp=sharing
link for dataset : https://drive.google.com/drive/folders/1BUWx1YzE-MtL2L-YZG4r2uqwWwNjjDA6?usp=sharing


"
49702,XLA: Cannot get IR on TPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab environment
- TensorFlow installed from (source or binary): Google Colab environment
- TensorFlow version (use command below): 2.5.0
- Python version: 3.7

**Describe the current behavior**
Code is in https://github.com/hjmus/mock/blob/master/TPUs_in_Colab.ipynb. I was trying to get HLO IR when running `tf.function` on TPU, by using `experimental_get_compiler_ir()`, but run into the following error:
```
ValueError: No matching device found for '/job:worker/replica:0/task:0/device:TPU:1'
```

**Describe the expected behavior**
Be able to get IR when running on TPU.

**Standalone code to reproduce the issue**
https://github.com/hjmus/mock/blob/master/TPUs_in_Colab.ipynb

**Other info / logs** 
The purpose of this exercise is to check out the IR generated for GSPMD (https://arxiv.org/pdf/2105.04663.pdf).

#comp:xla #XLA"
49658,"Unsupported TF Select ops: AddV2, Mul, Pad","### System information

- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- TensorFlow installation (pip package):
- TensorFlow library ( 2.5.0 ):

### Problem
I have an ONNX model, which itself is originated from pytorch. I'm trying to convert from ONNX format to tensorflow lite format without using Select ops.
First, I convert to TF SavedModel via onnx-tensorflow package, then I convert to TFLite with basic API:

```python
converter = tf.lite.TFLiteConverter.from_saved_model( name )
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]
```

I get the following errors:

```bash
...
<unknown>:0: note: loc(""PartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""onnx_tf_prefix_Add_65@__inference___call___373"" at ""PartitionedCall@__inference_signature_wrapper_435"") at ""PartitionedCall"")): 'tf.AddV2' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""PartitionedCall""): called from
<unknown>:0: error: failed while converting: 'main': 
Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select 
TF Select ops: AddV2, Mul, Pad
Details:
        tf.AddV2
        tf.AddV2 {device = """"}
        tf.Mul {device = """"}
        tf.Pad {device = """"}
```

I've also had problem with SoftMax operator, but I've solved the issue. It turned out, that TFLite version of [softmax operator](https://www.tensorflow.org/api_docs/python/tf/nn/softmax) doesn't support axis parameter, so I removed it and now converter is able to use non-flex softmax.
All modifications I do on ONNX graph, before converting to Tensorflow

What could be wrong with other operators: AddV2, Mul, Pad ?


### What I tried
I've noticed that [tfl.mul](https://www.tensorflow.org/mlir/tfl_ops#tflmul_tflmulop) docs don't tell anything about broadcasting compared to [tf.mul](https://www.tensorflow.org/mlir/tf_ops#tfmul_tfmulop). So my hypothesis was that non-flex tflite can multiply only tensors of the same shape, but can't multiply tensor by scalar. So I've replaced [Constant](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Constant) with [Shape](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Shape) -> [Cast](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Cast) (to float32) -> [ConstantOfShape](https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConstantOfShape) operators, but I still get the same errors.

I've also tried to convert all tensors with datatype int64 to int32 - no success.

Any suggestions? What do I have to pay attention first, when I get such select ops issues?

"
49642,test build issue,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
49627,2.4.0 docs,When clicking on r2.4 here https://www.tensorflow.org/versions it directs to v2.5.0 instead.
49626,RET_CHECK failure: operand != nullptr  when trying to run with TPU,"Hello,

I am trying to train my model with TPU on Google Colab. On GPU everything worked but was too slow for my workflows.
Now, after i have finished the initial setup I get the following error:

```
InternalError                             Traceback (most recent call last)
<ipython-input-14-9d78cb65fe31> in <module>()
    244 with tpu_strategy.scope():
    245     # Start the process
--> 246     out_label_all, true_label_all, features, test_labels, acc =                         start_session(log_dir, dsparams, hparams, eparams, mparams)
    247 results[""ACC""] = acc

15 frames
<ipython-input-14-9d78cb65fe31> in start_session(log_dir, dsparams, hparams, eparams, mparams)
    235                     create_dir(run_dir)
    236 
--> 237             results = run(run_dir, dsparams, hparams, eparams)
    238 
    239     return results

<ipython-input-14-9d78cb65fe31> in run(run_dir, dsparams, hparams, eparams)
    165             tf.summary.scalar('accuracy', results[-1], step=1)
    166     else:
--> 167         results = train_model(run_dir, dsparams, hparams, eparams)
    168 
    169     return results

<ipython-input-14-9d78cb65fe31> in train_model(run_dir, dsparams, hparams, eparams)
    121                 validation_data=ds_test,
    122                 verbose=eparams[""VERBOSE""],
--> 123                 callbacks=callbacks
    124             )
    125 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1186               logs = tmp_logs  # No error, now safe to assign to logs.
   1187               end_step = step + data_handler.step_increment
-> 1188               callbacks.on_train_batch_end(end_step, logs)
   1189               if self.stop_training:
   1190                 break

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)
    455     """"""
    456     if self._should_call_train_batch_hooks:
--> 457       self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)
    458 
    459   def on_test_batch_begin(self, batch, logs=None):

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)
    315       self._call_batch_begin_hook(mode, batch, logs)
    316     elif hook == 'end':
--> 317       self._call_batch_end_hook(mode, batch, logs)
    318     else:
    319       raise ValueError('Unrecognized hook: {}'.format(hook))

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_end_hook(self, mode, batch, logs)
    335       self._batch_times.append(batch_time)
    336 
--> 337     self._call_batch_hook_helper(hook_name, batch, logs)
    338 
    339     if len(self._batch_times) >= self._num_batches_for_timing_check:

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook_helper(self, hook_name, batch, logs)
    370       start_time = time.time()
    371 
--> 372     logs = self._process_logs(logs, is_batch_hook=True)
    373     for callback in self.callbacks:
    374       hook = getattr(callback, hook_name)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py in _process_logs(self, logs, is_batch_hook)
    290     if is_batch_hook and self._batch_hooks_support_tf_logs:
    291       return logs
--> 292     return tf_utils.sync_to_numpy_or_python_type(logs)
    293 
    294   def append(self, callback):

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py in sync_to_numpy_or_python_type(tensors)
    517     return t  # Don't turn ragged or sparse tensors to NumPy.
    518 
--> 519   return nest.map_structure(_to_single_numpy_or_python_type, tensors)
    520 
    521 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)
    865 
    866   return pack_sequence_as(
--> 867       structure[0], [func(*x) for x in entries],
    868       expand_composites=expand_composites)
    869 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py in <listcomp>(.0)
    865 
    866   return pack_sequence_as(
--> 867       structure[0], [func(*x) for x in entries],
    868       expand_composites=expand_composites)
    869 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py in _to_single_numpy_or_python_type(t)
    513   def _to_single_numpy_or_python_type(t):
    514     if isinstance(t, ops.Tensor):
--> 515       x = t.numpy()
    516       return x.item() if np.ndim(x) == 0 else x
    517     return t  # Don't turn ragged or sparse tensors to NumPy.

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in numpy(self)
   1092     """"""
   1093     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
-> 1094     maybe_arr = self._numpy()  # pylint: disable=protected-access
   1095     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
   1096 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in _numpy(self)
   1060       return self._numpy_internal()
   1061     except core._NotOkStatusException as e:  # pylint: disable=protected-access
-> 1062       six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
   1063 
   1064   @property

/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)
```

```
InternalError: 9 root error(s) found.
  (0) Internal: {{function_node __inference_train_function_19610}} RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1597) operand != nullptr 
	 [[{{node TPUReplicate/_compile/_16180436139931446061/_4}}]]
	 [[TPUReplicate/_compile/_16180436139931446061/_4/_256]]
  (1) Internal: {{function_node __inference_train_function_19610}} RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1597) operand != nullptr 
	 [[{{node TPUReplicate/_compile/_16180436139931446061/_4}}]]
	 [[tpu_compile_succeeded_assert/_6288160498006010166/_5/_273]]
  (2) Internal: {{function_node __inference_train_function_19610}} RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1597) operand != nullptr 
	 [[{{node TPUReplicate/_compile/_16180436139931446061/_4}}]]
	 [[TPUReplicate/_compile/_16180436139931446061/_4/_242]]
  (3) Internal: {{function_node __inference_train_function_19610}} RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1597) operand != nullptr 
	 [[{{node TPUReplicate/_compile/_16180436139931446061/_4}}]]
	 [[cluster_train_function/control_after/_1/_325]]
  (4) Internal: {{function_node __inference_train_function_19610}} RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1597) operand != nullptr 
	 [[{{node TPUReplicate/_compile/_16180436139931446061/_4}}]]
	 [[tpu_compile_succeeded_assert/_6288160498006010166/_5/_217]]
  (5) Internal: {{function_node __inference_train_function_19610}} RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1597) operand != nullptr 
	 [[{{node TPUReplicate/_compile/_16180436139931446061/_4}}]]
	 [[TPUReplicate/_compile/_16180436139931446061/_4/_200]]
  (6) Internal: {{function_node __inference_train_function_19610}} RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1597) operand != nullptr 
	 [[{{node TPUReplicate/_compile/_16180436139931446061/_4}}]]
	 [[tpu_compile_succeeded_assert/_6288160498006010166/_5/_231]]
  (7) Internal: {{function_node __inference_train_function_19610}} RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1597) operand != nullptr 
	 [[{{node TPUReplicate/_compile/_16180436139931446061/_4}}]]
	 [[TPUReplicate/_compile/_16180436139931446061/_4/_186]]
  (8) Internal: {{function_node __inference_train_function_19610}} RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1597) operand != nullptr 
	 [[{{node TPUReplicate/_compile/_16180436139931446061/_4}}]]
0 successful operations.
0 derived errors ignored.
```

I found out that the failure is related to this custom RNN-Cell when training is enabled. And if i just return the old values everything is working. The trainable parameters are w_in, w_rec and decay.

```
def call(self, input_at_t, states_at_t):
        old_v, old_z = states_at_t
        dim = tf.reduce_prod(tf.shape(input_at_t)[1:])
        new_input = tf.reshape(input_at_t, [-1, dim])
        i_t = tf.matmul(new_input, self.w_in) + tf.matmul(old_z, self.w_rec)
        i_reset = activation_functions.reset_by_threshold(old_z, self.decay, old_v, self.threshold)
        new_v = self.decay * old_v + (1.0 - self.decay) * i_t - i_reset
        new_z = activation_functions.spike_function(new_v/self.threshold)

        #return (new_z, new_v), (old_v, old_z)   # If I return this here everything works fine .. but that's wrong of course
        return (new_z, new_v), (new_v, new_z) # This doesn't work
```

I think that the problem is the second return value. If i return tensors on which operations should be performed, the error occurs.
Therefor I am searching a way to modify and return the tensor without any errors.

Environment:
- Google Colab Pro with TPU
- Tensorflow 2.5.0 (also tried with 2.4.1)"
49615,test build issue ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
49614,Documentation of ResourceVariable is hard to find.  (keras),"Please provide a link to the documentation entry, for example:

https://github.com/tensorflow/tensorflow/blob/a954d375fec881b2b050088f87754b3d0995924a/tensorflow/python/keras/engine/base_layer.py#L573


## Description of issue (what needs changing):

### Clear description

Model.add_weight describes use_resource with a single sentence in docstring.

It would be nice if we can add a link to some documentation of ResourceVariable describing what it does.

Otherwise, it is difficult to contextualize the implications of this argument.

For example, is this a tfv1 vs tfv2 issue?
What behavior changes to the variables are expected?

Adding to the difficulty to explore the context, is that searching for `ResourceVariable` on tf document website no documentation of ResourceVariable shows up as top results, but we get a ton of 'resource variable' and 'variable' documentation. That's probably a separate issue.

"
49613,spell correction,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
49612,Video classification TensorFlow Lite model(i3d) with 5D input on android ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Vivo Y91i
- TensorFlow installed from (source or binary): binary
- TensorFlow version: v2.5.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): NIL
- GCC/Compiler version (if compiling from source): NIL
- CUDA/cuDNN version: CUDA 11.0
- GPU model and memory: 11 GB



**Describe the problem**
Need to run a sign language video classification model(i3d) on android, that takes 5 dimension ( 1 3 64 224 224),https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android , but failes. But runs on PC with python3.7
```bash
import random
import re
import os
import tempfile
import ssl
import cv2
import scipy.special
import numpy as np
import pickle as pkl
import math
import copy
import tensorflow as tf
# Some modules to display an animation using imageio.
import imageio
from IPython import display

from urllib import request  # requires python3
# Utilities to open video files using CV2
def crop_center_square(frame):
  y, x = frame.shape[0:2]
  min_dim = min(y, x)
  start_x = (x // 2) - (min_dim // 2)
  start_y = (y // 2) - (min_dim // 2)
  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]

def load_label():
  with open(""labels.txt"", 'r') as f:
    labels = [line.strip() for line in f.readlines()]
    return labels

# load the label
word_data = load_label(
    
  )
# load the tensorflow lite run time

interpreter = tf.lite.Interpreter(model_path=""onnx_lite64.tflite"")
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# resize
resize = (224,224)
path = ""test.mp4""
# read the video
cap = cv2.VideoCapture(path)

# Get the Default resolutions
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))

# Define the codec and filename.
out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 5, (frame_width,frame_height))
frames = []

in_frames = 65
counter = 1


try:
  while True:
   
    ret, frame_old = cap.read()
    if not ret:
      break
    frame_new = copy.deepcopy(frame_old)
    frame = crop_center_square(frame_old)

    frame = cv2.resize(frame, resize)
    frame = frame[:, :, [2, 1, 0]] 
    
    frames.append(frame)
    # check the counter is not zero and append the frames
    if counter!=0:

      if counter % in_frames == 0:
      

        del frames[:]

    else:

     
      frames.append(frame)
     
     
    

    
    res = np.array(frames) / 255.0
    print(res.shape)
    value = res.shape[0] 
    counter+=1
   
  

    # Remove the frame with zero clip
    if value !=0 and value == 64:
      #print(res.shape)
      model_input = tf.constant(res, dtype=tf.float32)[tf.newaxis, ...]
      print(model_input.shape)
      inp = tf.transpose(model_input, perm=[0, 4, 1, 2,3])
      print(inp.shape)
      interpreter.set_tensor(input_details[0]['index'], inp)
      interpreter.invoke()
      outputs = interpreter.get_tensor(output_details[0]['index'])
      topk=1
      result = []
      num_clips =1
      num_detections = 2000
      for i in range(num_detections):
        res = outputs[0][i]
        result.append(res)
      #print(result)
      res = []
      res.append(result)
      
      raw_scores = np.array(res)

      prob_scores = scipy.special.softmax(raw_scores, axis=1)
      prob_sorted = np.sort(prob_scores, axis=1)[:, ::-1]
      pred_sorted = np.argsort(prob_scores, axis=1)[:, ::-1]
     



      word_topk = None
      for k in range(topk):
          for i, p in enumerate(pred_sorted[:, k]):
              if str(word_data[p])!=""want"":
                  print(str(word_data[p]))
              
                  word_topk= word_data[p]
      prob_topk = prob_sorted[:, :topk].transpose()
      print(""Predicted signs:"")
      print(word_topk)
      print(type(prob_topk))


      cv2.putText(frame_old, str(word_topk),(30,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,0),2,cv2.LINE_AA)
      out.write(frame_old)
      cv2.imshow(""Result"",frame_old)

  # All the results have been drawn on the frame, so it's time to display it.
    cv2.imshow('rgb', frame_new)


    if cv2.waitKey(1) == ord('q'):
      break


  #word_data = load_label()

finally:
  cap.release()

```
## Error on Android studio
![java](https://user-images.githubusercontent.com/48623612/119530465-a5dbe200-bda0-11eb-9a1e-5331b514fbd4.png)

**Provide the exact sequence of commands / steps that you executed before running into the problem**
The model was converted from PyTorch > TF .> TFLite. The code throws error while running on android studio.

![input](https://user-images.githubusercontent.com/48623612/119531294-68c41f80-bda1-11eb-8ae2-faaee6fc89e7.png)
![output](https://user-images.githubusercontent.com/48623612/119531305-6b267980-bda1-11eb-9852-1c597d11c502.png)

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached."
49611,[QST] tensorflow 2.4.2 release date [security patches],"Synopsys Black Duck is flagging tensorflow 2.4.0 with security vulnerabilities

looking at the security advisories - it looks like these would be patched with 2.4.2 - Is there an estimated date of when 2.4.2 would be released?

Apologies if this is already discussed elsewhere and I just wasn't able to find it"
49610,"""AutoGraph could not transform function  and will run it as-is"" for an Example from a Guide ","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro 19041.985
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: none
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: 3.8.8
- Bazel version (if compiling from source): none
- GCC/Compiler version (if compiling from source):none
- CUDA/cuDNN version:none
- GPU model and memory:none

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Run code 
```
def train_one_step():
  pass

@tf.function
def train(num_steps):
  print(""Tracing with num_steps = "", num_steps)
  tf.print(""Executing with num_steps = "", num_steps)
  for _ in tf.range(num_steps):
    train_one_step()

train(num_steps=10)
```
from the guide [https://www.tensorflow.org/guide/function](https://www.tensorflow.org/guide/function)
and received a warning (see an attachment) 
[warning.log](https://github.com/tensorflow/tensorflow/files/6540126/warning.log)

**Describe the expected behavior**
an example from the guide should work 
**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): no

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49607,New Compatibility Problem of Stateful Random Binomial Operators,"hi,
When tf is upgraded from 1.15 to 2.4.1, the implementation of the StatefulRandomBinomial operator is different in the two versions, and the verification rules for the input count and probs shape are changed. So what's the reason for this change? What are the differences between the two versions? In addition, the StatefulRandomBinomial operator is not found in API 1.15. Is this operator not supported in API 1.15?"
49606,reduce_variance gives error in case of RaggedTensor when axis=0,"As part of #37014 , `reduce_variance` was added for ragged tensors. Although it is working fine for `axis=1`, it gives error for same input if we change to `axis=0`. 

I am attaching the [gist](https://colab.research.google.com/gist/ashutosh1919/b0591ddb485107187b982a08276712be/untitled550.ipynb).

By observing the stack trace, what I think the issue is:
(1) when I explicitly pass input to `ragged_math_ops.reduce_variance`, it gives correct result. So, the problem is not with `reduce_variance` function.
(2) When I call `tf.math.reduce_variance`, it internally call `GlobalDispatcherOp` which iterates over all the dispatchers to see where the op is supported. 
(3) When the op runs for `BinaryRaggedElementwiseDispatcher`, it fails for some reason and that is why execution fails. It didn't reach till the dispatcher associated for `reduce_variance`.
(4) That's why the problem I think is with dispatcher module.

@mihaimaruseac, @edloper - I am not able to exactly find why the error occures in dispatcher. Please help me by pointing to specific direction and will contribute the fix."
49605,Prediction difference in the converted TFlite model and trained checkpoint from TFOD API,"### 1. System information

- OS Platform and Distribution : Android (Model trained linux Pop OS)
- TensorFlow installation : pip
- TensorFlow library : 2.4.1

**Descriptions**
We have been training model to predict corners using SSD MobileNet V2 320x320 FPNlite architecture model. We used TFOD API code files to train and convert the checkpoint into TFlite format . We were able to convert checkpoint (ckpt 55) into TFlite format without any errors. Analyzing prediction from TFlite model and checkpoint for the same image, we found there is significate difference in predicted coordinates and score values. We can't identify any issues when converting the model and the model is not quantized. 

Following are link includes to trained checkpoints, converted tflite model and prediction images.
 **link** : https://drive.google.com/drive/folders/1ZNJgMaUXWZTKCDQoB1gPFufwhypX6ZHB?usp=sharing

Tflite prediction -  
image : prediction_from_tflite.jpg
scores : [0.90501845 0.3708766  0.09824225 0.05691937 0.05246159 0.04990548
 0.04931968 0.03742141 0.03397185 0.03386968]

Checkpoint prediction 
image : prediction_from_checkpoint.jpg
scores : [0.98141104 0.9789326  0.7256872  0.49804866 0.309637   0.23567227
 0.19505009 0.05802718 0.056795   0.04440427]









"
49603,Didn't find op for builtin opcode 'EXPAND_DIMS',"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10  20H2 (19042.985)
- TensorFlow installed from (source or binary): Binary
- Tensorflow version (commit SHA if source): 2.4.0-alpha
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arduino Nano 33 BLE

**Describe the problem**
I made a model which uses the following Keras layers:
* Conv1d
* Maxpooling1d
* Flatten
* Dense

After conversion and quantisation I get the following error when attempting to use the model:
```
Didn't find op for builtin opcode 'EXPAND_DIMS' version '1'. An older version of this builtin might be supported. Are you using an old TFLite binary with a newer model?

Failed to get registration from op code EXPAND_DIMS

Failed starting model allocation.

AllocateTensors() failed 
```

**Please provide the exact sequence of commands/steps when you ran into the problem**

This is the code that led to the error [from the hello world example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world)
```
  // Map the model into a usable data structure. This doesn't involve any
  // copying or parsing, it's a very lightweight operation.
  model = tflite::GetModel(g_model);
  if (model->version() != TFLITE_SCHEMA_VERSION) {
    TF_LITE_REPORT_ERROR(error_reporter,
                         ""Model provided is schema version %d not equal ""
                         ""to supported version %d."",
                         model->version(), TFLITE_SCHEMA_VERSION);
    return;
  }
  
  // This pulls in all the operation implementations we need.
  // NOLINTNEXTLINE(runtime-global-variables)
  static tflite::AllOpsResolver resolver;

  // Build an interpreter to run the model with.
  static tflite::MicroInterpreter static_interpreter(
      model, resolver, tensor_arena, kTensorArenaSize, error_reporter);
  interpreter = &static_interpreter;

  // Allocate memory from the tensor_arena for the model's tensors.
  TfLiteStatus allocate_status = interpreter->AllocateTensors();
  if (allocate_status != kTfLiteOk) {
    TF_LITE_REPORT_ERROR(error_reporter, ""AllocateTensors() failed"");
    return;
  } 
```
"
49602,Update variable name within Anomaly Detection example,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:https://www.tensorflow.org/tutorials/generative/autoencoder?hl=en

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):
Within Anomaly Detection section, within Build the Model, some variables names are misleading with regard to data that is handled when using the encoder and decoder after training.
As a matter of fact, data here are ECG time series and no longer images like in previous example with mnist and fashion_mnist

### Clear description

encoded_imgs = autoencoder.encoder(normal_test_data).numpy()
decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()

should be replaced by something like:
encoded_data = autoencoder.encoder(normal_test_data).numpy()
decoded_data = autoencoder.decoder(encoded_data).numpy()

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
49601,Model divergence in a TD3 implementation converted from pytorch,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code: yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macos Big Sur and Ubuntu 18 (colab)
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.4.1-0-g85c8b2a817f 2.4.1 (colab) and v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0 (macos)
- Python version: 3.7 (colab), 3.9.5 (macos)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Based on this [implementation][1] of [TD3][2], I converted different torch-based methods to their tensorflow equivalents. No matter what hyperparameters I use, torch's version will start converging by 50,000 - 100,000 steps which happens within a few minutes however, tensorflow version doesn't show any signs of improvement up to 600,000 steps. Here's a [notebook][3] with both versions and I will include here the converted methods. I'm using gym's [BipedalWalker-v3][4] environment for both versions.

**What I tried**

I tried everything from lowering the default learning rate of the paper `0.0003`, hidden unit sizes (i tried 64, 128, 256, 512 and even 400, 300 the paper's defaults nothing works), changed batch size (100, 128, 256, ...), lowered buffer size (default: 1,000,000) to 100,000, 50,000 ... I also tried reusing `tf.GradientTape(persistent=True)` and doing the updates using the same tape, and needless to say, I even re-wrote the code multiple times. NOTHING works.

**Note** 

`self.max_action` in torch's implementation, equals 1 and you will find it hardcoded in tf's, to clear any confusion you may have.

**Common hyperparameters**

 - dense units: 256 (different from paper's 400 and 300)
 - actor update delay: 2
 - exploration noise std: 0.1
 - policy noise std: 0.2
 - noise clip norm: 0.5
 - tau: 0.005
 - optimizer: adam
 - learning rate: 0.0003
 - replay buffer size: 1,000,000
 - replay initial size: 25,000
 - batch size: 256 (different from paper's 100)

**Torch actor and critic models**

    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    
    
    class Actor(nn.Module):
        def __init__(self, state_dim, action_dim, max_action):
            super(Actor, self).__init__()
            self.l1 = nn.Linear(state_dim, 256)
            self.l2 = nn.Linear(256, 256)
            self.l3 = nn.Linear(256, action_dim)
            self.max_action = max_action
    
        def forward(self, state):
            a = F.relu(self.l1(state))
            a = F.relu(self.l2(a))
            return self.max_action * torch.tanh(self.l3(a))
    
    
    class Critic(nn.Module):
        def __init__(self, state_dim, action_dim):
            super(Critic, self).__init__()
            self.l1 = nn.Linear(state_dim + action_dim, 256)
            self.l2 = nn.Linear(256, 256)
            self.l3 = nn.Linear(256, 1)
            self.l4 = nn.Linear(state_dim + action_dim, 256)
            self.l5 = nn.Linear(256, 256)
            self.l6 = nn.Linear(256, 1)
    
        def forward(self, state, action):
            sa = torch.cat([state, action], 1)
            q1 = F.relu(self.l1(sa))
            q1 = F.relu(self.l2(q1))
            q1 = self.l3(q1)
            q2 = F.relu(self.l4(sa))
            q2 = F.relu(self.l5(q2))
            q2 = self.l6(q2)
            return q1, q2
    
        def Q1(self, state, action):
            sa = torch.cat([state, action], 1)
            q1 = F.relu(self.l1(sa))
            q1 = F.relu(self.l2(q1))
            q1 = self.l3(q1)
            return q1

**Tensorflow actor and critic models**

    from tensorflow.keras import Model
    from tensorflow.keras.layers import Dense, Input
    
    
    
    def actor(input_shape, output_units):
        x0 = Input(input_shape)
        x = Dense(256, 'relu')(x0)
        x = Dense(256, 'relu')(x)
        output = Dense(output_units, 'tanh')(x)
        return Model(x0, output)
    
    
    def critic(input_shape):
        x0 = Input(input_shape)
        x1 = Dense(256, 'relu')(x0)
        x1 = Dense(256, 'relu')(x1)
        v1 = Dense(1)(x1)
        x2 = Dense(256, 'relu')(x0)
        x2 = Dense(256, 'relu')(x2)
        v2 = Dense(1)(x2)
        return Model(x0, [v1, v2])

**Torch train step**

    def train(self, replay_buffer, batch_size=256):
        self.total_it += 1
        state, action, next_state, reward, not_done = replay_buffer.sample(batch_size)
        with torch.no_grad():
            noise = (torch.randn_like(action) * self.policy_noise).clamp(
                -self.noise_clip, self.noise_clip
            )
            next_action = (self.actor_target(next_state) + noise).clamp(
                -self.max_action, self.max_action
            )
            target_Q1, target_Q2 = self.critic_target(next_state, next_action)
            target_Q = torch.min(target_Q1, target_Q2)
            target_Q = reward + not_done * self.discount * target_Q
        current_Q1, current_Q2 = self.critic(state, action)
        critic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(
            current_Q2, target_Q
        )
        self.critic_optimizer.zero_grad()
        critic_loss.backward()
        self.critic_optimizer.step()
        if self.total_it % self.policy_freq == 0:
            actor_loss = -self.critic.Q1(state, self.actor(state)).mean()
            self.actor_optimizer.zero_grad()
            actor_loss.backward()
            self.actor_optimizer.step()
            for param, target_param in zip(
                self.critic.parameters(), self.critic_target.parameters()
            ):
                target_param.data.copy_(
                    self.tau * param.data + (1 - self.tau) * target_param.data
                )
            for param, target_param in zip(
                self.actor.parameters(), self.actor_target.parameters()
            ):
                target_param.data.copy_(
                    self.tau * param.data + (1 - self.tau) * target_param.data
                )

**tensorflow training methods**

    def update_critic_weights(self, states, actions, rewards, dones, new_states):
        policy_noise = tf.random.normal(
            (self.n_envs * self.buffer_batch_size, self.n_actions),
            0,
            self.policy_noise_std,
        )
        policy_noise = tf.clip_by_value(policy_noise, -self.noise_clip, self.noise_clip)
        target_actions = tf.clip_by_value(
            self.target_actor(new_states) + policy_noise, -1, 1
        )
        target_value1, target_value2 = self.target_critic(
            tf.concat([new_states, target_actions], 1)
        )
        target_value = rewards + (1 - dones) * self.gamma * tf.minimum(
            target_value1, target_value2
        )
        with tf.GradientTape() as tape:
            value1, value2 = self.critic(tf.concat([states, actions], 1))
            value_loss = MSE(value1, target_value) + MSE(value2, target_value2)
        self.critic.optimizer.minimize(
            value_loss, self.critic.trainable_variables, tape=tape
        )

    def update_actor_weights(self, states):
        with tf.GradientTape() as tape:
            actions = self.actor(states)
            loss = -tf.reduce_mean(self.critic([tf.concat([states, actions], 1)])[0])
        self.actor.optimizer.minimize(loss, self.actor.trainable_variables, tape=tape)

    @tf.function
    def train_step(self):
        self.updates.assign_add(1)
        step_actions = self.actor(self.get_states())
        exploration_noise = tf.random.normal(
            [self.n_actions], 0, self.exploration_noise_std
        )
        step_actions = tf.clip_by_value(step_actions + exploration_noise, -1, 1)
        tf.numpy_function(self.step_envs, [step_actions, False, True], [])
        batch = tf.numpy_function(self.concat_buffer_samples, [], 5 * [tf.float32])
        self.update_critic_weights(*batch)
        if tf.math.equal(tf.math.mod(self.updates, self.actor_delay), 0):
            self.update_actor_weights(batch[0])
            self.sync_target_models()

    def sync_target_models(self):
        for model, target_model in self.model_groups:
            for var, target_var in zip(
                model.trainable_variables, target_model.trainable_variables
            ):
                target_var.assign(self.tau * var + (1 - self.tau) * target_var)

The results which you can reproduce using the [notebook][3]:

**Torch**

    time: 0:00:01.928306, steps: 3875, games: 10, fps: 2009.0, mean reward: -105.27, best reward: -82.24
    time: 0:00:06.234093, steps: 13832, games: 20, fps: 2312.0, mean reward: -99.73, best reward: -77.94
    time: 0:00:09.219966, steps: 20691, games: 30, fps: 2297.0, mean reward: -99.37, best reward: -75.26
    time: 0:00:24.854520, steps: 27736, games: 40, fps: 450.0, mean reward: -102.14, best reward: -65.01
    time: 0:00:28.400598, steps: 28444, games: 50, fps: 199.0, mean reward: -103.27, best reward: -65.01
    time: 0:01:24.811760, steps: 39761, games: 60, fps: 200.0, mean reward: -107.92, best reward: -65.01
    time: 0:02:23.950100, steps: 51719, games: 70, fps: 202.0, mean reward: -105.17, best reward: -65.01
    time: 0:03:29.150313, steps: 64853, games: 80, fps: 201.0, mean reward: -103.09, best reward: -65.01
    time: 0:04:27.118459, steps: 76666, games: 90, fps: 203.0, mean reward: -105.1, best reward: -65.01
    time: 0:05:33.525320, steps: 90105, games: 100, fps: 202.0, mean reward: -104.47, best reward: -31.01
    time: 0:06:38.586421, steps: 103162, games: 110, fps: 200.0, mean reward: -102.21, best reward: -31.01
    time: 0:07:50.672645, steps: 117707, games: 120, fps: 201.0, mean reward: -99.69, best reward: -31.01
    time: 0:09:10.076208, steps: 133707, games: 130, fps: 201.0, mean reward: -93.53, best reward: -31.01
    time: 0:10:07.278960, steps: 145180, games: 140, fps: 200.0, mean reward: -88.81, best reward: -30.43
    time: 0:11:04.842319, steps: 156767, games: 150, fps: 201.0, mean reward: -85.12, best reward: -30.43
    time: 0:11:30.127616, steps: 161788, games: 160, fps: 198.0, mean reward: -83.37, best reward: -30.43
    time: 0:11:34.950709, steps: 162755, games: 170, fps: 200.0, mean reward: -86.65, best reward: -30.43
    time: 0:12:06.615783, steps: 169146, games: 180, fps: 201.0, mean reward: -89.97, best reward: -30.43
    time: 0:13:11.028382, steps: 182064, games: 190, fps: 200.0, mean reward: -84.38, best reward: -30.43
    time: 0:14:30.357974, steps: 198064, games: 200, fps: 201.0, mean reward: -79.24, best reward: -30.43
    time: 0:15:49.531968, steps: 214064, games: 210, fps: 202.0, mean reward: -74.81, best reward: -27.15
    time: 0:17:01.859939, steps: 228590, games: 220, fps: 200.0, mean reward: -71.18, best reward: 37.19

**Tensorflow**

    time: 0:00:33.882932, steps: 6825, games: 10, fps: 206, mean reward: -81.9, best reward: -68.04
    time: 0:01:30.612159, steps: 18306, games: 20, fps: 201, mean reward: -77.51, best reward: -68.04
    time: 0:01:49.359029, steps: 22075, games: 30, fps: 190, mean reward: -88.67, best reward: -68.04
    time: 0:01:53.394437, steps: 22881, games: 40, fps: 190, mean reward: -94.84, best reward: -68.04
    time: 0:01:56.996669, steps: 23603, games: 50, fps: 205, mean reward: -98.51, best reward: -68.04
    time: 0:02:16.071768, steps: 27402, games: 60, fps: 192, mean reward: -97.91, best reward: -68.04
    time: 0:02:28.969803, steps: 29996, games: 70, fps: 204, mean reward: -100.71, best reward: -68.04
    time: 0:02:32.286386, steps: 30656, games: 80, fps: 203, mean reward: -102.14, best reward: -68.04
    time: 0:02:41.094522, steps: 32407, games: 90, fps: 198, mean reward: -103.45, best reward: -68.04
    time: 0:02:57.489013, steps: 35634, games: 100, fps: 171, mean reward: -104.67, best reward: -68.04
    time: 0:03:15.559559, steps: 39184, games: 110, fps: 199, mean reward: -109.12, best reward: -68.04
    time: 0:03:26.770144, steps: 41374, games: 120, fps: 194, mean reward: -113.48, best reward: -68.04
    time: 0:03:56.878539, steps: 47205, games: 130, fps: 195, mean reward: -114.48, best reward: -68.04
    time: 0:04:37.541307, steps: 55078, games: 140, fps: 194, mean reward: -116.36, best reward: -68.04
    time: 0:05:14.164399, steps: 62089, games: 150, fps: 192, mean reward: -115.31, best reward: -68.04
    time: 0:06:14.816104, steps: 73559, games: 160, fps: 197, mean reward: -118.41, best reward: -68.04
    time: 0:06:51.555758, steps: 80434, games: 170, fps: 185, mean reward: -118.5, best reward: -68.04
    time: 0:07:11.885412, steps: 84218, games: 180, fps: 188, mean reward: -118.14, best reward: -68.04
    time: 0:07:51.662705, steps: 91584, games: 190, fps: 184, mean reward: -119.91, best reward: -68.04
    time: 0:08:12.492280, steps: 95425, games: 200, fps: 181, mean reward: -119.18, best reward: -68.04
    time: 0:08:33.173622, steps: 99274, games: 210, fps: 186, mean reward: -117.43, best reward: -68.04
    time: 0:08:40.747114, steps: 100642, games: 220, fps: 189, mean reward: -116.43, best reward: -68.04
    time: 0:09:09.865704, steps: 105968, games: 230, fps: 185, mean reward: -116.34, best reward: -68.04

And it will keep diverging forever guaranteed, I almost reached 1,000,000 steps and the reward keeps circling around the same average.

  [1]: https://github.com/sfujim/TD3
  [2]: https://arxiv.org/pdf/1802.09477.pdf
  [3]: https://colab.research.google.com/drive/1gG434fkNOQKXU3-TNOUBA04-44BE7H0Q?usp=sharing
  [4]: https://elegantrl.readthedocs.io/en/latest/examples/BipedalWalker-v3.html

**Describe the expected behavior**

Given that it's almost a copy and paste job from pytorch to tensorflow, the model is expected to work given the same hyperparameters and conditions and it doesn't, so this is a bug, it's not an implementation specific issue unless there is something I don't know that I do and I shouldn't

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): I don't know which component that has a bug but there definitely is a bug somewhere, if you point where I may propose a solution / contribute.

**Standalone code to reproduce the issue**

I included a notebook in the description above.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49600,`tf.keras.layers.LayerNormalization` may produce CPU->GPU Memcpy error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.2 / 8.1.1
- GPU model and memory: Quadro T1000 (computeCapability: 7.5)

**Describe the current behavior**

`tf.keras.layers.LayerNormalization` may produce an error when epsilon is too high (in my case it was 1e-3 but when setting it to 1e-7 it works as expected):
```
tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.
  (0) Internal:  cuDNN launch failure : input shape ([1,256,128,1])
         [[node GenieDelay/label/layer_norm/FusedBatchNormV3 (defined at Workspace\CompanyTransformer\company_transformer\src\company_transformer\genie\delay\modeling.py:53) ]]
         [[div_no_nan_3/ReadVariableOp/_566]]
  (1) Internal:  cuDNN launch failure : input shape ([1,256,128,1])
         [[node GenieDelay/label/layer_norm/FusedBatchNormV3 (defined at Workspace\CompanyTransformer\company_transformer\src\company_transformer\genie\delay\modeling.py:53) ]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_21841]
Function call stack:
train_function -> train_function
2021-05-24 19:06:14.571178: I tensorflow/stream_executor/stream.cc:1404] [stream=000001C31D860660,impl=000001C331B8A6D0] did not wait for [stream=000001C31D860D20,impl=000001C331B8A670]
2021-05-24 19:06:14.574031: F tensorflow/core/common_runtime/gpu/gpu_util.cc:340] CPU->GPU Memcpy failed
```

**Describe the expected behavior**

Not quite sure what should be expected here because I'm not quite sure why copying a float32[] from CPU to GPU fails but I guess if it's due to some precision (why so?) cropping should be applied. If it's due to NaN then maybe a proper logging would be fine (note that in that case, `tf.keras.callbacks.TerminateOnNaN()` was not hit, but I guess this is called only as a callback at then end of a batch but here it seems to occur in the middle of the calculation). Otherwise, I can't say why copying the buffer fails.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): Haven't investigated in the code right now but I can dig if need be.

**Standalone code to reproduce the issue**
Unfortunately I cannot provide the data as they're confidential but I don't think they matter that much actually. I use a `HuggingFace's` BERT-like Transformer (just the architecture, I adapated it to run on custom financial data) which I stack with other embeddings and standalone features, and append a head. The input vector size of this head is roughly ~300: the 256 first dimensions come from a pooled-CLS of a Transformer so having values between [-1,1] as they're output from `tanh`, there are roughly 10 features that are unscaled but positive, and the rest are embeddings gotten from layers three layers `tf.keras.layers.Embedding` with output dimension 16 (all weights are initialized with `tf.keras.initializers.TruncatedNormal(stddev=0.02)`). The error comes in the head and here the code stub (without data, I'll try to produce fake data that makes it fail if ever needed):
```Python
class DelayHead(tf.keras.layers.Layer):
    def __init__(self,
                 number_heads: int,
                 head_hidden_size: int,
                 initializer_range: float,
                 head_layer_norm_eps: float,
                 head_dropout_prob: float,
                 **kwargs):
        super().__init__(**kwargs)

        self.number_heads = number_heads
        self.denses = []
        self.layer_norms = []
        for _ in range(self.number_heads):
            self.denses.append(
                tf.keras.layers.Dense(
                    units=head_hidden_size,
                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
                    name='dense'
                )
            )
            self.layer_norms.append(
                tf.keras.layers.LayerNormalization(
                    epsilon=head_layer_norm_eps,
                    name='layer_norm'
                )
            )
        self.dropout = tf.keras.layers.Dropout(
            rate=head_dropout_prob
        )
        self.labeling = tf.keras.layers.Dense(
            units=1,
            activation='linear',
            name='label'
        )

    def call(self, hidden_state: tf.Tensor) -> tf.Tensor:
        for i in range(self.number_heads):
            hidden_state = self.denses[i](hidden_state)
            hidden_state = self.layer_norms[i](hidden_state)
        hidden_state = self.dropout(hidden_state)
        return self.labeling(hidden_state)
```

**Other info / logs** 

Logs can be slightly different from one run to another, but it boils down to a CPU->GPU memcpy error in the end. Here are two different logs I got:
```
2021-05-24 20:42:11.957505: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2021-05-24 20:42:11.957815: E tensorflow/stream_executor/cuda/cuda_dnn.cc:340] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on 
Windows
2021-05-24 20:42:11.958364: W .\tensorflow/stream_executor/stream.h:2048] attempting to perform DNN operation using StreamExecutor without DNN support
Traceback (most recent call last):
  File ""company_transformer\src\company_transformer\genie\delay\task.py"", line 150, in <module>
    main(
  File ""C:\Workspace\CompanyTransformer\company_transformer\src\company_transformer\utils.py"", line 86, in decorated
    return func(*args, **kwargs)
  File ""company_transformer\src\company_transformer\genie\delay\task.py"", line 131, in main
    model.fit(
  File ""C:\Users\vince\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""C:\Users\vince\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\vince\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\def_function.py"", line 888, in _call
    return self._stateless_fn(*args, **kwds)
  File ""C:\Users\vince\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py"", line 2942, in __call__
    return graph_function._call_flat(
  File ""C:\Users\vince\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py"", line 1918, in _call_flat
  File ""C:\Users\vince\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py"", line 555, in call
    outputs = execute.execute(
  File ""C:\Users\vince\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.
  (0) Internal:  cuDNN launch failure : input shape ([1,256,128,1])
         [[node GenieDelay/label/layer_norm/FusedBatchNormV3 (defined at Workspace\CompanyTransformer\company_transformer\src\company_transformer\genie\delay\modeling.py:53) ]] 
         [[gradient_tape/GenieDelay/company_transformer/company_transformer_embeddings/RaggedToTensor/strided_slice/_626]]
  (1) Internal:  cuDNN launch failure : input shape ([1,256,128,1])
         [[node GenieDelay/label/layer_norm/FusedBatchNormV3 (defined at Workspace\CompanyTransformer\company_transformer\src\company_transformer\genie\delay\modeling.py:53) ]] 
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_21841]

Function call stack:
train_function -> train_function

2021-05-24 20:42:12.384440: I tensorflow/stream_executor/stream.cc:1404] [stream=0000016D1BA41AA0,impl=0000016D2FC1F860] did not wait for [stream=0000016D1BA40540,impl=0000016D2FC1F830]
2021-05-24 20:42:12.385247: F tensorflow/core/common_runtime/gpu/gpu_util.cc:340] CPU->GPU Memcpy failed
```
and:
```
tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.
  (0) Internal:  cuDNN launch failure : input shape ([1,256,128,1])
         [[node GenieDelay/label/layer_norm/FusedBatchNormV3 (defined at Workspace\CompanyTransformer\company_transformer\src\company_transformer\genie\delay\modeling.py:53) ]]
         [[div_no_nan_3/ReadVariableOp/_566]]
  (1) Internal:  cuDNN launch failure : input shape ([1,256,128,1])
         [[node GenieDelay/label/layer_norm/FusedBatchNormV3 (defined at Workspace\CompanyTransformer\company_transformer\src\company_transformer\genie\delay\modeling.py:53) ]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_21841]

Function call stack:
train_function -> train_function

2021-05-24 19:06:14.571178: I tensorflow/stream_executor/stream.cc:1404] [stream=000001C31D860660,impl=000001C331B8A6D0] did not wait for [stream=000001C31D860D20,impl=000001C331B8A670]
2021-05-24 19:06:14.574031: F tensorflow/core/common_runtime/gpu/gpu_util.cc:340] CPU->GPU Memcpy failed
```"
49597," Due to the upgrade tensorflow2.5.0,I cannot load weights which tf2.4.0 canload,maybe the reson is  the h5py from 2.10.0 to 3.1.0,I want to use tf2.5.0 to load the  pretrain model,how can I do?","ValueError: in user code:

    E:\git_projects\segmentation\deeplabv31\subpixel.py:91 call  *
        return self._phase_shift(super(Subpixel, self).call(inputs))
    D:\software\soft\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\keras\layers\convolutional.py:273 call  **
        outputs.set_shape(out_shape)
    D:\software\soft\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\framework\ops.py:777 set_shape
        raise ValueError(str(e))

    ValueError: Dimension 1 in both shapes must be equal, but are 150 and 1200. Shapes are [?,150,150,128] and [?,1200,1200,2].
"
49579,unable to install,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
49555,Make a TensorFlow official conda channel,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.3
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
The feature will be to release TensorFlow and related packages like TensorFlow-Hub, TensorFlow-Datasets, Tensorflow-Extended, etc. through an official conda channel, in a similar way to Pytorch does currently.

**Will this change the current api? How?**
I don't believe there will be any significant changes to the API in regards to this

**Who will benefit with this feature?**
All Anaconda, Miniconda and similar users will benefit from this, it does facilitate the installation process a lot and to have all TensorFlow related packages in a centralized environment (if I'm not mistaken, ass TensorFlow dependencies are on conda some way or another, including the CUDA Toolkit and cuDNN)

**Any Other info.**
as seen [here](https://github.com/tensorflow/tensorflow/issues/35754) a lot of people are currently interested in this and it would be beneficial to everyone."
49521,ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.,"<em>This is a issue similar to the issues #35226 and #36392.</em>

**System information**
- I am testing  a code available at  https://github.com/hehefan/PointRNN on my system(which is a slurm cluster):
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.3
- CUDA/cuDNN version: 10.1 / 7.6

**Traceback**
```
`Use `tf.keras.layers.Conv1D` instead.
Traceback (most recent call last):
  File ""dist_arg.py"", line 119, in <module>
    model = create_model()
  File ""dist_arg.py"", line 106, in create_model
    model = Model(batch_size=args.batch_size,
  File ""/home/srijan.singh/convert_PointRNN_2/models/dist_arg.py"", line 158, in __init__
    gradients = tape.gradient(self.loss, params)
  File ""/home/srijan.singh/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py"", line 1051, in gradient
    flat_sources = [_handle_or_self(x) for x in flat_sources]
  File ""/home/srijan.singh/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py"", line 1051, in <listcomp>
    flat_sources = [_handle_or_self(x) for x in flat_sources]
  File ""/home/srijan.singh/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py"", line 729, in _handle_or_self
    return x.handle
  File ""/home/srijan.singh/.local/lib/python3.8/site-packages/tensorflow/python/distribute/values.py"", line 571, in handle
    raise ValueError(""`handle` is not available outside the replica context""
ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.`
```
**dist.arg.py**
```
mport os
import sys
import io
from datetime import datetime
import argparse
import numpy as np
from PIL import Image
import tensorflow as tf
#import matplotlib.pyplot as plt
#from mpl_toolkits.mplot3d import axes3d, Axes3D
from PIL import Image
import time

strategy = tf.distribute.MirroredStrategy()

BATCH_SIZE_PER_REPLICA = 2
GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
BUFFER_SIZE = 8
EPOCHS = 200000

import models.dist_arg as models

parser = argparse.ArgumentParser()
parser.add_argument('--data-dir', default='data/argo-5m', help='Dataset directory [default: data/argo-5m]')
parser.add_argument('--dataset', default='argo', help='Dataset. argo or nu [default: argo]')
parser.add_argument('--batch-size', type=int, default=8, help='Batch Size during training [default: 4]')
parser.add_argument('--num-iters', type=int, default=200000, help='Iterations to run [default: 200000]')
parser.add_argument('--save-iters', type=int, default=1000, help='Iterations to save checkpoints [default: 1000]')
parser.add_argument('--learning-rate', type=float, default=1e-5, help='Learning rate [default: 1e-5]')
parser.add_argument('--max-gradient-norm', type=float, default=5.0, help='Clip gradients to this norm [default: 5.0].')
parser.add_argument('--seq-length', type=int, default=10, help='Length of sequence [default: 10]')
parser.add_argument('--num-points', type=int, default=1024, help='Number of points [default: 1024]')
parser.add_argument('--num-samples', type=int, default=8, help='Number of samples [default: 8]')
parser.add_argument('--unit', type=str, default='pointrnn', help='Unit. pointrnn, pointgru or pointlstm [default: pointlstm]')
parser.add_argument('--alpha', type=float, default=1.0, help='Weigh on CD loss [default: 1.0]')
parser.add_argument('--beta', type=float, default=1.0, help='Weigh on EMD loss [default: 1.0]')
parser.add_argument('--log-dir', default='outputs', help='Log dir [default: outputs]')

args = parser.parse_args()
np.random.seed(999)
tf.compat.v1.set_random_seed(999)
print ('-'*60)
print (""arguments_parsed"")
print ('-'*60)
print (tf.distribute.get_strategy())

args.log_dir += '/%s-%s'%(args.dataset, args.unit)

if args.dataset == 'argo':
    from datasets.argo_nu import Argoverse as Dataset
if args.dataset == 'nu':
    from datasets.argo_nu import nuScenes as Dataset

train_dataset = Dataset(root=args.data_dir,
                        seq_length=args.seq_length,
                        num_points=args.num_points,
                        train=True)



print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))

def get_batch(dataset, batch_size):
    batch_data = []
    for i in range(batch_size):
        sample = dataset[0]
        batch_data.append(sample)
    return np.stack(batch_data, axis=0)

batch_data = tf.convert_to_tensor(get_batch(dataset=train_dataset, batch_size=args.batch_size))
dataset = tf.data.Dataset.from_tensor_slices(batch_data).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)
train_dist_dataset = strategy.experimental_distribute_dataset(dataset)
print(type(batch_data), batch_data.shape, dataset.element_spec)

print ('-'*60)
print (""distributed dataset"")

def create_model():
    model_name = 'Point' + args.unit[5:].upper()
    Model = getattr(models, model_name)
    model = Model(batch_size=args.batch_size,
              seq_length=args.seq_length,
              num_points=args.num_points,
              num_samples=args.num_samples,
              knn=True,
              alpha=args.alpha,
              beta=args.beta,
              learning_rate=args.learning_rate,
              max_gradient_norm=args.max_gradient_norm,
              is_training=True)
    return model

with strategy.scope():
  model = create_model()

print ('-'*60)
print (""model_made"")

@tf.function
def distributed_train_step(dataset_inputs):

        los, cd, emd, step, summary, predictions, _ = strategy.experimental_run_v2([model.loss, model.cd, model.emd, model.global_step, summary_op, model.predicted_frames, model.train_op], args=(dataset_inputs,))
        return strategy.reduce(tf.distribute.ReduceOp.SUM, los, axis=None)

for epoch in range(args.num_iters):
        # TRAIN LOOP
        total_loss = 0.0
        num_batches = 0
        for x in train_dist_dataset:
                total_loss += distributed_train_step(x)
                num_batches += 1
        train_loss = total_loss / num_batches

```
It calls the **model/dist_arg.py** which leads to the issue observed.

**models/dist.arg.py**
```
import os
import sys
import tensorflow as tf

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(BASE_DIR)
sys.path.append(os.path.join(ROOT_DIR, 'modules'))
sys.path.append(os.path.join(ROOT_DIR, 'modules/tf_ops/nn_distance'))
sys.path.append(os.path.join(ROOT_DIR, 'modules/tf_ops/approxmatch'))

from pointnet2 import *
from pointrnn_cell_impl import *
import tf_nndistance
import tf_approxmatch
""""""
strategy = tf.distribute.MirroredStrategy()
""""""
strategy = tf.distribute.get_strategy()

BATCH_SIZE_PER_REPLICA = 2
GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
BUFFER_SIZE = 8
EPOCHS = 200000

strategy = tf.distribute.get_strategy()

tf.compat.v1.disable_eager_execution()

class PointRNN(object):
    def __init__(self, batch_size, seq_length, num_points=1024, num_samples=8, knn=False, alpha=1.0, beta=1.0, learning_rate=0.001, max_gradient_norm=5.0, is_training=False):

        self.global_step = tf.Variable(0, trainable=False)

        self.inputs = tf.compat.v1.placeholder(tf.float32, [batch_size, seq_length, num_points, 3])
        frames = tf.split(value=self.inputs, num_or_size_splits=seq_length, axis=1)
        frames = [tf.squeeze(input=frame, axis=[1]) for frame in frames]

        cell1 = PointRNNCell(radius=1.0+1e-6, nsample=3*num_samples, out_channels=128, knn=knn, pooling='max')
        cell2 = PointRNNCell(radius=2.0+1e-6, nsample=2*num_samples, out_channels=256, knn=knn, pooling='max')
        cell3 = PointRNNCell(radius=4.0+1e-6, nsample=1*num_samples, out_channels=512, knn=knn, pooling='max')

        # context
        states1 = None
        states2 = None
        states3 = None
        for i in range(int(seq_length/2)):
            # 512
            xyz1, _, _, _ = sample_and_group(int(num_points/2), radius=0.5+1e-6, nsample=num_samples, xyz=frames[i], points=None, knn=False, use_xyz=False)
            with tf.compat.v1.variable_scope('encoder_1', reuse=tf.compat.v1.AUTO_REUSE) as scope:
                states1 = cell1((xyz1, None), states1)
                s_xyz1, s_feat1 = states1
            # 256
            xyz2, feat2, _, _ = sample_and_group(int(num_points/2/2), radius=1.0+1e-6, nsample=num_samples, xyz=s_xyz1, points=s_feat1, knn=False, use_xyz=False)
            feat2 = tf.reduce_max(input_tensor=feat2, axis=[2], keepdims=False, name='maxpool')
            with tf.compat.v1.variable_scope('encoder_2', reuse=tf.compat.v1.AUTO_REUSE) as scope:
                states2 = cell2((xyz2, feat2), states2)
                s_xyz2, s_feat2 = states2
            # 128
            xyz3, feat3, _, _ = sample_and_group(int(num_points/2/2/2), radius=2.0+1e-6, nsample=num_samples, xyz=s_xyz2, points=s_feat2, knn=False, use_xyz=False)
            feat3 = tf.reduce_max(input_tensor=feat3, axis=[2], keepdims=False, name='maxpool')
            with tf.compat.v1.variable_scope('encoder_3', reuse=tf.compat.v1.AUTO_REUSE) as scope:
                states3 = cell3((xyz3, feat3), states3)

        # prediction
        predicted_motions = []
        predicted_frames = []
        input_frame = frames[int(seq_length/2)-1]
        for i in range(int(seq_length/2), seq_length):
            # 512
            xyz1, _, _, _ = sample_and_group(int(num_points/2), radius=0.5+1e-6, nsample=num_samples, xyz=input_frame, points=None, knn=False, use_xyz=False)
            with tf.compat.v1.variable_scope('decoder_1', reuse=tf.compat.v1.AUTO_REUSE) as scope:
                states1 = cell1((xyz1, None), states1)
                s_xyz1, s_feat1 = states1
            # 256
            xyz2, feat2, _, _ = sample_and_group(int(num_points/2/2), radius=1.0+1e-6, nsample=num_samples, xyz=s_xyz1, points=s_feat1, knn=False, use_xyz=False)
            feat2 = tf.reduce_max(input_tensor=feat2, axis=[2], keepdims=False, name='maxpool')
            with tf.compat.v1.variable_scope('decoder_2', reuse=tf.compat.v1.AUTO_REUSE) as scope:
                states2 = cell2((xyz2, feat2), states2)
                s_xyz2, s_feat2 = states2
            # 128
            xyz3, feat3, _, _ = sample_and_group(int(num_points/2/2/2), radius=2.0+1e-6, nsample=num_samples, xyz=s_xyz2, points=s_feat2, knn=False, use_xyz=False)
            feat3 = tf.reduce_max(input_tensor=feat3, axis=[2], keepdims=False, name='maxpool')
            with tf.compat.v1.variable_scope('decoder_3', reuse=tf.compat.v1.AUTO_REUSE) as scope:
                states3 = cell3((xyz3, feat3), states3)
                s_xyz3, s_feat3 = states3


            with tf.compat.v1.variable_scope('fp', reuse=tf.compat.v1.AUTO_REUSE) as scope:
                l2_feat = pointnet_fp_module(xyz2,
                                             xyz3,
                                             s_feat2,
                                             s_feat3,
                                             mlp=[256],
                                             last_mlp_activation=True,
                                             scope='fp2')
                l1_feat = pointnet_fp_module(xyz1,
                                             xyz2,
                                             s_feat1,
                                             l2_feat,
                                             mlp=[256],
                                             last_mlp_activation=True,
                                             scope='fp1')
                l0_feat = pointnet_fp_module(input_frame,
                                             xyz1,
                                             None,
                                             l1_feat,
                                             mlp=[256],
                                            xyz1,
                                             None,
                                             l1_feat,
                                             mlp=[256],
                                             last_mlp_activation=True,
                                             scope='fp0')

            with tf.compat.v1.variable_scope('fc', reuse=tf.compat.v1.AUTO_REUSE) as scope:
                predicted_motion = tf.compat.v1.layers.conv1d(inputs=l0_feat, filters=128, kernel_size=1, strides=1, padding='valid', data_format='channels_last', activation=tf.nn.relu, name='fc1')
                predicted_motion = tf.compat.v1.layers.conv1d(inputs=predicted_motion, filters=3, kernel_size=1, strides=1, padding='valid', data_format='channels_last', activation=None, name='fc2')

            predicted_motions.append(predicted_motion)
            input_frame += predicted_motion
            predicted_frames.append(input_frame)

        # loss
        if is_training:
            with tf.GradientTape() as tape:
                optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)
                self.loss = self.emd = self.cd = 0
                for i in range(int(seq_length/2)):
                    match = tf_approxmatch.approx_match(frames[i+int(seq_length/2)], predicted_frames[i])
                    #input_emd = tf_approxmatch.match_cost(frames[i+int(seq_length/2)], predicted_frames[i], match)
                    emd_distance = tf_approxmatch.match_cost(frames[i+int(seq_length/2)], predicted_frames[i], match)
                    ####################################################
                    #print (i, match, input_emd, emd_distance)
                    loss_emd = emd_distance
                    self.emd += loss_emd

                    dists_forward, _, dists_backward, _ = tf_nndistance.nn_distance(predicted_frames[i], frames[i+int(seq_length/2)])
                    #loss_cd = tf.reduce_mean(input_tensor=dists_forward+dists_backward)
                    loss_cd = dists_forward + dists_backward
                    ######################################################
                    self.cd += loss_cd

                    self.loss += (alpha*loss_cd + beta*loss_emd)

                self.cd /= int(seq_length/2)
                self.emd /= (int(seq_length/2)*num_points)

                self.loss /= int(seq_length/2)

                self.lais /= (int(seq_length/2)*num_points)

                self.loss = tf.nn.compute_average_loss(self.loss, global_batch_size=GLOBAL_BATCH_SIZE)

            params = tf.compat.v1.trainable_variables()
            gradients = tape.gradient(self.loss, params)
            #gradients = tf.gradients(ys=self.loss, xs=params)
            #clipped_gradients, norm = tf.clip_by_global_norm(gradients, max_gradient_norm)
            #self.train_op = tf.compat.v1.train.AdamOptimizer(learning_rate).apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)
            #self.train_op = optimizer.apply_gradients(zip(gradients, model.trainable_variables))
            self.train_op = optimizer(learning_rate).apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)

        self.predicted_motions = tf.stack(values=predicted_motions, axis=1)
        self.predicted_frames = tf.stack(values=predicted_frames, axis=1)
        self.saver = tf.compat.v1.train.Saver(tf.compat.v1.global_variables(), max_to_keep=1)

```

The trace mentions the line 
```
gradients = tape.gradient(self.loss, params)
```
in the **models/dist_arg.py** (the second file shown above).

I have used 
```
strategy.experimental_run_v2([model.loss, model.cd, model.emd, model.lais, model.global_step, summary_op, model.predicted_frames, model.train_op], args=(dataset_inputs,)) 
```
as mentioned in similar issues and enclosed my loss computation part within

``` 
used tf.GradientTape() as tape:
```
and also commented
``` 
clipped_gradients, norm = tf.clip_by_global_norm(gradients, max_gradient_norm)  
```
as it was also mentioned that normalization was causing an error,  though the model was different(CNN).

Can someone please find any error on my part(as i have added/changed some lines of code to make it run on multiple gpus) or is it a tensorflow error?"
49518,Tensorflow 2.5.0 Windows - Cannot import name 'keras' from partially initialized module 'tensorflow',"Python returns an error when I run script 
`Cannot import name 'keras' from partially initialized module 'tensorflow' (most likely due to a circular import) (C:\Users\ytigiev\source\repos\tensorflow\tensorflow.py)
`

OS - Wn 10 64 bit
IDE - VS 2019 16.9.6 + env (with Python 3.8.10 - 64 bit. (Downloaded from https://www.python.org/downloads/windows/))

Source code from https://www.tensorflow.org/api_docs/python/tf/keras (Is this sample code actual for tensorflow 2.5.0?)

I just copied first strings - ""import""

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential


requirements.txt

absl-py==0.12.0
astunparse==1.6.3
cachetools==4.2.2
certifi==2020.12.5
chardet==4.0.0
cycler==0.10.0
flatbuffers==2.0
gast==0.4.0
google-auth==2.0.0.dev0
google-auth-oauthlib==0.4.4
google-pasta==0.2.0
grpcio==1.38.0
h5py==3.2.1
idna==3.1
Keras==2.4.3
keras-nightly==2.5.0.dev2021032900
Keras-Preprocessing==1.1.2
kiwisolver==1.3.1
Markdown==3.3.4
matplotlib==3.4.2
numpy==1.20.3
oauthlib==3.1.0
opt-einsum==3.3.0
Pillow==8.2.0
pip==21.1.2
protobuf==3.17.0
pyasn1==0.4.8
pyasn1-modules==0.2.8
pyparsing==2.4.7
python-dateutil==2.8.1
PyYAML==5.4.1
requests==2.25.1
requests-oauthlib==1.3.0
rsa==4.7.2
scipy==1.6.3
setuptools==57.0.0
six==1.16.0
tensorboard==2.5.0
tensorboard-data-server==0.6.1
tensorboard-plugin-wit==1.8.0
tensorflow==2.5.0
tensorflow-estimator==2.5.0
termcolor==1.1.0
typing-extensions==3.10.0.0
urllib3==1.26.4
Werkzeug==2.0.1
wheel==0.36.2
wrapt==1.12.1"
49515,File system is not working on Windows through tf.io.gfile.GFile interface,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): 2.5.0
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

It looks like on Windows, File system (e.g., gcs) is only working through `tf.io.read_file()` but not working through `tf.io.gfile.GFile().read()`.

On Windows, check the following command:
```bash
python3 -c ""import tensorflow as tf;print(tf.version.VERSION);tf.io.read_file('gs://1234567')"" 
```
throws out error of:
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: GCS path doesn't contain an object name: gs://1234567 [Op:ReadFile]
```

This indicates GCS file system at least is available.

On the other hand, the following command:
```bash
python3 -c ""import tensorflow as tf;print(tf.version.VERSION);tf.io.gfile.GFile('gs://1234567').read()"" 
```
throws out error of:
```
tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://1234567')
```

which indicate GCS file system is not even registered.

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): yes

**Standalone code to reproduce the issue**
See description above

The issue is due to the duplication of `Env::Default` in multiple places. The issue is exposed on Windows due to `config=monolithic` being passed to bazel. I think I have identified the places that cause the issue. Will submit a PR soon.

/cc @mihaimaruseac @vnvo2409 @kvignesh1420 @terrytangyuan @burgerkingeater "
49514,image dataset generation functions for image segmentation data,"**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Image (semantic) segmentation tasks consist of input image data and target image masks which classify each pixel of the input image. Example: https://www.tensorflow.org/tutorials/images/segmentation

Right now the Keras image data preprocessing API has convenient functions `image_dataset_from_directory` and `ImageDataGenerator.flow_from_directory` for creating TF Datasets for image data, but these are only suitable for image classification tasks (each image has a single classification).

Using these APIs for image segmentation requires some hacky fiddling (I'm currently using this solution from [SO](https://stackoverflow.com/questions/58050113/imagedatagenerator-for-semantic-segmentation)) e.g. creating two ImageDataGenerators with the same seed and `class_mode=None`, and some directory manipulation.

I would suggest adding something like `class_mode='segmentation'` along with a standard directory format for such tasks.

**Will this change the current api? How?**

It would add `class_mode='segmentation'` to these functions. For ImageDataGenerator, it requires defining whether augmentation is applied to the input image, target mask, and/or both.

**Who will benefit with this feature?**
Everyone working on image segmentation tasks

**Any other info**
This could also affect `flow_from_dataframe()`."
49512,I have never had success with Tensorflow (or lite version) build with cmake or bazel on windows,"i downloaded source from here [https://github.com/tensorflow/tensorflow/archive/refs/tags/v2.5.0.zip](url)

**why tensorflow doesn't directly provide static and dynamic windows library, why do we have to build it manually**

from this link [https://www.tensorflow.org/install/lang_c](url)

i can easily download tensorflowlite library
but it is **only x64 version**, whereas **i need x86 and x64** because i want to make an application that runs universally on **windows x86 and x64 versions**

**because tensorflow only provides the x64 version** [https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.5.0.zip](url)

i am not satisfied, **i want both x86 and x64 version** for my application to run on all windows versions universally

that's why I want to build it manually through the source provided [https://github.com/tensorflow/tensorflow](url)

- i downloaded tensorflow version 2.5.0 [https://github.com/tensorflow/tensorflow/archive/refs/tags/v2.5.0.zip](url)
- i downloaded cmake gui x64 version 3.20.2 [https://cmake.org/download/](url)
- i downloaded bazel x64 version 4.1.0 [https://github.com/bazelbuild/bazel/releases](url)

I did tensorflow zip extraction to **D:\tensorflow \tensorflow-2.5.0**
i make BUILD folder to **D:\tensorflow\BUILD**

i run cmake gui
- ""Where is the source code"" set to **D:\tensorflow\tensorflow-2.5.0\tensorflow\lite**
- ""Where to build the binaries"" set to **D:/tensorflow/BUILD**
cmake configue is
- visual studio 15 2017
- x64 use default native compiler
**D:\tensorflow\tensorflow-2.5.0\tensorflow\lite** **has CMakeLists.txt**
the error detail is :
**Setting build type to Release, for debug builds use'-DCMAKE_BUILD_TYPE=Debug'.
Selecting Windows SDK version 10.0.17134.0 to target Windows 6.1.7601.
The C compiler identification is MSVC 19.15.26732.1
The CXX compiler identification is MSVC 19.15.26732.1
Detecting C compiler ABI info
Detecting C compiler ABI info - done
Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.15.26726/bin/Hostx86/x64/cl.exe - skipped
Detecting C compile features
Detecting C compile features - done
Detecting CXX compiler ABI info
Detecting CXX compiler ABI info - done
Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.15.26726/bin/Hostx86/x64/cl.exe - skipped
Detecting CXX compile features
Detecting CXX compile features - done
-- Selecting Windows SDK version 10.0.17134.0 to target Windows 6.1.7601.
CMake Error at C:/Program Files/CMake/share/cmake-3.20/Modules/ExternalProject.cmake:2633 (message):
  error: could not find git for clone of abseil-cpp-populate
Call Stack (most recent call first):
  C:/Program Files/CMake/share/cmake-3.20/Modules/ExternalProject.cmake:3681 (_ep_add_download_command)
  CMakeLists.txt:22 (ExternalProject_Add)


-- Configuring incomplete, errors occurred!
See also ""D:/tensorflow/BUILD/_deps/abseil-cpp-subbuild/CMakeFiles/CMakeOutput.log"".

CMake Error at C:/Program Files/CMake/share/cmake-3.20/Modules/FetchContent.cmake:1000 (message):
  CMake step for abseil-cpp failed: 1
Call Stack (most recent call first):
  C:/Program Files/CMake/share/cmake-3.20/Modules/FetchContent.cmake:1141:EVAL:2 (__FetchContent_directPopulate)
  C:/Program Files/CMake/share/cmake-3.20/Modules/FetchContent.cmake:1141 (cmake_language)
  tools/cmake/modules/OverridableFetchContent.cmake:531 (FetchContent_Populate)
  tools/cmake/modules/abseil-cpp.cmake:34 (OverridableFetchContent_Populate)
  tools/cmake/modules/Findabsl.cmake:18 (include)
  CMakeLists.txt:127 (find_package)


Configuring incomplete, errors occurred!
See also ""D:/tensorflow/BUILD/CMakeFiles/CMakeOutput.log"".**

**and then**
- TFLITE_ENABLE_FLEX  = unchecked **(i dont need it)**
- TFLITE_ENABLE_GPU  = unchecked **(i dont need it)**
- TFLITE_ENABLE_MMAP  = unchecked **(i dont need it)**
- TFLITE_ENABLE_NNAAPI = unchecked **(i dont need it)**
- TFLITE_ENABLE_RESOURCE  = unchecked **(i dont need it)**
- TFLITE_ENABLE_RUY  = unchecked **(i dont need it)**
- TFLITE_ENABLE_XNNPACK  = unchecked **(i dont need it)**
i reconfigure but still failed.

WHAT I WaNT IS, I WANT **TENSORFLOW LlTE STATIC LIBRARY BOTH x86 AND x64**
i dont want my app only working on x64, i want my app run unviversally both x86 and x64

please just tell me **""the right way to build tensorflow lite""**, because it says ""**CMake step for abseil-cpp failed: 1**"" do I have to download the abseil-cpp library. Thank you

i want STATIC library not DYNAMIC library
i need LITE version"
49509,tf.image.sobel_edges not supported in TPU,"Hello,

I am training my deep neural network in TPU on google colab using tensorflow 2 and keras. I have added an L2 loss between the sobel edges of prediction and ground truth images. But, when I am calling `model.fit()` function, this `tf.image.sobel_edges` function raises errors. I believe that the function is not supported while compiling the graph in TPU. 

1. If I am correct then is there any alternate way to compute edges in TPU. 
2. And if I not correct then can you please point me to correct use of `tf.image.sobel_edges` function in TPU.
Thank you in advance."
49508,Exception happened in API function: Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled.,"**System information**
- Distribution: Deployed using bentoml
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.4
- Python version: 3.6

During `model.predict()`, the error below  does not happen during single run but happens occasionally during stress test. I used locust.io for stress test at 50 requests per second with around 90% failed requests
```
""Exception happened in API function: Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.predict` with eager mode enabled."".
```
My model was deployed in AWS SageMaker endpoint using bentoml for serving.


"
49507,No enable autoparallel optimizer doc in grappler,"
## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/config/optimizer/set_experimental_options#args

## Description of issue (what needs changing):

The [document of grappler ](https://www.tensorflow.org/guide/graph_optimization#available_graph_optimizers) says it has an `autoparallel optimizer`, and it supposed to be enabled using `tf.config.optimizer.set_experimental_options`.  While in [`tf.config.optimizer.set_experimental_options`](https://www.tensorflow.org/api_docs/python/tf/config/optimizer/set_experimental_options#args), it does not have the corresponding option (auto_parallel).


"
49506,"File ""..."", line 6, in <module> import tensorflow.compat.v1 as tf ModuleNotFoundError: No module named 'tensorflow'","When I push run the program shown me that. How can i solve it, plz and thank you everyone"
49505,AddBuiltin() mismatch ,"@tensorflow/micro

**System information**

- OS Platform and Distribution: Linux Ubuntu 20.10
-  TensorFlow version: 2.4.1
-   Python version : 3.8

**Describe the problem**

I have this compilation problem:

`../Core/Src/main.cpp: In function 'int main()':`
`../Core/Src/main.cpp:181:57: error: no matching function for call to 'tflite::MicroMutableOpResolver<1>::AddBuiltin(tflite::BuiltinOperator, TfLiteRegistration*)'`

`tflite::ops::micro::Register_FULLY_CONNECTED());`
                      
`workspace_1.3.0/sine/tensorflow_lite/tensorflow/lite/micro/micro_mutable_op_resolver.h:470:16: note: candidate expects 3 arguments, 2 provided`      

In particular I have problems with this snippet of code of main.cpp:

`static tflite::MicroMutableOpResolver<1> micro_op_resolver;`     
`tflite_status = micro_op_resolver.AddBuiltin(`     
`tflite::BuiltinOperator_FULLY_CONNECTED,`  
`tflite::ops::micro::Register_FULLY_CONNECTED());`                                                                                               




"
49503,tf.data.Dataset.from_tensor_slices support more types than int32,"Currently, `tf.data.Dataset.from_tensor_slices` transforms any slice into `int32`. If working with `uint8` data, this leads to an unnecessary and unexpected data type shift leading to extremely enlarged memory use."
49502,Unable to create TFLite LSTM Model with SND format (time_major = true),"### 1. System information

- TF Version - 2.4.1

I am trying to create model with `return_sequences` set to `false` and `time_major` set to `true`.

Unable to create `TF model` with these parameters. 

Could you tell me what was the mistake in the code, what are the `ytest` and `ytrain` dimensions to create the TF model.

 In this model , Time steps = 5 , Batch Size - 2, No.of features = 20  and LSTM layer has 128 internal units.

# 2. Code


```
`import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
model = keras.Sequential()
model.add(layers.LSTM(input_shape=(None,20),units= 128, time_major=True, return_sequences=False))
model.summary()


model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy']);

       
x_test = np.zeros([5,2,20], dtype=np.float32);
x_train = np.zeros([5,2,20], dtype=np.float32);

y_test =  np.zeros([2,128], dtype=np.float32);
y_train = np.zeros([2,128], dtype=np.float32);


model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test, y_test)

`
```


Once it is created, could you confirm the steps of conversion to TFLite . Is the below metioned steps correct

```
`run_model = tf.function(lambda x: model(x))
BATCH_SIZE = 1
STEPS = 2
INPUT_SIZE = 20
concrete_func = run_model.get_concrete_function(
    tf.TensorSpec([ STEPS, BATCH_SIZE, INPUT_SIZE], model.inputs[0].dtype))

model directory.
MODEL_DIR = ""keras_lstm_new""
model.save(MODEL_DIR, save_format=""tf"", signatures=concrete_func)

converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)
tflite_model = converter.convert()

with open('lstmmodelnew.tflite', 'wb') as f:
  f.write(tflite_model) `
```"
49501,Unable to create TFLite LSTM Model with SND format (time_major = true,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installation (pip package or built from source):
- TensorFlow library (version, if pip package or github SHA, if built from source):

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/gist/ymodak/e96a4270b953201d5362c61c1e8b78aa/tensorflow-datasets.ipynb?authuser=1): Demonstrate how to build your TF model.
2)  Reference [TensorFlow Lite Model Colab](https://colab.research.google.com/gist/ymodak/0dfeb28255e189c5c48d9093f296e9a8/tensorflow-lite-debugger-colab.ipynb): Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).

```
(You can paste links or attach files by dragging & dropping them below)
- Provide links to your updated versions of the above two colab notebooks.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

```
(You can paste links or attach files by dragging & dropping them below)
- Include code to invoke the TFLite Converter Python API and the errors.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.
- Model produces correct results, but it is slower than expected.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
49500,ModelCheckpoint does not check the value to monitor from logs modified with custom callback ,"I created a custom callback that adds an additional metrics to the logs after each epoch during training. In a Modelcheckpoint callback, I put the additional metric to be monitored. But the Modelcheckpoint does not save according to the added metrics.
Sample code:
```
class LossCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        logs['new_loss']=logs['loss']+logs['val_loss']

save = tf.keras.callbacks.ModelCheckpoint(
        'model.h5', monitor='new_loss', verbose=1, save_best_only=True,
        save_weights_only=True, mode='min', save_freq='epoch')

model.fit(
       data, 
        epochs=10, 
        callbacks = [LossCallback(),save], 
        steps_per_epoch=100,
        validation_data=val_data, 
    )
```
Is there any way to get ModelCheckpoint to access the updated logs and save accordingly?"
49496,RNN integer input error,"```
import numpy as np
import tensorflow as tf

x_1 = [ i for i in range(20) ]
x_2 = np.array(x_1)
x_3 = x_2.reshape([1,20,1])

rnn = tf.keras.layers.SimpleRNN(1)
rnn(x_3)
```

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-59-799b31aab8d4> in <module>()
      7 
      8 rnn = tf.keras.layers.SimpleRNN(1)
----> 9 rnn(x_3)

15 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)
    658 
    659     if initial_state is None and constants is None:
--> 660       return super(RNN, self).__call__(inputs, **kwargs)
    661 
    662     # If any of `initial_state` or `constants` are specified and are Keras

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
   1010         with autocast_variable.enable_auto_cast_variables(
   1011             self._compute_dtype_object):
-> 1012           outputs = call_fn(inputs, *args, **kwargs)
   1013 
   1014         if self._activity_regularizer:

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py in call(self, inputs, mask, training, initial_state)
   1571     self._maybe_reset_cell_dropout_mask(self.cell)
   1572     return super(SimpleRNN, self).call(
-> 1573         inputs, mask=mask, training=training, initial_state=initial_state)
   1574 
   1575   @property

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py in call(self, inputs, mask, training, initial_state, constants)
    802         input_length=row_lengths if row_lengths is not None else timesteps,
    803         time_major=self.time_major,
--> 804         zero_output_for_mask=self.zero_output_for_mask)
    805 
    806     if self.stateful:

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    200     try:
--> 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py in rnn(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)
   4347     # the value is discarded.
   4348     output_time_zero, _ = step_function(
-> 4349         input_time_zero, tuple(initial_states) + tuple(constants))
   4350     output_ta = tuple(
   4351         tensor_array_ops.TensorArray(

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py in step(inputs, states)
    788       def step(inputs, states):
    789         states = states[0] if len(states) == 1 and is_tf_rnn_cell else states
--> 790         output, new_states = cell_call_fn(inputs, states, **kwargs)
    791         if not nest.is_nested(new_states):
    792           new_states = [new_states]

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
   1010         with autocast_variable.enable_auto_cast_variables(
   1011             self._compute_dtype_object):
-> 1012           outputs = call_fn(inputs, *args, **kwargs)
   1013 
   1014         if self._activity_regularizer:

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py in call(self, inputs, states, training)
   1369       h = K.dot(inputs * dp_mask, self.kernel)
   1370     else:
-> 1371       h = K.dot(inputs, self.kernel)
   1372     if self.bias is not None:
   1373       h = K.bias_add(h, self.bias)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    200     try:
--> 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py in dot(x, y)
   1896     out = sparse_ops.sparse_tensor_dense_matmul(x, y)
   1897   else:
-> 1898     out = math_ops.matmul(x, y)
   1899   return out
   1900 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    200     try:
--> 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)
   3313     else:
   3314       return gen_math_ops.mat_mul(
-> 3315           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
   3316 
   3317 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py in mat_mul(a, b, transpose_a, transpose_b, name)
   5530       return _result
   5531     except _core._NotOkStatusException as e:
-> 5532       _ops.raise_from_not_ok_status(e, name)
   5533     except _core._FallbackException:
   5534       pass

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6860   message = e.message + ("" name: "" + name if name is not None else """")
   6861   # pylint: disable=protected-access
-> 6862   six.raise_from(core._status_to_exception(e.code, message), None)
   6863   # pylint: enable=protected-access
   6864 

/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:MatMul]

------------------

This is a dtype problem. Change int to float can solve the problem.
But I don't know why. Also, the final error message does not make sense.

```
import numpy as np
import tensorflow as tf

x_1 = [ float(i) for i in range(20) ]
x_2 = np.array(x_1)
x_3 = x_2.reshape([1,20,1])

rnn = tf.keras.layers.SimpleRNN(1)
rnn(x_3)

```

"
49494,Tutorial returning 404 on small part,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/tutorials/keras/regression?hl=nb

## Description of issue (what needs changing):

### Clear description

Under ther part:

```
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()
```

Parts of the tutorial returns a imbeded site which is a 404 page.

### Correct links

Yes

### Parameters defined

Not relevant

### Returns defined

Not relevant

### Raises listed and defined

Not relevant

### Usage example

Not relevant

### Request visuals, if applicable

![Bug report](https://user-images.githubusercontent.com/22838996/119238071-99f1e500-bb40-11eb-8cef-4e7a90674a17.PNG)


### Submit a pull request?

Not relevant
"
49493,Tensor documentation hints at differences in graph and eager mode without providing details,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/Tensor

## Description of issue (what needs changing):

Currently, the description of what a tensor is is cutoff: ""A tensor is a multidimensional array of elements represented by a""

Additionally, there is a comment about 

> ""Note that during eager execution, you may discover your Tensors are actually of type EagerTensor. This is an internal detail, but it does give you access to a useful function, numpy:""

 This implies that numpy is not available in graph mode. What else isn't available in graph mode? The documentation should describe the differences in capabilities between the two modes - probably on its own page if required.

In my case, I found this out when trying to create a custom loss function, only to find that a number of expected capabilities were not available on the tensor object. It took a long time to find this one line description that hints at the differences. Even then, however, I have no idea what I can use in that mode or where to set the mode so that I can access the data of the tensor.
"
49492,micro: Port ABS for int8 and int16 from lite to micro,"@tensorflow/micro

@advaitjain this issue tracks my work in porting int8 and int16 support for the ABS kernel in Micro

It will be delivered as one PR containing the porting of the operator and appropriate tests.



"
49490,negative sampling in Word2Vec tutorial,"## URL(s) with the issue:
[negative sampling](https://www.tensorflow.org/tutorials/text/word2vec#negative_sampling_for_one_skip-gram)
[generate training data](https://www.tensorflow.org/tutorials/text/word2vec#generate_training_data)

## Description of issue (what needs changing):
I was going through the tutorial on skipgram word2vec and I noticed that positive sample candidates are also negative sample candidates too.

### Clear description
For example, we have `sentence = ""The wide road shimmered in the hot sun""` and `window_size = 2` for `tf.keras.preprocessing.sequence.skipgrams`. Therefore positive skip-grams for include `(road, the), (road, wide), (road, shimmered), & (road, in)`. 

**I guess `the, wide, shimmered, & in` should not be later labeled as negative skip-grams for `road`, right?**.

PS: I'm a newbie"
49489,'is_tf_type' is deprecated in tensor_util.py what else  may i use? thanks.,"**System information*
--Google Colab
--Tensorflow v 2.4.1
--Python 3.7.10
--runtime (no hardware acceleration)


**Describe the current behavior**
I'm trying to do inference from a model I trained for object detection.
I successfully exported the model.

I'm using the python code to load this new model and do inference but my code keeps crashing at this part:

from object_detection.utils import label_map_util

and this is the error code:


```
 192 from tensorflow.python.framework.tensor_util import MakeNdarray as make_ndarray
    193 from tensorflow.python.framework.tensor_util import constant_value as get_static_value
--> 194 from tensorflow.python.framework.tensor_util import is_tf_type as is_tensor
    195 from tensorflow.python.framework.tensor_util import make_tensor_proto
    196 from tensorflow.python.framework.type_spec import TypeSpec

ImportError: cannot import name 'is_tf_type' from 'tensorflow.python.framework.tensor_util' 

```

so I checked 

tensor_util.py (tensorflow/python/framework/tensor_util.py)

and found that 'is_tf_type' is to be deprecated. The function is still there however.
Is there any other way to load and use/do inference with an exported saved model? without using  'is_tf_type'?

Thanks in advance. 

here is the code I am using by the way:

```
#Import the required libraries for Object detection infernece
import time
import tensorflow as tf
import object_detection.utils 
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils
import os
import cv2
import matplotlib.pyplot as plt
%matplotlib inline# setting min confidence threshold
MIN_CONF_THRESH=.6#Loading the exported model from saved_model directory

# PATH_TO_SAVED_MODEL =r'Custom_OD\Workspace\exported_model\saved_model'
PATH_TO_SAVED_MODEL =r'exported_model\saved_model'

print('Loading model...', end='')
start_time = time.time()# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION
detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)
end_time = time.time()
elapsed_time = end_time - start_time
print('Done! Took {} seconds'.format(elapsed_time))# LOAD LABEL MAP DATA

# PATH_TO_LABELS=r'\Custom_OD\Workspace\Annotations\label_map.pbtxt'
PATH_TO_LABELS=r'annotations\label_map.pbtxt'

category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)#Image file for inference


# IMAGE_PATH=r'\Custom_OD\Workspace\images\test\00178.jpg'def load_image_into_numpy_array(path):
IMAGE_PATH=r'images\test\testimage_(1).jpg'
def load_image_into_numpy_array(path):
    """"""Load an image from file into a numpy array.
    Puts image into numpy array of shape (height, width, channels), where channels=3 for RGB to feed into tensorflow graph.
    Args:
      path: the file path to the image
    Returns:
      uint8 numpy array with shape (img_height, img_width, 3)
    """"""
    return np.array(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB))
image_np = load_image_into_numpy_array(IMAGE_PATH)# Running the infernce on the image specified in the  image path
# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
input_tensor = tf.convert_to_tensor(image_np)
# The model expects a batch of images, so add an axis with `tf.newaxis`.
input_tensor = input_tensor[tf.newaxis, ...]
detections = detect_fn(input_tensor)

# All outputs are batches tensors.
# Convert to numpy arrays, and take index [0] to remove the batch dimension.
# We're only interested in the first num_detections.
num_detections = int(detections.pop('num_detections'))
detections = {key: value[0, :num_detections].numpy()
               for key, value in detections.items()}
detections['num_detections'] = num_detections# detection_classes should be ints.
detections['detection_classes'] = detections['detection_classes'].astype(np.int64)#print(detections['detection_classes'])
image_np_with_detections = image_np.copy()
viz_utils.visualize_boxes_and_labels_on_image_array(
      image_np_with_detections,
      detections['detection_boxes'],
      detections['detection_classes'],
      detections['detection_scores'],
      category_index,
      use_normalized_coordinates=True,
      max_boxes_to_draw=200,
      min_score_thresh=MIN_CONF_THRESH,
      agnostic_mode=False)
plt.figure()
plt.imshow(image_np_with_detections)
print('Done')
plt.show()

```
which I found at this tutorial online 
https://medium.com/analytics-vidhya/tensorflow-2-object-detection-api-using-custom-dataset-745f30278446 \

I went to the tensorflow api docs at 
https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/plot_object_detection_checkpoint.html \
but  it uses from object_detection.utils import label_map_util as well and gives me the same error.


Any advice would be much appreciated. Thanks in advance.
"
49487,Error while installing tf-nightly in Jupyter Notebook,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): pip
- TensorFlow version: tf-nightly
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the problem**
When trying to install **`tf-nightly`** in the **`Jupyter Notebook`** of my **`PC`**, I'm encountering errors. It is working fine in **`Google Colab`**, by the way.

Errors are:

```python
ERROR: tf-nightly-2-0-preview 2.0.0.dev20190601 has requirement tb-nightly<1.15.0a0,>=1.14.0a0, but you'll have tb-nightly 2.4.0a20201022 which is incompatible.
ERROR: tensorflow 2.5.0 has requirement gast==0.4.0, but you'll have gast 0.3.3 which is incompatible.
ERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.
ERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.18.5 which is incompatible.
ERROR: tensorflow-transform 0.24.1 has requirement tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2, but you'll have tensorflow 2.5.0 which is incompatible.
ERROR: tensorflow-text 2.3.0 has requirement tensorflow<2.4,>=2.3.0, but you'll have tensorflow 2.5.0 which is incompatible.
ERROR: tensorflow-gpu 2.0.0b1 has requirement tb-nightly<1.14.0a20190604,>=1.14.0a20190603, but you'll have tb-nightly 2.4.0a20201022 which is incompatible.
ERROR: tensorflow-gpu 2.0.0b1 has requirement tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501, but you'll have tf-estimator-nightly 2.4.0.dev2020090201 which is incompatible.
```


**Provide the exact sequence of commands / steps that you executed before running into the problem**
`!pip install tf-nightly`

**Any other info / logs**
Complete Error Log is present in this attachment,
[Error_Log.txt](https://github.com/tensorflow/tensorflow/files/6525736/Error_Log.txt)
"
49484,How could I get the correct middle layer output of TFLite quantized models,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.6.0-dev20210512

### 2. Question

May I know how could I get the correct middle layer output of TFLite quantized models? I got an answer from https://github.com/tensorflow/tensorflow/issues/49129

I did something like:
interpreter = tf.lite.Interpreter(model_path=str(tflite_file), experimental_preserve_all_tensors=True)
layer_output = interpreter.get_tensor(layer_index)

I tried the same input and for both quantized and normal TFLite model. I think the middle layers result for normal TFLite model is correct but not for the quantized model. 
Is that feature not support TFLite quantized model? 

Also, since this feature is not supported in 2.4.1 version, what will the interpreter.get_tensor(layer_index) return? Is is just some random number?"
49482, How to convert TFLite quantization model back to normal TFLite model?,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1

### 2. Question

How to convert TFLite quantization model back to normal TFLite model?

The models I compared are from https://www.tensorflow.org/lite/guide/hosted_models
1. https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_0.75_224.tgz
2. https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.75_224_quant.tgz

I tried to converted the second quantized model back to float model based on the quantization info from interpreter.get_tensor_details(). 

Issue 1:
The weight/bias info after converted back to float is totally different from those info from the normal tflite model. This is explained in this question that quantized model and normal models are from different training. https://github.com/tensorflow/tensorflow/issues/49119

Issue 2:
If I just converted quantized model back to normal model, the model will lack the activation function after each CONV node (RELU6 in this model), which could result in unconstrained range for output after each layer. At the end, the layer result could be extremely big or small (negative).
Therefore I add a 0-6 clip node after each CONV layer to eliminate extreme number. However, the final inference result is still away from the result of normal TFLite model.

Is there anything I did wrong?
Any suggestion to converted back quantized model to normal TFLite model? 
 
"
49473,Incorrect requirements.txt in Magic Wand Example,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04**
- TensorFlow installed from (source or binary): **Source** 
- Tensorflow version (commit SHA if source): f26800a1e5b1199cfc1a5aca916edc836b541687
- TensorFlow Python package version: **2.4.0 (attempted)**
- Python version: **Python 3.8 64-bit**
- Pip version: **Pip 21.1.1**

**Describe the problem**

For the [TensorFlow Lite Micro Magic Wand example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/magic_wand), attempting to install requirements following instructions in `README.md` fails.

```
Collecting numpy==1.16.2
  Downloading numpy-1.16.2.zip (5.1 MB)
     |████████████████████████████████| 5.1 MB 477 kB/s 
...
ERROR: Cannot install numpy==1.16.2 and tensorflow==2.4.0 because these package versions have conflicting dependencies.

The conflict is caused by:
    The user requested numpy==1.16.2
    tensorflow 2.4.0 depends on numpy~=1.19.2
```

Even when numpy is manually updated to 1.19.2 and the model is trained, (I think) tensorflow 2.4.0 doesn't recognize the operation:

```
...
Didn't find op for builtin opcode 'RESHAPE' version '1'
Failed to get registration from op code RESHAPE
Failed starting model allocation.
...
```

*Caveat*

To get the above result, I converted the Lite model with `xxd -i model.tflite > magic_wand_model_data.cc`, copied the model data and length from the TensorFlow tree into [the Zephyr tree's TensorFlow Magic Wand sample](https://github.com/zephyrproject-rtos/zephyr/tree/main/samples/modules/tensorflow/magic_wand) `magic_wand_model_data.cc`, and ran it on a Renode-emulated `litex_vexriscv` board.

Maybe there's a factor in that process that could've introduced an issue (and in that case, my apologies for filing this issue), but I also re-did that process after changing the `requirements.txt` back to the previous commit's `numpy==1.16.2` and `tensorflow==2.0.0-beta1`:

```
cd tensorflow/lite/micro/examples/magic_wand/train
python3.7 -m venv ./venv # following README.md
source venv/bin/activate
pip install --upgrade pip # if necessary
pip install -r requirements.txt
...
```

I didn't have the same issues during operation (although the model didn't recognize the sample inputs correctly this time I trained it - it's supposed to go RING CIRCLE RING CIRCLE):

```
*** Booting Zephyr OS build v2.6.0-rc1-310-g2a9b32d43f31  ***
Got accelerometer, label: accel-0
WING:
*         *         *
 *       * *       *
  *     *   *     *
   *   *     *   *
    * *       * *
     *         *
WING:
...
WING:
...
```

**Please provide the exact sequence of commands/steps when you ran into the problem**
```
cd tensorflow/lite/micro/examples/magic_wand/train
python3.8 -m venv ./venv
source venv/bin/activate
pip install --upgrade pip # if necessary
pip install -r requirements.txt
```

**Describe the expected behavior**

`pip install -r requirements.txt` should work and the scripts should work correctly with the TensorFlow version in the `requirements.txt`.

**Possible solutions**

- Downgrade requirements.txt `tensorflow==2.0.0-beta1`

OR

- Upgrade `numpy==1.19.2` to match `tensorflow==2.4.0`
- Rewrite scripts to accommodate TensorFlow 2.4.0 (?)

(This is my first time filing an issue on TensorFlow, so my apologies if this isn't a bug and please let me know if you'd like me to remove / add anything.)
"
49469,tf.range not works with fixed input parameter on TPU,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): colab
- TensorFlow version (use command below): 2.4.1
- Python version: colab
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
v2.4.1-0-g85c8b2a817f 2.4.1

**Describe the current behavior**
`tf.range` function cannot compiled on TPU or xla compile option with fixed input value.

[The Cloud TPU reference](https://cloud.google.com/tpu/docs/tensorflow-ops) says `tf.range` is available python api with compile-time constant. However, It cannot compiled on TPU using below code sample. You can know the parameter of `tf.range` is constant by printed value and I tried and failed compile using constant number as the argument of `tf.range` directly. It works if I changed `tf.range` to `range`.

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): no.. I don't know xla...

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf

resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.TPUStrategy(resolver)

class TestModel(tf.keras.Model):
  def __init__(self):
    super().__init__()

    self.embed = tf.keras.layers.Embedding(vocab_size, 32)
    self.dense = tf.keras.layers.Dense(vocab_size)

  def call(self, input, training=None):
    embedding = self.embed(input)
    token_length = embedding.shape[1]
    print(""Token Length:"", token_length)
    outputs = tf.TensorArray(tf.float32, token_length)

    for i in tf.range(token_length):
    # for i in range(token_length):
      output = self.dense(embedding[:, i, :])
      outputs = outputs.write(i, output)
    
    return tf.transpose(outputs.stack(), [1,0,2])

with strategy.scope():
  vocab_size = 1000
  batch_size = 32
  sequence_length = 32

  model = TestModel()
  model.compile('adam', tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))
  model(tf.keras.Input([sequence_length - 1]))

  dataset = tf.data.Dataset.from_tensor_slices(tf.random.uniform([10000, sequence_length], 0, vocab_size, dtype=tf.int32)).map(lambda x: (x[:-1], x[1:]))
  dataset = dataset.batch(batch_size)

  model.fit(dataset)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Error logs
```
InvalidArgumentError: 9 root error(s) found.
  (0) Invalid argument: {{function_node __inference_train_function_161299}} Compilation failure: The number of output elements 128 has to equal to number of input elements that are sliced 1 when input indices are not constant.
	 [[{{node test_model_26/while/strided_slice}}]]
	 [[test_model_26/while]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_1260395280479028058/_5]]
	 [[tpu_compile_succeeded_assert/_1260395280479028058/_5/_197]]
  (1) Invalid argument: {{function_node __inference_train_function_161299}} Compilation failure: The number of output elements 128 has to equal to number of input elements that are sliced 1 when input indices are not constant.
	 [[{{node test_model_26/while/strided_slice}}]]
	 [[test_model_26/while]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_1260395280479028058/_5]]
	 [[tpu_compile_succeeded_assert/_1260395280479028058/_5/_221]]
  (2) Invalid argument: {{function_node __inference_train_function_161299}} Compilation failure: The number of output elements 128 has to equal to number of input elements that are sliced 1 when input indices are not constant.
	 [[{{node test_model_26/while/strided_slice}}]]
	 [[test_model_26/while]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_1260395280479028058/_5]]
	 [[tpu_compile_succeeded_assert/_1260395280479028058/_5/_209]]
  (3) Invalid argument: {{function_node __inference_train_function_161299}} Compilation failure: The number of output elements 128 has to equal to number of input elements that are sliced 1 when input indices are not constant.
	 [[{{node test_model_26/while/strided_slice}}]]
	 [[test_model_26/while]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_1260395280479028058/_5]]
	 [[tpu_compile_succeeded_assert/_1260395280479028058/_5/_185]]
```"
49468,all_ops_resolver and custom ops,"In case I had to implement a generic op unsupported by TF Lite and specify layers of my model, for example like this:

`tflite::MicroMutableOpResolver<2> micro_op_resolver; `
`micro_op_resolver.AddConv2D(); `
`micro_op_resolver.AddX();`

where AddX() is the unsupported op which I have to create, what for its registration in all_ops_resolver.cc?

"
49467,Removal of PersistentTensor breaks custom ops (Horovod),"The recent commit https://github.com/tensorflow/tensorflow/commit/f8153ae87a88586ac1c364116208cfb144c9b64a#diff-b35354f62819de66aaa049a9498cccc261c108a7c488d39e04882110bdee65b5 removed the `PersistentTensor` from the TensorFlow C++ API. For Horovod, we rely on this functionality to allocate the ""fusion buffer"" that packs multiple smaller tensors into a single buffer during allreduce [here](https://github.com/horovod/horovod/blob/master/horovod/common/fusion_buffer_manager.cc#L39) which ultimately calls into [here](https://github.com/horovod/horovod/blob/master/horovod/tensorflow/mpi_ops.cc#L198).

The docs recommend using `Tensor` with `allocate_temp` instead, but this does not seem like a viable workaround. My understanding is these tensors will not survive past the life of a single Op. Other frameworks including PyTorch and MXNet provide similar mechanisms for allocating long-lived tensor buffers, it seems reasonable TensorFlow should continue to do the same. Or is there a workaround I am missing?

Thanks.

cc @reedwm @romerojosh @DEKHTIARJonathan
"
49465,"Can you please clarify the logic behind ""one-hot encoding the labels to use MSE""","## URL(s) with the issue:

https://www.tensorflow.org/guide/keras/train_and_evaluate/#custom_losses

Thank you for the very detailed explanation about Train and Evaluate but I have a query. Raised a [Stack Overflow question](https://stackoverflow.com/questions/67638773/can-you-please-clarify-the-logic-behind-one-hot-encoding-the-labels-to-use-mse) as well.

## Description of issue (what needs changing):
Nothing needs a change but I want to understand the statement,

> We need to one-hot encode the labels to use MSE

and want to understand exactly, how **`One-Hot-Encoding`** and **`MSE`** work together (because **`One-Hot-Encoding`** just creates columns with 0's and a 1), in the code mentioned below in the [Documentation of Keras Train and Evaluate ](https://www.tensorflow.org/guide/keras/train_and_evaluate/#custom_losses)

```python
def custom_mean_squared_error(y_true, y_pred):
    return tf.math.reduce_mean(tf.square(y_true - y_pred))


model = get_uncompiled_model()
model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)

# We need to one-hot encode the labels to use MSE
y_train_one_hot = tf.one_hot(y_train, depth=10)
model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)
```"
49464,Training a Model,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.5.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: NC
- GPU model and memory: KVM



**Describe the problem**
I'm trying to train a new model. I am the official Tensorflow tutorial. nevertheless I block towards the end on the training of the model (script : model_main_tf2.py )
`python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config
2021-05-21 15:27:42.920609: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-05-21 15:27:42.921036: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-05-21 15:27:47.225166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-05-21 15:27:47.225469: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-05-21 15:27:47.225561: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (reco-objets): /proc/driver/nvidia/version does not exist
2021-05-21 15:27:47.226220: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W0521 15:27:47.227876 139889528895296 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.
W0521 15:27:47.228754 139889528895296 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I0521 15:27:47.234278 139889528895296 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
INFO:tensorflow:Maybe overwriting train_steps: None
I0521 15:27:47.242940 139889528895296 config_util.py:552] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0521 15:27:47.243463 139889528895296 config_util.py:552] Maybe overwriting use_bfloat16: False
WARNING:tensorflow:From /home/sic/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:551: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
W0521 15:27:47.352285 139889528895296 deprecation.py:336] From /home/sic/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:551: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/sic/.local/lib/python3.6/site-packages/absl/app.py"", line 303, in run
    _run_main(main, args)
  File ""/home/sic/.local/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 110, in main
    record_summaries=FLAGS.record_summaries)
  File ""/home/sic/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 551, in train_loop
    train_dataset_fn)
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 337, in new_func
    return func(*args, **kwargs)
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 1168, in experimental_distribute_datasets_from_function
    return self.distribute_datasets_from_function(dataset_fn, options)
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 1160, in distribute_datasets_from_function
    dataset_fn, options)
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_strategy.py"", line 597, in _distribute_datasets_from_function
    options)
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 168, in get_distributed_datasets_from_function
    input_contexts, dataset_fn, options)
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 1566, in __init__
    input_contexts, self._input_workers, dataset_fn))
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 2301, in _create_datasets_from_function_with_input_context
    dataset = dataset_fn(ctx)
  File ""/home/sic/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 546, in train_dataset_fn
    input_context=input_context)
  File ""/home/sic/.local/lib/python3.6/site-packages/object_detection/inputs.py"", line 898, in train_input
    reduce_to_frame_fn=reduce_to_frame_fn)
  File ""/home/sic/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py"", line 210, in build
    decoder = decoder_builder.build(input_reader_config)
  File ""/home/sic/.local/lib/python3.6/site-packages/object_detection/builders/decoder_builder.py"", line 64, in build
    load_keypoint_depth_features=input_reader_config
  File ""/home/sic/.local/lib/python3.6/site-packages/object_detection/data_decoders/tf_example_decoder.py"", line 416, in __init__
    default_value=''),
  File ""/home/sic/.local/lib/python3.6/site-packages/object_detection/data_decoders/tf_example_decoder.py"", line 89, in __init__
    label_map_proto_file, use_display_name=False)
  File ""/home/sic/.local/lib/python3.6/site-packages/object_detection/utils/label_map_util.py"", line 201, in get_label_map_dict
    label_map = load_labelmap(label_map_path_or_proto)
  File ""/home/sic/.local/lib/python3.6/site-packages/object_detection/utils/label_map_util.py"", line 168, in load_labelmap
    label_map_string = fid.read()
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 117, in read
    self._preread_check()
  File ""/home/sic/.local/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 80, in _preread_check
    compat.path_to_str(self.__name), 1024 * 512)
tensorflow.python.framework.errors_impl.NotFoundError: PATH_TO_BE_CONFIGURED; No such file or directory
`
do you have an idea?


I confirm that I have the folder where the file is present:
model_dir=models/my_ssd_resnet50_v1_fpn 
pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config
 

thanks
"
49463,Random number generation with tf.function in tf 2.5.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS 7.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.6
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the current behavior**
Example provided on your website here: https://www.tensorflow.org/guide/random_numbers#passing_generators_as_arguments_to_tffunction leads to num_traces=2. This results in excessive retracing and thus slowdown in custom code. Noticed it after upgrading to 2.5.0 from 2.3.1.

**Describe the expected behavior**
As documentation describes num_traces=1 is expected, which it does produce in tf 2.3.1. 

**Standalone code to reproduce the issue**
```
import tensorflow as tf 

num_traces = 0
@tf.function
def foo(g):
  global num_traces
  num_traces += 1
  return g.normal([])
foo(tf.random.Generator.from_seed(1))
foo(tf.random.Generator.from_seed(2))
print(num_traces)
```
"
49462,XLA with tf.function failed on tf2.5,"I can run the tutorial code (https://www.tensorflow.org/xla/tutorials/jit_compile) successfully. But using XAL with `tf.function` on my code failed with the following errors:
```
tensorflow.python.framework.errors_impl.InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run __inference_train_multiple_steps_269495: No unary variant device copy function found for direction: 1 and Variant type_index: tensorflow::ResourceDeleter [Op:__inference_train_multiple_steps_269495]
```
Is there anything I missed when using it?
"
49461,Need clarification regarding SGD Optimizer,"I have a question regarding `SGD Optimizer`. Same issue has been raised in [Stack Overflow](https://stackoverflow.com/questions/67636925/need-clarification-regarding-sgd-optimizer) as well.

There are 3 types of `Gradient Descent Algorithm`:

1. Batch Gradient Descent
2. Mini-Batch Gradient Descent and
3. Stochastic Gradient Descent

**`Stochastic Gradient Descent`** is an `Algorithm` in which one `Instance` from `Training Set` is taken at `Random` and the **`Weights`** are updated with respect to that `Instance`.

**`SGD Optimizer`** is slightly deviating from the above definition where it can accept the **`batch_size`** of more than 1. Can someone clarify this deviation?

Below code seems to be in line with the definition of **`Stochastic Gradient Descent`**:

    model.compile(optimizer = 'sgd', loss = 'mse')
    model.fit(x, y,epochs = 500, batch_size = 1,verbose=1)

However, below code seems to be confusing/deviating (since `batch_size` > 1):

    model.compile(optimizer = 'sgd', loss = 'mse')
    model.fit(x, y,epochs = 500, batch_size = 32, verbose=1)

Thank you in advance for the clarification."
49460,mixed precision training failed on tf2.5," The following momentum updating steps failed when mixed precision is enabled.
```
        cur_step = tf.cast(cur_step, tf.float32)  
        total_step = tf.cast(total_step, tf.float32)  # tensor
        PI = tf.constant(math.pi, tf.float32)
        tau = 1.0 - (1.0 - self.tau_base) * (tf.math.cos(PI * cur_step / total_step) + 1.0) / 2.0

        for param_online, param_target in zip(self.online_net.trainable_variables, self.target_net.trainable_variables):
            param_target.assign(param_target * tau + param_online * (1.0 - tau))
```
And here is the error message
```
TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.
```
Is there anything wrong with the code?"
49459,text.tokenizer not removing filters char from text ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubutnu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):'2.5.0'
- Python version: 3.8

**Describe the current behavior**
The filter parameter of `tf.keras.preprocessing.text.Tokenizer` does not seem to filter out characters included in the ""filters"" paramter. those characters have an index in keys of `.get_config()`. Is this expected? 

The description of the ""filters parameteres reads "" a string where each element is a character that will be filtered from the texts."". 
Hence I would not expect these characters to have been given an index, (perhaps they all could be given one OOV index)
 
**Describe the expected behavior**
The characters included in the filters paramter would not be having different indices in the tokenizer. Either all have one oov index or none. 

**Standalone code to reproduce the issue**
```
import tensorflow as tf 

char_tokenizer = tf.keras.preprocessing.text.Tokenizer(
    num_words=None,
    filters='!""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    lower=True, char_level=True,
    document_count=0, 
)

char_tokenizer.fit_on_texts(['a%$#^ *'])
print(char_tokenizer.get_config()['index_word'])
```

`>> {""a"": 1, ""%"": 2, ""$"": 3, ""#"": 4, ""^"": 5, "" "": 6, ""*"": 7}`

Despite these special characters being included in the filters parameter, they are not filtered out and have been given an index. 

Expected behaviour
`>> {""a"": 1}`

Is this expected? 
"
49458,Process finished with exit code 132 (interrupted by signal 4: SIGILL) on apple m1,"print(""hello"")
import tensorflow
print(""hello"")
It only prints hello before importing TensorFlow running inside the PyCharm IDE and then python stop working. How can I solve this problem?

Versions:

Python version 3.6
TensorFlow version 2.5.0
IDE PyCharm
OS Mac M1 chip
![code image](https://user-images.githubusercontent.com/72116944/119127546-1659ca80-ba52-11eb-8881-98384fe206e2.jpeg)
"
49457,404 from https://www.tensorflow.org/get_started/embedding_viz,"This is the link from http://projector.tensorflow.org/ to ""Open documentation"" (the circle with a question mark inside)"
49456,tf.io.serialize_tensor/parse_tensor: ValueError: as_list() is not defined on an unknown TensorShape in model training,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Systems are: Ubuntu 20.04.2 LTS; Google Colab

- TensorFlow installed from (source or binary):
Installed from conda (Ubuntu), preinstalled (Colab)

- TensorFlow version (use command below):
Tensorflow v2.4.1

- Python version:
Python 3.8.5 (Ubuntu), Python 3.7.10(Colab)

**Describe the current behavior**

Training a simple toy model on a custom iris TFRecords dataset throws the following error:
`ValueError: as_list() is not defined on an unknown TensorShape.`

The custom TFRecord dataset was created by serializing/deserializing the numpy arrays with `tf.io.serialize_tensor/tf.io.parse_tensor` to save/recover the original shapes. Afterwards the tensors were written to TFRecords following the official [Tutorial](https://www.tensorflow.org/tutorials/load_data/tfrecord). Reading and parsing the data seemed to work properly, as the original data was recovered (inspection by eye/shape), but  trying to feed the dataset to `model.fit()` did result in the described error.

**Describe the expected behavior**

Expected behavior would be successful training/evaluation, as training with custom records from serialized numpy arrays (`numpy.tobytes()`) and deserialization by tf.io.decode_raw() and subsequent recovery of array shape was possible.


**Standalone code to reproduce the issue**
I saved the notebook to a [gist](https://gist.github.com/sroener/e9ca6b870647dcdac3ea8df79fcae9c0) after running it in Colab.
It contains 3 main sections:
1) train model on raw numpy arrays (sanity check of toy model)
2) train model on TFRecrods created from said data, serialized by numpy.tobytes() and reconstructed afterwards (works, model training from TFRecord dataset possible)
3) train model on TFrecords created from same data, serialized by tf.io.serialize/parse_tensor. (throws error)

**Other info / logs** 

Full traceback:


> Epoch 1/150
> ---------------------------------------------------------------------------
> ValueError                                Traceback (most recent call last)
> <ipython-input-22-4aa7a265b40e> in <module>()
>       7 model_tensor.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
>       8 # fit the model
> ----> 9 history_tensor = model_tensor.fit(parsed_train_dataset_tensor, epochs=150, batch_size=32, verbose=2)
>      10 
>      11 loss, acc = model.evaluate(parsed_test_dataset_tensor, verbose=0)
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
>    1098                 _r=1):
>    1099               callbacks.on_train_batch_begin(step)
> -> 1100               tmp_logs = self.train_function(iterator)
>    1101               if data_handler.should_sync:
>    1102                 context.async_wait()
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
>     826     tracing_count = self.experimental_get_tracing_count()
>     827     with trace.Trace(self._name) as tm:
> --> 828       result = self._call(*args, **kwds)
>     829       compiler = ""xla"" if self._experimental_compile else ""nonXla""
>     830       new_tracing_count = self.experimental_get_tracing_count()
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
>     869       # This is the first call of __call__, so we have to initialize.
>     870       initializers = []
> --> 871       self._initialize(args, kwds, add_initializers_to=initializers)
>     872     finally:
>     873       # At this point we know that the initialization is complete (or less
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
>     724     self._concrete_stateful_fn = (
>     725         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
> --> 726             *args, **kwds))
>     727 
>     728     def invalid_creator_scope(*unused_args, **unused_kwds):
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
>    2967       args, kwargs = None, None
>    2968     with self._lock:
> -> 2969       graph_function, _ = self._maybe_define_function(args, kwargs)
>    2970     return graph_function
>    2971 
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
>    3359 
>    3360           self._function_cache.missed.add(call_context_key)
> -> 3361           graph_function = self._create_graph_function(args, kwargs)
>    3362           self._function_cache.primary[cache_key] = graph_function
>    3363 
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
>    3204             arg_names=arg_names,
>    3205             override_flat_arg_shapes=override_flat_arg_shapes,
> -> 3206             capture_by_value=self._capture_by_value),
>    3207         self._function_attributes,
>    3208         function_spec=self.function_spec,
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
>     988         _, original_func = tf_decorator.unwrap(python_func)
>     989 
> --> 990       func_outputs = python_func(*func_args, **func_kwargs)
>     991 
>     992       # invariant: `func_outputs` contains only Tensors, CompositeTensors,
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
>     632             xla_context.Exit()
>     633         else:
> --> 634           out = weak_wrapped_fn().__wrapped__(*args, **kwds)
>     635         return out
>     636 
> 
> /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
>     975           except Exception as e:  # pylint:disable=broad-except
>     976             if hasattr(e, ""ag_error_metadata""):
> --> 977               raise e.ag_error_metadata.to_exception(e)
>     978             else:
>     979               raise
> 
> ValueError: in user code:
> 
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *
>         return step_function(self, iterator)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **
>         outputs = model.distribute_strategy.run(run_step, args=(data,))
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
>         return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
>         return self._call_for_each_replica(fn, args, kwargs)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
>         return fn(*args, **kwargs)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **
>         outputs = model.train_step(data)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:758 train_step
>         self.compiled_metrics.update_state(y, y_pred, sample_weight)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state
>         self.build(y_pred, y_true)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:318 build
>         self._metrics, y_true, y_pred)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1163 map_structure_up_to
>         **kwargs)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1258 map_structure_with_tuple_paths_up_to
>         func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1258 <listcomp>
>         func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1161 <lambda>
>         lambda _, *values: func(*values),  # Discards the path arg.
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:418 _get_metric_objects
>         return [self._get_metric_object(m, y_t, y_p) for m in metrics]
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:418 <listcomp>
>         return [self._get_metric_object(m, y_t, y_p) for m in metrics]
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:439 _get_metric_object
>         y_t_rank = len(y_t.shape.as_list())
>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1190 as_list
>         raise ValueError(""as_list() is not defined on an unknown TensorShape."")
> 
>     ValueError: as_list() is not defined on an unknown TensorShape."
49455,Colab doesnt use GPU despite connected to GPU runtime,My code worked well with GPU in Colab a few days ago. But today it was very slow. After checking the availability of GPU fI found out GPU isn't getting used despite connected to one. 
49453,Completely different training results on TF 2.4.1 and 2.0.0,"Hi! How are you? Hope y'all good.

I have a very specific scenario and it would be awesome to have your input. I'm working on a project in which I've developed a training script using TF 2.4.1. Just to give you context, I used MobileNetV2 as the base model to feature extraction and just a Dense layer with one neuron, and, with time, it got necessary to have different base models so as to perform a benchmark, so I started using different base models, such as InceptionV3 and VGG16, defining it as a command option while running my script.

However, so as to the others in my research team to run my script, I had to use TF 2.0.0 due to a software limitation on the laboratory machine (CUDA 10 instead of 11), and that's when it started getting weird. I checked on the documentation if anything in the methods that I was using changed, so as to adapt them. The only changed that I saw was that in TF 2.4.1, the `fit` method supported generators, so I changed my script (using TF 2.0.0) to use the `fit_generator` method, as you can see below:
- TF 2.4.1
  ```python
    training = model.fit(
        generator=train_data_generator,
        epochs=EPOCHS_NUMBER,
        validation_data=valid_data_generator,
        callbacks=callbacks,
    )
  ``` 

- TF 2.0.0
  ```python
    training = model.fit_generator(
        generator=train_data_generator,
        epochs=EPOCHS_NUMBER,
        validation_data=valid_data_generator,
        callbacks=callbacks,
    )
  ```

Besides that, I changed nothing in my script, which you can find at the end of this description. So, okay, what's the problem, right? It occurs that the validation loss does not decrease while running the script using TensorFlow 2.0.0. I tried to check the documentation, if there were any breaking changes or something like this, after checking if the data and the seeds were the same. However, I wasn't able to find anything that helped me understand why the validation loss changed so much, the performance was degraded and due to the fact that I'm using early stopping, the training was finishing earlier than expected, resulting in a worse test performance than the one that I got running with TF 2.4.1. For instance, running the same script, initializing the seed with the same value, using the two different versions, I got the following results:

- TF 2.0.0

name |  val_accuracy | val_loss | val_precision | val_recall | test_accuracy | test_loss | test_precision | test_recall
-- | -- | -- | -- | -- | -- | -- | -- | -- |
fold_5 | 80.2899% | 0.442051 | 85.1852% | 73.3333% | 81.2022% | 0.456165 | 93.0514% | 67.3961%
fold_4 |  77.3913% | 0.507347 | 85.6604% | 65.7971% | 83.4973% | 0.412218 | 95.0000% | 70.6783%
fold_3 |  75.9420% | 0.517585 | 78.7781% | 71.0145% | 76.3934% | 0.515756 | 81.6273% | 68.0525%
fold_2 |  74.8191% | 0.595039 | 95.2381% | 52.1739% | 74.7541% | 0.521118 | 95.9350% | 51.6411%
fold_1 | 73.0825% | 0.652833 | 92.5532% | 50.2890% | 72.5683% | 0.590006 | 96.3964% | 46.8271%

For instance, in the fold 5, this is how the loss and the accuracy are evolving with time:
![image](https://user-images.githubusercontent.com/19495917/119069893-57ec6600-b9bd-11eb-9b43-3bd9d9ae5bc1.png)

- TF 2.4.1

name | val_accuracy | val_loss | val_precision | val_recall | test_accuracy | test_loss | test_precision | test_recall
-- | -- | -- | -- | -- | -- | -- | -- | -- |
fold_5 | 96.6667% | 0.096043 | 96.0000% | 97.3913% | 95.5191% | 0.156118 | 92.2764% | 99.3435%
fold_4 | 94.4928% | 0.134758 | 92.5208% | 96.8116% | 96.3934% | 0.145110 | 93.6214% | 99.5624%
fold_3  | 96.0870% | 0.094560 | 96.7647% | 95.3623% | 96.3934% | 0.136126 | 94.1667% | 98.9059%
fold_2 | 97.3951% | 0.101784 | 97.6676% | 97.1014% | 96.6120% | 0.131193 | 94.5607% | 98.9059%
fold_1 | 96.3821% | 0.095308 | 97.3451% | 95.3757% | 96.5027% | 0.118284 | 95.1168% | 98.0306%

In the same fold (hoping that the seed is set correctly), but using the newest TF version, we have the following graphics:
![image](https://user-images.githubusercontent.com/19495917/119070039-a7cb2d00-b9bd-11eb-874e-ebea8ed94050.png)

It's possible to notice in the first plot that it seems that nothing is happening in the validation data. It seems that the model kind of learns something, because the training loss is decreasing, but ""nothing"" is happening with the validation loss. I honestly tried to search for a lot of things in order to explain this behavior, since it's exactly the same code but wasn't able to find anything useful. I do understand that, depending on the implementation, fluctuations might happen, but it seems to me that the scenario that I presented before is really specific.

Unfortunately, this is a no-go for my project because I do need to run the experiments in the other machine, which has CUDA 10, but I develop the whole application in the computer that I have access to, which is my personal one. 

Given this scenario, can you, please, help me trying to understand what is going on? Am I missing any other change that I have to do in the script? Is this type of behavior expected? I would appreciate any help! It might be worth saying that for me to test it, I installed both CUDAs (10.1 and 11) on my computer and created two different _conda_ environments so I can switch between them easily.

I'm sorry if I'm not in the right channel to ask this, and if it's not, please redirect me to the correct one. Thank you so much!

Below you can find my training script:
```python
from pathlib import Path

import mlflow.tensorflow
from sklearn.model_selection import GroupKFold, StratifiedKFold
from tensorflow.keras.callbacks import Callback, EarlyStopping
from tensorflow.keras.layers import Dense
from tensorflow.keras.metrics import Precision, Recall
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from classes.Evaluator import Evaluator
from utils.args import get_args_train
from utils.inputs import get_inputs_paths_and_targets
from utils.model import build_model, get_preprocess_function
from utils.seed import set_seeds

# Setting the random_state to get reproducible results
seed = set_seeds()

# Constants
ROOT_FOLDER = Path(__file__).resolve().parent.parent
FOLDS_NUMBER = 5
EPOCHS_NUMBER = 100
EPOCHS_WAITING_FOR_IMPROVEMENT = 5

# Gets which input we're going to use
args = get_args_train()
IMAGE_FOLDER_PATH = ROOT_FOLDER / f""crop_result_prop_{args.proportion}""


class TrainingAndValidationMetrics(Callback):
    def on_epoch_end(self, epoch, logs=None):
        mlflow.log_metrics(logs, step=epoch)


# Instantiates GroupKFold class to split into train and test
group_k_fold = GroupKFold(n_splits=FOLDS_NUMBER)

# Configuration dictionary that is going to be used to compile the model
config = {
    ""optimizer"": ""adam"",
    ""loss"": ""binary_crossentropy"",
    ""metrics"": [""accuracy"", Precision(), Recall()],
}

# Gets the dataframe that are going to be used in the flow_from_dataframe
# method from the ImageDataGenerator class
input_df = get_inputs_paths_and_targets(args.proportion)

idg = ImageDataGenerator(
    fill_mode=""nearest"",
    preprocessing_function=get_preprocess_function(args.model.lower()),
)

# Using GroupKFold only to guarantee that a group (in this case, the slide)
# will contain data only in the train or the test group
for train_idx, test_idx in group_k_fold.split(
    input_df.input, input_df.target, input_df.slide
):
    train_data = input_df.iloc[train_idx]
    test_data = input_df.iloc[test_idx]

    # Break here is being used to get only the first fold
    break

print(""### Testing data distribution ###"")
print(f""{test_data.groupby('slide').count()}"")

generator_kwargs = {
    ""directory"": IMAGE_FOLDER_PATH,
    ""x_col"": ""input"",
    ""y_col"": ""target"",
    ""seed"": seed,
    ""classes"": [""0"", ""1""],
}

# Generator that will be used to evaluate the model
test_data_generator = idg.flow_from_dataframe(
    test_data, class_mode=""binary"", shuffle=False, **generator_kwargs
)

# Instantiates the Early Stopping that is going to be used
# in the fit method
early_stopping = EarlyStopping(
    monitor=""val_loss"", patience=EPOCHS_WAITING_FOR_IMPROVEMENT
)

# Defines the list of callbacks that is an argument of the fit
# method
callbacks = [early_stopping, TrainingAndValidationMetrics()]

# K-fold Cross Validation model evaluation
kfold = StratifiedKFold(n_splits=FOLDS_NUMBER, shuffle=True, random_state=seed)

current_fold = 1
# Starts run on mlflow to register metrics (experiment)
mlflow.start_run(
    run_name=f""{args.model.lower()}"",
    tags={""data_proportion"": args.proportion, ""environment"": ""main""},
)


# Folds iteration
for train_idx, val_idx in kfold.split(train_data.input, train_data.target):

    # Builds the model
    model = build_model(args.model.lower(), [Dense(1, activation=""sigmoid"")], config)

    # Starts run on mlflow to register metrics (runs)
    with mlflow.start_run(run_name=f""fold_{current_fold}"", nested=True):

        fitting_data = train_data.iloc[train_idx]
        val_data = train_data.iloc[val_idx]

        mlflow.log_text(
            f""Training data: \n{fitting_data.groupby('target').count()} \n""
            f""Validation data: \n{val_data.groupby('target').count()} \n""
            f""Data proportion: {args.proportion} \n""
            f"" ----- Using Stratified KFold with seed 1 ----- "",
            artifact_file=""data_description.txt"",
        )

        train_data_generator = idg.flow_from_dataframe(
            fitting_data, class_mode=""binary"", **generator_kwargs
        )
        valid_data_generator = idg.flow_from_dataframe(
            val_data, class_mode=""binary"", **generator_kwargs
        )

        training = model.fit(
            train_data_generator,
            epochs=EPOCHS_NUMBER,
            validation_data=valid_data_generator,
            callbacks=callbacks,
        )

        # Logging model
        mlflow.keras.log_model(keras_model=model, artifact_path=""model"")

        evaluator = Evaluator(model, training, test_data_generator, test_data.target)

        # Classification report
        test_metrics = evaluator.evaluate_model()
        mlflow.log_metrics(test_metrics)

        # Saves the classification report generated from the predict method
        mlflow.log_text(
            evaluator.generate_classification_report(),
            artifact_file=""classification_report.txt"",
        )

        # Saves the accuracy and the loss per epoch
        mlflow.log_figure(
            evaluator.generate_training_history_image(),
            artifact_file=""accuracy_loss_epochs.png"",
        )

        # Saves ROC figure
        mlflow.log_figure(evaluator.generate_roc_figure(), artifact_file=""roc.png"")

    current_fold += 1

mlflow.end_run()
```
"
49389,Show search results of old path underneath 404 sign for dead links,A lot of old links to the Tensorflow documentation are now 404'ed. My suggestion would be that old link shows the 404 and also search results on tensorflow.org for the path. For example [https://www.tensorflow.org/deploy/distributed](https://www.tensorflow.org/deploy/distributed) should show the search results for [deploy distributed](https://www.tensorflow.org/s/results/?q=deploy%20distributed) underneath the 404 image.
49381,TFLite NCHW data format issue and Open Questions,"TFLite Version used - 2.4.1
Does TFlite Models can be created using NCHW format ?

When I tried to create , I was having issues ?
But the error i was getting was incorrect, Is this expected ?

In documentation it is not mentioned that NCHW is not supported ? When is this expected to support ?

Few open questions i found regarding this :- 
https://stackoverflow.com/questions/66671358/which-format-is-preferable-for-tflite-model-nchw-or-nhwc

Is it possible to create tflite nchw models ? When TFLite NCHW format is supported ? Facing issues in the attached TFLite script 


Open Questions :- 

**1.  Does TFLite supports NCHW ? 
2.  What is the default format of TFLite Models ? It is always N,H,W,C ?
3.  What is the default format of TFLite Models LSTM models ? It is always N,S,D ? Does TFLite LSTM support S,N,D ?
4.  What are the input formats other than  N,H,W, C  (or) N,S,D ?
5.  How is ideally LSTM's and CNN's differentiated in TFLite ?
6.  When will be NCHW supported for TFLite if its to be supported ?**


Facing issues in the below code :- 

```
import numpy as np
import tensorflow as tf
input_shape = (1, 3, 3, 227)
x = tf.random.normal(input_shape)


model = tf.keras.Sequential([
  tf.keras.layers.InputLayer(input_shape=( 1, 3,227,227)),
  tf.keras.layers.Conv2D(96, 11, activation='relu', strides=(4,4), dilation_rate=(1,1), groups=1, data_format = 'channels_first')])
model.save('my_conv_model') 

converter = tf.lite.TFLiteConverter.from_keras_model(model)

tflite_model = converter.convert()

with open('convmodel.tflite', 'wb') as f:
f.write(tflite_model)
```"
49379,Distinction between categorical_crossentropy and sparse_categorical_crossentropy is not clear in the documentation,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy
https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy

## Description of issue (what needs changing):

There is documentation for these 2 losses but there is no clear explanation distinguishing each of them and when exactly a specific Loss should be used."
49378,switch_case returns wrong dataset in graph mode,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
d1 = tf.data.Dataset.from_tensor_slices([tf.ones((2,2))]*2)
d2 = tf.data.Dataset.from_tensor_slices([tf.ones((4,4))]*2)
v = tf.Variable(0, dtype=tf.int32)
f = tf.function(lambda:tf.switch_case(v.read_value(), {0:(lambda:d1), 1:(lambda:d2)}))
print(f()) # shape is (2,2)
v.assign_add(1)
print(f()) # shape also is (2,2), which is wrong and it should be (4,4)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49377,Tensorflow 2.3 GPU build failed | NCCL no such package | RHEL 7,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): rhel 7
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.4.1
- Python version: 3.6.12
- Installed using virtualenv? pip? conda?: local
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 7.3.1
- CUDA/cuDNN version: 11.0 / 8.0
- Clang Version: 5.1
- GPU model and memory: 8 X Tesla V100 32GB



**Describe the problem**
  After successfull configuration of tensorflow build we executed bazel build command , then it failed with below error ------
-----------------------------------------------------------------------------------------------------------------

ERROR: /home/NTTA/vposaniadmin/tensorflow/tensorflow/core/kernels/BUILD:4689:1: C++ compilation of rule '//tensorflow/core/kernels:sparse_split_op' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /home/NTTA/vposaniadmin/.cache/bazel/_bazel_vposaniadmin/fbb878dda2a560b32c968c38a9e718c5/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda-11.0 \
    GCC_HOST_COMPILER_PATH=/opt/rh/devtoolset-7/root/usr/bin/gcc \
    LD_LIBRARY_PATH=/opt/rh/rh-python36/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/usr/local/lib \
    PATH=/usr/local/cuda/bin:/usr/local/cuda/bin:/opt/rh/rh-python36/root/usr/bin:/home/NTTA/vposaniadmin/anaconda3/condabin:/usr/local/cuda/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/local/cuda/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/usr/local/ssl/bin:/var/lib/snapd/snap/bin:/home/NTTA/vposaniadmin/.local/bin:/home/NTTA/vposaniadmin/bin:/usr/local/ssl/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/opt/rh/rh-python36/root/usr/bin/python3 \
    PYTHON_LIB_PATH=/opt/rh/rh-python36/root/usr/lib64/python3.6/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0 \
    TF_NEED_CUDA=1 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/sparse_split_op/sparse_split_op.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/sparse_split_op/sparse_split_op.pic.o' -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/com_google_absl -iquote bazel-out/k8-opt/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/k8-opt/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/k8-opt/bin/external/eigen_archive -iquote external/gif -iquote bazel-out/k8-opt/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/k8-opt/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/k8-opt/bin/external/com_google_protobuf -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/bin/external/highwayhash -iquote external/zlib -iquote bazel-out/k8-opt/bin/external/zlib -iquote external/local_config_cuda -iquote bazel-out/k8-opt/bin/external/local_config_cuda -iquote external/local_config_tensorrt -iquote bazel-out/k8-opt/bin/external/local_config_tensorrt -Ibazel-out/k8-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -w -DAUTOLOAD_DYNAMIC_KERNELS '-std=c++14' -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions '-DGOOGLE_CUDA=1' '-DTENSORFLOW_USE_NVCC=1' '-DTENSORFLOW_USE_XLA=1' -msse3 -pthread '-DGOOGLE_CUDA=1' '-DTENSORFLOW_USE_XLA=1' -c tensorflow/core/kernels/sparse_split_op.cc -o bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/sparse_split_op/sparse_split_op.pic.o)
Execution platform: @local_execution_config_platform//:platform
In file included from ./tensorflow/core/framework/op_kernel.h:35:0,
                 from tensorflow/core/kernels/sparse_split_op.cc:19:
tensorflow/core/kernels/sparse_split_op.cc: In member function 'void tensorflow::SparseSplitOp<T>::Compute(tensorflow::OpKernelContext*)':
tensorflow/core/kernels/sparse_split_op.cc:71:34: error: 'class tensorflow::TensorShape' has no member named 'AddDimWithStatus'
                      dense_shape.AddDimWithStatus(input_shape_flat(i)));
                                  ^
./tensorflow/core/framework/op_requires.h:52:29: note: in definition of macro 'OP_REQUIRES_OK'
     ::tensorflow::Status _s(__VA_ARGS__);                    \
                             ^~~~~~~~~~~
Target //tensorflow/tools/pip_package:build_pip_package failed to build


***** Full log attached below *********


**Provide the exact sequence of commands / steps that you executed before running into the problem**
./configure

Enabled CUDA support 
and rest of them are default

bazel build  //tensorflow/tools/pip_package:build_pip_package


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

"
49375,Setting fixed seed in PreprocessingLayer leads to different results ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.4.1
- Python version: 3.8
- CUDA/cuDNN version: Driver Version: 450.102.04   CUDA Version: 11.0
- GPU model and memory: V100

**Describe the current behavior**
I'm solving a task of image to image translation and would like to apply an identical augmentation to both the input and output images. For example, I'd like to flip both images, or rotate to the same degree. 
I can use transform from `tf.image.stateless_random_` and provide same seed value to get identical results, but there is no RandomTranslation or RandomRotation transforms. So I'm trying to use layers from `tf.keras.layers.experimental.preprocessing` with fixed seed.
But 2 layers initialised with same random seed are generating different transform (see example below). Is that expected?

**Describe the expected behavior**
Initialized from same seed 2 layers should do identical transformations.

**Standalone code to reproduce the issue**
```python
from tensorflow.keras import layers
import tensorflow as tf

transform_x = layers.experimental.preprocessing.RandomTranslation(height_factor=(-0.2, 0.3), width_factor=(-0.2, 0.3), seed=2)
transform_y = layers.experimental.preprocessing.RandomTranslation(height_factor=(-0.2, 0.3), width_factor=(-0.2, 0.3), seed=2)

def is_equal(x, y):
    return tf.reduce_sum(tf.cast(tf.math.equal(x, y), tf.float32)).numpy() == 0


x = tf.random.uniform((1, 32, 32, 3)) * 255.

for _ in range(15): 
    x_t = transform_x(x, training=True)
    y_t = transform_y(x, training=True)
    print(is_equal(x_t, y_t))
```

Running this code leads to the following result:
```
False
False
False
False
False
False
False
False
False
False
```

"
49374,Segmentation fault (core dumped) - TFLite,"@tensorflow/micro  x   @tensorflow/lite

Hi !

**Describe the problem**
To read a model from official [TensorFlow source (COCO SSD MobileNet v1)](https://www.tensorflow.org/lite/examples/object_detection/overview#get_started) and perform inference with [minimal.cc](https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/contrib/lite/examples/minimal/minimal.cc), we get the error below.

**System information**
- Host OS Platform and Distribution : Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): From source (branch r1.12)
- Target platform: iMX.6 (Arm v7)

**Please provide the exact sequence of commands/steps when you ran into the problem**
```
root@analytics:~# ./minimal ssd_mobilenet_v1_1_metadata_1.tflite
minimal: /usr/src/debug/tensorflow-lite/1.0-r0/git/tensorflow/contrib/lite/tools/make/downloads/eigen/unsupported/Eigen/CXX11/src/util/
MaxSizeVector.h:84: T& EigenForTFLite::MaxSizeVector<T>::operator[](std::size_t) [with T = EigenForTFLite::RunQueue
<EigenForTFLite::StlThreadEnvironment::Task, 1024u>*; std::size_t = unsigned int]: 
Assertion `i < size_' failed. 
Segmentation fault (core dumped)
```
Do you have any idea or suggestion about why we are facing this error (because of versions, TFlite binaries or the model etc.) ?
Thank you in advance."
49373,Extremely slow data processing of tensorflow dataset using when using tf.while_loop inside a tf.function or normal function,"**System information:**
Tried the code on both - Kaggle and Colab (Both only CPU)

**Code:**
I am trying to process a dataset containing ~20,000 images, their feature vectors and their masks(image segmentation). Due to the size of data, I can't perform in-memory processing.

I load the data using this function:

```
@tf.function
def get_mask_cum_featvecs_dataset(files_paths):
  paths_ds = tf.data.Dataset.list_files(files_paths)
  ds = paths_ds.interleave(lambda tfrec_path: tf.data.TFRecordDataset(tfrec_path).map(
                                  read_tfrec, num_parallel_calls=AUTO),
                               num_parallel_calls=AUTO)
  return ds
```
The preprocessing includes getting the euclidean distances between all the images present in the dataset and an input image (fed by the user), and then dividing all the euclidean distances by the max euclidean distance out of all euclidean distances present. For this I use the below given functions:
```
@tf.function
def euclidean_dist(comp_img_features, img_featvec):
    euclidean_dist = tf.sqrt(tf.reduce_sum(tf.square(img_featvec-comp_img_features), 0))
    return euclidean_dist

@tf.function
def preprocess(img_featvec, img_mask, mask_cum_featvecs_paths):
   
    tensor_img_featvec = img_featvec
    tensor_img_mask = img_mask
    tensor_mask_cum_featvecs_paths = mask_cum_featvecs_paths
    
    # the below given statements are used when this function
    # is not wrapped by tf.function decorator:
    #tensor_img_featvec = tf.constant(img_featvec)
    #tensor_img_mask = tf.constant(img_mask)
    #tensor_mask_cum_featvecs_paths = tf.constant(mask_cum_featvecs_paths)
    
    compare_img_ds = get_mask_cum_featvecs_dataset(tensor_mask_cum_featvecs_paths)
    
    get_img_euclidean_dists = partial(euclidean_dist, img_featvec=tensor_img_featvec)
    
    print(""Calculating Euclidean Distances......"")
    features_n_eucl_ds = compare_img_ds.map(lambda image_name, image, featvec, mask: (image_name, image, featvec, mask,
                                                                           get_img_euclidean_dists(featvec)),
                                 num_parallel_calls=AUTO)


    print(""Finding Maximum Euclidean Distance........"")
    num_of_loops = 2
    eucl_val_ds = features_n_eucl_ds.map(lambda image_name, image, featvec, mask, eucl_val: eucl_val,
                                         num_parallel_calls=AUTO)
   
    def dataset_reduce_max(ds, i):
        ds = ds.batch(5000)
        ds = ds.map(lambda eucl_vals: tf.math.reduce_max(eucl_vals),
                    num_parallel_calls=AUTO)
        i += 1
        return ds, i
    
    def loop_cond(ds, i):
        return tf.less(i, num_of_loops)
    
    eucl_val_ds, _ = tf.while_loop(loop_cond,
                                   dataset_reduce_max,
                                   [eucl_val_ds, tf.constant(0)])
    
    max_eucl_dist = tf.constant(0, dtype=tf.float32)

    #---------(I)---------#
    for item in eucl_val_ds.take(1):
        max_eucl_dist = item

    ratio_eucl_ds = features_n_eucl_ds.map(
                        lambda image_name, image, featvec, mask, eucl_val: (image_name,
                                                                            image,
                                                                            featvec,                                                                                             
                                                                            mask,                                                                                            
                                                                            eucl_val/max_eucl_dist),
                                           num_parallel_calls=AUTO)


    return ratio_eucl_ds #----------(II)-----------#

```
There is no in-built function for finding the maximum element in a particular datastream in tensorflow dataset (here, datastreams = image_names, image, featvecs, masks, eucl_dists) To find the maximum the euclidean distance, I created a separate tf.dataset containing euclidean distances and I used dataset reduction strategy. I created batches of size 5000, and return the maximum element present in them. Using this strategy, I can effectively get the maximum euclidean distance in 2 iterations.

**The problem:**
When I use tf.function decorator then the entire function will execute very fast and then get stuck at ""return ratio_eucl_ds""(I). If I don't use the tf.function decorator then the function gets stuck at for-loop(II). It takes ~12 mins to execute the code. When I randomly put any value in ""max_eucl_dist"", then the preprocess function executes seamlessly. Hence, I guess the problem is with the way I am trying to extract the value for ""max_eucl_dist"".

Colab Link for reproducing the issue:
https://colab.research.google.com/drive/1VFEDdfImcchMYNgA68Bi989EGiHiQ2rC?usp=sharing
The notebook also contains model building code (required to get the feature vector and mask of the input image) and also two data processing functions, a tf.function decorated function and other not decorated.

**Current Behaviour:**
Not using tf.function decorator - 
```
CPU times: user 9min 35s, sys: 16min 2s, total: 25min 37s
Wall time: 13min 15s
```
Using tf.function decorator - 
```
CPU times: user 6min 28s, sys: 7min 42s, total: 14min 11s
Wall time: 9min 26s
```

But, when I randomly or manually initialize the ""max_eucl_dist"", then the processing the works seamlessly.
Not using tf.function decorator - 
```
CPU times: user 1.33 s, sys: 1.83 ms, total: 1.34 s
Wall time: 6.36 s
```
Using tf.function decorator -
```
CPU times: user 1.24 s, sys: 22 ms, total: 1.27 s
Wall time: 6.16 s
```
"
49372,Relu fake quant after Quantification Aware Training ,"hi

when  do  Quantification Aware Training with tensorflow-model-optimization, for Relu op, 
after QAT, and found the min value of fake quant node is not zero ,and a constant value.

so what reason cause that , thanks."
49371,How to solve the INFO information: INFO:absl:resolver HttpCompressedFileResolver does not support the provided handle. INFO:absl:resolver GcsCompressedFileResolver does not support the provided handle. INFO:absl:resolver HttpUncompressedFileResolver does not support the provided handle.,"> INFO:absl:resolver HttpCompressedFileResolver does not support the provided handle.
> INFO:absl:resolver GcsCompressedFileResolver does not support the provided handle.
> INFO:absl:resolver HttpUncompressedFileResolver does not support the provided handle.

When I train my text classification model, there always comes the info above. I do not know where they come from ?
Any solutions to ban these ?"
49370,tflite_runtime interpreter produces strange results when warmup is done with empty images,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): YOCTO Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
I have an application that runs on an embedded system. The application acquires images from a camera and performs predictions using a custom quantized neural network and the tflite_runtime interpreter. The applications and the model works fine with good accuracy, but the first inferences are very slow because of the warmup time needed by the interpreter. For this reason I tried to perform the warmup before the application starts, by feeding the interpreter some empty images (numpy.zeros). However, this causes subsequent inferences with real images to produce almost constant (and wrong) predictions.

**Describe the expected behavior**
I expect the interpreter to perform well even if the warmup is done with empty images

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): no - Briefly describe your candidate solution
(if contributing): 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tflite_runtime.interpreter as tflite
import numpy as np
import cv2

def classify(interpreter, input_details, output_details, img):
	input_shape = input_details[0]['shape']
	img = cv2.resize(img, (input_shape[2], input_shape[1]))
	img = (img/255.0).astype(np.float32)
	img = np.expand_dims(img, 0)
	interpreter.set_tensor(input_details[0]['index'], img)	
	interpreter.invoke()			
	output = interpreter.get_tensor(output_details[0]['index'])
	output = np.squeeze(output)
        return output


interpreter = tflite.Interpreter('mymodel.tflite')
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
input_shape = input_details[0]['shape']

warmup_img = np.zeros(input_shape)
_ = classify(interpreter, input_details, output_details, warmup_img)

cap = cv2.VideoCapture(0)

while cap.isOpened():
      _, frame = cap.read()
      print(classify(interpreter, input_details, output_details, frame))
```

	

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49369,Need clarity on metrics reported in extras field on using run_op_benchmark,"
## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/test/Benchmark

## Description of issue (what needs changing):

I ran a simple tf.linalg.matvec operation using the benchmark framework and got different metrics in the extras field. I could not understand the difference between the keys in the extra field - allocator_max_num_bytes_GPU_0_bfc and allocator_max_num_bytes_gpu_host_bfc.


More  description of these metrics would help users understand what metrics are actually being  reported."
49368,"How about adding a note of `_get_optimizer` in ""Customize what happens in Model.fit"" guide?","## URL(s) with the issue:

https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit#wrapping_up_an_end-to-end_gan_example

## Description of issue (what needs changing):

### Clear description

When using Keras mixed-precision API and overriding `tf.keras.Model.compile` function like the above guide, training loss cannot converge easily, because the optimizers are not wrapped in `LossScaleOptimizer`. I found it can be fixed using `tf.keras.Model._get_optimizer` function like below.

https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/keras/engine/training.py#L479-L586

I think it would be much better to add a note like ``it is recommended to wrap optimizer objects using `self._get_optimizer` when using Keras mixed-precision API`` in that guide.
"
49367,benchmark_model performance,"I have a tflite quantizd model(qat). 

To benchmark it's performance with device rk3399(arm), I build a binary benchmark_model form  source, command is : ./tensorflow/lite/tools/make/build_aarch64_lib.sh.

I also download a pre-build binary(linux_aarch64) here: https://www.tensorflow.org/lite/performance/measurement. 

Then I have two excutable binaries,  but the tflite models'performance  has a large difference. 

With the binary I build from source, The performance is 74ms, but with the downloaded binary, the performance is 55ms.

I am confused what's wrong with it. Does the command I build form source wrong?

Tensorflow commtid d99c821817e"
49366,Undefined symbol zungqr_,"Traceback (most recent call last):
  File ""real_time_object_detection.py"", line 2, in <module>
    from imutils.video import VideoStream
  File ""/var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/imutils/__init__.py"", line 8, in <module>
    from .convenience import translate
  File ""/var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/imutils/convenience.py"", line 5, in <module>
    import numpy as np
  File ""/var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/numpy/__init__.py"", line 148, in <module>
    from . import lib
  File ""/var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/numpy/lib/__init__.py"", line 25, in <module>
    from .index_tricks import *
  File ""/var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/numpy/lib/index_tricks.py"", line 12, in <module>
    import numpy.matrixlib as matrixlib
  File ""/var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/numpy/matrixlib/__init__.py"", line 4, in <module>
    from .defmatrix import *
  File ""/var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/numpy/matrixlib/defmatrix.py"", line 11, in <module>
    from numpy.linalg import matrix_power
  File ""/var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/numpy/linalg/__init__.py"", line 73, in <module>
    from .linalg import *
  File ""/var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/numpy/linalg/linalg.py"", line 33, in <module>
    from numpy.linalg import lapack_lite, _umath_linalg
ImportError: /var/rootdirs/home/root/tflite/tflite-env/lib/python3.8/site-packages/numpy/linalg/lapack_lite.cpython-38-arm-linux-gnueabi.so: undefined symbol: zungqr_
"
49365,How to configure tensorflow2.x in Qt creator?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:no
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:18.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:source
-   **TensorFlow version (use command below)**:tensorflow2.4.1
-   **Python version**:python3.6
-   **Bazel version (if compiling from source)**:3.1.0
-   **GCC/Compiler version (if compiling from source)**:7.5.0
-   **CUDA/cuDNN version**:no
-   **GPU model and memory**:no
-   **Exact command to reproduce**:N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
49309,tensorflow error code 3221225501,"windows7 64bit 
what is the problem ?

Python 3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AM
D64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""C:\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", l
ine 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed with error code 3221225501 while importing _pywrap_
tensorflow_internal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Python38\lib\site-packages\tensorflow\__init__.py"", line 41, in <modu
le>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Python38\lib\site-packages\tensorflow\python\__init__.py"", line 39, i
n <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", l
ine 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", l
ine 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed with error code 3221225501 while importing _pywrap_
tensorflow_internal


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
49306,-DCMAKE_INSTALL_PREFIX has no effect when building with CMAKE,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution = Linux Ubuntu 20.04:
- TensorFlow installed from (source or binary): CMake efficient binary generation
- TensorFlow version: latest
- Python version: python 3.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 11.2
- GPU model and memory: Quadro RTX 4000 - 8GB



When following the instructions to build Tensorflow Lite as a cmake package with libraries and header files, it does not install anything to the install prefix. I followed the instructions here:

https://www.tensorflow.org/lite/guide/build_cmake 


Is there a command I am missing. After successful configuration and build, I try to run:

```
cmake --install . 

```

All that happens is the printout statement:
```
-- Install configuration: ""Release""
```

I am trying to install tflite as a cmake package that other projects can use the library and header files. However, it needs to be in a specific install location. Currently I am creating a Cmake project that uses ""ExternalProject"" to clone, configure, build, and install tensorflowlite. The only issue is that it does not install to the location I need it to even when specifying -DCMAKE_INSTALL_PREFIX.

Previously I used bazel to build from source, copy all the files, and also generate a cmake package configuration. However, I want to be able to build the entire package with just CMakelists.txt. I would appreciate any help on how to have the libraries and include files installed into a single location throuh Cmake. 

Thank you so much! I am sure a lot of users would really like this feature, especially in the robotics community.


"
49304,tf.data.experimental.service does not reach optimal consumption rate,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Using tensorflow/tensorflow:2.4.1-gpu docker image
- GPU model and memory: nvidia v100 32GB

Current behavior:
Training with `dataset = dataset.take(1).cache().repeat()` is 20% faster(iterations per sec) vs. training with the tf.data.experimental.service. Increasing the number of workers does not increase the number of iteration per second.
When increasing the number of workers, I can see that each worker is sending less data per time, but the data received in the consumer per time stays the same(126 MB/s, which is only 10% of the network in bandwidth of the consumer). 

I have tried setting the `max_outstanding_requests` [distributed function](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service/distribute) which did not seem to have any effect. 

How can I optimize the data service?
"
49302,Cannot import tensorflow: cannot import name 'LayerNormalization' from 'tensorflow.python.keras.layers.normalization,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version: tensorflow 2.5.0
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: GCC 9.3.0
- GPU model and memory: nvidia 940MX with 4GB memory



**
but i failed to install it. After then that i am unable to import tensorflow even after i reinstalled tensorflow i get import error as:
 
>>> import tensorflow
2021-05-19 19:21:42.165198: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib
2021-05-19 19:21:42.165227: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/keshav/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/home/keshav/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py"", line 48, in <module>
    from tensorflow.python import keras
  File ""/home/keshav/.local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py"", line 25, in <module>
    from tensorflow.python.keras import models
  File ""/home/keshav/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py"", line 20, in <module>
    from tensorflow.python.keras import metrics as metrics_module
  File ""/home/keshav/.local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py"", line 37, in <module>
    from tensorflow.python.keras import activations
  File ""/home/keshav/.local/lib/python3.8/site-packages/tensorflow/python/keras/activations.py"", line 18, in <module>
    from tensorflow.python.keras.layers import advanced_activations
  File ""/home/keshav/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py"", line 146, in <module>
    from tensorflow.python.keras.layers.normalization import LayerNormalization
ImportError: cannot import name 'LayerNormalization' from 'tensorflow.python.keras.layers.normalization' (/home/keshav/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization/__init__.py)

**

***i tried to install tensorflow on gpu and followed steps from following link and run the mentioned commands:
https://towardsdatascience.com/installing-tensorflow-gpu-in-ubuntu-20-04-4ee3ca4cb75d
$ sudo apt install nvidia-cuda-toolkit
$ tar -xvzf cudnn-10.1-linux-x64-v7.6.5.32.tgz
$ sudo cp cuda/include/cudnn.h /usr/lib/cuda/include/
$ sudo cp cuda/lib64/libcudnn* /usr/lib/cuda/lib64/
$ sudo chmod a+r /usr/lib/cuda/include/cudnn.h /usr/lib/cuda/lib64/libcudnn*
$ echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
$ echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/include:$LD_LIBRARY_PATH' >> ~/.bashrc
$ source ~/.bashrc
$ pip install tensorflow==2.2.0

after i failed to run tensorflow by this method i tried to revert changes that i made during installation so i tried following commands
sudo apt-get purge nvidia*
sudo apt-get autoremove
sudo apt-get autoclean
sudo rm -rf /usr/local/cuda*

and deleted cuda folder from usr/lib/cuda
**
now i am unable to import tensorflow please help as i am short on time to complete my collage project

thank you 
"
49301,issue about feature_column with empty string feature,"Hi,
I am using tf1.15 with Py3.6.
Below is part of my code,
```
feature_description = {
    ""city"": FixedLenFeature(dtype=tf.string, shape=[], default_value="""")
}

feature_columns = tf.feature_column.embedding_column(
                tf.feature_column.categorical_column_with_hash_bucket(
                   ""city"", hash_bucket_size=1  # 1 just for debug
                ),
                dimension=2
)
```
And I generated my train samples with tfrecord format.  If some of my train samples do not contains the key ""city"", when I parse them in training, they will be filled the ""city"" key with value """", right? So I can train my model successfully.
But when I inference with the exported model, if the data to predict does not contain ""city"", should I feed it with """", or just left it empty? I check both of them, I get different results. If i left it empty, the city will get zero embedding [0,0], while non-zeros embedding for city with """". Is this a bug, or which is the correct way to set city value?"
49299,An idea of  `tf.one_hot`,"According to my personal experience , the mechanism of  `tf.one_hot` is returning the value of `0,1` that match the index number as in [one_hot](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/one_hot). But it might cause an unforeseen problem that can not handle the input larger than depth like following code snippets described. What it be better if raise a warning or alert that telling the user what happend inside.

### How to reproduce
Environment: `tensorflow=1.15`
```
# init
batch_size = 1
seq_len = 4
vocab_size = 2
data_vocab_size = 6

token_type_ids = tf.random.uniform([batch_size, seq_len], minval=0, maxval=data_vocab_size, dtype=tf.dtypes.int32)
# calculate
flat_token_type_ids = tf.reshape(token_type_ids, [-1])
one_hot_ids = tf.one_hot(flat_token_type_ids, depth=vocab_size)
with tf.Session() as sess:
    np_one_hot_ids, np_flat_token_type_ids = sess.run([one_hot_ids, flat_token_type_ids])
    print(np_flat_token_type_ids)
    print(np_one_hot_ids)
```
>np_flat_token_type_ids: [1 5 3 0]
np_one_hot_ids:  
[[0. 1.]
 [0. 0.]
 [0. 0.]
 [1. 0.]]
"
49298,Superflous keras-nightly dependency?,"**Describe the problem**

TF 2.5.0 added a dependency on keras-nightly for some reason with https://github.com/tensorflow/tensorflow/commit/d171d94d899cc73e18bd8b2b11b5c320ea7aac2c

However at no place there is an actual `import keras` or similar in the TF code, hence that package is completely optional at least or superflous it seems.

What was the reasoning for including that in the *required* dependencies of TF? Can it be removed?

I'd guess usually people use tf.keras or install TF then keras (for some reason), i.e. keras depends on TF (more or less) but now there is a dependency cycle."
49297,013057005309211,"One master `const int left_x_index = in_x > 0.0 ? floorf(in_x) : 0;` so I think that we could close this

https://github.com/tensorflow/tensorflow/blob/3fd3ae1fbb10961dd1aa6805280674c781fd4609/tensorflow/core/kernels/image/resize_bilinear_op_gpu.cu.cc#L60-L63
https://github.com/tensorflow/tensorflow/issues/38389#issuecomment-844015731
_Originally posted by @bhack in https://github.com/tensorflow/tensorflow/issues/38389#issuecomment-844015731_"
49295,tensorflow 2.5.0 cuda and cudnn version,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:

[https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source)
[https://github.com/tensorflow/docs/blob/master/site/en/install/source.md](https://github.com/tensorflow/docs/blob/master/site/en/install/source.md)

## Description of issue (what needs changing):

### Clear description
The document shows : 
<table>
<tr><th>Version</th><th>Python version</th><th>Compiler</th><th>Build tools</th><th>cuDNN</th><th>CUDA</th></tr>
<tr><td>tensorflow-2.5.0</td><td>3.6-3.9</td><td>GCC 7.3.1</td><td>Bazel 3.1.0</td><td>8.0</td><td>11.0</td></tr>
</table>

But according to [https://github.com/tensorflow/tensorflow/releases/tag/v2.5.0](https://github.com/tensorflow/tensorflow/releases/tag/v2.5.0)


```
TensorFlow pip packages are now built with CUDA11.2 and cuDNN 8.1.0
```
This table should be changed to : 
<table>
<tr><th>Version</th><th>Python version</th><th>Compiler</th><th>Build tools</th><th>cuDNN</th><th>CUDA</th></tr>
<tr><td>tensorflow-2.5.0</td><td>3.6-3.9</td><td>GCC 7.3.1</td><td>Bazel 3.1.0</td><td>8.1</td><td>11.2</td></tr>
</table>
"
49294,TF Import Error ,"Hello Everyone

While importing Tensorflow, I am getting an error which is attached here. 

But next time importing the TensorFlow, it works well.

can you please comment on it.

![err2](https://user-images.githubusercontent.com/61820415/118755553-b3680800-b886-11eb-8147-da9f599c39a9.JPG)


"
49293,tflite::InterpreterBuilder::BuildLocalIndexToRegistrationMapping() SEGV_ACCERR,"Hardware Model: iPhone8 - 12
Process: Demo [2110]
Version: 9.10.0(9.10.0)
Code Type: ARM-64 (Native)
Parent Process:  [1]
OS Version: iPhone OS 13.6 (17G68) (all version of IOS)
Report Version: 104

Exception Type: SIGSEGV
Exception Codes: SEGV_ACCERR at 0x00000001238278f8
Crashed Thread: 0

Thread 0 Crashed: 
0  Demo                     0x00000001021dec6c tflite::InterpreterBuilder::BuildLocalIndexToRegistrationMapping() +  108
1  Demo                     0x00000001021e0114 tflite::InterpreterBuilder::operator()(std::__1::unique_ptr<tflite::Interpreter, std::__1::default_delete<tflite::Interpreter> >*, int) +  104
2  Demo                     0x0000000101f1a918 mdw::LiteModel::Initialize(char const*, unsigned long, bool, mdw::Config const&) +  320"
49291,Hola desde hace días presento un problema con tensorflow lo he intentando todo he leído cada guía y parece siempre llego al mismo punto ,"como se ve en la siguiente imagen mi problema es que al parecer 
![image](https://user-images.githubusercontent.com/67806145/118743784-aad8e880-b818-11eb-952a-fc4ac82d02f6.png)
"
49276,infinite dataset while it is actually finite from tf.data.experimental.choose_from_datasets,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip3 install
- TensorFlow version (use command below): 2.5.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 11.3 cudnn 8.2.0
- GPU model and memory: NVIDIA TITAN V 12 GB

**Describe the current behavior**
For datasets created by tf.data.experimental.choose_from_datasets
when I do len(dataset), it always say it is infinite but when I iterate it, it is actually finite and completely functional
The problem with this is that when I want to work with keras model like using model.evaluate with this dataset, it gives error 

**Standalone code to reproduce the issue**

```
import tensorflow as tf
datasets = [tf.data.Dataset.from_tensors(""foo"").repeat(),
            tf.data.Dataset.from_tensors(""bar"").repeat(),
            tf.data.Dataset.from_tensors(""baz"").repeat()]

choice_dataset = tf.data.Dataset.range(3).repeat(3)

result = tf.data.experimental.choose_from_datasets(datasets, choice_dataset)

len(result)
#TypeError: dataset length is infinite.

result.cardinality()
#<tf.Tensor: shape=(), dtype=int64, numpy=-1>

for i in result:
  print(i)
#finite and works fine

model.evaluate(result,verbose=0)
#ValueError: When providing an infinite dataset, you must specify the number of steps to run (if you did not intend to create an infinite dataset, make sure to not call `repeat()` on the dataset).
#i.e. no longer works with keras model


```
"
49269,TFLite GPU OpenGL delegate wrong results with NewConvolution1x1NodeShader,"- TensorFlow version (use command below): master, happens with all releases I got (at least since 2.3)
- GPU model and memory: Jetson TX2 and also Titan RTX

I am getting wrong results using SENets 1x1 convolutions in TFLite using GPU OpenGL delegate. Results are good with CPU delegate and GPU->OpenCL delegate. I believe there is a bug in [NewConvolution1x1NodeShader ](https://github.com/tensorflow/tensorflow/blob/c91043826234f4c4366bde805a504b55a46f94a5/tensorflow/lite/delegates/gpu/gl/kernels/conv.cc#L166)function.

I am sorry but I dont understand the syntax of the test code to create an official test case myself. However, my sample input is (BHWC) [1, ,1, 1, 72] and my sample output of keras layer Conv2D is [1,1,1,24] - with bias, thus the convolution weights are 24x1x1x72. I believe the exact values are not important and the bug will make itself apparent with any values. I did not test yet with smaller inputs, the code seems to break the convolution into 4-float chunks. If there is someone brave enough to create such a test case into [the test code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/gl/kernels/conv_test.cc
) it would be much appreciated.

The main difference as of my problem with regards to the existing test case is that both the convolution kernel and the input are WxH=1x1, whereas in the present test case the input is WxH=2x1.




"
49268,M1 chip,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
49267,"AttributeError: Layer genmodel is not connected, no input to return.","I want to train a custom GAN model, for which below is the code:
```
import tensorflow as tf
import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm
from imageio import imwrite


class Localization(tf.keras.layers.Layer):
    def __init__(self):
        super(Localization, self).__init__()
        self.bpool1 = tf.keras.layers.MaxPool2D()
        self.bpool2 = tf.keras.layers.MaxPool2D()
        self.bpool3 = tf.keras.layers.MaxPool2D()
        self.bpool4 = tf.keras.layers.MaxPool2D()

        self.mpool1 = tf.keras.layers.MaxPool2D()
        self.mpool2 = tf.keras.layers.MaxPool2D()
        self.mpool3 = tf.keras.layers.MaxPool2D()
        self.mpool4 = tf.keras.layers.MaxPool2D()

        self.cpool1 = tf.keras.layers.MaxPool2D()
        self.cpool2 = tf.keras.layers.MaxPool2D()
        self.cpool3 = tf.keras.layers.MaxPool2D()
        self.cpool4 = tf.keras.layers.MaxPool2D()

        self.bconv1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
        self.bconv2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
        self.bconv3 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
        self.bconv4 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
        self.bconv5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
        self.bconv6 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
        self.bconv7 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
        self.bconv8 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')

        self.mconv1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
        self.mconv2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
        self.mconv3 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
        self.mconv4 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
        self.mconv5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
        self.mconv6 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
        self.mconv7 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
        self.mconv8 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')

        self.cconv1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
        self.cconv2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
        self.cconv3 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
        self.cconv4 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
        self.cconv5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
        self.cconv6 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
        self.cconv7 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
        self.cconv8 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')

        self.concatenate1 = tf.keras.layers.concatenate
        self.concatenate2 = tf.keras.layers.concatenate
        self.tconv1 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')
        self.tpool1 = tf.keras.layers.MaxPool2D()
        self.tconv2 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')
        self.tpool2 = tf.keras.layers.MaxPool2D()
        self.flatten = tf.keras.layers.Flatten()
        self.fc0 = tf.keras.layers.Dense(100, activation='relu')
        self.fc1 = tf.keras.layers.Dense(20, activation='relu')
        self.fc2 = tf.keras.layers.Dense(6, activation=None, bias_initializer=tf.keras.initializers.constant(
            [1.0, 0.0, 0.0, 0.0, 1.0, 0.0]), kernel_initializer='zeros',  activity_regularizer=tf.keras.regularizers.l2(1e-2))

    def build(self, input_shape):
        print(""Building Localization Network with input shape:"", input_shape)

    def compute_output_shape(self, input_shape):
        return [None, 6]

    def call(self, inputs):
        mask, fg, bg, composite = inputs
        xm = self.concatenate1([fg, mask])
        xm = self.mconv1(xm)
        xm = self.mconv2(xm)
        xm = self.mpool1(xm)

        xm = self.mconv3(xm)
        xm = self.mconv4(xm)
        xm = self.mpool2(xm)

        xm = self.mconv5(xm)
        xm = self.mconv6(xm)
        xm = self.mpool3(xm)

        xm = self.mconv7(xm)
        xm = self.mconv8(xm)
        xm = self.mpool4(xm)

        xbg = self.bconv1(bg)
        xbg = self.bconv2(xbg)
        xbg = self.bpool1(xbg)

        xbg = self.bconv3(xbg)
        xbg = self.bconv4(xbg)
        xbg = self.bpool2(xbg)

        xbg = self.bconv5(xbg)
        xbg = self.bconv6(xbg)
        xbg = self.bpool3(xbg)

        xbg = self.bconv7(xbg)
        xbg = self.bconv8(xbg)
        xbg = self.bpool4(xbg)


        xc = self.cconv1(composite)
        xc = self.cconv2(xc)
        xc = self.cpool1(xc)

        xc = self.cconv3(xc)
        xc = self.cconv4(xc)
        xc = self.cpool2(xc)

        xc = self.cconv5(xc)
        xc = self.cconv6(xc)
        xc = self.cpool3(xc)

        xc = self.cconv7(xc)
        xc = self.cconv8(xc)
        xc = self.cpool4(xc)

        x = self.concatenate2((xbg, xm, xc))
        x = self.tconv1(x)
        x = self.tpool1(x)
        x = self.tconv2(x)
        x = self.tpool1(x)
        x = self.flatten(x)
        x = self.fc0(x)
        x = self.fc1(x)
        theta = self.fc2(x)
        theta = tf.keras.layers.Reshape((2, 3))(theta)
        return theta


class BilinearInterpolation(tf.keras.layers.Layer):
    def __init__(self, height=320, width=320):
        super(BilinearInterpolation, self).__init__()
        self.height = height
        self.width = width

    def compute_output_shape(self, input_shape):
        return [None, self.height, self.width, 1]

    def get_config(self):
        return {
            'height': self.height,
            'width': self.width,
        }

    def build(self, input_shape):
        print(""Building Bilinear Interpolation Layer with input shape:"", input_shape)

    def advance_indexing(self, inputs, x, y):
        '''
        Numpy like advance indexing is not supported in tensorflow, hence, this function is a hack around the same method
        '''
        shape = tf.shape(inputs)
        batch_size, _, _ = shape[0], shape[1], shape[2]

        batch_idx = tf.range(0, batch_size)
        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))
        b = tf.tile(batch_idx, (1, self.height, self.width))
        indices = tf.stack([b, y, x], 3)
        return tf.gather_nd(inputs, indices)

    def call(self, inputs):
        images, theta = inputs
        homogenous_coordinates = self.grid_generator(batch=tf.shape(images)[0])
        return self.interpolate(images, homogenous_coordinates, theta)

    def grid_generator(self, batch):
        x = tf.linspace(-1, 1, self.width)
        y = tf.linspace(-1, 1, self.height)

        xx, yy = tf.meshgrid(x, y)
        xx = tf.reshape(xx, (-1,))
        yy = tf.reshape(yy, (-1,))
        homogenous_coordinates = tf.stack([xx, yy, tf.ones_like(xx)])
        homogenous_coordinates = tf.expand_dims(homogenous_coordinates, axis=0)
        homogenous_coordinates = tf.tile(homogenous_coordinates, [batch, 1, 1])
        homogenous_coordinates = tf.cast(homogenous_coordinates, dtype=tf.float32)
        return homogenous_coordinates

    def interpolate(self, images, homogenous_coordinates, theta):
        with tf.name_scope(""Transformation""):
            transformed = tf.matmul(theta, homogenous_coordinates)
            transformed = tf.transpose(transformed, perm=[0, 2, 1])
            transformed = tf.reshape(transformed, [-1, self.height, self.width, 2])

            x_transformed = transformed[:, :, :, 0]
            y_transformed = transformed[:, :, :, 1]

            x = ((x_transformed + 1.) * tf.cast(self.width, dtype=tf.float32)) * 0.5
            y = ((y_transformed + 1.) * tf.cast(self.height, dtype=tf.float32)) * 0.5

        with tf.name_scope(""VariableCasting""):
            x0 = tf.cast(tf.math.floor(x), dtype=tf.int32)
            x1 = x0 + 1
            y0 = tf.cast(tf.math.floor(y), dtype=tf.int32)
            y1 = y0 + 1

            x0 = tf.clip_by_value(x0, 0, self.width - 1)
            x1 = tf.clip_by_value(x1, 0, self.width - 1)
            y0 = tf.clip_by_value(y0, 0, self.height - 1)
            y1 = tf.clip_by_value(y1, 0, self.height - 1)
            x = tf.clip_by_value(x, 0, tf.cast(self.width, dtype=tf.float32) - 1.0)
            y = tf.clip_by_value(y, 0, tf.cast(self.height, dtype=tf.float32) - 1)

        with tf.name_scope(""AdvanceIndexing""):
            Ia = self.advance_indexing(images, x0, y0)
            Ib = self.advance_indexing(images, x0, y1)
            Ic = self.advance_indexing(images, x1, y0)
            Id = self.advance_indexing(images, x1, y1)

        with tf.name_scope(""Interpolation""):
            x0 = tf.cast(x0, dtype=tf.float32)
            x1 = tf.cast(x1, dtype=tf.float32)
            y0 = tf.cast(y0, dtype=tf.float32)
            y1 = tf.cast(y1, dtype=tf.float32)

            wa = (x1 - x) * (y1 - y)
            wb = (x1 - x) * (y - y0)
            wc = (x - x0) * (y1 - y)
            wd = (x - x0) * (y - y0)

            wa = tf.expand_dims(wa, axis=3)
            wb = tf.expand_dims(wb, axis=3)
            wc = tf.expand_dims(wc, axis=3)
            wd = tf.expand_dims(wd, axis=3)

        return tf.math.add_n([wa * Ia + wb * Ib + wc * Ic + wd * Id])


class Composition(tf.keras.layers.Layer):
    def __init__(self):
        super(Composition, self).__init__()

    def build(self, input_shape):
        print(""Building Composition Network with input shape:"", input_shape)

    def compute_output_shape(self, input_shape):
        return input_shape

    def call(self, inputs):
        mask, fg, bg = inputs
        multiples = tf.constant([1, 1, 1, 3], tf.int32)
        mask_mod = tf.tile(mask, multiples)
        bg_mod = tf.keras.layers.Multiply()([bg, 1 - mask_mod])
        fg_mod = tf.keras.layers.Multiply()([fg, mask_mod])
        composite_image = tf.keras.layers.Add()([bg_mod, fg_mod])

        return composite_image


class Genmodel(tf.keras.Model):
    def __init__(self, bg_shape, iterations):
        super(Genmodel, self).__init__()
        self.bg_shape = bg_shape
        self.iterations = iterations
        self.localize = Localization()
        self.bilinearintp1 = BilinearInterpolation(height=self.bg_shape[0], width=self.bg_shape[1])
        self.bilinearintp2 = BilinearInterpolation(height=self.bg_shape[0], width=self.bg_shape[1])
        self.compose1 = Composition()
        self.compose2 = Composition()

    def call(self, inputs):
        mask, fg, bg = inputs
        xmask = mask
        xfg = fg
        composite = self.compose1([xmask, xfg, bg])
        for i in range(self.iterations):
            theta = self.localize([xmask, xfg, bg, composite])
            xmask = self.bilinearintp1([xmask, theta])
            xfg = self.bilinearintp2([xfg, theta])
            composite = self.compose2([xmask, xfg, bg])
        return composite


def disc_model(input_shape):
    inp = tf.keras.layers.Input(shape=input_shape)
    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same')(inp)
    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)

    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)
    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)

    x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same')(x)
    x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)

    x = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same')(x)
    x = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)

    x = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), padding='same')(x)
    x = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)

    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(25)(x)
    x = tf.keras.layers.LeakyReLU()(x)
    out = tf.keras.layers.Dense(1, activation='sigmoid')(x)
    return tf.keras.models.Model(inputs=inp, outputs=out, name='discriminator')


def stgan2(disc, gen):
    disc.trainable = False
    inp = gen.input
    x = gen(inp)
    out = disc(x)
    model = tf.keras.Model(inputs=inp, outputs=out)

    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),
                  metrics=['accuracy'])
    return model


gen = Genmodel(bg_shape=(420, 640, 3), iterations=5)
dis = disc_model(input_shape=(420, 640, 3))
dis.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])
gan = stgan2(dis, gen)
```
Upon executing this code in google colab I am getting this error:
AttributeError: Layer genmodel is not connected, no input to return."
49266,Running TFLite inference on single thread using XNNPACK and Flex delegate,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 8
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: x86_64
- TensorFlow installed from: source
- TensorFlow version (use command below): 2.3.2
- Bazel version (if compiling from source): 3.7.1
- GCC/Compiler version (if compiling from source): 8.3.1
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A, 32GB RAM

I am interested in running TFLite inference on single thread. My model uses a NonMaxSuppression layer for which I built TFLite with flex delegate dependency. I also included xnnpack delegate which runs inference on single thread by default ([link](https://fossies.org/linux/tensorflow/tensorflow/lite/delegates/xnnpack/README.md), [link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/README.md))

My interpreter is defined as follows:
```
tflite::ops::builtin::BuiltinOpResolver builtins;
std::unique_ptr<tflite::Interpreter> interpreter;
tflite::InterpreterBuilder(*flat_buffer_model, builtins)(&interpreter, 1);
interpreter->SetNumThreads(1);
thread_interpreter.interpreter_.reset(interpreter.release());
```

where thread_interpreter is an object of type :
```
struct ThreadInterpreter {
	explicit ThreadInterpreter() :
		interpreter_(nullptr),
		input_tensor(nullptr),
		output_tensor(){}

	boost::shared_ptr<tflite::Interpreter> interpreter_;
	TfLiteTensor* input_tensor;
	std::vector<TfLiteTensor*> output_tensor;
};
```

The program runs inference on few images and crashes. And here is the output of gdb:
```
(gdb) bt
#0  0x00007ffff5e314c0 in __pthread_timedjoin_ex () from /lib64/libpthread.so.0
#1  0x00007ffff3686661 in ?? ()
   from /home/smaniyar/Projects/test_project/target/linux-x86-64/bin/validation_package/11/lib/libtensorflowlite.so
#2  0x00007ffff3696137 in ?? ()
   from /home/smaniyar/Projects/test_project/target/linux-x86-64/bin/validation_package/11/lib/libtensorflowlite.so
#3  0x00007fffeb67dd69 in ?? ()
   from /home/smaniyar/Projects/test_project/target/linux-x86-64/bin/validation_package/11/lib/libtensorflowlite.so
#4  0x00007fffeb67e1b1 in ?? ()
   from /home/smaniyar/Projects/test_project/target/linux-x86-64/bin/validation_package/11/lib/libtensorflowlite.so
#5  0x00007fffeb640353 in tflite::flex::DelegateData::~DelegateData() ()
   from /home/smaniyar/Projects/test_project/target/linux-x86-64/bin/validation_package/11/lib/libtensorflowlite.so
#6  0x00007fffeb639134 in tflite::FlexDelegate::~FlexDelegate() ()
   from /home/smaniyar/Projects/test_project/target/linux-x86-64/bin/validation_package/11/lib/libtensorflowlite.so
#7  0x00007fffee762e3f in tflite::TfLiteDelegateFactory::DeleteSimpleDelegate(TfLiteDelegate*) ()
   from /home/smaniyar/Projects/test_project/target/linux-x86-64/bin/validation_package/11/lib/libtensorflowlite.so
#8  0x00007fffeb61799e in tflite::impl::Interpreter::~Interpreter() ()
   from /home/smaniyar/Projects/test_project/target/linux-x86-64/bin/validation_package/11/lib/libtensorflowlite.so
#9  0x00007ffff72bbdc7 in boost::checked_delete<tflite::impl::Interpreter> (x=0xe83960)
    at /home/smaniyar/Projects/test_project/vendor/boost/boost/checked_delete.hpp:34
#10 0x00007ffff72bc998 in boost::detail::sp_counted_impl_p<tflite::impl::Interpreter>::dispose (this=0x129b190)
    at /home/smaniyar/Projects/test_project/vendor/boost/boost/smart_ptr/detail/sp_counted_impl.hpp:78
#11 0x00007ffff70af8b6 in boost::detail::sp_counted_base::release (this=0x129b190)
    at /home/smaniyar/Projects/test_project/vendor/boost/boost/smart_ptr/detail/sp_counted_base_gcc_x86.hpp:146
#12 0x00007ffff70af949 in boost::detail::shared_count::~shared_count (this=0x100bd88, __in_chrg=<optimized out>)
    at /home/smaniyar/Projects/test_project/vendor/boost/boost/smart_ptr/detail/shared_count.hpp:371
#13 0x00007ffff72b962c in boost::shared_ptr<tflite::impl::Interpreter>::~shared_ptr (this=0x100bd80, __in_chrg=<optimized out>)
    at /home/smaniyar/Projects/test_project/vendor/boost/boost/smart_ptr/shared_ptr.hpp:328
#14 0x00007ffff72bca60 in TensorflowInferenceCore::ThreadInterpreter::~ThreadInterpreter (this=0x100bd80,
    __in_chrg=<optimized out>)
    at /home/smaniyar/Projects/test_project/src-main/deep_learning_inference/tensorflow_lite/TensorflowInferenceCore.h:17
```

During program execution I do see the flex delegate being deployed : 
```
INFO: TfLiteFlexDelegate delegate: 1 nodes delegated out of 398 nodes with 1 partitions.
```
But I do not see any such message for xnnpack delegate and I am not sure if my program is even using that for inference.

Is there a way I can confine inference to run on single thread using flex and xnnpack delegates?
Also it would be very helpful if I could know how to verify that xnnpack is being used by my TFLite runtime.

Thanks.
"
49265," ""download_dependencies.sh"" doesn't work","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Mac OS BigSur 11.2.3(arm64):
- TensorFlow installed from (source or binary): https://github.com/tensorflow/tensorflow
- TensorFlow version (use command below): the latest
- Python version: 3.8
- GPU model and memory:

**Describe the current behavior**
I try to use tensorflowlite with ios , and when i followed the instructions to the step ""download_dependencies.sh"" ,it shows that : 
 usage: grep [-abcDEFGHhIiJLlmnOoqRSsUVvwxZ] [-A num] [-B num] [-C[num]]
	[-e pattern] [-f file] [--binary-files=value] [--color=when]
	[--context[=num]] [--directories=action] [--label] [--line-buffered]
	[--null] [pattern] [file ...]

I think something wrong with ""grep -oP""
**Describe the expected behavior**
download the resources 

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes): - Briefly describe your candidate solution
(if contributing):
modify the grep -oP

<img width=""571"" alt=""截屏2021-05-18 下午9 28 15"" src=""https://user-images.githubusercontent.com/55579125/118660438-c8aa4b80-b820-11eb-9d9c-283ccd0cf1a2.png"">

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49264,Oh and 1 other thing,"
U fucking crossed the line with your fucking ""specific version dependencies""

ERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.32.0 which is incompatible.
ERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.
ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.
ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.
ERROR: apache-beam 2.29.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is **incompatible.**

does ur shitty tensorflor 2.5.0 distro needs fuckin' ""grpcio"" ? fine, you make ur fucking shitterflow compatible with any version of grpcio from 0.0001a to 10.31.8 or otherwise go fuck urself and do not release any 2.X shit. period. dipshits.

Btw feel free to ban from github the fake account registered trught some obscure russin darknet website Im currently using if this helps rais ur pathetic self esteem, I just wish you could be able to ban the incompetence and stupidity that lie in your shitheads as well


Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
49263,Compilation of TF 2.6 (master) crash,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Cloned master from Git
- TensorFlow version (use command below): refs/heads/master & refs/remotes/origin/HEAD & refs/remotes/origin/master
- Python version: 3.6.7
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): VC 2019
- CUDA/cuDNN version: 11.3 / 8
- GPU model and memory: GTX 1060 (6GB)

**Describe the current behavior**
I try to compile a monolith c++ library with this command:

```
bazel --output_user_root=""E:\tensorflow_gpu_cpp_v4\output"" build --local_ram_resources=HOST_RAM*.3 --config=opt --config=cuda --copt=-nvcc_options=disable-warnings --define=no_tensorflow_py_deps=true -s --config=monolithic --define framework_shared_object=false --explain=explain.txt --verbose_explanations --subcommands=pretty_print --repository_cache=""D:\Data\Users\andre-pl\Projects\TF_CACHE""  //tensorflow:libtensorflow_cc.so
```

During compilation I get this error:
```
SUBCOMMAND: # @llvm-project//llvm:config_gen [action 'Executing genrule @llvm-project//llvm:config_gen', configuration: a480bc448cf44313f1f5e14498fa07b461cb9a16e319fb75f5074c1505e5d54e, execution platform: @local_execution_config_platform//:platform]
cd E:/tensorflow_gpu_cpp_v4/output/tqha2ckh/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.3
    SET CUDNN_INSTALL_PATH=C:/Program Files/cudnn-11.3-windows-x64-v8.2.0.53
    SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\WINDOWS;C:\WINDOWS\System32;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\libnvvp;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\include;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\extras\CUPTI\lib64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\extras\CUPTI\include;C:\Program Files\cudnn-11.3-windows-x64-v8.2.0.53\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.24.28314\bin\Hostx64\x64\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;D:\Data\Users\andre-pl\AppData\Local\Programs\Python\Python36\Scripts\;D:\Data\Users\andre-pl\AppData\Local\Programs\Python\Python36\;C:\ProgramData\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Amazon\AWSCLI\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Program Files\Bazel;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Microsoft\Web Platform Installer\;C:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\110\Tools\Binn\;D:\orbograph\NuanceEng\bin;C:\Program Files\CMake\bin;C:\Program Files\PuTTY\;C:\Program Files\TortoiseGit\bin;C:\Program Files\SafeNet\Authentication\SAC\x64;C:\Program Files\SafeNet\Authentication\SAC\x32;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\msys64\usr\bin\;C:\Program Files\Conan\conan;D:\Data\Users\andre-pl\AppData\Local\Programs\Python\Python36\Scripts\;D:\Data\Users\andre-pl\AppData\Local\Programs\Python\Python36\;C:\Users\andre-pl\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Fiddler;C:\Program Files (x86)\Sophos\Sophos SSL VPN Client\bin;C:\Users\andre-pl\AppData\Local\Microsoft\WindowsApps
    SET PYTHON_BIN_PATH=D:/Data/Users/andre-pl/AppData/Local/Programs/Python/Python36/python.exe
    SET PYTHON_LIB_PATH=D:/Data/Users/andre-pl/AppData/Local/Programs/Python/Python36/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TF2_BEHAVIOR=1
    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1,7.0
    SET TF_CUDA_VERSION=11.3
    SET TF_CUDNN_VERSION=8
  C:/msys64/usr/bin/bash.exe \
    -c \
    source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt/bin/third_party/llvm/expand_cmake_vars.exe ""ENABLE_BACKTRACES=1"" ""LLVM_BINDIR=/dev/null"" ""LLVM_DISABLE_ABI_BREAKING_CHECKS_ENFORCING=0"" ""LLVM_ENABLE_ABI_BREAKING_CHECKS=0"" ""LLVM_ENABLE_THREADS=1"" ""LLVM_ENABLE_ZLIB=1"" ""LLVM_HAS_ATOMICS=1"" ""LLVM_INCLUDEDIR=/dev/null"" ""LLVM_INFODIR=/dev/null"" ""LLVM_MANDIR=/dev/null"" ""LLVM_NATIVE_TARGET=1"" ""LLVM_NATIVE_TARGETINFO=1"" ""LLVM_NATIVE_TARGETMC=1"" ""LLVM_NATIVE_ASMPRINTER=1"" ""LLVM_NATIVE_ASMPARSER=1"" ""LLVM_NATIVE_DISASSEMBLER=1"" ""LLVM_PREFIX=/dev/null"" ""LLVM_VERSION_MAJOR=0"" ""LLVM_VERSION_MINOR=0"" ""LLVM_VERSION_PATCH=0"" ""PACKAGE_NAME=llvm"" ""PACKAGE_STRING=llvm tensorflow-trunk"" ""PACKAGE_VERSION=tensorflow-trunk"" ""RETSIGTYPE=void"" ""LLVM_HOST_TRIPLE=x86_64-pc-win32"" ""LLVM_DEFAULT_TARGET_TRIPLE=x86_64-pc-win32"" ""LLVM_NATIVE_ARCH=X86"" ""HAVE_ERRNO_H=1"" ""HAVE_EXECINFO_H=1"" ""HAVE_FCNTL_H=1"" ""HAVE_FENV_H=1"" ""HAVE_INTTYPES_H=1"" ""HAVE_MALLOC_H=1"" ""HAVE_SIGNAL_H=1"" ""HAVE_STDINT_H=1"" ""HAVE_SYS_STAT_H=1"" ""HAVE_SYS_TYPES_H=1"" ""HAVE_ZLIB_H=1"" ""BACKTRACE_HEADER=execinfo.h"" ""HAVE_GETCWD=1"" ""HAVE_INT64_T=1"" ""HAVE_STRERROR=1"" ""HAVE_STRTOLL=1"" ""HAVE_SYSCONF=1"" ""HAVE_UINT64_T=1"" ""HAVE__CHSIZE_S=1"" ""HAVE___CHKSTK=1"" ""stricmp=_stricmp"" ""strdup=_strdup"" ""LTDL_SHLIB_EXT=.dll""< external/llvm-project/llvm/include/llvm/Config/config.h.cmake > bazel-out/x64_windows-opt/bin/external/llvm-project/llvm/include/llvm/Config/config.h
ERROR: E:/tensorflow_gpu_cpp_v4/output/tqha2ckh/external/llvm-project/llvm/BUILD:53:18: Executing genrule @llvm-project//llvm:llvm_config_gen failed (Exit -1073741819): bash.exe failed: error executing command
  cd E:/tensorflow_gpu_cpp_v4/output/tqha2ckh/execroot/org_tensorflow
  SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\WINDOWS;C:\WINDOWS\System32;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\libnvvp;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\include;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\extras\CUPTI\lib64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\extras\CUPTI\include;C:\Program Files\cudnn-11.3-windows-x64-v8.2.0.53\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.24.28314\bin\Hostx64\x64\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;D:\Data\Users\andre-pl\AppData\Local\Programs\Python\Python36\Scripts\;D:\Data\Users\andre-pl\AppData\Local\Programs\Python\Python36\;C:\ProgramData\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Amazon\AWSCLI\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Program Files\Bazel;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Microsoft\Web Platform Installer\;C:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\110\Tools\Binn\;D:\orbograph\NuanceEng\bin;C:\Program Files\CMake\bin;C:\Program Files\PuTTY\;C:\Program Files\TortoiseGit\bin;C:\Program Files\SafeNet\Authentication\SAC\x64;C:\Program Files\SafeNet\Authentication\SAC\x32;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.1.0\;C:\msys64\usr\bin\;C:\Program Files\Conan\conan;D:\Data\Users\andre-pl\AppData\Local\Programs\Python\Python36\Scripts\;D:\Data\Users\andre-pl\AppData\Local\Programs\Python\Python36\;C:\Users\andre-pl\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Fiddler;C:\Program Files (x86)\Sophos\Sophos SSL VPN Client\bin;C:\Users\andre-pl\AppData\Local\Microsoft\WindowsApps
    SET RUNFILES_MANIFEST_ONLY=1
  C:/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt/bin/third_party/llvm/expand_cmake_vars.exe ""ENABLE_BACKTRACES=1"" ""LLVM_BINDIR=/dev/null"" ""LLVM_DISABLE_ABI_BREAKING_CHECKS_ENFORCING=0"" ""LLVM_ENABLE_ABI_BREAKING_CHECKS=0"" ""LLVM_ENABLE_THREADS=1"" ""LLVM_ENABLE_ZLIB=1"" ""LLVM_HAS_ATOMICS=1"" ""LLVM_INCLUDEDIR=/dev/null"" ""LLVM_INFODIR=/dev/null"" ""LLVM_MANDIR=/dev/null"" ""LLVM_NATIVE_TARGET=1"" ""LLVM_NATIVE_TARGETINFO=1"" ""LLVM_NATIVE_TARGETMC=1"" ""LLVM_NATIVE_ASMPRINTER=1"" ""LLVM_NATIVE_ASMPARSER=1"" ""LLVM_NATIVE_DISASSEMBLER=1"" ""LLVM_PREFIX=/dev/null"" ""LLVM_VERSION_MAJOR=0"" ""LLVM_VERSION_MINOR=0"" ""LLVM_VERSION_PATCH=0"" ""PACKAGE_NAME=llvm"" ""PACKAGE_STRING=llvm tensorflow-trunk"" ""PACKAGE_VERSION=tensorflow-trunk"" ""RETSIGTYPE=void"" ""LLVM_HOST_TRIPLE=x86_64-pc-win32"" ""LLVM_DEFAULT_TARGET_TRIPLE=x86_64-pc-win32"" ""LLVM_NATIVE_ARCH=X86"" ""HAVE_ERRNO_H=1"" ""HAVE_EXECINFO_H=1"" ""HAVE_FCNTL_H=1"" ""HAVE_FENV_H=1"" ""HAVE_INTTYPES_H=1"" ""HAVE_MALLOC_H=1"" ""HAVE_SIGNAL_H=1"" ""HAVE_STDINT_H=1"" ""HAVE_SYS_STAT_H=1"" ""HAVE_SYS_TYPES_H=1"" ""HAVE_ZLIB_H=1"" ""BACKTRACE_HEADER=execinfo.h"" ""HAVE_GETCWD=1"" ""HAVE_INT64_T=1"" ""HAVE_STRERROR=1"" ""HAVE_STRTOLL=1"" ""HAVE_SYSCONF=1"" ""HAVE_UINT64_T=1"" ""HAVE__CHSIZE_S=1"" ""HAVE___CHKSTK=1"" ""stricmp=_stricmp"" ""strdup=_strdup"" ""LTDL_SHLIB_EXT=.dll""< external/llvm-project/llvm/include/llvm/Config/llvm-config.h.cmake > bazel-out/x64_windows-opt-exec-50AE0418/bin/external/llvm-project/llvm/include/llvm/Config/llvm-config.h
Execution platform: @local_execution_config_platform//:platform
      0 [main] bash (43208) C:\msys64\usr\bin\bash.exe: *** fatal error - add_item (""\??\C:\msys64"", ""/"", ...) failed, errno 1
Stack trace:
Frame        Function    Args
000FFFF8630  00180062835 (00180296FE2, 00180272E41, 0000000003F, 000FFFF8B10)
000FFFF8B60  001800488F2 (000FFFFFFFF, 00180020010, 000FFFFABCA, 000FFFF9BB0)
000FFFF9B70  00180048931 (000FFFF9BB0, 00000000001, 0000000003F, 00000000001)
000FFFF9C00  001800E5D0D (00000000000, 00140000024, 00000000000, 000FFFFCC50)
000FFFFCC70  001801363B5 (00000000000, 00000000000, 00000000000, 00000000000)
000FFFFCCE0  00180048F75 (00000000000, 00000000000, 00000000000, 00000000000)
000FFFFCDA0  0018004794A (00000000000, 00000000000, 00000000000, 00000000000)
000FFFFCE50  00180047A0C (00000000000, 00000000000, 00000000000, 00000000000)
End of stack trace
Target //tensorflow:libtensorflow_cc.so failed to build
INFO: Elapsed time: 29.040s, Critical Path: 23.42s
INFO: 67 processes: 67 internal.
FAILED: Build did NOT complete successfully
```
"
49262,"Keras mask propagation between recurrent, pooling and Dense layers from Masking layer","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8

**Current behavior**

From what I understand, the mask created by the Masking layer propagates only through certain layers, and I am having trouble figuring out through which layers and if the end result will vary depending on this mask's absence.

In my example, I have inputs of shape `(None, timesteps, features)` already embedded and 0-padded in order to have constant `timesteps` value. I want to pass the inputs through some recurrent layers, and then perform either classification (or token classification, but the problem remains the same). The questions are:
1) Do I have a problem if my output layer does not have an `input_mask` (0-padding computed in loss, for example)?
2) Do I need to make custom layers every time I need my mask to propagate (when not modifying the `timesteps` dimension)? 

For each of the four minimal examples below, I run this piece of code to figure out which layer has or hasn't an `input_mask`  attribute:
```
model = make_model(120, 768)
print(model.summary())
for layer in model.layers:
    print(layer.name, layer.input_mask)
``` 

**Example 1: Token classification with Masking+LSTM+Dense**
```
def make_model(m_len: int, emb_dim: int):
    inputs = Input(shape=(m_len, emb_dim))
    x = Masking(mask_value=0)(inputs)
    x = Bidirectional(LSTM(256, return_sequences=True))(x)
    output = Dense(1, activation=""sigmoid"")(x)
    mod = Model(inputs, output)
    mod.compile(
        optimizer=""Adam"",
        loss=""binary_crossentropy"",
        metrics=[""accuracy""]
    )
    return mod
```
output:
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 120, 768)]        0         
_________________________________________________________________
masking (Masking)            (None, 120, 768)          0         
_________________________________________________________________
bidirectional (Bidirectional (None, 120, 512)          2099200   
_________________________________________________________________
dense (Dense)                (None, 120, 1)            513       
=================================================================
Total params: 2,099,713
Trainable params: 2,099,713
Non-trainable params: 0
_________________________________________________________________
None
input_1 None
masking None
bidirectional KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.bool, name=None), name='masking/Squeeze:0')
dense KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.bool, name=None), name='Placeholder_2:0')
```
The mask is clearly propagated through both the recurrent layer and is also here in the Dense layer since the `timesteps` dimension hasn't changed.

**Example 2: Classification with Masking+LSTM+Dense**

Same code as above but setting `return_sequences=False`. output:

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 120, 768)]        0         
_________________________________________________________________
masking (Masking)            (None, 120, 768)          0         
_________________________________________________________________
bidirectional (Bidirectional (None, 512)               2099200   
_________________________________________________________________
dense (Dense)                (None, 1)                 513       
=================================================================
Total params: 2,099,713
Trainable params: 2,099,713
Non-trainable params: 0
_________________________________________________________________
None
input_1 None
masking None
bidirectional KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.bool, name=None), name='masking/Squeeze:0')
dense None
```
Works as expected so far, the dimension reduction doesn't allow a mask to pass on.

**Example 3: Classification with Masking+LSTM**
```
def make_model(m_len: int, emb_dim: int):
    inputs = Input(shape=(m_len, emb_dim))
    x = Masking(mask_value=0)(inputs)
    x = Bidirectional(LSTM(256, return_sequences=True))(x)
    output = LSTM(1, activation=""sigmoid"")(x)
    mod = Model(inputs, output)
    mod.compile(
        optimizer=""Adam"",
        loss=""binary_crossentropy"",
        metrics=[""accuracy""]
    )
    return mod
```
output
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 120, 768)]        0         
_________________________________________________________________
masking (Masking)            (None, 120, 768)          0         
_________________________________________________________________
bidirectional (Bidirectional (None, 120, 512)          2099200   
_________________________________________________________________
lstm_1 (LSTM)                (None, 1)                 2056      
=================================================================
Total params: 2,101,256
Trainable params: 2,101,256
Non-trainable params: 0
_________________________________________________________________
None
input_1 None
masking None
bidirectional KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.bool, name=None), name='masking/Squeeze:0')
lstm_1 KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.bool, name=None), name='Placeholder_2:0')
```
Even though the `timesteps` dim is removed, the mask is still effective on the output layer, is this behavior expected?

**Example 4: Classification with Masking+LSTM+AveragePooling+Flatten+Dense**
```
def make_model(m_len: int, emb_dim: int):
    inputs = Input(shape=(m_len, emb_dim))
    x = Masking(mask_value=0)(inputs)
    x = Bidirectional(LSTM(256, return_sequences=True))(x)
    x = AveragePooling1D(pool_size=512, data_format='channels_first')(x)
    x = Flatten()(x)
    output = Dense(1, activation=""sigmoid"")(x)
    mod = Model(inputs, output)
    mod.compile(
        optimizer=""Adam"",
        loss=""binary_crossentropy"",
        metrics=[""accuracy""]
    )
    return mod
```
output:
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 120, 768)]        0         
_________________________________________________________________
masking (Masking)            (None, 120, 768)          0         
_________________________________________________________________
bidirectional (Bidirectional (None, 120, 512)          2099200   
_________________________________________________________________
average_pooling1d (AveragePo (None, 120, 1)            0         
_________________________________________________________________
flatten (Flatten)            (None, 120)               0         
_________________________________________________________________
dense (Dense)                (None, 1)                 121       
=================================================================
Total params: 2,099,321
Trainable params: 2,099,321
Non-trainable params: 0
_________________________________________________________________
None
input_1 None
masking None
bidirectional KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.bool, name=None), name='masking/Squeeze:0')
average_pooling1d KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.bool, name=None), name='Placeholder_2:0')
flatten None
dense None
```
This one I am a bit less confident about, but averaging on the last dimension doesn't change the `timesteps` dimension and yet the mask isn't propagated. I thought maybe the averaging could create ""0"" vectors that would be ignored afterwards but the mask is computed by Masking and is 120 long boolean here, no matter what. Is there a reason why AveragePooling1D is not passing the mask to the Flatten layer?


"
49261,How team has made an animated 3D block diagram on tensorflow website?,"Hello Team,

This issue is not related to tensorflow package or any of its working. I am learning designing and I just wanted to know how google tensorflow team has made such a beautiful animated block diagram on the website [www.tensorflow.org](https://www.tensorflow.org/).

I'm referring to this diagram:
![Untitled](https://user-images.githubusercontent.com/7824529/118642791-6558f300-b7f9-11eb-984b-867b05ec6316.png)

Can anyone suggest what software are needed and from where can I start. The motion light animation and building up of diagram looks pretty awesome the moment website opens.

Please let me know. Thank you."
49260,Cannot link to built tensorflow.lib with Visual C++ -- undefined symbols; ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
-> Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
-> NA
- TensorFlow installed from (source or binary):
-> Source
- TensorFlow version:
-> r2.4.1 (also tried with master)
- Python version:
-> 3.6
- Installed using virtualenv? pip? conda?:
-> No
- Bazel version (if compiling from source):
-> 3.1.0
- GCC/Compiler version (if compiling from source):
-> Visual C++ 2019
- CUDA/cuDNN version:
-> 10.2 / 7.6.5
- GPU model and memory:
-> NVIDIA Quadro P400



**Describe the problem**
1) I build tensorflow.dll, tensorflow.lib and install_headers thanks to Bazel. The three ""Build completed successfully"" (see the three logs).
When I try to link to tensorflow.lib I get unresolved symbols
**error LNK2019: ""public: virtual __cdecl tensorflow::SavedModelBundleInterface::~SavedModelBundleInterface(void)"" (??1SavedModelBundleInterface@tensorflow@@UEAA@XZ) référencé dans la fonction ""int public: __cdecl tensorflow::SavedModelBundleLite::SavedModelBundleLite(void)'::1'::dtor$0"" (?dtor$0@?0???0SavedModelBundleLite@tensorflow@@QEAA@XZ@4HA)"".**

2) I had TF_EXPORT and #include ""tensorflow/core/platform/macros.h"" in loader.h, and then rebuild from src. I can compil but I get the following error when I run the .exe
**The procedure entry point ??1SavedModelBundleInterface@tensorflow@@UEAA@XZ could not be located in the dynamic link library C:\Users\bob\Documents\TF\test\x64\Debug\TF_cpp.exe**



**Provide the exact sequence of commands / steps that you executed before running into the problem**
1) python ./configure.py
        
        You have bazel 3.1.0 installed.
        Please specify the location of python. [Default is C:\Users\bob\AppData\Local\Programs\Python\Python38\python.exe]:

        Found possible Python library paths:
        C:\Users\bob\AppData\Local\Programs\Python\Python38\lib\site-packages
        Please input the desired Python library path to use. Default is [C:\Users\bob\AppData\Local\Programs\Python\Python38\lib\site-packages]
        
        Do you wish to build TensorFlow with ROCm support? [y/N]: N
        No ROCm support will be enabled for TensorFlow.
        
        Do you wish to build TensorFlow with CUDA support? [y/N]: N
        No CUDA support will be enabled for TensorFlow.
        
        Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:
        
        Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:
        Eigen strong inline overridden.
        
        Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
        Not configuring the WORKSPACE for Android builds.
        
          Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. 
          See .bazelrc for more details.
          --config=mkl # Build with MKL support.
          --config=mkl_aarch64 # Build with oneDNN support for Aarch64.
          --config=monolithic # Config for mostly static monolithic build.
          --config=ngraph # Build with Intel nGraph support.
          --config=numa # Build with NUMA support.
          --config=dynamic_kernels # (Experimental) Build kernels into separate shared objects.
          --config=v2 # Build TensorFlow 2.x instead of 1.x.
          Preconfigured Bazel build configs to DISABLE default on features:
          --config=noaws # Disable AWS S3 filesystem support.
          --config=nogcp # Disable GCP support.
          --config=nohdfs # Disable HDFS support.
          --config=nonccl # Disable NVIDIA NCCL support.

2) bazel build --config=opt tensorflow:tensorflow.dll
3) bazel build --config=opt tensorflow:tensorflow.lib
4) bazel build --config=opt tensorflow:install_headers



**Any other info / logs**

[dll.log](https://github.com/tensorflow/tensorflow/files/6500648/dll.log)
[headers.log](https://github.com/tensorflow/tensorflow/files/6500649/headers.log)
[lib.log](https://github.com/tensorflow/tensorflow/files/6500650/lib.log)


"
49259,issu,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49258,[TFLite] Failed to create Hexagon delegate on REALME x50 Pro,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS Catalina
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:realme x50 Pro
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):
- Python version: 3.6.8
- Bazel version (if compiling from source): 3.0.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

I use this device on Hexagon delegate before and get expected results. However, after some time, maybe because of system security patch upgrade, I can never create delegate on this device. When I run benchmark on Heaxagon delegate, it is aborted. 
![image](https://user-images.githubusercontent.com/21187757/118629720-70fbe800-b800-11eb-95e7-521366ecb873.png)
And when in Android App, it will  cause following log, which seems to fastrpc called failed:

05-17 21:28:02.051   869   869 I com.example.energy: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/rpcmem_android.c:143: rpcmem_init_internal: opened ION device fd 77, configured heap IDs: system (0x2000000), contig (0x400000), secure (0x200), secure flags (0x80080000)
05-17 21:28:02.051   869   869 I com.example.energy: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:2540: fastrpc_apps_user_init done
05-17 21:28:02.051   869   869 I com.example.energy: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1971: open_device_node: no access to default device of domain 3, open thru HAL
05-17 21:28:02.052   644   644 E SELinux : avc:  denied  { find } for interface=vendor.qti.hardware.dsp::IDspService sid=u:r:untrusted_app:s0:c110,c257,c512,c768 pid=869 scontext=u:r:untrusted_app:s0:c110,c257,c512,c768 tcontext=u:object_r:vendor_hal_dspmanager_hwservice:s0 tclass=hwservice_manager permissive=0
05-17 21:28:02.052   869   869 E dsp-client: DspClient.cpp (42): Error: DspClient: unable to acquire dspservice instance
05-17 21:28:02.052   869   869 E dsp-client: DspClient.cpp (82): Error: openSession: IDspManager session is NULL
05-17 21:28:02.052   869   869 E dsp-client: DspClient.cpp (131): Error: open_hal_session: failed to open session, error -1
05-17 21:28:02.052   869   869 E com.example.energy: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1988: Error 0: open_device_node failed for domain 3 (errno Success)
05-17 21:28:02.052   869   869 E com.example.energy: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:2342: Error 0x57: apps_dev_init failed for domain 3, errno Success
05-17 21:28:02.052   869   869 E com.example.energy: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:2440: Error 0x57: open_dev (-1) failed for domain 3
05-17 21:28:02.052   869   869 E com.example.energy: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1038: Error 0x57: remote_handle_open failed for hexagon_nn
05-17 21:28:02.052   869   869 E com.example.energy: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:918: Error 0x2c: remote_handle_invoke failed for handle 0xffffffff, method 27 on domain 3 (sc 0x1b000100)


**Describe the expected behavior**
create Hexagon delegate successfully

"
49257,tfdbg support dump all op outputs in tf2.x (just like tf1.x) instead of only NANs,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):2.4.1
- Are you willing to contribute it (Yes/No):No



**Describe the feature and the current behavior/state.**
Tensorflow 2.x's debugger helps me dump the input data of abnormal operators, which helps me a lot. However, after all, the operator where NAN occurs is not the first site of network anomalies. I often need to observe where the data starts to look abnormal. So I hope that the 2.x debugger can choose to dump the input and output data of any node like the 1.x.

**Will this change the current api? How?**
tf.debugging.experimental.enable_dump_debug_info()

**Who will benefit with this feature?**
Developers who need to perform network precision commissioning
**Any Other info.**
"
49256,Question VM UPGRADE Tensorflow,"Hello

Quick question, we are upgrading our systems from standalone to Virtual Machine environment Via VMware. 

Specs is GPU Tesla T4 

We are unsure for Tensorflow what would work best however maybe you might know?

what works best to move Tensor flow onto the VM enviroment ? ie what hardware specs. 


thanks

CH"
49255,Is  CUPTI error  due to tensorflow version or NVIDIA CUPTI libary API change ?,"The problem i met is in this issue  https://github.com/tensorflow/tensorflow/issues/35860.  I just want to confirm what raises this probelm. Is this due to the tensorflow version or the new version of   NVIDIA CUPTI libary? In tensorflow version belowing 2.0, my program runs normally. "
49254,Performance drop if I do some operation between predictions.,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): 1.15
- Python version: 3.6


**Describe the current behavior**
I am using CPU to predict, the issue occurs in both MKL(installed by conda, tested both default and TF_MKL_DISABLED=1) and non-MKL tensorflow(installed by pip).

If I run code like this
```
# warm up
for i in range(1000):
    predict my data
```
the time cost would be normal, but if change to 
```
# warm up
for i in range(1000):
    do some operation, let's denote it as op
    predict my data
```
The performance will drop, depending on op time cost, it would drop from about 10ms each batch to about 20ms when `TF_MKL_DISABLED=1`

Normally, each batch cost about 10ms, the less cost op is, the less drop would be. If op is 1ms, predict cost would be 11ms, if op is 5ms, predict cost would be 13ms.

**Describe the expected behavior**
no matter what operation between the predicts, the performance would not drop.

**Standalone code to reproduce the issue**
I do not know whether this is a normal behavior. If code is needed, I would post a colab.

"
49253,dependency conflict between tensorflow and tensorflow-text,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 7.5.0-3ubuntu1~18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.5.0
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

This command keeps trying to install different versions of various packages:

```pip install --upgrade pip tensorflow tensorflow-text```

It makes the Flax CI builds fail on Github ([example](https://github.com/google/flax/runs/2605209071?check_suite_focus=true)). We temporary fixed this by using `tensorflow==2.4.1`: https://github.com/google/flax/pull/1327
"
49252,SparseCategoricalAccuracy y_true and y_pred shape,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy

## Description of issue (what needs changing):
It seems that the usage example conflicts with documentation. I suppose that the usage example is correct https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/metrics.py#L3474-L3478

In usage example, `y_true` takes ground truth labels as input and `y_pred` takes logits/probabilities as input
```
m = tf.keras.metrics.SparseCategoricalAccuracy()
m.update_state([[2], [1]], [[0.1, 0.6, 0.3], [0.05, 0.95, 0]])
m.result().numpy()
```

In documentation, it states that:
`y_true` and `y_pred` should have the same shape.


<!--StartFragment-->
y_true | Ground truth values. shape =&nbsp;[batch_size,&nbsp;d0,&nbsp;..&nbsp;dN].
-- | --
y_pred | The predicted values. shape =&nbsp;[batch_size,&nbsp;d0,&nbsp;..&nbsp;dN].

<!--EndFragment-->

The documentation may need update.
"
49249,"tf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead. If you need this feature, please file a feature request at https://github.com/tensorflow/tensorflow/issues/new","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
49248,build failed with tensorrt 8.0,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 20.04.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.0
- Python version: 3.9.4
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source):  9.3.0
- CUDA/cuDNN version: 11.3 / 8.2.0
- GPU model and memory:
rtx3060 GDDR6 6GB


**Describe the problem**
bazel build failed
**Provide the exact sequence of commands / steps that you executed before running into the problem**
build with tensorrt support  ( tensorrt 8.0 )

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
ERROR: /home/alan/repo/tensorflow/tensorflow/compiler/tf2tensorrt/BUILD:39:11: C++ compilation of rule '//tensorflow/compiler/tf2tensorrt:tensorrt_stub' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/tf2tensorrt/_objs/tensorrt_stub/nvinfer_stub.pic.d ... (remaining 141 argument(s) skipped)
In file included from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:56:
./tensorflow/compiler/tf2tensorrt/stub/NvInfer_5_0.inc:5:7: error: declaration of ‘void* createInferBuilder_INTERNAL(void*, int)’ has a different exception specifier
    5 | void* createInferBuilder_INTERNAL(void* logger, int version) {
      |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:17:
bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInfer.h:8083:30: note: from previous declaration ‘void* createInferBuilder_INTERNAL(void*, int32_t) noexcept’
 8083 | extern ""C"" TENSORRTAPI void* createInferBuilder_INTERNAL(void* logger, int32_t version) noexcept;
      |                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:56:
./tensorflow/compiler/tf2tensorrt/stub/NvInfer_5_0.inc:12:7: error: declaration of ‘void* createInferRuntime_INTERNAL(void*, int)’ has a different exception specifier
   12 | void* createInferRuntime_INTERNAL(void* logger, int version) {
      |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInfer.h:54,
                 from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:17:
bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInferRuntime.h:2253:30: note: from previous declaration ‘void* createInferRuntime_INTERNAL(void*, int32_t) noexcept’
 2253 | extern ""C"" TENSORRTAPI void* createInferRuntime_INTERNAL(void* logger, int32_t version) noexcept;
      |                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:56:
./tensorflow/compiler/tf2tensorrt/stub/NvInfer_5_0.inc:33:28: error: declaration of ‘nvinfer1::IPluginRegistry* getPluginRegistry()’ has a different exception specifier
   33 | nvinfer1::IPluginRegistry* getPluginRegistry() {
      |                            ^~~~~~~~~~~~~~~~~
In file included from bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInfer.h:54,
                 from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:17:
bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInferRuntime.h:2264:51: note: from previous declaration ‘nvinfer1::IPluginRegistry* getPluginRegistry() noexcept’
 2264 | extern ""C"" TENSORRTAPI nvinfer1::IPluginRegistry* getPluginRegistry() noexcept;
      |                                                   ^~~~~~~~~~~~~~~~~
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 4508.840s, Critical Path: 130.04s
INFO: 23345 processes: 10553 internal, 12792 local.
FAILED: Build did NOT complete successfully
```
"
49247,nnlib,"Tflite offers _**libhexagon_nn_skel.so**_ to use hexagon delegate.I wonder is this library produced by nnlib?
Because when i used nnlib to get my own _**libhexagon_nn_skel.so**_  and applied it in tflite,something went wrong.

The logcat:
vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:735: Successfully opened file /system/vendor/lib/rfsa/adsp/libhexagon_nn_skel_v66.so
vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1022: Error 0x80000406: remote_handle_open_domain: dynamic loading failed for file:///libhexagon_nn_skel_v66.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp on domain 3 (**_dlerror signature verify start failed for libhexagon_nn_skel_v66.so_**)
vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1059: Error 0x80000406: remote_handle64_open failed for file:///libhexagon_nn_skel_v66.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp

I have signed my device and my own .so as Hexagon SDK said but still got the same wrong.So could you tell me what the tflite do to make your **_libhexagon_nn_skel_v66.so_** avaliable?Thanks  a lot!!!

"
49246,model.fit() with TensorFlow callback set to log each batch causes error on the second model.fit() call,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1 (edit: confirmed also with TF 2.5.0)
- Python version: 3.8.7
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 11.0/8.0.4.30
- GPU model and memory: GTX 1080 Ti 11 GB

**Describe the current behavior**
While training a model with TensorBoard callback set to log each batch, another `model.fit()` call fails with error:
```
2021-05-18 03:23:42.686008: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at summary_kernels.cc:210 : Not found: Resource localhost/_AnonymousVar6/class tensorflow::SummaryWriterInterface does not exist.
Traceback (most recent call last):
  File ""error.py"", line 11, in <module>
    model.fit([1, 2, 3, 4, 5])
  File ""C:\Users\danie\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""C:\Users\danie\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\danie\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\def_function.py"", line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""C:\Users\danie\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py"", line 2942, in __call__
    return graph_function._call_flat(
  File ""C:\Users\danie\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py"", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""C:\Users\danie\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py"", line 555, in call
    outputs = execute.execute(
  File ""C:\Users\danie\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.
  (0) Not found:  Resource localhost/_AnonymousVar6/class tensorflow::SummaryWriterInterface does not exist.
         [[{{node cond/then/_0/batch_loss}}]]
  (1) Not found:  Resource localhost/_AnonymousVar6/class tensorflow::SummaryWriterInterface does not exist.
         [[{{node cond/then/_0/batch_loss}}]]
         [[GroupCrossDeviceControlEdges_0/Identity_1/_15]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_208]

Function call stack:
train_function -> train_function
```

**Describe the expected behavior**
The second `model.fit()` call should not yield this error

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): no (I do not know the cause currently to think about a fix)

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```py
import tensorflow.keras as keras

model = keras.Sequential()
model.add(keras.layers.Input(shape=(1,)))

model.compile()
model.summary()

model.fit([1, 2, 3, 4, 5], callbacks=[keras.callbacks.TensorBoard(update_freq='batch')])
model.fit([1, 2, 3, 4, 5])
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Error message included above"
49245,AttributeError: module 'tensorflow.compat.v2' has no attribute '__internal__',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 20.04):
- TensorFlow version: 2.2.0
- Python version: 3.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11 / 8
- GPU model and memory: GTX 780



I'm trying to run Keras version 2.2.4 on Ubuntu 20.04 with python 3.8 and tensorflow 2.2.0 with CUDA 11.1 and I get the following error.

I've been looking around and according to me there is no stable version for python 3.8 using CUDA 11.1, I've tried to install different versions to solve the problem but in all of them I get the same thing.
"
49242,Request: Function (or example) for shuffling a large dataset on disk,"**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
There is currently no supported way to shuffle a large tfrecord dataset that does not fit into memory. For example, I am working with the Waymo Open Dataset, which consists of roughly 800 TFRecord files each with 200 frames of data. With 1TB of data it cannot be shuffled even with a very large 128GB memory. Ideally shuffling it would consist of writing to shards small enough to fit in memory, completely shuffling the shards randomly, and then randomly interleaving the shuffled shards. This would be a nice addition to the new experimental tf.data save and load APIs.

**Will this change the current api? How?**
Possibly? Either dedicated functions could be added, or this could be possibly achieved as a composition of existing tf.data operations.

**Who will benefit with this feature?**
Anyone using large datasets with tf.data

"
49241,LSTM and GRU on cudnn with mask puts different output from CPU or Non-cudnn kernel,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): colab
- TensorFlow version (use command below): colab
- Python version: Python 3.7.10 (colab)
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda_11.0_bu  (colab)
- GPU model and memory: colab

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v2.4.1-0-g85c8b2a817f 2.4.1

**Describe the current behavior**

When use LSTM or GRU with parameter `return_sequences=True` and use this layer on cudnn kernel,
The output values of timesteps on which input is masked is all zero.
And this behavior is different from CPU or GPU without cudnn, CPU  environment emit output of last unmasked timestep as masked timestep output.

**Describe the expected behavior**

I Think it should work same as it work on CPU or GPU without cudnn.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution

If it need python-level correction, I may contribute. But if it need cuda or cudnn something, I cannot contribute.
I Think the solution can be postprocessing for masked timestep simply.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Just run below code using colab on CPU and GPU.
The result is different.
```python
import tensorflow as tf

class TestModel(tf.keras.Model):
  def __init__(self):
    super().__init__()

    self.rnn = tf.keras.layers.LSTM(32, return_sequences=True)
  
  def call(self, x, mask=None):
    return self.rnn(x, mask=mask)[:, -1, :]

batch_size = 4
seq_len = 7

x = tf.random.normal([batch_size, seq_len, 32])
model = TestModel()
model(x, mask = tf.sequence_mask([seq_len - 1] * batch_size, maxlen=seq_len))
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49240,GridSearchCV error when n_jobs=-1,"Hello,

When I use GridSearchCV using njob=-1 I got an error bellow but it work great with njob=1. When using njob=-1 it runs for the first argument of taille_fen (7) but got error for the next. But it work with njob=1...


 The above exception was the direct cause of the following exception:

```
PicklingError                             Traceback (most recent call last)
<ipython-input-17-692078694243> in <module>()
     33     grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, n_jobs=-1, verbose=3)
     34 
---> 35     res = grid.fit(x_train, y_train,callbacks=[es])
     36     grid_result.append(res)
     37 

7 frames
/usr/lib/python3.7/concurrent/futures/_base.py in __get_result(self)
    382     def __get_result(self):
    383         if self._exception:
--> 384             raise self._exception
    385         else:
    386             return self._result

PicklingError: Could not pickle the task to send it to the workers.
```

My code is 

```
from keras.callbacks import EarlyStopping
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import KFold, TimeSeriesSplit, GridSearchCV
import pickle
from google.colab import files

dim_LSTM = [16,32,64,128]
l1_reg = [0,0.001,0.01,0.1]
l2_reg = [0,0.001,0.01,0.1]
taille_fen = [7,10,15,30,50]
bs = [512]
lrate = [0.1]

max_periodes = 1

es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=20, min_delta=1e-4, restore_best_weights=True)
tscv = TimeSeriesSplit(n_splits = 5)

grid_result = []
for bsize in bs:
  for taille in taille_fen:
    param_grid = {'dim_LSTM': dim_LSTM, 'l1_reg': l1_reg, 'l2_reg': l2_reg, 'lrate': lrate, 'taille_fen': [taille], 'bs':[bsize]}

    dataset = prepare_dataset_XY(serie_entrainement,taille,horizon,bsize)

    x,y = tuple(zip(*dataset))
    x_train = np.asarray(tf.reshape(np.asarray(x,dtype=np.float32),shape=(np.asarray(x).shape[0]*np.asarray(x).shape[1],taille,1)))
    y_train = np.asarray(tf.reshape(np.asarray(y,dtype=np.float32),shape=(np.asarray(y).shape[0]*np.asarray(y).shape[1])))

    model = KerasRegressor(build_fn=ModelLSTM, epochs=max_periodes, verbose=2)
    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, n_jobs=-1, verbose=3)

    res = grid.fit(x_train, y_train,callbacks=[es])
    grid_result.append(res)
```

Full error 

```
_RemoteTraceback                          Traceback (most recent call last)
_RemoteTraceback: 
""""""
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/backend/queues.py"", line 153, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File ""/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/backend/reduction.py"", line 271, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File ""/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/backend/reduction.py"", line 264, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File ""/usr/local/lib/python3.7/dist-packages/joblib/externals/cloudpickle/cloudpickle_fast.py"", line 563, in dump
    return Pickler.dump(self, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 437, in dump
    self.save(obj)
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 890, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 638, in save_reduce
    save(args)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 789, in save_tuple
    save(element)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 819, in save_list
    self._batch_appends(obj)
  File ""/usr/lib/python3.7/pickle.py"", line 846, in _batch_appends
    save(tmp[0])
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 774, in save_tuple
    save(element)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 890, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 819, in save_list
    self._batch_appends(obj)
  File ""/usr/lib/python3.7/pickle.py"", line 846, in _batch_appends
    save(tmp[0])
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 819, in save_list
    self._batch_appends(obj)
  File ""/usr/lib/python3.7/pickle.py"", line 843, in _batch_appends
    save(x)
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 819, in save_list
    self._batch_appends(obj)
  File ""/usr/lib/python3.7/pickle.py"", line 846, in _batch_appends
    save(tmp[0])
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 774, in save_tuple
    save(element)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 890, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 884, in _batch_setitems
    save(k)
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 774, in save_tuple
    save(element)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 890, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/usr/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 941, in save_module_dict
    StockPickler.save_dict(pickler, obj)
  File ""/usr/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/usr/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 819, in save_list
    self._batch_appends(obj)
  File ""/usr/lib/python3.7/pickle.py"", line 846, in _batch_appends
    save(tmp[0])
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 1087, in save_functor
    obj.keywords), obj=obj)
  File ""/usr/lib/python3.7/pickle.py"", line 638, in save_reduce
    save(args)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 789, in save_tuple
    save(element)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 774, in save_tuple
    save(element)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 1087, in save_functor
    obj.keywords), obj=obj)
  File ""/usr/lib/python3.7/pickle.py"", line 638, in save_reduce
    save(args)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 789, in save_tuple
    save(element)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/joblib/externals/cloudpickle/cloudpickle_fast.py"", line 745, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File ""/usr/local/lib/python3.7/dist-packages/joblib/externals/cloudpickle/cloudpickle_fast.py"", line 682, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File ""/usr/lib/python3.7/pickle.py"", line 638, in save_reduce
    save(args)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 789, in save_tuple
    save(element)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/lib/python3.7/pickle.py"", line 774, in save_tuple
    save(element)
  File ""/usr/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/usr/local/lib/python3.7/dist-packages/dill/_dill.py"", line 1177, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty
""""""

The above exception was the direct cause of the following exception:

PicklingError                             Traceback (most recent call last)
<ipython-input-17-692078694243> in <module>()
     33     grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, n_jobs=-1, verbose=3)
     34 
---> 35     res = grid.fit(x_train, y_train,callbacks=[es])
     36     grid_result.append(res)
     37 

7 frames
/usr/lib/python3.7/concurrent/futures/_base.py in __get_result(self)
    382     def __get_result(self):
    383         if self._exception:
--> 384             raise self._exception
    385         else:
    386             return self._result

PicklingError: Could not pickle the task to send it to the workers.
```"
49239,Segfault using XNNPACK with C++ API,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-73-lowlatency x86_64)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below):  2.5.0
- Python version: N/A
- Bazel version (if compiling from source):  4.0.0
- GCC/Compiler version (if compiling from source): GCC 10.2.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Running my C++ code with the XNNPACK backend results in segfault.

```
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
Segmentation fault
```

I used this build command and everything builds without errors. 
```
bazel build --define tflite_with_xnnpack=true --config=monolithic -c opt //tensorflow/lite:libtensorflowlite.so
```

The code compiles without errors but gets segfault when running the code. I also tried to build from the latest nightly release.

Linking libtensorflowlite.so built without xnnpack works without errors.

The same tflite-model works with TFlite Benchmarking Tool using XNNPACK.

**Describe the expected behavior**
XNNPACK running as the default backend for Tflite without segfault.


**Standalone code to reproduce the issue**

Here is the code I use ->

```
#include <tensorflow/lite/interpreter.h>
#include <tensorflow/lite/model.h>
#include <tensorflow/lite/kernels/register.h>
#include <iomanip>
#include <iostream>
#include <mutex>
#include <fstream>
#include ""tbb/concurrent_unordered_map.h""
#include <unicode/unistr.h>
#include <unicode/ustream.h>
#include <unicode/locid.h>
#include <chrono>
#include <boost/algorithm/string.hpp>

std::mutex mtx;

using namespace std;
using namespace std::chrono_literals;
using std::chrono::high_resolution_clock;
using std::chrono::duration_cast;
using std::chrono::duration;
using std::chrono::microseconds;	

tflite::ops::builtin::BuiltinOpResolver resolver_sv;
std::unique_ptr<tflite::FlatBufferModel> model_sv;
std::unique_ptr<tflite::Interpreter> interpreter_sv;
tbb::concurrent_unordered_map<string, int> vocab_sv;

float predict(string ss) {
	std::scoped_lock lock{mtx};
	int* input;
	float* output; 
	string s;
	icu::UnicodeString ustr(ss.c_str());
	ustr.toLower();
	ustr.toUTF8String(s);
	
	input = interpreter_sv->typed_input_tensor<int>(0);
	
	std::vector<std::string> result;
	boost::algorithm::split(result, s, boost::is_any_of("" *""), boost::token_compress_on);

	int i = 0;
	for(auto& word: result) { 
		try {
			input[i] = vocab_sv.at(word);
			i = i+1;
		}
		catch (const std::out_of_range& oor) {
			input[i] = 1;
			i = i+1;
		}
	}
	while(i<=20) {
		input[i] = 0;
		i = i+1;
	}

	interpreter_sv->Invoke();
	output = interpreter_sv->typed_output_tensor<float>(0);

	return output[0];
}

void init_model(){

	model_sv = tflite::FlatBufferModel::BuildFromFile(""/home/gustaf/cprojects/pacific/nlp/en/model.tflite"");
		
	if (model_sv == nullptr) {
			std::cerr << ""Model not found!"" << std::endl;
		}
	if (tflite::InterpreterBuilder(*model_sv, resolver_sv)(&interpreter_sv) != kTfLiteOk) {
		std::cerr << ""Failed to build interpreter!"" << std::endl;
		}

	interpreter_sv->SetNumThreads(1);

	if (interpreter_sv->AllocateTensors() != kTfLiteOk) {
		std::cerr << ""Failed to allocate tensors."" << std::endl;
	}
	if (interpreter_sv->Invoke() != kTfLiteOk) {
		std::cerr << ""Cannot invoke interpreter"" << std::endl;
	  }
	 
	ifstream infile(""/home/gustaf/cprojects/pacific/nlp/en/vocab.txt"");
	string a;
	int b;
	while (infile >> a >> b) {vocab_sv.insert(pair<string, int>(a, b));}

}

int main (){
	
	init_model();
	
	auto t1 = high_resolution_clock::now();
	predict(""This is a warmup text"");
	auto t2 = high_resolution_clock::now();
	predict(""This is another warmup text"");
	auto t3 = high_resolution_clock::now();
	predict(""This is an example text"");
	auto t4 = high_resolution_clock::now();
	predict(""This is another example text"");
	auto t5 = high_resolution_clock::now();
	predict(""This is the final text"");
	auto t6 = high_resolution_clock::now();


auto ms1 = duration_cast<microseconds>(t2 - t1);
auto ms2 = duration_cast<microseconds>(t3 - t2);
auto ms3 = duration_cast<microseconds>(t4 - t3);
auto ms4 = duration_cast<microseconds>(t5 - t4);
auto ms5 = duration_cast<microseconds>(t6 - t5);

cout << ""Prediction 1: "" << ms1.count() << "" us"" << endl;
cout << ""Prediction 2: "" << ms2.count() << "" us"" << endl;
cout << ""Prediction 3: "" << ms3.count() << "" us"" << endl;
cout << ""Prediction 4: "" << ms4.count() << "" us"" << endl;
cout << ""Prediction 5: "" << ms5.count() << "" us"" << endl;

}

```"
49238,ValueError: as_list() is not defined on an unknown TensorShape.,"Hi. I try to implement AlexNet with Coco dataset. I want to make multi label classification but tf throws the error. Full error is:

`
ValueError: in user code:

    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:758 train_step
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state
        self.build(y_pred, y_true)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:318 build
        self._metrics, y_true, y_pred)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1163 map_structure_up_to
        **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1258 map_structure_with_tuple_paths_up_to
        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1258 <listcomp>
        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1161 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:418 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:418 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:439 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1190 as_list
        raise ValueError(""as_list() is not defined on an unknown TensorShape."")

    ValueError: as_list() is not defined on an unknown TensorShape.
`

Here the Colab link:
[https://colab.research.google.com/drive/12nO4IDQJg02aiduqsMimyMJ6Z8KNlCFw?usp=sharing](url)

I don't understand where my mistake is.
**System information**
-Google Colab

You can collect some of this information using our environment capture
You can also obtain the TensorFlow version with:
TF 2.0: v2.4.1-0-g85c8b2a817f 2.4.1

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49237,MultiHeadAttention padding mask example,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention

## Description of issue:

I try to implement tranformers layer but there is no example of using this MultiHeadAttention layer with padding mask.
It is poffible to get one ?

"
49236,Custom Losses Documentation is Incomplete,"## URL(s) with the issue:

https://www.tensorflow.org/guide/keras/train_and_evaluate#custom_losses

## Description of issue (what needs changing):

### Clear description

The current documentation for writing custom loss functions is significantly incomplete. It does not indicate:

1) how to test compilation of the custom loss function
2) how to debug the custom loss function
3) what data types are expected for the function
4) what data type is expected to be returned from the function
5) what operations can be performed within the function.
For example. I found when run in the graph, functions like .numpy(), make_ndarray() and to_list() do not work on the tensors when in graph mode. However, these issues seem only to have arisen through raised issues rather than being proactively documented. Likewise, the documentation on how to to reenable these functions is not clearly documented."
49235,Question Pertaining to TanH Implementation for TFLite,"I was reading through the [TFLite Zero Skew Representation paper](https://arxiv.org/pdf/1712.05877.pdf) which makes a reference to the implementation of most mathematical functions [here](https://github.com/tensorflow/tensorflow/blob/4952f981be07b8bf508f8226f83c10cdafa3f0c4/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h). However, though the paper mentions the implementation of TanH function being available in the file, I couldn't find the fixed-point integer-only inference implementation of TanH. Can someone point me to the correct source please?"
49234,API Documentation pages do not allow providing written feedback,"## URL(s) with the issue:

All pages in the document including:
https://www.tensorflow.org/api_docs/python/tf

## Description of issue (what needs changing):
Right now, there is no simple means to provide feedback on the generated documentation aside from a thumbs up/thumbs down and limited multiple choice selection, making such feedback hardly useful. The API documentation at this stage is far too terse in many locations making it hard to use or unusable. It would make far more sense to allow written commentary to be collected against each page so that periodically, the software developers for each component could read the commentary and add necessary code comments to address the issues raised by people attempting to use the code.

Given that this is tensorflow machine learning documentation, it might even be possible to do natural language processing to extract common themes where people are running into issues.

The current system, like the angular documentation does seem like a conscious effort to avoid taking input from users and that really should not be the case."
49233,Should tf 2.5.0 recognize GPU on Windows 10 with CUDA 11.3/cuDNN 8.2 installed?,"[Tf docs](https://www.tensorflow.org/install/gpu#software_requirements) say that GPU support will work with CUDA 11, I assume meaning 11.* (??)

I have heard that tf GPU 2.5.0 is designed to work with CUDA 11.2 (https://github.com/tensorflow/tensorflow/issues/49190#issuecomment-841656229).

I have also heard that tf build failed with CUDA 11.3 libraries (#48803).  I assume this means that tf 2.5.0 GPU will NOT WORK with CUDA 11.3.  (??)

Can any Win 10 x64 users get their GPU recognized by tf 2.5.0 when CUDA 11.3/cuDNN 8.2 are installed?  If not, I assume I must downgrade CUDA to 11.2.2 and cuDNN to 8.1.1.

My GPU was recognized by tf 2.4.1 in my environment with CUDA 11.3.  After tf 2.5.0 was installed using pip, my GPU is no longer recognized.  

Thanks in advance!  

"
49229,TensorFlow eager-mode VS PyTorch eager-mode,"### Config:
```
OS: Windows 10
TensorFlow 2.4.1
Torch 1.7.1
```

### Query

**We know that **eager mode** is slow compared to graph mode in `TF 2.x`. But how much it can be slow compared to `PyTorch's` eager mode??**

A question was asked in [SO](https://stackoverflow.com/q/67383458/9215780) regarding this, where the OP used a deep reinforcement learning code example with a custom training loop to compare. In that example, whereas a `pytorch` code takes approximately **`~3` minutes** to complete; and with the same training pipeline a `tf` code takes approximately **`~2` hours** to complete, even with less accuracy comparatively. 

It probably also brings some other stuff like memory leaks during custom training loops etc. When I run the `pytorch` code, the `CPU` gets uses 100% and the `3D` thread of `GPU` (RTX 2070) was using approximately 20%. But when I run `tf` code, the `CPU` gets uses ~50%, physical **RAM** gets increased over time (possible memory leaks), and **VRAM** gets super high and no use of `3D` thread of `GPU`. Not sure what's the root cause. 

The only and **significant difference** occurs **after optimizing the `tf` code** and **compile it with graph execution**, as demonstrated in the accepted [answer](https://stackoverflow.com/a/67420239/9215780). The answer is fine but it seems more like the way to optimize `tf` code. 

I'm wondering, let's say we need to run `tf` code in eager mode, in that point, what is the root cause of this **performance and execution gap** between `tf` and `pytorch`. Is it expected behavior? The OP shared the plug-n-play code example, please find them from [here](https://github.com/navi2000/drl_test). 
"
49227,```tf.keras.callbacks.EarlyStopping``` always stops at the first epoch,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colab
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8
- CUDA/cuDNN version:  cuda11.2 cudnn8.2.0
- GPU model and memory: gtx1070

**Describe the current behavior**

```tf.keras.callbacks.EarlyStopping``` always stops at the first epoch .
Here is the colab :

[https://colab.research.google.com/drive/1FvWFE26IPrc8vcfbfEGWLPASP6ZJIBPu?usp=sharing](https://colab.research.google.com/drive/1FvWFE26IPrc8vcfbfEGWLPASP6ZJIBPu?usp=sharing)

**Describe the expected behavior**

It should stops at the best epoch like tensorflow2.4.1 .


"
49225,Can't call deprecated functions when embedding Python,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When calling deprecated functions using Python C API, they fail with

> AttributeError: 'NoneType' object has no attribute 'f_back'

Because there's not enough Python stack to be walked

Any deprecated function will fail with this error.

**Describe the expected behavior**

It should be possible to call deprecated functions using Python C APIs.

**[Contributing](https://www.tensorflow.org/community/contribute)**
- Do you want to contribute a PR? (yes/no): yes
- Briefly describe your candidate solution (if contributing): revert [offending commit](https://github.com/tensorflow/tensorflow/commit/42aab9b1f03713757d7c027b23f1113ea80f73ad) or add a check for `f == None` in [this line](https://github.com/tensorflow/tensorflow/blob/704610e1d21288482bf77923b387f9bb6c119318/tensorflow/python/util/deprecation.py#L105)

**Standalone code to reproduce the issue**

```c
Py_Initialize();
PyObject* tf_test = PyImport_ImportModule(""tensorflow.test"");
PyObject* is_gpu_available = PyObject_GetAttrString(tf_test, ""is_gpu_available"");
PyObject* haveGpu = PyObject_CallObject(is_gpu_available, NULL); // will return NULL and set Python error state
```
"
49224,Use gpudelegates failed: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.,"Hi,
Thanks for the project first.

### 1. System information

- OS Platform and Distribution: convert on Linux Ubuntu 20.04
- TensorFlow installation: pip package
- TensorFlow library: 2.4.1

### 2. Code
This is the model summary: 

![image](https://user-images.githubusercontent.com/30684101/118437622-8a743580-b715-11eb-8d4f-8dbbc1532540.png)


Converter code:
converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file('model.h5')
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
tflite_model = converter.convert()
with open(modelpath + '/model.tflite', 'wb') as f: 
        f.write(tflite_model)
print(""save successfully"")


### 3. Any other info / logs
I want to deploy a trained model in android with tflite and it has been deployed successfully in cpu, but when I want to use the delegate (like gpu & nnapi) to improve the performance, I get the error info: failed: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.

I guessed that I may miss some steps to fix the size (maybe the batch size?) after loading the trained model and before converting, but I have no idea what step I missed and what API I should use.

I also searched the some solution in this repo but I didn't still get the solution. Is there any solution, suggestion, or tutorial, please? 

Thanks so much!
"
49223,API to get mean and standard deviation for TFLite Models,"

In the example label_image.cc (under) lite/examples/label_image, we are hardcoding mean and standard deviation to 127.5f. How does this change based on model ?
How can we get these values of mean and standard deviation for any model ? Is there any API to fetch mean and std deviation ? where is this information stored ?
Can these values obtained run time ?

To change these mean and standard deviation ? what is the place to change , training ? (or) conversion (or) Inference ?

What is the significance of this mean and std deviation for LSTM(sequence) networks where input is not image ?


Please provide the API to get mean and std deviation values when running inference of any quantized model . 
**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No):




**Who will benefit with this feature?**
We dont have to specify mean and std deviation explicitly. 
"
49221,tensorflow lite chatbot and flutter integration,I would like to know if a chatbot built using tensorflow and exported as tensorflow lite model can be integrated into flutter. 
49220,NotFoundError:  No algorithm worked! Function call stack: train_function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Ubuntu 18.04
- TensorFlow installed using PIP
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8.8
- CUDA/cuDNN version: 11.0.228
- GPU model and memory: RTX 2070 super 8GB


**Describe the current behavior**
I'm training a model  for NLP with Bert and convolutional layers and gives me the follow error.

```
NotFoundError:  No algorithm worked!
	 [[node dcnn/conv1d_36/conv1d (defined at <ipython-input-123-fd67c57fea51>:44) ]] [Op:__inference_train_function_434559]

Function call stack:
train_function
```
The complete programming is the following:

```
import numpy as np
import math
import re
import pandas as pd
import random

import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers
import bert
import nltk
import re
import matplotlib.pyplot as plt

#Configuraciones 
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)


FullTokenizer = bert.bert_tokenization.FullTokenizer

bert_layer = hub.KerasLayer(""https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2"", trainable=False)
vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()
do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()
tokenizer = FullTokenizer(vocab_file, do_lower_case)

def encode_sentence(sent):
    return [""[CLS]""] + tokenizer.tokenize(sent) + [""[SEP]""]

data_inputs = [encode_sentence(sentence) for sentence in train[""excerpt_lemma""]]

def get_ids(tokens):
    return tokenizer.convert_tokens_to_ids(tokens)

def get_mask(tokens):
    return np.char.not_equal(tokens, ""[PAD]"").astype(int)

def get_segments(tokens):
    seg_ids = []
    current_seg_id = 0
    for tok in tokens:
        seg_ids.append(current_seg_id)
        if tok == ""[SEP]"":
            current_seg_id = 1-current_seg_id # convierte los 1 en 0 y vice versa
    return seg_ids


data_with_len = [[sent, train[""target""][i], len(sent)]
                 for i, sent in enumerate(data_inputs)]
# random.shuffle(data_with_len)
# data_with_len.sort(key=lambda x: x[2])
sorted_all = [({""input_1"":[get_ids(sent_lab[0]), get_mask(sent_lab[0]), get_segments(sent_lab[0])],
                ""input_2"":data_train.loc[idx].values},
                sent_lab[1])
              for idx, sent_lab in enumerate(data_with_len)]

all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,
                                             output_types=({""input_1"":tf.int32, ""input_2"":tf.float32}, tf.float32),
                                             output_shapes=({""input_1"":(3, None), ""input_2"":(18,)}, ()))

BATCH_SIZE = 32
all_batched = all_dataset.padded_batch(BATCH_SIZE,
                                       padded_shapes=({""input_1"":(3, None), ""input_2"":(18,)},()),
                                       padding_values=({""input_1"":0, ""input_2"":0.0}, 0.0))

NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)
NB_BATCHES_TEST = NB_BATCHES // 10
all_batched.shuffle(NB_BATCHES)

test_dataset = all_batched.take(NB_BATCHES_TEST)
train_dataset = all_batched.skip(NB_BATCHES_TEST)

class DCNNBERTEmbedding(tf.keras.Model):
    
    def __init__(self,
                 nb_filters=50,
                 FFN_units=512,
                 nb_classes=1,
                 dropout_rate=0.1,
                 name=""dcnn""):
        super(DCNNBERTEmbedding, self).__init__(name=name)
        
        self.bert_layer = hub.KerasLayer(
            ""https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2"",
            trainable=False)

        self.bigram = layers.Conv1D(filters=nb_filters,
                                    kernel_size=2,
                                    padding=""valid"",
                                    activation=""relu"")
        self.trigram = layers.Conv1D(filters=nb_filters,
                                     kernel_size=3,
                                     padding=""valid"",
                                     activation=""relu"")
        self.fourgram = layers.Conv1D(filters=nb_filters,
                                      kernel_size=4,
                                      padding=""valid"",
                                      activation=""relu"")
        self.pool = layers.GlobalMaxPool1D()
        self.dense_1 = layers.Dense(units=FFN_units, activation=""relu"")
        self.dropout = layers.Dropout(rate=dropout_rate)
        self.last_dense = layers.Dense(units=1,
                                           activation=""linear"")
    
    def embed_with_bert(self, all_tokens):
        print(""HOla"")
        _, embs = self.bert_layer([all_tokens[""input_1""][:, 0, :],
                                   all_tokens[""input_1""][:, 1, :],
                                   all_tokens[""input_1""][:, 2, :]])
        return embs

    def call(self, inputs, training):
        #Par
        x = self.embed_with_bert(inputs)

        x_1 = self.bigram(x)
        x_1 = self.pool(x_1)
        x_2 = self.trigram(x)
        x_2 = self.pool(x_2)
        x_3 = self.fourgram(x)
        x_3 = self.pool(x_3)
        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)
        merged = self.dense_1(merged)
        merged = self.dropout(merged, training)
        output = self.last_dense(merged)

        return output

NB_FILTERS = 20
FFN_UNITS = 20

DROPOUT_RATE = 0.3

NB_EPOCHS = 100

Dcnn = DCNNBERTEmbedding(nb_filters=NB_FILTERS,
                         FFN_units=FFN_UNITS,
                         dropout_rate=DROPOUT_RATE)

Dcnn.compile(loss=""mse"",
             optimizer=""adam"",
             metrics=[""mse"", ""mae""])

hist = Dcnn.fit(train_dataset,
         epochs=NB_EPOCHS,
         validation_data = test_dataset)
```

The complete error is the follow:

```
NotFoundError                             Traceback (most recent call last)
<ipython-input-156-31a351e764a6> in <module>
----> 1 hist = Dcnn.fit(train_dataset,
      2          epochs=NB_EPOCHS,
      3          validation_data = test_dataset)

~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1098                 _r=1):
   1099               callbacks.on_train_batch_begin(step)
-> 1100               tmp_logs = self.train_function(iterator)
   1101               if data_handler.should_sync:
   1102                 context.async_wait()

~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    826     tracing_count = self.experimental_get_tracing_count()
    827     with trace.Trace(self._name) as tm:
--> 828       result = self._call(*args, **kwds)
    829       compiler = ""xla"" if self._experimental_compile else ""nonXla""
    830       new_tracing_count = self.experimental_get_tracing_count()

~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    886         # Lifting succeeded, so variables are initialized and we can run the
    887         # stateless function.
--> 888         return self._stateless_fn(*args, **kwds)
    889     else:
    890       _, _, _, filtered_flat_args = \

~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2940       (graph_function,
   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)
-> 2942     return graph_function._call_flat(
   2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
   2944 

~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1916         and executing_eagerly):
   1917       # No tape is watching; skip to running the function.
-> 1918       return self._build_call_outputs(self._inference_function.call(
   1919           ctx, args, cancellation_manager=cancellation_manager))
   1920     forward_backward = self._select_forward_and_backward_functions(

~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    553       with _InterpolateFunctionError(self):
    554         if cancellation_manager is None:
--> 555           outputs = execute.execute(
    556               str(self.signature.name),
    557               num_outputs=self._num_outputs,

~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     57   try:
     58     ctx.ensure_initialized()
---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:

NotFoundError:  No algorithm worked!
	 [[node dcnn/conv1d_36/conv1d (defined at <ipython-input-123-fd67c57fea51>:44) ]] [Op:__inference_train_function_434559]

Function call stack:
train_function
```

If I try the same code but with one input instead of the dictionary with two inputs, it works. But I don't know why, I think the shapes are correctly, and if were wrong, Tensorflow have a specific error for that!

Can anyone help with this error please? Thank you"
49217,TF 2.0 'Tensor' object has no attribute 'numpy' while using .numpy() when use disable_eager_execution(),I need to convert tensor to numpy array in Graph mode.
49216,"ERROR when benchmarking TFLite model ""ERROR: Given shapes, [1, 40, 23, 256] and [1, 23, 40, 256], are not broadcastable.""","**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Ubuntu 20.04/Android 10
- Mobile device: Xiaomi Redmi Note 7
- TensorFlow installed from: pip
- TensorFlow version: v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: Python 3.8.8

**Describe the current behavior**
I am training a model and converting it to TFLite but when benchmarking it on TFLite I got an unexpected error shown below.
```
ERROR: Given shapes, [1, 40, 23, 256] and [1, 23, 40, 256], are not broadcastable.
ERROR: Node number 80 (ADD) failed to prepare.
```

**Describe the expected behavior**
Since the training works and that the shapes are good when I visualize the model in [netron](https://netron.app/), I expect it to work.
![image](https://user-images.githubusercontent.com/43449205/118394198-78c25d80-b643-11eb-8b43-c55521453662.png)

**Standalone code to reproduce the issue**
I am running the benchmark using the native tool which includes TFOps and Flex Delegate that can be downloaded [here](https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_arm_benchmark_model_plus_flex).

My model can be downloaded [here](https://github.com/tensorflow/tensorflow/files/6489086/model.zip).
I run the benchmark on an android device using the following lines:
```
adb push android_arm_benchmark_model_plus_flex /data/local/tmp/benchmark
adb shell chmod +x /data/local/tmp/benchmark
adb push model.tflite /data/local/tmp/model.tflite
adb shell ""/data/local/tmp/benchmark""  --graph=""/data/local/tmp/model.tflite"" --use_gpu=true --input_layer=input,scale_input --input_layer_shape=1,640,360,3:1,4
```

I do not understand where the error could be coming from since can train and run inference on the Tensorflow model and that the graph in Netron is good.

Thanks in advance!


"
49214,RNN weight conversion not applied within nested Functional models,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **no**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **any**, tested on MacOS 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): **binary** (independent)
- TensorFlow version (use command below): since **v2.3.0-rc0**, present in latest
  - since refactoring https://github.com/tensorflow/tensorflow/commit/bb15c97379f197a6a46ec1446d8fb0b292b860ba
- Python version: **any**, 3.7 (independent)
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: **any** (independent)
- GPU model and memory: -

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

The function `convert_nested_model()` nested within `keras.saving.load_model_from_hdf5()` converts layers only nested within `Model` or `Sequential` submodels, but not yet `Functional`.

For a model where GRU is within Functional nested model, trained with CuDNN, conversion when loading without CuDNN is not applied.

The result is that loading fails when setting weight values of incompatible shape.

**Describe the expected behavior**

The conversion is applied to GRU weights even when the layer is nested within a Functional submodel.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

Yes. I contributed the original code of some of those conversions.

https://github.com/keras-team/keras/pull/10081

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

I will provide a minimal example for reproduction.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
# in K.batch_set_value() for the GRU bias (CuDNN-compatible, ie .reset_after=True)
assign_op = x.assign(assign_placeholder)

self:
<tf.Variable 'gru_18/gru_cell_30/bias:0' shape=(2, 384) dtype=float32>
value:
<tf.Tensor 'Placeholder_173:0' shape=(?,) dtype=float32>
```

The bias value array is 768 and placeholder shape is `(?,)` (1D). It's missin conversion to proper shape: `(2, 384)` (as the variable has).

## Proposed solution

I tried adding the `'Functional'` to the list of nested class names to be be converted.

```
- elif layer.__class__.__name__ in ['Model', 'Sequential']:
+ elif layer.__class__.__name__ in ['Model', 'Sequential', 'Functional']:
```

And the whole model loaded correctly.

+ make unit tests
"
49213,Makefile: No such file or directory ( Windows ),"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
Trying to run the test_hello_world_test with make command, yet the Makefile is not present although I checked its presence in the directory...
**Please provide the exact sequence of commands/steps when you ran into the problem**

![issue](https://user-images.githubusercontent.com/44801135/118394269-8ffd4d00-b63b-11eb-8679-8b448965172b.jpg)
"
49212,Add a new split way in split_v_op.cc,"Now tensorflow has two way to split tensor.
1. Split tensor by single thread.
2. Split tensor by multi-thread.
The current data split method is not very uniform, like:
![image](https://user-images.githubusercontent.com/33950866/118393504-1f255780-b672-11eb-83b0-b39e9a580392.png)
We should add a new parallel split way. like:
![image](https://user-images.githubusercontent.com/33950866/118393518-2fd5cd80-b672-11eb-8f0b-eb1c1f999814.png)

example:
```
import tensorflow as tf
import time
sess_config = tf.ConfigProto(allow_soft_placement=False,
                             log_device_placement=True)

count = 3
keys = tf.random_uniform(shape=[4800, 107, 9], dtype=tf.int64, maxval=int(1e8))
arr = []
for i in range(0, 30):
  arr.append(1)
arr.append(77)
ret = tf.split(keys, arr, axis=1)

sess = tf.Session(config = sess_config)

start = time.time()
for i in range(0, 10):
    _ = sess.run(ret)
print('split_v seconds: %f' % (time.time() - start))
```
performance: 0.308505s vs 0.188766s"
49211,C++ compilation of rule '@llvm-project//llvm:Passes' failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): source (2.5.0 release)
- TensorFlow version: 2.5.0
- Python version: 3.8.7 GCC 7.5.0
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 11.3 / 8.2 
- GPU model and memory: NVIDIA GTX 1070 Ti / 8GB

**Describe the problem**
During the 
build process following error is thrown: 
[Logs+Config.zip](https://github.com/tensorflow/tensorflow/files/6488908/Logs%2BConfig.zip)

```C++ compilation of rule '@llvm-project//llvm:Passes' failed (Exit 4): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/external/llvm-project/llvm/_objs/Passes/PassBuilder.pic.d ... (remaining 59 argument(s) skipped)```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Detailed config and log files attached.

config => bazel build --local_ram_resources=4096 //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
49210,Windows Bazel build always fails,"While raising pull request, windows bazel tests always fails because of build failure. For example, you can look at this PR #49018

**Describe the expected behavior**
Build should fail only if test cases are failing.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): I want to contribute but I don't know the exact source of issue. If someone can guide me, I will raise PR."
49209,Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed,"### System information
- OS: Linux Debian 9 Stretch
- TensorFlow installed from (source or binary): source 
- TensorFlow version: 2.5.0
- Python version: 3.6 - 3.9
- Installed using: pip
- Bazel version: 3.7.2
- GCC/Compiler version: 6.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

### Describe the problem

Hi.

I'm trying to build TensorFlow v2.5.0 on a Raspberry Pi 4B. The environment (Docker) I'm using is `quay.io/pypa/manylinux_2_24_aarch64`.

When bazel is executing `Linking tensorflow/python/_pywrap_tensorflow_internal.so`, it always failed after about 1 minute.

During this process...
* the RAM is not insufficient
* disk should be OK (space is enough, and `fsck` returns no error)
* I didn't notice any other potential errors

###  Provide the exact sequence of commands / steps that you executed before running into the problem

Full logs here:

```
root@70a1a1f01b03:~/tf/src/tensorflow# ./configure
You have bazel 3.7.2 installed.
Please specify the location of python. [Default is /usr/bin/python3]: /opt/python/cp38-cp38/bin/python3


Found possible Python library paths:
  /opt/python/cp38-cp38/lib/python3.8/site-packages
Please input the desired Python library path to use.  Default is [/opt/python/cp38-cp38/lib/python3.8/site-packages]

Do you wish to build TensorFlow with ROCm support? [y/N]:
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]:
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]:
Clang will not be downloaded.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]:


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=mkl_aarch64    # Build with oneDNN and Compute Library for the Arm Architecture (ACL).
        --config=monolithic     # Config for mostly static monolithic build.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=nonccl         # Disable NVIDIA NCCL support.
Configuration finished
root@70a1a1f01b03:~/tf/src/tensorflow#
```

```
root@70a1a1f01b03:~/tf/src/tensorflow# bazel build --config=noaws --config=nogcp --config=nohdfs --config=nonccl //tensorflow/tools/pip_package:build_pip_package --verbose_failures
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=146
INFO: Reading rc options for 'build' from /root/tf/src/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /root/tf/src/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /root/tf/src/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/opt/python/cp38-cp38/bin/python3 --action_env PYTHON_LIB_PATH=/opt/python/cp38-cp38/lib/python3.8/site-packages --python_path=/opt/python/cp38-cp38/bin/python3
INFO: Found applicable config definition build:short_logs in file /root/tf/src/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /root/tf/src/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:noaws in file /root/tf/src/tensorflow/.bazelrc: --define=no_aws_support=true
INFO: Found applicable config definition build:nogcp in file /root/tf/src/tensorflow/.bazelrc: --define=no_gcp_support=true
INFO: Found applicable config definition build:nohdfs in file /root/tf/src/tensorflow/.bazelrc: --define=no_hdfs_support=true
INFO: Found applicable config definition build:nonccl in file /root/tf/src/tensorflow/.bazelrc: --define=no_nccl_support=true
INFO: Found applicable config definition build:linux in file /root/tf/src/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /root/tf/src/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (404 packages loaded, 31040 targets configured).
INFO: Found 1 target...
[16,226 / 16,343] 4 actions, 1 running
    Linking tensorflow/python/_pywrap_tensorflow_internal.so; 38s local
    [Sched] Linking tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so; 38s
    [Sched] Linking tensorflow/python/_pywrap_tensorflow_internal.so [for host]; 37s
    [Sched] Executing genrule @pasta//:augment/import_utils_py; 36s
ERROR: /root/tf/src/tensorflow/tensorflow/python/BUILD:5209:24: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1): gcc failed: error executing command
  (cd /root/.cache/bazel/_bazel_root/76de584e4721ac61540ca47fce08b572/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/opt/python/cp38-cp38/bin/python3 \
    PYTHON_LIB_PATH=/opt/python/cp38-cp38/lib/python3.8/site-packages \
    TF2_BEHAVIOR=1 \
  /usr/bin/gcc @bazel-out/aarch64-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params)
Execution platform: @local_execution_config_platform//:platform
/usr/bin/ld.gold: internal error in maybe_apply_stub, at ../../gold/aarch64.cc:5407
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 355.787s, Critical Path: 77.11s
INFO: 51 processes: 10 internal, 41 local.
FAILED: Build did NOT complete successfully
root@70a1a1f01b03:~/tf/src/tensorflow#
```

### Others
* This error has been reproduced on Python 3.8 and 3.9.
* The exact same env and commands could successfully build TF v2.4.1 and earlier versions.
Is there any possibility that is because of some new features in the latest version?

Thank you."
49208,"Model.fit() + LearningRateSchedule ignores initial_epoch/steps_per_epoch, giving wrong learning rates when resuming from checkpoints","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (see below)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab, Ubuntu 20.04, Windows 10
- TensorFlow installed from (source or binary): (preinstalled), (custom package), binary (pip)
- TensorFlow version (use command below): v2.4.1-0-g85c8b2a817f 2.4.1, unknown 2.6.0, v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: Python 3.7.10, Python 3.8.5, Python 3.7.9

**Describe the current behavior**

When training using a LearningRateSchedule, Optimizer and Model.fit(), the learning rate schedule ignores ""initial_epoch"" and ""steps_per_epoch"", so when starting a new session to resume training from a checkpoint, OptimizerV2._iterations and the resulting learning rate will be incorrect.

**Describe the expected behavior**

Model.fit() sees that ""initial_epoch"" and ""steps_per_epoch"" have been specified, and assigns ""initial_epoch * steps_per_epoch"" to OptimizerV2._iterations so that training can resume correctly.

**Standalone code to reproduce the issue**

```
import tensorflow as tf

input = tf.keras.layers.Input(shape=(2), dtype=tf.float32)
output = tf.keras.layers.Dense(1, activation=""relu"")(input)
model = tf.keras.Model(input, output)

learning_rate_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay([10], [0.5, 0.25])
optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer, loss=""mse"")

class ValidationCallback(tf.keras.callbacks.Callback):

  def __init__(self, expected):
    self.expected = expected
    self.actual = []

  def on_train_batch_end(self, batch, logs=None):
    self.actual.append(tf.keras.backend.get_value(self.model.optimizer.learning_rate(self.model.optimizer._iterations)).item())

  def on_train_end(self, logs=None):
    if self.actual == self.expected:
      print(""Good"")
    else:
      print(f""Bug: Expected {self.expected}, actual {self.actual}"")

values = tf.range(20, dtype=tf.float32)
inputs = tf.stack([values, values], axis=1)
outputs = values * 2.0
dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))
dataset = dataset.batch(1)

# Call fit() for steps 1-20.
print(""Test 1"")
model.fit(dataset, epochs=2, initial_epoch=0, steps_per_epoch=10, callbacks=[ValidationCallback([0.5] * 10 + [0.25] * 10)], verbose=0)

# Call fit() for steps 1-20 again (bug: the optimizer just retains its iterations, rather than calculating from epochs + initial_epoch + steps_per_epoch).
print(""Test 2"")
model.fit(dataset, epochs=2, initial_epoch=0, steps_per_epoch=10, callbacks=[ValidationCallback([0.5] * 10 + [0.25] * 10)], verbose=0)

# Call fit() for steps 1-20 a third time (work around the bug by resetting iterations).
print(""Test 3"")
model.optimizer.iterations.assign(0, read_value=False)
model.fit(dataset, epochs=2, initial_epoch=0, steps_per_epoch=10, callbacks=[ValidationCallback([0.5] * 10 + [0.25] * 10)], verbose=0)

# Call fit() for steps 11-20 (bug: should calculate iterations from epochs + initial_epoch + steps_per_epoch - very important when resuming training from a checkpoint).
print(""Test 4"")
model.optimizer.iterations.assign(0, read_value=False)
model.fit(dataset, epochs=2, initial_epoch=1, steps_per_epoch=10, callbacks=[ValidationCallback([0.25] * 10)], verbose=0)

# Call fit() for steps 11-20 (work around the bug by manually initializing iterations)
print(""Test 5"")
initial_epoch = 1
steps_per_epoch = 10
model.optimizer.iterations.assign(initial_epoch * steps_per_epoch, read_value=False)
model.fit(dataset, epochs=2, initial_epoch=initial_epoch, steps_per_epoch=steps_per_epoch, callbacks=[ValidationCallback([0.25] * 10)], verbose=0)
```

**Other info / logs**

```
Test 1
Good
Test 2
Bug: Expected [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25], actual [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 
0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]
Test 3
Good
Test 4
Bug: Expected [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25], actual [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]
Test 5
Good
```
"
49207,Didn't find op for builtin opcode 'RESIZE_BILINEAR' version '3',"System Information:
TensorFlow 2.3
Model Architecture - MobileNet V1
Arduino_TensorFlow Lite 2.4.0 Alpha

I fined Tuned Mobilenet V1 for face recoginition and later quantized using full integer Quantization Technique and later converted it to .cc format to upload it to Arduino Nano 33 BLE Sense. I used all_ops_resolver function but when i ran the Model on Microcontroller, invoke failed() and error message which was shown on Serial Monitor was "" Didn't find op for builtin opcode 'RESIZE_BILINEAR' version '3'. An older version of this builtin might be supported. Are you using an old TFLite binary with a newer model?"". Can anyone suggest me, how i can work around this error message.
After looking through the Arduino_TensorFlow Lite 2.4.0 - APLHA , i saw that resize_bilinear() isnt available in all_ops_resolver library but it is there in the master version of TensorFlow Lite on Tensorflow Github repository.  
Can anyone suggest me, how i overcome error message.

Colab Link - https://github.com/vatsDivyank/Face-Recoginition-TinyML/blob/985e769a84ecdd5ec8890d2288d262bbfa7cc18c/User_not_User_FineTuned.ipynb



"
49206,SSIM performance degradation in TF v2.5.0.,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Colab)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.0/2.5.0
- Python version: 3.7
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: 
- GPU model and memory: K80 GPU


**Describe the current behavior**
SSIM has become extremely slow in TF 2.5.0 as compared to TF 2.4.x
Here are some tests I ran on Colab
```
import tensorflow as tf
print(tf.__version__) # 2.5.0

%%timeit
ssim_ = tf.image.ssim(tf.random.normal((30,500,500,1)), tf.random.normal((30,500,500,1)), 1)

OUTPUT:
1 loop, best of 5: 30.1 s per loop
```
```
import tensorflow as tf
print(tf.__version__) # 2.4.0

%%timeit
ssim_ = tf.image.ssim(tf.random.normal((30,500,500,1)), tf.random.normal((30,500,500,1)), 1)

OUTPUT:
10 loops, best of 5: 93.5 ms per loop
```
The timeit tests warn clearly that there might be some caching involved for the 2.4.0 test (which isn't available for 2.5.0 I assume, I don't know why. Caching should be enabled for 2.5.0 as well if its the default behaviour)

**Describe the expected behavior**
There is clear performance degradation between the two versions. I haven't gotten the time to go through the `tensorflow/python/ops/image_ops_impl.py` but I assume there is some implementation change that is causing this issue

"
49205,SSIM performance degradation in TF v2.5.0,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Colab environment)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.0/2.5.0
- Python version: 3.7
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version:
- GPU model and memory: Tesla K80

**Describe the current behavior**
SSIM has become extremely slow in TF 2.5.0 as compared to TF 2.4.x
Here are some tests I ran on Colab
```
import tensorflow as tf
print(tf.__version__) # 2.5.0

%%timeit
ssim_ = tf.image.ssim(tf.random.normal((30,500,500,1)), tf.random.normal((30,500,500,1)), 1)

OUTPUT:
1 loop, best of 5: 30.1 s per loop
```
```
import tensorflow as tf
print(tf.__version__) # 2.4.0

%%timeit
ssim_ = tf.image.ssim(tf.random.normal((30,500,500,1)), tf.random.normal((30,500,500,1)), 1)

OUTPUT:
10 loops, best of 5: 93.5 ms per loop
```
The timeit tests warn clearly that there might be some caching involved for the 2.4.0 test (which isn't available for 2.5.0 I assume, I don't know why. Caching should be enabled for 2.5.0 as well if its the default behaviour)

**Describe the expected behavior**
The SSIM function clearly has performance degradation in 2.5.0 and should not take so much time on a GPU.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): Yes but I will have to go through the history of the `tensorflow/python/ops/image_ops_impl.py`  file

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Mentioned above

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49204,Model re-compilation updated under Distributed Mirror Strategy issue,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution : Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version: 11.0
- GPU model and memory: RTX 2080 Ti x4

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I am faced to an issue with Tensorflow with a model trained on multiple GPUs (x4) with the Distributed Mirror Strategy. 
The first training works perfectly with the Distributed Mirror Strategy.
After, I want to update some parameters (in the same run) such as learning rate, optimizer. The model compilation works perfectly and when the new training sequence is starting, I got the error below.

Here is my code. Do you have any advise to avoid this error and the training stop ? When I reload the model and run the next step of the training, it works but not in the pipeline. Do you have any idea ?
```
mirrored_strategy = tf.distribute.MirroredStrategy()
with mirrored_strategy.scope():
    # Everything that creates variables should be under the strategy scope.
    # In general this is only model construction & `compile()`.

    print(""[INFO] compiling model..."")
    baseModel, headModel, model = get_model(LastLayerNeurons=20, DropOut=0.5)

    for layer in baseModel.layers:
        layer.trainable = False

    # construct the set of metrics
    metrics = ['accuracy']
    opt = SGD(lr=1e-3)
    model.compile(loss=""categorical_crossentropy"", optimizer=opt, metrics=metrics)

print(""[INFO] training head..."")
model.fit(train_dataset,
          steps_per_epoch=steps_per_epoch,
          validation_data=val_dataset,
          validation_steps=validation_steps,
          epochs=10,
          max_queue_size=500,
          callbacks=callbacks,
          verbose=1,
          use_multiprocessing=True,
          workers=20)

with mirrored_strategy.scope():
    print(""[INFO] re-compiling model..."")

    for layer in model.layers[:]:  # Dernier block i.e #5
        layer.trainable = True

    # construct the set of metrics
    metrics = ['accuracy']

    opt = SGD(lr=1e-4)
    model.compile(loss=""categorical_crossentropy"", optimizer=opt, metrics=metrics)

print(""[INFO] fine-tuning V2 model..."")
model.fit(train_dataset,
        steps_per_epoch=steps_per_epoch,
        validation_data=val_dataset,
        validation_steps=validation_steps,
        epochs=100,
        max_queue_size=500,
        callbacks=callbacks,
        verbose=1,
        use_multiprocessing=True,
        workers=20)
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Exception ignored in: <bound method Image.__del__ of <tkinter.PhotoImage object at 0x7f1bc3ea32b0>>
Traceback (most recent call last):
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 3507, in __del__
    self.tk.call('image', 'delete', self.name)
RuntimeError: main thread is not in main loop
```
"
49203,"convert a keras model and load it on pi3, can not work","I convert a keras h5 model exported by teachable maching image classfication  to a tflite quantized model.
and load the converted model on pi3(with tflite-runtime 2.1.0), such error happend:
  didn't find op for builtin opcode 'conv_2d' version '5'

also i install tensorflow 2.4.0-rc2 on pi3.
so i tried to load the converted model , no error happend,
but the prediction accuracy is not good at all.

when i load the tflite quantized model export by teachable maching on pi3, it worked very well.
any one know why? and how google do it?


### 1. System information
I convert the keras model to tflite quantized model on the following environment:
- OS Platform and Distribution ( Linux Ubuntu 16.04):
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version): 2.4.0

### 2. The convert Code
import tensorflow as tf
import keras
model = keras.models.load_model('./keras_model/keras_model.h5')
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
f.write(tflite_model)
"
49202,"""Check failed: IsAligned()"" for pluggable devices with custom device memory allocator ","**Describe the current behavior**
We are using custom memory allocator registered for pluggable device. And while running unit tests like :while_v2_test.py"" we are running into issue of ""Check failed: IsAligned()"" 
https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/framework/tensor.cc;l=678

**Describe the expected behavior**
Since we are using our own memory allocator for device allocations the alignment of the data pointer is not necessarily related to the alignment of the data on the device, making this check not applicable. What can we do to fix it so that pluggable devices with custom allocators don't run into this issue. 

We were thinking of propogating the use_bfc_allocator flag to Tensor class to bypass the alignment check with custom allocator devices. Please let us know if it makes sense. 

@mihaimaruseac , @penpornk 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

No this is from running the unit test case.

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
MacOS

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
Source
- TensorFlow version (use command below):
- Python version:
3.8.2
- Bazel version (if compiling from source):
3.7.2
"
49201,Tensorflower gardener reverting changes made in PRs,"I had a couple of PRs merged before release of 2.5, and one after that. None of the changes in those PRs are now reflected in the code on master branch. Is this some internal process? 
The PRs before release are  #48000 #48491 and the one after the release is #48610

In all the three PRs, if we see in the History section of the file, we see Tensorflower gardener pushing the changes, but reverting them in the very next commit under the title ""Internal change"". Can someone please tell what's going on?

Following are the screenshots as well as links to the commits made by tensorflower-gardener


#48000: [Internal change](https://github.com/tensorflow/tensorflow/commit/a08001f32afab9952f27cd0b5fe15352569ce93e#diff-aedc7bfa50b8c6005dd96fb3d7f2d01d7d5538933829cbb52d11ced51e37eece)
![image](https://user-images.githubusercontent.com/64411306/118349261-46463100-b56d-11eb-8adc-8b09c5abbc55.png)


#48610: [Internal change](https://github.com/tensorflow/tensorflow/commit/0174bcb337e2c8e7d6782b60b094ea70460ad071#diff-f52657292a8a14c55f02a6cdacca9172be68e3fee9cd722cb5ac7d27326ecf9c)
![image](https://user-images.githubusercontent.com/64411306/118349280-6e359480-b56d-11eb-85bd-321fabbbd551.png)
"
49198,tflite_runtime pip package built using bazel is missing `metrics_portable` module,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.5 LTS (running in docker built from `latest-devel`)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source `master` branch
- TensorFlow version: 2.6.0 
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): gcc version 7.5.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


## Description 
* Standalone tflite_runtime pip package built using bazel ([reference](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package#normal-build-for-your-workstation)) is missing `metrics_portable` module that is imported in `tflite_runtimer/interpreter.py`
* The missing module is only encountered when the package is built using bazel. `build_pip_package.sh` bash script and cmake script include the metrics_* modules that are missing from the bazel scripts (refer: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/pip_package/build_pip_package.sh#L35-L36)

## Steps to reproduce
* Steps to reproduce the issue are detailed in this repo: https://github.com/avroshk/build-tflite-runtime

## Error logs
```
tflite_runtime==2.6.0
Traceback (most recent call last):
  File ""test_interpreter.py"", line 4, in <module>
    import tflite_runtime.interpreter as tflite
  File ""/usr/local/lib/python3.6/dist-packages/tflite_runtime/interpreter.py"", line 42, in <module>
    from tflite_runtime import metrics_portable as metrics
ImportError: cannot import name 'metrics_portable'
```
"
49196,Error in tf.keras.metrics.AUC,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): No
- TensorFlow version (use command below): 2.4.1
- Python version: 3.6.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
`tf.keras.metrics.AUC(from_logits=True)` and `tf.keras.metrics.AUC(from_logits=False)` outputs `TypeError: __init__() got an unexpected keyword argument 'from_logits'`

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Reproducible error: https://colab.research.google.com/drive/1-ZMVqG7t54a2QO-Vh2zKDdyT2gKYB47u?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: __init__() got an unexpected keyword argument 'from_logits'
```"
49195,Divide samples into multiple samples in tf.data input pipeline,"
**System information**
- TensorFlow version: 2.4.1
- Are you willing to contribute it: No


**Describe the feature and the current behavior/state.**

[Stack overflow link](https://stackoverflow.com/questions/67439611/chunk-tensorflow-dataset-records-into-multiple-records)

I have an unbatched tensorflow dataset that looks like this:

```python
ds = ...
for record in ds.take(3):
    print('data shape={}'.format(record['data'].shape))

-> data shape=(512, 512, 87)
-> data shape=(512, 512, 277)
-> data shape=(512, 512, 133)
```

I want to divide each sample into multiple samples by slicing along the final axis. For example, feed the data to my network in chunks of depth 5. In the example above, the tensor of shape (512, 512, 87) would be divided into 17 tensors of shape (512, 512, 5). The final 2 rows of the matrix (tensor[:, :, 85:87]) could be discarded.

```python
chunked_ds = ...
for record in chunked_ds.take(1):
    print('chunked data shape={}'.format(record['data'].shape))

-> chunked data shape=(512, 512, 5)
```

From looking at the tf.data API, there is no method that takes a single sample and returns multiple samples. Is it possible implement this in a pipeline?

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
49194,Build libtensorflowlite.so with TensorFlow ops supported for Android Error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu20.0.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version:tensorflow-nightly
- Python version:3.8.5
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):3.7.2
- GCC/Compiler version (if compiling from source):9.3.0
- CUDA/cuDNN version:no
- GPU model and memory:no



**Describe the problem**
I need Tensorflow OPS to run tflite model inference in C++.
I have added ""//tensorflow/lite/delegates/flex:delegate"" in /tensorflow/lite/BUILD according to the document
deps = [
        "":framework"",
        "":tflite_exported_symbols.lds"",
        "":tflite_version_script.lds"",
        ""//tensorflow/lite/delegates/flex:delegate"",
        ""//tensorflow/lite/kernels:builtin_ops_all_linked"",
    ],
**Provide the exact sequence of commands / steps that you executed before running into the problem**
./configure
bazel build -j 12 -c opt --config=android_arm --cxxopt=""-std=c++14"" --config=monolithic --local_ram_resources=4096 //tensorflow/lite:tensorflowlite
**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
**This is .tf_configure.bazelrc**
build --action_env PYTHON_BIN_PATH=""/usr/bin/python3""
build --action_env PYTHON_LIB_PATH=""/usr/lib/python3/dist-packages""
build --python_path=""/usr/bin/python3""
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-Wno-sign-compare
build --action_env ANDROID_NDK_HOME=""/home/liuchen/android-ndk-r18b""
build --action_env ANDROID_NDK_API_LEVEL=""21""
build --action_env ANDROID_BUILD_TOOLS_VERSION=""30.0.3""
build --action_env ANDROID_SDK_API_LEVEL=""28""
build --action_env ANDROID_SDK_HOME=""/home/liuchen/Android/Sdk""
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only
*******************************************************************************************
**Terminal Log**
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /home/liuchen/tensorflow-nightly/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/liuchen/tensorflow-nightly/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true
INFO: Reading rc options for 'build' from /home/liuchen/tensorflow-nightly/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --action_env ANDROID_NDK_HOME=/home/liuchen/android-ndk-r18b --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=30.0.3 --action_env ANDROID_SDK_API_LEVEL=28 --action_env ANDROID_SDK_HOME=/home/liuchen/Android/Sdk
INFO: Found applicable config definition build:short_logs in file /home/liuchen/tensorflow-nightly/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/liuchen/tensorflow-nightly/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:android_arm in file /home/liuchen/tensorflow-nightly/.bazelrc: --config=android --cpu=armeabi-v7a --fat_apk_cpu=armeabi-v7a
INFO: Found applicable config definition build:android in file /home/liuchen/tensorflow-nightly/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --define=with_xla_support=false
INFO: Found applicable config definition build:monolithic in file /home/liuchen/tensorflow-nightly/.bazelrc: --define framework_shared_object=false
WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/5e0ab05514761a40824142ccbd75dab5aaa6c0d8.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
DEBUG: /home/liuchen/.cache/bazel/_bazel_liuchen/e2427695e0c557633b86683d5e3a86ac/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.
WARNING: Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/40548a2974f1aea06215272d9c2b47a14a24e556.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  /home/liuchen/tensorflow-nightly/WORKSPACE:23:14: in <toplevel>
  /home/liuchen/tensorflow-nightly/tensorflow/workspace0.bzl:108:34: in workspace
  /home/liuchen/.cache/bazel/_bazel_liuchen/e2427695e0c557633b86683d5e3a86ac/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
Repository rule git_repository defined at:
  /home/liuchen/.cache/bazel/_bazel_liuchen/e2427695e0c557633b86683d5e3a86ac/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/ruy/archive/d37128311b445e758136b8602d1bbd2a755e115d.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
INFO: Analyzed target //tensorflow/lite:tensorflowlite (152 packages loaded, 8399 targets configured).
INFO: Found 1 target...
ERROR: /home/liuchen/tensorflow-nightly/tensorflow/lite/BUILD:914:24: Linking of rule '//tensorflow/lite:libtensorflowlite.so' failed (Exit 1): clang failed: error executing command external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang -shared -o bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/libtensorflowlite.so -Wl,-whole-archive ... (remaining 558 argument(s) skipped)
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'tflite::ops::builtin::BuiltinOpResolver::GetDelegates(int) const'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'tflite::ops::builtin::BuiltinOpResolverWithoutDefaultDelegates::GetDelegates(int) const'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'typeinfo for tflite::ops::builtin::BuiltinOpResolver'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'typeinfo for tflite::ops::builtin::BuiltinOpResolverWithoutDefaultDelegates'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'typeinfo name for tflite::ops::builtin::BuiltinOpResolver'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'typeinfo name for tflite::ops::builtin::BuiltinOpResolverWithoutDefaultDelegates'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'vtable for tflite::ops::builtin::BuiltinOpResolver'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops_all_linked.pic.lo(register.pic.o): multiple definition of 'vtable for tflite::ops::builtin::BuiltinOpResolverWithoutDefaultDelegates'
external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/kernels/libbuiltin_ops.pic.a(register.pic.o): previous definition here
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/lite:tensorflowlite failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1756.851s, Critical Path: 1286.77s
INFO: 2312 processes: 94 internal, 2218 local.
FAILED: Build did NOT complete successfully
"
49193,Can't save checkpoint when using multi-cells RNN,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: Python 3.7.6
- CUDA/cuDNN version: 11.3
- GPU model and memory: NVIDIA Corporation GV100GL [Tesla V100 PCIe 32GB] 

**Describe the current behavior**
I'm using multi-cells RNN with the following code:
```python
self.rnn_cells = [tf.keras.layers.LSTMCell(self.cfg.hidden_units) for _ in range(self.cfg.depth)]
self.encoder = tf.keras.layers.RNN(
    self.rnn_cells, return_sequences=True, return_state=True)
```
And I'm using `tf.train.Checkpoint` and `tf.train.CheckpointManager` to save checkpoint of my model.

However, `self.manager.save()` throws an error that is paste below:
```
ValueError: Unable to save the object ListWrapper([<tensorflow.python.keras.layers.recurrent_v2.LSTMCell object at 0x7f24a2c08f90>, <tensorflow.python.keras.layers.recurrent_v2.LSTMCell object at 0x7f24a2bc5810>, <tensorflow.python.keras.layers.recurrent_v2.LSTMCell object at 0x7f24a2bc5f10>, <tensorflow_addons.seq2seq.attention_wrapper.AttentionWrapper object at 0x7f24a3ee1090>]) (a list wrapper constructed to track trackable TensorFlow objects). A list element was replaced (__setitem__, __setslice__), deleted (__delitem__, __delslice__), or moved (sort). In order to support restoration on object creation, tracking is exclusively for append-only data structures.

If you don't need this list checkpointed, wrap it in a non-trackable object; it will be subsequently ignored.
```
**Describe the expected behavior**
`self.manager.save()`  can save the model correctly.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): No, I don't know how to solve this problem
"
49191,the ceritificate for mirror.tensorflow.org is invalid,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: 10.2/8.2
- GPU model and memory:



**Describe the problem**
while building tensorflow the following link is used by bazel to download an extension for aws:
https://mirror.tensorflow.org/github.com/aws/aws-sdk-cpp/archive
The Certificate under that link isn't for mirror.tensorflow.org but for *.storage.googleapis.com

**Provide the exact sequence of commands / steps that you executed before running into the problem**
not applicable

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
49190,GPU does not work ,"```
model.compile(
"
49189,Problem of optimisation with Tensorflow,"Hello,

My Tensorflow version is as below:

v1.12.1-53126-gd2083b259d1 (tf.version.GIT_VERSION),  2.5.0-dev20210318 (f.version.VERSION).

When I performed training using Gradient Tapes for deep GP models (https://github.com/FelixOpolka/Deep-Gaussian-Process), the code for one iteration of optimisation is as below:

for x_batch, y_batch in zip(bch_X, bch_Y):
	with tf.GradientTape(watch_accessed_variables=False) as tape:
		tape.watch(dgp.trainable_variables)
		objective = -model.elbo((x_batch, y_batch))
		gradients = tape.gradient(objective, model.trainable_variables)
	optimizer.apply_gradients(zip(gradients, model.trainable_variables))
	elbos.append(-objective.numpy())
When I do multiple iterations of optimisations, say 100 iterations, the optimiser may fail and crash at some iteration, with error being a matrix inversion problem. It means the parameters reach a space which would make the matrix non-invertible. However, optimisers if they can compute the objective at the start should not fail and crash when they try parameters that fail the objective (they should just keep the current objective and sample somewhere else, as what the Scipy optimiser does.

Just wondered if there is any solution for this?

Many thanks.
"
49188,TF Lite converter does not always identify the `hard_swish` activation,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur 11.2.3
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): v2.4.0-49-g85c8b2a817f (2.4.1)

**Provide the text output from tflite_convert**

N/A

**Description**
Currently TensorFlow Lite Converter can identify (i.e., convert to a single op) a hard swish activation which is defined as:

`x * tf.nn.relu6(x + np.float32(3)) * np.float32(1. / 6.)`

(see [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/toco/graph_transformations/identify_hardswish.cc)). Unfortunately, it is not able to identify a hard swish defined in a ""Keras"" fashion (e.g., like in the official MobileNet v3 implementation [here](https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/applications/mobilenet_v3.py#L444-L445)):

`keras.layers.Multiply()[keras.layers.ReLU(6.)(x + 3.) * (1. / 6.), x]`

It would be sensible if it was able to identify `hard_swish` in both cases.

**Standalone code to reproduce the issue** 
Please see a Colab Notebook [here](https://colab.research.google.com/drive/1gBwh-OQ0t86-ErJpml4cILeUGdEGmRpe?usp=sharing) for a more detailed presentation of the issue.

**Any other info / logs**

N/A
"
49187,AttributeError: 'MirroredStrategy' object has no attribute 'experimental_run_v2',"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (Linux Ubuntu 18.04):
- TensorFlow installed from (pip3):
- TensorFlow version (use command below):
`pip3 install tensorflow-gpu==2.4.1`
- Python version:3.8.0
- CUDA/cuDNN version: cuda11.3 driver 465.19
- GPU model and memory: eight 3090 cards

codes as the [URL](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb)
never modified

bugs
```
2021-05-14 18:00:34.332244: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: ""TensorSliceDataset/_2""
op: ""TensorSliceDataset""
input: ""Placeholder/_0""
input: ""Placeholder/_1""
attr {
  key: ""Toutput_types""
  value {
    list {
      type: DT_FLOAT
      type: DT_UINT8
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: 28
        }
        dim {
          size: 28
        }
        dim {
          size: 1
        }
      }
      shape {
      }
    }
  }
}

2021-05-14 18:00:34.366102: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: ""TensorSliceDataset/_2""
op: ""TensorSliceDataset""
input: ""Placeholder/_0""
input: ""Placeholder/_1""
attr {
  key: ""Toutput_types""
  value {
    list {
      type: DT_FLOAT
      type: DT_UINT8
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: 28
        }
        dim {
          size: 28
        }
        dim {
          size: 1
        }
      }
      shape {
      }
    }
  }
}

2021-05-14 18:00:35.243992: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-14 18:00:35.262293: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2500000000 Hz
Traceback (most recent call last):
  File ""/data/prod/xulm1/custom_training.py"", line 113, in <module>
    total_loss += distributed_train_step(x)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py"", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py"", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py"", line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py"", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py"", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in user code:

    /data/prod/xulm1/custom_training.py:99 distributed_train_step  *
        per_replica_losses = strategy.experimental_run_v2(train_step,

    AttributeError: 'MirroredStrategy' object has no attribute 'experimental_run_v2'


```

how to deal with this ?
thx
"
49186,How to convert a channel first Keras model to channel last model?,"Hello,

I have a pre-trained Keras model (in h5 format) where all the layers operate on channel first data format. I want to convert this model to operate on the channel last data format (the default data format). 
Does TensorFlow support this out of the box? Any help or pointers on how to do this is much appreciated.

For some clarity, the current model summary looks like this:

    Model: ""model""
    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to
    ==================================================================================================
    input0 (InputLayer)             [(None, 3, 240, 320) 0
    __________________________________________________________________________________________________
    259_pad (ZeroPadding2D)         (None, 3, 242, 322)  0           input0[0][0]
    __________________________________________________________________________________________________
    259 (Conv2D)                    (None, 16, 120, 160) 432         259_pad[0][0]
    __________________________________________________________________________________________________
    260 (BatchNormalization)        (None, 16, 120, 160) 64          259[0][0]
    __________________________________________________________________________________________________
    261 (Activation)                (None, 16, 120, 160) 0           260[0][0]
    __________________________________________________________________________________________________
    262_pad (ZeroPadding2D)         (None, 16, 122, 162) 0           261[0][0]
    __________________________________________________________________________________________________
    262 (DepthwiseConv2D)           (None, 16, 120, 160) 144         262_pad[0][0]

As you can see, it's in the channel first format. I want to convert each layer in the model to operate on channel last format. So the ideal model summary will be as follows:

    Model: ""model""
    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to
    ==================================================================================================
    input0 (InputLayer)             [(None, 240, 320, 3) 0
    __________________________________________________________________________________________________
    259_pad (ZeroPadding2D)         (None, 242, 322, 3)  0           input0[0][0]
    __________________________________________________________________________________________________
    259 (Conv2D)                    (None, 120, 160, 16) 432         259_pad[0][0]
    __________________________________________________________________________________________________
    260 (BatchNormalization)        (None, 120, 160, 16) 64          259[0][0]
    __________________________________________________________________________________________________
    261 (Activation)                (None, 120, 160, 16) 0           260[0][0]
    __________________________________________________________________________________________________
    262_pad (ZeroPadding2D)         (None, 122, 162, 16) 0           261[0][0]
    __________________________________________________________________________________________________
    262 (DepthwiseConv2D)           (None, 120, 160, 16) 144         262_pad[0][0]

Thanks.

"
49185,Installing tensorflow-gpu and upgrade grpcio,"I have never had this problem before today, but now when I run code I have these errors


"
49184,Is it possible to use Sparse Tensor in Distributed Tensorflow ? ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Hey everyone,

I have been trying to feed sparse tensor as an input into my distributed tensorflow model. The struggle is real at the moment, it doesn't seem to work -> all I get is this error message which makes me wonder is it even possible with tensorflow ?

`TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(""cond_1/Identity:0"", shape=(None, 3), dtype=int64, device=/job:worker/replica:0/task:0/device:CPU:0), values=Tensor(""sequential/dense/Cast:0"", shape=(None,), dtype=float32, device=/job:worker/replica:0/task:0/device:CPU:0), dense_shape=Tensor(""cond_1/Identity_2:0"", shape=(3,), dtype=int64, device=/job:worker/replica:0/task:0/device:CPU:0)). Consider casting elements to a supported type.`

Indeed, I have been reading other issue that others faced when using sparse tensor and the workaround that had been mentioned was to cast it to dense during runtime. However, the the training speed is heavily effected by it, at least for me causing it run 1 hour and 30 minutes per epoch whereas running it locally its 4 minute per epoch (**mind blown**) 

Best regards and stay safe

**Describe the expected behavior**


**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49183,BUG: `RESHAPE` op is not always compatible with the `resize_tensor_input` method of the TF Lite Interpreter,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur 11.2.3
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): v2.4.0-49-g85c8b2a817f (2.4.1)

**Provide the text output from tflite_convert**
N/A

**Description**
`RESHAPE` op (as converted from `tf.reshape` + `tf.shape` functions) is not compatible with the `resize_tensor_input` method of the TF Lite `Interpreter` when the tflite model is obtained from the model with the known input shape (e.g., the known shape being `(1, 1, 16000)`). In this case the `allocate_tensors` method called after `resize_tensor_input` (e.g., with the new input shape being `(1, 1, 32000)`) results in the

```
RuntimeError: tensorflow/lite/kernels/reshape.cc:69 num_input_elements != num_output_elements (32000 != 16000)Node number 0 (RESHAPE) failed to prepare.
```

On the other hand, when the tflite model is obtained from the model with partially unknown input shape (e.g. `(1, 1, None)`) then `resize_tensor_input` works correctly.

**Standalone code to reproduce the issue** 
Please see a Colab Notebook [here](https://colab.research.google.com/drive/1WEQbsJeB3cqQKVfsfuQsXvyTfh3FeF9A?usp=sharing) for a more detailed presentation of the issue (the last cell in the notebook results in the `RuntimeError` mentioned above).

**Any other info / logs**
N/A
"
49182,Exception ignored in: function CapturableResource.__del__ after upgrading to TF 2.5,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS X 11.2.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Python version: 3.8.6
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: No
- GPU model and memory: No

**Describe the current behavior**
After upgrading from TF 2.4.1 to TF 2.5.0 i see strange messages in console when run training/testing of my model. See logs below.

**Describe the expected behavior**
No ignored exceptions should be printed

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): No

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1IpmIj3WI17j6JkfgGWH0YEpowja7m71Y?usp=sharing
 

**Other info / logs** 
In some cases i got only such logs
```python
Exception ignored in: <function CapturableResource.__del__ at 0x15ad1c790>
Traceback (most recent call last):
  File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py"", line 277, in __del__
    self._destroy_resource()
  File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 889, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 924, in _call
    results = self._stateful_fn(*args, **kwds)
  File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3022, in __call__
    filtered_flat_args) = self._maybe_define_function(args, kwargs)
  File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3444, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3279, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 999, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 672, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
AttributeError: 'NoneType' object has no attribute '__wrapped__'
```

But in another, it prepended with another one:
```python
  Traceback (most recent call last):
    File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 2560, in get_attr
      pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)
  tensorflow.python.framework.errors_impl.InvalidArgumentError: Operation 'raggedconcat_assert_equal_3_assert_assertguard_placeholder_1' has no attr named '_class'.
  
  During handling of the above exception, another exception occurred:
  
  Traceback (most recent call last):
    File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py"", line 277, in __del__
      self._destroy_resource()
  ...
    File ""/Users/alex/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 672, in wrapped_fn
      out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  AttributeError: 'NoneType' object has no attribute '__wrapped__'
```"
49181,Problems with using tf.data.Datasets with MirroredStrategy with eager execution disables,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4
- Python version: 3.8


**Describe the current behavior**
When training a model that uses tf.data.Datasets with MirroredStrategy while eager execution is disabled, the function (under backend.GraphExecutionFunction) below does not know how to handle inputs that do not include numpy arrays. 

```
  def __call__(self, inputs):
    inputs = nest.flatten(inputs, expand_composites=True)

    session = get_session(inputs)
    feed_arrays = []
    array_vals = []
    feed_symbols = []
    symbol_vals = []
    for tensor, value in zip(self.inputs, inputs):
      if value is None:
        continue

      if tensor_util.is_tensor(value):
        # Case: feeding symbolic tensor.
        feed_symbols.append(tensor)
        symbol_vals.append(value)
      else:
        # Case: feeding Numpy array.
        feed_arrays.append(tensor)
        # We need to do array conversion and type casting at this level, since
        # `callable_fn` only supports exact matches.
        tensor_type = dtypes_module.as_dtype(tensor.dtype)
        array_vals.append(np.asarray(value,
                                     dtype=tensor_type.as_numpy_dtype))

    if self.feed_dict:
      for key in sorted(self.feed_dict.keys()):
        array_vals.append(
            np.asarray(self.feed_dict[key], dtype=key.dtype.base_dtype.name))

    # Refresh callable if anything has changed.
    if (self._callable_fn is None or feed_arrays != self._feed_arrays or
        symbol_vals != self._symbol_vals or
        feed_symbols != self._feed_symbols or self.fetches != self._fetches or
        session != self._session):
      self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)

    fetched = self._callable_fn(*array_vals,
                                run_metadata=self.run_metadata)
    self._call_fetch_callbacks(fetched[-len(self._fetches):])
    output_structure = nest.pack_sequence_as(
        self._outputs_structure,
        fetched[:len(self.outputs)],
        expand_composites=True)
    # We need to evaluate any composite tensor objects that have been
    # reconstructed in 'pack_sequence_as', since otherwise they'll be output as
    # actual CompositeTensor objects instead of the value(s) contained in the
    # CompositeTensors. E.g., if output_structure contains a SparseTensor, then
    # this ensures that we return its value as a SparseTensorValue rather than
    # a SparseTensor.
    return nest.map_structure(self._eval_if_composite, output_structure)

```

In particular, these lines fail when the inputs are only symbolic tensors with symbolic values.

```
    fetched = self._callable_fn(*array_vals,
                                run_metadata=self.run_metadata)
    self._call_fetch_callbacks(fetched[-len(self._fetches):])
    output_structure = nest.pack_sequence_as(
        self._outputs_structure,
        fetched[:len(self.outputs)],
        expand_composites=True)
```


**Describe the expected behavior**
This function should be able to run when there are only feed_symbols and symbols_vals. Unless I am missing something? Does this function need to have feed_arrays/array_vals? 
"
49179,TF2.5.0 pip package depends on keras-nightly,"**Describe the problem**

`pip install tensorflow==2.5.0` installs `keras-nightly`. Is that intended?

**Any other info / logs**
https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/tools/pip_package/setup.py#L105-L107"
49177,File system scheme '[local]' not implemented on TPU,"Hello, I have a task to train a model with millions of images using TPU, so I plan to load local data batch by batch when training. The main function to load data is shown below.

`def batch_processing(image):
    image1 = tf.image.decode_jpeg(tf.io.read_file(image), 3)
    return tf.image.resize(image1, [IMGSIZE, IMGSIZE])/255.


def data_loading(path, data, batch, buffer=1000, training=False):
    img1, start1 = [], 0
    
    while start1 < len(data):
        path1 = data['image_id'][start1:start1+buffer]
        img1 += path1.apply(lambda x: path+'train/'+x[0]+'/'+x[1]+'/'+x[2]+'/'+x+'.png').tolist()
        start1 += buffer

    set1 = tf.data.Dataset.from_tensor_slices((img1))
    set1 = set1.map(batch_processing, num_parallel_calls=AUTOTUNE)
    set1 = set1.shuffle(buffer).batch(batch) if training else set1.batch(batch)
    set1 = set1.prefetch(buffer_size=AUTOTUNE)
    return tpu_strategy.experimental_distribute_datasets_from_function(lambda _: set1)`

However, I have got an error ""File system scheme '[local]' not implemented"". Since this code works on GPU, I think such local file scheme isn't supported on TPU currently. Could you please tell me how to deal with this problem, when I have too many local images to load?

Thank you!
"
49175,Tensorflow GPU Instructions should be updated for TF 2.5 and CUDA 11.2,"## URL(s) with the issue:

https://www.tensorflow.org/install/gpu#windows_setup
https://github.com/tensorflow/docs/blob/master/site/en/install/gpu.md

## Description of issue (what needs changing):

[TensorFlow 2.5](https://github.com/tensorflow/tensorflow/releases/tag/v2.5.0) is built against CUDA 11.2 and cuDNN 8.1.0. However, the GPU instructions still refer to CUDA 11.0 and cuDNN 8.0.4. I believe that for the sake of clarity these should be updated to match TF 2.5. This includes both the installation commands for Linux and the path commands for Windows.

### Submit a pull request?

I'd be glad to submit a PR for the windows instructions, but I don't currently have access to a machine I can use to verify the Linux steps.

<!--
Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
--->"
49172,Error importing from Keras models - AttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- Keras version: 2.4.3
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.5.0
- Python version: 3.7.10
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
The following error is raised when importing `Model` from keras.models 

```bash
dosma/models/oaiunet2d.py:14: in <module>
    from keras.models import Model
/opt/hostedtoolcache/Python/3.7.10/x64/lib/python3.7/site-packages/keras/__init__.py:20: in <module>
    from . import initializers
/opt/hostedtoolcache/Python/3.7.10/x64/lib/python3.7/site-packages/keras/initializers/__init__.py:124: in <module>
    populate_deserializable_objects()
/opt/hostedtoolcache/Python/3.7.10/x64/lib/python3.7/site-packages/keras/initializers/__init__.py:49: in populate_deserializable_objects
    LOCAL.GENERATED_WITH_V2 = tf.__internal__.tf2.enabled()
E   AttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2'
```

**Describe the expected behavior**
No error should be thrown

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): if this requires a fix, yes

**Standalone code to reproduce the issue**
```python
from keras.models import Model
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49169,Tensorflow2 - “tf.data.experimental.make_csv_dataset” doesn't work with “tf.keras.preprocessing.timeseries_dataset_from_array”,"Hello! I am trying to get TensorFlow to read +100 CSV files that ***don't*** fit in memory (+1GB size each). The files contain time-series data (EEG signals), with the labels in the first column. From the TensorFlow documentation it seems like I should be able to use the *tf.data* API to load my data off-disk.

For the sake of simplicity and reproducibility, let's consider the following ""*sample_data.csv*"" dataset:

| Label    | Feature 1 | Feature 2 | 
| -------- | --------- | --------- |
| Apple    | 1         | 2         |
| Banana   | 3         | 4         |
| Coconut  | 5         | 6         |
| Durian   | 7         | 8         |
| Eggplant | 9         | 10        |
| Fruit    | 11        | 12        |

I've tried using [tf.data.experimental.make_csv_dataset][1] to load the CSV files into *tf.data.Dataset* objects, and then [tf.keras.preprocessing.timeseries_dataset_from_array][2] to process the data into sliding windows with overlap. For the dataset above, I would do:

    import tensorflow as tf

    input_data = tf.data.experimental.make_csv_dataset(
        'sample_data.csv',
        batch_size=1,
        column_names=['Label', 'Feature 1', 'Feature 2']
        label_name='Label',
        num_epochs=1,
        shuffle=False
    )

Which we can check works correctly by looking at the output from `list(input_data.as_numpy_iterator())`:
```
[319:]   [(OrderedDict([('Feature 1', array([1])), ('Feature 2', array([2]))]),
          array([b'Apple'], dtype=object)),
         (OrderedDict([('Feature 1', array([3])), ('Feature 2', array([4]))]),
          array([b'Banana'], dtype=object)),
         (OrderedDict([('Feature 1', array([5])), ('Feature 2', array([6]))]),
          array([b'Coconut'], dtype=object)),
         (OrderedDict([('Feature 1', array([7])), ('Feature 2', array([8]))]),
          array([b'Durian'], dtype=object)),
         (OrderedDict([('Feature 1', array([9])), ('Feature 2', array([10]))]),
          array([b'Eggplant'], dtype=object)),
         (OrderedDict([('Feature 1', array([11])), ('Feature 2', array([12]))]),
          array([b'Fruit'], dtype=object))]
```

We can then feed `input_data` to the next function:

    my_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(
        input_data,
        targets=None,
        sequence_length=3,
        sequence_stride=2,
        sampling_rate=1,  
        batch_size=1,
        shuffle=False
    )

Which unfortunately **throws this error**:

    [342]:  ~\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in __len__(self)
            452       raise TypeError(""dataset length is infinite."")
            453     if length.numpy() == UNKNOWN:
        --> 454       raise TypeError(""dataset length is unknown."")
            455     return length
            456 
    
    TypeError: dataset length is unknown.

I also tried using `my_dataset = input_data.window(3, shift=2)` (see the [tf.data.Dataset.window][3] documentation) and it didn't throw an error, but it seems to be returning an **empty dataset**? See ""*_VariantDataset shapes: (None,)*"" in the output:

    list(input_data.window(3, shift=2))

    [344]:
    [(OrderedDict([('Feature 1',
                    <_VariantDataset shapes: (None,), types: tf.int32>),
                   ('Feature 2',
                    <_VariantDataset shapes: (None,), types: tf.int32>)]),
      <_VariantDataset shapes: (None,), types: tf.string>),
     (OrderedDict([('Feature 1',
                    <_VariantDataset shapes: (None,), types: tf.int32>),
                   ('Feature 2',
                    <_VariantDataset shapes: (None,), types: tf.int32>)]),
      <_VariantDataset shapes: (None,), types: tf.string>),
     (OrderedDict([('Feature 1',
                    <_VariantDataset shapes: (None,), types: tf.int32>),
                   ('Feature 2',
                    <_VariantDataset shapes: (None,), types: tf.int32>)]),
      <_VariantDataset shapes: (None,), types: tf.string>)]

If I load the ""*sample_data.csv*"" in memory using pandas and then feed the *timeseries_dataset_from_array* function a numpy array instead, it works correctly.

Any ideas on how to solve this? **What's the best method to input overlapping windows from off-memory time-series data into TensorFlow**?

Thank you!


  [1]: https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset
  [2]: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array
  [3]: https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window"
49168, Could not compute output KerasTensor,"I am trying to train a generator model, for which I am combining the generator and discriminator models.
The code:
```
  import tensorflow as tf
  import os
  import numpy as np
  import PIL
  from PIL import Image
  from tqdm import tqdm
  
  class Localization(tf.keras.layers.Layer):
      def __init__(self):
          super(Localization, self).__init__()
          self.bpool1 = tf.keras.layers.MaxPool2D()
          self.bpool2 = tf.keras.layers.MaxPool2D()
          self.bpool3 = tf.keras.layers.MaxPool2D()
          self.bpool4 = tf.keras.layers.MaxPool2D()
          
          self.mpool1 = tf.keras.layers.MaxPool2D()
          self.mpool2 = tf.keras.layers.MaxPool2D()
          self.mpool3 = tf.keras.layers.MaxPool2D()
          self.mpool4 = tf.keras.layers.MaxPool2D()
  
          self.bconv1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
          self.bconv2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
          self.bconv3 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
          self.bconv4 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
          self.bconv5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
          self.bconv6 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
          self.bconv7 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
          self.bconv8 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
  
          self.mconv1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
          self.mconv2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')
          self.mconv3 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
          self.mconv4 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')
          self.mconv5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
          self.mconv6 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')
          self.mconv7 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
          self.mconv8 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
          
          self.concatenate1 = tf.keras.layers.concatenate
          self.concatenate2 = tf.keras.layers.concatenate
  
          self.flatten = tf.keras.layers.Flatten()
          self.fc0 = tf.keras.layers.Dense(100, activation='relu')
          self.fc1 = tf.keras.layers.Dense(20, activation='relu')
          self.fc2 = tf.keras.layers.Dense(6, activation=None, bias_initializer=tf.keras.initializers.constant([1.0, 0.0, 0.0, 0.0, 1.0, 0.0]), kernel_initializer='zeros')
  
      def build(self, input_shape):
          print(""Building Localization Network with input shape:"", input_shape)
  
      def compute_output_shape(self, input_shape):
          return [None, 6]
  
      def call(self, inputs):
          mask, fg, bg = inputs
          xm = self.concatenate1([fg, mask])
          xm = self.mconv1(xm)
          xm = self.mconv2(xm)
          xm = self.mpool1(xm)
  
          xm = self.mconv3(xm)
          xm = self.mconv4(xm)
          xm = self.mpool2(xm)
  
          xm = self.mconv5(xm)
          xm = self.mconv6(xm)
          xm = self.mpool3(xm)
  
          xm = self.mconv7(xm)
          xm = self.mconv8(xm)
          xm = self.mpool4(xm)
  
  
          xbg = self.bconv1(bg)
          xbg = self.bconv2(xbg)
          xbg = self.bpool1(xbg)
          
          xbg = self.bconv3(xbg)
          xbg = self.bconv4(xbg)
          xbg = self.bpool2(xbg)
          
          xbg = self.bconv5(xbg)
          xbg = self.bconv6(xbg)
          xbg = self.bpool3(xbg)
          
          xbg = self.bconv7(xbg)
          xbg = self.bconv8(xbg)
          xbg = self.bpool4(xbg)
  
          x = self.concatenate2((xbg, xm))
          x = self.flatten(x)
          x = self.fc0(x)
          x = self.fc1(x)
          theta = self.fc2(x)
          theta = tf.keras.layers.Reshape((2, 3))(theta)
          return theta
  
  class BilinearInterpolation(tf.keras.layers.Layer):
      def __init__(self, height=320, width=320):
          super(BilinearInterpolation, self).__init__()
          self.height = height
          self.width = width
  
      def compute_output_shape(self, input_shape):
          return [None, self.height, self.width, 1]
  
      def get_config(self):
          return {
              'height': self.height,
              'width': self.width,
          }
      
      def build(self, input_shape):
          print(""Building Bilinear Interpolation Layer with input shape:"", input_shape)
  
      def advance_indexing(self, inputs, x, y):
          '''
          Numpy like advance indexing is not supported in tensorflow, hence, this function is a hack around the same method
          '''        
          shape = tf.shape(inputs)
          batch_size, _, _ = shape[0], shape[1], shape[2]
          
          batch_idx = tf.range(0, batch_size)
          batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))
          b = tf.tile(batch_idx, (1, self.height, self.width))
          indices = tf.stack([b, y, x], 3)
          return tf.gather_nd(inputs, indices)
  
      def call(self, inputs):
          images, theta = inputs
          homogenous_coordinates = self.grid_generator(batch=tf.shape(images)[0])
          return self.interpolate(images, homogenous_coordinates, theta)
  
      def grid_generator(self, batch):
          x = tf.linspace(-1, 1, self.width)
          y = tf.linspace(-1, 1, self.height)
              
          xx, yy = tf.meshgrid(x, y)
          xx = tf.reshape(xx, (-1,))
          yy = tf.reshape(yy, (-1,))
          homogenous_coordinates = tf.stack([xx, yy, tf.ones_like(xx)])
          homogenous_coordinates = tf.expand_dims(homogenous_coordinates, axis=0)
          homogenous_coordinates = tf.tile(homogenous_coordinates, [batch, 1, 1])
          homogenous_coordinates = tf.cast(homogenous_coordinates, dtype=tf.float32)
          return homogenous_coordinates
      
      def interpolate(self, images, homogenous_coordinates, theta):
  
          with tf.name_scope(""Transformation""):
              transformed = tf.matmul(theta, homogenous_coordinates)
              transformed = tf.transpose(transformed, perm=[0, 2, 1])
              transformed = tf.reshape(transformed, [-1, self.height, self.width, 2])
                  
              x_transformed = transformed[:, :, :, 0]
              y_transformed = transformed[:, :, :, 1]
                  
              x = ((x_transformed + 1.) * tf.cast(self.width, dtype=tf.float32)) * 0.5
              y = ((y_transformed + 1.) * tf.cast(self.height, dtype=tf.float32)) * 0.5
  
          with tf.name_scope(""VariableCasting""):
              x0 = tf.cast(tf.math.floor(x), dtype=tf.int32)
              x1 = x0 + 1
              y0 = tf.cast(tf.math.floor(y), dtype=tf.int32)
              y1 = y0 + 1
  
              x0 = tf.clip_by_value(x0, 0, self.width-1)
              x1 = tf.clip_by_value(x1, 0, self.width-1)
              y0 = tf.clip_by_value(y0, 0, self.height-1)
              y1 = tf.clip_by_value(y1, 0, self.height-1)
              x = tf.clip_by_value(x, 0, tf.cast(self.width, dtype=tf.float32)-1.0)
              y = tf.clip_by_value(y, 0, tf.cast(self.height, dtype=tf.float32)-1)
  
          with tf.name_scope(""AdvanceIndexing""):
              Ia = self.advance_indexing(images, x0, y0)
              Ib = self.advance_indexing(images, x0, y1)
              Ic = self.advance_indexing(images, x1, y0)
              Id = self.advance_indexing(images, x1, y1)
  
          with tf.name_scope(""Interpolation""):
              x0 = tf.cast(x0, dtype=tf.float32)
              x1 = tf.cast(x1, dtype=tf.float32)
              y0 = tf.cast(y0, dtype=tf.float32)
              y1 = tf.cast(y1, dtype=tf.float32)
                              
              wa = (x1-x) * (y1-y)
              wb = (x1-x) * (y-y0)
              wc = (x-x0) * (y1-y)
              wd = (x-x0) * (y-y0)
  
              wa = tf.expand_dims(wa, axis=3)
              wb = tf.expand_dims(wb, axis=3)
              wc = tf.expand_dims(wc, axis=3)
              wd = tf.expand_dims(wd, axis=3)
                          
          return tf.math.add_n([wa*Ia + wb*Ib + wc*Ic + wd*Id])
  
  class Composition(tf.keras.layers.Layer):
      def __init__(self):
          super(Composition, self).__init__()
      def build(self, input_shape):
          print(""Building Composition Network with input shape:"", input_shape)
  
      def compute_output_shape(self, input_shape):
          return input_shape
  
      def call(self, inputs):
          mask, fg, bg = inputs
          multiples = tf.constant([1, 1, 1, 3], tf.int32)
          mask_mod = tf.tile(mask, multiples)
          bg_mod = tf.keras.layers.Multiply()([bg, 1-mask_mod])
          fg_mod = tf.keras.layers.Multiply()([fg, mask_mod])
          composite_image = tf.keras.layers.Add()([bg_mod, fg_mod])
          
          return composite_image
  
  def gen_model(input_shape):
      mask = tf.keras.layers.Input(shape=(input_shape[0], input_shape[1], 1))
      fg = tf.keras.layers.Input(shape=(input_shape[0], input_shape[1], input_shape[2]))
      bg = tf.keras.layers.Input(shape=(input_shape[0], input_shape[1], input_shape[2]))
      theta = Localization()([mask, fg, bg])
      xm = BilinearInterpolation(height=input_shape[0], width=input_shape[1])([mask, theta])
      xfg = BilinearInterpolation(height=input_shape[0], width=input_shape[1])([fg, theta])
      composite = Composition()([xm, xfg, bg])
  
      return tf.keras.models.Model(inputs=[mask, fg, bg], outputs=composite, name='generator')
  
  def disc_model(input_shape):
    inp = tf.keras.layers.Input(shape=input_shape) 
    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3),padding='same')(inp)
    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3),padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)
  
    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3),padding='same')(x)
    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3),padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)
    
    x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3),padding='same')(x)
    x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3),padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)
    
    x = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3),padding='same')(x)
    x = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3),padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)
    
    x = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3),padding='same')(x)
    x = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3),padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.MaxPool2D()(x)
    
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(25)(x)
    x = tf.keras.layers.LeakyReLU()(x)
    out = tf.keras.layers.Dense(1, activation='sigmoid')(x)
    return tf.keras.models.Model(inputs=inp, outputs=out, name='discriminator')
  
  
  def stgan2(disc, gen):
    disc.trainable = False
    model = tf.keras.models.Sequential()
    model.add(gen)
    model.add(disc)
  
    model.compile(loss='binary_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), metrics = ['accuracy'])
    return model
  
  gen = gen_model(input_shape=(420, 640, 3))
  
  dis = disc_model(input_shape=(420, 640, 3))
  
  gan = stgan2(dis, gen)
```

The error:
AssertionError: Could not compute output KerasTensor(type_spec=TensorSpec(shape=(None, 420, 640, 3), dtype=tf.float32, name=None), name='composition/add/add:0', description=""created by layer 'composition'"")

Colab [link](https://colab.research.google.com/drive/1oMbH2Ka1hNcVZgyzf9Uahx9Snufv_aTv?usp=sharing)

"
49167,Could not load dynamic library 'libcusolver.so.10:No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64,"TF2.4
CUDA 11.2


When I import tensorflow and list devices, I get this:

`>>> tf.config.list_physical_devices()   
2021-03-18 10:56:30.410381: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-18 10:56:30.411387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-18 10:56:30.451723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-03-18 10:56:30.451771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-18 10:56:30.454059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-18 10:56:30.454124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-18 10:56:30.454855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-18 10:56:30.455023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-18 10:56:30.455150: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64
2021-03-18 10:56:30.455675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-18 10:56:30.455764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-18 10:56:30.455776: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
`


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):2.4
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:11.2
- GPU model and memory:

"
49165,`tf.data.experimental.load` segfaults when using repeat and prefetch,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Centos 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): 2.4.0
- TensorFlow version (use command below): 2.4.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Using the following simple script, we can see a segmentation fault:
```python
import tensorflow as tf
import numpy as np
dataset1 = tf.data.Dataset.from_tensor_slices(np.random.rand(16, 1024))
tf.data.experimental.save(dataset1, 'snapshot')
dataset = tf.data.experimental.load('snapshot')
dataset = dataset.shuffle(buffer_size=16)
dataset = dataset.batch(16)
dataset = dataset.repeat()
dataset = dataset.prefetch(1)
def run(dataset):
    iterator = iter(dataset)
    for _ in range(30):
        next(iterator)
for _ in range(10):
    run(dataset) 
```
If we run it with Tensorflow 2.4.0 (or Tensorflow 2.4.1), the output is:
```
...
2021-05-04 11:04:17.989897: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-04 11:04:17.990504: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2596985000 Hz
Segmentation fault (core dumped)
```
If either of `load` or `repeat` or `prefetch` is removed, this would not occur.

**Describe the expected behavior**
The expected behavior is that there would not be a segmentation fault
**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - yes
Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
import numpy as np
dataset1 = tf.data.Dataset.from_tensor_slices(np.random.rand(16, 1024))
tf.data.experimental.save(dataset1, 'snapshot')
dataset = tf.data.experimental.load('snapshot')
dataset = dataset.shuffle(buffer_size=16)
dataset = dataset.batch(16)
dataset = dataset.repeat()
dataset = dataset.prefetch(1)
def run(dataset):
    iterator = iter(dataset)
    for _ in range(30):
        next(iterator)
for _ in range(10):
    run(dataset)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Analyzing the core dump, this is the truncated stack trace:
```
        tensorflow::data::experimental::LoadDatasetOp::Dataset::Iterator::~Iterator()
        tensorflow::data::DatasetBase::MakeIterator(tensorflow::data::IteratorContext*, tensorflow::data::IteratorBase const*, std::string const&, std::unique_ptr<tensorflow::data::IteratorBase, std::default_delete<tensorflow::data::IteratorBase> >*) const
        tensorflow::data::ShuffleDatasetOpBase::ShuffleDatasetBase::Iterator::GetNextInternal(tensorflow::data::IteratorContext*, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, bool*)
        tensorflow::data::DatasetBaseIterator::GetNext(tensorflow::data::IteratorContext*, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, bool*)
        tensorflow::data::BatchDatasetOp::Dataset::Iterator::GetNextInternal(tensorflow::data::IteratorContext*, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, bool*)
        tensorflow::data::DatasetBaseIterator::GetNext(tensorflow::data::IteratorContext*, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, bool*)
        tensorflow::data::RepeatDatasetOp::Dataset::ForeverIterator::GetNextInternal(tensorflow::data::IteratorContext*, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, bool*)
        tensorflow::data::DatasetBaseIterator::GetNext(tensorflow::data::IteratorContext*, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, bool*)
        tensorflow::data::PrefetchDatasetOp::Dataset::Iterator::PrefetchThread(std::shared_ptr<tensorflow::data::IteratorContext> const&)

        std::_Function_handler<void (), std::_Bind<void (*(std::function<void ()>, std::shared_ptr<tensorflow::Notification>))(std::function<void ()> const&, std::shared_ptr<tensorflow::Notification>)> >::_M_invoke(std::_Any_data const&)
        tensorflow::UnboundedWorkQueue::PooledThreadFunc()
```"
49164,Parallel execution operator scheduling seems to be inconsistent across runs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2.89
- GPU model and memory: 512-core Volta GPU with Tensor Cores
--

**Describe the current behavior**
I'm trying to run a small computational graph in parallel on both CPU and GPU. The computational graph is shown below.
![image](https://user-images.githubusercontent.com/23744021/118153973-1cd5ba00-b434-11eb-98cf-d75e3d2b0ee3.png)
I want Conv1, Conv2 and Conv4 to be executed on GPU and Conv3 to be executed on CPU. After mapping the operators to the required device, I'm observing inconsistent operator scheduling when executing the graph across multiple runs. You can observe three different execution trace for the same computational graph. These three traces have different total inference or run times. They vary from 300ms to 400ms.  
![image](https://user-images.githubusercontent.com/23744021/118152724-aa180f00-b432-11eb-8640-4c0a2103fa5e.png)
![image](https://user-images.githubusercontent.com/23744021/118154468-b7ce9400-b434-11eb-9282-928fb6c6c96b.png)
![image](https://user-images.githubusercontent.com/23744021/118154589-dcc30700-b434-11eb-814d-aa2a0d8b6e26.png)

**Describe the expected behavior**
Its expected to produce the first trace output shown above where both operation on CPU and GPU starts executing in parallel at almost the same time. 

**Standalone code to reproduce the issue**
Please find the code snippet [here](https://gist.github.com/surya00060/a0bcf49a53353011c36bf5290fa81355)"
49162,Failure to load model files.,"I have a tensorflow model that I train using customizing the model.fit() as in following link
https://keras.io/guides/customizing_what_happens_in_fit/
Now when I save the model using ModelCheckpoint callback and then later try to reload the model (using tf.keras.models.Model.load_model) or weights (model.load_weights), I am unable to do that, with the following errors:

with _.load_model()_
> ValueError: No model found in config file. 

with _.load_weights()_
> ValueError: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights.

My models are defined using FunctionalAPI (https://keras.io/guides/functional_api/).

I am currently working with tensorflow==2.4.1 but I have faced a similar issue with 2.2.0 before.

Back then, to solve this issue, I wrote my own custom callback to save the model (using `.save()`) and then reload with `.load_model()`, as I discuss in this article [link](https://medium.com/dive-into-ml-ai/customization-of-model-fit-to-write-a-combined-discriminator-generator-gan-trainer-in-keras-524bce10cf66). But I was wondering if there is a default way to this."
49161,Progbar prints invalid metrics value when using multiple thresholds,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- TensorFlow version: 2.4.1
- Python version: 3.8.8

**Describe the current behavior**
Progbar prints mean metric value of all thersholds

**Describe the expected behavior**
Progbar prints first value or value for default threshold (0.5)

**Standalone code to reproduce the issue**
https://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/python/keras/utils/generic_utils.py#L625
https://colab.research.google.com/drive/1zEa5GB9e8IrufWlHVw2Cc35euc8aXGKy?usp=sharing
"
49160,No operations will run on the GPU for mobilenet_v1_1.0_224_quant.tflite using C++,"Hello.

I tired to load mobilenet_v1_1.0_224_quant.tflite from tflite example (tensorflow/lite/java/demo/app/src/main/), but it print errors to log:

```
Following operations are not supported by GPU delegate:
    AVERAGE_POOL_2D: OP is supported, but tensor type isn't matched!
    CONV_2D: OP is supported, but tensor type isn't matched!
    DEPTHWISE_CONV_2D: OP is supported, but tensor type isn't matched!
    RESHAPE: OP is supported, but tensor type isn't matched!
    SOFTMAX: OP is supported, but tensor type isn't matched!
    No operations will run on the GPU, and all 31 operations will run on the CPU.
```

I use this code to load:

```
  tflite::InterpreterBuilder interpreter_builder(flatbuffer, op_resolver);
  if (interpreter_builder(&interpreter) != kTfLiteOk || !interpreter) {
    return absl::InternalError(""Unable to prepare TfLite interpreter."");
  }
  TfLiteGpuDelegateOptionsV2 options = TfLiteGpuDelegateOptionsV2Default();
  TfLiteDelegate* delegate = TfLiteGpuDelegateV2Create(&options);

  DelegateContext::DelegateData delegate_data{interpreter->inputs(),
                                              interpreter->outputs(), graph};

  delegate->data_ = &delegate_data;
  delegate->flags = kTfLiteDelegateFlagsNone;
  delegate->Prepare = DelegatePrepare;
  delegate->CopyFromBufferHandle = nullptr;
  delegate->CopyToBufferHandle = nullptr;
  delegate->FreeBufferHandle = nullptr;

  if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk)  // Error prints in in this call.
```

Why TFlite cannot run mobilenet_v1_1.0_224_quant.tflite on GPU? Or is it ok?

If I load mobilenet_v1_1.0_224_quant.tflite using Java interface I don't have any errors in log.

I have built TFlite by my self, run on Android Google Pixel 2."
49159,Checkpoint` was expecting a trackable object,"

**System information**

- OS Platform and Distribution: Linux Ubuntu 18.04.5
- Python version: 3.7
- tensorflow_gpu: 2.4.1
- CUDA/cuDNN version: 11.3/7.6.5



**Description**
All models are written in tf.keras.
I wanted to do a hyperparameter tuning for the model and vary the number of convultional layers, bottleneck layers, but now the discriminator model seems to be no longer trackable.
Can anyone help?

**Output**
```python
ValueError                                Traceback (most recent call last)
<ipython-input-124-88c04dabe8f8> in <module>
     21           print('--- Starting trial: %s' % run_name)
     22           print({h.name: hparams[h] for h in hparams})
---> 23           run('logs/hparam_tuning/' + run_name, hparams,train_256=train256_dataset,test_256=test256_dataset,EPOCHS=5)
     24           session_num += 1

<ipython-input-72-992a1cf189f8> in run(run_dir, hparams, train_256, test_256, EPOCHS)
      3      with tf.summary.create_file_writer(run_dir).as_default():
      4         hp.hparams(hparams)
----> 5         gen_l1_loss,disc_loss=train_test(hparams,train_256,test_256,EPOCHS=EPOCHS)
      6         tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)
      7         tf.summary.scalar('disc_loss', disc_loss, step=epoch)

<ipython-input-123-120ded423bb9> in train_test(hparams, train_256, test_256, EPOCHS)
    129                                      discriminator_optimizer=discriminator_optimizer,
    130                                      generator=generator,
--> 131                                      discriminator=discriminator)
    132     log_dir=""logs/""
    133     sum_log=f""{log_dir} {model_name}/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}""

~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py in __init__(self, root, **kwargs)
   1927       # v to a Trackable data structure when v is a list/dict/tuple.
   1928       converted_v = getattr(self, k)
-> 1929       _assert_trackable(converted_v)
   1930 
   1931       if root:

~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py in _assert_trackable(obj)
   1413         ""object should be trackable (i.e. it is part of the ""
   1414         ""TensorFlow Python API and manages state), please open an issue.""
-> 1415         .format(obj))
   1416 
   1417 

ValueError: `Checkpoint` was expecting a trackable object (an object derived from `TrackableBase`), got <function train_test.<locals>.Discriminator at 0x7fa5a8174f80>. If you believe this object should be trackable (i.e. it is part of the TensorFlow Python API and manages state), please open an issue.
```


"
49158,Inference with small tflite model does not benefit from warm up,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-73-lowlatency x86_64)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Desktop
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.6.0
- Python version: n/a
- Bazel version (if compiling from source): 4.0.0
- GCC/Compiler version (if compiling from source): GCC 10.2.0

**Describe the current behavior**
Inference with small tflite model does not benefit from warm up. TFlite Benchmarking Tool indicates that it should.

**Describe the expected behavior**
When benchmarking my tflite-model with the TFlite Benchmarking Tool I cleary see a speed up in steady stage after the initial warm ups. `Inference timings in us: Init: 769, First inference: 533, Warmup (avg): 14.6845, Inference (avg): 15.5197`

When I'm running inference in my C++ code, the inference speed is always around 300-500 us. If I read the benchmarking tool output correctly, it should be able to reach well below 100 us after warm up.

The result from the benchmarking tool ->

```
STARTING!
Log parameter values verbosely: [0]
Num threads: [1]
Graph: [/home/gustaf/cprojects/pacific/nlp/en/model.tflite]
#threads used for CPU inference: [1]
Loaded model /home/gustaf/cprojects/pacific/nlp/en/model.tflite
The input model file size (MB): 0.367488
Initialized session in 0.769ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=33776 first=533 curr=14 min=13 max=533 avg=14.6845 std=3

Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=63948 first=14 curr=17 min=13 max=90 avg=15.5197 std=2

Inference timings in us: Init: 769, First inference: 533, Warmup (avg): 14.6845, Inference (avg): 15.5197
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Peak memory footprint (MB): init=0.574219 overall=0.574219
```

**Standalone code to reproduce the issue**

Output ->
```
Prediction 1: 477 us
Prediction 2: 307 us
Prediction 3: 320 us
Prediction 4: 319 us
Prediction 5: 299 us
```

Code ->
```
#include <tensorflow/lite/interpreter.h>
#include <tensorflow/lite/model.h>
#include <tensorflow/lite/kernels/register.h>
#include <iomanip>
#include <iostream>
#include <mutex>
#include <fstream>
#include ""tbb/concurrent_unordered_map.h""
#include <unicode/unistr.h>
#include <unicode/ustream.h>
#include <unicode/locid.h>
#include <chrono>
#include <boost/algorithm/string.hpp>

std::mutex mtx;

using namespace std;
using namespace std::chrono_literals;
using std::chrono::high_resolution_clock;
using std::chrono::duration_cast;
using std::chrono::duration;
using std::chrono::microseconds;	

tflite::ops::builtin::BuiltinOpResolver resolver_sv;
std::unique_ptr<tflite::FlatBufferModel> model_sv;
std::unique_ptr<tflite::Interpreter> interpreter_sv;
tbb::concurrent_unordered_map<string, int> vocab_sv;

float predict(string ss) {
	std::scoped_lock lock{mtx};
	int* input;
	float* output; 
	string s;
	icu::UnicodeString ustr(ss.c_str());
	ustr.toLower();
	ustr.toUTF8String(s);
	
	input = interpreter_sv->typed_input_tensor<int>(0);
	
	std::vector<std::string> result;
	boost::algorithm::split(result, s, boost::is_any_of("" *""), boost::token_compress_on);

	int i = 0;
	for(auto& word: result) { 
		try {
			input[i] = vocab_sv.at(word);
			i = i+1;
		}
		catch (const std::out_of_range& oor) {
			input[i] = 1;
			i = i+1;
		}
	}
	while(i<=20) {
		input[i] = 0;
		i = i+1;
	}

	interpreter_sv->Invoke();
	output = interpreter_sv->typed_output_tensor<float>(0);

	return output[0];
}

void init_model(){

	model_sv = tflite::FlatBufferModel::BuildFromFile(""/home/gustaf/cprojects/pacific/nlp/en/model.tflite"");
		
	if (model_sv == nullptr) {
			std::cerr << ""Model not found!"" << std::endl;
		}
	if (tflite::InterpreterBuilder(*model_sv, resolver_sv)(&interpreter_sv) != kTfLiteOk) {
		std::cerr << ""Failed to build interpreter!"" << std::endl;
		}

	interpreter_sv->SetNumThreads(1);

	if (interpreter_sv->AllocateTensors() != kTfLiteOk) {
		std::cerr << ""Failed to allocate tensors."" << std::endl;
	}
	if (interpreter_sv->Invoke() != kTfLiteOk) {
		std::cerr << ""Cannot invoke interpreter"" << std::endl;
	  }
	 
	ifstream infile(""/home/gustaf/cprojects/pacific/nlp/en/vocab.txt"");
	string a;
	int b;
	while (infile >> a >> b) {vocab_sv.insert(pair<string, int>(a, b));}

}

int main (){
	
	init_model();
	
	auto t1 = high_resolution_clock::now();
	predict(""This is a warmup text"");
	auto t2 = high_resolution_clock::now();
	predict(""This is another warmup text"");
	auto t3 = high_resolution_clock::now();
	predict(""This is an example text"");
	auto t4 = high_resolution_clock::now();
	predict(""This is another example text"");
	auto t5 = high_resolution_clock::now();
	predict(""This is the final text"");
	auto t6 = high_resolution_clock::now();


auto ms1 = duration_cast<microseconds>(t2 - t1);
auto ms2 = duration_cast<microseconds>(t3 - t2);
auto ms3 = duration_cast<microseconds>(t4 - t3);
auto ms4 = duration_cast<microseconds>(t5 - t4);
auto ms5 = duration_cast<microseconds>(t6 - t5);

cout << ""Prediction 1: "" << ms1.count() << "" us"" << endl;
cout << ""Prediction 2: "" << ms2.count() << "" us"" << endl;
cout << ""Prediction 3: "" << ms3.count() << "" us"" << endl;
cout << ""Prediction 4: "" << ms4.count() << "" us"" << endl;
cout << ""Prediction 5: "" << ms5.count() << "" us"" << endl;

}
```


"
49157,Internal error: Failed to run on the given Interpreter: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.," I use tf.image.combined_non_max_suppression in my model. I can transfer it to tflite. But when I use it in Android or use python tf.lite.interpreter, I got the issue.
![118105343-d752c600-b40e-11eb-9810-5a12f18e1ce3](https://user-images.githubusercontent.com/54882489/118111091-cd809100-b415-11eb-9aca-f6ee3fd0b5ef.png)
How can I resolve it?"
49156,Convert from TF 1.8 checkpoint to TF2 SavedModel : variables not visible,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): From dockerhub
- TensorFlow version (use command below): 2.41
- Python version: '3.6.9 (default, Oct  8 2020, 12:12:24) \n[GCC 8.4.0]'
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0
- GPU model and memory: 1080ti, 10GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

```
2021-05-13 09:38:26.223909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
v2.4.0-49-g85c8b2a817f 2.4.1
```

**Describe the current behavior**

The converted and loaded FuncGraph's variables is not visible.

I converted it by the script below. as you can see, I ran `tf.compat.v1.enable_resource_variables()
` before building the model.
```python
import os
from tensorflow.python.saved_model import signature_constants
from tensorflow.python.saved_model import tag_constants
tf.compat.v1.enable_resource_variables()


trained_checkpoint_prefix = '../pretrained/model.ckpt'
export_dir = os.path.join('../total_exported')

target_tensors = {}
all_tensors = []
all_nodes = []
all_placeholders = []
graph = tf.Graph()
tensor_info_inputs = []
tensor_info_outputs = []

with tf.compat.v1.Session(graph=graph) as sess:
    # Restore from checkpoint
    loader = tf.compat.v1.train.import_meta_graph(trained_checkpoint_prefix + '.meta')
    loader.restore(sess, trained_checkpoint_prefix)
    # all_nodes = [n for n in tf.compat.v1.get_default_graph().as_graph_def().node]
    print(graph)
    all_nodes = [n for n in graph.as_graph_def().node]
    all_tensors = all_tensors + [tensor for op in graph.get_operations() for tensor in op.values()]
    all_placeholders = [placeholder for op in graph.get_operations() if op.type=='Placeholder' for placeholder in op.values()]
    
    for tensor in all_tensors:
        if tensor.name == 'resnet_v2_101/predictions/Reshape_1:0':
            target_tensors['feature'] = tensor
        elif tensor.name == 'Placeholder:0':
            target_tensors['img'] = tensor
        elif tensor.name == 'Placeholder_1:0':
            target_tensors['kp_map_gt'] = tensor
        elif tensor.name == 'Placeholder_2:0':
            target_tensors['short_offset_gt'] = tensor
        elif tensor.name == 'Placeholder_3:0':
            target_tensors['mid_offset_gt'] = tensor
        elif tensor.name == 'Placeholder_4:0':
            target_tensors['long_offset_gt'] = tensor
        elif tensor.name == 'Placeholder_5:0':
            target_tensors['seg_mask_gt'] = tensor
        elif tensor.name == 'Placeholder_6:0':
            target_tensors['crowd_mask'] = tensor
        elif tensor.name == 'Placeholder_7:0':
            target_tensors['unannotated_mask'] = tensor
        elif tensor.name == 'Placeholder_8:0':
            target_tensors['overlap_mask'] = tensor
        elif tensor.name == 'short_offsets/BiasAdd:0':
            target_tensors['short_offset'] = tensor
        elif tensor.name == 'mid_offsets/BiasAdd:0':
            target_tensors['mid_offset'] = tensor
        elif tensor.name == 'long_offsets/BiasAdd:0':
            target_tensors['long_offset'] = tensor
        elif tensor.name == 'kp_maps/Sigmoid:0':
            target_tensors['kp_map'] = tensor
        elif tensor.name == 'seg_mask/Sigmoid:0':
            target_tensors['seg_mask'] = tensor

    tensor_info_inputs = {
              'img': tf.compat.v1.saved_model.build_tensor_info(target_tensors['img']),  
              'kp_map_gt': tf.compat.v1.saved_model.build_tensor_info(target_tensors['kp_map_gt']),
              'short_offset_gt': tf.compat.v1.saved_model.build_tensor_info(target_tensors['short_offset_gt']),
              'mid_offset_gt': tf.compat.v1.saved_model.build_tensor_info(target_tensors['mid_offset_gt']),
              'long_offset_gt': tf.compat.v1.saved_model.build_tensor_info(target_tensors['long_offset_gt']),
              'seg_mask_gt': tf.compat.v1.saved_model.build_tensor_info(target_tensors['seg_mask_gt']),
              'crowd_mask': tf.compat.v1.saved_model.build_tensor_info(target_tensors['crowd_mask']),
              'unannotated_mask': tf.compat.v1.saved_model.build_tensor_info(target_tensors['unannotated_mask']),
              'overlap_mask': tf.compat.v1.saved_model.build_tensor_info(target_tensors['overlap_mask']),
    }
    tensor_info_outputs = {
        'feature' : tf.compat.v1.saved_model.build_tensor_info(target_tensors['feature']),
        'short_offset' : tf.compat.v1.saved_model.build_tensor_info(target_tensors['short_offset']),
        'mid_offset' : tf.compat.v1.saved_model.build_tensor_info(target_tensors['mid_offset']),
        'long_offset' : tf.compat.v1.saved_model.build_tensor_info(target_tensors['long_offset']),
        'kp_map' : tf.compat.v1.saved_model.build_tensor_info(target_tensors['kp_map']),
        'seg_mask' : tf.compat.v1.saved_model.build_tensor_info(target_tensors['seg_mask']),
    }

    detection_signature = (
            tf.compat.v1.saved_model.build_signature_def(
                  inputs=tensor_info_inputs,
                  outputs=tensor_info_outputs,
            method_name='total'))

    # Export checkpoint to SavedModel
    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)
    builder.add_meta_graph_and_variables(
              sess, [tf.saved_model.SERVING],
              signature_def_map={
                  'total': detection_signature,
              },
          )
    
#     builder.add_meta_graph_and_variables(sess,
#                                          [tf.saved_model.TRAINING, tf.saved_model.SERVING],
#                                          strip_default_attrs=True)
    builder.save()
```

And warn message shows up.
```python
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/conv1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/conv1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/conv1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/conv1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
```

with no visible variables.
```python
import tensorflow as tf
tf.compat.v1.enable_resource_variables()
model = tf.compat.v1.saved_model.load_v2('../total_exported')
f = model.signatures['total']
outputs = f(**inputs)

model.graph.variables
# ()
```



**Describe the expected behavior**

Loaded model has graph with visible variables.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49155,problem using tf.compat.v1.get_variable in tf2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macos mojave 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source):no
- GCC/Compiler version (if compiling from source):no
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
reference：https://www.tensorflow.org/api_docs/python/tf/compat/v1/get_variable?hl=en
I referenced the above links and got the following results
v1:<tf.Variable 'foo/v:0' shape=(1,) dtype=float32, numpy=array([1.3727096], dtype=float32)>
v2:<tf.Variable 'foo/v:0' shape=(1,) dtype=float32, numpy=array([-1.0603657], dtype=float32)>

**Describe the expected behavior**
v1 should be equal to v2
When I use tf1, I get the following results：
v1:[0.91463006]
v2:[0.91463006]

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): no
(if contributing):

**Standalone code to reproduce the issue**
reference：https://www.tensorflow.org/api_docs/python/tf/compat/v1/get_variable?hl=en
tf2 version:
```import tensorflow as tf
def foo():
    with tf.compat.v1.variable_scope(""foo"", reuse=tf.compat.v1.AUTO_REUSE):
        v = tf.compat.v1.get_variable(""v"", [1], initializer=tf.compat.v1.glorot_uniform_initializer())
        return v
v1 = foo()
v2 = foo()
print(v1)
print(v2)
```
tf1 version:
```import tensorflow as tf
def foo():
    with tf.compat.v1.variable_scope(""foo"", reuse=tf.compat.v1.AUTO_REUSE):
        v = tf.compat.v1.get_variable(""v"", [1], initializer=tf.compat.v1.glorot_uniform_initializer())
        return v
v1 = foo()
v2 = foo()
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(f'v1:{sess.run(v1)}')
    print(f'v2:{sess.run(v2)}')
```"
49154,TensorBuffer does not support data type: INT32,"
I used tf.image.combined_non_max_suppression in my model to post-process my output.   And I transfer it to tflite file.  When I use the tflite file in the android app.  I found an issue. 
Process: ncu.edu.mao, PID: 26529
    java.lang.AssertionError: TensorBuffer does not support data type: INT32
        at org.tensorflow.lite.support.tensorbuffer.TensorBuffer.createFixedSize(TensorBuffer.java:79)

![image](https://user-images.githubusercontent.com/54882489/118098482-8b038800-b406-11eb-9b08-dccd78b248aa.png)
"
49153,using sampled softmax is slow in 'double-tower' like model #49145,"I'm trying to implement a 'double tower' like recommendation model, as something described in paper 'Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations'. It mentioned to use 'in batch softmax' to learn the embedding. I think this 'in batch softmax' is very likely to the 'sampled softmax' used in word2vec. So I tried to use the tf.nn.nce_loss to implement this logic. I wrote some code try to train a simple model.

    
    graph = tf.Graph()
    vocabulary_size = 300000
    embedding_size = 128
    dense_size = 64
    batch_size = 256
    
    import math
    
    with graph.as_default():
    # Input data.

    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])
    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])
    

    # Ops and variables pinned to the CPU because of missing GPU implementation
    with tf.device('/cpu:0'):
        # Look up embeddings for inputs.
        embeddings = tf.Variable(
            tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
        user = tf.nn.embedding_lookup(embeddings, train_inputs)
        user = tf.layers.dense(user, dense_size, activation='relu')
        user = tf.nn.l2_normalize(user, axis=-1)
        print(user)
        
        right_embedding = tf.Variable(
            tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
        right_hidden = tf.layers.dense(right_embedding, dense_size, activation='relu')
        
        
        nce_biases = tf.Variable(tf.zeros([vocabulary_size]),dtype=tf.float32,trainable=False)

        loss = tf.reduce_mean(
            tf.nn.nce_loss(weights=right_hidden,biases=nce_biases, inputs=user, labels=train_labels,
                 num_sampled=num_sampled, num_classes=vocabulary_size))
        
        optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)
        init = tf.global_variables_initializer()

and I found that the training is really slow. **I doubt that it's because every time tensorflow need to calculate the right_hidden = tf.layers.dense(right_embedding, dense_size, activation='relu'), and the sampled softmax only applies to the last matrix ""right_hidden"", but we still need to calculate the entire right_hidden matrix beforehand**. So am I right? or anyone can give a better solution to deal with the 'sampled softmax' or 'in batch softmax'. thanks 

And here is the colab link to reproduce the result: 
https://colab.research.google.com/drive/11prB0qNvxXAiE-zzD9TtBn4OS8ozVeY_?usp=sharing"
49151,tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f8ef0275730> triggered tf.function retracing.,"`tf version: 2.4.1`
```

import tensorflow as tf
import pandas as pd 
from tensorflow.keras import layers
from tensorflow.keras.callbacks import *
import tensorflow_hub as hub
import tensorflow_text as text
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from tensorflow import keras

class MultiHeadSelfAttention(layers.Layer):
    def __init__(self, embed_dim, num_heads=8):
        super(MultiHeadSelfAttention, self).__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        assert embed_dim % num_heads == 0
        #if embed_dim % num_heads != 0:
        #    raise ValueError(f""embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}"")
        self.projection_dim = embed_dim // num_heads
        self.query_dense = layers.Dense(embed_dim)
        self.key_dense = layers.Dense(embed_dim)
        self.value_dense = layers.Dense(embed_dim)
        self.combine_heads = layers.Dense(embed_dim)

    def attention(self, query, key, value):
        score = tf.matmul(query, key, transpose_b=True)
        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)
        scaled_score = score / tf.math.sqrt(dim_key)
        weights = tf.nn.softmax(scaled_score, axis=-1)
        output = tf.matmul(weights, value)
        return output, weights

    def separate_heads(self, x, batch_size):
        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    def call(self, inputs):
        # x.shape = [batch_size, seq_len, embedding_dim]
        batch_size = tf.shape(inputs)[0]
        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)
        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)
        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)
        query = self.separate_heads(
            query, batch_size
        )  # (batch_size, num_heads, seq_len, projection_dim)
        key = self.separate_heads(
            key, batch_size
        )  # (batch_size, num_heads, seq_len, projection_dim)
        value = self.separate_heads(
            value, batch_size
        )  # (batch_size, num_heads, seq_len, projection_dim)
        attention, weights = self.attention(query, key, value)
        attention = tf.transpose(
            attention, perm=[0, 2, 1, 3]
        )  # (batch_size, seq_len, num_heads, projection_dim)
        concat_attention = tf.reshape(
            attention, (batch_size, -1, self.embed_dim)
        )  # (batch_size, seq_len, embed_dim)
        output = self.combine_heads(
            concat_attention
        )  # (batch_size, seq_len, embed_dim)
        return output

class TransformerBlock(layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()  
        if tf.__version__.startswith('2.4') or tf.__version__.startswith('2.5'):        
            self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        else:
            self.att = MultiHeadSelfAttention(num_heads=num_heads, embed_dim=embed_dim)
        self.ffn = keras.Sequential(
            [layers.Dense(ff_dim, activation=""relu""), layers.Dense(embed_dim),]
        )
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        if tf.__version__.startswith('2.4') or tf.__version__.startswith('2.5'): 
            attn_output = self.att(inputs, inputs)
        else:
            attn_output = self.att(inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)


class TokenAndPositionEmbedding(layers.Layer):
    def __init__(self, maxlen, vocab_size, embed_dim):
        super(TokenAndPositionEmbedding, self).__init__()
        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)
        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)

    def call(self, x):
        maxlen = tf.shape(x)[-1]
        positions = tf.range(start=0, limit=maxlen, delta=1)
        positions = self.pos_emb(positions)
        x = self.token_emb(x)
        return x + positions

preprocessor_file = ""./albert_en_preprocess_3"" # https://tfhub.dev/tensorflow/albert_en_preprocess/3
preprocessor_layer = hub.KerasLayer(preprocessor_file)


def get_model_transormer(num_classes):
    embed_dim = 32  # Embedding size for each token
    num_heads = 2  # Number of attention heads
    ff_dim = 32  # Hidden layer size in feed forward network inside transformer
    
    preprocessor = hub.load(preprocessor_file)
    vocab_size = preprocessor.tokenize.get_special_tokens_dict()['vocab_size'].numpy()

    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string) 

    encoder_inputs = preprocessor_layer(text_input)['input_word_ids']

    embedding_layer = TokenAndPositionEmbedding(encoder_inputs.shape[1], vocab_size, embed_dim)
    x = embedding_layer(encoder_inputs)
    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)
    x = transformer_block(x)
    x = layers.GlobalAveragePooling1D()(x)
    x = layers.Dense(32, activation=""relu"")(x)
    outputs = layers.Dense(num_classes, activation=""softmax"")(x)

    #outputs = layers.Dense(1, activation=""sigmoid"")(x)
    model = keras.Model(inputs=text_input, outputs=outputs)

    model.compile(""adam"", ""categorical_crossentropy"", metrics=[""acc""])
    #model.compile(""adam"", ""binary_crossentropy"", metrics=[""accuracy""])
    return model
```
when I run the initialization code below
`model = get_model_transormer(4)`

there comes the warning info:

> WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f51284a4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.




How to fix my code to avoid this warning ?"
49150,Compilation fails on Ubuntu 20.04 when using TensorRT 8. ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.4.1, 2.5, etc
- Python version: 3.8
- Installed using virtualenv? pip? conda?: no, built from source
- Bazel version (if compiling from source): 3.1 (for TF 2.4.1), 3.7.2 (for TF 2.5.0-rcx)
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
- CUDA/cuDNN version: Cuda 11.1, cudnn8 (8.0.5.39-1+cuda11.1) or Cuda-11-2, libcudnn 8.1.1, 8.2, 
- GPU model and memory: GTX-1080ti
- TensorRT (crucial): 8.0.0-1+cuda11.0, or 8.0.0-1+cuda11.3

**Describe the problem**
When compiling with support for TensorRT 8 (via libnvinfer8), compilation fails (log is below). 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
When configuring the build, make sure you build with TensorRT support, and make sure TensorRT version 8 is selected. Build TF as usual. Compilation will fail. 

If you install  TensorRT version 7 manually (from debs available for Ubuntu 18.04), compilation will complete just fine.

**Any other info / logs**
Relevant error: 
`C++ compilation of rule '//tensorflow/compiler/tf2tensorrt:tensorrt_stub' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command`

`In file included from bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInfer.h:54,
                 from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:17:
bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInferRuntime.h:2264:51: note: from previous declaration 'nvinfer1::IPluginRegistry* getPluginRegistry() noexcept'
 2264 | extern ""C"" TENSORRTAPI nvinfer1::IPluginRegistry* getPluginRegistry() noexcept;`

Full log here: 
[gesdm-tf2.5.0rc3-error.txt](https://github.com/tensorflow/tensorflow/files/6469944/gesdm-tf2.5.0rc3-error.txt)

"
49148,Implement ragged `tf.gather_nd` with `batch_dims > 0`.,"**System information**
- TensorFlow version (you are using): TF 2.4, TF 2.5rc3, TF-nightly
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

Currently, using ragged `tf.gather_nd` with `batch_dims > 0` does not work:
```python
tf.gather_nd(tf.ragged.constant([[1,2], [3,4]]), tf.ragged.constant([[[0]], [[1]]], ragged_rank=1), batch_dims=1)
```
fails with
```python
ValueError: batch_dims != 0 is not supported for ragged gather yet.
```
https://colab.research.google.com/drive/10BIgfMaeO_rL3ZBQqXCHuoW0CZxnhh5S?usp=sharing

I propose for the missing functionality to be implemented.

**Will this change the current api? How?**

The API will stay the same, but an unsupported combination will be implemented.

**Who will benefit with this feature?**

Users using ragged tensors.

**Any Other info.**

Using non-ragged `tf.gather_nd` works
```python
tf.gather_nd(tf.ragged.constant([[1,2], [3,4]]).to_tensor(), tf.ragged.constant([[0], [1]]).to_tensor(), batch_dims=1)
```
as does does ragged `tf.gather_nd` with `batch_dims==0`
```python
tf.gather_nd(tf.ragged.constant([[1,2], [3,4]]), tf.ragged.constant([[[0]], [[1]]], ragged_rank=1), batch_dims=0)
```"
49147,Training grouped Conv2D is slow,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f, 2.4.1
- Python version: 3.7.7
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: 11 / 8.0
- GPU model and memory: Titan RTX, 24 GB

**Describe the current behavior**
Training the two networks defined below takes almost the same amount of time, despite GROUPED using groups=8, which should cut down the FLOPS by ~8x compared to REGULAR. 

**Describe the expected behavior**
Training the two networks should take radically different amounts of time, something closer to ~3 seconds for GROUPED vs ~19 seconds for REGULAR. 

**Standalone code to reproduce the issue**
```python
import sys
import time
import numpy as np
import tensorflow as tf

print(f'sys.version_info: {sys.version_info}')  # sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)
print(f'tf.version.VERSION: {tf.version.VERSION}')  # 2.4.1
print(f'tf.version.GIT_VERSION: {tf.version.GIT_VERSION}')  # v2.4.0-49-g85c8b2a817f

steps = 50
batch_size = 16
input_w = 224
input_shape = (input_w, input_w, 3)

model_grouped = tf.keras.Sequential(layers=[
    tf.keras.layers.Input(shape=input_shape, batch_size=batch_size),
    tf.keras.layers.Conv2D(128, 1, padding='same'),
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 0
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 1
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 2
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 3
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 4
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 5
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 6
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 7
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 8
    tf.keras.layers.Conv2D(128, 3, padding='same', groups=8),  # 9
    tf.keras.layers.GlobalMaxPooling2D(),
    tf.keras.layers.Dense(2),
    tf.keras.layers.Activation('softmax')], name=""Grouped"")

model_regular = tf.keras.Sequential(layers=[
    tf.keras.layers.Input(shape=input_shape, batch_size=batch_size),
    tf.keras.layers.Conv2D(128, 1, padding='same'),
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 0
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 1
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 2
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 3
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 4
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 5
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 6
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 7
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 8
    tf.keras.layers.Conv2D(128, 3, padding='same'),  # 9
    tf.keras.layers.GlobalMaxPooling2D(),
    tf.keras.layers.Dense(2),
    tf.keras.layers.Activation('softmax')], name=""Regular"")

model_grouped.compile(optimizer=tf.optimizers.SGD(0.1, 0.8, True), loss=tf.keras.losses.BinaryCrossentropy())
model_regular.compile(optimizer=tf.optimizers.SGD(0.1, 0.8, True), loss=tf.keras.losses.BinaryCrossentropy())

images = np.full((2 * batch_size, input_w, input_w, 3), 0.5)
labels = np.full((2 * batch_size, 2), 1)

print(""Warming up"")
model_grouped.fit(images, labels, batch_size=batch_size)
model_regular.fit(images, labels, batch_size=batch_size)
print(""Warmup completed"")

images = np.full((steps * batch_size, input_w, input_w, 3), 0.5)
labels = np.full((steps * batch_size, 2), 1)

print(""Training GROUPED model"")
t0 = time.time()
model_grouped.fit(images, labels,
                  batch_size=batch_size)  # 50/50 [==============================] - 16s 317ms/step - loss: 0.0573
delta = time.time() - t0
print(f""Trained GROUPED in {delta: .3f} seconds"")  # Trained GROUPED in  16.019 seconds

print(""Training REGULAR model"")
t0 = time.time()
model_regular.fit(images, labels,
                  batch_size=batch_size)  # 50/50 [==============================] - 19s 387ms/step - loss: 0.0000e+00
delta = time.time() - t0
print(f""Trained REGULAR in {delta: .3f} seconds"")  # Trained REGULAR in  19.492 seconds
```

**Other info / logs** 
```
sys.version_info: sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)
tf.version.VERSION: 2.4.1
tf.version.GIT_VERSION: v2.4.0-49-g85c8b2a817f
2021-05-12 11:07:17.540364: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 11:07:17.541021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-05-12 11:07:17.567324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 24.00GiB deviceMemoryBandwidth: 625.94GiB/s
2021-05-12 11:07:17.567480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-05-12 11:07:17.572104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-05-12 11:07:17.572193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-05-12 11:07:17.574848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-05-12 11:07:17.575756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-05-12 11:07:17.581969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-05-12 11:07:17.583916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-05-12 11:07:17.584412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-05-12 11:07:17.584543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-05-12 11:07:17.584822: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-12 11:07:17.586613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 24.00GiB deviceMemoryBandwidth: 625.94GiB/s
2021-05-12 11:07:17.587022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-05-12 11:07:17.587220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-05-12 11:07:17.587398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-05-12 11:07:17.587488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-05-12 11:07:17.587565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-05-12 11:07:17.587640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-05-12 11:07:17.587707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-05-12 11:07:17.587779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-05-12 11:07:17.587909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-05-12 11:07:18.069972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-12 11:07:18.070055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-05-12 11:07:18.070100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-05-12 11:07:18.070261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21843 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:08:00.0, compute capability: 7.5)
2021-05-12 11:07:18.070704: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
Warming up
2021-05-12 11:07:18.849525: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-12 11:07:19.185194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-05-12 11:07:19.547236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-05-12 11:07:19.554048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-05-12 11:07:20.340878: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

2021-05-12 11:07:20.377477: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

2/2 [==============================] - 6s 311ms/step - loss: 0.6704
2/2 [==============================] - 2s 388ms/step - loss: 0.5845
Warmup completed
Training GROUPED model
50/50 [==============================] - 16s 317ms/step - loss: 0.0573
Trained GROUPED in  16.019 seconds
Training REGULAR model
50/50 [==============================] - 19s 387ms/step - loss: 0.0000e+00
Trained REGULAR in  19.492 seconds

Process finished with exit code 0
```
"
49146,tf.gradients with variable shaped inputs returns error (inverse extract volume patches),"**System information**
- Google Colab
- TF v2.4.1-0-g85c8b2a817f

Using the gradients (as suggested in [#6743](https://github.com/tensorflow/tensorflow/issues/6743#issuecomment-271969125) and on [stackoverflow](https://stackoverflow.com/a/51785735/12528320)) to compute the inverse of `tf.extract_volume_patches` works for statically known input shapes, however it does returns an error when used with variably input shapes.

An minimal example for synthetic 3D MNIST dataset, (it works when `input=(28,28,28,1)` however I need the extraction on variable sized data input (large biomedical images)):
```python

import tensorflow as tf
import numpy as np

def gaussian(x, amp=1, mu=None, sig=None):
    """""" Gaussian function over d dimensions of x
    """"""
    if mu is None:
        mu = np.zeros_like(x)
    if sig is None:
        sig = np.ones_like(x)
    return amp * np.exp(-np.sum(np.square(x - mu) / (2 * np.square(sig))))

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.


multiplier = np.zeros((28,), dtype=np.float32)
for i in range(4):
    multiplier[13-i] = round(gaussian(i),2)
    multiplier[14+i] = round(gaussian(i),2)
print(multiplier)

x_train = np.einsum('bhw,d->bdhw', x_train, multiplier)[...,np.newaxis]


class ExtractPatches(tf.keras.layers.Layer):
    def __init__(self, ksizes, strides, shape):
        super(ExtractPatches, self).__init__()
        self.ksizes = ksizes
        self.strides = strides
        self.shape = shape

    def call(self, inputs):
        patches = tf.extract_volume_patches(inputs,
                                        ksizes=self.ksizes,
                                        strides=self.strides,
                                        padding=""VALID"")
        return tf.reshape(patches, self.shape), tf.shape(inputs)

class CombinePatches(tf.keras.layers.Layer):
    def __init__(self, ksizes, strides):
        super(CombinePatches, self).__init__()
        self.ksizes = ksizes
        self.strides = strides

    def call(self, patches, inputs):
        target_volume = tf.zeros_like(inputs)
        target_patches = tf.extract_volume_patches(
            target_volume,
            ksizes=self.ksizes,
            strides=self.strides,
            padding=""VALID""
        )
        # Creates list of gradient mappings from patches to target shape
        # Patches without overlap get 1, elements that overlap receive 1 
        # times the number of overlaps.
        target_grad_mapping = tf.gradients(target_patches, target_volume)[0]

        # Computes gradients again and dividing by grad, otherwise its just summed.
        return tf.gradients(target_patches, target_volume, patches)[0] / target_grad_mapping


def create_model():
    inputs = tf.keras.layers.Input(shape=(None,None,None,1))
    patches, shape = ExtractPatches(ksizes=[1,14,14,14,1], strides=[1,14,14,14,1], shape=(-1,14,14,14,1))(inputs)
    encoded = tf.keras.layers.Conv3D(filters=28, kernel_size=(14,14,14), strides=(14,14,14))(patches)
    decoded = tf.keras.layers.Conv3DTranspose(filters=1, kernel_size=(14,14,14), strides=(14,14,14))(encoded)
    merged = CombinePatches(ksizes=[1,14,14,14,1], strides=[1,14,14,14,1])(decoded, inputs)

    return tf.keras.models.Model(inputs=inputs, outputs=merged)

ae = create_model()

ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
           loss=tf.keras.losses.MeanSquaredError(),
           metrics=['accuracy'])


test_history = ae.fit(x_train,
                       x_train,
                       batch_size=1,
                       epochs=1,
                       callbacks=None)

```
## Stacktrace
```python
---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

<ipython-input-5-733ae79232be> in <module>()
     55 
     56 
---> 57 ae = create_model()
     58 
     59 ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),

5 frames

/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    668       except Exception as e:  # pylint:disable=broad-except
    669         if hasattr(e, 'ag_error_metadata'):
--> 670           raise e.ag_error_metadata.to_exception(e)
    671         else:
    672           raise

TypeError: in user code:

    <ipython-input-5-733ae79232be>:41 call  *
        target_grad_mapping = tf.gradients(target_patches, target_volume)[0]
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_impl.py:318 gradients_v2  **
        unconnected_gradients)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:684 _GradientsHelper
        lambda: grad_fn(op, *out_grads))
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:340 _MaybeCompile
        return grad_fn()  # Exit early
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:684 <lambda>
        lambda: grad_fn(op, *out_grads))
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_grad.py:1067 _ExtractVolumePatchesGrad
        input_indices_num = 1 + planes_in * rows_in * cols_in

    TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
```
"
49145,using sampled softmax is slow in 'double-tower' like model,"I'm trying to implement a 'double tower' like recommendation model, as something described in paper 'Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations'. It mentioned to use 'in batch softmax' to learn the embedding. I think this 'in batch softmax' is very likely to the 'sampled softmax' used in word2vec. So I tried to use the tf.nn.nce_loss to implement this logic. I wrote some code try to train a simple model.

    
    graph = tf.Graph()
    vocabulary_size = 300000
    embedding_size = 128
    dense_size = 64
    batch_size = 256
    
    import math
    
    with graph.as_default():
    # Input data.

    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])
    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])
    

    # Ops and variables pinned to the CPU because of missing GPU implementation
    with tf.device('/cpu:0'):
        # Look up embeddings for inputs.
        embeddings = tf.Variable(
            tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
        user = tf.nn.embedding_lookup(embeddings, train_inputs)
        user = tf.layers.dense(user, dense_size, activation='relu')
        user = tf.nn.l2_normalize(user, axis=-1)
        print(user)
        
        right_embedding = tf.Variable(
            tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
        right_hidden = tf.layers.dense(right_embedding, dense_size, activation='relu')
        
        
        nce_biases = tf.Variable(tf.zeros([vocabulary_size]),dtype=tf.float32,trainable=False)

        loss = tf.reduce_mean(
            tf.nn.nce_loss(weights=right_hidden,biases=nce_biases, inputs=user, labels=train_labels,
                 num_sampled=num_sampled, num_classes=vocabulary_size))
        
        optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)
        init = tf.global_variables_initializer()

and I found that the training is really slow. I doubt that it's because every time tensorflow need to calculate the right_hidden = tf.layers.dense(right_embedding, dense_size, activation='relu'), and the sampled softmax only applies to the last matrix ""right_hidden"", but we still need to calculate the entire right_hidden matrix beforehand. So am I right? or anyone can give a better solution to deal with the 'sampled softmax' or 'in batch softmax'. thanks "
49142,Not possible to build cortex_m_generic target on Windows,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source): ce84c661ef8e223a7d76d69d79ce0f26c216c3b9
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
Building the microlite lib for the cortex_m_generic target on Windows is not working.

**Please provide the exact sequence of commands/steps when you ran into the problem**
For example using Git Bash follow the instructions in tensorflow/lite/micro/cortex_m_generic/README.md.
"
49140,[XLA:GPU] Support integer convolutions,"**System information**
- TensorFlow version (you are using): `2.6.0.dev20210512`
- Are you willing to contribute it (Yes/No): Yes (I am not familiar with that part of the codebase so would need a bit of help)

**Describe the feature and the current behavior/state.**

https://github.com/tensorflow/tensorflow/commit/89fc1ddd96f25aa9d8eb6a0104ca1fdb11b26753 added support for integer convolutions on `XLA:CPU` which means that `XLA:GPU` is now the only backend unable to run integer convolutions. This came up in https://github.com/google/jax/pull/6467 and it looks like it is already tracked internally in `b/183565702`.

Is there any timeline for integer convolution support on GPU? As far as I know CUDA and CUDNN have options to execute integer convolutions on NVIDIA GPUs so I don't think anything fundamental should block this conceptually.

**Who will benefit with this feature?**

Support for integer convolutions would bring the GPU backend inline with CPU and TPU which would be great for users as they might expect integer support for convolutions similar to how it currently works in `DotGeneral` which could enable novel research on true integer quantization aware training."
49139,TensorRT Segmentation Fault During Conversion For Debug Mode,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8
- Bazel version (if compiling from source): bazelisk
- GCC/Compiler version (if compiling from source): gcc5
- CUDA/cuDNN version: 11.0
- GPU model and memory: Tesla 4

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Run the converter with my optimize_pass

**Describe the expected behavior**

In release mode, I get correct result but in Debug mode, I found segmentgraph(in segment.cc) got nullptr for output_edge

**Other info / logs**
[Thread 0x7fef967fc700 (LWP 51404) exited]
[Thread 0x7ff01e7fc700 (LWP 51369) exited]
[Thread 0x7ff01d7fa700 (LWP 51371) exited]
[Thread 0x7fef1ffff700 (LWP 51422) exited]
[Thread 0x7fef957fa700 (LWP 51406) exited]
[Thread 0x7fef96ffd700 (LWP 51403) exited]
[Thread 0x7ff01ffff700 (LWP 51366) exited]
[Thread 0x7ff016ffd700 (LWP 51375) exited]
[Thread 0x7ff0867fc700 (LWP 51362) exited]
[Thread 0x7fef1d7fa700 (LWP 51427) exited]
[Thread 0x7fef5dffb700 (LWP 51412) exited]
[Thread 0x7fef5e7fc700 (LWP 51411) exited]
[Thread 0x7fef5d7fa700 (LWP 51413) exited]
[Thread 0x7fef9ffff700 (LWP 51394) exited]
[Thread 0x7ff015ffb700 (LWP 51377) exited]
[Thread 0x7fef57fff700 (LWP 51415) exited]

Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
0x00007ff3cbebf9d8 in tensorflow::Edge::dst (this=0x0) at external/org_tensorflow/tensorflow/core/graph/graph.h:384
384	external/org_tensorflow/tensorflow/core/graph/graph.h: No such file or directory.
(gdb) bt
#0  0x00007ff3cbebf9d8 in tensorflow::Edge::dst (this=0x0) at external/org_tensorflow/tensorflow/core/graph/graph.h:384
#1  0x00007ff3cc908839 in tensorflow::(anonymous namespace)::DFSFromHelper<tensorflow::Node*>(const tensorflow::Graph &, tensorflow::gtl::ArraySlice, const std::function<void(tensorflow::Node*)> &, const std::function<void(tensorflow::Node*)> &, const tensorflow::NodeComparator &, const tensorflow::EdgeFilter &) (g=..., start=..., enter=..., leave=..., stable_comparator=..., edge_filter=...)
    at external/org_tensorflow/tensorflow/core/graph/algorithm.cc:81
#2  0x00007ff3cc90779a in tensorflow::DFS(tensorflow::Graph const&, std::function<void (tensorflow::Node*)> const&, std::function<void (tensorflow::Node*)> const&, std::function<bool (tensorflow::Node const*, tensorflow::Node const*)> const&, std::function<bool (tensorflow::Edge const&)> const&) (g=..., enter=..., leave=..., stable_comparator=..., edge_filter=...) at external/org_tensorflow/tensorflow/core/graph/algorithm.cc:93
#3  0x00007ff3cc907a53 in tensorflow::GetPostOrder(tensorflow::Graph const&, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >*, std::function<bool (tensorflow::Node const*, tensorflow::Node const*)> const&, std::function<bool (tensorflow::Edge const&)> const&) (g=..., 
    order=0x7ffcdfbe9850, stable_comparator=..., edge_filter=...) at external/org_tensorflow/tensorflow/core/graph/algorithm.cc:207
#4  0x00007ff3cbebc567 in tensorflow::tensorturbo::convert::ConvertAfterShapes (params=...) at convert/tt_convert_graph.cc:578
#5  0x00007ff3cbed5d50 in tensorflow::tensorturbo::convert::TTOptimizationPass::Optimize (this=0x7ffcdfbea910, cluster=0x0, item=..., 
    optimized_graph=0x7ffcdfbea6f0) at convert/tt_optimization_pass.cc:97
#6  0x00007ff3cbe6ca82 in <lambda(const pybind11::bytes&, bool, const string&)>::operator()(const pybind11::bytes &, bool, const std::__cxx11::string &) const (__closure=0x55986103aff8, serialized_metagraph=..., verbose=false, graph_id=""graph_to_optimize"")
    at convert/tt_optimizer_wrapper.cc:63
#7  0x00007ff3cbe6d7a2 in pybind11::detail::argument_loader<pybind11::bytes const&, bool, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&>::call_impl<pybind11::bytes, pybind11_init__pywrap_tt_optimizer(pybind11::module&)::<lambda(const pybind11::bytes&, bool, const string&)>&, 0, 1, 2, pybind11::detail::void_type>(<lambda(const pybind11::bytes&, bool, const string&)> &, std::index_sequence, pybind11::detail::void_type &&) (this=0x7ffcdfbeab50, f=...)
    at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/cast.h:1935
#8  0x00007ff3cbe6d1b6 in pybind11::detail::argument_loader<pybind11::bytes const&, bool, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&>::call<pybind11::bytes, pybind11::detail::void_type, pybind11_init__pywrap_tt_optimizer(pybind11::module&)::<lambda(const pybind11::bytes&, bool, const string&)>&>(<lambda(const pybind11::bytes&, bool, const string&)> &) (this=0x7ffcdfbeab50, f=...)
    at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/cast.h:1912
#9  0x00007ff3cbe6cf01 in pybind11::cpp_function::<lambda(pybind11::detail::function_call&)>::operator()(pybind11::detail::function_call &) const (__closure=0x0, call=...) at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/pybind11.h:159
#10 0x00007ff3cbe6cfae in pybind11::cpp_function::<lambda(pybind11::detail::function_call&)>::_FUN(pybind11::detail::function_call &) ()
    at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/pybind11.h:137
#11 0x00007ff3cbe7724a in pybind11::cpp_function::dispatcher (self=0x7ff3cd9e6f30, args_in=0x7ff33425d640, kwargs_in=0x0)
    at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/pybind11.h:624
#12 0x000055985cdbff76 in cfunction_call_varargs (kwargs=<optimized out>, args=<optimized out>, func=0x7ff3cdcbfbd0)
    at /tmp/build/80754af9/python_1599203911753/work/Objects/call.c:742


![image](https://user-images.githubusercontent.com/15120783/117979468-83d86d80-b365-11eb-8fa3-38a03fe74f78.png)

In release mode, here is not nullptr, otherwise in Debug mode, the nullptr causes core dump.
Why?

"
49138,Normalization using TensorFlow Keras,"Our task is as below not sure what we done mistake in it -

```
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from matplotlib import pyplot
import seaborn as sns
import pandas as pd
from keras.layers import BatchNormalization
from keras.models import model_from_json
import tensorflow as tf
from sklearn.datasets import load_breast_cancer
from sklearn import metrics
import random as rn
from keras import backend as K
import matplotlib.pyplot as plt
import os
from keras.layers import Activation
```

```
os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""
os.environ[""CUDA_VISIBLE_DEVICES""] = """"
sd = 22 # Here sd means seed.
np.random.seed(sd)
rn.seed(sd)
os.environ['PYTHONHASHSEED']=str(sd)
```

```
config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)
tf.set_random_seed(sd)
sess = tf.Session(graph=tf.get_default_graph(), config=config)
K.set_session(sess)
```

Load the breast cancer dataset using load_breast_cancer function

`X, y = load_breast_cancer(return_X_y=True)`


`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=500)`

- Create a sequential model
- The model expects rows of data with 30 variables (the input_dim=30 argument)
- The first hidden layer has 90 nodes and uses the relu activation function.
- The second hidden layer has 60 nodes and uses the relu activation function.
- The third hidden layer has 30 nodes and uses the relu activation function.
- The output layer has 1 node and uses the sigmoid activation function.

```
While comipling the model pass the following parameters -

     -optimizer as Adagrad
     -loss as binary cross entropy 
     -metrics as accuracy

```
  ```
  model = Sequential()
    model.add(Dense(30, input_dim=30))
    model.add(Dense(90, activation='relu'))
    model.add(Dense(60, activation='relu'))
    model.add(Dense(30, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='Adagrad', metrics=['accuracy'])
```

fit the model with X_train, y_train, epochs=50, batch_size=50,shuffle=False,validation_split=0.2,verbose=1 and save it in history

`history = model.fit(X_train, y_train, epochs=50, batch_size=50,shuffle=False,validation_split=0.2,verbose=1 )`

```
_, train_acc = model.evaluate(X_train, y_train, verbose=0)
_,test_acc=  model.evaluate(X_test, y_test, verbose=0)
print('Train: %.2f, Test: %.2f' % (train_acc, test_acc))
```
Train: 0.61, Test: 0.69

```
def plot_history(history):
    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]
    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]
    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]
    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]
    
    if len(loss_list) == 0:
        print('Loss is missing in history')
        return 
    
    ## As loss always exists
    epochs = range(1,len(history.history[loss_list[0]]) + 1)
    
    ## Loss
    plt.figure(1)
    for l in loss_list:
        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))
    for l in val_loss_list:
        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))
    
    plt.title('Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    
    ## Accuracy
    plt.figure(2)
    for l in acc_list:
        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')
    for l in val_acc_list:    
        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')

    plt.title('Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()
# Calling the function
plot_history(history)

```

- Create a sequential model1
- The model1 expects rows of data with 30 variables (the input_dim=30 argument)
- The first hidden layer has 90 nodes.
- Add Batch Normalization using BatchNormalization function to the model1.
- Add the activation function as relu
- The second hidden layer has 60 nodes.
- Add Batch Normalization using BatchNormalization function to the model1.
- Add the activation function as relu
- The third hidden layer has 30 nodes.
- Add Batch Normalization using BatchNormalization function to the model1.
- Add the activation function as relu
- The output layer has 1 node and uses the sigmoid activation function.


```
While comipling the model1 pass the following parameters -

     -optimizer as Adagrad
     -loss as binary cross entropy 
     -metrics as accuracy

```   
   ```
 model1 =  Sequential()
    model1.add(Dense(30, input_dim=30))
    model1.add(Dense(90))
    model1.add(Dense(60))
    model1.add(Dense(30))
    model1.add(BatchNormalization())
    model1.add(Activation('relu'))
    model1.add(Dense(1, activation='sigmoid'))
    model1.compile(loss='binary_crossentropy', optimizer='Adagrad', metrics=['accuracy'])
```

`history1 =  model1.fit(X_train, y_train, epochs=50, batch_size=50,shuffle=False,validation_split=0.2,verbose=1 )
`
```
_, train_acc1 = model1.evaluate(X_train, y_train, verbose=0)
_,test_acc1 =  model1.evaluate(X_test, y_test, verbose=0)
print('Train: %.2f, Test: %.2f' % (train_acc1, test_acc1))
```
Train: 0.93, Test: 0.99


```
plt.figure(1)
pyplot.plot(history1.history['accuracy'], label='train')
pyplot.plot(history1.history['val_accuracy'], label='test')

plt.figure(2)
pyplot.plot(history1.history['loss'], label='train')
pyplot.plot(history1.history['val_loss'], label='test')
pyplot.legend()
pyplot.show()
```


- Create a sequential model2
- The model2 expects rows of data with 30 variables (the input_dim=30 argument)
- The first hidden layer has 90 nodes and uses the relu activation function.
- Add Batch Normalization using BatchNormalization function to the model2.
- The second hidden layer has 60 nodes and uses the relu activation function.
- Add Batch Normalization using BatchNormalization function to the model2.
- The third hidden layer has 30 nodes and uses the relu activation function.
- Add Batch Normalization using BatchNormalization function to the model2.
- The output layer has 1 node and uses the sigmoid activation function.

```
While comipling the model2 pass the following parameters -

     -optimizer as Adagrad
     -loss as binary cross entropy 
     -metrics as accuracy
```  
   

   ```
model2 =  Sequential()
    model2.add(Dense(30, input_dim=30))
    model2.add(Activation('relu'))
    model2.add(BatchNormalization())
    model2.add(Dense(90))
    model2.add(Dense(60))
    model2.add(Dense(30))
    model2.add(Dense(1, activation='sigmoid'))
    model2.compile(loss='binary_crossentropy', optimizer='Adagrad', metrics=['accuracy'])

```

`history2 =  model2.fit(X_train, y_train, epochs=50, batch_size=50,shuffle=False,validation_split=0.2,verbose=1 )`

```
_, train_acc2 = model2.evaluate(X_train, y_train, verbose=0)
_,test_acc2 =  model2.evaluate(X_test, y_test, verbose=0)
print('Train: %.2f, Test: %.2f' % (train_acc2, test_acc2))

```
Train: 0.92, Test: 0.91

```
plt.figure(1)
pyplot.plot(history2.history['accuracy'], label='train')
pyplot.plot(history2.history['val_accuracy'], label='test')

plt.figure(2)
pyplot.plot(history2.history['loss'], label='train')
pyplot.plot(history2.history['val_loss'], label='test')
pyplot.legend()
pyplot.show()

```
"
49137,Training on tf distribute takes long time ->  Complete shape not known for Adam for SparseTensor,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No mobile
- TensorFlow installed from (source or binary): Rejected
- TensorFlow version (use command below): 2.4.0
- Python version: 3.7
- Bazel version (if compiling from source): Negative
- GCC/Compiler version (if compiling from source): Negative
- CUDA/cuDNN version: No
- GPU model and memory: No

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I am trying to run my model with MultiWorkerMirroredStrategy() but I am facing this issue:
`2021-05-07 19:47:04.704974: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:455] error: Aborted: Complete shape not known for Adam/allreduce/CollectiveReduce_3
2021-05-07 19:47:04.705015: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:1138] error: Aborted: Complete shape not known for Adam/allreduce/CollectiveReduce_3
2021-05-07 19:47:04.705027: E tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:1155] ScopedAllocatorOptimizer: Aborted: Complete shape not known for Adam/allreduce/CollectiveReduce_3
2021-05-07 19:47:04.705033: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:928] error: Aborted: Complete shape not known for Adam/allreduce/CollectiveReduce_3
`
My code in the tf.distribute takes more than 1 hour per epoch whereas running it normally it takes 4 minutes per epoch. The difference is humongous, I am suspecting its maybe due to the warning msg above. 

For the dataset I am using sklearn's CountVectorizer to transform text to feature vector and LabelEncoder to encode the class names. I then convert x to SparseTensor. 


```
x # coo_matrix with 300k observations and 42000 feature size
y # array containing integer value of size 300k x 1 
BATCH_SIZE = 256
NUM_WORKERS = 2

GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS

def build_model():
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(512,  activation='relu'))
    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))
    model.compile(optimizer=""adam"",
                  loss='sparse_categorical_crossentropy',
                  metrics=[""accuracy""])

    return model

def coo_to_tensor(coo):
    return tf.sparse.SparseTensor(list(zip(coo.row, coo.col)), coo.data, coo.shape)

options = tf.data.Options()
options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA 
ds = tf.data.Dataset.from_tensor_slices((coo_to_tensor(x),y)).batch(GLOBAL_BATCH_SIZE).with_options(options)..batch(GLOBAL_BATCH_SIZE)

with strategy.scope():
    multi_worker_model = build_model()

multi_worker_model.fit(ds, epochs=args.epochs, batch_size=BATCH_SIZE)
```


**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49136,[manylinux2014][aarch64][git] fatal error: AArch64GenO0PreLegalizeGICombiner.inc: No such file or directory,"**System information**
- OS Platform and Distribution: manylinux2014 (CentOS 7)
- TensorFlow installed from (source or binary): source
- TensorFlow version: commit db73cf59f471354ace196bb2ccb1f5c951b6cec1 
- Python version: 3.6
- Installed using virtualenv
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): gcc (GCC) 9.3.1 20200408 (Red Hat 9.3.1-2)
- CUDA/cuDNN version: CUDA disabled
- GPU model and memory: no GPU

**Describe the problem**

I am working on building manylinux2014 compatible wheels of TensorFlow for AArch64. So far built 1.15.5 and 2.4.1 versions. But git HEAD fails:
```
    Execution platform: @local_execution_config_platform//:platform                                                                                                                    
    external/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64O0PreLegalizerCombiner.cpp:45:10: fatal error: AArch64GenO0PreLegalizeGICombiner.inc: No such file or directory
       45 | #include ""AArch64GenO0PreLegalizeGICombiner.inc""                                                                                                                           
          |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                           
    compilation terminated.   
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
      bazel clean --expunge
      export BAZEL_LINKLIBS=-l%:libstdc++.a
      bazel build --config=noaws --config=nogcp --config=nonccl \
            //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
    + bazel build --config=noaws --config=nogcp --config=nonccl //tensorflow/tools/pip_package:build_pip_package --verbose_failures
    Starting local Bazel server and connecting to it...
    INFO: Options provided by the client:
      Inherited 'common' options: --isatty=0 --terminal_columns=80
    INFO: Reading rc options for 'build' from /tmp/workspace6/tensorflow-git/.bazelrc:
      Inherited 'common' options: --experimental_repo_remote_exec
    INFO: Reading rc options for 'build' from /tmp/workspace6/tensorflow-git/.bazelrc:
      'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --defi
ne=no_hdfs_support=true
    INFO: Reading rc options for 'build' from /tmp/workspace6/tensorflow-git/.tf_configure.bazelrc:
      'build' options: --action_env PYTHON_BIN_PATH=/tmp/workspace6/venv-cp36-cp36m/bin/python3 --action_env PYTHON_LIB_PATH=/tmp/workspace6/venv-cp36-cp36m/lib/python3.6/site-packages --python_path=/tmp/workspace6/venv-cp36-cp36m/bin/python3
    INFO: Found applicable config definition build:short_logs in file /tmp/workspace6/tensorflow-git/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
    INFO: Found applicable config definition build:v2 in file /tmp/workspace6/tensorflow-git/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
    INFO: Found applicable config definition build:noaws in file /tmp/workspace6/tensorflow-git/.bazelrc: --define=no_aws_support=true
    INFO: Found applicable config definition build:nogcp in file /tmp/workspace6/tensorflow-git/.bazelrc: --define=no_gcp_support=true
    INFO: Found applicable config definition build:nonccl in file /tmp/workspace6/tensorflow-git/.bazelrc: --define=no_nccl_support=true
    INFO: Found applicable config definition build:linux in file /tmp/workspace6/tensorflow-git/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
    INFO: Found applicable config definition build:dynamic_kernels in file /tmp/workspace6/tensorflow-git/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
    Loading:
    Loading: 0 packages loaded
    Loading: 0 packages loaded
    DEBUG: /root/.cache/bazel/_bazel_root/5ad6f84b01b6d62f14bf0104cde27024/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.
    Loading: 0 packages loaded
    Loading: 0 packages loaded
    Loading: 0 packages loaded
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (1 packages loaded)
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (1 packages loaded, 0 targets configured)
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (54 packages loaded, 14 targets configured)
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (55 packages loaded, 14 targets configured)
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (194 packages loaded, 3759 targets configured)
    DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
    DEBUG: Repository io_bazel_rules_docker instantiated at:
      /tmp/workspace6/tensorflow-git/WORKSPACE:23:14: in <toplevel>
      /tmp/workspace6/tensorflow-git/tensorflow/workspace0.bzl:108:34: in workspace
      /root/.cache/bazel/_bazel_root/5ad6f84b01b6d62f14bf0104cde27024/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
    Repository rule git_repository defined at:
      /root/.cache/bazel/_bazel_root/5ad6f84b01b6d62f14bf0104cde27024/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (230 packages loaded, 3969 targets configured)
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (232 packages loaded, 3969 targets configured)
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (382 packages loaded, 11241 targets configured)
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (404 packages loaded, 20479 targets configured)
    Analyzing: target //tensorflow/tools/pip_package:build_pip_package (404 packages loaded, 20479 targets configured)
    WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/6351993da72e298b3f79218e4f129a9bbde3e679.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
    INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (410 packages loaded, 31658 targets configured).
    INFO: Found 1 target...
    [0 / 511] [Prepa] Expanding template tensorflow/lite/tools/visualize ... (4 actions, 0 running)
    [40 / 511] Compiling com_google_protobuf/src/google/protobuf/descriptor.cc [for host]; 7s local ... (16 actions, 15 running)
    [67 / 511] Compiling com_google_protobuf/src/google/protobuf/descriptor.cc [for host]; 17s local ... (16 actions, 15 running)
    [108 / 511] Compiling com_google_protobuf/src/google/protobuf/descriptor.cc [for host]; 28s local ... (16 actions, 15 running)
    [167 / 511] Compiling com_google_protobuf/src/google/protobuf/compiler/cpp/cpp_enum.cc [for host]; 7s local ... (16 actions, 15 running)
    [312 / 1,088] Compiling com_google_protobuf/src/google/protobuf/compiler/cpp/cpp_message.cc [for host]; 13s local ... (16 actions running)
    [536 / 1,180] Compiling tensorflow/core/framework/op_gen_lib.cc [for host]; 10s local ... (16 actions running)
    [763 / 2,128] Compiling tensorflow/python/util/tf_stack.cc [for host]; 17s local ... (16 actions running)
    [1,179 / 2,128] Compiling boringssl/src/crypto/fipsmodule/bcm.c [for host]; 10s local ... (16 actions running)
    [1,423 / 2,128] Compiling com_github_grpc_grpc/src/core/lib/security/credentials/tls/grpc_tls_credentials_options.cc [for host]; 1s local ... (16 actions running)
    [1,588 / 6,871] Compiling tensorflow/core/kernels/scatter_nd_op_cpu_impl_2.cc [for host]; 23s local ... (16 actions running)
    [1,686 / 6,871] Compiling llvm-project/llvm/utils/TableGen/GlobalISelEmitter.cpp [for host]; 24s local ... (16 actions running)
    [1,851 / 6,871] Compiling llvm-project/llvm/lib/Support/ItaniumManglingCanonicalizer.cpp [for host]; 7s local ... (16 actions running)
    [1,966 / 7,128] Compiling llvm-project/llvm/utils/TableGen/GlobalISelEmitter.cpp [for host]; 23s local ... (16 actions, 15 running)
    [2,699 / 7,660] Compiling llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp [for host]; 10s local ... (16 actions running)
    [2,958 / 7,881] Compiling llvm-project/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp [for host]; 17s local ... (16 actions running)
    [3,036 / 7,881] Compiling tensorflow/core/kernels/reduction_ops_mean.cc [for host]; 62s local ... (16 actions running)
    [3,099 / 7,881] Compiling tensorflow/core/kernels/linalg/matrix_square_root_op.cc [for host]; 92s local ... (16 actions running)
    [3,177 / 7,881] Compiling tensorflow/core/kernels/linalg/matrix_square_root_op.cc [for host]; 178s local ... (16 actions running)
    [3,342 / 7,881] Compiling tensorflow/core/kernels/linalg/matrix_square_root_op.cc [for host]; 277s local ... (16 actions running)
    [3,504 / 7,882] Compiling llvm-project/mlir/lib/Rewrite/ByteCode.cpp [for host]; 18s local ... (16 actions running)
    [3,667 / 7,882] Compiling tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc [for host]; 46s local ... (16 actions running)
    [3,800 / 7,886] Compiling tensorflow/core/kernels/conv_grad_filter_ops.cc [for host]; 144s local ... (16 actions running)
    [3,955 / 7,898] Compiling tensorflow/compiler/xla/service/hlo_evaluator_typed_visitor_bfloat16.cc [for host]; 53s local ... (16 actions running)
    [4,125 / 7,912] Compiling tensorflow/core/kernels/reverse_op.cc [for host]; 78s local ... (16 actions running)
    [4,369 / 7,912] Compiling tensorflow/core/kernels/reverse_sequence_op.cc [for host]; 65s local ... (16 actions running)
    ERROR: /root/.cache/bazel/_bazel_root/5ad6f84b01b6d62f14bf0104cde27024/external/llvm-project/llvm/BUILD:816:11: C++ compilation of rule '@llvm-project//llvm:AArch64CodeGen' failed (Exit 1): gcc failed: error executing command
      (cd /root/.cache/bazel/_bazel_root/5ad6f84b01b6d62f14bf0104cde27024/execroot/org_tensorflow && \
      exec env - \
        LD_LIBRARY_PATH=/opt/rh/devtoolset-9/root/usr/lib64:/opt/rh/devtoolset-9/root/usr/lib:/opt/rh/devtoolset-9/root/usr/lib64/dyninst:/opt/rh/devtoolset-9/root/usr/lib/dyninst:/usr/local/lib64 \
        PATH=/tmp/workspace6/venv-cp36-cp36m/bin:/opt/rh/devtoolset-9/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
        PWD=/proc/self/cwd \
      /opt/rh/devtoolset-9/root/usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/host/bin/external/llvm-project/llvm/_objs/AArch64CodeGen/AArch64O0PreLegalizerCombiner.pic.d '-frandom-seed=bazel-out/host/bin/external/llvm-project/llvm/_objs/AArch64CodeGen/AArch64O0PreLegalizerCombiner.pic.o' -fPIC -DLLVM_ENABLE_STATS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D
__STDC_FORMAT_MACROS -DLLVM_BUILD_GLOBAL_ISEL -iquoteexternal/llvm-project -iquotebazel-out/host/bin/external/llvm-project -iquoteexternal/zlib -iquotebazel-out/host/bin/external/zlib -isystem external/llvm-project/llvm/lib/Target/AArch64 -isystem bazel-out/host/bin/external/llvm-project/llvm/lib/Target/AArch64 -isystem external/llvm-project/llvm/include -isystem bazel-out/host/bin/external/llvm-project/llvm/include -isystem external/zlib -isystem bazel-out/host/bin/external/zlib -isystem external/llvm-project/llvm/include/llvm/IR -isystem bazel-out
/host/bin/external/llvm-project/llvm/include/llvm/IR -isystem external/llvm-project/llvm/lib/Target/AMDGPU -isystem bazel-out/host/bin/external/llvm-project/llvm/lib/Target/AMDGPU -g0 -w -g0 '-std=c++14' -Iexternal/llvm-project/llvm/lib/Target/AArch64 -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64O0PreLegalizerCombiner.cpp -o bazel-out/host/bin/external/llvm-project/llvm/_objs/AArch64CodeGen/AArch64O
0PreLegalizerCombiner.pic.o)
    Execution platform: @local_execution_config_platform//:platform
    external/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64O0PreLegalizerCombiner.cpp:45:10: fatal error: AArch64GenO0PreLegalizeGICombiner.inc: No such file or directory
       45 | #include ""AArch64GenO0PreLegalizeGICombiner.inc""
          |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    compilation terminated.
    Target //tensorflow/tools/pip_package:build_pip_package failed to build
    ERROR: /tmp/workspace6/tensorflow-git/tensorflow/tools/pip_package/BUILD:69:10 C++ compilation of rule '@llvm-project//llvm:AArch64CodeGen' failed (Exit 1): gcc failed: error executing command
      (cd /root/.cache/bazel/_bazel_root/5ad6f84b01b6d62f14bf0104cde27024/execroot/org_tensorflow && \
      exec env - \
        LD_LIBRARY_PATH=/opt/rh/devtoolset-9/root/usr/lib64:/opt/rh/devtoolset-9/root/usr/lib:/opt/rh/devtoolset-9/root/usr/lib64/dyninst:/opt/rh/devtoolset-9/root/usr/lib/dyninst:/usr/local/lib64 \
        PATH=/tmp/workspace6/venv-cp36-cp36m/bin:/opt/rh/devtoolset-9/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
        PWD=/proc/self/cwd \
      /opt/rh/devtoolset-9/root/usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/host/bin/external/llvm-project/llvm/_objs/AArch64CodeGen/AArch64O0PreLegalizerCombiner.pic.d '-frandom-seed=bazel-out/host/bin/external/llvm-project/llvm/_objs/AArch64CodeGen/AArch64O0PreLegalizerCombiner.pic.o' -fPIC -DLLVM_ENABLE_STATS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D
__STDC_FORMAT_MACROS -DLLVM_BUILD_GLOBAL_ISEL -iquoteexternal/llvm-project -iquotebazel-out/host/bin/external/llvm-project -iquoteexternal/zlib -iquotebazel-out/host/bin/external/zlib -isystem external/llvm-project/llvm/lib/Target/AArch64 -isystem bazel-out/host/bin/external/llvm-project/llvm/lib/Target/AArch64 -isystem external/llvm-project/llvm/include -isystem bazel-out/host/bin/external/llvm-project/llvm/include -isystem external/zlib -isystem bazel-out/host/bin/external/zlib -isystem external/llvm-project/llvm/include/llvm/IR -isystem bazel-out
/host/bin/external/llvm-project/llvm/include/llvm/IR -isystem external/llvm-project/llvm/lib/Target/AMDGPU -isystem bazel-out/host/bin/external/llvm-project/llvm/lib/Target/AMDGPU -g0 -w -g0 '-std=c++14' -Iexternal/llvm-project/llvm/lib/Target/AArch64 -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64O0PreLegalizerCombiner.cpp -o bazel-out/host/bin/external/llvm-project/llvm/_objs/AArch64CodeGen/AArch64O
0PreLegalizerCombiner.pic.o)
    Execution platform: @local_execution_config_platform//:platform
    INFO: Elapsed time: 1979.907s, Critical Path: 313.84s
    INFO: 4575 processes: 520 internal, 4055 local.
    FAILED: Build did NOT complete successfully
    FAILED: Build did NOT complete successfully
```"
49135,How to reduce false positives when training a model using tensorflow object detection API?,"I have trained a tensorflow object detection model which will detect a box, bag and crate. when i tested that trained model it is giving more false positives. I trained that with the cleaned datas with proper annotations, though it is giving more false positives. Is there any way to reduce the false positives?

I am using ssd_mobilenet_v1_coco to train a model. Do i need to change anything in the pipeline.config file to reduce the false positives?"
49133,the input->params.scale must equal to output->params.scale of the pooling node,"Hi,
     Recently, i found that inside the pooling.cc, it will assert the input->params.scale and the output->params.scale,
![image](https://user-images.githubusercontent.com/49855018/117932150-a1d8aa80-b332-11eb-9fa1-237550d923aa.png)
when using a quantization model which has a average pool or max pool.
     But when the kernel size of the pooling node is not equal to the input size, the right and the bottom will be discarded with valid padding. When the max value is just at there, then we can make sure the max value of the maxpooling layer is still the same with the input node.
    Also when we use the avg pool, the max value of the output can not be the same with the input, will always be smaller.
   So, i want to ask, why we assert the max value of the input / output scale is same?

Regards,
    Crist


"
49131,Cannot import TensorFlow in Docker running at M1 (with AMD64 emulation),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 in Docker (running at Apple M1)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8.5
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: -
- GPU model and memory: M1

```zsh
8:04 martin@martins-MacBook-Pro /Users/martin/Projects/rl-toolkit
% docker run -it -p 8000:8000 --rm markub3327/rl-toolkit bash
WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested
+ Xvfb -screen 0 1024x768x24
+ export DISPLAY=:0
+ DISPLAY=:0
+ display=0
+ file=/tmp/.X11-unix/X0
++ seq 1 10
+ for i in $(seq 1 10)
+ '[' -e /tmp/.X11-unix/X0 ']'
+ echo 'Waiting for /tmp/.X11-unix/X0 to be created (try 1/10)'
Waiting for /tmp/.X11-unix/X0 to be created (try 1/10)
+ sleep 1
+ for i in $(seq 1 10)
+ '[' -e /tmp/.X11-unix/X0 ']'
+ break
+ '[' -e /tmp/.X11-unix/X0 ']'
+ exec bash
root@215c42188dbc:~/rl-toolkit# python3
Python 3.8.5 (default, Jan 27 2021, 15:41:15) 
[GCC 9.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
2021-05-12 06:04:33.062104: F tensorflow/core/lib/monitoring/sampler.cc:42] Check failed: bucket_limits_[i] > bucket_limits_[i - 1] (0 vs. 10)
qemu: uncaught target signal 6 (Aborted) - core dumped
Aborted
root@215c42188dbc:~/rl-toolkit# 
```

Why I cannot import the TensorFlow package on Ubuntu 20.04 running in a Docker container (arch AMD64)? I use Apple M1 with Rosetta 2, which allows the run of AMD64 containers."
49130,[ERROR] TF Object Detection API: “tensorflow.python.framework.errors_impl.FailedPreconditionError: HashTable has different value for same key. Key item { has 0 and trying to add value 4 [Op:InitializeTableFromTextFileV2]”,"I am trying to work with this [yolov4 in tensorflow 2.0 model](https://github.com/zzh8829/yolov3-tf2), it requires the dataset to be in Tensorflow Object Detection API format. Since I had no prior experience with this api so I was following Adrian Rosebrock's tutorial in his ImageNet bundle book. I barely changed the code in tutorial other than changing paths and file names, the code files and more in depth detail of error is posted in my this [Stack Overflow post](https://stackoverflow.com/questions/67497274/tensorflow-object-detection-api-failedpreconditionerror-hashtable-has-differe).
But when I try to use the acquired tf record files with the yolov4 tensorflow model mentioned above, I get this error. I couldnt find any working solution on the web, so here I am. If you can pls help, I'll be more grateful than you can imagine! :)

Error: 
```
Traceback (most recent call last):
  File ""train.py"", line 195, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 303, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""train.py"", line 64, in main
    FLAGS.dataset, FLAGS.classes, FLAGS.size)
  File ""/content/yolov3-tf2/yolov3_tf2/dataset.py"", line 124, in load_tfrecord_dataset
    class_file, tf.string, 0, tf.int64, LINE_NUMBER, delimiter=""\n""), -1)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/lookup_ops.py"", line 314, in __init__
    super(StaticHashTable, self).__init__(default_value, initializer)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/lookup_ops.py"", line 185, in __init__
    self._init_op = self._initialize()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/lookup_ops.py"", line 188, in _initialize
    return self._initializer.initialize(self)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/lookup_ops.py"", line 744, in initialize
    -1 if self._vocab_size is None else self._vocab_size, self._delimiter)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_lookup_ops.py"", line 363, in initialize_table_from_text_file_v2
    _ops.raise_from_not_ok_status(e, name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 6862, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.FailedPreconditionError: HashTable has different value for same key. Key item { has 0 and trying to add value 4 [Op:InitializeTableFromTextFileV2]
```"
49129,How could I get middle layers output of TFLite ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4.1

**Describe the feature and the current behavior/state.**
I would like to know how to get the middle layers output of TFLite models. 
For now, the method I used is:

interpreter.allocate_tensors()
interpreter.set_tensor(input_details[""index""], test_image)
interpreter.invoke()

layer_output = interpreter.get_tensor(**index**), where index is the the index of the tensor

Is that correct?

**Who will benefit with this feature?**
Anyone who would like to access the middle layer outputs

"
49127,Question about `input_fn` in Tensorflow's multi worker estimator tutorial,"
In this [tutorial](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_estimator), function input_fn has a param named mode. I can't figure out how this param get passed to input_fn when training.
```python
BUFFER_SIZE = 10000
BATCH_SIZE = 64

def input_fn(mode, input_context=None):
  datasets, info = tfds.load(name='mnist',
                                with_info=True,
                                as_supervised=True)
  mnist_dataset = (datasets['train'] if mode == tf.estimator.ModeKeys.TRAIN else
                   datasets['test'])

  def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255
    return image, label

  if input_context:
    mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,
                                        input_context.input_pipeline_id)
  return mnist_dataset.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
```

To better clarify my question, see how this `input_fn` is passed as a function param. It is just passed without any wrapper that give `mode` a value.
```python
tf.estimator.train_and_evaluate(
    classifier,
    train_spec=tf.estimator.TrainSpec(input_fn=input_fn),
    eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)
)
```"
49125,Keras Tensorboard callback not  generating profile with model.train_on_batch(),"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary):  pip
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
No profile shown in Tensorboard.

**Describe the expected behavior**
Should see active profile. 



**Standalone code to reproduce the issue**

```
  .
  '
   model.compile(optimizer='adam', loss='mse', metrics=['mae'])
   tboard_cb = tf.keras.callbacks.TensorBoard(log_dir = logs,
                                                 histogram_freq = 1,
                                                 update_freq = 'batch',
                                                 write_images = True,
                                                 write_graph = True,
                                                 profile_batch = '0,3',
                                                )
    pbar_cb = tf.keras.callbacks.ProgbarLogger(count_mode='steps',
                                stateful_metrics=None)
    cblist = tf.keras.callbacks.CallbackList(callbacks=[tboard_cb, pbar_cb],
                       model=model, add_history=True, add_progbar=True)
   X_batch = ...
   Y_batch = ...
   for i in range(10):
      loss = model.train_on_batch(X_batch, Y_batch)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49123,Conv2D with dilation_rate>1 runs extremely slow on cpu,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes for the tf.keras.applications
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy Note 10 plus
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2 / 8.1.1
- GPU model and memory: RTX 3080, 10GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
```
ibrary libcudart.so.11.0
unknown 2.4.0
```

**Describe the current behavior**
1. I modified tf.keras.applications.efficientNet.py's Conv2D operations from having dilation_rate=1 to dilation_rate=2.
2. Converted the trained model into tflite format
3. Ran inference on Android devices.
4. It is running about 4 times slower on cpu compared to the baseline which has dilation_rate=1 conv. (GPU inference runs in similar speed)

**Describe the expected behavior**
Expected to be running in a similiar speed on cpu

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
# Copyright 2019 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
# pylint: disable=invalid-name
# pylint: disable=missing-docstring
""""""EfficientNet models for Keras.

Reference:
  - [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](
      https://arxiv.org/abs/1905.11946) (ICML 2019)
""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import copy
import math

from tensorflow.python.keras import backend
from tensorflow.python.keras.applications import imagenet_utils
from tensorflow.python.keras.engine import training
from tensorflow.python.keras.layers import VersionAwareLayers
from tensorflow.python.keras.utils import data_utils
from tensorflow.python.keras.utils import layer_utils
from tensorflow.python.lib.io import file_io
from tensorflow.python.util.tf_export import keras_export


BASE_WEIGHTS_PATH = 'https://storage.googleapis.com/keras-applications/'

WEIGHTS_HASHES = {
    'b0': ('902e53a9f72be733fc0bcb005b3ebbac',
           '50bc09e76180e00e4465e1a485ddc09d'),
    'b1': ('1d254153d4ab51201f1646940f018540',
           '74c4e6b3e1f6a1eea24c589628592432'),
    'b2': ('b15cce36ff4dcbd00b6dd88e7857a6ad',
           '111f8e2ac8aa800a7a99e3239f7bfb39'),
    'b3': ('ffd1fdc53d0ce67064dc6a9c7960ede0',
           'af6d107764bb5b1abb91932881670226'),
    'b4': ('18c95ad55216b8f92d7e70b3a046e2fc',
           'ebc24e6d6c33eaebbd558eafbeedf1ba'),
    'b5': ('ace28f2a6363774853a83a0b21b9421a',
           '38879255a25d3c92d5e44e04ae6cec6f'),
    'b6': ('165f6e37dce68623721b423839de8be5',
           '9ecce42647a20130c1f39a5d4cb75743'),
    'b7': ('8c03f828fec3ef71311cd463b6759d99',
           'cbcfe4450ddf6f3ad90b1b398090fe4a'),
}

DEFAULT_BLOCKS_ARGS = [{
    'kernel_size': 3,
    'repeats': 1,
    'filters_in': 32,
    'filters_out': 16,
    'expand_ratio': 1,
    'id_skip': True,
    'strides': 1,
    'se_ratio': 0.25
}, {
    'kernel_size': 3,
    'repeats': 2,
    'filters_in': 16,
    'filters_out': 24,
    'expand_ratio': 6,
    'id_skip': True,
    'strides': 2,
    'se_ratio': 0.25
}, {
    'kernel_size': 5,
    'repeats': 2,
    'filters_in': 24,
    'filters_out': 40,
    'expand_ratio': 6,
    'id_skip': True,
    'strides': 2,
    'se_ratio': 0.25
}, {
    'kernel_size': 3,
    'repeats': 3,
    'filters_in': 40,
    'filters_out': 80,
    'expand_ratio': 6,
    'id_skip': True,
    'strides': 2,
    'se_ratio': 0.25
}, {
    'kernel_size': 5,
    'repeats': 3,
    'filters_in': 80,
    'filters_out': 112,
    'expand_ratio': 6,
    'id_skip': True,
    'strides': 1,
    'se_ratio': 0.25
}, {
    'kernel_size': 5,
    'repeats': 4,
    'filters_in': 112,
    'filters_out': 192,
    'expand_ratio': 6,
    'id_skip': True,
    'strides': 2,
    'se_ratio': 0.25
}, {
    'kernel_size': 3,
    'repeats': 1,
    'filters_in': 192,
    'filters_out': 320,
    'expand_ratio': 6,
    'id_skip': True,
    'strides': 1,
    'se_ratio': 0.25
}]

CONV_KERNEL_INITIALIZER = {
    'class_name': 'VarianceScaling',
    'config': {
        'scale': 2.0,
        'mode': 'fan_out',
        'distribution': 'truncated_normal'
    }
}

DENSE_KERNEL_INITIALIZER = {
    'class_name': 'VarianceScaling',
    'config': {
        'scale': 1. / 3.,
        'mode': 'fan_out',
        'distribution': 'uniform'
    }
}

layers = VersionAwareLayers()

BASE_DOCSTRING = """"""Instantiates the {name} architecture.

  Reference:
  - [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](
      https://arxiv.org/abs/1905.11946) (ICML 2019)

  Optionally loads weights pre-trained on ImageNet.
  Note that the data format convention used by the model is
  the one specified in your Keras config at `~/.keras/keras.json`.
  If you have never configured it, it defaults to `""channels_last""`.

  Arguments:
    include_top: Whether to include the fully-connected
        layer at the top of the network. Defaults to True.
    weights: One of `None` (random initialization),
          'imagenet' (pre-training on ImageNet),
          or the path to the weights file to be loaded. Defaults to 'imagenet'.
    input_tensor: Optional Keras tensor
        (i.e. output of `layers.Input()`)
        to use as image input for the model.
    input_shape: Optional shape tuple, only to be specified
        if `include_top` is False.
        It should have exactly 3 inputs channels.
    pooling: Optional pooling mode for feature extraction
        when `include_top` is `False`. Defaults to None.
        - `None` means that the output of the model will be
            the 4D tensor output of the
            last convolutional layer.
        - `avg` means that global average pooling
            will be applied to the output of the
            last convolutional layer, and thus
            the output of the model will be a 2D tensor.
        - `max` means that global max pooling will
            be applied.
    classes: Optional number of classes to classify images
        into, only to be specified if `include_top` is True, and
        if no `weights` argument is specified. Defaults to 1000 (number of
        ImageNet classes).
    classifier_activation: A `str` or callable. The activation function to use
        on the ""top"" layer. Ignored unless `include_top=True`. Set
        `classifier_activation=None` to return the logits of the ""top"" layer.
        Defaults to 'softmax'.

  Returns:
    A `keras.Model` instance.
""""""


def EfficientNet(
    width_coefficient,
    depth_coefficient,
    default_size,
    dropout_rate=0.2,
    drop_connect_rate=0.2,
    depth_divisor=8,
    activation='swish',
    blocks_args='default',
    model_name='efficientnet',
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'):
  """"""Instantiates the EfficientNet architecture using given scaling coefficients.

  Reference:
  - [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](
      https://arxiv.org/abs/1905.11946) (ICML 2019)

  Optionally loads weights pre-trained on ImageNet.
  Note that the data format convention used by the model is
  the one specified in your Keras config at `~/.keras/keras.json`.

  Arguments:
    width_coefficient: float, scaling coefficient for network width.
    depth_coefficient: float, scaling coefficient for network depth.
    default_size: integer, default input image size.
    dropout_rate: float, dropout rate before final classifier layer.
    drop_connect_rate: float, dropout rate at skip connections.
    depth_divisor: integer, a unit of network width.
    activation: activation function.
    blocks_args: list of dicts, parameters to construct block modules.
    model_name: string, model name.
    include_top: whether to include the fully-connected
        layer at the top of the network.
    weights: one of `None` (random initialization),
          'imagenet' (pre-training on ImageNet),
          or the path to the weights file to be loaded.
    input_tensor: optional Keras tensor
        (i.e. output of `layers.Input()`)
        to use as image input for the model.
    input_shape: optional shape tuple, only to be specified
        if `include_top` is False.
        It should have exactly 3 inputs channels.
    pooling: optional pooling mode for feature extraction
        when `include_top` is `False`.
        - `None` means that the output of the model will be
            the 4D tensor output of the
            last convolutional layer.
        - `avg` means that global average pooling
            will be applied to the output of the
            last convolutional layer, and thus
            the output of the model will be a 2D tensor.
        - `max` means that global max pooling will
            be applied.
    classes: optional number of classes to classify images
        into, only to be specified if `include_top` is True, and
        if no `weights` argument is specified.
    classifier_activation: A `str` or callable. The activation function to use
        on the ""top"" layer. Ignored unless `include_top=True`. Set
        `classifier_activation=None` to return the logits of the ""top"" layer.

  Returns:
    A `keras.Model` instance.

  Raises:
    ValueError: in case of invalid argument for `weights`,
      or invalid input shape.
    ValueError: if `classifier_activation` is not `softmax` or `None` when
      using a pretrained top layer.
  """"""
  if blocks_args == 'default':
    blocks_args = DEFAULT_BLOCKS_ARGS

  if not (weights in {'imagenet', None} or file_io.file_exists_v2(weights)):
    raise ValueError('The `weights` argument should be either '
                     '`None` (random initialization), `imagenet` '
                     '(pre-training on ImageNet), '
                     'or the path to the weights file to be loaded.')

  if weights == 'imagenet' and include_top and classes != 1000:
    raise ValueError('If using `weights` as `""imagenet""` with `include_top`'
                     ' as true, `classes` should be 1000')

  # Determine proper input shape
  input_shape = imagenet_utils.obtain_input_shape(
      input_shape,
      default_size=default_size,
      min_size=32,
      data_format=backend.image_data_format(),
      require_flatten=include_top,
      weights=weights)

  if input_tensor is None:
    img_input = layers.Input(shape=input_shape)
  else:
    if not backend.is_keras_tensor(input_tensor):
      img_input = layers.Input(tensor=input_tensor, shape=input_shape)
    else:
      img_input = input_tensor

  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1

  def round_filters(filters, divisor=depth_divisor):
    """"""Round number of filters based on depth multiplier.""""""
    filters *= width_coefficient
    new_filters = max(divisor, int(filters + divisor / 2) // divisor * divisor)
    # Make sure that round down does not go down by more than 10%.
    if new_filters < 0.9 * filters:
      new_filters += divisor
    return int(new_filters)

  def round_repeats(repeats):
    """"""Round number of repeats based on depth multiplier.""""""
    return int(math.ceil(depth_coefficient * repeats))

  # Build stem
  x = img_input
  x = layers.Rescaling(1. / 255.)(x)
  x = layers.Normalization(axis=bn_axis)(x)

  x = layers.ZeroPadding2D(
      padding=imagenet_utils.correct_pad(x, 3),
      name='stem_conv_pad')(x)
  x = layers.Conv2D(
      round_filters(32),
      3,
      strides=2,
      padding='valid',
      use_bias=False,
      kernel_initializer=CONV_KERNEL_INITIALIZER,
      name='stem_conv')(x)
  x = layers.BatchNormalization(axis=bn_axis, name='stem_bn')(x)
  x = layers.Activation(activation, name='stem_activation')(x)

  # Build blocks
  blocks_args = copy.deepcopy(blocks_args)

  b = 0
  blocks = float(sum(round_repeats(args['repeats']) for args in blocks_args))
  for (i, args) in enumerate(blocks_args):
    assert args['repeats'] > 0
    # Update block input and output filters based on depth multiplier.
    args['filters_in'] = round_filters(args['filters_in'])
    args['filters_out'] = round_filters(args['filters_out'])

    for j in range(round_repeats(args.pop('repeats'))):
      # The first block needs to take care of stride and filter size increase.
      if j > 0:
        args['strides'] = 1
        args['filters_in'] = args['filters_out']
      x = block(
          x,
          activation,
          drop_connect_rate * b / blocks,
          name='block{}{}_'.format(i + 1, chr(j + 97)),
          **args)
      b += 1

  # Build top
  x = layers.Conv2D(
      round_filters(1280),
      1,
      padding='same',
      use_bias=False,
      kernel_initializer=CONV_KERNEL_INITIALIZER,
      name='top_conv')(x)
  x = layers.BatchNormalization(axis=bn_axis, name='top_bn')(x)
  x = layers.Activation(activation, name='top_activation')(x)
  if include_top:
    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)
    if dropout_rate > 0:
      x = layers.Dropout(dropout_rate, name='top_dropout')(x)
    imagenet_utils.validate_activation(classifier_activation, weights)
    x = layers.Dense(
        classes,
        activation=classifier_activation,
        kernel_initializer=DENSE_KERNEL_INITIALIZER,
        name='predictions')(x)
  else:
    if pooling == 'avg':
      x = layers.GlobalAveragePooling2D(name='avg_pool')(x)
    elif pooling == 'max':
      x = layers.GlobalMaxPooling2D(name='max_pool')(x)

  # Ensure that the model takes into account
  # any potential predecessors of `input_tensor`.
  if input_tensor is not None:
    inputs = layer_utils.get_source_inputs(input_tensor)
  else:
    inputs = img_input

  # Create model.
  model = training.Model(inputs, x, name=model_name)

  # Load weights.
  if weights == 'imagenet':
    if include_top:
      file_suffix = '.h5'
      file_hash = WEIGHTS_HASHES[model_name[-2:]][0]
    else:
      file_suffix = '_notop.h5'
      file_hash = WEIGHTS_HASHES[model_name[-2:]][1]
    file_name = model_name + file_suffix
    weights_path = data_utils.get_file(
        file_name,
        BASE_WEIGHTS_PATH + file_name,
        cache_subdir='models',
        file_hash=file_hash)
    model.load_weights(weights_path)
  elif weights is not None:
    model.load_weights(weights)
  return model


def block(inputs,
          activation='swish',
          drop_rate=0.,
          name='',
          filters_in=32,
          filters_out=16,
          kernel_size=3,
          strides=1,
          expand_ratio=1,
          se_ratio=0.,
          id_skip=True):
  """"""An inverted residual block.

  Arguments:
      inputs: input tensor.
      activation: activation function.
      drop_rate: float between 0 and 1, fraction of the input units to drop.
      name: string, block label.
      filters_in: integer, the number of input filters.
      filters_out: integer, the number of output filters.
      kernel_size: integer, the dimension of the convolution window.
      strides: integer, the stride of the convolution.
      expand_ratio: integer, scaling coefficient for the input filters.
      se_ratio: float between 0 and 1, fraction to squeeze the input filters.
      id_skip: boolean.

  Returns:
      output tensor for the block.
  """"""
  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1

  # Expansion phase
  filters = filters_in * expand_ratio
  if expand_ratio != 1:
    x = layers.Conv2D(
        filters,
        1,
        padding='same',
        use_bias=False,
        kernel_initializer=CONV_KERNEL_INITIALIZER,
        name=name + 'expand_conv')(
            inputs)
    x = layers.BatchNormalization(axis=bn_axis, name=name + 'expand_bn')(x)
    x = layers.Activation(activation, name=name + 'expand_activation')(x)
  else:
    x = inputs

  # Depthwise Convolution
  if strides == 2:
    x = layers.ZeroPadding2D(
        padding=imagenet_utils.correct_pad(x, kernel_size),
        name=name + 'dwconv_pad')(x)
    conv_pad = 'valid'
  else:
    conv_pad = 'same'
  x = layers.DepthwiseConv2D(
      kernel_size,
      strides=strides,
      padding=conv_pad,
      use_bias=False,
      depthwise_initializer=CONV_KERNEL_INITIALIZER,
      name=name + 'dwconv')(x)
  x = layers.BatchNormalization(axis=bn_axis, name=name + 'bn')(x)
  x = layers.Activation(activation, name=name + 'activation')(x)

  # Squeeze and Excitation phase
  if 0 < se_ratio <= 1:
    filters_se = max(1, int(filters_in * se_ratio))
    se = layers.GlobalAveragePooling2D(name=name + 'se_squeeze')(x)
    se = layers.Reshape((1, 1, filters), name=name + 'se_reshape')(se)
    se = layers.Conv2D(
        filters_se,
        1,
        padding='same',
        activation=activation,
        kernel_initializer=CONV_KERNEL_INITIALIZER,
        name=name + 'se_reduce')(
            se)
    se = layers.Conv2D(
        filters,
        1,
        padding='same',
        activation='sigmoid',
        kernel_initializer=CONV_KERNEL_INITIALIZER,
        name=name + 'se_expand')(se)
    x = layers.multiply([x, se], name=name + 'se_excite')

  # Output phase
  x = layers.Conv2D(
      filters_out,
      1,
      padding='same',
      use_bias=False,
      kernel_initializer=CONV_KERNEL_INITIALIZER,
      name=name + 'project_conv')(x)
  x = layers.BatchNormalization(axis=bn_axis, name=name + 'project_bn')(x)
  if id_skip and strides == 1 and filters_in == filters_out:
    if drop_rate > 0:
      x = layers.Dropout(
          drop_rate, noise_shape=(None, 1, 1, 1), name=name + 'drop')(x)
    x = layers.add([x, inputs], name=name + 'add')
  return x


@keras_export('keras.applications.efficientnet.EfficientNetB0',
              'keras.applications.EfficientNetB0')
def EfficientNetB0(include_top=True,
                   weights='imagenet',
                   input_tensor=None,
                   input_shape=None,
                   pooling=None,
                   classes=1000,
                   classifier_activation='softmax',
                   **kwargs):
  return EfficientNet(
      1.0,
      1.0,
      224,
      0.2,
      model_name='efficientnetb0',
      include_top=include_top,
      weights=weights,
      input_tensor=input_tensor,
      input_shape=input_shape,
      pooling=pooling,
      classes=classes,
      classifier_activation=classifier_activation,
      **kwargs)


@keras_export('keras.applications.efficientnet.EfficientNetB1',
              'keras.applications.EfficientNetB1')
def EfficientNetB1(include_top=True,
                   weights='imagenet',
                   input_tensor=None,
                   input_shape=None,
                   pooling=None,
                   classes=1000,
                   classifier_activation='softmax',
                   **kwargs):
  return EfficientNet(
      1.0,
      1.1,
      240,
      0.2,
      model_name='efficientnetb1',
      include_top=include_top,
      weights=weights,
      input_tensor=input_tensor,
      input_shape=input_shape,
      pooling=pooling,
      classes=classes,
      classifier_activation=classifier_activation,
      **kwargs)


@keras_export('keras.applications.efficientnet.EfficientNetB2',
              'keras.applications.EfficientNetB2')
def EfficientNetB2(include_top=True,
                   weights='imagenet',
                   input_tensor=None,
                   input_shape=None,
                   pooling=None,
                   classes=1000,
                   classifier_activation='softmax',
                   **kwargs):
  return EfficientNet(
      1.1,
      1.2,
      260,
      0.3,
      model_name='efficientnetb2',
      include_top=include_top,
      weights=weights,
      input_tensor=input_tensor,
      input_shape=input_shape,
      pooling=pooling,
      classes=classes,
      classifier_activation=classifier_activation,
      **kwargs)


@keras_export('keras.applications.efficientnet.EfficientNetB3',
              'keras.applications.EfficientNetB3')
def EfficientNetB3(include_top=True,
                   weights='imagenet',
                   input_tensor=None,
                   input_shape=None,
                   pooling=None,
                   classes=1000,
                   classifier_activation='softmax',
                   **kwargs):
  return EfficientNet(
      1.2,
      1.4,
      300,
      0.3,
      model_name='efficientnetb3',
      include_top=include_top,
      weights=weights,
      input_tensor=input_tensor,
      input_shape=input_shape,
      pooling=pooling,
      classes=classes,
      classifier_activation=classifier_activation,
      **kwargs)


@keras_export('keras.applications.efficientnet.EfficientNetB4',
              'keras.applications.EfficientNetB4')
def EfficientNetB4(include_top=True,
                   weights='imagenet',
                   input_tensor=None,
                   input_shape=None,
                   pooling=None,
                   classes=1000,
                   classifier_activation='softmax',
                   **kwargs):
  return EfficientNet(
      1.4,
      1.8,
      380,
      0.4,
      model_name='efficientnetb4',
      include_top=include_top,
      weights=weights,
      input_tensor=input_tensor,
      input_shape=input_shape,
      pooling=pooling,
      classes=classes,
      classifier_activation=classifier_activation,
      **kwargs)


@keras_export('keras.applications.efficientnet.EfficientNetB5',
              'keras.applications.EfficientNetB5')
def EfficientNetB5(include_top=True,
                   weights='imagenet',
                   input_tensor=None,
                   input_shape=None,
                   pooling=None,
                   classes=1000,
                   classifier_activation='softmax',
                   **kwargs):
  return EfficientNet(
      1.6,
      2.2,
      456,
      0.4,
      model_name='efficientnetb5',
      include_top=include_top,
      weights=weights,
      input_tensor=input_tensor,
      input_shape=input_shape,
      pooling=pooling,
      classes=classes,
      classifier_activation=classifier_activation,
      **kwargs)


@keras_export('keras.applications.efficientnet.EfficientNetB6',
              'keras.applications.EfficientNetB6')
def EfficientNetB6(include_top=True,
                   weights='imagenet',
                   input_tensor=None,
                   input_shape=None,
                   pooling=None,
                   classes=1000,
                   classifier_activation='softmax',
                   **kwargs):
  return EfficientNet(
      1.8,
      2.6,
      528,
      0.5,
      model_name='efficientnetb6',
      include_top=include_top,
      weights=weights,
      input_tensor=input_tensor,
      input_shape=input_shape,
      pooling=pooling,
      classes=classes,
      classifier_activation=classifier_activation,
      **kwargs)


@keras_export('keras.applications.efficientnet.EfficientNetB7',
              'keras.applications.EfficientNetB7')
def EfficientNetB7(include_top=True,
                   weights='imagenet',
                   input_tensor=None,
                   input_shape=None,
                   pooling=None,
                   classes=1000,
                   classifier_activation='softmax',
                   **kwargs):
  return EfficientNet(
      2.0,
      3.1,
      600,
      0.5,
      model_name='efficientnetb7',
      include_top=include_top,
      weights=weights,
      input_tensor=input_tensor,
      input_shape=input_shape,
      pooling=pooling,
      classes=classes,
      classifier_activation=classifier_activation,
      **kwargs)


EfficientNetB0.__doc__ = BASE_DOCSTRING.format(name='EfficientNetB0')
EfficientNetB1.__doc__ = BASE_DOCSTRING.format(name='EfficientNetB1')
EfficientNetB2.__doc__ = BASE_DOCSTRING.format(name='EfficientNetB2')
EfficientNetB3.__doc__ = BASE_DOCSTRING.format(name='EfficientNetB3')
EfficientNetB4.__doc__ = BASE_DOCSTRING.format(name='EfficientNetB4')
EfficientNetB5.__doc__ = BASE_DOCSTRING.format(name='EfficientNetB5')
EfficientNetB6.__doc__ = BASE_DOCSTRING.format(name='EfficientNetB6')
EfficientNetB7.__doc__ = BASE_DOCSTRING.format(name='EfficientNetB7')


@keras_export('keras.applications.efficientnet.preprocess_input')
def preprocess_input(x, data_format=None):  # pylint: disable=unused-argument
  return x


@keras_export('keras.applications.efficientnet.decode_predictions')
def decode_predictions(preds, top=5):
  return imagenet_utils.decode_predictions(preds, top=top)


decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__
```


Is there any reason why dilated convolution in tf.keras.layers.Conv2D runs extremely slower in cpu?
Thanks.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
49119,How does TFLite model and TFLite-quantized model converted?,"### 1. System information
 Linux Ubuntu 16.04

### 2. Question
I downloaded two tflite models from https://www.tensorflow.org/lite/guide/hosted_models
1. https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_0.75_224.tgz
2.https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.75_224_quant.tgz
They are both Mobilenet_V1_0.75_224 but one if float version and one is quant version. 

When I checked the weights in first CONV (MobilenetV1/Conv2d_0/weights) node, I can notice that the first value in the float model is 0.15756385028362274 and the first value in the quantized model is 171. However, as the quantization information provided in quantized model, the float value is 0.018297843635082245 * (q - 153), which is 0.3293612003326416 for q == 171, which is not matched with float model.

May I know why is that? Does it mean that although two models are both from  Mobilenet_V1_0.75_224 but they are not converted from each other?

Also, even if two models weights are not matched, I can get nearly the same output classification when I tried several pictures. It seems that both models are correct but with different weights. Does it mean that two models are trained in different ways?
"
49113,Patch mkl_serv_intel_cpu() to speed up MKL on AMD CPUs,"Per https://www.agner.org/optimize/blog/read.php?i=49#1022 and https://danieldk.eu/Posts/2020-08-31-MKL-Zen.html patching `int mkl_serv_intel_cpu()` to return 1 will cause MKL to run significantly fast under AMD CPUs. The link provides background information.

Is it possible to patch this out-of-the-box in the tensorflow-mkl package?

Note: I am not associated with the authors of these blogs. I am just a TensorFlow end-user with an AMD processor."
49112, tensorflow/core/grappler/costs/op_level_cost_estimator.cc:654] Check failed: iz % kz == 0 (256 vs. 0)Input channel 256 is not a multiple of filter channel 512.,"I am implementing the following code i.e CBAM module in a network, however, I am getting the **following error:**

F tensorflow/core/grappler/costs/op_level_cost_estimator.cc:654] Check failed: iz % kz == 0 (256 vs. 0)Input channel 256 is not a multiple of filter channel 512

Here is the code of the CBAM block

`import tensorflow as tf

def CBAM(input, reduction):
    """"""
    @Convolutional Block Attention Module
    """"""

    _, channel, width, height = input.get_shape()  # (B, W, H, C)

    input = tf.transpose(input, perm=[0, 3, 2, 1]) 
    # channel attention
    x_mean = tf.reduce_mean(input, axis=(1, 2), keepdims=True)   # (B, 1, 1, C)
    x_mean = tf.layers.conv2d(x_mean, channel // reduction, 1, activation=tf.nn.relu, name='CA1', reuse=tf.AUTO_REUSE)  # (B, 1, 1, C // r)
    x_mean = tf.layers.conv2d(x_mean, channel, 1, name='CA2', reuse=tf.AUTO_REUSE)   # (B, 1, 1, C)

    x_max = tf.reduce_max(input, axis=(1, 2), keepdims=True)  # (B, 1, 1, C)
    x_max = tf.layers.conv2d(x_max, channel // reduction, 1, activation=tf.nn.relu, name='CA1', reuse=tf.AUTO_REUSE)
    # (B, 1, 1, C // r)
    x_max = tf.layers.conv2d(x_max, channel, 1, name='CA2', reuse=tf.AUTO_REUSE)  # (B, 1, 1, C)

    x = tf.add(x_mean, x_max)   # (B, 1, 1, C)
    x = tf.nn.sigmoid(x)        # (B, 1, 1, C)
    x = tf.multiply(input, x)   # (B, W, H, C)

    # spatial attention
    y_mean = tf.reduce_mean(x, axis=3, keepdims=True)  # (B, W, H, 1)
    y_max = tf.reduce_max(x, axis=3, keepdims=True)  # (B, W, H, 1)
    y = tf.concat([y_mean, y_max], axis=-1)     # (B, W, H, 2)
    y = tf.layers.conv2d(y, 1, 7, padding='same', activation=tf.nn.sigmoid)    # (B, W, H, 1)
    y = tf.multiply(x, y)  # (B, W, H, C)

    y = tf.transpose(y, perm=[0, 3, 2, 1])
    return y`


**I have called CBAM module in-network as given below:**

`layer17 = tf.layers.conv2d(layer16, 512, 3,
                           padding=""same"",
                           activation=tf.nn.relu,
                           dilation_rate=2,
                           data_format=self._data_format,
                           name=""conv5/conv5_3"")

layer17=CBAM(layer17, 8)
layer18 = tf.layers.max_pooling2d(layer17, 2, 1,
                                  padding=""same"",
                                  data_format=self._data_format)` 
"
49107,TensorFlow won't detect GPU,"Hi, I'm beginning to use TensorFlow for a project and I'm having some issues with it picking up my GPU. When I run print(tf.config.list_physical_devices('GPU')) it returns an empty list instead.

I'm running it on TensorFlow 2.3.0, cudatoolkit 10.1 and my GPU is CUDA enabled.

Any help is very much appreciated.


"
49105,tensorflow.python.framework.errors_impl.NotFoundError: Key BeamSearchDecoderStep/multi_rnn_cell/cell_0_attention/attention_wrapper/lstm_cell_9/bias not found in checkpoint,"**System information**
- TensorFlow version: 2.4.0
- Python version: 3.6.2

**Problem**
I am trying to upgrade the LAS model from tensorflow 1.8.0 version to 2.4.0. There is no problem in training the model, but in the testing phase, loading the model will show that there is a parameter not found. I printed the saved model file, there is a parameter named 1 in it. I don't understand where the problem is. I would be very grateful if you can answer my question!

**Error Message**
```
2021-05-11 17:09:25.582423: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-05-11 17:09:25.582893: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO:tensorflow:Using config: {'_model_dir': './data_kss/Kspon_dataset/model_test', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Building listener
2021-05-11 17:09:33.837384: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-11 17:09:33.841199: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2021-05-11 17:09:33.841721: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-05-11 17:09:33.850617: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-I630CDV
2021-05-11 17:09:33.851304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-I630CDV
2021-05-11 17:09:33.852078: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-11 17:09:33.853485: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
INFO:tensorflow:Building speller
WARNING:tensorflow:From C:\Users\yangrui\Desktop\PythonProject\Korean_Speech\las\model.py:346: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2021-05-11T17:09:47Z
INFO:tensorflow:Graph was finalized.
2021-05-11 17:09:48.052221: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
INFO:tensorflow:Restoring parameters from ./data_kss/Kspon_dataset/model_test\model.ckpt-0
2021-05-11 17:09:48.135902: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2021-05-11 17:09:48.321843: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at save_restore_v2_ops.cc:205 : Not found: Key BeamSearchDecoderStep/multi_rnn_cell/cell_0_attention/attention_wrapper/lstm_cell_9/bias not found in checkpoint
Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\client\session.py"", line 1375, in _do_call
    return fn(*args)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\client\session.py"", line 1360, in _run_fn
    target_list, run_metadata)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\client\session.py"", line 1453, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.NotFoundError: Key BeamSearchDecoderStep/multi_rnn_cell/cell_0_attention/attention_wrapper/lstm_cell_9/bias not found in checkpoint
	 [[{{node save/RestoreV2}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 1298, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\client\session.py"", line 968, in run
    run_metadata_ptr)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\client\session.py"", line 1191, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\client\session.py"", line 1369, in _do_run
    run_metadata)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\client\session.py"", line 1394, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Key BeamSearchDecoderStep/multi_rnn_cell/cell_0_attention/attention_wrapper/lstm_cell_9/bias not found in checkpoint
	 [[node save/RestoreV2 (defined at \Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py:1647) ]]

Original stack trace for 'save/RestoreV2':
  File ""/Users/yangrui/Desktop/PythonProject/Korean_Speech/eval.py"", line 114, in <module>
    main(args)
  File ""/Users/yangrui/Desktop/PythonProject/Korean_Speech/eval.py"", line 85, in main
    input_fn=lambda: input_fn(
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 467, in evaluate
    name=name)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 510, in _actual_eval
    return _evaluate()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 499, in _evaluate
    output_dir=self.eval_dir(name))
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1647, in _evaluate_run
    config=self._session_config)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\evaluation.py"", line 269, in _evaluate_once
    session_creator=session_creator, hooks=hooks) as session:
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1038, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 749, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1231, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1236, in _create_session
    return self._sess_creator.create_session()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 902, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 660, in create_session
    self._scaffold.finalize()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 235, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 606, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 835, in __init__
    self.build()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 847, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 885, in _build
    build_restore=build_restore)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 509, in _build_internal
    restore_sequentially, reshape)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 388, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 335, in _AddRestoreOps
    restore_sequentially)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 582, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 1510, in restore_v2
    name=name)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 750, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\framework\ops.py"", line 3536, in _create_op_internal
    op_def=op_def)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\framework\ops.py"", line 1990, in __init__
    self._traceback = tf_stack.extract_stack()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\py_checkpoint_reader.py"", line 70, in get_tensor
    self, compat.as_bytes(tensor_str))
RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 1308, in restore
    names_to_keys = object_graph_key_mapping(save_path)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 1626, in object_graph_key_mapping
    object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\py_checkpoint_reader.py"", line 74, in get_tensor
    error_translator(e)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/yangrui/Desktop/PythonProject/Korean_Speech/eval.py"", line 114, in <module>
    main(args)
  File ""C:/Users/yangrui/Desktop/PythonProject/Korean_Speech/eval.py"", line 85, in main
    input_fn=lambda: input_fn(
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 467, in evaluate
    name=name)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 510, in _actual_eval
    return _evaluate()
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 499, in _evaluate
    output_dir=self.eval_dir(name))
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1647, in _evaluate_run
    config=self._session_config)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\evaluation.py"", line 269, in _evaluate_once
    session_creator=session_creator, hooks=hooks) as session:
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1038, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 749, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1231, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1236, in _create_session
    return self._sess_creator.create_session()
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 902, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 669, in create_session
    init_fn=self._scaffold.init_fn)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\session_manager.py"", line 295, in prepare_session
    config=config)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\session_manager.py"", line 209, in _restore_checkpoint
    saver.restore(sess, checkpoint_filename_with_path)
  File ""C:\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 1314, in restore
    err, ""a Variable name or other graph key that is missing"")
tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Key BeamSearchDecoderStep/multi_rnn_cell/cell_0_attention/attention_wrapper/lstm_cell_9/bias not found in checkpoint
	 [[node save/RestoreV2 (defined at \Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py:1647) ]]

Original stack trace for 'save/RestoreV2':
  File ""/Users/yangrui/Desktop/PythonProject/Korean_Speech/eval.py"", line 114, in <module>
    main(args)
  File ""/Users/yangrui/Desktop/PythonProject/Korean_Speech/eval.py"", line 85, in main
    input_fn=lambda: input_fn(
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 467, in evaluate
    name=name)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 510, in _actual_eval
    return _evaluate()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 499, in _evaluate
    output_dir=self.eval_dir(name))
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1647, in _evaluate_run
    config=self._session_config)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\evaluation.py"", line 269, in _evaluate_once
    session_creator=session_creator, hooks=hooks) as session:
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1038, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 749, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1231, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1236, in _create_session
    return self._sess_creator.create_session()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 902, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 660, in create_session
    self._scaffold.finalize()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 235, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 606, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 835, in __init__
    self.build()
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 847, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 885, in _build
    build_restore=build_restore)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 509, in _build_internal
    restore_sequentially, reshape)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 388, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 335, in _AddRestoreOps
    restore_sequentially)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\training\saver.py"", line 582, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 1510, in restore_v2
    name=name)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 750, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\framework\ops.py"", line 3536, in _create_op_internal
    op_def=op_def)
  File ""\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\framework\ops.py"", line 1990, in __init__
    self._traceback = tf_stack.extract_stack()


Process finished with exit code 1

```

**Part of my code:**
```
import tensorflow as tf
import numpy as np
from tensorflow.python.util import nest
import tensorflow_addons as tfa

from las.ops import lstm_cell
from las.ops import pyramidal_bilstm
# assert tf.executing_eagerly()
__all__ = [
    'listener',
    'speller',
]


""""""Reference: https://github.com/tensorflow/nmt/blob/master/nmt/gnmt_model.py""""""


class AttentionMultiCell(tf.keras.layers.StackedRNNCells):
# class AttentionMultiCell(tf.compat.v1.nn.rnn_cell.MultiRNNCell):
    """"""A MultiCell with attention style.""""""

    def __init__(self, attention_cell, cells, use_new_attention=False):
        """"""Creates a AttentionMultiCell.
        Args:
          attention_cell: An instance of AttentionWrapper.
          cells: A list of RNNCell wrapped with AttentionInputWrapper.
          use_new_attention: Whether to use the attention generated from current
            step bottom layer's output. Default is False.
        """"""
        cells = [attention_cell] + cells
        self.use_new_attention = use_new_attention
        super(AttentionMultiCell, self).__init__(
            cells)

    def __call__(self, inputs, state, training=False, scope=None):
        """"""Run the cell with bottom layer's attention copied to all upper layers.""""""
        if not nest.is_sequence(state):
            raise ValueError(
                ""Expected state to be a tuple of length %d, but received: %s""
                % (len(self.state_size), state))

        with tf.compat.v1.variable_scope(scope or ""multi_rnn_cell""):
            new_states = []

            with tf.compat.v1.variable_scope(""cell_0_attention""):
                attention_cell = self.cells[0]
                attention_state = state[0]
                cur_inp, new_attention_state = attention_cell(
                    inputs, attention_state)

                new_states.append(new_attention_state)

            for i in range(1, len(self.cells)):
                with tf.compat.v1.variable_scope(""cell_%d"" % i):

                    cell = self.cells[i]
                    cur_state = state[i]

                    if self.use_new_attention:
                        cur_inp = tf.concat(
                            [cur_inp, new_attention_state.attention], -1)
                    else:
                        cur_inp = tf.concat(
                            [cur_inp, attention_state.attention], -1)

                    cur_inp, new_state = cell(cur_inp, cur_state)
                    new_states.append(new_state)
        return cur_inp, new_states


class CustomAttention(tfa.seq2seq.LuongAttention):
    def __init__(self,
                 num_units,
                 memory,
                 memory_sequence_length=None,
                 scale=False,
                 probability_fn=None,
                 score_mask_value=None,
                 dtype=None,
                 name=""CustomAttention""):

        super(CustomAttention, self).__init__(
            num_units=num_units,
            memory=memory,
            memory_sequence_length=memory_sequence_length,
            scale=scale,
            probability_fn=probability_fn,
            score_mask_value=score_mask_value,
            dtype=dtype,
            name=name)

        self._query_layer = tf.compat.v1.layers.Dense(
            num_units, name='query_layer', use_bias=False, dtype=dtype)

        self._keys = tf.nn.relu(self.keys)

    def __call__(self, query, state):
        processed_query = tf.nn.relu(self.query_layer(query))

        return super(CustomAttention, self).__call__(processed_query, state)


def listener(encoder_inputs,
             source_sequence_length,
             mode,
             hparams):

    if hparams['use_pyramidal']:
        return pyramidal_bilstm(encoder_inputs, source_sequence_length, mode, hparams)
    else:
        forward_cell_list, backward_cell_list = [], []
        for layer in range(hparams['num_layers']):
            with tf.compat.v1.variable_scope('fw_cell_{}'.format(layer)):
                cell = lstm_cell(hparams['num_units'], hparams['dropout'], mode)

            forward_cell_list.append(cell)

            with tf.compat.v1.variable_scope('bw_cell_{}'.format(layer)):
                cell = lstm_cell(hparams['num_units'], hparams['dropout'], mode)

            backward_cell_list.append(cell)

        forward_cell = tf.keras.layers.StackedRNNCells(forward_cell_list)
        backward_cell = tf.keras.layers.StackedRNNCells(backward_cell_list)

        encoder_outputs, encoder_state = tf.keras.layers.Bidirectional(
            forward_cell,
            backward_cell,
            encoder_inputs,
            sequence_length=source_sequence_length,
            dtype=tf.float32)
        # outputs:[batch_size, max_time, forward_cell.output_size]
        # [batch_size, max_time, hidden_size]

        encoder_outputs = tf.concat(encoder_outputs, -1)

        return (encoder_outputs, source_sequence_length), encoder_state


def attend(encoder_outputs,
           source_sequence_length,
           mode,
           hparams):

    memory = encoder_outputs

    if hparams['attention_type'] == 'luong':
        attention_fn = tfa.seq2seq.LuongAttention
    elif hparams['attention_type'] == 'bahdanau':
        attention_fn = tfa.seq2seq.BahdanauAttention
    elif hparams['attention_type'] == 'custom':
        attention_fn = CustomAttention

    attention_mechanism = attention_fn(
        hparams['num_units'], memory, source_sequence_length)

    cell_list = []
    for layer in range(hparams['num_layers']):

        with tf.compat.v1.variable_scope('decoder_cell_'.format(layer)):
            cell = lstm_cell(hparams['num_units'], hparams['dropout'], mode)

        # cell = lstm_cell(hparams['num_units'], hparams['dropout'], mode)
        cell_list.append(cell)

    alignment_history = (mode != tf.estimator.ModeKeys.TRAIN)

    if hparams['bottom_only']: # False
        #  Only wrap the bottom layer with the attention mechanism.

        attention_cell = cell_list.pop(0)
        # attention_cell = tf.cast(attention_cell, dtype='float32')
        # attention_mechanism = tf.cast(attention_mechanism, dtype='float32')
        attention_cell = tfa.seq2seq.AttentionWrapper(
            attention_cell, attention_mechanism,
            attention_layer_size=hparams['attention_layer_size'],
            alignment_history=alignment_history)

        decoder_cell = AttentionMultiCell(attention_cell, cell_list)
    else:
        decoder_cell = tf.keras.layers.StackedRNNCells(cell_list)

        decoder_cell = tfa.seq2seq.AttentionWrapper(
            decoder_cell, attention_mechanism,
            attention_layer_size=hparams['attention_layer_size'],
            alignment_history=alignment_history)

    return decoder_cell


def speller(encoder_outputs,
            encoder_state,
            decoder_inputs,
            source_sequence_length,
            target_sequence_length,
            mode,
            hparams):

    batch_size = tf.shape(input=encoder_outputs)[0]
    beam_width = hparams['beam_width']

    if mode == tf.estimator.ModeKeys.PREDICT and beam_width > 0:
        encoder_outputs = tfa.seq2seq.tile_batch(
            encoder_outputs, multiplier=beam_width)
        source_sequence_length = tfa.seq2seq.tile_batch(
            source_sequence_length, multiplier=beam_width)
        encoder_state = tfa.seq2seq.tile_batch(
            encoder_state, multiplier=beam_width)
        batch_size = batch_size * beam_width


    if mode == tf.estimator.ModeKeys.EVAL and beam_width > 0:
        encoder_outputs = tfa.seq2seq.tile_batch(
            encoder_outputs, multiplier=beam_width)
        source_sequence_length = tfa.seq2seq.tile_batch(
            source_sequence_length, multiplier=beam_width)
        encoder_state = tfa.seq2seq.tile_batch(
            encoder_state, multiplier=beam_width)
        batch_size = batch_size * beam_width

    def embedding_fn(ids):
        # pass callable object to avoid OOM when using one-hot encoding
        if hparams['embedding_size'] != 0:
            target_embedding = tf.compat.v1.get_variable(
                'target_embedding', [
                    hparams['target_vocab_size'], hparams['embedding_size']],
                dtype=tf.float32, initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=""fan_avg"", distribution=""uniform""))

            return tf.nn.embedding_lookup(params=target_embedding, ids=ids)
        else:
            return tf.one_hot(ids, hparams['target_vocab_size'])

    decoder_cell = attend(
        encoder_outputs, source_sequence_length, mode, hparams)

    projection_layer = tf.keras.layers.Dense(
        hparams['target_vocab_size'], use_bias=True, name='projection_layer')

    if hparams['pass_hidden_state'] and hparams['bottom_only']:
        initial_state = tuple(
            zs.clone(cell_state=es)
            if isinstance(zs, tfa.seq2seq.AttentionWrapperState) else es
            for zs, es in zip(
                decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32), encoder_state))
    else:
        initial_state = decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)

    maximum_iterations = None
    if mode != tf.estimator.ModeKeys.TRAIN:
        max_source_length = tf.reduce_max(input_tensor=source_sequence_length)
        maximum_iterations = tf.cast(tf.round(tf.cast(
            max_source_length, dtype=tf.float32) * hparams['decoding_length_factor']), dtype=tf.int32)

    if mode == tf.estimator.ModeKeys.TRAIN:
        decoder_inputs = embedding_fn(decoder_inputs)
        decay_steps = hparams['decay_steps']
        iter_num = tf.compat.v1.train.get_global_step()
        inverse_probability = tf.compat.v1.train.polynomial_decay(
            1.0, iter_num, decay_steps, 0.6)
        sampling_probability = 1.0 - inverse_probability
        if hparams['sampling_probability']:
            helper = tfa.seq2seq.ScheduledEmbeddingTrainingSampler(
                sampling_probability=sampling_probability,
                embedding_fn=embedding_fn
            )
        else:
            helper = tfa.seq2seq.TrainingSampler()

        decoder = tfa.seq2seq.BasicDecoder(
            cell=decoder_cell,
            sampler=helper,
            output_layer=projection_layer,
            maximum_iterations=maximum_iterations
        )
     
        decoder_outputs, final_context_state, final_sequence_length = tfa.seq2seq.dynamic_decode(
            decoder, training=True, decoder_init_input=decoder_inputs, decoder_init_kwargs={
                'initial_state': initial_state, 'sequence_length': target_sequence_length
            })

    elif mode == tf.estimator.ModeKeys.PREDICT and beam_width > 0:
        start_tokens = tf.fill(
            [tf.compat.v1.div(batch_size, beam_width)], hparams['sos_id'])

        decoder = tfa.seq2seq.BeamSearchDecoder(
            cell=decoder_cell,
            embedding_fn=embedding_fn,
            beam_width=beam_width,
            output_layer=projection_layer,
            maximum_iterations=maximum_iterations
        )
        decoder_outputs, final_context_state, final_sequence_length = tfa.seq2seq.dynamic_decode(
            decoder, decoder_inputs=embedding_fn(decoder_inputs),
            training=False, decoder_init_kwargs={
                'start_tokens': start_tokens, 'end_token': hparams['eos_id'],
                'initial_state': initial_state
            })
    else:
        '''
        start_tokens = tf.fill([batch_size], hparams.sos_id)

        helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(
            embedding_fn, start_tokens, hparams.eos_id)
        
        decoder = tf.contrib.seq2seq.BasicDecoder(
            decoder_cell, helper, initial_state, output_layer=projection_layer)
        '''

        start_tokens = tf.fill(
            [tf.compat.v1.div(batch_size, beam_width)], hparams['sos_id'])

        decoder = tfa.seq2seq.BeamSearchDecoder(
            cell=decoder_cell,
            embedding_fn=embedding_fn,
            beam_width=beam_width,
            output_layer=projection_layer,
            maximum_iterations=maximum_iterations
        )

       

        decoder_outputs, final_context_state, final_sequence_length = tfa.seq2seq.dynamic_decode(
            decoder, decoder_inputs=embedding_fn(decoder_inputs),
            training=False, decoder_init_kwargs={
                'start_tokens':start_tokens,
                'end_token':hparams['eos_id'],
                'initial_state': initial_state
            })

    return decoder_outputs, final_context_state, final_sequence_length


```
Besides,  I use tf.estimator.Estimator for training and evaluation.
"
49103,Tensorflow Certificate on Mac M1,"**System information**
- OS Platform and Distribution: Mac M1 Big Sur 11.3
- TensorFlow version: 2.4.1
- Python version:3.8
- GPU model and memory: M1



**Describe the problem**

Anyone has tried to take the TF certificate exam on a Mac M1 device?

I've installed tensorflow-macos in an env and it works fine. However, the exam would create a new project in Pycharm using my global python and install original tensorflow 2.4.1. I tried to manually install original tensorflow 2.4.1 globally, but I got :

Process finished with exit code 132 (interrupted by signal 4: SIGILL)

So is there any way that I can use a existing env to run the exam or I get the original tensorflow working properly on Mac M1?

Many thanks!
"
49102,code error,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
**tensorflow/tensorflow/lite/micro/test_helpers.h::line25**
```bash
#include ""tensorflow/lite  //   kernels/internal/tensor_ctypes.h""
```
**there are two slashs before kernels.obviously it is an error.**

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
49101,`tf.keras.preprocessing.image.smart_resize` stable docs does not render properly,"## URL(s) with the issue:

> Please provide a link to the documentation entry, for example:

https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/smart_resize 

## Description of issue (what needs changing):

### Clear description

In the ""Stable"" tab of the [`tf.keras.preprocessing.image.smart_resize`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/smart_resize ) docs, the output docs seem like they're HTML-escaped and/or input markdown (opposed to actually rendering as HTML). 

For reference, I'm reporting this bug from Chrome 90 on macOS. I get the same results on Firefox and Safari, also on macOS - likely, the generated docs page is incorrect.

### Usage example

N/A

### Request visuals, if applicable

> Are there currently visuals? If not, will it clarify the content?

Here's a screenshot of what I see on Chrome 90 on macOS, under the ""stable"" tab:

![Screen Shot 2021-05-10 at 5 18 41 PM](https://user-images.githubusercontent.com/14893287/117739761-d7a35500-b1b3-11eb-9575-a2d07c8cb151.png)

In contrast, here is the nightly tab, which works as intended:

![Screen Shot 2021-05-10 at 5 19 21 PM](https://user-images.githubusercontent.com/14893287/117739839-04f00300-b1b4-11eb-911b-a873dc323207.png)


### Submit a pull request?

Not very familiar with the tensorflow docs API, but if it's a simple change, I wouldn't mind taking a crack at it!
"
49048,File-Based Dataset Sharding not working with experimental dataset load(),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8
- CUDA/cuDNN version: 11.0
- GPU model and memory: 2x RTX A6000

**Describe the current behavior**
I am experimenting with the new api for loading and saving a tf.data dataset, and everything works fine until I go to distribute on multiple GPUs. When doing so, I get warnings such as the following indicating that file-based sharding failed and that data-based sharding will be used:

```
2021-05-10 11:42:25.281639: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard
. Error: Did not find a shardable source, walked to a node which is not a dataset: name: ""LoadDataset/_1""                                                                                                                               
op: ""LoadDataset""                                                                                                                                                                                                                       
input: ""Const/_0""         
attr {                    
  key: ""Treader_func_args""
  value {             
    list {            
    }                 
  }                   
}                     
attr {                
  key: ""compression""  
  value {             
    s: ""GZIP""         
  }                   
}                     
attr {                
  key: ""output_shapes""
  value {             
    list {            
      shape {         
        dim {         
          size: 678400
        }         
      }           
      shape {     
        dim {     
          size: 16
        }         
      }           
      shape {     
        dim {     
          size: 64
        }         
      }           
      shape {     
        dim {     
          size: -1
        }
        dim {
          size: 5
        }
      }
    }
  }
}
attr {                                                                                                                                                                                                                                  
  key: ""output_types""                                                                                                                                                                                                                   
  value {                                                                                                                                                                                                                               
    list {                                                                                                                                                                                                                              
      type: DT_FLOAT                                                                                                                                                                                                                    
      type: DT_FLOAT                                                                                                                                                                                                                    
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""reader_func""
  value {
    func {
      name: ""__inference_load_lambda_53""
    }
  }
}
. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_poli
cy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
```

The thing is, file-based sharding should work. When I saved the dataset using tf.data.experimental.save(), I specified splitting into 20 shards, 10 for each of my 2 GPUs, but somehow the distribute strategy isn't aware of these file shards.

**Describe the expected behavior**
Tensorflow would detect a file-sharded dataset and use file sharding rather than data sharding.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): no

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

How I'm saving the data:

```
def shard_func(w, x, y, z):
    return tf.random.uniform([1], minval=0, maxval=20, dtype=tf.int64)

tf.data.experimental.save(tensor_ds, 'mypath', compression='GZIP', shard_func=shard_func)
```
How I'm loading it:

```
tensor_ds = tf.data.experimental.load('mypath', (
                                                    tf.TensorSpec(shape=[678400], dtype=tf.float32), 
                                                    tf.TensorSpec(shape=[16], dtype=tf.float32), 
                                                    tf.TensorSpec(shape=[64], dtype=tf.float32), 
                                                    tf.TensorSpec(shape=[None,5], dtype=tf.float32)),
                                                    compression=""GZIP""
                                                    ).shuffle(1024).prefetch(128)
tensor_ds = tensor_ds.map(shape, num_parallel_calls=32)
tensor_ds = tensor_ds.map(transform, num_parallel_calls=32)
tensor_ds = tensor_ds.apply(tf.data.experimental.dense_to_ragged_batch(batch_size=32, drop_remainder=True))
final_ds = tensor_ds.map(fill_boxes, num_parallel_calls=tf.data.AUTOTUNE).prefetch(2)
```

Finally, I'm using tf.distribute.MirroredStrategy() as my strategy.

Is it possible my additional map() steps in the data pipeline are causing the information about sharding to get lost? I.e. things would work if the model directly consumed the data from load() function? "
49047,DSP(Hexagon) delegate run tensorflow-lite C++ example label_image more slowly than CPU,"I compile tensorflow-lite and the example label_image in tensorflow-lite source code success,
I did run with delegates of DSP(Hexagon) and CPU by ADB with running comands:
CPU: ./label_image -m tflite_model_int8.tflite -i grace_hopper.bmp -l labels.txt 1
DSP: ./label_image -m tflite_model_int8.tflite -i grace_hopper.bmp -l labels.txt -j 1
Both seems runs success, but average time or DSP: 60.00 ms, average time or CPU : 40.00 ms
Is it right? DSP is more slow than CPU for 50% ?
If Not, what should I do to make DSP(Hexagon) runs at good performance?

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 9.0
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: BBK S5d (SOC: Qualcomm Snapdragon 660)
TensorFlow installed from (source or binary): build by myself
TensorFlow version (use command below): tensorflow-2.4.1
Python version: Python 3.8.5
Bazel version (if compiling from source): 3.1.0
GCC/Compiler version (if compiling from source): g++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
CUDA/cuDNN version:
GPU model and memory:
SOC: Qualcomm Snapdragon 660

Could anyone help? Or give a advice?
Thank you so much~
"
49046,Unclear error message in keras.backend.bias_add,"https://github.com/tensorflow/tensorflow/blob/40caef44549a199eaac327b673fa862194b66fc4/tensorflow/python/keras/backend.py#L6004-L6007

Is line 6007 supposed to be `(len(bias_shape), ndim(x) - 1))`?"
49045,Converted model ERROR: Unsupported data type 14 in tensor,"### 1. System information
Converted on:
- Widows 10
- TensorFlow 2.5.0

Run on:


- iOS 11.1
- POD installation:
- TensorFlowLite 2.4.0:

### 2. Code
regular tensroflowlite ios app example

### 3. Failure after conversion

ERROR:
Unsupported data type 14 in tensor

------------------------------------
Details:
I converted tensorflow model to tensorflow lite and tried to use it with iOS app (firstly on simulator) and unfortunately it makes an error during the interpreter build

Model path:
https://drive.google.com/drive/folders/1rdbLyp9BJWhz9oyR0-PAdsLPjcAzno6Z
You can ask for access if you need it


@mariaHit FYI
"
49044,How to pack libtensorflow_cc.so along with wheel file,"I am building TF 1.15 from source and I am able to build the wheel file using this command:
**bazel build -c opt //tensorflow/tools/pip_package:build_pip_package**
**./bazel-bin/tensorflow/tools/pip_package/build_pip_package ../**
 And i am able to install and use above wheel file without any issue in another system.

Next i am trying to build libtensorflow_cc.so and i am using below command:
**bazel build -c opt //tensorflow:libtensorflow_cc.so**
I can see the .so file built and present in the path: **tensorflow/bazel-bin/tensorflow/libtensorflow_cc.so**
Is there any way I can package the **libtensorflow_cc.so** file along with wheel file?
What would be command/changes required to do it?
How to get single wheel file that I can build in one system and use the wheel file in another system so that i am able to run both python interface as well as C++ interface?"
49043,Batch segment reduce function,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.15 (It's natural to update the feature in tf 2.x. And it's much better if the feature can be added in tf 1.x too)
- Are you willing to contribute it (Yes/No): Yes. I would try.

**Describe the feature and the current behavior/state.**
   Thanks for providing tensorflow framework and it's quit efficient to use `tf.math.segment_x` for some manipulations. Howerver,  we usually use batch training in deep learning pipeline. So, I'm eager for the function family like `tf.math.batch_segment_x`. Here is the api description for one example:
Batch segment reduce sum:
`tf.math.batch_segment_sum(data, batch_segment_ids, max_seq_len, mask_vals, name)`
- `data`: Tensor whose rank >= 2  
- `batch_segment_ids`: Tensor or list whose rank == 2; Sorted; `batch_segment_ids.shape[0] == data.shape[0]`
- `max_seq_len`: Scalar. Different instances in a batch may have different segmentation. Some length is larger(max value in `batch_segment_ids[i, :]`, some is small. This is for length alignment in a batch.  Clip while length of one instance(`data[i, :, ..., :]`) after op is larger than `max_seq_len`; Mask while smaller.
- `mask_vals`: Scalar or 1D tensor. If it's 1D tensor, it's length must be equal with `data.shape[0]`. Mask vals for instances in a batch. Scalar means all mask value is same. Tensor for different vals with different instances.

**Will this change the current api? How?**
Yes. Some new api will be added into `tf.math`, like `tf.math.batch_segment_sum`, `tf.math.batch_segment_max`, `tf.math.batch_segment_min`, etc.

**Who will benefit with this feature?**
Someone who often work with sequence model and need some feature engineering or some  complex manipulation in a model. 
Hope this feature request issue can be achieved and I appreciate a lot for all the development work about this issue.

**Any Other info.**
It would be better if `tf.math.batch_unsorted_segment_x` api can be added."
49041,Error: No such file or directory,"Can anyone help me fix this error:
```
...
  File ""/home/notooth/anaconda3/lib/python3.8/site-packages/tensorflow_text/__init__.py"", line 21, in <module>
    from tensorflow_text.python import metrics
  File ""/home/notooth/anaconda3/lib/python3.8/site-packages/tensorflow_text/python/metrics/__init__.py"", line 20, in <module>
    from tensorflow_text.python.metrics.text_similarity_metric_ops import *
  File ""/home/notooth/anaconda3/lib/python3.8/site-packages/tensorflow_text/python/metrics/text_similarity_metric_ops.py"", line 28, in <module>
    gen_text_similarity_metric_ops = load_library.load_op_library(resource_loader.get_path_to_datafile('_text_similarity_metric_ops.so'))
  File ""/home/notooth/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 58, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: /home/notooth/anaconda3/lib/python3.8/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb
bash: --gin_param=input_filename='input.txt': No such file or directory
```"
49029,BasicDecoderOutput with None lengths in networks_seq2seq_nmt example,"## URL(s) with the issue:
https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt

## Description of issue (what needs changing):
It is not clear what the output of the BasicDecoder is. The output variable is is from type BasicDecoderOutput and has two attributes: rnn_output and  sample_id. The output should be (in my opinion) of shape (batch_size, target_leghts, vocab_size) and (batch_size, target_leghts) respectively. When I print the variable in the training loop the larget_lengths is None. Why is this not an issue for the calculation of the loss? and how do I get the real predictions inside the train_step function e.g. to calculate metrics?

### Submit a pull request?
Currently not since I don't understand the solution myself. But afterwards, I would create a pull request to share the information.
"
49028,tf_uniform_replay_buffer Warning,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Springdale Linux 7.9 (Verona)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.9.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.3
- GPU model and memory: Tesla P100

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
TF uniform buffer raises error.

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): no

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
import numpy as np

from tf_agents import specs
from tf_agents.agents.dqn import dqn_agent
from tf_agents.drivers import dynamic_step_driver
from tf_agents.environments import suite_gym
from tf_agents.environments import tf_py_environment
from tf_agents.networks import q_network
from tf_agents.replay_buffers import py_uniform_replay_buffer
from tf_agents.replay_buffers import tf_uniform_replay_buffer
from tf_agents.specs import tensor_spec
from tf_agents.trajectories import time_step

tf.compat.v1.enable_v2_behavior()

data_spec =  (
        tf.TensorSpec([3], tf.float32, 'action'),
        (
            tf.TensorSpec([5], tf.float32, 'lidar'),
            tf.TensorSpec([3, 2], tf.float32, 'camera')
        )
)

batch_size = 1
max_length = 1000

replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(
    data_spec,
    batch_size=batch_size,
    max_length=max_length)

action = tf.constant(1 * np.ones(
    data_spec[0].shape.as_list(), dtype=np.float32))
lidar = tf.constant(
    2 * np.ones(data_spec[1][0].shape.as_list(), dtype=np.float32))
camera = tf.constant(
    3 * np.ones(data_spec[1][1].shape.as_list(), dtype=np.float32))

values = (action, (lidar, camera))
values_batched = tf.nest.map_structure(lambda t: tf.stack([t] * batch_size),
                                       values)

for _ in range(5):
    replay_buffer.add_batch(values_batched)

dataset = replay_buffer.as_dataset(sample_batch_size=4,single_deterministic_pass=False)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
[bug_report.txt](https://github.com/tensorflow/tensorflow/files/6448373/bug_report.txt)

"
49027,why with mirroredStrategy GPUs have different memory footprint?,"With data parallelization, I was expecting all GPUs will have the same memory footprint for a training model with GLOBAL_BATCH_SIZE divisible by #GPUs. But why I am seeing different memory footprint ranging from 5.2GB to 9.2G per GPU? I am on a DGX-1 and training a GAN model with GLOBAL_BATCH_SIZE=32 and 8 V100 GPUs. The model is quite small though (128x128)

After more testings, it seems that TF allocates a constant memory (~4GB) regardless of the model size and prefetch() causes this random memory footprint. Can someone help to explain TF memory model? 

<img width=""890"" alt=""Screen Shot 2021-05-09 at 3 28 26 PM"" src=""https://user-images.githubusercontent.com/3358807/117586048-65f7d800-b0db-11eb-8648-ed342320ea16.png"">
"
49022,Problems when using a100 graphics card,"Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...

Is there any way to install tensorflow directly when using a100 server?
Do I have to use the docker image provided by nvidia?
Installation was done with pip tensorflow-gpu."
49021,Variable scope is created repeatedly,"tensorflow version: 1.15.0
python version: 3.6.12
Variable scope is created repeatedly using tf.variable_scope as follows:
```python
with tf.variable_scope(""my_variable_scope"", reuse=tf.AUTO_REUSE):
    v = tf.get_variable(""v"", [1])
    print(v.name)
    w = tf.get_variable(""w"", [1])
    print(w.name)
    b = w + 1
    c = w + 1
    print(b.name, c.name)

with tf.variable_scope(""my_variable_scope"", reuse=tf.AUTO_REUSE) as scope:
    scope.reuse_variables()
    v1 = tf.get_variable(""v"")
    a = v1 + 1
    print(v1.name)
    print(a.name)

with tf.variable_scope(""my_variable_scope"", reuse=tf.AUTO_REUSE) as scope:
    scope.reuse_variables()
    v1 = tf.get_variable(""v"")
    a = v1 + 1
    print(v1.name)
    print(a.name)
```
Here comes the output:
```bash
my_variable_scope/v:0
my_variable_scope/w:0
my_variable_scope/add:0 my_variable_scope/add_1:0
my_variable_scope/v:0
my_variable_scope_1/add:0
my_variable_scope/v:0
my_variable_scope_2/add:0
```
So, why my_variable_scope, my_variable_scope_1, my_variable_scope_2 are created for a. Thanks for your help."
49020,Hey there.,"We are doing a survey on globally distributed software engineering focused on open source projects. If you have some spare time we would really appreciate your response. The form takes about 10 minutes. Thanks in advance!
Survey can be found [here](https://forms.gle/N1TnifRuCYHrCY9JA)
"
49019,Cached memory for Eigen backend since TF 2.5,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  From source
- TensorFlow version (use command below): TF 2.5.0-rc3
- Python version:
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: No
- GPU model and memory: No

I have built `TF 2.5.0-rc3` from sources without MKL backend under Windows. I didn't specify `--config=mkl` in build command, so I assume Eigen backend was used during the build. Isn't it ? The full build command is:
`bazel --output_base=myPath build -c opt --copt=/arch:AVX1 //tensorflow:get_tensorflow_cc_dll_import_lib`


I know that in TF with MKL backend memory is cached. With Eigen there was not this issue, all memory after querying model was released (tested in TF2.1 and TF2.3). Now, since TF2.5 I have seen that memory is cached also for Eigen backend. Why is it so?

I have modified primitive capacity inside `MklPrimitiveFactory` template from 1024 to 4, but not all memory is released, but it indicates that MKL backend was used to build library:

```
  static inline LRUCache<MklPrimitive>& GetLRUCache() {
    static const int kCapacity = 4;  // 1024 cache capacity
    static thread_local LRUCache<MklPrimitive> lru_cache_(kCapacity);
    return lru_cache_;
  }
```
 
What is going on here? Without explicitly specyfing `--config=mkl`, MKL is choosen by default ? 

Question: how to build TF with Eigen backend with releasing all memory, without caching?



"
49017,import tensorflow throws ImportError: cannot import name 'LayerNormalization' from 'tensorflow.python.keras.layers.normalization' ,"Hey, I have been trying to get my computer to use the GPU instead of the CPU for the last 2 days. During this process, I had reinstalled TensorFlow, CUDA, cuDNN and everything that's possibly related to the problem.

Anyway, now I'm stuck with a new error. I'm not able to even import TensorFlow
![image](https://user-images.githubusercontent.com/29381705/117567669-b884c480-b0da-11eb-867e-797e0e32255a.png)
"
49016,Sparse Data support for tf.data.Dataset.from_generator API using sparse COO arrays,"**System information**
- TensorFlow version 2.4.1:


I was trying to ingest sparse data into `tf.data.Dataset` by using the `from_generator` API. Τhe example below uses `scipy.coo_matrix`. Trying that with on-prem design for Sparse Arrays which follows the COO representation I was not able to pass the

```
row = np.array([0, 3, 1, 0])
col = np.array([0, 3, 1, 2])
data = np.array([4, 5, 7, 9])
a = coo_matrix((data, (row, col)), shape=(4, 4))
return tf.data.Dataset.from_generator(
            generator=cls._generator,
            output_signature=(
                tf.SparseTensorSpec(dtype=tf.int32)
            )
            ,args=(a,),
        )
```
I was getting the following error:
```
TypeError(""Failed to convert object of type %s to Tensor. ""
TypeError: Failed to convert object of type <class 'SparseArray'> to Tensor. Contents: ....
```
Thinking that the culprit may be the `on-prem` implementation of sparse data I tried the same with `scipy.coo_matrix`

I get the same error:

```
Attempt to convert a value (<4x4 sparse matrix of type '<class 'numpy.int64'>' with 4 stored elements in COOrdinate format>) with an unsupported type (<class 'scipy.sparse.coo.coo_matrix'>) to a Tensor.
```

After some debugging I saw that the error comes from the evaluation of the arguments of generator function, Which makes sense since in the docs here clearly states that the args should be `tf.Tensors`.

https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator

```
args | (Optional.) A tuple of tf.Tensor objects that will be evaluated and passed to generator as NumPy-array arguments.
```

However after the introduction of `SparseTensors` and `SparseTensorSpec` I'm not sure if it's just me, but when I read this part of the documentation I was under the impression that these `scipy.coo_matrix` would be translated into `SparseTensors` or at least to` index, value` Numpy-arrays by exploiting the `data, row, col` attr of the COO sparse format (e.g. `scipy.coo_matrix`), especially since `tf.SparseTensors` uses the same COO format. Is there any walk-around on how someone can ingest sparse data using from_generator? Is there any formal way that I am not aware? I think it would make sense to support it as a feature if it is not currently supported

**I think it would make sense to support it as a feature if it is not currently supported. There might be alternatives but getting batches of sparse data without having to transform them into dense representation and lose memory efficiency of them I think can be critical in some implementations.**

**I commented also on an old open issue https://github.com/tensorflow/tensorflow/issues/44565 but I thought that it might be better if I set it as a separate one.**"
49015,"@mitramir55 please open a new issue, fill in issue template and provide minimal code to reproduce. It's likely you have some dependency issue / some wrong version of TF installed. `pip list` should also help in identifying the issue","@mitramir55 please open a new issue, fill in the issue template and provide minimal code to reproduce. It's likely you have some dependency issue / some wrong version of TF installed. `pip list` should also help in identifying the issue

_Originally posted by @mihaimaruseac in https://github.com/tensorflow/tensorflow/issues/31315#issuecomment-643346367_

I have checked the version too still the same issue. Attribute error: TensorFlow has no attribute "
49014,MultiWorkerMirroredStrategy for multiple gpus on a worker,could tensorflow provide official examples for MultiWorkerMirroredStrategy for multiple gpus on a worker.
49013,E: Failed to stat /var/lib/apt/lists/partial/developer.download.nvidia.com_compute_cuda_repos_ntu1604_x86%5f64_Packages - pkgAcqTransactionItem::TransactionState-stat (2: No such file or directory),"
https://www.tensorflow.org/install/gpu?hl=ur#ubuntu_1604_cuda_110

On 5th step

```
sudo add-apt-repository ""deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/ /""
sudo apt-get update
```

```
Hit:1 http://ru.archive.ubuntu.com/ubuntu xenial InRelease
Hit:2 http://ru.archive.ubuntu.com/ubuntu xenial-updates InRelease                                                                                     
Hit:3 http://ru.archive.ubuntu.com/ubuntu xenial-backports InRelease                                                                                   
Hit:4 http://linux.teamviewer.com/deb stable InRelease                                                                                                 
Ign:5 http://dl.google.com/linux/chrome-remote-desktop/deb stable InRelease                                                                            
Hit:6 http://dl.google.com/linux/chrome-remote-desktop/deb stable Release                                                                              
Hit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu xenial InRelease                                                                                  
Hit:8 http://deb.anydesk.com all InRelease                                                                                                             
Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu xenial InRelease                                                                           
Ign:10 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease                                                           
Hit:11 http://security.ubuntu.com/ubuntu xenial-security InRelease      
Hit:12 https://deb.nodesource.com/node_12.x xenial InRelease            
Hit:13 https://apt.syncthing.net syncthing InRelease
Ign:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease
Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release.gpg [836 B]
Ign:17 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease
Get:19 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release [697 B]
Hit:20 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release
Get:21 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release.gpg [836 B]
Ign:23 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages
Get:23 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages [687 kB]
Ign:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages
Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages [687 kB]
Fetched 1 375 kB in 2s (619 kB/s) 
Reading package lists... Done
E: Failed to stat /var/lib/apt/lists/partial/developer.download.nvidia.com_compute_cuda_repos_ubuntu1604_x86%5f64_Packages - pkgAcqTransactionItem::TransactionState-stat (2: No such file or directory)
W: Duplicate sources.list entry http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release
```"
49012,MobileBert inference with TFlite GPU delegate,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version: (2.6.0)
- Are you willing to contribute it: (No)



**Describe the feature and the current behavior/state.**

**Requested feature**: Add support for [mobilebert](https://tfhub.dev/tensorflow/lite-model/mobilebert/1/metadata/1) model/operations in [TFlite GPU delegate](https://www.tensorflow.org/lite/performance/gpu)


**Current behaviour**: I'm trying to use the TFlite GPU delegate for mobilbert TFlite model inference. I'm using [TFlite benchmark tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark), with the GPU delegate enabled, to run the model. The inference automatically goes to the CPU backend with the following Info/Error:

```
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: tensorflow/lite/core/subgraph.cc:1169 node_index >= 0 was not true.
ERROR: Couldn't get node and registration info for op: -1793924896

INFO: Created 0 GPU delegate kernels.
Though GPU delegate is explicitly applied, the model graph will not be executed by the delegate.

```
and then continues to run on the CPU.

I'm not sure what this error means. I know that the TFlite GPU delegate only supports a handful of [models and operations](https://www.tensorflow.org/lite/performance/gpu#supported_models_and_ops). So I guess it is a support issue. However, the error does not seem to me a support issue because, I should have just received a warning as described [here](https://www.tensorflow.org/lite/performance/gpu#non-supported_models_and_ops) reporting the unsupported Ops.

I could not understand what node_index means and what makes it positive or negative.

Since the supported models runs perfectly with no errors , I speculated that it's a support issue.




**Will this change the current api? How?**
Not sure

**Who will benefit with this feature?**
Who is interested in accelerating BERT on mobile GPUs

**Any Other info.**
"
49011,tflite int8 12x times slower than float32,"Please check this colab to reproduce for huggingface gpt2 model

https://colab.research.google.com/drive/1DNTPR_GgidU8Jve0zoDI1MfoqWQ0L06n?usp=sharing
"
49007,Order of resampled dataset is wrong,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.1


**Describe the current behavior**

I am using `tf.data.experimental.sample_from_datasets()` to balance a dataset. Now, I am creating two data loaders out of the resampled dataset and then zipping them up.  When I am iterating through the zipped dataset the images are coming in different orders. 

Let's walk this through step by step:

**Data**

```python
(x_train, y_train), (_, _) = tf.keras.datasets.cifar10.load_data()
sampled_idx = np.random.choice(len(x_train), 4000)
sampled_train, sampled_labels = x_train[sampled_idx], y_train[sampled_idx].squeeze()
support_ds = tf.data.Dataset.from_tensor_slices((sampled_train, sampled_labels))
```

**Utilities**

```python
def support_sampler(ds):
    ds_list = []
    for i in np.arange(0, 10):
        ds_label = ds.filter(lambda image, label: label == i).repeat()
        ds_list.append(ds_label)
    return ds_list

def get_support_ds(ds, bs=640):
    listed_ds = support_sampler(ds)
    balanced_ds = tf.data.experimental.sample_from_datasets(listed_ds, [0.1] * 10)

    loaders = tuple()
    for _ in range(2):
        loaders += (balanced_ds, )

    final_ds = tf.data.Dataset.zip(loaders)
    return final_ds.batch(bs)
```

**Issue verification**

Get a sample batch first:

```python
sample_support_ds = get_support_ds(support_ds)
support_images_one, support_images_two = next(iter(sample_support_ds))
```

**Plot the images from `support_images_one`**

```python
plt.figure(figsize=(7, 7))
for i, image in enumerate(support_images_one[0][:9]):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(image.numpy().astype(""int""))
    plt.title(int(support_images_one[1][i]))
    plt.axis(""off"")
```

Gives:

![image](https://user-images.githubusercontent.com/22957388/117529164-a54af980-aff3-11eb-9c8e-8e1312c2c38c.png)

The same thing with `support_images_two[0][:9]` (with the labels printed accordingly):

![image](https://user-images.githubusercontent.com/22957388/117529176-be53aa80-aff3-11eb-8c6f-2792b60b3bdb.png)


**Describe the expected behavior**

The image batches should be the same.

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): No

**Standalone code to reproduce the issue**

[Colab Notebook](https://colab.research.google.com/gist/sayakpaul/7e003afbd3714549d6ecb0f39b6b81b4/scratchpad.ipynb)
"
49001,What is the specific operation process of the tf.stop.gradient？,"What is the specific implementation process of the tf.stop.gradient？

My code is:

def round_through(x):
    '''Element-wise rounding to the closest integer with full gradient propagation.
    A trick from [Sergey Ioffe](http://stackoverflow.com/a/36480182)
    a op that behave as f(x) in forward mode,
    but as g(x) in the backward mode.
    '''
    rounded = tf.round(x)
    return x + tf.stop_gradient(rounded-x)

I want to know the specific operation process of stop gradient and the operational formula of stop gradient.

Thank you very much.
"
49000,"Random rotation, flip, translation, and zoom for 3D data? ","Does TF have any plan to support 3D random transform layers? or why not? Or is there already an experimental version or some other contributions on github related to this? Thanks
"
48999,num_parallel_calls= for tf.data map(),"I was playing with different numbers for num_parallel_calls= for map(), however I can hardly get CPU usage above 400%. I am on a DGX-1, so there are 40 CPU cores. I used a very big prefetch number. Ideally if CPU is saturated, I should see ~4000% usage. Just wondering if I need to configure other parameters. I don't know how TF implements num_parallel_calls. I tried setting OMP_NUM_THREADS=40, but this setting doesn't work. 
"
48987,python': double free or corruption (!prev): 0x0000556f555937e0 ***,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](INFO:tensorflow:Reading data files from /home/lyg/data/tmp/t2t/data/protein_specific_ligand_generation-train*
I0507 22:41:25.676374 140279178368768 problem.py:653] Reading data files from /home/lyg/data/tmp/t2t/data/protein_specific_ligand_generation-train*
*** Error in `/home/lyg/anaconda3/envs/tf/bin/python': double free or corruption (!prev): 0x0000556f555937e0 ***
======= Backtrace: =========
/lib64/libc.so.6(+0x38f107956e)[0x7f954a23756e]
/lib64/libc.so.6(+0x38f1079d0f)[0x7f954a237d0f]
/lib64/ld-linux-x86-64.so.2(_dl_deallocate_tls+0x57)[0x7f954a7a1b37]
/lib64/libpthread.so.0(+0x38f1806266)[0x7f954a579266]
/lib64/libpthread.so.0(+0x38f180638a)[0x7f954a57938a]
/lib64/libpthread.so.0(pthread_join+0xc4)[0x7f954a57b264]
/home/lyg/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2(+0x10b7c01)[0x7f94cdc97c01]
/home/lyg/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2(_ZN10tensorflow6thread10ThreadPoolD1Ev+0x204)[0x7f94cdcacfd4]
/home/lyg/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2(_ZN10tensorflow8internal16GetMatchingPathsEPNS_10FileSystemEPNS_3EnvERKSsPSt6vectorISsSaISsEE+0x641)[0x7f94cdcaa061]
/home/lyg/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2(_ZN10tensorflow15PosixFileSystem16GetMatchingPathsERKSsPSt6vectorISsSaISsEE+0x30)[0x7f94cdc9d120]
/home/lyg/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2(_ZN10tensorflow3Env16GetMatchingPathsERKSsPSt6vectorISsSaISsEE+0x40)[0x7f94cdca07e0]
/home/lyg/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/_pywrap_file_io.so(+0x2118e)[0x7f94c9f8318e]
/home/lyg/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/_pywrap_file_io.so(+0x1cb89)[0x7f94c9f7eb89]
/home/lyg/anaconda3/envs/tf/bin/python(_PyMethodDef_RawFastCallKeywords+0x264)[0x556f54be68b4]
/home/lyg/anaconda3/envs/tf/bin/python(_PyCFunction_FastCallKeywords+0x21)[0x556f54be69d1]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x4e0a)[0x556f54c52e5a]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x416)[0x556f54c4e466]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x4a99)[0x556f54c52ae9]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x4a99)[0x556f54c52ae9]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalCodeWithName+0xc30)[0x556f54b96640]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallDict+0x3ff)[0x556f54b9701f]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x1e47)[0x556f54c4fe97]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalCodeWithName+0x5da)[0x556f54b95fea]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallDict+0x3ff)[0x556f54b9701f]
/home/lyg/anaconda3/envs/tf/bin/python(_PyObject_Call_Prepend+0x63)[0x556f54bb57a3]
/home/lyg/anaconda3/envs/tf/bin/python(PyObject_Call+0x6e)[0x556f54ba83ae]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x1e47)[0x556f54c4fe97]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalCodeWithName+0x2f9)[0x556f54b95d09]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0x387)[0x556f54be60b7]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x14e9)[0x556f54c4f539]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalCodeWithName+0xc30)[0x556f54b96640]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallDict+0x3ff)[0x556f54b9701f]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x1e47)[0x556f54c4fe97]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalCodeWithName+0x2f9)[0x556f54b95d09]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0x325)[0x556f54be6055]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x6a0)[0x556f54c4e6f0]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x6a0)[0x556f54c4e6f0]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x6a0)[0x556f54c4e6f0]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x6a0)[0x556f54c4e6f0]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalCodeWithName+0x2f9)[0x556f54b95d09]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0x387)[0x556f54be60b7]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x14e9)[0x556f54c4f539]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x6a0)[0x556f54c4e6f0]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalCodeWithName+0xc30)[0x556f54b96640]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0x387)[0x556f54be60b7]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x6a0)[0x556f54c4e6f0]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x4a99)[0x556f54c52ae9]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalCodeWithName+0x2f9)[0x556f54b95d09]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0x325)[0x556f54be6055]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x416)[0x556f54c4e466]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x416)[0x556f54c4e466]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]
/home/lyg/anaconda3/envs/tf/bin/python(_PyEval_EvalFrameDefault+0x4a99)[0x556f54c52ae9]
/home/lyg/anaconda3/envs/tf/bin/python(_PyFunction_FastCallKeywords+0xfb)[0x556f54be5e2b]https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48973,save and load specific keras/tensorflow layers,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
extract layer of one model with weights and use in another model. For example, using an embedding layer weights of one transformer model in another transformer model. Compared to glove embeddings and word2vec embeddings, it's difficult to map the embedding weights of a transformer.

**Will this change the current api? How?**
Most probably no.

**Who will benefit with this feature?**
those who need to export only embeddings layer (or any other layer) and use in another model.

**Any Other info.**
"
48967,Get HLO PROTO from TF (in python),"Hi,

I'm using `experimental_get_compiler_ir` to extract the HLO-IR of functions written in TF2. 
However, hitting some issues and was wondering if there is an API from TF, that exposes the proto format, something similar to what `JAX` does like here:
[xla_computation](https://jax.readthedocs.io/en/latest/jax.html#jax.xla_computation
) with the `as_serialized_hlo_module_proto`. 

There is probably a better way to go from TF code (in python) to HLO PROTO, but even when I'm using `experimental_get_compiler_ir`, maybe you could just allow this function to not serialize the result:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/jit/get_compiler_ir.cc#L136

Thanks!
"
48966,Compilation time regression: 4 straglers,"With TF container: tensorflow/tensorflow:devel-gpu  and this commit:

commit 38dc3cc0278a0e91247c872799e2c49bce831bb2 (HEAD -> master, origin/master, origin/HEAD)
Author: Adrian Kuegel <akuegel@google.com>
Date:   Tue May 4 03:35:01 2021 -0700

    Add MLIR generated Relu kernel.

    It is still disabled by default.

    PiperOrigin-RevId: 371881143
    Change-Id: I1216d77978cf6d1b9e128ef63bc0d52b5c55a3e2

We have 4 new compilation stragler. I still haven't finished compiling, but 4 rules are taking over 1h to compile...

```
[41,044 / 41,048] 4 actions running
    Executing genrule //tensorflow/lite/python/testdata:permute_float; 3615s local
    Executing genrule //tensorflow/lite/python/testdata:gather_string; 3615s local
    Executing genrule //tensorflow/lite/python/testdata:permute_uint8; 3615s local
    Executing genrule //tensorflow/lite/python/testdata:gather_string_0d; 3615s local
```

Full repro steps:
The command used to compile:
```
docker run --gpus=all -it tensorflow/tensorflow:devel-gpu /bin/bash
cd /tensorflow_src
bazel build -c opt --config cuda //tensorflow/tools/pip_package:build_pip_package
```"
48965,Keras model.fit takes long until training begins when sample_weight is provided,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.10
- CUDA/cuDNN version: 11.0
- GPU model and memory: 1080 Ti 12 GB

(+ also on colab)

**Describe the current behavior**
Fit function of keras Model class takes long to begin with the training when sample_weight is provided.
I already recognized the following:
- In the backend, the method `training_utils.handle_partial_sample_weights` is used which should not be necessary because the length of my samples corresponds to the length of my labels.
- It looks like that the statement `any(w is None for w in sample_weights)` takes very long. If I execute this with on my sample_weight numpy array, this only takes 154 ms. But could it be that sample_weight is transformed into a Tensor before that operation and it therefore takes that long?

**Describe the expected behavior**
It should not have a huge impact on the runtime if sample_weight are provided.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1Q5pTFK56AlhYAXNzlRLX--oOceQJc58_?usp=sharing
"
48964,Grappler does not fuse kernels in simple GELU implementation,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.3.1
- Python version: 3.6.6
- CUDA/cuDNN version: CUDA 10.1
- GPU model and memory: V100 16GB


**Describe the current behavior**

Running the GELU example below in both graph and eager mode seems to result in the same kernel GPU kernel launches. Using nvprof and NVIDIA Visual Profiler reveals 5 kernel launches in each case:

3x eigen::internal::scalar_product_op
1x eigen::internal::1x scalar_pow_op
1x eigen::internal::1x scalar_sum_op

**Describe the expected behavior**

From reading https://www.tensorflow.org/guide/graph_optimization and the Stanford slides here http://web.stanford.edu/class/cs245/slides/TFGraphOptimizationsStanford.pdf, I was expecting Grappler to fuse some of these operations in the graph mode case.

It would be great to understand either why this does not happen in this case and exactly what kinds of operations can be fused with Grappler, or alternatively what else needs to be done to achieve this behaviour with Grappler.

**Standalone code to reproduce the issue**

```
import timeit
import math
import contextlib
import os

os.environ[""CUDA_VISIBLE_DEVICES""] = ""1""

import tensorflow as tf
import cupy


@contextlib.contextmanager
def options(options):
    old_opts = tf.config.optimizer.get_experimental_options()
    tf.config.optimizer.set_experimental_options(options)
    try:
        yield
    finally:
        tf.config.optimizer.set_experimental_options(old_opts)


def _gelu(x):
    constant = tf.constant(0.5 * (1 + math.tanh(math.sqrt(2 / math.pi))))
    x_cubed = tf.pow(x, 3, name=""x_cubed"")
    return tf.multiply(constant * x, tf.add(x, 0.044715 * x_cubed), name=""gelu"")


def gelu_graph(x):
    @tf.function
    def gelu(x):
        return _gelu(x)

    return gelu(x)


def gelu_eager(x):
    def gelu(x):
        return _gelu(x)

    return gelu(x)


# with options({'min_graph_nodes': 1}):
print(tf.config.optimizer.get_experimental_options())

x = tf.random.uniform((int(1e6), 128))

# with cupy.cuda.profile(): 
print(""Graph execution:"", timeit.timeit(lambda: gelu_graph(x), number=100), ""s"")

print(""Eager execution:"", timeit.timeit(lambda: gelu_eager(x), number=100), ""s"")
```
"
48963,recipe for target 'CMakeFiles/tensorflow-lite.dir/all' failed     issue while cross-compile tflite.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution : Linux Ubuntu 16:


- TensorFlow  Lite version--Latest:
- Python version:3.7





**Describe the problem**

Hi I am new to tensorflow. I try to cross-compile and generate the python wheel for  the tensorflow-lite for aarch64. i followed the steps which given in the official tensorflow-lite website. https://www.tensorflow.org/lite/guide/build_cmake_pip. But I cannot able to cross compile it. 

The steps which I follow:
1. Git clone the tensorflow source code.
2. Execute the below command from the tensorflow src folder.

**tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \
  tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh aarch64**
 
Then the program execute with some following error.

**Any other info / logs**

CMakeFiles/Makefile2:1139: recipe for target 'CMakeFiles/tensorflow-lite.dir/all' failed
make[2]: *** [CMakeFiles/tensorflow-lite.dir/all] Error 2
make[2]: Leaving directory '/workspace/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.7/cmake_build'
CMakeFiles/Makefile2:1247: recipe for target 'CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule' failed
make[1]: *** [CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule] Error 2
make[1]: Leaving directory '/workspace/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.7/cmake_build'
Makefile:215: recipe for target '_pywrap_tensorflow_interpreter_wrapper' failed
make: *** [_pywrap_tensorflow_interpreter_wrapper] Error 2

 
"
48961,GlobalAveragePooling1D does not work with a mask when mixed precision policy is set.,"**System information**
- OS: colab (Ubuntu 18.04.5)
- TensorFlow installed from : pre-installed in colab
- TensorFlow version: 2.4.1
- Python version: 3.7.10
- GPU model and memory: Tesla K80, 12GB

**Describe the current behavior**
When setting the mixed precision policy and using a `GlobalAveragePooling1D` layer with a mask, the mask is wrongly cast with `backend.floatx()` (=`float32` even with mixed precision) and this raises an issue of un-matching types for the forward pass.

**Describe the expected behavior**
We can use `GlobalAveragePooling1D` with a mask and mixed precision set.

**[Contributing](https://www.tensorflow.org/community/contribute)** 
- Do you want to contribute a PR? Yes
- Briefly describe your candidate solution:
in `GlobalAveragePooling1D::call()` (/tensorflow/python/keras/layers/pooling.py::L795): `mask = math_ops.cast(mask, inputs.dtype)`

**Standalone code to reproduce the issue**
```
from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy('mixed_float16')

inputs1 = keras.Input(shape=(36, 512), name='digits', dtype=""float16"")
inputs2 = keras.Input(shape=(36,), name='digits', dtype=""bool"")
average_layer = layers.GlobalAveragePooling1D()
x = average_layer(inputs1, inputs2)
```

This yields the issue. Setting `tf.keras.backend.set_floatx('float16')` solves the issue, but this might be better to directly cast the `mask` to `inputs.dtype` in `GlobalAveragePooling1D::call()`
```
def call(self, inputs, mask=None):
    steps_axis = 1 if self.data_format == 'channels_last' else 2
    if mask is not None:
      mask = math_ops.cast(mask, backend.floatx())
      mask = array_ops.expand_dims(
          mask, 2 if self.data_format == 'channels_last' else 1)
      inputs *= mask
      return backend.sum(inputs, axis=steps_axis) / math_ops.reduce_sum(
          mask, axis=steps_axis)
    else:
      return backend.mean(inputs, axis=steps_axis)
```



**Other info / logs** 
Error trace:
```
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/pooling.py in call(self, inputs, mask)
    796       mask = array_ops.expand_dims(
    797           mask, 2 if self.data_format == 'channels_last' else 1)
--> 798       inputs *= mask
    799       return backend.sum(inputs, axis=steps_axis) / math_ops.reduce_sum(
    800           mask, axis=steps_axis)
...
TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.
```
"
48960,Both pip and conda versions of numpy and six required to load tensorflow 2.4.1?,"I am running tensorflow 2.4.1 in a conda environment using Python 3.8.8 on a Windows 10 x64 system.  GPU support is working.  My conda channel setup is:

```
> conda config --env --show channels
channels:
      - conda-forge
      - defaults
> conda config --env --show channel_priority
channel_priority: flexible
```

I installed tensorflow and related packages using pip:

> pip install tensorflow tensorflow_io python-dotenv

I don't really know if python-dotenv is needed here, but I heard that it was.  (?????)

I also have several conda-forge packages installed, such as pandas, scikit-learn, matplotlib, ipympl, seaborn, jupyterlab, notebook, nodejs, and scipy.

Here is a list of packages in the env:

```
> conda list
# packages in environment at C:\Users\me\Miniconda3\envs\tf38:
#
# Name                    Version                   Build  Channel
absl-py                   0.12.0                   pypi_0    pypi
anyio                     2.2.0            py38haa244fe_0    conda-forge
argon2-cffi               20.1.0           py38h294d835_2    conda-forge
astunparse                1.6.3                    pypi_0    pypi
async_generator           1.10                       py_0    conda-forge
attrs                     21.2.0             pyhd8ed1ab_0    conda-forge
babel                     2.9.1              pyh44b312d_0    conda-forge
backcall                  0.2.0              pyh9f0ad1d_0    conda-forge
backports                 1.0                        py_2    conda-forge
backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge
bleach                    3.3.0              pyh44b312d_0    conda-forge
brotlipy                  0.7.0           py38h294d835_1001    conda-forge
ca-certificates           2020.12.5            h5b45459_0    conda-forge
cachetools                4.2.2                    pypi_0    pypi
certifi                   2020.12.5        py38haa244fe_1    conda-forge
cffi                      1.14.5           py38hd8c33c5_0    conda-forge
chardet                   4.0.0            py38haa244fe_1    conda-forge
colorama                  0.4.4              pyh9f0ad1d_0    conda-forge
cryptography              3.4.7            py38hd7da0ea_0    conda-forge
cycler                    0.10.0                     py_2    conda-forge
decorator                 5.0.7              pyhd8ed1ab_0    conda-forge
defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge
deprecation               2.1.0              pyh9f0ad1d_0    conda-forge
entrypoints               0.3             pyhd8ed1ab_1003    conda-forge
flatbuffers               1.12                     pypi_0    pypi
freetype                  2.10.4               h546665d_1    conda-forge
gast                      0.3.3                    pypi_0    pypi
google-auth               1.30.0                   pypi_0    pypi
google-auth-oauthlib      0.4.4                    pypi_0    pypi
google-pasta              0.2.0                    pypi_0    pypi
grpcio                    1.32.0                   pypi_0    pypi
h5py                      2.10.0                   pypi_0    pypi
icu                       68.1                 h0e60522_0    conda-forge
idna                      2.10               pyh9f0ad1d_0    conda-forge
importlib-metadata        4.0.1            py38haa244fe_0    conda-forge
intel-openmp              2021.2.0           h57928b3_616    conda-forge
ipykernel                 5.5.4            py38h43734a8_0    conda-forge
ipympl                    0.7.0              pyhd8ed1ab_0    conda-forge
ipython                   7.23.1           py38h43734a8_0    conda-forge
ipython_genutils          0.2.0                      py_1    conda-forge
ipywidgets                7.6.3              pyhd3deb0d_0    conda-forge
jedi                      0.18.0           py38haa244fe_2    conda-forge
jinja2                    2.11.3             pyh44b312d_0    conda-forge
joblib                    1.0.1              pyhd8ed1ab_0    conda-forge
jpeg                      9d                   h8ffe710_0    conda-forge
json5                     0.9.5              pyh9f0ad1d_0    conda-forge
jsonschema                3.2.0              pyhd8ed1ab_3    conda-forge
jupyter-packaging         0.10.1             pyhd8ed1ab_0    conda-forge
jupyter_client            6.1.12             pyhd8ed1ab_0    conda-forge
jupyter_core              4.7.1            py38haa244fe_0    conda-forge
jupyter_server            1.6.4            py38haa244fe_0    conda-forge
jupyterlab                3.0.14             pyhd8ed1ab_0    conda-forge
jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge
jupyterlab_server         2.5.0              pyhd8ed1ab_0    conda-forge
jupyterlab_widgets        1.0.0              pyhd8ed1ab_1    conda-forge
keras-preprocessing       1.1.2                    pypi_0    pypi
kiwisolver                1.3.1            py38hbd9d945_1    conda-forge
lcms2                     2.12                 h2a16943_0    conda-forge
libblas                   3.9.0                     9_mkl    conda-forge
libcblas                  3.9.0                     9_mkl    conda-forge
libclang                  11.1.0          default_h5c34c98_0    conda-forge
liblapack                 3.9.0                     9_mkl    conda-forge
libpng                    1.6.37               h1d00b33_2    conda-forge
libsodium                 1.0.18               h8d14728_1    conda-forge
libtiff                   4.2.0                hc10be44_1    conda-forge
lz4-c                     1.9.3                h8ffe710_0    conda-forge
m2w64-gcc-libgfortran     5.3.0                         6    conda-forge
m2w64-gcc-libs            5.3.0                         7    conda-forge
m2w64-gcc-libs-core       5.3.0                         7    conda-forge
m2w64-gmp                 6.1.0                         2    conda-forge
m2w64-libwinpthread-git   5.0.0.4634.697f757               2    conda-forge
markdown                  3.3.4                    pypi_0    pypi
markupsafe                1.1.1            py38h294d835_3    conda-forge
matplotlib                3.4.1            py38haa244fe_0    conda-forge
matplotlib-base           3.4.1            py38heae8d8c_0    conda-forge
matplotlib-inline         0.1.2              pyhd8ed1ab_2    conda-forge
mistune                   0.8.4           py38h294d835_1003    conda-forge
mkl                       2021.2.0           hb70f87d_389    conda-forge
msys2-conda-epoch         20160418                      1    conda-forge
nbclassic                 0.2.7              pyhd8ed1ab_0    conda-forge
nbclient                  0.5.3              pyhd8ed1ab_0    conda-forge
nbconvert                 6.0.7            py38haa244fe_3    conda-forge
nbformat                  5.1.3              pyhd8ed1ab_0    conda-forge
nest-asyncio              1.5.1              pyhd8ed1ab_0    conda-forge
nodejs                    15.14.0              h57928b3_0    conda-forge
notebook                  6.3.0              pyha770c72_1    conda-forge
numpy                     1.19.5                   pypi_0    pypi
oauthlib                  3.1.0                    pypi_0    pypi
olefile                   0.46               pyh9f0ad1d_1    conda-forge
openjpeg                  2.4.0                h48faf41_0    conda-forge
openssl                   1.1.1k               h8ffe710_0    conda-forge
opt-einsum                3.3.0                    pypi_0    pypi
packaging                 20.9               pyh44b312d_0    conda-forge
pandas                    1.2.4            py38h60cbd38_0    conda-forge
pandoc                    2.13                 h8ffe710_0    conda-forge
pandocfilters             1.4.2                      py_1    conda-forge
parso                     0.8.2              pyhd8ed1ab_0    conda-forge
patsy                     0.5.1                      py_0    conda-forge
pickleshare               0.7.5                   py_1003    conda-forge
pillow                    8.2.0                    pypi_0    pypi
pip                       21.1.1             pyhd8ed1ab_0    conda-forge
prometheus_client         0.10.1             pyhd8ed1ab_0    conda-forge
prompt-toolkit            3.0.18             pyha770c72_0    conda-forge
protobuf                  3.15.8                   pypi_0    pypi
pyasn1                    0.4.8                    pypi_0    pypi
pyasn1-modules            0.2.8                    pypi_0    pypi
pycparser                 2.20               pyh9f0ad1d_2    conda-forge
pygments                  2.9.0              pyhd8ed1ab_0    conda-forge
pyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge
pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge
pyqt                      5.12.3           py38haa244fe_7    conda-forge
pyqt-impl                 5.12.3           py38h885f38d_7    conda-forge
pyqt5-sip                 4.19.18          py38h885f38d_7    conda-forge
pyqtchart                 5.12             py38h885f38d_7    conda-forge
pyqtwebengine             5.12.1           py38h885f38d_7    conda-forge
pyrsistent                0.17.3           py38h294d835_2    conda-forge
pysocks                   1.7.1            py38haa244fe_3    conda-forge
python                    3.8.8           h7840368_0_cpython    conda-forge
python-dateutil           2.8.1                      py_0    conda-forge
python-dotenv             0.17.1                   pypi_0    pypi
python_abi                3.8                      1_cp38    conda-forge
pytz                      2021.1             pyhd8ed1ab_0    conda-forge
pywin32                   300              py38h294d835_0    conda-forge
pywinpty                  1.0.1            py38hd3f51b4_0    conda-forge
pyzmq                     22.0.3           py38h09162b1_1    conda-forge
qt                        5.12.9               h5909a2a_4    conda-forge
requests                  2.25.1             pyhd3deb0d_0    conda-forge
requests-oauthlib         1.3.0                    pypi_0    pypi
rsa                       4.7.2                    pypi_0    pypi
scikit-learn              0.24.2           py38h5d5d464_0    conda-forge
scipy                     1.6.3            py38he847743_0    conda-forge
seaborn                   0.11.1               hd8ed1ab_1    conda-forge
seaborn-base              0.11.1             pyhd8ed1ab_1    conda-forge
send2trash                1.5.0                      py_0    conda-forge
setuptools                49.6.0           py38haa244fe_3    conda-forge
six                       1.15.0                   pypi_0    pypi
sniffio                   1.2.0            py38haa244fe_1    conda-forge
sqlite                    3.35.5               h8ffe710_0    conda-forge
statsmodels               0.12.2           py38h347fdf6_0    conda-forge
tbb                       2021.2.0             h2d74725_0    conda-forge
tensorboard               2.5.0                    pypi_0    pypi
tensorboard-data-server   0.6.0                    pypi_0    pypi
tensorboard-plugin-wit    1.8.0                    pypi_0    pypi
tensorflow                2.4.1                    pypi_0    pypi
tensorflow-estimator      2.4.0                    pypi_0    pypi
tensorflow-io             0.17.1                   pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
terminado                 0.9.4            py38haa244fe_0    conda-forge
testpath                  0.4.4                      py_0    conda-forge
threadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge
tk                        8.6.10               h8ffe710_1    conda-forge
tomlkit                   0.7.0            py38haa244fe_3    conda-forge
tornado                   6.1              py38h294d835_1    conda-forge
traitlets                 5.0.5                      py_0    conda-forge
typing-extensions         3.7.4.3                  pypi_0    pypi
urllib3                   1.26.4             pyhd8ed1ab_0    conda-forge
vc                        14.2                 hb210afc_4    conda-forge
vs2015_runtime            14.28.29325          h5e1d092_4    conda-forge
wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge
webencodings              0.5.1                      py_1    conda-forge
werkzeug                  1.0.1                    pypi_0    pypi
wheel                     0.36.2             pyhd3deb0d_0    conda-forge
widgetsnbextension        3.5.1            py38haa244fe_4    conda-forge
win_inet_pton             1.1.0            py38haa244fe_2    conda-forge
wincertstore              0.2             py38haa244fe_1006    conda-forge
winpty                    0.4.3                         4    conda-forge
wrapt                     1.12.1                   pypi_0    pypi
xlrd                      2.0.1              pyhd8ed1ab_3    conda-forge
xz                        5.2.5                h62dcd97_1    conda-forge
zeromq                    4.3.4                h0e60522_0    conda-forge
zipp                      3.4.1              pyhd8ed1ab_0    conda-forge
zlib                      1.2.11            h62dcd97_1010    conda-forge
zstd                      1.4.9                h6255e5f_0    conda-forge
```

**Problem:**

When I update tensorflow using this command:

`pip install --upgrade tensorflow tensorflow_io python-dotenv`

the upgrade works, but pip removes conda numpy and six and replaces them with PyPi (pip) versions.  After that, tensorflow will not load in a Jupyter notebook, throwing this error:

```
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
<ipython-input-2-ac1231bd92eb> in <module>
----> 1 import tensorflow as tf
      2 print(tf.__version__)
      3 # tf 2.4.1 used in course

~\Miniconda3\envs\tf38\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\Miniconda3\envs\tf38\lib\site-packages\tensorflow\python\__init__.py in <module>
     46 from tensorflow.python import data
     47 from tensorflow.python import distribute
---> 48 from tensorflow.python import keras
     49 from tensorflow.python.feature_column import feature_column_lib as feature_column
     50 from tensorflow.python.layers import layers

~\Miniconda3\envs\tf38\lib\site-packages\tensorflow\python\keras\__init__.py in <module>
     25 
     26 # See b/110718070#comment18 for more details about this import.
---> 27 from tensorflow.python.keras import models
     28 
     29 from tensorflow.python.keras.engine.input_layer import Input

~\Miniconda3\envs\tf38\lib\site-packages\tensorflow\python\keras\models.py in <module>
     24 from tensorflow.python.keras import metrics as metrics_module
     25 from tensorflow.python.keras import optimizer_v1
---> 26 from tensorflow.python.keras.engine import functional
     27 from tensorflow.python.keras.engine import sequential
     28 from tensorflow.python.keras.engine import training

~\Miniconda3\envs\tf38\lib\site-packages\tensorflow\python\keras\engine\functional.py in <module>
     36 from tensorflow.python.keras.engine import keras_tensor
     37 from tensorflow.python.keras.engine import node as node_module
---> 38 from tensorflow.python.keras.engine import training as training_lib
     39 from tensorflow.python.keras.engine import training_utils
     40 from tensorflow.python.keras.saving.saved_model import network_serialization

~\Miniconda3\envs\tf38\lib\site-packages\tensorflow\python\keras\engine\training.py in <module>
     50 from tensorflow.python.keras.engine import base_layer_utils
     51 from tensorflow.python.keras.engine import compile_utils
---> 52 from tensorflow.python.keras.engine import data_adapter
     53 from tensorflow.python.keras.engine import training_utils
     54 from tensorflow.python.keras.mixed_precision import loss_scale_optimizer as lso

~\Miniconda3\envs\tf38\lib\site-packages\tensorflow\python\keras\engine\data_adapter.py in <module>
     59 
     60 try:
---> 61   from scipy import sparse as scipy_sparse  # pylint: disable=g-import-not-at-top
     62 except ImportError:
     63   scipy_sparse = None

~\Miniconda3\envs\tf38\lib\site-packages\scipy\__init__.py in <module>
    128 
    129     # Allow distributors to run custom init code
--> 130     from . import _distributor_init
    131 
    132     from scipy._lib import _pep440

~\Miniconda3\envs\tf38\lib\site-packages\scipy\_distributor_init.py in <module>
     57             os.chdir(libs_path)
     58             for filename in glob.glob(os.path.join(libs_path, '*dll')):
---> 59                 WinDLL(os.path.abspath(filename))
     60         finally:
     61             os.chdir(owd)

~\Miniconda3\envs\tf38\lib\ctypes\__init__.py in __init__(self, name, mode, handle, use_errno, use_last_error, winmode)
    371 
    372         if handle is None:
--> 373             self._handle = _dlopen(self._name, mode)
    374         else:
    375             self._handle = handle

FileNotFoundError: Could not find module 'C:\Users\me\Miniconda3\envs\tf38\lib\site-packages\scipy\.libs\libbanded5x.EHDKC2XVYTQQ5MALRS6XN2CUSS6SRL6P.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax.
```

The only way to fix the problem is to keep running

`conda update --all`

until conda detects package inconsistencies in the env and installs conda versions of numpy and six.  After that, tensorflow will import and run normally, and the pip version of numpy (1.19.5) shows when I list packages.  The conda version of numpy (1.20.2) does not show in 'conda list', but is apparently there, and required for tf to load and run.

**Question:**

How can I stop the package inconsistencies from happening every time I upgrade tensorflow using pip install --upgrade?

Perhaps my setup of mixed conda/pip packages is a bad idea?  I would MUCH rather avoid pip completely, but the version of tensorflow in conda pkgs/main is way outdated (2.3.0), and stopped working anyway (that is another issue: running conda tf suddenly started killing jupyter kernels).

Is there a better way to get tensorflow 2.4.1 running in a stable manner on my system?  Is there a tf install bug involved here?  Obviously tf 2.4.1 requires numpy 1.19.5.  I tried pinning the env to numpy 1.19.5, but that didn't seem to work.

Any advice would be greatly appreciated.  Thanks in advance.



"
48959,[TFLite] Fully Connected layers are not outputting accurate values with INT16 inputs of rank > 2,"**Describe the current behavior**

The Fully connected layers outputs in a TensorFlow Lite model when using INT16 acitvations are completely off when the input rank is greater than 2, but totally correct when the rank is 2. 

It seems that the computation is somehow broken when the rank >= 3.

I was able to reproduce this in TensorFlow 2.5.0-rc2 and 2.6.0-dev.


**Standalone code to reproduce the issue**

```python
import tensorflow as tf
print(tf.__version__)

class MyModel(tf.keras.Model):
    def __init__(self, squeeze=False):
        super().__init__()
        self.squeeze = squeeze
        self.dense = tf.keras.layers.Dense(5)
    
    def call(self, x):
        if self.squeeze:
            x = tf.squeeze(x)
        return self.dense(x)
    
def representative_dataset():
    for _ in range(100):
        yield [tf.random.uniform(shape=[1, 30, 5])]
   
model = MyModel(squeeze=False)
model(tf.random.uniform(shape=[1, 30, 5]))

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]

tflite_model = converter.convert()

input_ = tf.random.uniform(shape=[1, 30, 5])
output = model(input_)

interpreter = tf.lite.Interpreter(model_content=tflite_model)

interpreter.allocate_tensors()
interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_)
interpreter.invoke()
tflite_output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])

print(tf.reduce_max(tf.abs(output - tflite_output)))
```
When running this code, the output was : `tf.Tensor(2.128053, shape=(), dtype=float32)`.
I ran it multiple times and always got a value of that order.

In the next snippet, I am using the same model, and the same input shape, but I squeeze the input in the forward pass so that the Fully Connected layer effectively receives an input tensor of rank 2:

```python
model = MyModel(squeeze=True)
model(tf.random.uniform(shape=[1, 30, 5]))

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]

tflite_model = converter.convert()

input_ = tf.random.uniform(shape=[1, 30, 5])
output = model(input_)

interpreter = tf.lite.Interpreter(model_content=tflite_model)

interpreter.allocate_tensors()
interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_)
interpreter.invoke()
tflite_output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])

print(tf.reduce_max(tf.abs(output - tflite_output)))
```
This time the output was: `tf.Tensor(0.0044746697, shape=(), dtype=float32)`"
48957,ParameterServerStrategy - generators support,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
  - Im using nightly version while the stable is 2.4.1 
- Are you willing to contribute it (Yes/No):
  - No, I have no idea how to do this 



**Describe the feature and the current behavior/state.**

If I pass to `strategy.distribute_datasets_from_function` a fully created dataset (`Dataset.from_tensor_slices`) it works correctly. But while using `Dataset.from_generator` the training seems to get stuck in some infinite recursion or loop.

I get this error infinitely:
```
ERROR:tensorflow:Worker /job:worker/replica:0/task:0 failed with UnavailableError():2 root error(s) found.
  (0) Unavailable:  failed to connect to all addresses
Additional GRPC error information from remote target /job:chief/replica:0/task:0/device:CPU:0:
:{""created"":""@1620307041.224861224"",""description"":""Failed to pick subchannel"",""file"":""external/com_github_grpc_grpc/src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":3941,""referenced_errors"":[{""created"":""@1620307041.224860264"",""description"":""failed to connect to all addresses"",""file"":""external/com_github_grpc_grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":393,""grpc_status"":14}]}
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional]]
  (1) Unavailable:  failed to connect to all addresses
Additional GRPC error information from remote target /job:chief/replica:0/task:0/device:CPU:0:
:{""created"":""@1620307041.224861224"",""description"":""Failed to pick subchannel"",""file"":""external/com_github_grpc_grpc/src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":3941,""referenced_errors"":[{""created"":""@1620307041.224860264"",""description"":""failed to connect to all addresses"",""file"":""external/com_github_grpc_grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":393,""grpc_status"":14}]}
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional]]
	 [[OptionalHasValue/_2]]
0 successful operations.
0 derived errors ignored.
Additional GRPC error information from remote target /job:worker/replica:0/task:0:
:{""created"":""@1620307041.225796166"",""description"":""Error received from peer ipv4:192.168.88.111:10001"",""file"":""external/com_github_grpc_grpc/src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""2 root error(s) found.\n  (0) Unavailable:  failed to connect to all addresses\nAdditional GRPC error information from remote target /job:chief/replica:0/task:0/device:CPU:0:\n:{""created"":""@1620307041.224861224"",""description"":""Failed to pick subchannel"",""file"":""external/com_github_grpc_grpc/src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":3941,""referenced_errors"":[{""created"":""@1620307041.224860264"",""description"":""failed to connect to all addresses"",""file"":""external/com_github_grpc_grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":393,""grpc_status"":14}]}\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n\t [[RemoteCall]]\n\t [[IteratorGetNextAsOptional]]\n  (1) Unavailable:  failed to connect to all addresses\nAdditional GRPC error information from remote target /job:chief/replica:0/task:0/device:CPU:0:\n:{""created"":""@1620307041.224861224"",""description"":""Failed to pick subchannel"",""file"":""external/com_github_grpc_grpc/src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":3941,""referenced_errors"":[{""created"":""@1620307041.224860264"",""description"":""failed to connect to all addresses"",""file"":""external/com_github_grpc_grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":393,""grpc_status"":14}]}\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n\t [[RemoteCall]]\n\t [[IteratorGetNextAsOptional]]\n\t [[OptionalHasValue/_2]]\n0 successful operations.\n0 derived errors ignored."",""grpc_status"":14} [Op:__inference_fun_178]

Function call stack:
fun -> fun -> fun -> fun

2021-05-06 15:17:21.226996: W tensorflow/core/common_runtime/eager/context_distributed_manager.cc:671] Device filters can only be specified when initializing the cluster. Any changes in device filters are ignored when updating the server def.
2021-05-06 15:17:21.227082: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job ps -> {0 -> 192.168.88.110:10000}
2021-05-06 15:17:21.227095: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 192.168.88.111:10001}
2021-05-06 15:17:21.227101: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job chief -> {0 -> localhost:55849}
2021-05-06 15:17:21.228992: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job ps -> {0 -> 192.168.88.110:10000}
2021-05-06 15:17:21.229009: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 192.168.88.111:10001}
2021-05-06 15:17:21.229017: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job chief -> {0 -> localhost:55849}
```
[This tutorial](https://www.tensorflow.org/tutorials/distribute/parameter_server_training#known_limitations) elaborates on this limitation if I understand correctly.

It's very important to be able to train on large datasets while using data-parallel training. It's obvious behavior.

**Will this change the current api? How?**
Probably no.

**Who will benefit with this feature?**

**Any Other info.**
"
48955,Missing libtensorflow builds for 2.3.2,"There don't appear to be prebuilt binaries for libtensorflow (https://www.tensorflow.org/install/lang_c) for `2.3.2`.

https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-2.3.2.tar.gz actually yields the `darwin` build, which is missing at its own URI. 

These are missing entirely:
- https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-2.3.2.tar.gz
- https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-darwin-x86_64-2.3.2.tar.gz

Would it be possible to push those binaries/trigger CI builds to generate them? Thanks!

Related: #48550"
48954,Sanity Tests & Unity Test checking fails ,"Commands:
- `tensorflow/tools/ci_build/ci_build.sh CPU tensorflow/tools/ci_build/ci_sanity.sh`
- `tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...`
While running above two commands, the test fails and stop because of pip package installation error as shown below.
```
2021-05-07 06:26:49 (1.75 MB/s) - 'get-pip.py' saved [1937346/1937346]

/install/install_pip_packages.sh: line 21: python3.6: command not found
```"
48953,The speed performance of validation_batch_size does not work.,"I assume that the `validation_batch_size` could help speed up the validation process at each epoch. However, this contradict with the experiments.

> In [15]: x_train.shape
> Out[15]: (128, 1)
> 
> In [16]: x_test.shape
> Out[16]: (7600, 1)

Here is my experiments that I run several times, tf version: 2.3.1
```
model = get_model_transormer(num_classes)
for b in [8, 32, 64, 256, 512, 1024]:
    t1 = time.time()
    history = model.fit(
        x_train, y_train, batch_size=8, epochs=1, \
        validation_batch_size=b,
        validation_data=(x_test, y_test), verbose=1,
        callbacks = [EarlyStopping(monitor='val_acc', patience=3, mode='max')]
    )
    t2 = time.time()
    print('b:',b,  ' diff:', t2-t1)
```
Here is the report:

> 16/16 [==============================] - 12s 734ms/step - loss: 0.6992 - acc: 0.7812 - val_loss: 1.1789 - val_acc: 0.4779
> b: 8  diff: 11.802898168563843
> 16/16 [==============================] - 7s 468ms/step - loss: 0.5877 - acc: 0.7891 - val_loss: 1.4876 - val_acc: 0.3555
> b: 32  diff: 7.545728445053101
> 16/16 [==============================] - 7s 420ms/step - loss: 0.4992 - acc: 0.8594 - val_loss: 1.4072 - val_acc: 0.3999
> b: 64  diff: 6.773781061172485
> 16/16 [==============================] - 12s 731ms/step - loss: 0.3447 - acc: 0.9062 - val_loss: 1.1698 - val_acc: 0.5408
> b: 256  diff: 11.749623537063599
> 16/16 [==============================] - 27s 2s/step - loss: 0.2456 - acc: 0.9453 - val_loss: 1.0378 - val_acc: 0.5968
> b: 512  diff: 26.67411971092224
> 16/16 [==============================] - 52s 3s/step - loss: 0.1412 - acc: 0.9922 - val_loss: 1.1378 - val_acc: 0.5218
> b: 1024  diff: 52.29804968833923

It seems that setting validation_batch_size to 64 is the optimal option. That's quite weird.
Any explanation ?"
48952,How to add the dependency of TensorFlow 2.5.1-rc1 in my build.gradle file?,"Hey y'all I am working on an android application. The tensor flow version I was using had couple of error, so I switched to nightly builds. However, the latest nightly build does not support my application. I am trying to switch to a newer version of pre-release probably 2.5.1. The TF 2.5.1 can be found in the link https://github.com/tensorflow/tensorflow/tags. How do I add this version of TF to my application in the build.gradle file? 

Currently, I am using 2.4.0 (stable release), and it looks like this: 
```
dependencies {
    implementation 'androidx.appcompat:appcompat:1.2.0'
    implementation 'com.google.android.material:material:1.3.0'
    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'
    implementation 'com.google.firebase:firebase-auth:20.0.3'
    implementation 'com.google.firebase:firebase-database:19.7.0'
    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.2.0'
    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0'
    implementation ""org.tensorflow:tensorflow-lite:2.4.0""
    implementation group:'org.tensorflow',name:'tensorflow-lite-select-tf-ops',version:'2.4.0'
    implementation 'com.google.firebase:firebase-ml-model-interpreter:22.0.3'
//    implementation 'org.tensorflow:tensorflow-lite:2.6.0.dev20210427-nightly-SNAPSHOT'
//    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly-SNAPSHOT'
    testImplementation 'junit:junit:4.+'
    implementation 'com.github.PhilJay:MPAndroidChart:v3.1.0'
    androidTestImplementation 'androidx.test.ext:junit:1.1.2'
    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'
}
```
 I tried searching for the dependency on https://search.maven.org/, however I could not find the implementation. "
48949,TF 2.4.1 SavedModel.load() gives -Error: Expected these arguments to match one of the following Options,"Hi,


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `No custom code`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux Ubuntu 16.04`
- TensorFlow installed from (source or binary): `Binary`
- TensorFlow version (use command below): `v2.4.0-49-g85c8b2a817f 2.4.1`
- Python version: `3.6.8`
- Running on `CPU`

**Describe the current behavior**

I'm running simple text boundary detection model. I have saved this model using ONNX functions available for TensorFlow conversions (`onnx_tf.backend.prepare` and `onnx_tf.backend.export_graph`). [Repo Link](https://github.com/onnx/onnx-tensorflow/blob/master/onnx_tf/backend_rep.py) for reference

TF Model by itself runs fine but when exported and saved with `SavedModel` type gives error. I see that this is an old and common issue folks are running into. Some suggested updating versions, however I'm already using 2.4.1 which does not help in this case.
 
SavelModel - [here ](https://1drv.ms/u/s!Astr8XJs2VCYge03AifwF6EiFItolg?e=IWRX3n)


Command to reproduce - 

```python
import tensorflow as tf
# Load saved model and build the detection function
detect_fn = tf.saved_model.load('detect/')

input_tensor = tf.convert_to_tensor(np.array(any_input_image) # Any google image of sizable width and height [1x3xHxW] should work

detections,features = detect_fn(input_tensor)  # <-- Gives error on this line

```


**Stack Trace:**

```python

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-109-35d1f70160c5> in <module>
----> 1 detections,features = detect_fn(input_tensor)
      2 # print(detect_fn)

~/anaconda3/envs/textdet/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py in _call_attribute(instance, *args, **kwargs)
    666 
    667 def _call_attribute(instance, *args, **kwargs):
--> 668   return instance.__call__(*args, **kwargs)
    669 
    670 

~/anaconda3/envs/textdet/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    822     if RUN_FUNCTIONS_EAGERLY:
    823       with trace.Trace(self._name, tf_function_call=""eager""):
--> 824         return self._python_function(*args, **kwds)
    825 
    826     tracing_count = self.experimental_get_tracing_count()

~/anaconda3/envs/textdet/lib/python3.6/site-packages/tensorflow/python/saved_model/function_deserialization.py in restored_function_body(*args, **kwargs)
    271         .format(_pretty_format_positional(args), kwargs,
    272                 len(saved_function.concrete_functions),
--> 273                 ""\n\n"".join(signature_descriptions)))
    274 
    275   concrete_function_objects = []

ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * tf.Tensor(
[[[[ 2.2317834  2.2317834  2.2317834 ... -2.117904  -2.117904
    -2.117904 ]
   [ 2.2317834  2.2317834  2.2317834 ... -2.117904  -2.117904
    -2.117904 ]
   [ 2.2317834  2.2317834  2.2317834 ... -2.117904  -2.117904
    -2.117904 ]
   ...
   [ 2.2146587  2.2317834  2.2489083 ... -2.117904  -2.117904
    -2.117904 ]
   [ 2.2146587  2.2317834  2.2489083 ... -2.117904  -2.117904
    -2.117904 ]
   [ 2.2146587  2.2317834  2.2489083 ... -2.117904  -2.117904
    -2.117904 ]]

  [[ 2.4110644  2.4110644  2.4110644 ... -2.0357144 -2.0357144
    -2.0357144]
   [ 2.4110644  2.4110644  2.4110644 ... -2.0357144 -2.0357144
    -2.0357144]
   [ 2.4110644  2.4110644  2.4110644 ... -2.0357144 -2.0357144
    -2.0357144]
   ...
   [ 2.3935575  2.4110644  2.4285715 ... -2.0357144 -2.0357144
    -2.0357144]
   [ 2.3935575  2.4110644  2.4285715 ... -2.0357144 -2.0357144
    -2.0357144]
   [ 2.3935575  2.4110644  2.4285715 ... -2.0357144 -2.0357144
    -2.0357144]]

  [[ 2.6225708  2.6225708  2.6225708 ... -1.8044444 -1.8044444
    -1.8044444]
   [ 2.6225708  2.6225708  2.6225708 ... -1.8044444 -1.8044444
    -1.8044444]
   [ 2.6225708  2.6225708  2.6225708 ... -1.8044444 -1.8044444
    -1.8044444]
   ...
   [ 2.6051416  2.6225708  2.64      ... -1.8044444 -1.8044444
    -1.8044444]
   [ 2.6051416  2.6225708  2.64      ... -1.8044444 -1.8044444
    -1.8044444]
   [ 2.6051416  2.6225708  2.64      ... -1.8044444 -1.8044444
    -1.8044444]]]], shape=(1, 3, 1280, 960), dtype=float32)
  Keyword arguments: {}

Expected these arguments to match one of the following 2 option(s):

Option 1:
  Positional arguments (0 total):
    * 
  Keyword arguments: {'input.1': TensorSpec(shape=(1, 3, 1280, 960), dtype=tf.float32, name='input.1')}

Option 2:
  Positional arguments (0 total):
    * 
  Keyword arguments: {'input.1': TensorSpec(shape=(1, 3, 768, 768), dtype=tf.float32, name='input.1')}
```

Also why is my `keywords arguments` dictionary showing empty ?

Any help appreciated."
48947,keras optimizer.iterations are not properly save & restored,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Any
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0rc2
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

optimizer.iterations are not properly save & restored. After restoring iterations are reset as 0, which leads to wrong lr based on lr_scheduler

**Describe the expected behavior**

provide an option to either reset it or not, for backward compatibility maybe default to reset

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf

@tf.keras.utils.register_keras_serializable(package='Custom', name='MyScheduler')
class MyScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):
    def __init__(self, **kwargs):
        super(MyScheduler, self).__init__(**kwargs)

    def __call__(self, step):
        return step

    def get_config(self):
        return {}


inputs = tf.keras.Input(10)
outputs = tf.keras.layers.Dense(10)(inputs)
model = tf.keras.Model(inputs, outputs)

lr_scheduler = MyScheduler()
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)
model.compile(optimizer=optimizer, loss=""mse"")


def get_dataset(repeat):
    inputs_data = tf.ones([16, 10])
    labels_data = tf.ones([16, 10])
    dataset = (
        tf.data.Dataset.from_tensors(inputs_data)
        .map(
            lambda x: (
                inputs_data,
                labels_data,
                None,
            )
        ).repeat(repeat)
    )
    return dataset


model.fit(get_dataset(3), epochs=1)
print(model.optimizer.iterations, lr_scheduler(model.optimizer.iterations))

path = ""./foo/""
model.save(path)
loaded = tf.keras.models.load_model(path)
loaded.fit(get_dataset(4), epochs=1)
print(loaded.optimizer.iterations, lr_scheduler(loaded.optimizer.iterations))

```
the last print shows 4, but it should 3+4=7

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48946,How to add the dependency of TensorFlow 2.5.1-rc1 in my build.gradle file?,"Hey y'all I am working on an android application. The tensor flow version I was using had couple of error, so I switched to nightly builds. However, the latest nightly build does not support my application. I am trying to switch to a newer version of pre-release probably 2.5.1. The TF 2.5.1 can be found in the link https://github.com/tensorflow/tensorflow/tags. How do I add this version of TF to my application in the build.gradle file? 

Currently I am using 2.4.0 (stable release), and it looks like this: 
```
dependencies {
    implementation 'androidx.appcompat:appcompat:1.2.0'
    implementation 'com.google.android.material:material:1.3.0'
    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'
    implementation 'com.google.firebase:firebase-auth:20.0.3'
    implementation 'com.google.firebase:firebase-database:19.7.0'
    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.2.0'
    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0'
    implementation ""org.tensorflow:tensorflow-lite:2.4.0""
    implementation group:'org.tensorflow',name:'tensorflow-lite-select-tf-ops',version:'2.4.0'
    implementation 'com.google.firebase:firebase-ml-model-interpreter:22.0.3'
//    implementation 'org.tensorflow:tensorflow-lite:2.6.0.dev20210427-nightly-SNAPSHOT'
//    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly-SNAPSHOT'
    testImplementation 'junit:junit:4.+'
    implementation 'com.github.PhilJay:MPAndroidChart:v3.1.0'
    androidTestImplementation 'androidx.test.ext:junit:1.1.2'
    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'
}
```
 I tried searching for the dependency on https://search.maven.org/, however I could not find the implementation. "
48943,[keras] [tensorboard] buggy behavior of keras x tensorboard,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Any
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):  v2.4.0-rc4-71-g582c8d236cb 2.4.0 and above (e.g. 2.5.0rc2)
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

in the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard?hl=en) there are examples of how to use `tf.summary.histogram(...)` without specifying `step` in either subclass model or functiona api model. However it is actually broken since the step will always be 0.

This is due to `# TODO(b/151339474): Fix deadlock when not using .value() here.`  (in both 2.4.0 and 2.5.0) in  `tensorflow/tensorflow/python/keras/callbacks.py`. If I use `step` instead of `step.value()`, then everything is as expected. This is also explained in here https://github.com/tensorflow/tensorflow/pull/36839/commits/fed7d1a1fd23ca166c256bec0f9085a218f943e3#diff-d2cf8455ca3dbffe505170fa5fe38ed5e0d5969bcacb3b92e0b638b6d3c20461R230-R233 

May I ask what's the deadlock issue is and when the fix can be expected? Thx.

Also, I think it's better to move [this function call](https://github.com/tensorflow/tensorflow/blob/053ad9ed9222c9f201028f7fc1bd66eb9bd6baf6/tensorflow/python/keras/engine/training.py#L853) from `Model` to `Tensorboard` callback, in case if someone wants to overwrite step in `Tensorboard` (e.g. using a global step that can be save & restore in a continuous daily training model)


**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing): Yes

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

a code snippet
```
import tensorflow as tf


def my_summary(x):
  tf.summary.scalar(""mean_functional"", tf.reduce_mean(x))
  return x

class MyLayer(tf.keras.layers.Layer):
    def __init(self):
        super(MyLayer, self).__init__()

    def call(self, inputs):
        tf.summary.scalar(""mean_subclass"", tf.reduce_mean(inputs))
        return inputs

inputs = tf.keras.Input(10)
x = tf.keras.layers.Dense(10)(inputs)
outputs = tf.keras.layers.Lambda(my_summary)(x)
outputs = MyLayer()(outputs)
model = tf.keras.Model(inputs, outputs)
model.compile('sgd', 'mse')

# Make sure to set `update_freq=N` to log a batch-level summary every N batches.
# In addition to any `tf.summary` contained in `Model.call`, metrics added in
# `Model.compile` will be logged every N batches.
tb_callback = tf.keras.callbacks.TensorBoard('./logs240', update_freq=1)

inputs_data = tf.ones([16, 10])
labels_data = tf.ones([16, 10])

dataset = (
    tf.data.Dataset.from_tensors(inputs_data)
    .map(
        lambda x: (
            inputs_data,
            labels_data,
            None,
        )
    ).repeat(100)
)
model.fit(dataset, callbacks=[tb_callback], epochs=5)

```

with and without `.value()` : 
![Screen Shot 2021-05-06 at 12 40 42 PM](https://user-images.githubusercontent.com/3350930/117361380-d0581080-ae6e-11eb-92cc-e9743b2d29b9.png)
![Screen Shot 2021-05-06 at 11 30 19 AM](https://user-images.githubusercontent.com/3350930/117361382-d1893d80-ae6e-11eb-86db-1b4ee51cfab2.png)


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48942,"Building tensorflow for SSE4.2, cannot find proper option in configure.py","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>![image](https://user-images.githubusercontent.com/34324909/117359506-80387880-ae85-11eb-9821-290f3ddb3ee0.png)
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.15.0
- Python version: 3.7.9
- Installed using virtualenv? pip? conda?: build
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): not sure
- CUDA/cuDNN version: 10, 7.4
- GPU model and memory: 4gb, 1050ti and 1650 super, 6.1,7.5



**Describe the problem**
Building for SSE4.2. No suggestion on how to specify in ./configure.py

**Provide the exact sequence of commands / steps that you executed before running into the problem**
![image](https://user-images.githubusercontent.com/34324909/117359540-8c243a80-ae85-11eb-87f6-96d12a76cc09.png)

**Any other info / logs**
![image](https://user-images.githubusercontent.com/34324909/117359577-96463900-ae85-11eb-9df2-ba5a2fd241f0.png)"
48941,tf.ragged.constant fails on list of np.array,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX Catalina 10.15
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.5.0rc2
- Python version: 3.9.2

**Describe the current behavior**

Passing a list of Numpy arrays of rank > 1 one breaks tf.ragged.constant. Happens in both tf 2.4 and 2.5

**Describe the expected behavior**

That it would create the requests multidimensional ragged constant. I think this is a pretty common use case; for example, I have N variable-sized lists of xyz points, shape (None, 3), and want to turn them into one ragged constant of shape (N, None, 3).

**Standalone code to reproduce the issue**

https://colab.research.google.com/drive/1Zi40gL5IdARNeKid_7R_2b7_JcnWDW0T?usp=sharing 

**Other info / logs** Include any logs or source code that would be helpful to
`Traceback (most recent call last):
  File ""/Users/user1/Desktop/CS/ML/trees/trees-pointnet/test.py"", line 31, in <module>
    b = tf.ragged.constant(a, ragged_rank=1)
  File ""/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py"", line 206, in wrapper
    return target(*args, **kwargs)
  File ""/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py"", line 86, in constant
    return _constant_value(ragged_factory, constant_op.constant, pylist, dtype,
  File ""/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py"", line 218, in _constant_value
    inner_shape = _default_inner_shape_for_pylist(pylist, ragged_rank)
  File ""/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py"", line 311, in _default_inner_shape_for_pylist
    inner_shape = get_inner_shape(flat_values)
  File ""/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py"", line 285, in get_inner_shape
    return (len(item),) + get_inner_shape(item[0])
  File ""/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py"", line 284, in get_inner_shape
    elif item:
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()`
"
48940,"TF 1.15.0 GPU, 1050ti & 1650 super, CUDNN 7.4.2 CUDA 10.0.130","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version: 1.15.0 gpu
- Python version: 3.7.9
- Installed using virtualenv? pip? conda?: conda, pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0.130, 7.4.2
- GPU model and memory: 1050ti, 4gb, 1650 super, 4gb



**Describe the problem**
![image](https://user-images.githubusercontent.com/34324909/117342305-13b37e80-ae71-11eb-9eb5-16e74c168067.png)


**Provide the exact sequence of commands / steps that you executed before running into the problem**
Installed CUDA and CUDNN. Used conda to create new env with python 3.7.9, attempted 3.7.10 and lower versions too
including 3.6
python
import tensorflow as tf

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
This exact installation worked on my other computer, and I was using it to test out a completely new rig. "
48939,couldn't install tensorflow with poetry,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 20.1 (based on Ubuntu 20.04)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No.
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.4.1
- Python version: 3.8
- Installed using virtualenv? pip? conda?: poetry
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Nvidia RTX 2080



**Describe the problem**
Tensorflow finds the GPU but it isn't listed under `tf.config.list_physical_devices()`.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```console
(base) lukas@Makushin:~$ cd ~/Desktop
(base) lukas@Makushin:~/Desktop$ poetry new poetry-demo
Created package poetry_demo in poetry-demo
```

At this point I replaced the `pyproject.toml` file with the following file:

```
[tool.poetry]
name = ""poetry_demo""
version = ""0.1.0""
description = """"
authors = [""xxx <xxx@xxx.xx>""]

[tool.poetry.dependencies]
# python
python = ""3.8.8""
# data science
numpy = ""*""
pandas = ""*""
geopandas = ""*""
matplotlib = ""*""
sklearn = ""*""
tensorflow = ""^2.4.1""
# image processing
Pillow = ""*""
rasterio = ""*""

```

```console
(base) lukas@Makushin:~/Desktop$ cd poetry-demo
(base) lukas@Makushin:~/Desktop/poetry-demo$ poetry install
Creating virtualenv poetry-demo-bLNYl46S-py3.8 in /home/lukas/.cache/pypoetry/virtualenvs
Updating dependencies
Resolving dependencies... (6.6s)

Writing lock file

Package operations: 86 installs, 0 updates, 0 removals

  • Installing certifi (2020.12.5)
  • Installing chardet (4.0.0)
  • Installing idna (2.10)
```

<details>
  <summary>...</summary>

```console
  • Installing pyasn1 (0.4.8)
  • Installing urllib3 (1.26.4)
  • Installing cachetools (4.2.2)
  • Installing oauthlib (3.1.0)
  • Installing pyasn1-modules (0.2.8)
  • Installing requests (2.25.1)
  • Installing rsa (4.7.2)
  • Installing six (1.15.0)
  • Installing click (7.1.2)
  • Installing google-auth (1.30.0)
  • Installing numpy (1.19.5)
  • Installing requests-oauthlib (1.3.0)
  • Installing absl-py (0.12.0)
  • Installing attrs (21.1.0)
  • Installing click-plugins (1.1.1)
  • Installing cligj (0.7.1)
  • Installing google-auth-oauthlib (0.4.4)
  • Installing grpcio (1.32.0)
  • Installing joblib (1.0.1)
  • Installing markdown (3.3.4)
  • Installing markupsafe (1.1.1)
  • Installing munch (2.5.0)
  • Installing protobuf (3.15.8)
  • Installing pyparsing (2.4.7)
  • Installing python-dateutil (2.8.1)
  • Installing pytz (2021.1)
  • Installing scipy (1.6.3)
  • Installing tensorboard-data-server (0.6.1)
  • Installing tensorboard-plugin-wit (1.8.0)
  • Installing threadpoolctl (2.1.0)
  • Installing werkzeug (1.0.1)
  • Installing affine (2.3.0)
  • Installing alabaster (0.7.12)
  • Installing appdirs (1.4.4)
  • Installing astunparse (1.6.3)
  • Installing babel (2.9.1): Installing...
  • Installing cycler (0.10.0)
  • Installing docutils (0.16): Installing...
  • Installing fiona (1.8.19): Installing...
  • Installing flatbuffers (1.12)
  • Installing gast (0.3.3)
  • Installing google-pasta (0.2.0)
  • Installing h5py (2.10.0): Installing...
  • Installing imagesize (1.2.0)
  • Installing imagesize (1.2.0)
  • Installing h5py (2.10.0)
  • Installing imagesize (1.2.0)
  • Installing iniconfig (1.1.1)
  • Installing flatbuffers (1.12)
  • Installing gast (0.3.3)
  • Installing google-pasta (0.2.0)
  • Installing h5py (2.10.0)
  • Installing imagesize (1.2.0)
  • Installing iniconfig (1.1.1)
  • Installing fiona (1.8.19)
  • Installing flatbuffers (1.12)
  • Installing gast (0.3.3)
  • Installing google-pasta (0.2.0)
  • Installing h5py (2.10.0)
  • Installing imagesize (1.2.0)
  • Installing iniconfig (1.1.1)
  • Installing cycler (0.10.0)
  • Installing docutils (0.16): Installing...
  • Installing fiona (1.8.19)
  • Installing flatbuffers (1.12)
  • Installing gast (0.3.3)
  • Installing google-pasta (0.2.0)
  • Installing h5py (2.10.0)
  • Installing imagesize (1.2.0)
  • Installing iniconfig (1.1.1)
  • Installing babel (2.9.1)
  • Installing cycler (0.10.0)
  • Installing docutils (0.16): Installing...
  • Installing fiona (1.8.19)
  • Installing flatbuffers (1.12)
  • Installing gast (0.3.3)
  • Installing google-pasta (0.2.0)
  • Installing h5py (2.10.0)
  • Installing imagesize (1.2.0)
  • Installing iniconfig (1.1.1)
  • Installing fiona (1.8.19)
  • Installing flatbuffers (1.12)
  • Installing gast (0.3.3)
  • Installing google-pasta (0.2.0)
  • Installing h5py (2.10.0)
  • Installing imagesize (1.2.0)
  • Installing iniconfig (1.1.1)
  • Installing docutils (0.16)
  • Installing fiona (1.8.19)
  • Installing flatbuffers (1.12)
  • Installing gast (0.3.3)
  • Installing google-pasta (0.2.0)
  • Installing h5py (2.10.0)
  • Installing imagesize (1.2.0)
  • Installing iniconfig (1.1.1)
  • Installing jinja2 (2.11.3)
  • Installing keras-preprocessing (1.1.2)
  • Installing kiwisolver (1.3.1)
  • Installing mypy-extensions (0.4.3)
  • Installing opt-einsum (3.3.0)
  • Installing packaging (20.9)
  • Installing pandas (1.2.4): Installing...
  • Installing pandas (1.2.4)
  • Installing pathspec (0.8.1)
  • Installing pillow (8.2.0)
  • Installing pluggy (0.13.1)
  • Installing py (1.10.0)
  • Installing pygments (2.9.0)
  • Installing pyproj (3.0.1)
  • Installing regex (2021.4.4)
  • Installing scikit-learn (0.24.2)
  • Installing snowballstemmer (2.1.0)
  • Installing shapely (1.7.1)
  • Installing snuggs (1.4.7)
  • Installing sphinxcontrib-applehelp (1.0.2)
  • Installing sphinxcontrib-devhelp (1.0.2)
  • Installing sphinxcontrib-htmlhelp (1.0.3)
  • Installing sphinxcontrib-jsmath (1.0.1)
  • Installing sphinxcontrib-qthelp (1.0.3)
  • Installing tensorboard (2.5.0)
  • Installing tensorflow-estimator (2.4.0)
  • Installing sphinxcontrib-serializinghtml (1.1.4)
  • Installing termcolor (1.1.0)
  • Installing toml (0.10.2)
  • Installing typing-extensions (3.7.4.3)
  • Installing wrapt (1.12.1)
  • Installing black (21.5b0)
  • Installing geopandas (0.9.0)
  • Installing matplotlib (3.4.1)
  • Installing pytest (6.2.4)
  • Installing rasterio (1.2.3)
```

</details>

```console
  • Installing sklearn (0.0)
  • Installing sphinx (3.5.4)
  • Installing tensorflow (2.4.1)

Installing the current project: poetry_demo (0.1.0)
(base) lukas@Makushin:~/Desktop/poetry-demo$ poetry run python
Python 3.8.8 (default, Apr 13 2021, 19:58:26) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
2021-05-06 17:51:27.535624: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-05-06 17:51:27.535643: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
>>> tf.config.list_physical_devices()
2021-05-06 17:51:57.675020: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-06 17:51:57.675844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-05-06 17:51:57.701899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 17:51:57.702606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.77GiB deviceMemoryBandwidth: 417.23GiB/s
2021-05-06 17:51:57.702710: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-05-06 17:51:57.702793: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory
2021-05-06 17:51:57.702866: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory
2021-05-06 17:51:57.704592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-06 17:51:57.704887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-06 17:51:57.706566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-06 17:51:57.706678: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory
2021-05-06 17:51:57.706759: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2021-05-06 17:51:57.706778: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
>>> 

```


**Any other info / logs**
Another way I tried was to install Tensorflow into a fresh Anaconda environment using `conda create --name tf_gpu tensorflow-gpu`. That way the GPU was listed in `tf.config.list_physical_devices()`. However I would like to avoid Anaconda if posibble because it has other, unrelated drawbacks.
"
48937,Can't print RaggedTensor with dtype uint8,"Following code block
`>>> tf.print(tf.ragged.constant([[1,2,3],[1,2]], dtype=tf.uint8)`
raises 
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of uint8 is not in the list of allowed values: int8, int16, int32, int64, complex64, complex128, float, double, bool, variant
	; NodeDef: {{node AsString}}; Op<name=AsString; signature=input:T -> output:string; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128, DT_FLOAT, DT_DOUBLE, DT_BOOL, DT_VARIANT]; attr=precision:int,default=-1; attr=scientific:bool,default=false; attr=shortest:bool,default=false; attr=width:int,default=-1; attr=fill:string,default=""""> [Op:AsString]
```
I'm filing this as a bug because I really don't think this error is thrown intentionally. If it is, apologies. 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): tested in `2.4.1` and `2.6.0-dev20210506` (latest dev I could find)
- Python version: 3.8

**Describe the current behavior**
It raises an errror
**Describe the expected behavior**
The Ragged tensor can be printed

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes): sure, I have absolutely no idea where to start though. 

**Standalone code to reproduce the issue**
`tf.print(tf.ragged.constant([[1,2,3],[1,2]], dtype=tf.uint8) ` in an interactive python shell
"
48936,Use MultiHeadAttention in tf:2.3.1,"I want to use `MultiHeadAttention` layer in tf:2.3.1 due to CUDA version limit.

here is the test code:
```
import multi_head_attention  

test_layer = multi_head_attention.MultiHeadAttention(
    num_heads=12, key_dim=64)
# Create a 3-dimensional input (the first dimension is implicit).
query = keras.Input(shape=(40, 80))
output, coef = test_layer(query, query, return_attention_scores=True)

```

I copy this file : https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/layers/multi_head_attention.py 
to my current working path for import.

Here is the error:

> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-6-8ef8346e0a54> in <module>
>       1 query = keras.Input(shape=(40, 80))
> ----> 2 output, coef = test_layer(query, query, return_attention_scores=True)
> 
> ~/yanan/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
>     924     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):
>     925       return self._functional_construction_call(inputs, args, kwargs,
> --> 926                                                 input_list)
>     927
>     928     # Maintains info about the `Layer.call` stack.
> 
> ~/yanan/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)
>    1115           try:
>    1116             with ops.enable_auto_cast_variables(self._compute_dtype_object):
> -> 1117               outputs = call_fn(cast_inputs, *args, **kwargs)
>    1118
>    1119           except errors.OperatorNotAllowedInGraphError as e:
> 
> ~/yanan/env/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
>     256       except Exception as e:  # pylint:disable=broad-except
>     257         if hasattr(e, 'ag_error_metadata'):
> --> 258           raise e.ag_error_metadata.to_exception(e)
>     259         else:
>     260           raise
> 
> TypeError: in user code:
> 
>     /root/yanan/berts/topic_classification_augmentation/multi_head_attention.py:510 call  *
>         attention_output, attention_scores = self._compute_attention(
>     /root/yanan/berts/topic_classification_augmentation/multi_head_attention.py:475 _compute_attention  *
>         attention_scores = self._masked_softmax(attention_scores, attention_mask)
>     /root/yanan/berts/topic_classification_augmentation/multi_head_attention.py:438 _masked_softmax  *
>         return self._softmax(attention_scores, attention_mask)
>     /root/yanan/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:926 __call__  **
>         input_list)
>     /root/yanan/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:1117 _functional_construction_call
>         outputs = call_fn(cast_inputs, *args, **kwargs)
> 
>     TypeError: call() takes 2 positional arguments but 3 were given


Any solution ?"
48934,Tflite Hexagon delegate performance drop when upgrading from TF 2.2 to 2.4,"
**System information**
- Have I written custom code: Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Android.
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Snapdragon 855 dev platform
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2 and 2.4
- Python version: 3.8
- Bazel version (if compiling from source): 3.7
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A 
- GPU model and memory: N/A

**Describe the current behavior**

* A Keras model is converted to TfLite with full integer quantization and is executed on device using hexagon delegate.
When converted using Tensorflow 2.2, 97 of 99 nodes are a executed on DSP and good performance is achieved - 12 ms per inference. When the same model is converted using Tensorflow 2.4, the output TfLite NN has 112 nodes of which only 81 are executed on DSP an runtime is 40 ms - nearly 4 times worse! 

* When converted using Tensorflow 2.2, a run time of 12 ms is observed in an offline test. When running online (in an android app), run time of inference degrades to 18 ms. 

**Describe the expected behavior**

* Runtime (in an offline test) is expected to remain nearly the same when upgrading from Tensorflow 2.2 to Tensorflow 2.4
* Runtime difference between online and offline execution is expected to be much less than 6ms (18 ms vs 12 ms) as most of the network is offloaded to DSP. 


**Standalone code to reproduce the issue**
See [attached](https://drive.google.com/file/d/1yoPakbmxyhKXaXydn3RXLGMnsLdFl2t5/view?usp=sharing) a zip file with:
1. The Keras model
2. Conversion script
3. representative dataset for conversion
3. output TfLite model for TF version 2.2
4. output Tflite model for TF version 2.4
5. logs from TfLite benchmark utility for both TfLite model versions.

_usage:_ python convertandquantize.py
Switch from TF 2.2 to TF 2.4 in your environment between runs


"
48933,"Input depth should be equal to filter depth, conv2d, Tensorflow, Convolution operation, CNN","Tensorflow version 2.0

Python version 3.7




Following tensors extracted from TF Resnet50 model for experimentation on convolution.
in1.shape = (1,56,56,64)
weight_kernel.shape = (64,3,3,64)

Method1:-
image_conv = tensorflow.nn.conv2d(in1, weight_kernel, strides=(1,1), padding='SAME', dilations=None, data_format='NHWC')

Method2:-
image_conv = tensorflow.keras.backend.conv2d(in1, kernel=weight_kernel, strides=(1, 1), padding='same', dilation_rate=(1,1), data_format='channels_last')



Error:-
InvalidArgumentError: input depth must be evenly divisible by filter depth: 64 vs 3 [Op:Conv2D]

Tried changing the padding; data_format, strides also.


When the convolution has no issue happening in resnet model, why recreating outside is an issue with same tensor size; secondly  there is not depedency of filter depth as such in convolution, On what basis is 64 vs 3 coming up?
If i keep one tensor in channels first format and other one in channels last format, it starts giving error on 56 vs 3,  though I believe both should be in same format for the convolution operation."
48932,Tflite from pytorch-onnx - seesaw facenet very slow loading.,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Xiaomi Redmi Note 5 Pro
- TensorFlow installed from (source or binary): pip install tensorflow==2.4.0
- TensorFlow version (use command below): 2.4.0
- Python version: 3.8
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
TFlite loading time is approximately 10 seconds on Redmi Note 5 Pro. Pytorch for android is giving me lesser inference time and loading time on same mobile device.
```

Average (of three) loading and running time (in ms) on 2 mobile devices!

                               Inference Time                Model Loading Time
                               Mobile 1 | Mobile 2            Mobile 1   | Mobile 2
Resnet-34 130 mb TFlite         768          1328               7                10
Seesaw Facenet 35 mb Tflite     1669        3507               9332          15867
Seesaw Facenet 35 mb Torch       922          2173               2925          9468

```

**Describe the expected behavior**
TFlite loading time should be under 1 second as with other models like ResNets (34, 100 etc.)

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
''' Model code and pre-trained files here https://github.com/cvtower/seesawfacenet_pytorch/blob/master/src/seesaw_models/DW_seesawFaceNetv2.py ''''

# IMPORTS
from DW_seesawFaceNetv2 import *
model = DW_seesawFaceNetv2(512)
model = torch.nn.DataParallel(model)
model.load_state_dict(torch.load('./trained-model.pth', map_location=torch.device('cpu') ))
model.eval();
model.to('cpu')

print(model(torch.zeros(1,3,112,112))) # for checking output after conversion
input_names = ['input'] # [""Conv2d-1""]
output_names = ['output'] # [""DW_seesawFaceNetv2-826""]
inputs = torch.randn((1, 3, 112, 112), device = torch.device('cpu')) #to('cpu')
dummy_input = Variable(inputs, requires_grad=True)

torch_out = torch.onnx.export(model.module.to('cpu'), dummy_input, 'output.onnx', export_params=True, verbose=True,
                              input_names=input_names, output_names=output_names,
                              opset_version = 12, do_constant_folding=False,
                              enable_onnx_checker=True))

# onnx.checker.check_model('./output.onnx') # to check the onnx conversion is correct

model = onnx.load(""output.onnx"")
onnx.helper.printable_graph(model.graph) # print onnx graph!

sess = nxrun.InferenceSession(""./output.onnx"")
ximg = np.zeros((1, 3, 112, 112)).astype(np.float32)

print(""The model expects input shape: "", sess.get_inputs()[0].shape)
print(""The shape of the Image is: "", ximg.shape)

input_name = sess.get_inputs()[0].name
label_name = sess.get_outputs()[0].name
% time result = sess.run(None, {input_name: ximg})
prob = result[0]
print(prob.ravel()) # to check if onnx outputs are same as torch model

# Load ONNX model
model_onnx = onnx.load('./output.onnx')

# conv./output_onnxto TensorFlow format
tf_rep = prepare(model_onnx)

# Export model as .pb file
tf_rep.export_graph('./onnx2tf')

tf_model = tf.saved_model.load('./onnx2tf')

converter = tf.lite.TFLiteConverter.from_saved_model('./onnx2tf') # path to the SavedModel directory
converter.allow_custom_ops = True

# I have not used the below options!
# converter.experimental_new_converter = True
# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert() # takes a lot of time !!

# Save the model.
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
```
------------------------------------------------------------------------------------------------------

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The tflite model is the same size as the torch model approximately, the inference time is also in a good range. But the loadin time is coming out to be 10 seconds on some mobile devices, and consistently more than other models like ResNets (34,100 etc)

A sample tflite model can be found here. There is a slight change in the number of blocks in original model and this model
https://drive.google.com/file/d/1S52OXU0q9aFyk_IwGybyJ85WH1hEq3Hn/view?usp=sharing"
48931,"in customized async op, should gpu allocate_output call be synchronized?","Hi, I am using tensorflow 1.15 with horovod in which cusomized asynchronous op kernel is involved.
horovod implements its collective op by enqueuing collective request to its own runtime message queue, and in nvidia gpu environment, horovod uses its own cuda stream other than tensorflow gpu stream.
generally, horovod gpu allgather operation calls allocate_output and synchronizes on it (blocking host code). 
my question is that, if allocate_output return valid memory pointer as soon as the call return, why calling BlockHostUntilDone on tensorflow stream is necessary?
I checked tensorflow allocator implementation but got no clues. it appears to me that gpu memory allocation is done synchronously and actually not related to any stream.
a related discussion can be found [here](https://github.com/horovod/horovod/discussions/2877).
"
48930,tensorflow go bazel visibility issue during bazel build,"I'm using tensorflow 1.4.0 and  we are using bazel to build our service. During bazel build I'm getting the following error,

`in go_library rule @com_github_tensorflow_tensorflow//tensorflow/go/op:op: target '@com_github_tensorflow_tensorflow//tensorflow/go:go' is not visible from target '@com_github_tensorflow_tensorflow//tensorflow/go/op:op'. Check the visibility declaration of the former target if you think the dependency is legitimate`


I observed that the issue is existing because default package visibility is private.
Is there any way to override this visibility behavior.

"
48929,How the tf.linalg.eig operation is implemented and why it is  differentiable?,"I used the tf.linalg.eig to compute the eigenvalues of an arbitrary real matrix. Although it is differentiable, I am concerned about how this operation is implemented and whether the differentiation is always correct.

https://www.tensorflow.org/api_docs/python/tf/linalg/eig"
48928,compat.v1.resize_bilinear fails in 2.4.1,"The following code works in 2.3.2 but fails in 2.4.1:

`
h, w = 3, 1
image = tf.constant(np.arange(h*w).reshape((h, w)), dtype=tf.float32)[tf.newaxis, ..., tf.newaxis]
_input = tf.keras.layers.Input((h, w, 1))
tf2_img = tf.image.resize(_input, [9, 1])
tf1_img = tf.compat.v1.image.resize(_input, [9, 1], align_corners=True)
tf1_img_bl = tf.compat.v1.image.resize_bilinear(_input, [9, 1], align_corners=True)  # <-- problematic line
out = tf.concat([tf1_img, tf2_img, tf1_img_bl], 2)

m = tf.keras.Model(inputs=_input, outputs=out)
`
"
48927,Error loading maskrcnn  .pbtxt file,"Error loading maskrcnn  .pbtxt file in opencv dnnn. i made a custom dataset and trained and created pb and ptxt  and i want to run the trained model in opencv dnn 
created .pbtxt using this code below 
link to .pbtxt file https://drive.google.com/file/d/1HK86GRMg3LR8N9BPGZL5JyLdxVIxn3N3/view?usp=sharing
```
import tensorflow as tf
with tf.gfile.FastGFile('data/gaze_model.pb', ""rb"") as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

    for i in reversed(range(len(graph_def.node))):
        if graph_def.node[i].op == 'Const':
            del graph_def.node[i]

    graph_def.library.Clear()

    tf.train.write_graph(graph_def, """", 'data/gaze_model.pbtxt', as_text=True)
```

generated the  pb using trained .h5 file using this code 

```
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import warnings

import keras.backend as K
import tensorflow as tf

warnings.filterwarnings('ignore', category=FutureWarning)
# suppress warning and error message tf
os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""3""

# Root directory of the project
ROOT_DIR = os.getcwd()
# Import Mask RCNN
sys.path.append(ROOT_DIR)  # To find local version of the library
from mrcnn import model as modellib
from mrcnn import utils

import coco 
K.clear_session()
K.set_learning_phase(0)

##############################################################################
# Load model
##############################################################################


# Model Directory
MODEL_DIR = (""/logs"")
DEFAULT_WEIGHTS =  (""/content/drive/MyDrive/thirip2/mask_rcnn_coco.h5"")
# Download COCO trained weights from Releases if needed
if not os.path.exists(DEFAULT_WEIGHTS):
    utils.download_trained_weights(DEFAULT_WEIGHTS)

##############################################################################
# Load configuration
##############################################################################



class InferenceConfig(coco.CocoConfig):
        # Set batch size to 1 since we'll be running inference on
        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU
        GPU_COUNT = 1
        IMAGES_PER_GPU = 1
        

##############################################################################
# Save entire model function
##############################################################################

def h5_to_pb(h5_model, output_dir, model_name, out_prefix=""output_""):
    out_nodes = []
    for i in range(len(h5_model.outputs)):
        out_nodes.append(out_prefix + str(i + 1))
        tf.identity(h5_model.output[i], out_prefix + str(i + 1))
    sess = K.get_session()
    init_graph = sess.graph.as_graph_def()
    main_graph = tf._api.v1.graph_util.convert_variables_to_constants(sess, init_graph, out_nodes)
    with tf.gfile.GFile(os.path.join(output_dir, model_name), ""wb"") as filemodel:
        filemodel.write(main_graph.SerializeToString())
    print(""pb model: "", {os.path.join(output_dir, model_name)})


if __name__ == ""__main__"":
    config = InferenceConfig()
    config.display()
    # Create model in inference mode
    model = modellib.MaskRCNN(mode=""inference"", model_dir=MODEL_DIR, config=config)

    # Set path to model weights
    weights_path = DEFAULT_WEIGHTS#model.find_last()
    # Load weights
    print(""Loading weights "", weights_path)
    model.load_weights(weights_path, by_name=True)
    model.keras_model.summary()

    # make folder for full model
    model_dir = os.path.join(ROOT_DIR, ""Model"")
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)

    # save h5 full model
    name_model = os.path.join(model_dir, ""/content/drive/MyDrive/thirip2/mask_rcnn_bottle_0040.h5"")
    if not os.path.exists(name_model):
        model.keras_model.save(name_model)
        print(""save model: "", name_model)

    # export pb model
    pb_name_model = ""mask_rcnn_landing.pb""
    h5_to_pb(model.keras_model, output_dir=model_dir, model_name=pb_name_model)
    K.clear_session()
    sys.exit()
```

link to pb file https://drive.google.com/file/d/18B5_a7uKU6smvg05f6-H-JvsxDZYqGwY/view
```?usp=sharing


and loaded my .pb and generated pbtxt file to opencv dnn  got error  Failed to parse GraphDef file: E:/model.pbtxt in function 'cv::dnn::ReadTFNetParamsFromTextFileOrDie'

would be great if you guys help to get this done
thank you "
48926,Installing tensorflow headers and libs for c++,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): from source
- TensorFlow version: 2.3.1
- Python version: 3.6
- Installed using virtualenv? pip? conda?: NA
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): gcc version 7.5.0 (Ubuntu/Linaro 7.5.0-3ubuntu1~18.04) 
- CUDA/cuDNN version: 10.2/8.0.0
- GPU model and memory: 256-core NVIDIA Pascal™ GPU architecture with 256 NVIDIA CUDA cores



**Describe the problem**
I have successfully compiled the code on Tx2. how should I install it. I see  bazel-bin,  bazel-out,  bazel-tensorflow directory got created. I want to to install .so in /usr/local/lib and headers in /usr/local/include/tensorflow paths. Tried searchign goole but not enough info available.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
below is the command I tried running for compilation
sudo bazel --host_jvm_args=-Xmx1624m build --config=opt --config=monolithic --config=v2 --local_cpu_resources=2 //tensorflow:libtensorflow_cc.so

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

`Target //tensorflow:libtensorflow_cc.so up-to-date:                                                                         
  bazel-bin/tensorflow/libtensorflow_cc.so                                                                                           
INFO: Elapsed time: 34104.697s, Critical Path: 909.56s                                                         
INFO: 3868 processes: 3868 local.                                                                                                        INFO: Build completed successfully, 4367 total actions `"
48925,Only some Keras activations under `tf.keras.activations` are supported,"Hi,

When adapting QAT(Quantization aware training) to get bbox regression with Keras, 
I've got following error:
`ValueError: Only some Keras activations under `tf.keras.activations` are supported. For other activations, use `Quantizer` directly, and update layer config using `QuantizeConfig`.
`
Even I referred some Tensorflow documents, I cannot find out what's problem at all.
[link](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/quantization/keras/quantize_model?hl=ko): 

I attach my code block as below:
```
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

INIT_LR = 1e-4
NUM_EPOCHS = 1
BATCH_SIZE = 8

basemodel = MobileNetV2(weights=""imagenet"", include_top=False,
        input_tensor=Input(shape=(224, 224, 3)))
basemodel.trainable = False

# MobileNetV2
flatten = basemodel.output
bboxHead = Flatten(name=""flatten"")(flatten)
bboxHead = Dense(128, activation=""relu"")(bboxHead)
bboxHead = Dense(4, activation=""sigmoid"")(bboxHead)

model = Model(inputs=basemodel.input, outputs=bboxHead)
opt = Adam(INIT_LR)
model.compile(loss=""mse"", optimizer=opt)
H = model.fit(
        trainImages, trainTargets, 
        validation_data=(testImages, testTargets),
        batch_size=BATCH_SIZE,
        epochs=NUM_EPOCHS,
        verbose=1)

import tensorflow_model_optimization as tfmot
quantize_model = tfmot.quantization.keras.quantize_model

q_aware_model = quantize_model(model)
q_aware_model.compile(loss=""mse"", optimizer=opt, metrics=['accuracy'])
```
'**sigmoid**' of the last Dense layer may the error, because if I change this to the other activation, the error disappeared.
Just disappeared.

-----
[Edit]
TF: 2.4.1

Thanks,


"
48924,Failed init TFL interpreter when enabled XNNPACK,"**System information**
- IDE: XCode 12.5
- Mobile device: iPhone 12 Pro Max
- TensorFlow installed: 'TensorFlowLiteObjC' from CocoaPods
- TensorFlow version: tried '2.3.0', '2.4.0', and '0.0.1-nightly.20210503'

**Describe the current behavior**
Whenever enabled XNNPACK, model initiation will fail. (see code snippets below)

**Describe the expected behavior**
Expected to initiate mode successfully

**Standalone code to reproduce the issue**
NSError *err = nil;
TFLInterpreterOptions *options = [[TFLInterpreterOptions alloc] init];
options.useXNNPACK = YES;
NSString *modelPath = [[NSBundle mainBundle] pathForResource:@""mymodel"" ofType:@""tflite""];
_modelInterpreter = [[TFLInterpreter alloc] initWithModelPath:modelPath options:options error:&err];

where mymodel.tflite is a custom trained model. If set 
         options.useXNNPACK = NO;
everything will work normally. When XNNPACK is enabled, the init will fail for interpreter. Specifically, it fails at 
         _interpreter = TfLiteInterpreterCreate(model, cOptions);
inside TFLInterpreter.mm in the framework, and there's no source code to trace further.
"
48923, Failed to initialize TensorFlow context: subgraphs is null,"I am trying to run this program; however I keep on getting the error listed below. 
```
package com.example.se;

import android.content.Context;
import android.content.Intent;
import android.content.SharedPreferences;
import android.content.res.AssetFileDescriptor;
import android.content.res.AssetManager;
import android.database.Cursor;
import android.media.AudioManager;
import android.net.Uri;
import android.net.rtp.AudioStream;
import android.os.Bundle;
import android.os.FileUtils;
import android.util.Log;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.Button;
import android.widget.Toast;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;
import androidx.fragment.app.Fragment;
import androidx.fragment.app.FragmentManager;
import androidx.fragment.app.FragmentPagerAdapter;
import androidx.fragment.app.FragmentTransaction;
import androidx.viewpager.widget.ViewPager;

import com.example.se.ui.main.SectionsPagerAdapter;
import com.google.android.material.tabs.TabLayout;

import org.tensorflow.lite.Interpreter;
import org.tensorflow.lite.flex.FlexDelegate;
import java.io.BufferedInputStream;
import java.io.BufferedReader;
import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.lang.Object;
import java.lang.reflect.Array;
import java.net.URISyntaxException;
import java.nio.ByteBuffer;
import java.nio.FloatBuffer;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class Classify extends Fragment {
    private Button choose_file_button;
    public static final int PICKFILE_RESULT_CODE = 1;
    private Uri fileUri;
    private String filePath; // This is the final file path
    View classify_view;

    // To load from asset folder
    private static final String LABEL_FILENAME = ""file:///android_asset/labels.txt"";
    private static final String MODEL_FILENAME = ""file:///android_asset/soundclassifier.tflite"";
    private static final String LOG_TAG = ""Log tagges is here"";

    // For label and modelfile
    private List<String> labels = new ArrayList<String>();
    private List<String> displayedLabels = new ArrayList<>();

    // For the audio file
    ByteArrayOutputStream out = new ByteArrayOutputStream();
    InputStream in;
    byte[] audioBytes;
    Float[][] audioFile = new Float[1][44032];

    // For machine learning
    private MappedByteBuffer tfLiteModel;
    private Interpreter tfLite;
    private final Interpreter.Options ftliteOptions = new Interpreter.Options();
    float[] outputs;
    private RecognizeCommands recognizeCommands = null;
    private int modelInputLength;
    private int modelNumClasses;
    private FloatBuffer inputBuffer;

    @Nullable
    @Override
    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
        classify_view = inflater.inflate(R.layout.classify,container,false);

        // Both finds the classify and stop classify button
        choose_file_button = (Button) classify_view.findViewById(R.id.classify_button);

        // For labels file
        String actualLabelFilename = LABEL_FILENAME.split(""file:///android_asset/"",-1)[1];
        Log.i(LOG_TAG,""Reading labels from "" + actualLabelFilename);

        BufferedReader br = null;
        try{
            br = new BufferedReader(new InputStreamReader(classify_view.getContext().getAssets().open(actualLabelFilename)));
            String line;
            while ((line = br.readLine()) != null){
                labels.add(line);
                if (line.charAt(0) != '_'){
                    displayedLabels.add(line.substring(0,1).toUpperCase()+ line.substring(1));
                }
            }
        } catch (IOException e){
            throw new RuntimeException(""Problem reading the label file!"",e);
        }
        // Creates the equal number of labels on the output file
        Log.i(LOG_TAG,""Labels file messages are :""+ displayedLabels);
        outputs = new float[displayedLabels.size()];

        // ToDo : Implement Recognize Commands if not working

        // Opening the model file
        String actualModelFilename = MODEL_FILENAME.split(""file:///android_asset/"",-1)[1];
        try{
            tfLiteModel = loadModelFile(classify_view.getContext().getAssets(), actualModelFilename);
        } catch (Exception e){
            throw new RuntimeException(e);
        }

        Log.i(LOG_TAG,""The modal file is :""+actualModelFilename);
        Log.i(LOG_TAG,""The actual content is :""+tfLiteModel);

        // ToDo : Model file opened here
        try{
            ftliteOptions.setNumThreads(1);
            FlexDelegate flex = new FlexDelegate();
            ftliteOptions.addDelegate(flex);
            File openThis = new File(MODEL_FILENAME);
            tfLite = new Interpreter(tfLiteModel,ftliteOptions);
            // tfLite = new Interpreter(openThis);
        } catch (Exception e){
            throw new RuntimeException(e);
        }
        Log.i(LOG_TAG,""TF lite file loaded. "");

        // To load the metadata and verify it
        int [] inputShape = tfLite.getInputTensor(0).shape();
        modelInputLength = inputShape[1];

        int [] outputShape  = tfLite.getOutputTensor(0).shape();
        modelNumClasses = outputShape[1];

        Log.i(LOG_TAG,"" ""+modelNumClasses);
        if (modelNumClasses != displayedLabels.size()){
            Log.e(LOG_TAG,""The file's metadata is not the same"");
        }else{
            Log.i(LOG_TAG,""The file's metadata is same"");
        }
        Log.i(LOG_TAG,"" ""+displayedLabels.size());
        inputBuffer = FloatBuffer.allocate(modelInputLength);

        choose_file_button.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                Intent chooseFile = new Intent(Intent.ACTION_GET_CONTENT);
                chooseFile.setType(""*/*"");
                chooseFile = Intent.createChooser(chooseFile, ""Choose a file"");
                startActivityForResult(chooseFile, PICKFILE_RESULT_CODE);
                // At this point we have the path of the file
                // File path working.
                /*
                    For pie chart we can have : https://github.com/PhilJay/MPAndroidChart
                 * */
            }
        });
        return classify_view;
    }
    // This gets the file path
    @Override
    public void onActivityResult(int requestCode, int resultCode, Intent data) {
        switch (requestCode) {
            case PICKFILE_RESULT_CODE:
                if (resultCode == -1) {
                    fileUri = data.getData();
                    filePath = fileUri.getPath();
                    System.out.println(""The selected file path is :""+filePath);
                    open_audio_file(fileUri);
                    // Opens main audio file
                    try{
                        FloatBuffer outputBuffer = FloatBuffer.allocate(modelNumClasses);
                        inputBuffer.rewind();
                        outputBuffer.rewind();
                        tfLite.run(inputBuffer,outputBuffer);
                        Log.i(LOG_TAG,""The output is :""+ Arrays.toString(outputBuffer.array()));
                        SharedPreferences sharedPref = classify_view.getContext().getSharedPreferences(getString(R.string.ml_values), Context.MODE_PRIVATE); // To open in private mode, can only be seen
                        // by our application
                        SharedPreferences.Editor editor = sharedPref.edit(); // Opening the file to edit
                        float [] arr = outputBuffer.array();
                        String str = "" "";
                        for(int i=0;i<arr.length;i++){
                            str = str + "", ""+ arr[i];
                        }
                        editor.putString(""FLOAT_ARR"",str); // Putting in the string, Now Email keyword in SharedPref is associated with email entered by the user
                        editor.apply(); // Applying the changes
                        inputBuffer.clear();
                        outputBuffer.clear();
                        openHistoryPage(); // This opens history page after everything is done
                    }catch(Exception e){
                        throw new RuntimeException(e);
                    }
                }
                break;
        }
    }

    public void open_audio_file(Uri filePath){
        try{
            in = new BufferedInputStream(getContext().getContentResolver().openInputStream(filePath));

            int read;
            byte[] buff = new byte[1024];
            while ((read = in.read(buff)) > 0)
            {
                out.write(buff, 0, read);
            }
            out.flush();
        }catch(Exception e){
            throw new RuntimeException(e);
        }

        //Todo : Change the audio file to a float pointer
        audioBytes = out.toByteArray();
        for (int i = 0;i < audioBytes.length;i++){
            float val = (float) audioBytes[i];
            inputBuffer.put(i,val);
            audioFile[0][i] = val;
        }
    }

    // This method loads the TF lite file
    private static MappedByteBuffer loadModelFile(AssetManager assets, String modelFileName)
            throws IOException{
        AssetFileDescriptor fileDescriptor = assets.openFd(modelFileName);
        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());
        FileChannel fileChannel = inputStream.getChannel();
        long startOffset = fileDescriptor.getStartOffset();
        long declaredLength = fileDescriptor.getDeclaredLength();
        return fileChannel.map(FileChannel.MapMode.READ_ONLY,startOffset,declaredLength);
    }
    // To open history page
    public void openHistoryPage(){
        ViewPager viewPager = getActivity().findViewById(R.id.view_pager);
        viewPager.setCurrentItem(2);
    }
}
```
```
E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.example.se, PID: 5777
    java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Failed to initialize TensorFlow context: subgraphs is null
    Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.
    Node number 2 (FlexSize) failed to prepare.
    
        at com.example.se.Classify.onCreateView(Classify.java:138)
        at androidx.fragment.app.Fragment.performCreateView(Fragment.java:2600)
        at androidx.fragment.app.FragmentManagerImpl.moveToState(FragmentManagerImpl.java:881)
        at androidx.fragment.app.FragmentManagerImpl.moveFragmentToExpectedState(FragmentManagerImpl.java:1238)
        at androidx.fragment.app.FragmentManagerImpl.moveToState(FragmentManagerImpl.java:1303)
        at androidx.fragment.app.BackStackRecord.executeOps(BackStackRecord.java:439)
        at androidx.fragment.app.FragmentManagerImpl.executeOps(FragmentManagerImpl.java:2079)
        at androidx.fragment.app.FragmentManagerImpl.executeOpsTogether(FragmentManagerImpl.java:1869)
        at androidx.fragment.app.FragmentManagerImpl.removeRedundantOperationsAndExecute(FragmentManagerImpl.java:1824)
        at androidx.fragment.app.FragmentManagerImpl.execSingleAction(FragmentManagerImpl.java:1696)
        at androidx.fragment.app.BackStackRecord.commitNowAllowingStateLoss(BackStackRecord.java:299)
        at androidx.fragment.app.FragmentPagerAdapter.finishUpdate(FragmentPagerAdapter.java:235)
        at androidx.viewpager.widget.ViewPager.populate(ViewPager.java:1244)
        at androidx.viewpager.widget.ViewPager.populate(ViewPager.java:1092)
        at androidx.viewpager.widget.ViewPager.onMeasure(ViewPager.java:1622)
        at android.view.View.measure(View.java:25466)
        at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:6957)
        at androidx.coordinatorlayout.widget.CoordinatorLayout.onMeasureChild(CoordinatorLayout.java:760)
        at com.google.android.material.appbar.HeaderScrollingViewBehavior.onMeasureChild(HeaderScrollingViewBehavior.java:99)
        at com.google.android.material.appbar.AppBarLayout$ScrollingViewBehavior.onMeasureChild(AppBarLayout.java:2003)
        at androidx.coordinatorlayout.widget.CoordinatorLayout.onMeasure(CoordinatorLayout.java:831)
        at android.view.View.measure(View.java:25466)
        at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:6957)
        at android.widget.FrameLayout.onMeasure(FrameLayout.java:194)
        at androidx.appcompat.widget.ContentFrameLayout.onMeasure(ContentFrameLayout.java:146)
        at android.view.View.measure(View.java:25466)
        at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:6957)
        at android.widget.LinearLayout.measureChildBeforeLayout(LinearLayout.java:1552)
        at android.widget.LinearLayout.measureVertical(LinearLayout.java:842)
        at android.widget.LinearLayout.onMeasure(LinearLayout.java:721)
        at android.view.View.measure(View.java:25466)
        at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:6957)
        at android.widget.FrameLayout.onMeasure(FrameLayout.java:194)
        at android.view.View.measure(View.java:25466)
        at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:6957)
        at android.widget.LinearLayout.measureChildBeforeLayout(LinearLayout.java:1552)
        at android.widget.LinearLayout.measureVertical(LinearLayout.java:842)
        at android.widget.LinearLayout.onMeasure(LinearLayout.java:721)
        at android.view.View.measure(View.java:25466)
        at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:6957)
        at android.widget.FrameLayout.onMeasure(FrameLayout.java:194)
        at com.android.internal.policy.DecorView.onMeasure(DecorView.java:747)
        at android.view.View.measure(View.java:25466)
        at android.view.ViewRootImpl.performMeasure(ViewRootImpl.java:3397)
        at android.view.ViewRootImpl.measureHierarchy(ViewRootImpl.java:2228)
        at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2486)
        at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1952)
        at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:8171)
E/AndroidRuntime:     at android.view.Choreographer$CallbackRecord.run(Choreographer.java:972)
        at android.view.Choreographer.doCallbacks(Choreographer.java:796)
        at android.view.Choreographer.doFrame(Choreographer.java:731)
        at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:957)
        at android.os.Handler.handleCallback(Handler.java:938)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at android.os.Looper.loop(Looper.java:223)
        at android.app.ActivityThread.main(ActivityThread.java:7656)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)
     Caused by: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Failed to initialize TensorFlow context: subgraphs is null
    Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.
    Node number 2 (FlexSize) failed to prepare.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegates(NativeInterpreterWrapper.java:367)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:85)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:277)
        at com.example.se.Classify.onCreateView(Classify.java:135)
        	... 58 more
```
"
48919,cannot build TensorFLow with --config=dbg,"when building opensource  TensorFlow with

bazel build --config=dbg  --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/tools/pip_package:build_pip_package

(for SM 7.0 only)

The build dies at link time with:

`ERROR: /home/baarts/tensorflow-GH/tensorflow/python/BUILD:3373:24: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-dbg/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(AnnotationRemarks.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(BDCE.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(CallSiteSplitting.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(ConstantHoisting.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(ConstraintElimination.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(CorrelatedValuePropagation.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(DCE.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(DeadStoreElimination.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(DivRemPairs.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(EarlyCSE.pic.o):(.debug_aranges+0x6): relocation truncated to fit: R_X86_64_32 against `.debug_info'
bazel-out/k8-dbg/bin/external/llvm-project/llvm/libScalar.a(FlattenCFGPass.pic.o):(.debug_aranges+0x6): additional relocation overflows omitted from the output
collect2: error: ld returned 1 exit status`

Adding -mcmodel=large makes no difference, as the overflow is in a debug section.
I tried -gdwarf64 which is not supported by gcc

some platform info:
```
root@7fe23091cb5b:/opt/tensorflow# gcc --version
gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

root@7fe23091cb5b:/opt/tensorflow# uname -a
Linux 7fe23091cb5b 4.15.0-72-generic #81-Ubuntu SMP Tue Nov 26 12:20:02 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
```"
48916,No gradients exist for a sub-classed model,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  binary
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.8.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: using CPU
- GPU model and memory: using CPU

**Describe the current behavior**
No gradients provided for any variable of a simple subclassed model. The weights are not zero. 

**Describe the expected behavior**
The gradients for all the variables should exist

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): No - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
The full model is quite large/complex, in the full architecture, this basic block is the only part of the model that throws this issue. It is the most fundamental part of the architecture.

For google colab:
Add this to ""My Drive"" on google drive:
https://drive.google.com/drive/folders/1epROVNfvO10Ksy8CwJQdamSK96JZnWW9?usp=sharing
and then run the code: 
https://colab.research.google.com/drive/18sMqNn8IpTQLZBlInWSbX0ITd2GWDDkz?usp=sharing

```
class BasicBlock(tf.keras.Model):
        def __init__(self, ncIn, ncOut, batchNorm_type=0, strides=(1,1), dynamic=True, name=None):
        super(BasicBlock, self).__init__(dynamic=True)
        self.ncIn = ncIn
        self.ncOut = ncOut
        self.conv_1 = SeparableConv2D(self.ncOut, kernel_size=(1,1), strides=(1,1), padding=""same"", use_bias=False, name=f'BB_conv_1_{name}')
        self.conv_2 = SeparableConv2D(self.ncOut, kernel_size=(1,1), strides=(1,1), padding=""same"", use_bias=False, name=f'BB_conv_2_{name}') 
        self.bn = BatchNormalization(name=f'BN_0_{name}')
        def call(self, inputs):
            x = inputs[0]
            out = self.conv_1(x)
            out = self.bn(out)
            out = Activation('relu')(out) 
            out = self.conv_2(out)
            out = self.bn(out) 
            out = Activation('relu')(out)
            return out 
```

For the network architecture itself  and,

```        
        epoch = 0
        optimizer = Adam()
        bb = BasicBlock(1, 32)

        while True:
            real_samples = self.generate_real_samples(n_batch, n_patch)
            [X_real_img, X_real_sh, X_gt_sh], y_real = real_samples
            X_real_img = np.concatenate(X_real_img)
            X_target_sh = np.concatenate(X_real_sh)
            X_gt_sh = np.concatenate(X_gt_sh)
            
            with tf.GradientTape() as tape:
                test = bb([X_real_img])
                loss_value = MSE(X_gt_sh, X_target_sh) #dummy loss

            #retrieve gradients of trainable variables w.r.t the loss
            grads = tape.gradient(loss_value, bb.trainable_weights)
            #Run SGD
            optimizer.apply_gradients(zip(grads, bb.trainable_weights))
```

for the training.

**Other info / logs** Include any logs or source code that would be helpful to

`ValueError: No gradients provided for any variable: ['basic_block_8/BB_conv_1_None/depthwise_kernel:0', 'basic_block_8/BB_conv_1_None/pointwise_kernel:0', 'basic_block_8/BB_conv_2_None/depthwise_kernel:0', 'basic_block_8/BB_conv_2_None/pointwise_kernel:0', 'basic_block_8/BN_0_None/gamma:0', 'basic_block_8/BN_0_None/beta:0']`

"
48915,Dynamic Input support for TFLite models,"Hello Tensors
I have a TF model with (None,None,100) input dims and its converted into TFLite too.
But when I do inference, it gives error-
RuntimeError: tensorflow/lite/kernels/reshape.cc:58 stretch_dim != -1 (0 != -1)Node number 72 (RESHAPE) failed to prepare.

**System information**
- TensorFlow version (you are using): 2.4.1.

**Describe the feature and the current behavior/state.**
Currently, 0th index can be dynamic(None or -1).

**Will this change the current api? How?**
Other indexs of model input can be dynamic(None or -1)

**Who will benefit with this feature?**
Generally, Vision models have 0th index dynamic but NLP models have other dimensions as dynamic.
"
48914,MIRROR PAD result mixed,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 20
- TensorFlow installed from (source or binary):binary
- TensorFlow version (or github SHA if from source):2.4



When I tested the mirror pad, I found that the result was a bit unexpected.
The input shape of pad is [1,1,2,2], paddings[[0, 0], [0, 0], [3, 3], [3, 3]],pad mode: SYMMETRIC.
I know that my parameters may not be in line with the correct usage of pad, but I want to know whether his result is caused by a bug or if I run it incorrectly.

### model [file](https://www.notion.so/tflite-pad-symmetric-mode-bb313fc05adc497cae4d719896da70f4)

###The wrong result:
![image](https://user-images.githubusercontent.com/39184746/117141626-588fd480-ade1-11eb-8bd3-4c57e341d761.png)

If i had took a mistake, please tell me how to fix it ! THX :p"
48913,Custom Tensorflow optimizer cSGLD (Stochastic Langevin Dynamics) in TF2: correct update ops? ,"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.2
Python version: 3.6.9
CUDA/cuDNN version: v10.2
GPU model and memory: GeForce GTX 1070 - 8117MiB

Describe the current behavior:

I implemented Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning as a custom optimizer in TF2. While it does run, I am not exactly sure about my implementation since the documentation for Tensorflow optimizers is almost non-existent... I would appreciate any help!
For your reference the pytorch implementation (WAY simpler) is here: https://github.com/ruqizhang/csgmcmc/blob/master/experiments/cifar_csgmcmc.py

Describe the bug

It's not so much a bug, rather asking advice on how to implement the noisy update in TF2 for stochastic gradient langevin dynamics without preconditioning. In Addons there is the TF1 only example of preconditioned SGLD, whereas I want to make it work for TF2.

Code to reproduce the issue

See the implementation with a running example here:
https://colab.research.google.com/drive/16kwhGfiat-SkK0RWvf4EADZC_FDVudL8?usp=sharing

If you use momentum (i.e. alpha < 1), then the implementation does not work.
I think the community would benefit from having access to this example (once working). Since there is no Tensorflow implementation yet of Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning."
48912,Question about tf.distribute.strategy,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch

## Description of issue (what needs changing):
Confused on how the losses get added up

### Clear description

I had one additional question for this line in documentation  (training_loss.update_state(loss * strategy.num_replicas_in_sync)
Why do we multiply the loss by number of replicas. I understand the gradients get added up but what happens to the loss. Does that get added up?
If not, s this randomly choosing the loss on one replica and multiplying by the number of replicas?

```
@tf.function
def train_multiple_steps(iterator, steps):
  """"""The step function for one training step""""""

  def step_fn(inputs):
    """"""The computation to run on each TPU device.""""""
    images, labels = inputs
    with tf.GradientTape() as tape:
      logits = model(images, training=True)
      loss = tf.keras.losses.sparse_categorical_crossentropy(
          labels, logits, from_logits=True)
      loss = tf.nn.compute_average_loss(loss, global_batch_size=batch_size)
    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))
    training_loss.update_state(loss * strategy.num_replicas_in_sync)
    training_accuracy.update_state(labels, logits)

  for _ in tf.range(steps):
```

### Correct links

Is the link to the source code correct?
yes

### Parameters defined

Are all parameters defined and formatted correctly?
yes

### Returns defined

Are return values defined?
yes

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

Yes
### Usage example

Is there a usage example?

Yes

### Request visuals, if applicable
Not applicable

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
48910,How does the tf.raw_ops.Timestamp operator get unix time? Can we manipulate the timestamp by changing device time for tf.raw_ops.Timestamp operator?,"According to tensorflow documentation, the tf.raw_ops.Timestamp operator returns the timestamp as a float64 for seconds since the Unix epoch. I got a question when using the tf.raw_ops.Timestamp operator: what if users change the device time when they do inference? Can we manipulate the timestamp it returns by change the system time? Specifically, if a user do inference on a phone and changes the time of his phone, can this operator still return the current time?

A follow-up question: how does the tf.raw_ops.Timestamp operator get Unix time? From software (e.g, phone's operating system) or hardware?

Jaesung Chung from tflite team has kindly pointed the [source file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/default/env_time.cc#L25) of how tf gets the time. But I found it hard to answer my questions from the file. Code in the source file:

```
#include <sys/time.h>
#include <time.h>

#include ""tensorflow/core/platform/env_time.h""

namespace tensorflow {

/* static */
uint64 EnvTime::NowNanos() {
  struct timespec ts;
  clock_gettime(CLOCK_REALTIME, &ts);
  return (static_cast<uint64>(ts.tv_sec) * kSecondsToNanos +
          static_cast<uint64>(ts.tv_nsec));
}

}  // namespace tensorflow
```"
48908,tflite::Intepreter move constructor,"`tflite::Interpeter` doesn't have a move constructor.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/interpreter.h

Because of this it's more difficult to make a resource pool of `Interpeter`s which is itself desirable because `Interpeter` is not itself threadsafe, and the critical piece which is needed once-per-thread, and is simultaneously expensive to build.

**System information**
- TensorFlow version (you are using): latest
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Currently move is not possible. Move would is desirable.

**Will this change the current api? How?**
Adds constructor to `tflite::Interpeter` so technically it's an API change, but it's backward compatible.

**Who will benefit with this feature?**
Anyone attempting to use many `tflite::Interpeter`s in parallel.

**Any Other info.**
First pass glance at the code suggests that implementation likely be trivial.
"
48907,Compact Multi-Class Boosted Trees,"<em>The issue related to the performance of the [BoostedTree](https://github.com/tensorflow/estimator/blob/781c0d30c6bf100aa174591dd97cb70fc39d294d/tensorflow_estimator/python/estimator/canned/boosted_trees_test.py#L403) classifier in terms of accuracy.</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Linux Ubuntu 16.04, Windows 10
- TensorFlow installed from (source or binary): pip install TensorFlow 
- TensorFlow version (use command below): 2.4.1
- Python version: 3.6

**Describe the model**
BoostedTree classifier is a model introduced by [N Ponomareva, T Colthurst, G Hendry.2017](https://ieeexplore.ieee.org/abstract/document/8257910).
It is built over the Xgboost idea and learning is done through building one layer of decision tree regressor over N boosting iteration.


**Describe the expected behavior**
As the related paper discovered, for ten trees, the accuracy of the xgboost is about 60%, and for the TF model is 73%.
This experiment had done over the Cover type dataset.
**Describe the current behavior**
I did the same [experiments](https://github.com/samanemami/TFBoostedTree/blob/main/examples/Comparison.ipynb) over the same dataset and identical configuration, but the results have a huge difference.
In this experiment, the accuracy of xgboost is about 70%, and the TF model score is about 58 percent.
It is worthy to note the fact the logistic regression at least achieves 70 percent.

About the training time, if you plot the training time over boosting iteration you will have a Neutral trend which should be linear as the gradient boosting is a linear ensemble mode.

**Standalone code to reproduce the issue**
I reproduced the model [here](https://github.com/samanemami/TFBoostedTree/blob/main/TFBT.py).
Also, you may find the related experiments [here](https://github.com/samanemami/TFBoostedTree/tree/main/examples)."
48903,tf.data.experimental.snapshot segfault when using repeat and prefetch,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Centos 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): 2.4.0
- TensorFlow version (use command below): 2.4.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Using the following simple script, we can see a segmentation fault:
```python
import tensorflow as tf
import numpy as np
dataset = tf.data.Dataset.from_tensor_slices(np.random.rand(16, 1024))
dataset = dataset.apply(
    tf.data.experimental.snapshot('snapshot'))
dataset = dataset.shuffle(buffer_size=16)
dataset = dataset.batch(16)
dataset = dataset.repeat()
dataset = dataset.prefetch(1)
def run(dataset):
    iterator = iter(dataset)
    for _ in range(30):
        next(iterator)
for _ in range(10):
    run(dataset) 
```
If we run it with Tensorflow 2.4.0 (or Tensorflow 2.4.1), the output is:
```
...
2021-05-04 11:04:17.989897: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-04 11:04:17.990504: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2596985000 Hz
Segmentation fault (core dumped)
```
If either of `snapshot` or `repeat` or `prefetch` is removed, this would not occur.

**Describe the expected behavior**
The expected behavior is that there would not be a segmentation fault
**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - yes
Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
import numpy as np
dataset = tf.data.Dataset.from_tensor_slices(np.random.rand(16, 1024))
dataset = dataset.apply(
    tf.data.experimental.snapshot('snapshot'))
dataset = dataset.shuffle(buffer_size=16)
dataset = dataset.batch(16)
dataset = dataset.repeat()
dataset = dataset.prefetch(1)
def run(dataset):
    iterator = iter(dataset)
    for _ in range(30):
        next(iterator)
for _ in range(10):
    run(dataset) 
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Analyzing the core dump, this is the truncated stack trace:
```
#0  0x00007fa2236c08af in tensorflow::data::experimental::SnapshotDatasetV2Op::Dataset::Iterator::Reader::~Reader() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#1  0x00007fa2236c0971 in tensorflow::data::experimental::SnapshotDatasetV2Op::Dataset::Iterator::Reader::~Reader() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007fa2236c04aa in tensorflow::data::experimental::SnapshotDatasetV2Op::Dataset::Iterator::~Iterator() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007fa2222eefee in tensorflow::data::MapDatasetOp::Dataset::Iterator::~Iterator() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007fa222335867 in tensorflow::data::ShuffleDatasetOpBase::ShuffleDatasetBase::Iterator::~Iterator() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007fa2222c13a9 in tensorflow::data::BatchDatasetOp::Dataset::Iterator::~Iterator() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007fa22232b529 in tensorflow::data::RepeatDatasetOp::Dataset::ForeverIterator::~ForeverIterator() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007fa223e7e385 in tensorflow::data::PrefetchDatasetOp::Dataset::Iterator::~Iterator() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007fa223771615 in tensorflow::data::experimental::(anonymous namespace)::MaxIntraOpParallelismDatasetOp::Dataset::Iterator::~Iterator() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007fa2222fb665 in tensorflow::data::ModelDatasetOp::Dataset::Iterator::~Iterator() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#10 0x00007fa223e441ab in std::_Sp_counted_ptr_inplace<tensorflow::data::IteratorResource::State, std::allocator<tensorflow::data::IteratorResource::State>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#11 0x00007fa21d44b1f6 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#12 0x00007fa223e4dc62 in tensorflow::data::IteratorResource::~IteratorResource() () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#13 0x00007fa223e4dd51 in tensorflow::data::IteratorResource::~IteratorResource() () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#14 0x00007fa2199ac086 in tensorflow::ResourceMgr::ResourceAndName::~ResourceAndName() () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#15 0x00007fa2199ae73f in tensorflow::ResourceMgr::DoDelete(std::string const&, unsigned long long, std::string const&, std::string const&) ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#16 0x00007fa2199aeb89 in tensorflow::ResourceMgr::Delete(tensorflow::ResourceHandle const&) ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#17 0x00007fa223e4f684 in tensorflow::data::DeleteIteratorOp::DoCompute(tensorflow::OpKernelContext*) ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#18 0x00007fa223e444b1 in tensorflow::data::HybridAsyncOpKernel::Compute(tensorflow::OpKernelContext*) ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#19 0x00007fa22396409b in tensorflow::KernelAndDeviceOp::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector<absl::lts_2020_02_25::variant<tensorflow::Tensor, tensorflow::TensorShape>, std::allocator<absl::lts_2020_02_25::variant<tensorflow::Tensor, tensorflow::TensorShape> > >*, tensorflow::CancellationManager*, absl::lts_2020_02_25::optional<tensorflow::EagerRemoteFunctionParams> const&) ()
   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#20 0x00007fa22391f359 in tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::lts_2020_02_25::InlinedVector<tensorflow::TensorHandle*, 4ul, std::allocator<tensorflow::TensorHandle*> > const&, absl::lts_2020_02_25::optional<tensorflow::EagerRemoteFunctionParams> const&, std::unique_ptr<tensorflow::KernelAndDevice, tensorflow::core::RefCountDeleter> const&, tensorflow::GraphCollector*, tensorflow::CancellationManager*, absl::lts_2020_02_25:
:Span<tensorflow::TensorHandle*>) () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#21 0x00007fa2239202c0 in tensorflow::ExecuteNode::Run() () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#22 0x00007fa22395d14f in tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) ()
```"
48902,_pywrap_tensorflow_internal.so is enormous,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow version: 2.3
- Python version:  3.8
- Installed using virtualenv? pip? conda?: virtualenv and pip3

**Describe the problem**

`_pywrap_tensorflow_internal.so` is 591MB. Based on #40492 it sounds like there was some expectation that it would get smaller, but instead it seems to be getting larger. That issue was unfortunately closed with no action taken.

"
48901,There's no way to pass class labels from list in tf.keras.preprocessing.image_dataset_from_directory using this,"If there're no subfolders and labels to preprocessing.image_dataset_from_directory function are passed from external list this part of code will generate empty 'results' variable and further in line 88-98 this will lead to an error of not finding any files.
But if there's at least one subfolder the same code will lead to labels being inherited from subfolder name.
This means labels at all times behave as ""inferred"" and there's no option to pass labels from list in preprocessing.image_dataset_from_directory that uses this function. 

https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/preprocessing/dataset_utils.py#L84"
48898,I am still having this issue...,"@HaraBeron This is a know bug with `accuracy`. In earlier TF versions `accuracy` was correctly inferred from the `loss` function. In this case, `accuracy` need to be inferred as `sparse_categorical_accuracy` but in the current version it is not working as expected.

Everything works as expected If you replace `accuracy` with `sparse_categorical_accuracy` in `model.compile` as shown below.

```
model.compile(optimizer='adam',
              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['sparse_categorical_accuracy'])
```



_Originally posted by @jvishnuvardhan in https://github.com/tensorflow/tensorflow/issues/42890#issuecomment-685998646_




Can someone please help me about the above? I already trained a few models with TF=2.3.0, then when I tried loading the model to print some ROC curves, I got zero-accuracy across everything. I tried to compile with 'sparse_categorical_accuracy' as referenced above after I load_model, but it did not work.. Do I have to re-train all my models because of this bug?

Please help"
48896,Issue,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - Briefly describe your candidate solution
(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48895,"Couldnot visualize convnet's internals, TypeError: Cannot convert a symbolic Keras input/output to a numpy array. Same for keras-vis and Kaggle kernel","Firstly I was checking [this notebook][1] from Kaggle, and for some reason I couldn't reproduce the **Visualizing Filter Patterns of Convolution layers** section of this notebook.

I am getting this error:

```
During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)

TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.


During handling of the above exception, another exception occurred:

RecursionError                            Traceback (most recent call last)

RecursionError: maximum recursion depth exceeded


The above exception was the direct cause of the following exception:

TypeError                                 Traceback (most recent call last)

/usr/lib/python3.7/inspect.py in getfullargspec(func)
   1130         # else. So to be fully backwards compatible, we catch all
   1131         # possible exceptions here, and reraise a TypeError.
-> 1132         raise TypeError('unsupported callable') from ex
   1133
   1134     args = []

TypeError: unsupported callable
```



Secondly, I tried to use the [Keras blog tutorial][2],

I get this error,

```
      4
----> 5 loss, img = visualize_filter(0)
      6 keras.preprocessing.image.save_img(""0.png"", img)

6 frames

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in _override_gradient_function(self, gradient_function_map)
   4957
   4958     # This is an internal API and we don't need nested context for this.
-> 4959     assert not self._gradient_function_map
   4960     self._gradient_function_map = gradient_function_map
   4961     yield

AssertionError:
```

Thirdly, I found this amazing [Keras library][3], but with this too, I was unable to get anything.

This was giving same error as the first option.

```

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)

TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.


During handling of the above exception, another exception occurred:

RecursionError                            Traceback (most recent call last)

RecursionError: maximum recursion depth exceeded while calling a Python object


The above exception was the direct cause of the following exception:

TypeError                                 Traceback (most recent call last)

/usr/lib/python3.7/inspect.py in getfullargspec(func)
   1130         # else. So to be fully backwards compatible, we catch all
   1131         # possible exceptions here, and reraise a TypeError.
-> 1132         raise TypeError('unsupported callable') from ex
   1133
   1134     args = []

TypeError: unsupported callable
```

I have seen this issue crop up suddenly here, but not sure if this has any way around or not.


Here is the code for reproducing the errors:


```python3
import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
import numpy as np
import glob
import time
import cv2
import os

#https://drive.google.com/file/d/12q7fPPb9Lb-cL2LJxn2d_dQGHto27PYT/view?usp=sharing
! wget ""https://github.com/Jimut123/simply_junk/raw/main/models/classification_model_blood.h5""

import tensorflow as tf
from keras.regularizers import l2
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D, Flatten, \
                                    GlobalMaxPool2D, Dropout, SpatialDropout2D, add, concatenate
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras.models import Model

# m1_1, m1_2, l1_1, l1_2, m2_1, m2_2, l2_1, l2_2, m3_1, m3_2, m3_1, m3_2, l3_1, l3_2, m4_1,

H, W, C = 360, 360, 3
N_LABELS = 8
D = 1
def Classification(H,W,C):
    
    input_layer = tf.keras.Input(shape=(H, W, C))

    m1_1 = BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=""m1_1"", padding='same')(input_layer))
    m1_2 = BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=""m1_2"", padding='same')(m1_1))
    m1_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=""m1_3"", padding='same')(m1_2)))

    l1_1 = BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=""l1_1"", padding='same')(m1_3))
    l1_2 = BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=""l1_2"", padding='same')(l1_1))
    l1_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=""l1_3"", padding='same')(l1_2)))

    m2_1 = BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=""m2_1"", padding='same')(l1_3))
    m2_2 = BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=""m2_2"", padding='same')(m2_1))
    m2_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=""m2_3"", padding='same')(m2_2)))

    l2_1 = BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=""l2_1"", padding='same')(m2_3))
    l2_2 = BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=""l2_2"", padding='same')(l2_1))
    l2_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=""l2_3"", padding='same')(l2_2)))


    m3_1 = BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=""m3_1"", padding='same')(l2_1))
    m3_2 = BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=""m3_2"", padding='same')(m3_1))
    m3_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=""m3_3"", padding='same')(m3_2)))

    l3_1 = BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=""l3_1"", padding='same')(m3_3))
    l3_2 = BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=""l3_2"", padding='same')(l3_1))
    l3_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=""l3_3"", padding='same')(l3_2)))

    m4_1 = BatchNormalization(axis=-1)(Conv2D(256, 3, activation='relu', strides=(2, 2), name=""m4_1"")(l3_3))
    m4_2 = BatchNormalization(axis=-1)(Conv2D(256, 3, activation='relu', strides=(2, 2), name=""m4_2"")(m4_1))
    # m4_3 = BatchNormalization(axis=-1)(Conv2D(512, 3, activation='relu', strides=(2, 2), name=""m4_3"")(m4_2))
    # m4_4 = BatchNormalization(axis=-1)(Conv2D(512, 3, activation='relu', strides=(2, 2), name=""m4_4"")(m4_3))


    #x = SpatialDropout2D(0.5, name=""dropout_3"")(m4_4)
    x = Flatten(name=""flatten"")(m4_2)
    x = Dense(512, activation='relu', name=""dense_512"")(x)
    x = Dense(N_LABELS, activation='softmax', name=""output_layer"")(x)

    model = tf.keras.models.Model(inputs=input_layer, outputs=x)
    return model


model = Classification(H,W,C)

opt = Adam(learning_rate=1e-5)

model.compile(optimizer=opt,
              loss='categorical_crossentropy',
              metrics= ['accuracy'])

model.summary()


from tensorflow import keras
model = keras.models.load_model('classification_model_blood.h5')

# https://www.kaggle.com/anktplwl91/visualizing-what-your-convnet-learns

# The purpose of this function is to just convert a numpy array to a standard image format, so that it can be displayed and viewed comfortably
def deprocess_image(x):
    
    x -= x.mean()
    x /= (x.std() + 1e-5)
    x *= 0.1
    x += 0.5
    x = np.clip(x, 0, 1)
    x *= 255
    x = np.clip(x, 0, 255).astype('uint8')

    return x

# This function is used to create a loss function that maximizes the value of a given filter in a convolution layer, and then we use SGD to adjust the values of the
# input image so as to maximize this activation value. We pass the layer name and the filter index to the function as arguments. 'loss' is the mean for that particular
# filter, 'grads' is the gradient calculated for this loss with respect to input image. Finally, SGD is run for 80 iterations which continuously maximizes the response
# to input image by adding the gradient. Finally, it uses 'deprocess_image' to convert this array to a representable image format.

def generate_pattern(layer_name, filter_index, size=150):
    
    layer_output = model.get_layer(layer_name).output
    loss = K.mean(layer_output[:, :, :, filter_index])
    grads = K.gradients(loss, model.input)[0]
    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)
    iterate = K.function([model.input], [loss, grads])
    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.
    step = 1.
    for i in range(80):
        loss_value, grads_value = iterate([input_img_data])
        input_img_data += grads_value * step
        
    img = input_img_data[0]
    return deprocess_image(img)



#======================================== Part 1

import os
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import cv2
import matplotlib.pyplot as plt
import keras.backend as K
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Input, Dense, Dropout
from keras.applications.inception_v3 import InceptionV3
from keras.applications.inception_v3 import preprocess_input, decode_predictions

%matplotlib inline

from tensorflow.python.framework.ops import disable_eager_execution
disable_eager_execution()

# Below are the patterns to which the filters from first convolution layer get activated. As we can see these are very basic cross-sectional patterns formed by
# horizontal and vertical lines, which is what the these filters look in the input image and get activated if they find one.
fig = plt.figure(figsize=(2, 2))
for img in range(4):
    ax = fig.add_subplot(2, 2, img+1)
    ax = plt.imshow(generate_pattern('l3_2', img))
    plt.xticks([])
    plt.yticks([])
    fig.subplots_adjust(wspace=0.05, hspace=0.05)






#========================== Part - 2

# 'm1_1', 'm1_2', 'l1_1', 'l1_2', 'm2_1', 'm2_2', 'l2_1', 'l2_2', 'm3_1', 'm3_2', 'm3_1', 'm3_2', 'l3_1', 'l3_2', 'm4_1', 'm4_2'

import numpy as np
import tensorflow as tf
from tensorflow import keras

# The dimensions of our input image
img_width = 360
img_height = 360
# Our target layer: we will visualize the filters from this layer.
# See `model.summary()` for list of layer names, if you want to change this.
layer_name = ""m2_2""


# Set up a model that returns the activation values for our target layer
layer = model.get_layer(name=layer_name)
feature_extractor = keras.Model(inputs=model.inputs, outputs=layer.output)

def compute_loss(input_image, filter_index):
    activation = feature_extractor(input_image)
    # We avoid border artifacts by only involving non-border pixels in the loss.
    filter_activation = activation[:, 2:-2, 2:-2, filter_index]
    return tf.reduce_mean(filter_activation)


@tf.function
def gradient_ascent_step(img, filter_index, learning_rate):
    with tf.GradientTape() as tape:
        tape.watch(img)
        loss = compute_loss(img, filter_index)
    # Compute gradients.
    grads = tape.gradient(loss, img)
    # Normalize gradients.
    grads = tf.math.l2_normalize(grads)
    img += learning_rate * grads
    return loss, img


def initialize_image():
    # We start from a gray image with some random noise
    img = tf.random.uniform((1, img_width, img_height, 3))
    # ResNet50V2 expects inputs in the range [-1, +1].
    # Here we scale our random inputs to [-0.125, +0.125]
    return (img - 0.5) * 0.25


def visualize_filter(filter_index):
    # We run gradient ascent for 20 steps
    iterations = 30
    learning_rate = 10.0
    img = initialize_image()
    for iteration in range(iterations):
        loss, img = gradient_ascent_step(img, filter_index, learning_rate)

    # Decode the resulting input image
    img = deprocess_image(img[0].numpy())
    return loss, img


def deprocess_image(img):
    # Normalize array: center on 0., ensure variance is 0.15
    img -= img.mean()
    img /= img.std() + 1e-5
    img *= 0.15

    # Center crop
    img = img[25:-25, 25:-25, :]

    # Clip to [0, 1]
    img += 0.5
    img = np.clip(img, 0, 1)

    # Convert to RGB array
    img *= 255
    img = np.clip(img, 0, 255).astype(""uint8"")
    return img


from IPython.display import Image, display
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

loss, img = visualize_filter(0)
keras.preprocessing.image.save_img(""0.png"", img)


#======================================== Part 3

! pip install keras-vis

from keras.applications import VGG16

from vis.losses import ActivationMaximization
from vis.regularizers import TotalVariation, LPNorm
from vis.input_modifiers import Jitter
from vis.optimizer import Optimizer
from vis.callbacks import GifGenerator

import tensorflow.compat.v2.feature_column as fc

# Build the VGG16 network with ImageNet weights
#model = VGG16(weights='imagenet', include_top=True)
print('Model loaded.')

# The name of the layer we want to visualize
# (see model definition in vggnet.py)
layer_name = 'm2_2'
layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])
output_class = [1]

losses = [
    (ActivationMaximization(layer_dict[layer_name], output_class), 2),
    (LPNorm(model.input), 10),
    (TotalVariation(model.input), 10)
]
opt = Optimizer(model.input, losses)
opt.minimize(max_iter=500, verbose=True, input_modifiers=[Jitter()], callbacks=[GifGenerator('opt_progress')])

```

Here is the [Colab][4] version. Not sure if this is a bug or not, but mostly it is difficult to perform this operation using our own custom Tensorflow functional models. Any work around would help!

  [1]: https://www.kaggle.com/anktplwl91/visualizing-what-your-convnet-learns
  [2]: https://keras.io/examples/vision/visualizing_what_convnets_learn/
  [3]: https://github.com/raghakot/keras-vis
  [4]: https://colab.research.google.com/drive/13MS7dk4ZA1OgJJVuriCfKR17dAjVIFKj?usp=sharing
"
48890,Build with CUDA support fails with GCC >= 10.3,"**System information**
- OS Platform and Distribution: Ubuntu Linux 21.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.5.0-rc2
- Python version: 3.9
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 10.3
- CUDA/cuDNN version: 11.2 / 8.2

**Describe the problem**

Building tensorflow with CUDA support with GCC 10.3 fails with the following error:
```
/usr/include/c++/10/chrono:428:27: internal compiler error: Segmentation fault
  428 |  _S_gcd(intmax_t __m, intmax_t __n) noexcept
      |                           ^~~~~~
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-10/README.Bugs> for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
```

Apparently, this is a regression starting with GCC 10.3 (default compiler on Ubuntu 21.04) when using gcc in conjunction with nvcc. Here is the upstream bug report: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=100102

Installing and using gcc-9 as NVCC host compiler in `configure` still works."
48889,Which version of gast for TF 2.4?  (Autograph warning),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Centos7
- TensorFlow installed from (source or binary):  Conda install
- TensorFlow version: 2.4.1
- Python version: 3.7
- Installed using virtualenv? pip? conda?: Conda

**Describe the problem**

When training a model, receive ""WARNING: Autograph could not transform..."" ... ""Cause: module 'gast' has no attribute 'Index'""

I have gast 0.4.0 installed.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

model.fit() with custom loss.

Sorry, can't paste long stuff in due to being on offline system.

My real question, do I need to back off to an older gats version?

"
48888,Possible memory leak in eager context's thread_local_data,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
5.10.19-1rodete1-amd64 #1 SMP Debian 5.10.19-1rodete1 (2021-03-11) x86_64 GNU/Linux

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3 binary
- TensorFlow version (use command below): nightly (5/2)
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

v1.12.1-52250-g36e43c933a8 2.5.0-dev20210305

**Describe the current behavior**

Details in https://github.com/tensorflow/agents/issues/569.

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
pip3 install --upgrade tf-nightly
pip3 install --upgrade tf-agents-nightly[reverb]
```
(go to site-local `tf_agents/examples/dqn` directory)
```
python3 dqn_train_eval.py
```

if you edit that python file to `tracemalloc` snapshot on iterations of `learner.run()`, e.g., between iterations 1000 and 5000, you'll see the (possible) memory leak.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48886,Traceback (most recent call last):,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution ( Windows 10 Home ):
- TensorFlow installed from (source ):
- TensorFlow version: don't know 
- Python version: 3.9.4
- Installed using virtualenv? pip? conda?: pip 
- GPU model and memory: AMD Redeon R4 integrated graphics card 4 gb memory 



**Describe the problem**

Traceback (most recent call last):
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\cli\base_command.py"", line 180, in _main
    status = self.run(options, args)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\cli\req_command.py"", line 204, in wrapper
    return func(self, options, args)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\commands\install.py"", line 318, in run
    requirement_set = resolver.resolve(
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py"", line 127, in resolve       
    result = self._result = resolver.resolve(
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_vendor\resolvelib\resolvers.py"", line 473, in resolve
    state = resolution.resolve(requirements, max_rounds=max_rounds)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_vendor\resolvelib\resolvers.py"", line 341, in resolve
    name, crit = self._merge_into_criterion(r, parent=None)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_vendor\resolvelib\resolvers.py"", line 172, in _merge_into_criterion     
    if not criterion.candidates:
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_vendor\resolvelib\structs.py"", line 139, in __bool__
    return bool(self._sequence)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 143, in __bool__
    return any(self)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 129, in <genexpr>
    return (c for c in iterator if id(c) not in self._incompatible_ids)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py"", line 33, in _iter_built
    candidate = func()
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\resolution\resolvelib\factory.py"", line 200, in _make_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 306, in __init__    
    super().__init__(
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 151, in __init__    
    self.dist = self._prepare()
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 234, in _prepare    
    dist = self._prepare_distribution()
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py"", line 317, in _prepare_distribution
    return self._factory.preparer.prepare_linked_requirement(
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\operations\prepare.py"", line 508, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\operations\prepare.py"", line 550, in _prepare_linked_requirement
    local_file = unpack_url(
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\operations\prepare.py"", line 239, in unpack_url
    file = get_http_url(
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\operations\prepare.py"", line 102, in get_http_url
    from_path, content_type = download(link, temp_dir.path)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\network\download.py"", line 157, in __call__
    for chunk in chunks:
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\cli\progress_bars.py"", line 152, in iter
    for x in it:
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_internal\network\utils.py"", line 62, in response_chunks
    for chunk in response.raw.stream(
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_vendor\urllib3\response.py"", line 576, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_vendor\urllib3\response.py"", line 541, in read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\contextlib.py"", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File ""c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages\pip\_vendor\urllib3\response.py"", line 443, in _error_catcher
    raise ReadTimeoutError(self._pool, None, ""Read timed out."")
pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.
WARNING: Ignoring invalid distribution -yqt5-sip (c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages)
WARNING: Ignoring invalid distribution -yqt5-sip (c:\users\lenovo\appdata\local\programs\python\python39\lib\site-packages) 


**Provide the exact sequence of commands/steps that you executed before running into the problem**
`pip install tenserflow`


**Any other info/logs**
Include any logos or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
48885,Docker Hosted automl predict ignores score_threshold param,"I have deployed the .pb file exported out of GCP as per below instructions 
 
https://cloud.google.com/vision/automl/object-detection/docs/containers-gcs-tutorial
 
I am able to get the response but I am getting all predictions with all scores. I tried to limit the responses with below payload and score_threshold. But its still not filtering the response with low scores and seems to be ignoring score_threshold [](url)
 
I followed documentation at here
https://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#google.cloud.automl.v1.PredictRequest
 
 
Place where Docker is hosted: http://localhost:8080/v1/models/default:predict
 
Payload:
{
    ""instances"": [
        {
            ""image_bytes"": {
                ""b64"": ""<base64 image>”
          },
            ""key"": ""your-chosen-image-key123""
        }
    ],
                ""params"": {
                ""score_threshold"": 0.7
            }
}
 "
48884,"TFLite NNApi / GPU causes results to be outputted as 0.0, while on CPU results are correct","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubunto 20.04.2 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 4 / 5
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.4


**Describe the current behavior**

When using the following code:

https://colab.research.google.com/gist/AiaHaruv/906b7d73395ef437f135c81f2c7754e9/filter_issue.ipynb

On the edge device (Pixel 4 or 5), some of the results are reported as 0.0, when GPU or NNAPI delegates are used. 
This is in the context of using TFLite on android, pulling the latest nightly build.
I cannot find any indication as to why this happens. 

Using CPU, or when ran via the normal TF (not lite), this produces correct results

**Describe the expected behavior**

Would expect to receive correct (non 0.0) results when using acceleration 

**Standalone code to reproduce the issue**

https://colab.research.google.com/gist/AiaHaruv/906b7d73395ef437f135c81f2c7754e9/filter_issue.ipynb

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48882,Tensorflow is not detecting  GPU but Pytorch is,"Hi,

I am on Manjaro _5.4.114-1-MANJARO_ kernel. Pytorch is detecting the GPU and using it while training the model but TensorFlow
 is not detecting it.

![image](https://user-images.githubusercontent.com/28386721/116854848-f8990280-ac15-11eb-829c-364d85a3ac5e.png)
"
48881,Tensorflow cpu memory profiling,"
**System information**
- TensorFlow version (you are using): 2.3.1
- Are you willing to contribute it (**Yes**/No):

**Describe the feature and the current behavior/state.**

Tensorflow cpu memory profiling: we want to get detailed profiling as in GPU memory profiling.
(Beginning with a single thread.)
Currently: when running the memory profiler in CPU mode we do not see any memory profile data captured.

**Will this change the current api? How?**
no

**Who will benefit with this feature?**
Anyone profiling memory on CPU and trying to understand the memory behavior of operators.


**Any Other info.**
"
48880,Error occured Bidirectional layer with TPU,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Colab
- TensorFlow version (use command below): Current Colab default (2.4.1)
- Python version: Colab default (3.7.10)
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
('v2.4.1-0-g85c8b2a817f', '2.4.1')

**Describe the current behavior**
There is code below. The problem is error under the specific conditions.

Here are conditions under which an error occurs.
1. On TPU
2. Use Bidirectional layer with ``return_sequence==True``
3. Use tf.keras.layers.Masking or ``mask_zero=True`` with tf.keras.layers.Embedding

Under the triple of upper conditions, training code puts error below.
Without even only one of the conditions, error not occured.
```
InternalError: 9 root error(s) found.
  (0) Internal: {{function_node __inference_train_function_212595}} Compilation failure: RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1343) operand != nullptr 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_1920970171686233974/_5}}]]
	 [[tpu_compile_succeeded_assert/_1920970171686233974/_5/_79]]
  (1) Internal: {{function_node __inference_train_function_212595}} Compilation failure: RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1343) operand != nullptr 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_1920970171686233974/_5}}]]
	 [[tpu_compile_succeeded_assert/_1920970171686233974/_5/_143]]
  (2) Internal: {{function_node __inference_train_function_212595}} Compilation failure: RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1343) operand != nullptr 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_1920970171686233974/_5}}]]
	 [[tpu_compile_succeeded_assert/_1920970171686233974/_5/_159]]
  (3) Internal: {{function_node __inference_train_function_212595}} Compilation failure: RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1343) operand != nullptr 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_1920970171686233974/_5}}]]
	 [[tpu_compile_succeeded_assert/_1920970171686233974/_5/_95]]
  (4) Internal: {{function_node __inference_train_function_212595}} Compilation failure: RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1343) operand != nullptr 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_1920970171686233974/_5}}]]
	 [[tpu_compile_succeeded_assert/_1920970171686233974/_5/_127]]
  (5) Internal: {{function_node __inference_train_function_212595}} Compilation failure: RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1343) operand != nullptr 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_1920970171686233974/_5}}]]
	 [[tpu_compile_succeeded_assert/_1920970171686233974/_5/_63]]
  (6) Internal: {{function_node __inference_train_function_212595}} Compilation failure: RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1343) operand != nullptr 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_1920970171686233974/_5}}]]
	 [[cluster_train_function/control_after/_1/_195]]
  (7) Internal: {{function_node __inference_train_function_212595}} Compilation failure: RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1343) operand != nullptr 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_1920970171686233974/_5}}]]
  (8) Internal: {{function_node __inference_train_function_212595}} Compilation failure: RET_CHECK failure (third_party/tensorflow/compiler/xla/service/dynamic_dimension_inference.cc:1343) operand != nullptr 
 ... [truncated]
```

**Describe the expected behavior**
I expect to works well under the conditions also.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import os
import tensorflow as tf

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=os.environ[""TPU_NAME""])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.TPUStrategy(resolver)

class TestModel(tf.keras.Model):
  def __init__(self):
    super().__init__()

    self.embedding = tf.keras.layers.Embedding(input_dim=6, output_dim=64)
    self.pad_masking = tf.keras.layers.Masking(0, name=""masking"")
    lstm = tf.keras.layers.LSTM(64, return_sequences=True)
    self.lstm = tf.keras.layers.Bidirectional(lstm)
    self.dense = tf.keras.layers.Dense(1)

  def call(self, input, training=None):
    output = self.embedding(input)
    output = self.pad_masking(output)
    output = self.lstm(output)
    output = self.dense(output[:, -1, :])
    return output

with strategy.scope():
  x = tf.data.Dataset.from_tensor_slices([tf.constant([1,2,3,4,5]), tf.constant([1,2,3,4,5]), tf.constant([1,2,3,4,5])])
  y = tf.data.Dataset.from_tensor_slices([[1],[2],[3]])
  dataset = tf.data.Dataset.zip((x,y)).repeat().batch(2)

  model = TestModel()
  model(tf.keras.Input([None]))

  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
                optimizer=tf.keras.optimizers.Adam(1e-4),
                metrics=['accuracy'])
  model.fit(dataset, epochs=10, steps_per_epoch=10)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48879,"How to modify weights in TFLite model and check effect on activation layer output, set_tensor helps only on input layers and not intermediate tensors.","How to modify weights in TFLite model and check effect on activation layer output for experimentation purpose, set_tensor helps reapply things only on input layers and not intermediate tensors.
I am ok doing in offline by extracting output of previous layer and convolving it with the extracted weights and biases of layer in consideration. 
Please share if there is a command for that. Else how can I exactly replicate the convolution and activation process of that particular Resnet50 layer outside the model using python etc.
Using standard Resnet50- keras model, quantised by TFLite converter.

Targetting conv2_block1_2 for experimentation; able to extract output of previous conv block which is input to this (conv2_block1_1) along with weights (ReadVariableOp) and bias of conv2_block1_2 from the TFLite model.

Tensorflow 2.0"
48878,[Custom Layer]ValueError: tf.function-decorated function tried to create variables on non-first call,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Colab**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**
- TensorFlow installed from (source or binary): **Colab**
- TensorFlow version (use command below): **Colab**
- Python version: **Colab**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: **Colab**
- GPU model and memory: **Colab**


## **Describe the current behaviour**
I am trying to implement a custom transformer encoder layer **which I truly believe is the custom layer that is causing the above error**. Apart from the above layer, I have developed 3 more simple custom layers which I didn't mention here to maintain neatness.

### Transformer layer

    class transformer(layers.Layer):
      
      def __init__(self, num_heads, transformer_layers, patch_size):
        super(transformer, self).__init__()
        self.num_heads = num_heads
        self.transformer_layers = transformer_layers
        self.patch_size = patch_size
      
      def call(self, encoded_patches):
        for _ in range(self.transformer_layers):
            x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
            attention_output = layers.MultiHeadAttention(
                num_heads = self.num_heads, key_dim = projection_dim, dropout = 0.1 
            )(x1,x1)
            x2 = attention_output + encoded_patches
            x3 = layers.LayerNormalization(epsilon=1e-6)(x2)
            x3 = mlp(x3, transformer_units, 0.2)
            encoded_patches = x3 + x2
    
        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
        resize_img = layers.Reshape([image_size // self.patch_size, image_size // self.patch_size, 64])(representation)
        
        return resize_img 

### Model 

    def PVT():
    
      # Inputs
      input = layers.Input(shape=input_shape)
      augment = data_augmentation(input)
    
      # Stage 1
      patches_1 = Patch_1(patch_size_1)(augment)
      patches_1 = PatchEncoder(num_patches=(image_size // patch_size_1) ** 2, projection_dim=projection_dim)(patches_1)
      input_2 = transformer(num_heads, transformer_layers, patch_size_1)(patches_1) #Output 1
    
      # Stage 2
      patches_2 = Patch_2(patch_size_2)(input_2)
      patches_2 = PatchEncoder(num_patches=(image_size // patch_size_2) ** 2, projection_dim=projection_dim)(patches_2)
      input_3 = transformer(num_heads, transformer_layers, patch_size_2)(patches_2) #Output 2
    
      # Stage 3
      patches_3 = Patch_3(patch_size_3)(input_3)
      patches_3 = PatchEncoder(num_patches=(image_size // patch_size_3) ** 2, projection_dim=projection_dim)(patches_3)
      input_4 = transformer(num_heads, transformer_layers, patch_size_3)(patches_3) #Output 3
    
      # Stage 4
      patches_4 = Patch_4(patch_size_4)(input_4)
      patches_4 = PatchEncoder(num_patches=(image_size // patch_size_4) ** 2, projection_dim=projection_dim)(patches_4)
      input_5 = transformer(num_heads, transformer_layers, patch_size_4)(patches_4) #Output 4
    
      representation = layers.Flatten()(input_5)
      representation = layers.Dropout(0.5)(representation)
      # Classify outputs.
      logits = layers.Dense(num_classes)(representation)
      # Create the Keras model.  
      model = keras.Model(inputs=input, outputs=logits)
    
      return model

### Compiler and optimizer

    def run_experiment(model):
    
        optimizer = tfa.optimizers.AdamW(
            learning_rate=learning_rate, weight_decay=weight_decay, beta_1=0.9, beta_2=0.999
        )
    
        model.compile(
            optimizer=optimizer,
            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
            metrics=[
                keras.metrics.SparseCategoricalAccuracy(name=""accuracy""),
                keras.metrics.SparseTopKCategoricalAccuracy(5, name=""top-5-accuracy""),
            ],
        )
    
    
        history = model.fit(
            x=xtrain,
            y=ytrain,
            batch_size=batch_size,
            epochs=5,
            validation_split=0.1
        )
    
        model.save('model-5.h5')
    
        return history
    
    pvt = PVT()
    history = run_experiment(pvt)

### Note
I have checked several sources about this but still, I am confused about understanding this error. Before you direct me to other sources, I assure you that I have already checked them all. So I sincerely request you to please provide a clean solution here. By the way, this code is my attempt to reproduce the [Pyramid vision transformers](https://arxiv.org/abs/2102.12122).

### Model summary(FYI)

    Model: ""model_2""
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
    _________________________________________________________________
    data_augmentation (Sequentia (None, 72, 72, 3)         7         
    _________________________________________________________________
    patch_1_2 (Patch_1)          (None, None, 48)          0         
    _________________________________________________________________
    patch_encoder_8 (PatchEncode (None, 324, 64)           23872     
    _________________________________________________________________
    transformer_8 (transformer)  (None, 18, 18, 64)        0         
    _________________________________________________________________
    patch_2_2 (Patch_2)          (None, None, 4096)        0         
    _________________________________________________________________
    patch_encoder_9 (PatchEncode (None, 81, 64)            267392    
    _________________________________________________________________
    transformer_9 (transformer)  (None, 9, 9, 64)          0         
    _________________________________________________________________
    patch_3_2 (Patch_3)          (None, None, 16384)       0         
    _________________________________________________________________
    patch_encoder_10 (PatchEncod (None, 16, 64)            1049664   
    _________________________________________________________________
    transformer_10 (transformer) (None, 4, 4, 64)          0         
    _________________________________________________________________
    patch_4_2 (Patch_4)          (None, None, 65536)       0         
    _________________________________________________________________
    patch_encoder_11 (PatchEncod (None, 4, 64)             4194624   
    _________________________________________________________________
    transformer_11 (transformer) (None, 2, 2, 64)          0         
    =================================================================
    Total params: 5,535,559
    Trainable params: 5,535,552
    Non-trainable params: 7

## **Describe the expected behavior**
To train without any bugs.

## **Standalone code to reproduce the issue**
[Colab Code](https://colab.research.google.com/drive/1o2SWFH74WnmR9Vkz352Zh9R9_fw5lnE5?usp=sharing)

## **Other info/logs** 
```
ValueError                                Traceback (most recent call last)
<ipython-input-15-b64accfa4347> in <module>()
     27     return history
     28 
---> 29 pvt = PVT()
     30 history = run_experiment(pvt)

13 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    975           except Exception as e:  # pylint:disable=broad-except
    976             if hasattr(e, ""ag_error_metadata""):
--> 977               raise e.ag_error_metadata.to_exception(e)
    978             else:
    979               raise

ValueError: in user code:

    <ipython-input-14-e002dca74606>:12 call  *
        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1008 __call__  **
        self._maybe_build(inputs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2710 _maybe_build
        self.build(input_shapes)  # pylint:disable=not-callable
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/normalization.py:1206 build
        experimental_autocast=False)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:639 add_weight
        caching_device=caching_device)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:810 _add_variable_with_custom_getter
        **kwargs_for_getter)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:142 make_variable
        shape=variable_shape if variable_shape else None)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:260 __call__
        return cls._variable_v1_call(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call
        shape=shape)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:67 getter
        return captured_getter(captured_previous, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:731 invalid_creator_scope
        ""tf.function-decorated function tried to create ""

    ValueError: tf.function-decorated function tried to create variables on non-first call.
```
"
48877,Android implementation orientation question,"Hi, I am trying to switch orientation of sample android classification app, and having trouble making screen as full-screen.

I modified menifest xml's orientation from portrait to landscape, but still main cameraview of the app takes just part of the screen, which is not full-screen.
Besides, when I changed orientation from portrait to landscape, logcat returns the warnings which are,
```
Unable to acquire a buffer item, very likely client tried to acquire more than maxImages buffers
```

Is there any guide or things to change to make the app's default orientation as landscape view?

Thanks.

++ 
I found that there exists auto-orient code in CameraConnectionFragment.java, but it does fit to the optimal size with the comparison function, rather than the full screen size."
48876,download error for cars196 dataset when using tfds.load,"It seems ""cars196"" dataset is not available:

(train_ds, val_ds, test_ds), metadata = tfds.load(
    'cars196',
    split=['train[:80%]', 'train[80%:]', 'test'],
    with_info=True
)

**DownloadError**: Failed to get url https://image-net.org/internal/car196/cars_test.tgz. HTTP code: 404."
48875,Understanding distributed strategy loss for tpu training,"I had some questions about distribute strategy custom training. https://www.tensorflow.org/tutorials/distribute/custom_training.

""If you are using regularization losses in your model then you need to scale the loss value by number of replicas. You can do this by using the tf.nn.scale_regularization_loss function.""
Why are regularization loss treated different compared to other type of losses?

""Using tf.reduce_mean is not recommended. Doing so divides the loss by actual per replica batch size which may vary step to step.""
How does the batch size vary step to step per replica? Also, I am not exactly sure why we would not tf.reduce mean if the batch size changes step instead of diving by the global batch size
"
48874,'File' value has no field or method 'append' in in _prune_relocatable_code rule @nccl_archive//:device_pruned:,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mint 20.1, Ubuntu 20.04 base
- TensorFlow installed from (source or binary): Source
- TensorFlow version: origin/r2.5
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: Regular version installed via pip, but that's not the one with the issue
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 9.3
- CUDA/cuDNN version: CUDA 11.3, cuDNN 8
- GPU model and memory: GeForce GT 750M, Driver Version: 418.113
- Clang 12
- NCCL 2.9.6 installled with the local installer off nvidia site

Configure options were CUDA only, CUDA and cuDNN autodetected, python 3.8, GPU capability 3.0, using clang without experimental download, default flags, no android. Running the following line I copied off an online guide:

`bazel build --config=opt --config=cuda --local_resources 2048,.5,1.0 //tensorflow/tools/pip_package:build_pip_package`

I got:
```
WARNING: The following configs were expanded more than once: [cuda_clang, cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
WARNING: Option 'local_resources' is deprecated: --local_resources is deprecated. Please use --local_ram_resources and --local_cpu_resources instead.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=190
INFO: Reading rc options for 'build' from /home/davidoso/Downloads/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/davidoso/Downloads/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /home/davidoso/Downloads/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3.8/dist-packages --python_path=/usr/bin/python3 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.3 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.0 --action_env LD_LIBRARY_PATH=:/usr/local/cuda-11.3/lib64 --config=cuda_clang --action_env CLANG_CUDA_COMPILER_PATH=/usr/local/bin/clang --config=cuda_clang
INFO: Found applicable config definition build:short_logs in file /home/davidoso/Downloads/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/davidoso/Downloads/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:cuda_clang in file /home/davidoso/Downloads/tensorflow/.bazelrc: --config=cuda --repo_env TF_CUDA_CLANG=1 --@local_config_cuda//:cuda_compiler=clang
INFO: Found applicable config definition build:cuda in file /home/davidoso/Downloads/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:cuda_clang in file /home/davidoso/Downloads/tensorflow/.bazelrc: --config=cuda --repo_env TF_CUDA_CLANG=1 --@local_config_cuda//:cuda_compiler=clang
INFO: Found applicable config definition build:cuda in file /home/davidoso/Downloads/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:opt in file /home/davidoso/Downloads/tensorflow/.tf_configure.bazelrc: --copt=-Wno-sign-compare --host_copt=-Wno-sign-compare
INFO: Found applicable config definition build:cuda in file /home/davidoso/Downloads/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:linux in file /home/davidoso/Downloads/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/davidoso/Downloads/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Build options --@local_config_cuda//:cuda_compiler, --action_env, and --repo_env have changed, discarding analysis cache.
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  /home/davidoso/Downloads/tensorflow/WORKSPACE:23:14: in <toplevel>
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace0.bzl:105:34: in workspace
  /home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
Repository rule git_repository defined at:
  /home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
ERROR: /home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/nccl_archive/BUILD.bazel:54:17: in _prune_relocatable_code rule @nccl_archive//:device_pruned: 
Traceback (most recent call last):
	File ""/home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/local_config_nccl/build_defs.bzl"", line 207, column 15, in _prune_relocatable_code_impl
		output.append(outputs)
Error: 'File' value has no field or method 'append'
INFO: Repository pybind11 instantiated at:
  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1068:20: in _tf_repositories
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>
INFO: Repository mkl_dnn_v1 instantiated at:
  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:180:20: in _tf_repositories
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>
INFO: Repository cython instantiated at:
  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:856:20: in _tf_repositories
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>
INFO: Repository jsoncpp_git instantiated at:
  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:693:20: in _tf_repositories
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>
INFO: Repository cudnn_frontend_archive instantiated at:
  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace
  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:157:20: in _tf_repositories
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis of target '@nccl_archive//:device_pruned' failed
INFO: Elapsed time: 679.978s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (363 packages loaded, 16248 targets configured)

```

I specifically notice the one error on the nccl part, copied below to highlight it

```
ERROR: /home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/nccl_archive/BUILD.bazel:54:17: in _prune_relocatable_code rule @nccl_archive//:device_pruned: 
Traceback (most recent call last):
	File ""/home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/local_config_nccl/build_defs.bzl"", line 207, column 15, in _prune_relocatable_code_impl
		output.append(outputs)
Error: 'File' value has no field or method 'append'
```"
48873,Could not initialize EfficientNet with mixed precision policy,"

### System information

-   **Have I written custom code**: yes
-   **OS Platform and Distribution**: Manjaro 21.0.3 Ornara
-   **TensorFlow installed from**: binary
-   **TensorFlow version**: 2.5.0-rc
-   **Python version**: 3.9
-   **CUDA/cuDNN version**: 11.3
-   **GPU model and memory**: RTX 3060 (6GB) [laptop]
-   **Exact command to reproduce**: 
```python
# this does not work
import tensorflow as tf
tf.keras.mixed_precision.set_global_policy('mixed_float16')
model = tf.keras.applications.EfficientNetB0()

# this works
import tensorflow as tf
tf.keras.mixed_precision.set_global_policy('mixed_float16')
model = tf.keras.applications.MobileNetV2()
```

### Describe the problem

Could not initialize EfficientNet model using the command and environment mentioned above. This problem could not be reproduced on google colab with TF version 2.4.1 (it works on colab). Initialization of different model (MobileNetV2) works fine on my laptop (environment above).


### Source code / logs
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
   1244             r_op = getattr(y, ""__r%s__"" % op_name)
-> 1245             out = r_op(x)
   1246             if out is NotImplemented:

~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in r_binary_op_wrapper(y, x)
   1265       #   r_binary_op_wrapper use different force_same_dtype values.
-> 1266       y, x = maybe_promote_tensors(y, x)
   1267       return func(x, y, name=name)

~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in maybe_promote_tensors(force_same_dtype, *tensors)
   1201       promoted_tensors.append(
-> 1202           ops.convert_to_tensor(tensor, dtype, name=""x""))
   1203     return promoted_tensors

~/venv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py in wrapped(*args, **kwargs)
    162           return func(*args, **kwargs)
--> 163       return func(*args, **kwargs)
    164 

~/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1532     if dtype is not None and not dtype.is_compatible_with(value.dtype):
-> 1533       raise ValueError(
   1534           ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %

ValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: <tf.Tensor 'normalization/Cast:0' shape=(None, 224, 224, 3) dtype=float32>

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
<ipython-input-1-11aa21a3e81b> in <module>
      1 import tensorflow as tf
      2 tf.keras.mixed_precision.set_global_policy('mixed_float16')
----> 3 model = tf.keras.applications.EfficientNetB0()

~/venv/lib/python3.9/site-packages/tensorflow/python/keras/applications/efficientnet.py in EfficientNetB0(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)
    533                    classifier_activation='softmax',
    534                    **kwargs):
--> 535   return EfficientNet(
    536       1.0,
    537       1.0,

~/venv/lib/python3.9/site-packages/tensorflow/python/keras/applications/efficientnet.py in EfficientNet(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)
    319   x = img_input
    320   x = layers.Rescaling(1. / 255.)(x)
--> 321   x = layers.Normalization(axis=bn_axis)(x)
    322 
    323   x = layers.ZeroPadding2D(

~/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    967     # >> model = tf.keras.Model(inputs, outputs)
    968     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):
--> 969       return self._functional_construction_call(inputs, args, kwargs,
    970                                                 input_list)
    971 

~/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)
   1105         layer=self, inputs=inputs, build_graph=True, training=training_value):
   1106       # Check input assumptions set after layer building, e.g. input shape.
-> 1107       outputs = self._keras_tensor_symbolic_call(
   1108           inputs, input_masks, args, kwargs)
   1109 

~/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py in _keras_tensor_symbolic_call(self, inputs, input_masks, args, kwargs)
    838       return nest.map_structure(keras_tensor.KerasTensor, output_signature)
    839     else:
--> 840       return self._infer_output_signature(inputs, args, kwargs, input_masks)
    841 
    842   def _infer_output_signature(self, inputs, args, kwargs, input_masks):

~/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py in _infer_output_signature(self, inputs, args, kwargs, input_masks)
    878           self._maybe_build(inputs)
    879           inputs = self._maybe_cast_inputs(inputs)
--> 880           outputs = call_fn(inputs, *args, **kwargs)
    881 
    882         self._handle_activity_regularization(inputs, outputs)

~/venv/lib/python3.9/site-packages/tensorflow/python/keras/layers/preprocessing/normalization.py in call(self, inputs)
    240     mean = array_ops.reshape(self.mean, self._broadcast_shape)
    241     variance = array_ops.reshape(self.variance, self._broadcast_shape)
--> 242     return ((inputs - mean) /
    243             math_ops.maximum(math_ops.sqrt(variance), backend.epsilon()))
    244 

~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
   1248             return out
   1249           except (TypeError, ValueError):
-> 1250             raise e
   1251         else:
   1252           raise

~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
   1232         #   r_binary_op_wrapper use different force_same_dtype values.
   1233         x, y = maybe_promote_tensors(x, y, force_same_dtype=False)
-> 1234         return func(x, y, name=name)
   1235       except (TypeError, ValueError) as e:
   1236         # Even if dispatching the op failed, the RHS may be a tensor aware

~/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    204     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    205     try:
--> 206       return target(*args, **kwargs)
    207     except (TypeError, ValueError):
    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in subtract(x, y, name)
    546 @dispatch.add_dispatch_support
    547 def subtract(x, y, name=None):
--> 548   return gen_math_ops.sub(x, y, name)
    549 
    550 

~/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py in sub(x, y, name)
  10559       pass  # Add nodes to the TensorFlow graph.
  10560   # Add nodes to the TensorFlow graph.
> 10561   _, _, _op, _outputs = _op_def_library._apply_op_helper(
  10562         ""Sub"", x=x, y=y, name=name)
  10563   _result = _outputs[:]

~/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    553                   inferred_from[k] = ""Default in OpDef""
    554 
--> 555             raise TypeError(
    556                 ""%s type %s of argument '%s'."" %
    557                 (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,

TypeError: Input 'y' of 'Sub' Op has type float16 that does not match type float32 of argument 'x'.
```
"
48870,Go generation of protos during install is problematic,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Debian Buster
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.0-rc2
- Python version: 3.8
- Installed using virtualenv? pip? conda?: n/a
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 8.3.0-6
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the problem**

There exists a general issue, of which this specific issue contributes, that installation and use of Tensorflow in Golang is complicated. Use of `go get` to obtain Tensorflow fails.  The reason for this is that the protos need to be generated; see #44655 and discussion that including generated protos would create a maintenance issue.  To resolve this, a user must fetch the repo and then issue the following command:

```sh
go generate github.com/tensorflow/tensorflow/tensorflow/go/op
```

This results in two problems:

1. The `go generate` command errors and completes with a non-zero exit status:

```
../genop/internal/api_def_map.go:34:2: no required module provides package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/api_def_go_proto; to add it:
        go get github.com/tensorflow/tensorflow/tensorflow/go/core/framework/api_def_go_proto
../genop/internal/api_def_map.go:35:2: no required module provides package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/op_def_go_proto; to add it:
        go get github.com/tensorflow/tensorflow/tensorflow/go/core/framework/op_def_go_proto
generate.go:18: running ""go"": exit status 1
```

2. The generated protos are written to a vendor directory (`tensorflow/go/vendor`), although Go will not search for them there. The `vendor` directory is not meant for adding arbitrary modules (see [https://github.com/golang/go/issues/29079](https://github.com/golang/go/issues/29079)).  Thus, the contents must be manually relocated from the vendor directory to `tensorflow/go`.

### Proposed resolution

To make installation more straightforward, I propose that the protos be output in their correct location with the source tree (not in `vendor`).  Indeed, `tensorflow/go/op/generate.go` does this to some extent now, overwriting `wrappers.go` in the source tree. 

"
48869,"Flag TF_GPU_ALLOCATOR=cuda_malloc_async ( to work with large tensors),  results in: "" Error in py_call_impl(callable, dots$args, dots$keywords) :    InternalError: No allocator statistics ""","

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): my code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10/Rstudio
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): ""v2.5.0-rc0-36-g0d1805aede0""
- Python version: 3.7.3

- CUDA/cuDNN version: 11.2.1
- GPU model and memory: 3070/8G



**Describe the current behavior**
To work with large files, like 3GB, it returns an error asking for setting that flag. 
The flat set, TF_GPU_ALLOCATOR=cuda_malloc_async , it can handle the
object fine, but tensorflow no longer is able to run training, or load
saved models, even from keras.applications

**Describe the expected behavior**
Load models without any error

**Standalone code to reproduce the issue**
on rstudio, but i belive would be the same on python 

a<- application_densenet121(input_shape = c(256,256,3), include_top = F)

2021-05-02 07:59:46.375811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2021-05-02 07:59:46.376160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-05-02 07:59:46.376323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-02 07:59:46.376479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 
2021-05-02 07:59:46.376581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N 
 Error in py_call_impl(callable, dots$args, dots$keywords) : 
  InternalError: No allocator statistics 

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

This error, "" Error in py_call_impl(callable, dots$args, dots$keywords) : 
  InternalError: No allocator statistics ""
happens in many other circunstancies, loading saved model, or even to run any model.

happend on tf 2.5.0-rc1/ 2.5.0-rc2/2.4.1. If disable the flag, the error doesnt happen, but 
tensorflow cant handle larger tensors, like images over 2GB.


"
48868,"""Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found""","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.4.0
- Python version: 3.8.8
- Installed using virtualenv? pip? conda?: pip inside a virtualenv.
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: v11.0.3_451.82 / cudnn-11.0-windows-x64-v8.0.4.30.zip
- GPU model and memory: 2080 8G
-Nvidia driver version: 465.89


**Describe the problem**

A similar issue as to #46606, #43193, and #45055. When attempting to run `python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""`, I get the following trace;

`2021-05-02 16:52:00.618495: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-05-02 16:52:00.618653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-05-02 16:52:02.101881: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-02 16:52:02.102613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-05-02 16:52:02.130031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.845GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.23GiB/s
2021-05-02 16:52:02.130365: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-05-02 16:52:02.130609: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2021-05-02 16:52:02.130862: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2021-05-02 16:52:02.131045: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2021-05-02 16:52:02.131225: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2021-05-02 16:52:02.131484: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found
2021-05-02 16:52:02.131796: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2021-05-02 16:52:02.132066: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2021-05-02 16:52:02.132188: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-05-02 16:52:02.132804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-02 16:52:02.133414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-02 16:52:02.133546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]
2021-05-02 16:52:02.133646: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
tf.Tensor(-115.45033, shape=(), dtype=float32)`

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I continue to get the above issue despite following the steps and suggestions in each of the other similar issues.

I tried adding the environmental variables through cmd, which wasn't mirrored in the GUI so I added them there as well. This did not fix the issue.

I re-installed the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019. This did not fix the issue.

I enabled long paths. This did not fix the issue.

I was already on a 64bit release of Python 3.8.8, which the venv I'm using was created with.

I've restarted the terminal and restarted my PC several times, which did not fix the issue.

I created the C:\tools\cuda folder and extracted the contents of the cuDNN there, and ensured that it was on PATH. This confuses me since it's not mentioned as a necessity in the installation process of cuDNN itself. Either way, this did not fix the issue.

**Any other info / logs**
deviceQuery running.
![image](https://user-images.githubusercontent.com/16676174/116808189-0c872a80-ab6a-11eb-995e-87fd672736f8.png)
All the items in PATH.
![image](https://user-images.githubusercontent.com/16676174/116808218-30e30700-ab6a-11eb-86e8-8ea6e6caae1e.png)
The contents of the CUDA bin folder, showing the supposedly missing files exist.
![image](https://user-images.githubusercontent.com/16676174/116808272-7dc6dd80-ab6a-11eb-9561-18d6b2edc3be.png)

Thank you in advance for your help.
"
48867,Issues serializing model (resource conversion),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.8
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 11.2
- GPU model and memory: T4 16GB

**Describe the current behavior**

When attempting to serialize my model using model.save(), I get the following warnings/errors:

```
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fe87653dc50>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fe87653dc50>, because it is not built.
WARNING:absl:Found untraced functions such as concatenate_layer_call_and_return_conditional_losses, concatenate_layer_call_fn, resnet_block_layer_call_and_return_conditional_losses, resnet_block_layer_call_fn, resnet_block_1_layer_call_and_return_conditional_losses while saving (showing 5 of 365). These functions will not be directly callable after loading.
WARNING:absl:Found untraced functions such as concatenate_layer_call_and_return_conditional_losses, concatenate_layer_call_fn, resnet_block_layer_call_and_return_conditional_losses, resnet_block_layer_call_fn, resnet_block_1_layer_call_and_return_conditional_losses while saving (showing 5 of 365). These functions will not be directly callable after loading.

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    521                 as_ref=input_arg.is_ref,
--> 522                 preferred_dtype=default_dtype)
    523         except TypeError as err:

27 frames
ValueError: Tensor conversion requested dtype resource for Tensor with dtype float32: <tf.Tensor 'Adam/beta_1/Read/ReadVariableOp:0' shape=() dtype=float32>

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    543           if input_arg.type != types_pb2.DT_INVALID:
    544             raise TypeError(""%s expected type of %s."" %
--> 545                             (prefix, dtypes.as_dtype(input_arg.type).name))
    546           else:
    547             # Update the maps with the default, if needed.

TypeError: Input 'resource' of 'AssignVariableOp' Op has type float32 that does not match expected type of resource.
```

I'm not sure what the warning about the batchnorm layer means and if it's relevant to the error. From #47479 it the warnings about untraced functions can be safely ignored. It seems odd though that it would error out on the beta parameter of the adam optimizer. Can someone clarify what this float32 -> resource conversion is and why it could fail? I'm unfamiliar with the concept of a ""resource"" and documentation is rather open ended.

**Describe the expected behavior**
The layer should properly serialize

**Standalone code to reproduce the issue**

```
tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs)
model = build_model_functional()
optimizer = tf.keras.optimizers.Adam(learning_rate=0.002, epsilon=1e-8)
model.compile(optimizer=optimizer, loss={'classes': ClassLoss()})
model.fit(final_ds, epochs=4, steps_per_epoch=4, callbacks = [tboard_callback])
```

Working on creating a minimal example but having difficulty pinpointing the exact element causing this issue. Worst case I can post my full project colab notebook but I'd rather be more general if possible. I'm using a pretty standard functional api model that has some internal custom layers that make use of the subclassing API.
"
48866,undefined symbol: _ZN10tensorflow....,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.5
- Python version: 3.9.4
- Installed using virtualenv? pip? conda?: N/A, building from source
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): gcc 10.2.0 (Ubuntu 10.2.0-5ubuntu1~20.04)
- CUDA/cuDNN version: N/A
- GPU model and memory: No GPU



**Describe the problem**
I encounter an undefined symbol error when it tried to import something on target 17076/32005, about 30k seconds in.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
``git clone https://github.com/tensorflow/tensorflow.git``
``cd /root/tensorflow/``
``git checkout r2.5``
``./configure``
(answered no to everything, copts set to -march=native and -Os)
``/root/bazelisk-linux-amd64 build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures --config=v2 --config=noaws --config=nogcp --config=nohdfs --config=nonccl --config=libc++ --config=mkl --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --local_ram_resources=4096``

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
ERROR: /root/tensorflow/tensorflow/python/keras/api/BUILD:138:19: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Exit 1): bash failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow && \
  exec env - \
    CXXFLAGS='-stdlib=libc++' \
    PATH=/root/.cache/bazelisk/downloads/bazelbuild/bazel-3.7.2-linux-x86_64/bin:/root/.autojump/bin:/root/.pyenv/shims:/root/.pyenv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PYTHON_BIN_PATH=/root/.pyenv/versions/3.9.4/bin/python3 \
    PYTHON_LIB_PATH=/root/.pyenv/versions/3.9.4/lib/python3.9/site-packages \
    TF2_BEHAVIOR=1 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2  --apidir=bazel-out/k8-opt/bin/tensorflow/python/keras/api_v2/ --apiname=keras --apiversion=2  --loading=default --packages=tensorflow.python,tensorflow.python.keras,tensorflow.python.keras.activations,tensorflow.python.keras.applications.densenet,tensorflow.python.keras.applications.efficientnet,tensorflow.python.keras.applications.imagenet_utils,tensorflow.python.keras.applications.inception_resnet_v2,tensorflow.python.keras.applications.inception_v3,tensorflow.python.keras.applications.mobilenet,tensorflow.python.keras.applications.mobilenet_v2,tensorflow.python.keras.applications.mobilenet_v3,tensorflow.python.keras.applications.nasnet,tensorflow.python.keras.applications.resnet,tensorflow.python.keras.applications.resnet_v2,tensorflow.python.keras.applications.vgg16,tensorflow.python.keras.applications.vgg19,tensorflow.python.keras.applications.xception,tensorflow.python.keras.backend,tensorflow.python.keras.backend_config,tensorflow.python.keras.callbacks,tensorflow.python.keras.callbacks_v1,tensorflow.python.keras.constraints,tensorflow.python.keras.datasets.boston_housing,tensorflow.python.keras.datasets.cifar10,tensorflow.python.keras.datasets.cifar100,tensorflow.python.keras.datasets.fashion_mnist,tensorflow.python.keras.datasets.imdb,tensorflow.python.keras.datasets.mnist,tensorflow.python.keras.datasets.reuters,tensorflow.python.keras.engine.base_layer,tensorflow.python.keras.engine.data_adapter,tensorflow.python.keras.engine.input_layer,tensorflow.python.keras.engine.input_spec,tensorflow.python.keras.engine.sequential,tensorflow.python.keras.engine.training,tensorflow.python.keras.estimator,tensorflow.python.keras.feature_column.sequence_feature_column,tensorflow.python.keras.initializers,tensorflow.python.keras.initializers.initializers_v1,tensorflow.python.keras.initializers.initializers_v2,tensorflow.python.keras.layers.advanced_activations,tensorflow.python.keras.layers.convolutional,tensorflow.python.keras.layers.convolutional_recurrent,tensorflow.python.keras.layers.core,tensorflow.python.keras.layers.cudnn_recurrent,tensorflow.python.keras.layers.dense_attention,tensorflow.python.keras.layers.embeddings,tensorflow.python.keras.layers.local,tensorflow.python.keras.layers.merge,tensorflow.python.keras.layers.noise,tensorflow.python.keras.layers.normalization,tensorflow.python.keras.layers.normalization_v2,tensorflow.python.keras.layers.preprocessing,tensorflow.python.keras.layers.pooling,tensorflow.python.keras.layers.recurrent,tensorflow.python.keras.layers.recurrent_v2,tensorflow.python.keras.layers.serialization,tensorflow.python.keras.layers.wrappers,tensorflow.python.keras.losses,tensorflow.python.keras.metrics,tensorflow.python.keras.mixed_precision.get_layer_policy,tensorflow.python.keras.mixed_precision.loss_scale_optimizer,tensorflow.python.keras.mixed_precision.policy,tensorflow.python.keras.models,tensorflow.python.keras.optimizer_v2.adadelta,tensorflow.python.keras.optimizer_v2.adagrad,tensorflow.python.keras.optimizer_v2.adam,tensorflow.python.keras.optimizer_v2.adamax,tensorflow.python.keras.optimizer_v2.ftrl,tensorflow.python.keras.optimizer_v2.gradient_descent,tensorflow.python.keras.optimizer_v2.learning_rate_schedule,tensorflow.python.keras.optimizer_v2.nadam,tensorflow.python.keras.optimizer_v2.optimizer_v2,tensorflow.python.keras.optimizer_v2.rmsprop,tensorflow.python.keras.optimizers,tensorflow.python.keras.premade.linear,tensorflow.python.keras.premade.wide_deep,tensorflow.python.keras.preprocessing.image,tensorflow.python.keras.preprocessing.sequence,tensorflow.python.keras.preprocessing.text,tensorflow.python.keras.regularizers,tensorflow.python.keras.saving.model_config,tensorflow.python.keras.saving.save,tensorflow.python.keras.saving.saved_model_experimental,tensorflow.python.keras.utils.data_utils,tensorflow.python.keras.utils.generic_utils,tensorflow.python.keras.utils.io_utils,tensorflow.python.keras.utils.layer_utils,tensorflow.python.keras.utils.losses_utils,tensorflow.python.keras.utils.multi_gpu_utils,tensorflow.python.keras.utils.np_utils,tensorflow.python.keras.utils.vis_utils,tensorflow.python.keras.wrappers.scikit_learn --output_package=tensorflow.python.keras.api._v2 --use_relative_imports=True bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/activations/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/densenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/efficientnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/imagenet_utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_v3/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet_v3/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/nasnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet50/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg16/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg19/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/xception/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/backend/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/constraints/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/boston_housing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar10/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar100/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/fashion_mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/imdb/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/reuters/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/estimator/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/initializers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/losses/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/metrics/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/premade/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/models/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/schedules/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/image/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/sequence/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/text/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/regularizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/utils/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/scikit_learn/__init__.py')
Execution platform: @local_execution_config_platform//:platform
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow6StatusC1ENS_5error4CodeEN4absl14lts_2020_09_2311string_viewEOSt6vectorINS_10StackFrameESaIS7_EE

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 26, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/eager/context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow6StatusC1ENS_5error4CodeEN4absl14lts_2020_09_2311string_viewEOSt6vectorINS_10StackFrameESaIS7_EE


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```"
48865,Performance Issue: GTX 1080 Tensorflow training is stuck indefinitely | GPU Load 0%,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): _**Yes**_
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): _**Windows 10 Version 2004 Build 19041.928**_
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): _**source**_
- TensorFlow version (use command below): _**Tensorflow = 2.4.0 / Keras = 2.4.3**_
- Python version: _**3.6.5 64-bit (virtualenv)**_
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: _**CUDA = 11.0.194 / CuDNN = 8.0.4**_  | **Nvidia Driver = 460.79**
- GPU model and memory: **_Nvidia GTX 1080 / 8GB Memory / 320.3 GBs Bandwitdh_**
- Other System Specs _**: Intel i5-3570K @4.1GHz | 16GB DDR3 RAM @1360Mhz | 5400RPM HDD (where the code is executed from)**_
- IDE:  **_Visual Studio Code 1.55.2_**


**Describe the current behavior**
_Running a custom code to train a BERT transformer on sentimenent analysis traning dataset.
Batch Size = 8
Sequence Length = 128
Dense Layers = 1 with 512 neurons_

_The GPU VRAM fills up to around 7.5GB without any OOM, however the GPU Load is 0~1%, and a CPU load is fluctuating between 60% ~ 100%
_The 1st training Epoch is stuck there indefinitely, without any progress in the training progress bar._
_If I trained using the CPU, it is slow, but there is a progress and it is not stuck.(CPU Load 100% all the time)_

**Describe the expected behavior**

_Running another non-custom code brought from github to test if the GPU is working or not,
After executing it, the GPU VRAM is filled at around 7.5GB with a GPU load of 22% to 27%.
I am expecting a similar behavior with the custom code._

**Standalone code to reproduce the issue**



- BERT.ipynb (The BERT Transformer) <-- The code that exhibits the current behaviour.
- cnn_tutorial.ipynb <-- A code that exhibits an expected behaviour to ensure TF is running on GPU.
- train.tsv <-- Training dataset for the custom code.
[Attachments.zip](https://github.com/tensorflow/tensorflow/files/6409674/Attachments.zip)



**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached. **_(None)_**
@bhack "
48864,tf.compat.v1.flags.EnumClassSerializer throws error on Windows,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): TensorFlow 2.4.1
- Python version: 3.7.5
- CUDA/cuDNN version: N/a
- GPU model and memory: N/a

**Standalone code to reproduce the issue**
```
import tensorflow as tf
tf.compat.v1.flags.EnumClassSerializer
```
**Outputs:**
```
AttributeError: module 'tensorflow.python.platform.flags' has no attribute 'EnumClassSerializer'
```

**Describe the current behavior**
Throws AttributeError. The same problem occurs when I try to use the following APIs:
 - tf.compat.v1.app.flags.EnumClassListSerializer
 - tf.compat.v1.app.flags.EnumClassSerializer
 - tf.compat.v1.flags.EnumClassListSerializer

**Describe the expected behavior**
I can use these APIs on Linux. Expect them to work on Windows as well.
"
48863,Stateful ConvLSTM2D reset_states() throws error,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Windows 10 (10.0.19042)
- TensorFlow installed from: binary
- TensorFlow version: v2.4.0-49-g85c8b2a817f, 2.4.1
- Python version: 3.7.7
- CUDA/cuDNN version: 11.0/8.0
- GPU model and memory: GeForce GTX 1080 Ti

**Describe the current behavior**

The `reset_states()` method of the `ConvolutionalLSTM2D` layer throws a TypeError if called with the default argument.

**Describe the expected behavior**

The `reset_states()` method of the `ConvolutionalLSTM2D` layer should reset its states if the method is called with the default argument.

**Standalone code to reproduce the issue**

```
import tensorflow as tf
l = tf.keras.layers.ConvLSTM2D(32, kernel_size=3, strides=1, padding='same', stateful=True, batch_size=32)
l.reset_states()
```

**Other info / logs** 

Relevant part of the stack trace: 
```
File ""...\venv\lib\site-packages\tensorflow\python\keras\layers\convolutional_recurrent.py"", line 357, in reset_states
    state_shape = self.compute_output_shape(input_shape)
  File ""...\venv\lib\site-packages\tensorflow\python\keras\utils\tf_utils.py"", line 272, in wrapper
    output_shape = fn(instance, input_shape)
  File ""...\venv\lib\site-packages\tensorflow\python\keras\layers\convolutional_recurrent.py"", line 193, in compute_output_shape
    rows = input_shape[2]
TypeError: 'NoneType' object is not subscriptable

Process finished with exit code 1
```

"
48862,Optimizer that is wrapped with two different LossScaleOptimizer throws a error.,"**System information**
- OS: colab (Ubuntu 18.04.5)
- Where TensorFlow installed from : pre-installed in colab
- TensorFlow version: 2.4.1
- Python version: 3.7.10
- GPU model and memory: Tesla K80, 12GB

**The current behavior**

When using tf.keras.Optimizer that is wrapped with two different `tf.keras.mixed_precision.LossScaleOptimizer`, the optimizer raises a error below.

```
ValueError: Called Trackable._track_trackable() with name='loss_scale', but a Trackable with this name is already declared as a dependency. Names must be unique (or overwrite=True).
```

**The expected behavior**

I believe that the error should be NOT occurred.

**Standalone code to reproduce the issue**

• The code snippet to reproduce the error.

```python
import tensorflow as tf

optimizer = tf.optimizers.RMSprop()
wrapped_optimizer_1 = tf.keras.mixed_precision.LossScaleOptimizer(optimizer) # There is no error.
wrapped_optimizer_2 = tf.keras.mixed_precision.LossScaleOptimizer(optimizer) # The error occurred.
```

• The error

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-efa101fb525d> in <module>()
      3 optimizer = tf.optimizers.RMSprop()
      4 wrapped_optimizer_1 = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)
----> 5 wrapped_optimizer_2 = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)

2 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py in __init__(self, inner_optimizer, dynamic, initial_scale, dynamic_growth_steps)
    545       self._loss_scale = _DynamicLossScaleState(
    546           initial_scale, dynamic_growth_steps, multiplier=2)
--> 547       self._track_trackable(self._loss_scale, 'loss_scale')
    548     else:
    549       if initial_scale is None:

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py in _track_trackable(self, trackable, name, overwrite)
    154 
    155   def _track_trackable(self, trackable, name, overwrite=False):  # pylint: disable=redefined-outer-name
--> 156     return self._trackable._track_trackable(trackable, name, overwrite)
    157 
    158   def _handle_deferred_dependencies(self, name, trackable):  # pylint: disable=redefined-outer-name

/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py in _track_trackable(self, trackable, name, overwrite)
    897             (""Called Trackable._track_trackable() with name='%s', ""
    898              ""but a Trackable with this name is already declared as a ""
--> 899              ""dependency. Names must be unique (or overwrite=True)."") % (name,))
    900       # This is a weird thing to do, but we're not going to stop people from
    901       # using __setattr__.

ValueError: Called Trackable._track_trackable() with name='loss_scale', but a Trackable with this name is already declared as a dependency. Names must be unique (or overwrite=True).
```

**Other info / logs**

N/A

Thanks!"
48861,@YonitZall,"@YonitZall 
did you get any solutions? I am facing the same problem

_Originally posted by @apramanik62 in https://github.com/tensorflow/tensorflow/issues/29078#issuecomment-830577011_"
48860,[Mixed_precision] Model#__call__() behavior is different when using tf.Tensor input and when using tf.Variable input.,"**System information**
- OS: colab (Ubuntu 18.04.5)
- Where TensorFlow installed from : pre-installed in colab
- TensorFlow version: 2.4.1
- Python version: 3.7.10
- GPU model and memory: Tesla K80, 12GB

**The current behavior**

On default (`float32`) policy environment, I have to load and use a keras model that is loaded from a `h5` file that was created with `mixed_float16` policy.
When using `tf.Variable` instead of `tf.Tensor` as input value to model, a error bellow is occurred.

```
ValueError: Incompatible type conversion requested to type 'float32' for AutoCastVariable which is casted to type 'float16'
```

I want to calculate the gradient with respect to the input value and update the input value itself iteratively.
To do so, the input value needs to be `tf.Variable`.

**The expected behavior**

I believe that the behavior of both (tf.Tensor and tf.Variable) should be same, that's, the error should be NOT occurred.

**Standalone code to reproduce the issue**

The steps for reproducing:

1. Set mixed_float16 policy
1. Create a model file
1. Set float32 (default) policy
1. Load model and When using tf.Tensor for input of model that is loaded from h5 file, Model#__call__() will NOT throw the error.
1. Load model and When using tf.Valiable for input of model that is loaded from h5 file,Model#__call__() will throw the error.

I've uploaded a notebook to reproduce the error:

https://gist.github.com/keisen/087713c2e547b05a6867506ea5402b93

**Other info / logs**

N/A


Thanks!

"
48858,Keras bidirectional lstm incorrect predictions,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution Linux Ubuntu 20.04):
- TensorFlow installed from (source or binary): Binary & Source
- TensorFlow version (use command below): 2.4 & 2.3.1
- Python version: 3.8
- Bazel version (if compiling from source): 3.1
- CUDA/cuDNN version: 11 / 8
- GPU model and memory: RTX Quadro 8000 / 48GB

You can also obtain the TensorFlow version with:
I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
unknown 2.3.1

**Describe the current behavior**

I have a previous model written with the old Keras API before it was integrated into TensorFlow. We've been using this model, code and build setup for 2 years now no issues whatsoever. We decided to finally upgrade to TensorFlow 2. After upgrading we tried training. 

During training the model achieves the expected validation accuracy, but if we test the model after training it just spits out garbage values. For a sanity check we tested the model trained with the old version of Keras in TensorFlow 2 and it produces the correct output. Absolutely nothing has changed with the data or process. Only difference is the version of Keras and TensorFlow. We are stumped as to what the issue could be. The model is very simple, stacked bi-directional LSTMs. It also achieves the expected validation accuracy in training. 

Interestingly, this model is destined for CoreML, but exporting the model trained in TensorFlow 2 generates a larger model with significantly more layers than the previous. 

**Describe the expected behavior**

The trained model should produce the correct output.

**Standalone code to reproduce the issue**

This is the model.

`

        x = Input(shape=(length , feature_size,))
        branch_1 = Bidirectional(LSTM(256, return_sequences=True))(x)
        branch_1 = Bidirectional(LSTM(128, return_sequences=True))(branch_1)
        branch_1 = Bidirectional(LSTM(64, return_sequences=True))(branch_1)
        sequence = TimeDistributed(Dense(10, activation='softmax'), name='out')(branch_1)
        temporal_model = Model([x], [sequence])`


"
48857,java.lang.UnsatisfiedLinkError: Failed to load native TensorFlow Lite methods.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy s5 min
- TensorFlow installed from (source or binary): source 
- TensorFlow version: 'org.tensorflow:tensorflow-lite:2.4.0' + org.tensorflow:tensorflow-android:1.13.1'
- Python version:
- Installed using virtualenv? pip? conda?: 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

hello little question for a computer project in computer license I have to refactor an old application and make it modular. But here's when I build my generate signed bundle and I launch a feature on demand who use tensorflow on my android I have this error:

FATAL EXCEPTION: Thread-9
Process: descartes.info.l3ak2.eyetrek, PID: 7275
java.lang.UnsatisfiedLinkError: Failed to load native TensorFlow Lite methods. Check that the correct native libraries are present, and, if using a custom native library, have been properly loaded via System.loadLibrary():
java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file ""/system/framework/android.test.runner.jar"", zip file ""/data/app/androidx.test.tools.crawler-gvh38WebyoKL_IpGVoIEuw==/base.apk"", zip file ""/data/app/descartes.info.l3ak2.eyetrek-h1-hReoVf26OAguR-8QZHw==/base.apk"", zip file ""/data/app/descartes.info.l3ak2.eyetrek-h1-hReoVf26OAguR-8QZHw==/split_config.xxhdpi.apk"", zip file ""/data/app/descartes.info.l3ak2.eyetrek-h1-hReoVf26OAguR-8QZHw==/split_moduleastronomie.apk"", zip file ""/data/app/descartes.info.l3ak2.eyetrek-h1-hReoVf26OAguR-8QZHw==/split_moduleastronomie.config.xxhdpi.apk"", zip file ""/data/app/descartes.info.l3ak2.eyetrek-h1-hReoVf26OAguR-8QZHw==/split_modulereconnaissancechantsoiseaux.apk"", zip file ""/data/app/descartes.info.l3ak2.eyetrek-h1-hReoVf26OAguR-8QZHw==/split_modulereconnaissancechantsoiseaux.config.xxhdpi.apk"", zip file ""/data/app/descartes.info.l3ak2.eyetrek-h1-hReoVf26OAguR-8QZHw==/split_modulereconnaissancefeuille.apk"", zip file ""/data/app/descartes.info.l3ak2.eyetrek-h1-hReoVf26OAguR-8QZHw==/split_modulereconnaissancefeuille.config.xxhdpi.apk""],nativeLibraryDirectories=[/data/app/androidx.test.tools.crawler-gvh38WebyoKL_IpGVoIEuw==/lib/arm64, /data/app/descartes.info.l3ak2.eyetrek-h1-hReoVf26OAguR-8QZHw==/lib/arm64, /system/lib64, /vendor/lib64]]] couldn't find ""libtensorflowlite_jni.so""
at org.tensorflow.lite.TensorFlowLite.init(TensorFlowLite.java:80)
at org.tensorflow.lite.NativeInterpreterWrapper.(NativeInterpreterWrapper.java:52)
at org.tensorflow.lite.Interpreter.(Interpreter.java:277)
at org.tensorflow.lite.Interpreter.(Interpreter.java:262)
at descartes.info.l3ak2.eyetrek.module_reconnaissance_feuille.tensorflow.ImageClassifierFpasF.(ImageClassifierFpasF.java:102)
at descartes.info.l3ak2.eyetrek.module_reconnaissance_feuille.fragment.FragmentScanFeuille$6.run(FragmentScanFeuille.java:1306)
at java.lang.Thread.run(Thread.java:764)

how can I resolve this ?
"
48855,TF_AddGradientsWithPrefix doesn't seem to lock the gradients properly,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Using TF-Java
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS
- TensorFlow installed from (source or binary): Maven Central binary
- TensorFlow version (use command below): v2.4.1

**Describe the current behavior**

When training a model I'm hitting a non-determinism issue, the models are initialized identically, and fed identical data in an identical order, with inter-op and intra-op parallelism both set to 1, but I can get complete training failure when building simple MLPs and CNNs on MNIST.

TF-Java uses TF_AddGradientsWithPrefix to construct the gradients. We then wrap that in Optimizers to make a higher level front end to training, similar to the v1 optimizers package, and Keras in v2. As gradients are only available in Graph mode in the C API our code is most similar to the v1 optimizers package. I think we want to have the gating behaviour set to `GATE_OP` (https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/Optimizer), but that's all implemented entirely in python, and the C API codepath doesn't seem to add the required control dependencies to ensure the gradients are all computed before being back-propped any further (in Python that's performed here - https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/ops/gradients_util.py#L692, but there doesn't seem to be an equivalent in the C API here - https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/cc/framework/gradients.cc#L568).

**Describe the expected behavior**

The model should train identically with identical gradients.

**Standalone code to reproduce the issue**

See this test in TF-Java - https://github.com/Craigacp/tensorflow-java/blob/03402b30e271a46438c1feff12409095737f3d3e/tensorflow-framework/src/test/java/org/tensorflow/framework/optimizers/GradientDescentTest.java#L121. This test when run complains that out of the 20 runs some of them diverged even when trained using identical graph defs on identical data, for an identical number of steps, when using single threaded computation.
"
48853,Recommenders item vs item.,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue: https://www.tensorflow.org/recommenders/examples/basic_ranking

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing): Right now everything is pretty much user to item, I was wondering how can I use tensorflow in order to get an item vs item while accomodating the user behavior? Right now we are passing in the user to predict what are the recommended item for the user, Is there a way I can pass in an item and recommend me similar items?

### Clear description

For example, why should someone use this method? How is it useful? Content-based filtering.

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly? Yes

### Returns defined

Are return values defined? Yes

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

No

### Usage example

Is there a usage example? In - https://www.tensorflow.org/recommenders/examples/basic_retrieval#making_predictions
Hoping to do 
_, titles = index(tf.constant([""Bridges of Madison County, The (1995)""]))

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
48852,Use of TensorFlow trademark in product name,"After reading the licensing doc and the TM usage guidelines I am still unclear: can the TensorFlow TM be used in a product name, provided that the attributions, as described in the TM guide, are used in the product description.  As an example:

""xxxxx for Machine Learning - Includes Installed TensorFlow Distribution""

Thanks in advance.
"
48851,tf.function traces twice when creating Variables in the first call?,"I have struggled to understand this strange behavior when using `@tf.function`. I have the following code:
```python
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # This prevents tensorflow from print WARNING messages
import tensorflow as tf


class Count:
    def __init__(self):
        self.count = tf.Variable(0)

    @tf.function
    def increment(self):
        print(""This function is tracing !"")
        tf.print(""This function is executing !"")
        return self.count.assign_add(1)

counter = Count()
counter.increment()
```
According to [this guide](https://www.tensorflow.org/guide/function#tracing), the above code will first build a `tf. Graph` (**tracing**) and then execute the built `tf. Graph`. When running the above code, I get the expected result as below:
```
This function is tracing!
This function is executing!
```
However, if I try to create the variable `self. count` inside the function decorated with `@tf.function` (`increment` in this case), the function gets traced twice:

*Code:*
```python
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # This prevents tensorflow from print WARNING messages
import tensorflow as tf


class Count:
    def __init__(self):
        self.count = None

    @tf.function
    def __call__(self):
        print(""This function is tracing !"")
        tf.print(""This function is executing !"")
        if self.count is None:
            self.count = tf.Variable(0)
        return self.count.assign_add(1)

counter = Count()
counter()
```
*Output:*
```
This function is tracing!
This function is tracing!
This function is executing!
```

There is another closely related question, which is [this](https://stackoverflow.com/questions/65323657/why-tf-function-traces-layers-twice). But none of the answers give a clear explanation to my question. I am currently using Python 3.8.5 and TensorFlow 2.4.1


"
48850,CenterNet TFLite crashes while running on Android,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Android 9, not specific device(RK3399 cpu, and QC835 cpu)
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.14 and 2.4
- Python version: 3.7
- Bazel version (if compiling from source): 3.5.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: not used
- GPU model and memory: not used 

**Describe the current behavior**
We have built a shared object (.so) with Tensorflow cpp API, and then we are linking it with Android App. The shared object contain CenterNet Model in order to predict skeleton detections. When we create a binary for arm64-v8a or armeabi-v7a which is linked against that .so and run it as executable it works just fine. But when we try to predict within android app we are getting the following crash error:
```
/data/app/com.example.app-XsHutFbryKx6M754dZvzBg==/lib/arm64/lib_centernet.so (tflite::Subgraph::ReportErrorC(TfLiteContext*, char const*, ...)+112)
/data/app/com.example.app-XsHutFbryKx6M754dZvzBg==/lib/arm64/lib_centernet.so (TfLiteStatus tflite::ops::builtin::reduce::EvalLogic<int>(TfLiteContext*, TfLiteNode*, tflite::ops::builtin::reduce::OpContext*, int, tflite::ops::builtin::reduce::OpContext* (*)(tflite::ops::builtin::reduce::OpContext*, tflite::ops::builtin::reduce::OpContext*))+1668)
/data/app/com.example.app-XsHutFbryKx6M754dZvzBg==/lib/arm64/lib_centernet.so (_ZN6tflite3ops7builtin6reduce11EvalGenericILNS2_10KernelTypeE0ELNS2_10ReduceTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+240)
/data/app/com.example.app-XsHutFbryKx6M754dZvzBg==/lib/arm64/lib_centernet.so (tflite::ops::builtin::reduce::EvalSum(TfLiteContext*, TfLiteNode*)+240)
/data/app/com.example.app-XsHutFbryKx6M754dZvzBg==/lib/arm64/lib_centernet.so (tflite::Subgraph::Invoke()+1008)
/data/app/com.example.app-XsHutFbryKx6M754dZvzBg==/lib/arm64/lib_centernet.so (tflite::Interpreter::Invoke()+92)
/data/app/com.example.app-XsHutFbryKx6M754dZvzBg==/lib/arm64/lib_centernet.so (lib::CenterNet::Detect(unsigned char*, int, int)+96)
``` 
**Describe the expected behavior**
As a binary we are getting output from the interpreter and we except to work the same in app. 

If you find that there is missing information just ask and I will try to add that to. 

Thank you in advance!"
48849,[For GShard] parameter instruction in HLO could not get sharding information from annotated VarHandleOp,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): (2.6.0)master branch on 30, April
- Python version: 3.6.9
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 8.4.0
- CUDA/cuDNN version: 11.2/8
- GPU model and memory: V100 32GB


**Describe the current behavior**
I write some codes with GShard API provided in ``` experimental/xla_sharding/xla_sharding.py ```.  As proposed in GShard paper, the annotation can marked anywhere when needed. But As I annotated the trainable variable, it seems no effect on HLO for `parameter` instruction.

For example, a trainable variable could be created from the following API.  The ```self.in_weights``` is ```VarHandleOp``` Type
```
 self.weight = tf.get_variable(name=""weights"",
                                      shape=shape,
                                      dtype=tf.float32,
                                      initializer=self.initializer)
```

And When I annotates like the following:

```    
 self.weight = xla_sharding.split(self.weight, 0, 2)
```

I have checked the annotation on ```NodeDef``` and make sure that the ```_XLA_Sharding``` Attribute has beed added on. But this important information is missing in HLO when entering the ``` GpuCompiler::OptimizeHloModule```.

To debug the missing information, I noticed the ```XlaCompiler::CompileGraph()``` function intent to get Sharding Attribute from ```NodeDef``` by ```ComputeArgAndRetvalShardings```.  The  source code of this function is as follows: 

```
// Uses the _Arg and _Retval nodes in the graph to determine an OpSharding for
// each argument and return value.
xla::StatusOr<
    std::pair<std::map<int, xla::OpSharding>, std::map<int, xla::OpSharding>>>
ComputeArgAndRetvalShardings(const Graph& graph) {
  auto get_sharding_for_node =
      [](const Node* n) -> xla::StatusOr<absl::optional<xla::OpSharding>> {
    TF_ASSIGN_OR_RETURN(
        auto sharding,
        ParseShardingFromDevice(*n, std::numeric_limits<int32>::max(),
                                /*add_metadata=*/false));
    return sharding;
  };
  std::map<int, xla::OpSharding> arg_shardings;
  std::map<int, xla::OpSharding> retval_shardings;
  for (const Node* n : graph.nodes()) {
    if (n->IsArg()) {
      TF_ASSIGN_OR_RETURN(auto sharding, get_sharding_for_node(n));
      if (!sharding.has_value()) continue;
      int index;
      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), ""index"", &index));
      TF_RET_CHECK(index >= 0) << ""Negative _Arg index"";
      arg_shardings[index] = std::move(*sharding);
    } else if (n->IsRetval()) {
      TF_ASSIGN_OR_RETURN(auto sharding, get_sharding_for_node(n));
      if (!sharding.has_value()) continue;
      int index;
      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), ""index"", &index));
      TF_RET_CHECK(index >= 0) << ""Negative _Retval index"";
      retval_shardings[index] = std::move(*sharding);
    }
  }
  return std::make_pair(std::move(arg_shardings), std::move(retval_shardings));
}
```

But here the ```Arg``` and ```RetVals``` belongs to ```Xla_Compile``` Op , not ```XlaRun``` Op. The indices acquired from ```arg_shardings``` are different from ```XlaRun```'s. And the ```BuildArguments``` function uses these indices to
decide sharding information for HLO, which leads to the hlo_sharding missing due to the mismatched indices for 
 ```input_to_args```.
```
    for (std::vector<int>::size_type i = 0; i < input_to_args->size(); ++i) {
      auto it = arg_shardings.find(i);
      xla::XlaScopedShardingAssignment assign_sharding(
          builder, it == arg_shardings.end() ? absl::optional<xla::OpSharding>()
                                             : it->second);
```

Is that the expected  behavior for ```parameter_instruction``` or a bug for TensorFlow GraphDef?


**Describe the expected behavior**
I think the ```arg_shardings``` of ```XlaCompile``` Op is meaningless for deciding ``` parameter```'s sharding information. These arguments indices should be referred to the inputs of ENTRY computation for hlo module. 

Can anyone help for solving this problem? @ukoxyz 

"
48846,Is tensorflow going to support amd gpu with ROCm ？ ,"**Describe the problem**
I notice that ```pytorch``` supports amd gpu with ROCm in version 1.8.1 ([https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)) . I want to know whether ```tensorflow``` is going to support amd gpu or not ..."
48845,BatchNorm generates NaN moving_variance on GPU with fused set to True,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab, Ubuntu
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary (Colab), source (Ubuntu)
- TensorFlow version (use command below): 'v2.4.1-0-g85c8b2a817f', '2.4.1'
- Python version: 3
- Bazel version (if compiling from source): default for TF 2.4.1
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: default for colab, cuda 11.0.3, cudnn 8.1.0.77 (Ubuntu)
- GPU model and memory: default for colab, 1080Ti (Ubuntu)

**Describe the current behavior**
This is a continue of https://github.com/tensorflow/tensorflow/issues/34062
Original issue was not resolved due to wrong test (GPU is not used with tf-nightly-gpu).

**Describe the expected behavior**
Batchnorm should correctly work on GPU with batch size == 1 and fused = True

**Standalone code to reproduce the issue**
Make sure to uncomment line with ""set_log_device_placement"" if you want to test with tf-nightly (you will see only CPU placement in colab logs)
https://colab.research.google.com/drive/16LccjOuj9Aj8x0S9Q-hOTxGgqVWdVZ53?usp=sharing
"
48844,TensorFlow 2 slow on small numbers of batches,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and Colab (observed such performance issue on both platform)
- TensorFlow installed from (source or binary): pip / provided in colab
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8
- CUDA/cuDNN version: CUDA 11.0, cuDNN 8.0 / provided in colab
- GPU model and memory: GTX 1660Ti / provided in colab

I have already asked this question on StackOverflow, but nobody answered, so considering it is a performance issue, I opened an issue, sorry if this is not appropriate to be asked in issues.

When training a small number of batches (not batch size), TensorFlow 2 is significantly slower than PyTorch.
(for example, train 30 batches, note that different but still relatively large ratios still apply for a smaller number of batches like training a single batch, different models with a few more layers/params, and/or different batch size)
below are approximations of the performance difference I observed in colab CPU:

with low-level gradient tape training, TensorFlow is 9 times slower than equivalent model/data on PyTorch
with low-level gradient tape + @tf.function train step, TensorFlow is 18 times slower than equivalent model/data on PyTorch
with high-level fit(), TensorFlow is 19 times slower than equivalent model/data on PyTorch
with high-level train_on_batch(), TensorFlow is 22 times slower than equivalent model/data on PyTorch

**A reproducible code** example can be found here, which shows a simple model (can run on both CPU or GPU depending on whether GPU is turned on in Colab) and generated random data being trained with all functions/API discussed above: https://colab.research.google.com/drive/1VHYLEZ79etKSkK0iWIqHkt7OG8nbU9uU?usp=sharing 

above code is partially modified from the official tutorial https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch
and partially written on my own.

training single batch or a few batches are widely used in Deep Reinforcement Learning and some special cases of Deep Learning. 
The code above is just for demonstration of my observation. I also noticed a large train time gap between TF and PyTorch when I work on DQN locally on my Windows machine, since DQN Experience replay trains on one batch each time.

Am I using TF incorrectly? if yes, what is the best way to train a small number of batches?
Even if I am not using the best way. 
Why is @tf.function that is meant to accelerate slowing down training?
Why is train_on_batch that seems to be designed for a single batch the slowest of all?

Any help would be great! Thank you.
"
48843,Can't detect GPU with Tensorflow-GPU,"- NVIDIA GTX 1050 Ti (4GB)
- Window 10
- Python 3.9.0
- Cuda V11.2.152

I have `tensorflow-gpu` installed and I run this code to verify if tensorflow detected my GPU

```
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
```

Tensorflow could only detect my CPU

```
[name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 10182600208144693220
]
```

So I uninstalled `tensorflow-gpu` and installed `tf-nightly-gpu`, then I run the same code again.

```
[name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 761424825523677949
, name: ""/device:GPU:0""
device_type: ""GPU""
memory_limit: 2912380519
locality {
  bus_id: 1
  links {
  }
}
incarnation: 4915443179038048022
physical_device_desc: ""device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1""
]
```

This time no problem. But one probelm with nigtly is that it doesn't support addons. Is there a bug in `tensorflow-gpu` or something?

"
48841,Inconsistencies in micro_speech example,"This may be related to https://github.com/tensorflow/tensorflow/issues/48752. The `micro_speech` model is int8 quantized for both input and output. The test for the example has some lines with `data.int8` and `data.uint8` when querying the output data.

For example:

https://github.com/tensorflow/tensorflow/blob/173b50a525e0f88fa25674980f1243ada460114e/tensorflow/lite/micro/examples/micro_speech/micro_speech_test.cc#L103

and:

https://github.com/tensorflow/tensorflow/blob/173b50a525e0f88fa25674980f1243ada460114e/tensorflow/lite/micro/examples/micro_speech/micro_speech_test.cc#L105


<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/a
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): master branch
- Python version: n/a
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
TFLM example micro_speech has inconsistencies in the test file. It treats some outputs as `int8` and some as `uint8`.

**Describe the expected behavior**
Treat all outputs from the model as the same as they are all `int8`.

**Standalone code to reproduce the issue**
Affected lines can be seen above. Does not raise an error but it does not make sense.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached."
48839,Can't build TFL micro build with armclang toolchain,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): N/A
- Tensorflow version (commit SHA if source): 9000e360d95b9d2c3925672ba100579bd459ee30
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Any target

**Describe the problem**
When using the armclang toolchain to build the microlite lib, the warning `implicit-const-int-float-conversion` is hit. Warnings are treated as errors, hence build fails.

**Please provide the exact sequence of commands/steps when you ran into the problem**
For example:
`make -j -f tensorflow/lite/micro/tools/make/Makefile OPTIMIZED_KERNEL_DIR=ethos_u TOOLCHAIN=armclang TARGET=cortex_m_generic TARGET_ARCH=cortex-m55 microlite
`

Output with error:
```
armclang -std=c11 -fno-unwind-tables -ffunction-sections -fdata-sections -fmessage-length=0 -DTF_LITE_STATIC_MEMORY -DTF_LITE_DISABLE_X86_NEON -O3 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wswitch -Wvla -Wall -Wextra -Wstrict-aliasing -Wno-unused-parameter -DCORTEX_M_GENERIC -DETHOS_U --target=arm-arm-none-eabi -mcpu=cortex-m55 -DTF_LITE_MCU_DEBUG_LOG -mthumb -mfloat-abi=hard -funsigned-char -mlittle-endian -Wno-implicit-fallthrough -Wno-strict-aliasing -Wno-unused-variable -Wno-type-limits -Wno-unused-private-field -fomit-frame-pointer -MD -DCPU_M55=1 -D__DSP_PRESENT=1 -D__FPU_PRESENT=1 -I. -Itensorflow/lite/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include -Itensorflow/lite/micro/tools/make/downloads/ruy -Itensorflow/lite/micro/tools/make/downloads/ethos_u_core_driver/include -Itensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/Core/Include -c tensorflow/lite/micro/tools/make/downloads/ethos_u_core_driver/src/ethosu_driver.c -o tensorflow/lite/micro/tools/make/gen/cortex_m_generic_cortex-m55_default/obj/tensorflow/lite/micro/tools/make/downloads/ethos_u_core_driver/src/ethosu_driver.o
tensorflow/lite/kernels/kernel_util.cc:342:15: error: implicit conversion from 'std::numeric_limits<int>::type' (aka 'int') to 'float' changes value from 2147483647 to 2147483648 [-Werror,-Wimplicit-const-int-float-conversion]
        tmp <= std::numeric_limits<int32_t>::max());
```"
48838,LSTM and GRU layers do not use cuDNN acceleration when processing RaggedTensors,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian stable
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0 / 8.0 (the ones on Colab were used)
- GPU model and memory: Colab

**Describe the current behavior**

When LSTM/GRU layers are executed on RaggedTensors, they do not use cuDNN acceleration on GPU and are much slower. The attached Colab notebook shows more than 5-times slowdown compared to manual conversion before/after the call.

**Describe the expected behavior**

The LSTM/GRU layers executed on RaggedTensors should use cuDNN acceleration on GPU.

**Standalone code to reproduce the issue**

https://colab.research.google.com/drive/1eR3ggwp-5sNKQjJld7XiTjet3BT740F1?usp=sharing

Note that when converting the RaggedTensors before/after the RNN call manually like this:
```python
outputs = rnn(inputs.to_tensor(), mask=tf.sequence_mask(inputs.row_lengths()))
outputs = tf.RaggedTensor.from_tensor(outputs, inputs.row_lengths())
```
allows using cuDNN implementation.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The problem is described directly in the sources: GRU here: https://github.com/tensorflow/tensorflow/blob/9a2545aecc498e7a5e8bf5d63c47af59e1550111/tensorflow/python/keras/layers/recurrent_v2.py#L447-L449 and LSTM here: https://github.com/tensorflow/tensorflow/blob/9a2545aecc498e7a5e8bf5d63c47af59e1550111/tensorflow/python/keras/layers/recurrent_v2.py#L1165-L1167

Note that same code is still in current head: GRU here: https://github.com/tensorflow/tensorflow/blob/9000e360d95b9d2c3925672ba100579bd459ee30/tensorflow/python/keras/layers/recurrent_v2.py#L434-L436 LSTM here: https://github.com/tensorflow/tensorflow/blob/9000e360d95b9d2c3925672ba100579bd459ee30/tensorflow/python/keras/layers/recurrent_v2.py#L1161-L1163"
48837,BatchNormalization layers in Tensorflow 2.4.1 give constant validation accuracy,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Anaconda (conda 4.10.1 using conda install)
- TensorFlow version (use command below): 2.4.1
- Python version: Python 3.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.2
- GPU model and memory: GeForce GTX 1080, 7845MB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

I was building a simple CNN for a binary image classification task and found something confusing regarding the use of the `BatchNormalization` layer in Tensorflow. There are 320 images in the training set with evenly divided negative and positive cases. There are 80 images in the validation set with evenly divided negative and positive cases. I set the `batch_size` for both training and validation set to 32.

Here is the architecture of my original model.
```
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dropout, Dense
        
model = Sequential([
    Input(shape=(256, 256, 3]),
    Conv2D(64, (3, 3), padding=“same”, activation=“relu”),
    Conv2D(64, (3, 3), padding=“same”, activation=“relu”),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), padding=“same”, activation=“relu”),
    Conv2D(128, (3, 3), padding=“same”, activation=“relu”),
    MaxPooling2D((2, 2)),
    Conv2D(256, (3, 3), padding=“same”, activation=“relu”),
    Conv2D(256, (3, 3), padding=“same”, activation=“relu”),
    Conv2D(256, (3, 3), padding=“same”, activation=“relu”),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation=“relu”),
    Dropout(0.5),
    Dense(64, activation=“relu”),
    Dense(1, activation=“sigmoid”)
])

```
Both training and validation accuracies increased from somewhere between 0.5 and 0.6 and eventually converged somewhere between 0.95, which is good. However, with everything else unchanged, if I introduced `BatchNormalization` layers between `Conv2D` layers like the following:
```

model = Sequential([
    Input(shape=(256, 256, 3]),
    Conv2D(64, (3, 3), padding=“same”),
    BatchNormalization(),
    ReLU(),
    Conv2D(64, (3, 3), padding=“same”, activation=“relu”),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), padding=“same”),
    BatchNormalization(),
    ReLU(),
    Conv2D(128, (3, 3), padding=“same”, activation=“relu”),
    MaxPooling2D((2, 2)),
    Conv2D(256, (3, 3), padding=“same”),
    BatchNormalization(),
    ReLU(),
    Conv2D(256, (3, 3), padding=“same”),
    BatchNormalization(),
    ReLU(),
    Conv2D(256, (3, 3), padding=“same”, activation=“relu”),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation=“relu”),
    Dropout(0.5),
    Dense(64, activation=“relu”),
    Dense(1, activation=“sigmoid”)
])

```
The training accuracy still behaved the same way as before but validation accuracy remained constant at 0.5. I also tried several other implementations of `BatchNormalization` layers and had the same observation.
```

model = Sequential([
    Input(shape=(256, 256, 3]),
    Conv2D(64, (3, 3), padding=“same”, activation=“relu”),
    BatchNormalization(),
    Conv2D(64, (3, 3), padding=“same”, activation=“relu”),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), padding=“same”, activation=“relu”),
    BatchNormalization(),
    Conv2D(128, (3, 3), padding=“same”, activation=“relu”),
    MaxPooling2D((2, 2)),
    Conv2D(256, (3, 3), padding=“same”, activation=“relu”),
    BatchNormalization(),
    Conv2D(256, (3, 3), padding=“same”, activation=“relu”),
    BatchNormalization(),
    Conv2D(256, (3, 3), padding=“same”, activation=“relu”),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation=“relu”),
    Dropout(0.5),
    Dense(64, activation=“relu”),
    Dense(1, activation=“sigmoid”)
])

```
There are people online saying that there are bugs in Keras’s implementation of `BatchNormalization`. I had tried to reduce the layers of `BatchNormalization` and found that with even a single layer of `BatchNormalization` introduced, the validation accuracy will be constant at 0.5. Do you have any ideas why?

**Describe the expected behavior**

 I am rather new with deep learning and from what I have read recently on different tutorials about `BatchNormalization`, it should usually (though not always) be a performance booster. However, from what I have observed, `BatchNormalization` was ruining my validation performance. 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48836,CMake build option TFLITE_ENABLE_RUY=OFF does not work,"**System information**
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): source
TensorFlow version: 2.5.0-rc2
Python version: 3.6.8 (but probably n/a)
Installed using virtualenv? pip? conda?: n/a
Bazel version (if compiling from source): n/a
GCC/Compiler version (if compiling from source): Apple clang version 12.0.0
CUDA/cuDNN version: n/a
GPU model and memory: n/a

**Describe the problem**

Follow the instructions at https://www.tensorflow.org/lite/guide/build_cmake to build `libtensorflow-lite.a`, using the default value of TFLITE_ENABLE_RUY=OFF. Then use `nm` to look at the library and see that there are many uses of ruy (including undefined symbols) that make this library unusable.

From a casual inspection, it appear that there are lots of references to ruy in the source code (eg #includes in optimized_ops.h) that may not be easily removed; if ruy is truly required to build TFLite, there shouldn't be an option to disable it. (Alternately, if it's not required, the code should actually allow excluding it.)
"
48835,CMake build rule for C api is incomplete when building with TFLITE_C_BUILD_SHARED_LIBS=OFF,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.0-rc2
- Python version:  3.6.8 (but probably n/a)
- Installed using virtualenv? pip? conda?: n/a
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the problem**

Documentation at https://www.tensorflow.org/lite/guide/build_cmake describes how to use the (experimental) CMake build files to build TFLite, and also the TFLite C API. If you build the C API library as-is using the instructions on that page, you do indeed get `libtensorflowlite_c.so` as expected, which is usable as-is. 

However, if you use the option `TFLITE_C_BUILD_SHARED_LIBS=OFF` when building, the resulting `libtensorflowlite_c.a` doesn't include any of tflite itself... just the C API wrappers for it. This is unexpected and suboptimal. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
n/a"
48833,Performance Bug When Using CMake to Build TFLite r2.4 for Android (2x slower inference times than Bazel),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: MediaTek X20 Development Board
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): r2.4
- Python version: 3.6.9 (also happens on 3.9.4)
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version:
- GPU model and memory:



You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
After building benchmark_model for Android and running it on my development board, I get an inference time on MobilenetV2_Quantized of about 240ms when using Bazel built benchmark_model but over 550ms when using CMake built benchmark_model.

*Building is done on Ubuntu 18.04
*MobilenetV2_Quant is from tflite hosted models (.tflite) https://www.tensorflow.org/lite/guide/hosted_models
*Performance is measured on MediaTek A53 dev board running Android 7

**Describe the expected behavior**
benchmark_model binary should have the same performance regardless of build system

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
*Clone Repo and Mkdir*
git clone https://github.com/tensorflow/tensorflow.git tensorflow_src
mkdir tflite_build

*CMake Build*
cd tflite_build
cmake -DCMAKE_TOOLCHAIN_FILE=/home/ubuntu/android-ndk-r21e/build/cmake/android.toolchain.cmake \
-DANDROID_ABI=armeabi-v7a -DANDROID_NATIVE_API_LEVEL=28 -DANDROID_ARM_NEON=ON \
-DCMAKE_BUILD_TYPE=Release ../tensorflow_src/tensorflow/lite
cmake --build . -j -t benchmark_model

*Bazel Build (in tensorflow_src dir)*
bazel build -c opt --config=android_arm tensorflow/lite/tools/benchmark:benchmark_model

*Running on Mediatek dev board*
I adb push both benchmark_model binaries to my dev board and run them, but get drastically different speeds. The board uses A53 cores, hence the android_arm argument in Bazel and armeabi-v7a argument in CMake.


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

"
48830,Error when loading TensorFlow SavedModel with tag set 'serve': FileFactory 'local_file' not found.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Preinstalled
- TensorFlow version: 2.4.1
- Python version:  3.7.10
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version:  11.2  
- GPU model and memory: Tesla P100 16G



**Describe the problem**
I have created a sequence classification model using tfhub `small_bert/bert_en_uncased_L-6_H-512_A-8` preprocessor and `bert_en_uncased_preprocess/2` encoder.  I have provided the main components of the code below.  After saving the saved_model and uploading to Google Cloud Storage, I am following the documentation for instantiating a BigQuery ML model from the saved model but receiving the following error:

```
Executing query with job ID: d6223072-8b7c-4672-a450-5ec8a23e7351
Query executing: 8.99s
ERROR:
 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/adapt-ml/queries/d6223072-8b7c-4672-a450-5ec8a23e7351?maxResults=0&timeoutMs=400&location=US: Error when loading TensorFlow SavedModel with tag set 'serve': FileFactory 'local_file' not found. The application has not been linked against the '//file/localfile' library or InitGoogle() has not been called yet.
	 [[{{node text_file_init/InitializeTableFromTextFileV2}}]]

(job ID: d6223072-8b7c-4672-a450-5ec8a23e7351)

                              -----Query Job SQL Follows-----                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:CREATE OR REPLACE MODEL `adapt-ml.bigquery_ml.sentiment`
   2:OPTIONS (MODEL_TYPE='TENSORFLOW',  MODEL_PATH='gs://adapt-ml-bucket/finetuned_model/*')
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
````
I am not sure if this is a TensorFlow, TFHub, or BigQuery error as I was unable to locate any similar issue in web searches or Github searches.


**Provide the exact sequence of commands / steps that you executed before running into the problem**
COmmand steps follow linearly below.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Model Information:
```
def build_classifier_model(train_dataset):
  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing', )
  encoder_inputs = preprocessing_layer(text_input)
  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')
  outputs = encoder(encoder_inputs)
  pooled = outputs['pooled_output']

  net = tf.keras.layers.Dense(
              HIDDEN_LAYER_DIMS,
              kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.002),
              activation=""relu"",
              name=""pre_classifier""
          )(pooled)  
  
  net = tf.keras.layers.Dropout(DROPOUT, trainable=True)(net)
  net = tf.keras.layers.Dense(2, activation=""sigmoid"", name='classifier')(net)
  model = tf.keras.Model(text_input, net)

  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

  epochs = EPOCHS
  steps_per_epoch = tf.data.experimental.cardinality(train_dataset).numpy()
  num_train_steps = steps_per_epoch * epochs
  num_warmup_steps = int(0.1*num_train_steps)

  optimizer = optimization.create_optimizer(init_lr=LEARNING_RATE,
                                            num_train_steps=num_train_steps,
                                            num_warmup_steps=num_warmup_steps,
                                            optimizer_type='adamw')

  model.compile(optimizer=optimizer,
                          loss=loss,
                          metrics=['accuracy'])
  
  model.summary()
  
  return model
```

Train Model:
```
model = build_classifier_model(train_dataset)

checkpoint = ModelCheckpoint(filepath=SAVE_MODEL_PATH, 
                             verbose=1,
                             save_freq='epoch',
                             monitor='val_accuracy',
                             save_best_only=True, 
                             mode='max', 
                             save_weights_only=True)


# Training model...
history = model.fit(train_dataset, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=checkpoint, validation_data=valid_dataset)
```

Reload model and save as saved_model:
```
model = build_classifier_model(train_dataset)
model.load_weights(SAVE_MODEL_PATH)
#model.save('finetuned_model', include_optimizer=False, save_traces=False)
#model = tf.keras.models.load_model('finetuned_model')

!rm -r finetuned_model

tf.saved_model.save(
    model,
    'finetuned_model',
    signatures=None,
    options=None, 
)
```

Checking correct signature:
```
loaded = tf.saved_model.load('finetuned_model')
print(list(loaded.signatures.keys()))  # [""serving_default""]

infer = loaded.signatures[""serving_default""]
print(infer.structured_input_signature)
print(infer.structured_outputs)
-------------------------------------------------
['serving_default']
((), {'text': TensorSpec(shape=(None,), dtype=tf.string, name='text')})
{'classifier': TensorSpec(shape=(None, 2), dtype=tf.float32, name='classifier')}
```

After copying to GS Bucket:
```
%%bigquery

CREATE OR REPLACE MODEL `adapt-ml.bigquery_ml.sentiment`
OPTIONS (MODEL_TYPE='TENSORFLOW',  MODEL_PATH='gs://adapt-ml-bucket/finetuned_model/*')
```

"
48829,Session takes a long time to initialize c++ api,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: 
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: CUDA 10.1/ cuDNN 7.6.5 / computeCapability: 7.5
- GPU model and memory: GeForce RTX 2080 SUPER, 7982MiB

**Describe the current behavior**
I compiled tensorflow from the source code and link it to my program, using CMake to build it. When I create a new session, it takes a long time, about 2-4 minutes. The Tensorflow logs below show that initialization took 3 minutes.

**Standalone code to reproduce the issue**
```cpp
#include <memory>
#include ""tensorflow/core/public/session.h""

namespace tf = tensorflow;

int main() {
  std::unique_ptr <tf::Session>  session(tf::NewSession(tf::SessionOptions()));
  return 0;
}
```

```cmake
CMAKE_MINIMUM_REQUIRED(VERSION 3.10 FATAL_ERROR)
PROJECT(example LANGUAGES CXX)

ADD_EXECUTABLE(example main.cpp)
TARGET_LINK_LIBRARIES(example
  PRIVATE
    /path/to/libtensorflow_cc.so
)
TARGET_INCLUDE_DIRECTORIES(example
  PRIVATE
    /path/to/tensorflow/include
)

```

**Describe the expected behavior**
On my second computer with i7-5820K and 1080ti (11gb), the session initializes instantly. It seems to me that the problem is with the processor instructions, but I do not know which ones.

**Other info / logs** 

**lscpu-log:**
```
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
CPU(s):              8
On-line CPU(s) list: 0-7
Thread(s) per core:  1
Core(s) per socket:  1
Socket(s):           8
NUMA node(s):        1
Vendor ID:           GenuineIntel
CPU family:          6
Model:               79
Model name:          Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz
Stepping:            1
CPU MHz:             2099.998
BogoMIPS:            4199.99
L1d cache:           32K
L1i cache:           32K
L2 cache:            256K
L3 cache:            20480K
NUMA node0 CPU(s):   0-7
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 invpcid rtm rdseed adx smap xsaveopt arat md_clear flush_l1d arch_capabilities
```
**tensorflow-log:**
```
2021-04-29 23:10:50.424958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1                                                                
2021-04-29 23:10:50.428763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning
 NUMA node zero                                                                                                                                                                                             
2021-04-29 23:10:50.429258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                                                                                        
pciBusID: 0000:03:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5                                                                                                                                  
coreClock: 1.86GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s                                                                                                               
2021-04-29 23:10:50.429579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                           
2021-04-29 23:10:50.431668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10                                                             
2021-04-29 23:10:50.433630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10                                                              
2021-04-29 23:10:50.433988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10                                                             
2021-04-29 23:10:50.436231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10                                                           
2021-04-29 23:10:50.437545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10                                                           
2021-04-29 23:10:50.443697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7                                                               
2021-04-29 23:10:50.443824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning
 NUMA node zero                                                                                                                                                                                             
2021-04-29 23:10:50.444345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning
 NUMA node zero                                                                                                                                                                                             
2021-04-29 23:10:50.444774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0                                                                                          
2021-04-29 23:13:59.144099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:                                                        
2021-04-29 23:13:59.144129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0                                                                                                                 
2021-04-29 23:13:59.144197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N                                                                                                                 
2021-04-29 23:13:59.144430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning
 NUMA node zero                                                                                                                                                                                             
2021-04-29 23:13:59.144994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning
 NUMA node zero                                                                                                                                                                                             
2021-04-29 23:13:59.145535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning
 NUMA node zero                                                                                                                                                                                             
2021-04-29 23:13:59.146044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2227 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:03:00.0, compute capability: 7.5)
```
**thanks!**"
48828,make -f error,"maos 11.3
Python 3.9.4
esp-idf4.2


error：

cafe@CafedeiMac tensorflow % make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project
tensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.
tensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.
make: *** No rule to make target 'tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/hello_world/esp-idf/components/tfmicro/third_party/gemmlowp/fixedpoint/fixedpoint.h', needed by 'generate_hello_world_esp_project'.  Stop.

"
48826,Cached augmentation and BATCH_SIZE not used in CycleGAN tutorial ,"## URL(s) with the issue:

https://www.tensorflow.org/tutorials/generative/cyclegan

## Description of issue (what needs changing):

Seems like the data pipeline for the CycleGAN is using cache after augmenting the data.
Is this intentional? Doesn't that make augmentation useless?

Another ""problem"" in the data pipeline: a batch size of 1 is used even if there is a 'BATCH_SIZE' variable at the start of the tutorial."
48825,Warning message when using custom loss function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution: UBUNTU 18.04
- TensorFlow installed from: CONDA
- TensorFlow version: 2.4.1
- Python version: 3.8
- CUDA/cuDNN version: 11.2
- GPU model and memory: 4 x TITAN Xp 12GB

----------------------

Greetings from Italy!
I coded a simple autoencoder (I used one of the stock example script you can find on TF) just to see if I was able to implement a custom loss function. This is the code (jupyter notebook file): 

https://github.com/notprime/autoencoder/blob/main/autoencoder.ipynb

Basically, that **`function`** in `[3]` is something I didn't code, and its vectorialization is pretty hard. Therefore, when I get the hidden output tensor, I convert it into a numpy array, compute the matrix I need, convert it back into a TF tensor, and I compute the custom loss function.

When I train the model, I get the following error:
```
WARNING:tensorflow:AutoGraph could not transform <function compute_loss at 0x7f0e688fbe50> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
```

Is this something I should worry about?
Moreover, how does TF handle the automatic-differentiation of this `compute_loss` function (which calls in every for loop the other ** `function`**? This is something I'd really like to better understand.
If you also have some advices on how optimize the code let me know, this is really my first time using TF. Maybe I can convert those function into TF function using the methods `tf.autograph` or `tf.autograph.to_graph`?

Thanks in advance!
"
48824,"When pulling out layers from the model for extracting intermediate computation data, weights and activation output etc. the weights and biases are changing in different cases.","I realised is the weights and biases are getting modified in this procedure and graph structure is also changing when visualised through netron and the same changed structure is reflecting when checked via scripting to cross validate the netron output. Conv2_block1_2 for example had no BN layer before Relu. But If want to pull out the Relu output then it adds BN layers at every node which is being pulled out



outputs= [my_model.get_layer(""conv2_block1_1_relu"").output, my_model.get_layer(""conv2_block1_2_conv"").output, my_model.get_layer(""conv2_block1_2_relu"").output]

model_debug = tensorflow.keras.Model(inputs=my_model.inputs, outputs=outputs)

![orginal resnet tflite converted](https://user-images.githubusercontent.com/82860513/116591121-1deaef80-a93c-11eb-9473-e90b6a32abd4.png)
![with few pulled to outputs weights changed ](https://user-images.githubusercontent.com/82860513/116590970-f7c54f80-a93b-11eb-9bf6-0c0b8b270e19.png)
![with all initial layers pulled to outputs (2)](https://user-images.githubusercontent.com/82860513/116590996-feec5d80-a93b-11eb-81a3-71dec8623c28.png)



"
48823,"U2Net tf pb model works fine , but tflite model works wrong","The project is from [pytorch model](https://github.com/xuebinqin/U-2-Net)  
I use [colab](https://colab.research.google.com/drive/10bPSzQL8-im6RdP8fXm2_VCcbETGvcNM?usp=sharing)
I put two result pics together.    

Only need to update my_tf_model.pb-20210429T083200Z-001.zip in colab.  
 
[my_tf_model.pb-20210429T083200Z-001.zip](https://github.com/tensorflow/tensorflow/files/6397925/my_tf_model.pb-20210429T083200Z-001.zip)  

[my_tf_model.zip](https://github.com/tensorflow/tensorflow/files/6397926/my_tf_model.zip)  
[my_model2.zip](https://github.com/tensorflow/tensorflow/files/6397932/my_model2.zip)  

"
48821,C++ compilation of rule '@llvm-project//mlir:SPIRVDialect' failed (Exit 1): gcc failed: error executing command,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):Tensorflow-2.4.0
- Python version:3.7.9
- Bazel version (if compiling from source):3.1.0
- GCC/Compiler version (if compiling from source):8.3.0
- CUDA/cuDNN version: cpu mode
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
when I build tensorflow-2.4.0 on loongson platform, it build failed, log as below:

root@loongson:/home/loongson/codespace/tensorflow-2.4.0# bazel build --verbose_failures --config=noaws --config=opt --host_copt=-march=loongarch64 --copt=-O3 --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector  //tensorflow/tools/pip_package:build_pip_package --disk_cache /mnt
Starting local Bazel server and connecting to it...
INFO: Invocation ID: a03d3db0-1b20-48fb-bef6-f73324e9b282
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=198
INFO: Reading rc options for 'build' from /home/loongson/codespace/tensorflow-2.4.0/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/loongson/codespace/tensorflow-2.4.0/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /home/loongson/codespace/tensorflow-2.4.0/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.7/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:noaws in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --define=no_aws_support=true
INFO: Found applicable config definition build:opt in file /home/loongson/codespace/tensorflow-2.4.0/.tf_configure.bazelrc: --copt=-march=loongarch64 --host_copt=-march=loongarch64 --define with_default_optimizations=true
INFO: Found applicable config definition build:linux in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (381 packages loaded, 29967 targets configured).
INFO: Found 1 target...
INFO: Deleting stale sandbox base /root/.cache/bazel/_bazel_root/ed10c4c178351d92634570f8a57528bc/sandbox
**ERROR: /root/.cache/bazel/_bazel_root/ed10c4c178351d92634570f8a57528bc/external/llvm-project/mlir/BUILD:1931:1: C++ compilation of rule '@llvm-project//mlir:SPIRVDialect' failed (Exit 1): gcc failed: error executing command** 
  (cd /root/.cache/bazel/_bazel_root/ed10c4c178351d92634570f8a57528bc/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/local/lib/python3.7/dist-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.d '-frandom-seed=bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.o' -fPIC -DLLVM_ENABLE_STATS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DLLVM_BUILD_GLOBAL_ISEL -iquote external/llvm-project -iquote bazel-out/loongarch64-opt/bin/external/llvm-project -iquote external/zlib -iquote bazel-out/loongarch64-opt/bin/external/zlib -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/DialectSymbolRegistry -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineMemoryOpInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ViewLikeInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFPassIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVAvailabilityIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVCanonicalizationIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpUtilsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVPassIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVSerializationGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CopyOpInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/TransformsPassIncGen -isystem external/llvm-project/mlir/include -isystem bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/include -isystem external/llvm-project/llvm/include -isystem bazel-out/loongarch64-opt/bin/external/llvm-project/llvm/include -isystem external/zlib -isystem bazel-out/loongarch64-opt/bin/external/zlib -w -DAUTOLOAD_DYNAMIC_KERNELS '-march=loongarch64' -O3 -Wformat -Wformat-security -fstack-protector -fPIC -fpic '-std=c++14' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/llvm-project/mlir/lib/Dialect/SPIRV/SPIRVDialect.cpp -o bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.o)
Execution platform: @local_execution_config_platform//:platform
/tmp/ccE09hqX.s: Assembler messages:
/tmp/ccE09hqX.s:182293: Internal error (Bus error).
Please report this bug.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 338.589s, Critical Path: 58.18s
INFO: 162 processes: 162 local.
FAILED: Build did NOT complete successfully


**Describe the expected behavior**
It is because llvm-project issue?  How can I set to use system llvm  when build Tensorflow, not use external/llvm-project which is download from the github.

**Please help to resolve this issue!** 
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48820,Convert Tensorflow trained model to older version compatible.,"I want to make an object detection API. I decided to deploy it on AWS Lambda. For that purpose I used this git repository https://github.com/mikylucky/lambda-tensorflow-object-detection

As you can see it uses tensorflow 1.9 version. Unfortunately, I trained my model and exported inference graph with tensorflow 1.12 and when I try to run inference on AWS lambda with this script:

```
import os
import glob
import boto3
import numpy as np
import tensorflow as tf
import PIL
import matplotlib
import sys
from distutils.version import StrictVersion
from PIL import Image
from utils import ops as utils_ops
from matplotlib import pyplot as plt

# Object detection imports
from utils import label_map_util
from utils import visualization_utils as vis_util
import json

# Download Model From S3.
MODEL_GRAPH_DEF_PATH = '/tmp/model.pb'
BUCKET_NAME = 'solver'

def lambda_handler(event, context):
  s3 = boto3.resource('s3')
  print(event['queryStringParameters'])
  img_url = 'images/' + event['queryStringParameters']['image_name']
  model_path = 'models/' + event['queryStringParameters']['model_name'] + '.pb'
  print(""DOWNLOADING MODEL "" + model_path)
  s3.Bucket(BUCKET_NAME).download_file(model_path,MODEL_GRAPH_DEF_PATH)
  print(""DOWNLOADING IMAGE "" + img_url)
  s3.Bucket(BUCKET_NAME).download_file(img_url,'/tmp/image.jpg')
  label_path = 'models/' + event['queryStringParameters']['model_name'] + '.pbtxt'
  print(""DOWNLOADING LABEL MAP "" + label_path)
  s3.Bucket(BUCKET_NAME).download_file(label_path,'/tmp/label_map.pbtxt')
  print(glob.glob(""/tmp/*""))
  detect()

def detect():
  PATH_TO_CKPT = '/tmp/model.pb'
  PATH_TO_IMAGE = '/tmp//image.jpg'
  NUM_CLASSES = 1
  label_map = label_map_util.load_labelmap('/tmp/label_map.pbtxt')
  categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)
  category_index = label_map_util.create_category_index(categories)

  detection_graph = tf.Graph()
  with detection_graph.as_default():
    od_graph_def = tf.GraphDef()
    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
        serialized_graph = fid.read()
        od_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(od_graph_def, name='')

    sess = tf.Session(graph=detection_graph)

  # Define input and output tensors (i.e. data) for the object detection classifier

  # Input tensor is the image
  image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')

  # Output tensors are the detection boxes, scores, and classes
  # Each box represents a part of the image where a particular object was detected
  detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')

  # Each score represents level of confidence for each of the objects.
  # The score is shown on the result image, together with the class label.
  detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')
  detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')

  # Number of objects detected
  num_detections = detection_graph.get_tensor_by_name('num_detections:0')
 
  print(""SOMETHING WAS LOADED"")
  print(num_detections)
```

I get an error like this: 

> NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, Truncate=false](image_tensor). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).: ValueError
> Traceback (most recent call last):
>   File ""/var/task/lambda_function.py"", line 36, in lambda_handler
>     detect()
>   File ""/var/task/lambda_function.py"", line 52, in detect
>     tf.import_graph_def(od_graph_def, name='')
>   File ""/var/task/tensorflow/python/util/deprecation.py"", line 432, in new_func
>     return func(*args, **kwargs)
>   File ""/var/task/tensorflow/python/framework/importer.py"", line 422, in import_graph_def
>     raise ValueError(str(e))
> ValueError: NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, Truncate=false](image_tensor). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).

I read that it is because of tensorflow version difference between runtime environment and the one I trained model on. Sadly I cannot update tensorflow version on lambda to 1.12 to make it work, cause lambda has 200mb limit of function code, and this repository Im using is specially made to fit this requirement. Retraining models on 1.9 is not an option too, cause it would take a lot of time, and due to CUDA requirements I'm not even sure at the moment if my computer would be suitable for this.

I wonder if there is a way to somehow convert .pb file to match 1.9 tensorflow version and to make it work?

"
48818,TFDS link broken for Cars196,"Trying to download Cars196 using tflite_model_maker

train_data, validation_data, test_data = ImageClassifierDataLoader.from_tfds('cars196')

DownloadError: Failed to get url https://imagenet.stanford.edu/internal/car196/cars_test.tgz. HTTP code: 404.

It was working previously, How to resolve?"
48817,Distillation and multi-gpu training with tf.keras,"I use https://github.com/keras-team/keras-io/blob/master/examples/vision/knowledge_distillation.py and single gpu everything is right.

When I use https://keras.io/guides/distributed_training/#singlehost-multidevice-synchronous-training and knowledge_distillation, the val_loss will become very big and the acc is very low.

If I only use distributed_training to train, everything is right too.

When I define test_step and train_step in class Distiller(keras.Model), should I use https://tensorflow.google.cn/guide/distributed_training#using_tfdistributestrategy_with_custom_training_loops?
"
48816,log_softmax potential issue in tflite int8 quantization (how can we skip it?),Since tf.nn.log_softmax givens unexpected constant [-15.9375] for many dimensions. Can I ask how we can skip particular operations quantization? 
48815,Expose a few C API functions to allow custom gradients,"**System information**
- TensorFlow version: 2.4.1
- Are you willing to contribute it: Yes

I'm working on adding custom gradient support to TF-Java, using the legacy graph bindings until the new API is done (tensorflow/java#292).

This requires exposing a few internal functions of the C API:
* `TF_Operation* ToOperation(Node* node) ` to work with the c++ API for gradient defs (necessary since the `Node` constructor isn't public, I can't just use the struct).
* `TF_NewOperationLocked` and
* `TF_FinishOperationLocked` because both the C API gradient definition function and the normal versions of those functions lock the graph's muxex, preventing you from using the C API op def functions in a gradient definition.

**Describe the feature and the current behavior/state.**
I would like to expose the above functions, presumably in `c_api_internal.h`.  These functions are not exposed currently.

Another option is to create and expose a `TF_AddGradientsWithPrefixLocked` that doesn't use the mutex instead of exposing `TF_NewOperationLocked` and `TF_FinishOperationLocked`.

**Will this change the current api? How?**
It will expose the above functions.

**Who will benefit with this feature?**

Anyone who wants to add custom gradient support to an API using the C API.
"
48813,undefined reference to `tensorflow::Status::Status,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.1
- Python version: python3.6
- Bazel version (if compiling from source): bazel 3.1.0
- GCC/Compiler version (if compiling from source): GCC7.5.0
- CUDA/cuDNN version: N
- GPU model and memory: N

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I have run the speech command example, and I already trained the model with python, and now I want to inference with C++ API, so I build libtensorflow.so successfully, and I compile **label_wav.cc** with CMakefile.txt , errors as bellow:

/usr/bin/ld: CMakeFiles/main.dir/label_wav.cc.o: in function `tensorflow::Status::Status(tensorflow::error::Code, absl::string_view)':
/home/yw.shi/env/tf241/tensorflow/core/platform/status.h:54: undefined reference to `tensorflow::Status::Status(tensorflow::error::Code, absl::string_view, std::vector<tensorflow::StackFrame, std::allocator<tensorflow::StackFrame> >&&)'
collect2: 错误：ld 返回 1
make[2]: *** [CMakeFiles/main.dir/build.make:84：../main] 错误 1
make[1]: *** [CMakeFiles/Makefile2:76：CMakeFiles/main.dir/all] 错误 2
make: *** [Makefile:84：all] 错误 2


**Describe the expected behavior**
Want to know how to build the label_wav.cc with cmake.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
CMakefile.txt
cmake_minimum_required(VERSION 2.8)
project(assistant-service)

message(${CMAKE_SOURCE_DIR})

if (${CMAKE_BUILD_TYPE} STREQUAL ""DEBUG"")
    add_definitions(-D_DEBUG)
endif (${CMAKE_BUILD_TYPE} STREQUAL ""DEBUG"")

set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -std=c++11 -fPIC -fpermissive"")
set(CMAKE_CXX_FLAGS_DEBUG ""-O0 -g -ggdb -Wall"")
set(CMAKE_CXX_FLAGS_RELEASE ""-O3 -Wall"")

SET(CMAKE_THIRDPARTY_PATH ""/home/yw.shi/env/tf241"")

SET(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE) 
SET(CMAKE_INSTALL_RPATH
    ""/root/anaconda3/lib""
    ""/usr/lib64""
    ""/home/yw.shi/env/tf241/lib/""
    ""/home/yw.shi/env/tf241/third_party/abseil-cpp/lib/""
   )

set(Main  ""${CMAKE_SOURCE_DIR}/label_wav.cc"")

include_directories(""/home/yw.shi/framework/tensorflow-2.4.1/bazel-tensorflow-2.4.1/external/eigen_archive"")
include_directories(""/home/yw.shi/env/tf241"")
include_directories(""/home/yw.shi/env/tf241/compile"")

include_directories(""/home/yw.shi/env/tf241/third_party/abseil-cpp/include/"")
include_directories(""/home/yw.shi/env/tf241/protobuf/v3.9.2/include/"")


link_directories(""/usr/lib64"")
link_directories(""/home/yw.shi/env/tf241/lib"")
link_directories(""/home/yw.shi/env/tf241/protobuf/v3.9.2/lib/"")

link_directories(""/home/yw.shi/env/tf241/third_party/abseil-cpp/lib64"")

set(EXECUTABLE_OUTPUT_PATH ${CMAKE_SOURCE_DIR})
add_executable(main ${Main})
target_link_libraries(main tensorflow_cc tensorflow_framework)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48810,xla Compiling and Bug issues,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution : UBUNTU 18.04
- TensorFlow installed from (source or binary): NVIDIA Container 21.03
- TensorFlow version (use command below): 1.15.5
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:11.2/8.1.1
- GPU model and memory: A100 40GB

Dear All-

We tried to run a tensorflow based program with xla option on and with Float64. It throws the following error

2021-04-28 21:33:40.228029: W ./tensorflow/compiler/xla/service/hlo_pass_fix.h:50] Unexpectedly high number of iterations in HLO passes 'simplification' exiting fixed point loop.
2021-04-28 21:34:18.432071: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.
2021-04-28 21:34:18.432136: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2021-04-28 21:34:18.432146: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2021-04-28 21:34:18.432150: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2021-04-28 21:34:18.432153: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2021-04-28 21:34:18.432157: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2021-04-28 21:34:18.489483: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-04-28 21:34:21.374512: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.
2021-04-28 21:34:21.374608: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2021-04-28 21:34:21.374616: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2021-04-28 21:34:21.374620: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2021-04-28 21:34:21.374624: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2021-04-28 21:34:21.374629: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2021-04-28 21:34:21.432005: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-04-28 21:34:22.707773: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.
2021-04-28 21:34:22.707843: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2021-04-28 21:34:22.707865: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2021-04-28 21:34:22.707870: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2021-04-28 21:34:22.707875: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2021-04-28 21:34:22.707881: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2021-04-28 21:34:22.770755: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-04-28 21:34:23.269560: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.
2021-04-28 21:34:23.269643: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2021-04-28 21:34:23.269654: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2021-04-28 21:34:23.269658: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2021-04-28 21:34:23.269664: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2021-04-28 21:34:23.269668: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2021-04-28 21:34:23.335512: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-04-28 21:34:25.538813: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.
2021-04-28 21:34:25.538892: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2021-04-28 21:34:25.538902: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2021-04-28 21:34:25.538907: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2021-04-28 21:34:25.538910: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2021-04-28 21:34:25.538915: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2021-04-28 21:34:25.597336: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-04-28 21:34:26.675753: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.
2021-04-28 21:34:26.675825: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2021-04-28 21:34:26.675835: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2021-04-28 21:34:26.675839: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2021-04-28 21:34:26.675844: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2021-04-28 21:34:26.675873: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2021-04-28 21:34:26.738493: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-04-28 21:34:28.676419: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.
2021-04-28 21:34:28.676522: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2021-04-28 21:34:28.676543: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2021-04-28 21:34:28.676550: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2021-04-28 21:34:28.676554: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2021-04-28 21:34:28.676558: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2021-04-28 21:34:28.692114: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.
2021-04-28 21:34:28.692203: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2021-04-28 21:34:28.692213: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2021-04-28 21:34:28.692219: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2021-04-28 21:34:28.692223: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2021-04-28 21:34:28.692226: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2021-04-28 21:34:28.741081: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-04-28 21:34:28.754700: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-04-28 21:34:30.031037: E tensorflow/stream_executor/cuda/cuda_driver.cc:614] failed to load PTX text as a module: CUDA_ERROR_INVALID_PTX: a PTX JIT compilation failed
2021-04-28 21:34:30.031132: E tensorflow/stream_executor/cuda/cuda_driver.cc:619] error log buffer (1024 bytes): ptxas error   : Entry function 'fusion_466' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_462' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_488' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_498' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_490' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_500' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_520' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_524' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_460' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_534' uses too much shared data (0xc600 bytes, 0xc000 max)
ptxas error   : Entry function 'fusion_464' uses too 
Traceback (most recent call last):
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/client/session.py"", line 1349, in _run_fn
    return self._call_tf_sessionrun(options, feed_dict, fetch_list,
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/client/session.py"", line 1441, in _call_tf_sessionrun
    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
tensorflow.python.framework.errors_impl.InternalError: Failed to load PTX text as a module: CUDA_ERROR_INVALID_PTX: a PTX JIT compilation failed
	 [[{{node cluster_2_1/xla_run}}]]
The same code run with out the xla option on. The xla option work seamlessly for float32 and tf32.

We will appreciate your help.

Thanks!
Raj
"
48808,Tensorflow 2.3 or up Installation on Mac OS Big Sur 11.3,"Hi,

I am trying to install tensorflow 2.3 or up on Mac OS Big Sur 11.3.  I'm trying to do it in a conda environment with python 3.7.  This is a cpu install.  

When I try pip install tensorflow, and go into a python terminal and import, it says that the module does not exist.  
When I conda install tensorflow in the conda environment and go into a python terminal and import, I can only get tensorflow 2.0.0.  
When I try conda install -c conda-forge tensorflow and go into a python terminal and import tensorflow, I get a slew of warnings of signed and unsigned types:
/Users/blah/anaconda3/envs/funkmuffin2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: 
FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/Users/blah/anaconda3/envs/funkmuffin2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: 
FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
.....
/Users/blah/anaconda3/envs/funkmuffin2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
.... and when I conda update -f -c conda-forge tensorflow, I get the same warnings and I still only get tensorflow 1.14.

Would you know why I cannot simply get tensorflow 2.3 or higher installed?  and/or would anybody know how to do so?  Thank you.   

"
48802,C API TF_LoadSessionFromSavedModel leaks memory,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Using TF-Java bindings
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Oracle Linux 7
- TensorFlow installed from (source or binary): binary from TF-Java
- TensorFlow version (use command below): 2.4.1
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): gcc-7

**Describe the current behavior**

When running the reproducer code from https://github.com/tensorflow/java/issues/304 under `valgrind --tool=memcheck --leak-check=full` after recompiling TF with debug symbols shows leaks in the `TF_LoadSessionFromSavedModel` and `TF_NewGraph`.

```
==64241== 1,452,789 (73,728 direct, 1,379,061 indirect) bytes in 9 blocks are definitely lost in loss record 144,850 of 144,860
==64241==    at 0x4C2C375: memalign (vg_replace_malloc.c:908)
==64241==    by 0x4C2C43F: posix_memalign (vg_replace_malloc.c:1072)
==64241==    by 0x568E8E56: tensorflow::port::AlignedMalloc(unsigned long, int) (port.cc:241)
==64241==    by 0x5688C970: tensorflow::core::Arena::AllocNewBlock(unsigned long, unsigned int) (arena.cc:174)
==64241==    by 0x5688CC98: tensorflow::core::Arena::MakeNewBlock(unsigned int) (arena.cc:111)
==64241==    by 0x5688CD60: tensorflow::core::Arena::GetMemoryFallback(unsigned long, int) (arena.cc:211)
==64241==    by 0x565887E8: GetMemory (arena.h:75)
==64241==    by 0x565887E8: Alloc (arena.h:42)
==64241==    by 0x565887E8: tensorflow::Graph::AllocateNode(std::shared_ptr<tensorflow::NodeProperties>, tensorflow::Node const*, tensorflow::Node::NodeClass) (graph.cc:773)
==64241==    by 0x5658ECAA: tensorflow::Graph::AddNode(tensorflow::NodeDef, tensorflow::Status*) (graph.cc:438)
==64241==    by 0x567DF8A3: MakeNode (graph_constructor.cc:778)
==64241==    by 0x567DF8A3: tensorflow::(anonymous namespace)::GraphConstructor::Convert() (graph_constructor.cc:1246)
==64241==    by 0x567E54C0: tensorflow::(anonymous namespace)::GraphConstructor::TryImport() (graph_constructor.cc:195)
==64241==    by 0x567E8BB4: tensorflow::(anonymous namespace)::GraphConstructor::Construct(tensorflow::(anonymous namespace)::GraphConstructor::Options const&, absl::lts_2020_02_25::Span<tensorflow::NodeDef const* const>, tensorflow::VersionDef const*, tensorflow::FunctionDefLibrary const*, tensorflow::Graph*, tensorflow::ShapeRefiner*, std::vector<std::pair<tensorflow::Node*, int>, std::allocator<std::pair<tensorflow::Node*, int> > >*, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >*, std::vector<tensorflow::SafeTensorId, std::allocator<tensorflow::SafeTensorId> >*) (graph_constructor.cc:503)
==64241==    by 0x567E93AC: tensorflow::ImportGraphDef(tensorflow::ImportGraphDefOptions const&, tensorflow::GraphDef const&, tensorflow::Graph*, tensorflow::ShapeRefiner*, tensorflow::ImportGraphDefResults*) (graph_constructor.cc:1556)
==64241== 
==64241== 1,971,801 (1,728 direct, 1,970,073 indirect) bytes in 12 blocks are definitely lost in loss record 144,855 of 144,860
==64241==    at 0x4C2AC38: operator new[](unsigned long) (vg_replace_malloc.c:433)
==64241==    by 0x842C67275: Init (flatrep.h:267)
==64241==    by 0x842C67275: FlatRep (flatrep.h:52)
==64241==    by 0x842C67275: FlatMap (flatmap.h:75)
==64241==    by 0x842C67275: FlatMap (flatmap.h:72)
==64241==    by 0x842C67275: TF_Graph::TF_Graph() (c_api.cc:1534)
==64241==    by 0x842C6732D: TF_NewGraph (c_api.cc:1539)
==64241==    by 0x7F938FCB: Java_org_tensorflow_internal_c_1api_global_tensorflow_TF_1NewGraph (in /home/apocock/.javacpp/cache/tensorflow-core-api-0.3.1-linux-x86_64.jar/org/tensorflow/internal/c_api/linux-x86_64/libjnitensorflow.so)
==64241==    by 0xEBC3C7A: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBB6CC8: ???
==64241==    by 0x6430284: JavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) (in /usr/java/jdk-16.0.1/lib/server/libjvm.so)
==64241== 
==64241== 2,300,256 (15,792 direct, 2,284,464 indirect) bytes in 14 blocks are definitely lost in loss record 144,856 of 144,860
==64241==    at 0x4C2A593: operator new(unsigned long) (vg_replace_malloc.c:344)
==64241==    by 0x842C67322: TF_NewGraph (c_api.cc:1539)
==64241==    by 0x7F938FCB: Java_org_tensorflow_internal_c_1api_global_tensorflow_TF_1NewGraph (in /home/apocock/.javacpp/cache/tensorflow-core-api-0.3.1-linux-x86_64.jar/org/tensorflow/internal/c_api/linux-x86_64/libjnitensorflow.so)
==64241==    by 0xEBC3C7A: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBBF3AA: ???
==64241==    by 0xEBB6CC8: ???
==64241==    by 0x6430284: JavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) (in /usr/java/jdk-16.0.1/lib/server/libjvm.so)
==64241==    by 0x64C369A: jni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) [clone .constprop.1] (in /usr/java/jdk-16.0.1/lib/server/libjvm.so)
==64241==
==64241== 3,249,675 (640 direct, 3,249,035 indirect) bytes in 20 blocks are definitely lost in loss record 144,858 of 144,860
==64241==    at 0x4C2A593: operator new(unsigned long) (vg_replace_malloc.c:344)
==64241==    by 0x842C71031: allocate (new_allocator.h:111)
==64241==    by 0x842C71031: allocate (alloc_traits.h:436)
==64241==    by 0x842C71031: _M_allocate_node<const std::piecewise_construct_t&, std::tuple<const std::basic_string<char, std::char_traits<char>, std::allocator<char> >&>, std::tuple<> > (hashtable_policy.h:2060)
==64241==    by 0x842C71031: std::__detail::_Map_base<std::string, std::pair<std::string const, tensorflow::Node*>, std::allocator<std::pair<std::string const, tensorflow::Node*> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::string const&) (hashtable_policy.h:725)
==64241==    by 0x842C717AF: operator[] (unordered_map.h:976)
==64241==    by 0x842C717AF: GraphImportGraphDefLocked (c_api.cc:1722)
==64241==    by 0x842C79442: TF_LoadSessionFromSavedModel (c_api.cc:2235)
==64241==    by 0x7F939893: Java_org_tensorflow_internal_c_1api_global_tensorflow_TF_1LoadSessionFromSavedModel__Lorg_tensorflow_internal_c_1api_TF_1SessionOptions_2Lorg_tensorflow_internal_c_1api_TF_1Buffer_2Lorg_bytedeco_javacpp_BytePointer_2Lorg_bytedeco_javacpp_PointerPointer_2ILorg_tensorflow_internal_c_1api_TF_1Graph_2Lorg_tensorflow_internal_c_1api_TF_1Buffer_2Lorg_tensorflow_internal_c_1api_TF_1Status_2 (in /home/apocock/.javacpp/cache/tensorflow-core-api-0.3.1-linux-x86_64.jar/org/tensorflow/internal/c_api/linux-x86_64/libjnitensorflow.so)
```

**Describe the expected behavior**

No leaks in the saved model loading code.

**Standalone code to reproduce the issue**
Run the code from https://github.com/tensorflow/java/issues/304 under valgrind.

**Other info / logs**
I have a 29M valgrind file but it's got a lot of noise from the JVM in it. If necessary I can snip out most of the JVM related noise."
48801,Accessing numpy array from a Tensor object using dataset map,"I am trying to access the numpy array from a tensor object that is processed with  https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map.

I get the error: `AttributeError: 'Tensor' object has no attribute 'numpy'`

When I try to access the tensor as: `np_array = tensor.numpy()`

While if I use: `dataset.take(n)`, i am able to access the numpy array.

For more clarity on the situation I am facing, here is a short reproducible example of the error in a google colab:

https://colab.research.google.com/drive/13ectGEMDSygcyuW4ip9zrWaHO3pSxc3p?usp=sharing

Tensorflow version: 2.4.1"
48799,AttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2,"Hey
Some help on this bug, 
I am using tensorflow ==1.15

Traceback (most recent call last):
  File ""a2c.py"", line 7, in <module>
    import  keras.backend as K
  File ""/home/david/miniconda3/envs/kedro-environment/lib/python3.7/site-packages/keras/__init__.py"", line 20, in <module>
    from . import initializers
  File ""/home/david/miniconda3/envs/kedro-environment/lib/python3.7/site-packages/keras/initializers/__init__.py"", line 124, in <module>
    populate_deserializable_objects()
  File ""/home/david/miniconda3/envs/kedro-environment/lib/python3.7/site-packages/keras/initializers/__init__.py"", line 49, in populate_deserializable_objects
    LOCAL.GENERATED_WITH_V2 = tf.__internal__.tf2.enabled()
AttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2'

"
48797,Importing torchvision before tensorflow causes protobuf error.,"**System information**
<details>
<summary>System information</summary>

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux x86_64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary? (package: `tensorflow-cuda` from official Arch repos)
- TensorFlow version (use command below): unknown 2.4.1
- Python version: 3.9.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA=11.3.0, cuDNN=8.1.1.33
- GPU model and memory: NVIDIA GeForce GTX 1060 6GB

</details>

**Describe the current behavior**

```python
import torchvision
import tensorflow
```

causes:

```python
  File ""/usr/lib/python3.9/site-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 141, in <module>
    ResourceHandleProto = _reflection.GeneratedProtocolMessageType('ResourceHandleProto', (_message.Message,), {
SystemError: google/protobuf/pyext/descriptor.cc:354: bad argument to internal function
```

However,

```python
import tensorflow
import torchvision
```

...causes no such error.

**Describe the expected behavior**

No error.

**Standalone code to reproduce the issue**

```python
import torchvision
import tensorflow
```

**Other info / logs**

<details>
<summary>Traceback</summary>

```python
Traceback (most recent call last):
  File ""/home/mulhaq/tmp.py"", line 2, in <module>
    import tensorflow
  File ""/usr/lib/python3.9/site-packages/tensorflow/__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/usr/lib/python3.9/site-packages/tensorflow/python/__init__.py"", line 41, in <module>
    from tensorflow.python.eager import context
  File ""/usr/lib/python3.9/site-packages/tensorflow/python/eager/context.py"", line 32, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/usr/lib/python3.9/site-packages/tensorflow/core/framework/function_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/usr/lib/python3.9/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/usr/lib/python3.9/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
  File ""/usr/lib/python3.9/site-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 141, in <module>
    ResourceHandleProto = _reflection.GeneratedProtocolMessageType('ResourceHandleProto', (_message.Message,), {
SystemError: google/protobuf/pyext/descriptor.cc:354: bad argument to internal function
```

</details>

Other users with similar issue: https://stackoverflow.com/questions/65874607/torchvision-and-tensorflow-gpu-import-error"
48796,"Example of tf.scatter_nd contains Session, which is obselete","## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/scatter_nd

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/scatter_nd

## Description of issue (what needs changing):
The Code, 

```python
with tf.Session() as sess:
      print(sess.run(scatter))
```
should be replaced with `print(scatter)`, as the **`Sessions`** are no longer required in **`Tensorflow 2.x`**.

### Correct links

Is the link to the source code correct? : NA

### Parameters defined

Are all parameters defined and formatted correctly? : Yes

### Returns defined

Are return values defined? : Yes

### Raises listed and defined

Are the errors defined? No

### Usage example

Is there a usage example? : Yes"
48794,tensorflow2.3.2 compilation ERROR,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:None
- TensorFlow installed from (source or binary):source
- TensorFlow version:2.3.2
- Python version:3.8.6
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):3.7.2
- GCC/Compiler version (if compiling from source):MSVC2019
- CUDA/cuDNN version:11.0/8.0.5
- GPU model and memory:GeForce RTX 2080 ti

**Describe the problem**
ERROR: C:/users/zn58887/_bazel_zn58887/e5awb3j2/external/nsync/BUILD:467:11: C++ compilation of rule '@nsync//:nsync_cpp' failed (Exit 2): python.exe failed: error executing command

**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build -c dbg --copt=/wd4716 --copt=/FS --copt=THRUST_IGNORE_CUB_VERSION_CHECK --config=opt //tensorflow:tensorflow_cc.dll

**Any other info / logs**
cd C:/users/zn58887/_bazel_zn58887/e5awb3j2/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\ATLMFC\include;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\cppwinrt
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\ATLMFC\lib\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\lib\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\um\x64
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\\Extensions\Microsoft\IntelliCode\CLI;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\MSBuild\Current\bin\Roslyn;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.8 Tools\x64\;C:\Program Files (x86)\HTML Help Workshop;C:\Program Files (x86)\Windows Kits\10\bin\10.0.19041.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\\MSBuild\Current\Bin;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\Tools\;;C:\Windows\system32;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Python38/python.exe
    SET PYTHON_LIB_PATH=C:/Python38/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\zn58887\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=7.5
    SET TF_ENABLE_XLA=1
    SET TF_NEED_CUDA=1
    SET TMP=C:\Users\zn58887\AppData\Local\Temp
  C:/Python38/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /Iexternal/nsync /Ibazel-out/x64_windows-dbg/bin/external/nsync /Iexternal/nsync/public /Ibazel-out/x64_windows-dbg/bin/external/nsync/public /showIncludes /MDd /Od /Z7 /DDEBUG /w /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /wd4716 /FS THRUST_IGNORE_CUB_VERSION_CHECK /arch:AVX /TP -DNSYNC_ATOMIC_CPP11 -DNSYNC_USE_CPP11_TIMEPOINT -I./external/nsync//platform/c++11 -I./external/nsync//platform/win32 -I./external/nsync//platform/msvc -I./external/nsync//platform/x86_64 -I./external/nsync//public -I./external/nsync//internal -I./external/nsync//platform/posix /Fobazel-out/x64_windows-dbg/bin/external/nsync/_objs/nsync_cpp/mu.o /c external/nsync/internal/mu.c
Execution platform: @local_execution_config_platform//:platform
THRUST_IGNORE_CUB_VERSION_CHECK
c1xx: fatal error C1083: 无法打开源文件: “THRUST_IGNORE_CUB_VERSION_CHECK”: No such file or directory
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_cpp.h
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\platform\c++11\platform.h
注意: 包含文件:   C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\string.h
注意: 包含文件:    C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt.h
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\vcruntime.h
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\sal.h
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\concurrencysal.h
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\vadefs.h
注意: 包含文件:    C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_memory.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_memcpy_s.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\errno.h
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\vcruntime_string.h
注意: 包含文件:    C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wstring.h
注意: 包含文件:   C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\stdlib.h
注意: 包含文件:    C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_malloc.h
注意: 包含文件:    C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_search.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\stddef.h
注意: 包含文件:    C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wstdlib.h
注意: 包含文件:    C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\limits.h
注意: 包含文件:   C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\inttypes.h
注意: 包含文件:    C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\stdint.h
注意: 包含文件:   C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\stdio.h
注意: 包含文件:    C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wstdio.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_stdio_config.h
注意: 包含文件:   C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\stdarg.h
注意: 包含文件:   C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\mutex
注意: 包含文件:    C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\yvals_core.h
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xkeycheck.h
注意: 包含文件:    C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\chrono
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\limits
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\cfloat
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\float.h
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\climits
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\cwchar
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\cstdio
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\wchar.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wconio.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wctype.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wdirect.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wio.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_share.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wprocess.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wtime.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\sys/stat.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\sys/types.h
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\intrin0.h
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\isa_availability.h
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xstddef
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\cstddef
注意: 包含文件:        C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xtr1common
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\cstdlib
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\math.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_math.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_math_defines.h
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\initializer_list
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\ratio
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\type_traits
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\time.h
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\utility
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xtimec.h
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\yvals.h
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\crtdbg.h
注意: 包含文件:        C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\vcruntime_new_debug.h
注意: 包含文件:         C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\vcruntime_new.h
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\crtdefs.h
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\use_ansi.h
注意: 包含文件:    C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\system_error
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\__msvc_system_error_abi.hpp
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\cerrno
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\stdexcept
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\exception
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\malloc.h
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\vcruntime_exception.h
注意: 包含文件:        C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\eh.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_terminate.h
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xstring
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\iosfwd
注意: 包含文件:        C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\cstring
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xmemory
注意: 包含文件:        C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\cstdint
注意: 包含文件:        C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\new
注意: 包含文件:        C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xatomic.h
注意: 包含文件:        C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xutility
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xcall_once.h
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xerrc.h
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\atomic
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\xthreads.h
注意: 包含文件:    C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\thread
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\memory
注意: 包含文件:      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\typeinfo
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\vcruntime_typeinfo.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\process.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_startup.h
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\math.h
注意: 包含文件:       C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\vcruntime_startup.h
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\tuple
注意: 包含文件:   C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\condition_variable
注意: 包含文件:   C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\platform\win32\platform_c++11_os.h
注意: 包含文件:    C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\sys/timeb.h
注意: 包含文件:    C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\Windows.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\winapifamily.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\winpackagefamily.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\sdkddkver.h
注意: 包含文件:     C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\excpt.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\windef.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\minwindef.h
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\specstrings.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\specstrings_strict.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\specstrings_undef.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\driverspecs.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\sdv_driverspecs.h
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winnt.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\ctype.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\kernelspecs.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\basetsd.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\guiddef.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack4.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack4.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack4.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack2.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack2.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack2.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack8.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack1.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack1.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\apiset.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\ktmtypes.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winbase.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\apisetcconv.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\minwinbase.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\apiquery2.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\processenv.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\fileapifromapp.h
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\fileapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\debugapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\utilapiset.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\handleapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\errhandlingapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\fibersapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\namedpipeapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\profileapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\heapapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\ioapiset.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\synchapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\interlockedapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\processthreadsapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\sysinfoapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\memoryapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\enclaveapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\threadpoollegacyapiset.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\threadpoolapiset.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\jobapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\jobapi2.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\wow64apiset.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\libloaderapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\securitybaseapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\namespaceapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\systemtopologyapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\processtopologyapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\securityappcontainer.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\realtimeapiset.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\winerror.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\timezoneapi.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\wingdi.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winuser.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack2.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\tvout.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winnls.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\datetimeapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\stringapiset.h
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winnls.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\wincon.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\wincontypes.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\consoleapi.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\consoleapi2.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\consoleapi3.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winver.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\verrsrc.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winreg.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\reason.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winnetwk.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\wnnc.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\stralign.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winsvc.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\mcx.h
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\imm.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\ime_cmodes.h
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\platform\msvc\compiler.h
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\platform\x86_64\cputype.h
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync.h
注意: 包含文件:   C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_mu.h
注意: 包含文件:    C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_atomic.h注意: 包含文件:   C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_mu_wait.h注意: 包含文件:    C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_time.h
注意: 包含文件:     C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_time_internal.h
注意: 包含文件:   C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_cv.h
注意: 包含文件:   C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_note.h
注意: 包含文件:   C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_counter.h注意: 包含文件:   C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_waiter.h
注意: 包含文件:   C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_once.h
注意: 包含文件:   C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\public\nsync_debug.h
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\internal\dll.h
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\internal\sem.h
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\internal\wait_internal.h
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\internal\common.h
注意: 包含文件:  C:\users\zn58887\_bazel_zn58887\e5awb3j2\execroot\org_tensorflow\external\nsync\platform\c++11\atomic.h正在生成代码...
Target //tensorflow:tensorflow_cc.dll failed to build
INFO: Elapsed time: 82.343s, Critical Path: 9.33s
INFO: 4405 processes: 3447 internal, 958 local.
FAILED: Build did NOT complete successfully"
48791,Help : Incorrect read of byte[] { Cannot convert between a TensorFlowLite tensor with type FLOAT32 and a Java object of type [B (which is compatible with the TensorFlowLite type UINT8)  },"The official tutorial mentions that tensor flow should support Byte[]. However, when passed to the model , the following error occurs: 
```
E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.example.se, PID: 6529
    java.lang.RuntimeException: Failure delivering result ResultInfo{who=null, request=65537, result=-1, data=Intent { dat=content://com.android.providers.media.documents/document/audio:31 flg=0x1 }} to activity {com.example.se/com.example.se.Homepage}: java.lang.RuntimeException: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite tensor with type FLOAT32 and a Java object of type [B (which is compatible with the TensorFlowLite type UINT8).
        at android.app.ActivityThread.deliverResults(ActivityThread.java:5015)
        at android.app.ActivityThread.handleSendResult(ActivityThread.java:5056)
        at android.app.servertransaction.ActivityResultItem.execute(ActivityResultItem.java:51)
        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:135)
        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:95)
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2066)
        at android.os.Handler.dispatchMessage(Handler.java:106)
        at android.os.Looper.loop(Looper.java:223)
        at android.app.ActivityThread.main(ActivityThread.java:7656)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)
     Caused by: java.lang.RuntimeException: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite tensor with type FLOAT32 and a Java object of type [B (which is compatible with the TensorFlowLite type UINT8).
        at com.example.se.Classify.onActivityResult(Classify.java:164)
        at androidx.fragment.app.FragmentActivity.onActivityResult(FragmentActivity.java:170)
        at android.app.Activity.dispatchActivityResult(Activity.java:8310)
        at android.app.ActivityThread.deliverResults(ActivityThread.java:5008)
        at android.app.ActivityThread.handleSendResult(ActivityThread.java:5056) 
        at android.app.servertransaction.ActivityResultItem.execute(ActivityResultItem.java:51) 
        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:135) 
        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:95) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2066) 
        at android.os.Handler.dispatchMessage(Handler.java:106) 
        at android.os.Looper.loop(Looper.java:223) 
        at android.app.ActivityThread.main(ActivityThread.java:7656) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947) 
     Caused by: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite tensor with type FLOAT32 and a Java object of type [B (which is compatible with the TensorFlowLite type UINT8).
        at org.tensorflow.lite.Tensor.throwIfTypeIsIncompatible(Tensor.java:427)
        at org.tensorflow.lite.Tensor.getInputShapeIfDifferent(Tensor.java:287)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:146)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:360)
        at org.tensorflow.lite.Interpreter.run(Interpreter.java:319)
        at com.example.se.Classify.onActivityResult(Classify.java:161)
        at androidx.fragment.app.FragmentActivity.onActivityResult(FragmentActivity.java:170) 
        at android.app.Activity.dispatchActivityResult(Activity.java:8310) 
        at android.app.ActivityThread.deliverResults(ActivityThread.java:5008) 
        at android.app.ActivityThread.handleSendResult(ActivityThread.java:5056) 
        at android.app.servertransaction.ActivityResultItem.execute(ActivityResultItem.java:51) 
        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:135) 
        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:95) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2066) 
        at android.os.Handler.dispatchMessage(Handler.java:106) 
        at android.os.Looper.loop(Looper.java:223) 
        at android.app.ActivityThread.main(ActivityThread.java:7656) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947) 
```
My main code is :
```
package com.example.se;

import android.content.Context;
import android.content.Intent;
import android.content.res.AssetFileDescriptor;
import android.content.res.AssetManager;
import android.database.Cursor;
import android.media.AudioManager;
import android.net.Uri;
import android.net.rtp.AudioStream;
import android.os.Bundle;
import android.os.FileUtils;
import android.util.Log;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.Button;
import android.widget.Toast;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;
import androidx.fragment.app.Fragment;

import org.tensorflow.lite.Interpreter;
import org.tensorflow.lite.flex.FlexDelegate;
import java.io.BufferedInputStream;
import java.io.BufferedReader;
import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.lang.Object;
import java.net.URISyntaxException;
import java.nio.ByteBuffer;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class Classify extends Fragment {
    private Button choose_file_button;
    private Button stop_classify;
    public static final int PICKFILE_RESULT_CODE = 1;
    private Uri fileUri;
    private String filePath; // This is the final file path
    View classify_view;

    // To load from asset folder
    private static final String LABEL_FILENAME = ""file:///android_asset/labels.txt"";
    private static final String MODEL_FILENAME = ""file:///android_asset/soundclassifier.tflite"";
    private static final String LOG_TAG = ""Log tagges is here"";

    // For label and modelfile
    private List<String> labels = new ArrayList<String>();
    private List<String> displayedLabels = new ArrayList<>();

    // For the audio file
    ByteArrayOutputStream out = new ByteArrayOutputStream();
    InputStream in;
    byte[] audioBytes;


    // For machine learning
    private final Interpreter.Options tfliteOptions = new Interpreter.Options();
    private MappedByteBuffer tfLiteModel;
    private Interpreter tfLite;
    private final Interpreter.Options ftliteOptions = new Interpreter.Options();
    float[] outputs;
    private RecognizeCommands recognizeCommands = null;
    // ToDo : Remove this if not needed

    @Nullable
    @Override
    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
        classify_view = inflater.inflate(R.layout.classify,container,false);

        // Both finds the classify and stop classify button
        choose_file_button = (Button) classify_view.findViewById(R.id.classify_button);
        stop_classify = (Button) classify_view.findViewById(R.id.stop_classify);

        // For labels file
        String actualLabelFilename = LABEL_FILENAME.split(""file:///android_asset/"",-1)[1];
        Log.i(LOG_TAG,""Reading labels from "" + actualLabelFilename);

        BufferedReader br = null;
        try{
            br = new BufferedReader(new InputStreamReader(classify_view.getContext().getAssets().open(actualLabelFilename)));
            String line;
            while ((line = br.readLine()) != null){
                labels.add(line);
                if (line.charAt(0) != '_'){
                    displayedLabels.add(line.substring(0,1).toUpperCase()+ line.substring(1));
                }
            }
        } catch (IOException e){
            throw new RuntimeException(""Problem reading the label file!"",e);
        }
        // Creates the equal number of labels on the output file
        outputs = new float[displayedLabels.size()];
        Log.i(LOG_TAG,""Labels file messages are :""+ displayedLabels);

        // ToDo : Implement Recognize Commands if not working

        // Opening the model file
        String actualModelFilename = MODEL_FILENAME.split(""file:///android_asset/"",-1)[1];
        try{
            tfLiteModel = loadModelFile(classify_view.getContext().getAssets(), actualModelFilename);
        } catch (Exception e){
            throw new RuntimeException(e);
        }

        Log.i(LOG_TAG,""The modal file is :""+actualModelFilename);
        Log.i(LOG_TAG,""The actual content is :""+tfLiteModel);

        // ToDo : Model file opened here
        try{
            ftliteOptions.setNumThreads(1);
            FlexDelegate flex = new FlexDelegate();
            ftliteOptions.addDelegate(flex);
            File openThis = new File(MODEL_FILENAME);
            tfLite = new Interpreter(tfLiteModel,ftliteOptions);
            // tfLite = new Interpreter(openThis);
        } catch (Exception e){
            throw new RuntimeException(e);
        }
        Log.i(LOG_TAG,""TF lite file loaded. "");

        choose_file_button.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                Intent chooseFile = new Intent(Intent.ACTION_GET_CONTENT);
                chooseFile.setType(""*/*"");
                chooseFile = Intent.createChooser(chooseFile, ""Choose a file"");
                startActivityForResult(chooseFile, PICKFILE_RESULT_CODE);
                // At this point we have the path of the file
                // File path working.
                /*
                    For pie chart we can have : https://github.com/PhilJay/MPAndroidChart
                 * */
            }
        });
        return classify_view;
    }
    // This gets the file path
    @Override
    public void onActivityResult(int requestCode, int resultCode, Intent data) {
        switch (requestCode) {
            case PICKFILE_RESULT_CODE:
                if (resultCode == -1) {
                    fileUri = data.getData();
                    filePath = fileUri.getPath();
                    System.out.println(""The selected file path is :""+filePath);
                    open_audio_file(fileUri);
                    // Opens main audio file
                    try{
                        // Todo : Remove another loadModelFile @Depreciated
                        tfLite.run(audioBytes,outputs);
                        Log.i(LOG_TAG,""The output is :""+ outputs);
                    }catch(Exception e){
                        throw new RuntimeException(e);
                    }
                }
                break;
        }
    }

    public void open_audio_file(Uri filePath){
        try{
            in = new BufferedInputStream(getContext().getContentResolver().openInputStream(filePath));

            int read;
            byte[] buff = new byte[1024];
            while ((read = in.read(buff)) > 0)
            {
                out.write(buff, 0, read);
            }
            out.flush();
        }catch(Exception e){
            throw new RuntimeException(e);
        }
        //Todo : Change the audio file to a float pointer
        audioBytes = out.toByteArray();
        for (int i = 0;i < audioBytes.length;i++){
            Log.i(LOG_TAG,i+"" ""+audioBytes[i]);
        }
    }

    // This method loads the TF lite file
    private static MappedByteBuffer loadModelFile(AssetManager assets, String modelFileName)
            throws IOException{
        AssetFileDescriptor fileDescriptor = assets.openFd(modelFileName);
        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());
        FileChannel fileChannel = inputStream.getChannel();
        long startOffset = fileDescriptor.getStartOffset();
        long declaredLength = fileDescriptor.getDeclaredLength();
        return fileChannel.map(FileChannel.MapMode.READ_ONLY,startOffset,declaredLength);
    }

}
```

I am trying to convert the.wav file into an byte array using the function : 
```
public void open_audio_file(Uri filePath){
        try{
            in = new BufferedInputStream(getContext().getContentResolver().openInputStream(filePath));

            int read;
            byte[] buff = new byte[1024];
            while ((read = in.read(buff)) > 0)
            {
                out.write(buff, 0, read);
            }
            out.flush();
        }catch(Exception e){
            throw new RuntimeException(e);
        }
        //Todo : Change the audio file to a float pointer
        audioBytes = out.toByteArray();
        for (int i = 0;i < audioBytes.length;i++){
            Log.i(LOG_TAG,i+"" ""+audioBytes[i]);
        }
    }
```"
48788,Incorrect batch size info with keras.utils.Sequence,"TensorFlow 2.4.1

Batch size info is miscalculated when data is wrapped in Sequence. The example below is the output for the first epoch training on 10,000 points with batch_size=32, which should result in 313 mini-batch updates.  The batch number on the far left is correct (313/313), however, the size and batch before loss seem to be incorrect. 

Output: 
Epoch 1/100
313/313 [==============================] - 1s 966us/step - **_batch: 156.0000 - size: 31.9489_** - loss: 0.1579

 "
48787,Tensorflow 2.4.1 hangs on any operation using Conda and RTX3070,"Hello all. I'm having a bit of a trouble using Tensorflow on a dedicated conda environment. Any operation e.g. instantiating two tensors and printing them hangs the execution. I'm using:

**System information**
- Linux Ubuntu 20.04
- Desktop with RTX 3070, nvidia drivers 460
- CUDA Version 11.2

I even tried to force it to use the CPU but no better results. It only works if I just do:

`import tensorflow as tf`
`print(tf.__version__)`

and prints:

`python3 main.py`
`2021-04-27 22:14:42.169855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1`
`2.4.1`

but when making any operation such as:

`a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])`
`b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])`
`c = tf.matmul(a, b)`

it stops, printing this:

![Screenshot from 2021-04-27 22-25-32](https://user-images.githubusercontent.com/30077568/116314881-9b312b80-a7a7-11eb-9179-f8d230dc9064.png)

I even tried to add:
`my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')`
`tf.config.experimental.set_visible_devices(devices= my_devices, device_type='CPU')`

but no luck :/ it ends up executing but takes minutes.
Thanks!
"
48786,"Allocation Tensor change output shape from [1,136] to [0,136]: Invalid tensor size on reading output tensor","### 1. System information

Running on Google Colab 
TensorFlow : 2.4.1

[Model.zip](https://github.com/tensorflow/tensorflow/files/6387424/Model.zip)
Have attached the Tflite model and the Tensorflow model graph

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/drive/1N2umiVDPnTuj6-F9_V00L8GUidHP2rkB?usp=sharing): Demonstrate code to convert PyTorch to Tflite and the issue.
[](url)
### 3. Failure after conversion

- Generated model before allocation tensor show output tensor size (1,136), after allocation the tensor size becomes (0,136)
- After invoke, if try to get output tensor it show ValueError: Invalid tensor size.
- The PyTorch model is giving desired output (face landmark) before conversion to Tflite
"
48785,Warnings related to Custom Layer ,"**System information**
- Windows 10 (64-bit): 
- TensorFlow version: 2.1.0
- Python version: 3.6
- CPU

**Describe the current behavior**
I have implemented the custom layer described [here](https://github.com/fabianbormann/Tensorflow-DeconvNet-Segmentation/blob/master/DeconvNet.py). This layer is the UpSampling layer described in the SegNet model.

In order to test the implementation, I wrote a short dummy code (see in the standalone version): 

After  running, the following Info, Warning and Errors appear:

```

INFO:tensorflow:Converted call: <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>>
    args: (<tf.Tensor 'stage1_conv1_4/Identity:0' shape=(None, 64, 64, 64) dtype=float32>,)
    kwargs: {}

Converted call: <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>>
    args: (<tf.Tensor 'stage1_conv1_4/Identity:0' shape=(None, 64, 64, 64) dtype=float32>,)
    kwargs: {}

INFO:tensorflow:Error transforming entity <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>>
Traceback (most recent call last):
  File ""C:\Users\zz19101\Anaconda3\envs\tf21\lib\site-packages\tensorflow_core\python\autograph\impl\api.py"", line 526, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""C:\Users\zz19101\Anaconda3\envs\tf21\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 328, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""C:\Users\zz19101\Anaconda3\envs\tf21\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""C:\Users\zz19101\Anaconda3\envs\tf21\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
Error transforming entity <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>>
WARNING:tensorflow:AutoGraph could not transform <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
WARNING: AutoGraph could not transform <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
Model: ""model_4""

Traceback (most recent call last):
  File ""C:\Users\zz19101\Anaconda3\envs\tf21\lib\site-packages\tensorflow_core\python\autograph\impl\api.py"", line 526, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""C:\Users\zz19101\Anaconda3\envs\tf21\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 328, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""C:\Users\zz19101\Anaconda3\envs\tf21\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""C:\Users\zz19101\Anaconda3\envs\tf21\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError

```


**Standalone code to reproduce the issue**

```
def max_pool_with_argmax(x):
    """"""According to the documentation, the value at each position in the argmax tensor 
    is calculated according to:  so that a maximum value at position [b, y, x, c] 
    becomes flattened index: (y * width + x) * channels + c if include_batch_in_index 
    is False; ((b * height + y) * width + x) * channels + c if include_batch_in_index is True.
    
    """"""
    return tf.nn.max_pool_with_argmax(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')


class UnpoolingLayer(Layer):
    
    """""" This class generates the Unpooling Layer present in the Segnet and 
    DeconvNet models.
    """"""
    def __init__(self, pooling_argmax, stride=[1,2,2,1], **kwargs):
        self.stride = stride
        self.pooling_argmax = pooling_argmax
        super(UnpoolingLayer, self).__init__(**kwargs)
        
    def build(self, input_shape):
        super(UnpoolingLayer, self).build(input_shape)

        
    def call(self, inputs):
       input_shape = K.cast(K.shape(inputs), dtype='int64')  # Convert
       
       output_shape = (input_shape[0],
                       input_shape[1]*self.stride[1],
                       input_shape[2]*self.stride[2],
                       input_shape[3])
       
       argmax = self.pooling_argmax
       one_like_mask = K.ones_like(argmax) # Create Tensor of 1s with same shape as argmax --> 4-dimensional tensor
       batch_range = K.reshape(K.arange(start=0, stop=input_shape[0], dtype='int64'), 
                                 shape=[input_shape[0], 1, 1, 1]) # Create a tensor of shape (Batch Size, 1 ,1 ,1)
       
       b = one_like_mask * batch_range  # 4 dimensional tensor
       #Multiply the ones mask by the batch range, so that we have a 4-dimension tensor, wth the pixels in the first dimension indicating the batch id for each index
       y = argmax // (output_shape[2] * output_shape[3])
       x = argmax % (output_shape[2] * output_shape[3]) // output_shape[3]
       feature_range = K.arange(start=0, stop=output_shape[3], dtype='int64')  # Indicate the channel index
       f = one_like_mask * feature_range
       
       updates_size = tf.size(inputs)  # Number of elements in the tensor
       indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))   # Generate a 2D array where the rows are the b, y, x , f values and the columns are actually the number of elements in the input tensor, and then just transpose it
       values = K.reshape(inputs, [updates_size]) # flatten it to one dimension so that they can be feed to the tf.scatter
       
       
       return tf.scatter_nd(indices, values, output_shape)
   
    def compute_output_shape(self, input_shape):
        return (input_shape[0], input_shape[1] * 2, input_shape[2] * 2, input_shape[3])
    
    
    def get_config(self):
        base_config = super(UnpoolingLayer, self).get_config()
        base_config['pooling_argmax'] = self.pooling_argmax
        base_config['stride'] = self.stride
        return base_config

    @classmethod
    def from_config(cls, config):
        return cls(**config)
       

if __name__ == ""__main__"":
    
    
   input_tensor = Input(shape=(128,128,1))
   
   pool1, pool1_argmax = Lambda(max_pool_with_argmax, name='max_pool1')(input_tensor)
   
   x = Conv2D(64, kernel_size=3, padding='same', kernel_initializer='he_normal', name='stage1_conv1')(pool1)
   
   unpool1 = UnpoolingLayer(pool1_argmax, name='unpool1')(x)
   unpool1.set_shape(pool1.get_shape())
   
   x = Conv2D(64, kernel_size=3, padding='same', kernel_initializer='he_normal', name='stage1_conv1')(unpool1)
   
   model = Model(inputs = input_tensor, outputs = unpool1)
   model.summary()
```

What can be causing these warnings? Can I just ignore them?"
48783,"Help: Using Demo application of tflite java, how to run three different models on CPU, GPU and DSP in parallel ","System information

Have I written custom code: Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 8.1.0 
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: MI 8 Pro with Qualcomm Snapdragon 845


Describe the problem

Qualcomm Snapdragon 845 contains three hardware devices named CPU, GPU and DSP. I am implementing the demo tflite Android application on the Mi 8 pro mobile phone based on https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/java/demo. I am trying to write a code such that three different classifier instances execute in parallel on CPU, GPU and DSP simultaneously.

`  
private void startBackgroundThread() {
    backgroundThread = new HandlerThread(HANDLE_THREAD_NAME);
    backgroundThread.start();
    backgroundHandler = new Handler(backgroundThread.getLooper());
    
    for ( int i = 0; i < 200; i++) {
       
     TimeUnit.MILLISECONDS.sleep(1);

    backgroundHandler.post(periodicClassify);
    backgroundHandler.post(periodicClassify2);
    backgroundHandler.post(periodicClassify3);



    }



    updateActiveModel(); //initializes classifier1 on CPU, classifier2 on GPU, classifier3 on DSP
  }

  private Runnable periodicClassify =
      new Runnable() {
        @Override
        public void run() {
            if (runClassifier) {
              classifyFrame(classifier1,1);

            }
        }
      };

  private Runnable periodicClassify2 =
      new Runnable() {
        @Override
        public void run() {
            if (runClassifier) {
              classifyFrame(classifier2,4);

            }
        }
      };

  private Runnable periodicClassify3 =
      new Runnable() {
        @Override
        public void run() {
            if (runClassifier) {
              classifyFrame(classifier3, 3);

            }
        }
      };

  private void classifyFrame(ImageClassifier classifierNow, int batchSize) {
    if (classifier == null || getActivity() == null || cameraDevice == null) {
      // It's important to not call showToast every frame, or else the app will starve and
      // hang. updateActiveModel() already puts an error message up with showToast.
      // showToast(""Uninitialized Classifier or invalid context."");
      return;
    }
    SpannableStringBuilder textToShow = new SpannableStringBuilder();
    Bitmap bitmap = textureView.getBitmap(classifier.getImageSizeX(), classifier.getImageSizeY());
    classifierNow.classifyFrame(bitmap, textToShow, batchSize); // Execute classifierNow with a batch size.
    bitmap.recycle();
    showToast(textToShow);
  }

`

With this code, I am able to successfully run the classifier1, classifier2, classifier3 on CPU, GPU and DSP respectively. However, the execution is not happening in parallel. i.e. classifier2 starts executing on GPU only after classifier1 is finished. Similarly classifier3 starts executing only after classifier2 is done.

To solve this I have written my startBackgroundThread function by creating different threads in this way:

`
private void startBackgroundThread() {
    backgroundThread = new HandlerThread(HANDLE_THREAD_NAME);
    backgroundThread.start();
    backgroundHandler = new Handler(backgroundThread.getLooper());

    backgroundThread2 = new HandlerThread(HANDLE_THREAD_NAME2);
    backgroundThread2.start();
    backgroundHandler2 = new Handler(backgroundThread2.getLooper());

    backgroundThread3 = new HandlerThread(HANDLE_THREAD_NAME3);
    backgroundThread3.start();
    backgroundHandler3 = new Handler(backgroundThread3.getLooper());
    
    
    for ( int i = 0; i < 200; i++) {
       
     TimeUnit.MILLISECONDS.sleep(1);

    backgroundHandler.post(periodicClassify);
    backgroundHandler2.post(periodicClassify2);
    backgroundHandler3.post(periodicClassify3);



    }



    updateActiveModel(); //initializes classifier1 on CPU, classifier2 on GPU, classifier3 on DSP
  }

`

This code creates new problems. If I implement this code, then I have no control over which thread executes at which time (race condition). Mostly the batch sizes are getting mixed up and the application crashes because of it.

My runInference function looks like this:

`    protected void runInference2(int tentativeBatchSize) {
         labelProbArray = new byte[tentativeBatchSize][getNumLabels()];


        Tensor t1 = tflite.getInputTensor(0);

        int[] dims = t1.shape();

        for ( int dim : dims ){
            System.out.println(""Dimension "" + dim + getModelPath());
        }

        long startModel = SystemClock.uptimeMillis();


        int[] timings2 = new int[] {tentativeBatchSize,224,224,3};

        tflite.resizeInput(0,timings2);

        for ( int dim : dims ){
            System.out.println(""Dimension "" + dim + getModelPath());
        }


        long endModel = SystemClock.uptimeMillis();

        System.out.println(""Resize time "" + (endModel-startModel));



        tflite.run(imgData, labelProbArray);
    }
`

Some one please help me with a fix in such a way that I can execute classifiers on CPU, GPU and DSP in parallel.

Thank you.
"
48781,restoring checkpoint from 2.3 fails on TPU version 2.4.0 ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.7.x


**Describe the current behavior**
We have a checkpoint that is trained using tpu with tf 2.3. We recently upgraded to 2.4.0 and tried restoring the checkpoint using tpu. We get some internal error from tpu.

**Describe the expected behavior**
We expect that the older checkpoints could be restored without any errors. 


**Standalone code to reproduce the issue**
*Will soon provide checkpoint and code example*

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
![tf2 4_bug](https://user-images.githubusercontent.com/40743476/116276513-9b530c00-a752-11eb-93e7-5c6412f9ef46.png)
<img width=""1576"" alt=""screen_shot 2021-04-27 at 12 16 40"" src=""https://user-images.githubusercontent.com/40743476/116276559-a27a1a00-a752-11eb-8308-f32e88cf53f3.png"">
<img width=""1678"" alt=""screen_shot 2021-04-27 at 12 17 09"" src=""https://user-images.githubusercontent.com/40743476/116276832-e4a35b80-a752-11eb-87df-fb8667aeaf7a.png"">
"
48779,"installation on ubuntu 18.04 failed, followed official instructions","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution Ubuntu 18.04


**Describe the problem**

I followed https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_110 to install GPU enabled tensorflow

```
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin
sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub
sudo add-apt-repository ""deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /""
```

and I got error on the 4th command

```
W: GPG error: https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu1804/x86_64  Release: The following signatures were invalid: BADSIG F60F4B3D7FA2AF80 cudatools <cudatools@nvidia.com>
E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release' is not signed.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
48778,Probele with make when trying to build the Test_hello_world_test TinyML,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- TensorFlow installed from (source or binary): Source
- Tensorflow version (commit SHA if source): 1.12.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): PC

**Describe the problem**
I'm trying to build the Test_hello_world_test from the TinyML book using make command but I receive the following error.
Make version is 4.3.
I found some other issues but they don't resolve my probleme. I'am bocked at this stage.
It seems that the probleme is with the makefile
Can Any One Help Me Please?

**Please provide the exact sequence of commands/steps when you ran into the problem**

C:\tensorflow>make -f tensorflow/lite/micro/tools/make/Makefile hello_world_test
process_begin: CreateProcess(NULL, uname -m, ...) failed.
tensorflow/lite/micro/tools/make/Makefile:47: pipe: No error
-m était inattendu.
'tr' n’est pas reconnu en tant que commande interne
ou externe, un programme exécutable ou un fichier de commandes.
FIND : format incorrect de paramètre
FIND : format incorrect de paramètre
La syntaxe de la commande n’est pas correcte.
process_begin: CreateProcess(NULL, bash C:\tensorflow\tensorflow\lite\micro\tools\make\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.
tensorflow/lite/micro/tools/make/Makefile:570: pipe: Bad file descriptor
tensorflow/lite/micro/tools/make/Makefile:572: *** Something went wrong with the flatbuffers download: .  Stop."
48777,"After installing cudatoolkit 10.1, cudnn 7.6.5 & tf 2.3.0, I still can´t see my GPU device.","**System information**
OS Platform and Distribution: Win10 x64
TensorFlow installed from (source or binary): binary
TensorFlow version: 2.3.0
Python version: 3.8.5
Installed using conda
CUDA toolkit/cuDNN version: 10.1 / 7.6.5
GPU model and memory: GTX1650 Ti

**Describe the problem**
I have installed the above version of packages plus jupyter notebook in Miniconda. 
![image](https://user-images.githubusercontent.com/9957900/116236369-4669c280-a75f-11eb-8ed1-b016dfdb219a.png)

![image](https://user-images.githubusercontent.com/9957900/116236390-4ec1fd80-a75f-11eb-9bce-6bc711392255.png)

![image](https://user-images.githubusercontent.com/9957900/116236422-584b6580-a75f-11eb-88a1-5bd6d6371435.png)

![image](https://user-images.githubusercontent.com/9957900/116236453-600b0a00-a75f-11eb-8a5c-88f521b6e1d7.png)

I still can´t see my GPU device after running the code.
![image](https://user-images.githubusercontent.com/9957900/116236592-87fa6d80-a75f-11eb-870f-2527ab50758b.png)

**Execution**
 
I have checked the compatibility of the versions and followed exactly the installation process.

I can verify my CUDA installation from my cmd prompt using `nvcc --version`. 
![image](https://user-images.githubusercontent.com/9957900/116233269-60a1a180-a75b-11eb-99af-f24ab6733244.png)

I have added the paths in my environment variable:
![image](https://user-images.githubusercontent.com/9957900/116233360-7911bc00-a75b-11eb-98eb-3b5f622af955.png)

I have rebooted before running the notebook and found no GPU running."
48775,Please support native acos/asin/atan/atan2 operations within TFLite library,"**System information**
- `Linux 5.11.4-arch1-1 #1 SMP PREEMPT Sun, 07 Mar 2021 18:00:49 +0000 x86_64 GNU/Linux`
- `TensorFlow 2.4.1` from `tensorflow-opt-cuda` package (https://archlinux.org/packages/community/x86_64/tensorflow-opt-cuda)

**Provide the text output from tflite_convert**

```
ConverterError: /usr/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:5037:0: error: 'tf.Acos' op is neither a custom op nor a flex op
/usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201:0: note: called from
/home/barabanus/work/4a-games/pfnn-tools/test/tflite-acos-missing.py:6:0: note: called from
/usr/lib/python3.9/site-packages/IPython/utils/py3compat.py:168:0: note: called from
/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2740:0: note: called from
/usr/lib/python3.9/site-packages/IPython/core/shellapp.py:377:0: note: called from
/usr/lib/python3.9/site-packages/IPython/core/shellapp.py:452:0: note: called from
/usr/lib/python3.9/site-packages/IPython/core/shellapp.py:328:0: note: called from
/usr/lib/python3.9/site-packages/IPython/terminal/ipapp.py:323:0: note: called from
/usr/lib/python3.9/site-packages/traitlets/config/application.py:87:0: note: called from
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	tf.Acos {device = """"}
```

**Standalone code to reproduce the issue** 
```
# use tensorflow API v1
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

X = tf.placeholder(dtype=tf.float32, shape=[], name=""X"")
Y = tf.acos(X, name=""Y"")

with tf.Session() as session:
    acosZero = session.run(Y, feed_dict={ X: 0., })
    acosOne = session.run(Y, feed_dict={ X: 1., })
    print(f""TensorFlow: acos(0.)={acosZero}, acos(1.)={acosOne}"")

    converter = tf.lite.TFLiteConverter.from_session(
        session,
        input_tensors=[X],
        output_tensors=[Y]
    )
    flatbuffer = converter.convert()
```
"
48774,[RNN] Completely wrong predictions after dynamic range quantization,"Hi everyone,  I'm using dynamic range quantization ([integer with float fallback](https://www.tensorflow.org/lite/performance/post_training_quantization#integer_with_float_fallback_using_default_float_inputoutput)) with a representative dataset, trying to resolved the prediction performance problem I highlighted in #48487.
Unfortunately the predictions I get from the model are wrong and don't correspond at all to the ones the non-quantized model outputs. The class probabilities are often all zeros, a part from one very close to 1. You can see an example of the output here:
```
tf.Tensor(
[[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.99609375 0.         0.         0.
  0.         0.         0.        ]], shape=(1, 39), dtype=float32)
```


In order to make the conversion work, I have to set `unroll=True` when instantiating the model, while I have `unroll=False` during training. If I don't set `unroll=True`, then I get `Failed to parse the model: pybind11::init(): factory function returned nullptr.` (_Originally posted by @wenjielu123 in https://github.com/tensorflow/tensorflow/issues/39392#issuecomment-791634847_)

I'm handling the states myself, re-inputting the previous state in the next step.

I tried many different combinations of the possible flags, as explained in https://www.tensorflow.org/lite/performance/post_training_quantization . They all output strange predictions, with the full integer quantization outputting all zeros, but a couple of classes with the same values, for example 26.

Am I doing something wrong in the conversion? Why are the probabilities outputted by the model so off from the ones of the non-quantized model?

Thanks a lot for the help!
Luca

### 1. System information

OS Platform and Distribution: Linux Ubuntu 20.04
TensorFlow installation: pip package
TensorFlow library: tf-nightly==2.6.0.dev20210407

### 2. Code

Conversion code:
```
converter = tf.lite.TFLiteConverter.from_keras_model(model) 
converter.experimental_new_converter = True 
converter.experimental_new_quantizer = True 
converter.optimizations = [tf.lite.Optimize.DEFAULT] 
converter.representative_dataset = representative_dataset_generator 
# or also adding all the combinations of the following:
# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] 
# converter.inference_input_type = tf.uint8 
# converter.inference_output_type = tf.uint8
converter.convert() 
```

Model code:
```
def _build_test_graph(self, with_tf_lite_ready_setup=False):
        # Inputs
        if with_tf_lite_ready_setup:
            # Set the batch size of 1 when using TFLite, or it will result in a much bigger checkpoint that still only works with batch size 1
            batch_size = 1
            inputs = Input(shape=(1), batch_size=batch_size)
        else:
            batch_size = None
            inputs = Input(shape=(None,))

        # Input state
        h_0 = [Input(shape=[self.state_dim], batch_size=batch_size)]

        self.rnn_layer = tensorflow.keras.layers.GRU(self.state_dim, return_state=True, unroll=True)
        # unroll is set to false during training for simplicity, but to true during conversion, because otherwise
        # the conversion fails
        rnn_inputs = tf.one_hot(tf.cast(inputs, tf.int32), depth=self.vocab_size)

        embedder = Embedding(self.vocab_size, self.emb_dim, mask_zero=True)
        m = embedder.compute_mask(inputs) # the token 0 is the padding token
        # Apply RNN
        out = self.rnn_layer(rnn_inputs, initial_state=h_0, mask=m)

        rnn_out = out[0]
        h_out = out[1:]

        dense = Dense(self.vocab_size, activation=""softmax"")
        output = dense(rnn_out)

        return keras.Model([inputs] + h_0, [output] + h_out)
```"
48773,Wrong results of AvgPoolGrad and AvgPool3dGrad in some specific shapes,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
 **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
 **Linux Ubuntu 18.04**
- TensorFlow installed from (source or binary):
**source**
- TensorFlow version (use command below):
2.4.1 and 1.15 both tried
- Python version:
3.7.5


You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Hello, I'm using MaxPoolGrad and find that in same cases the results seemed to be wrong compared with hand-calculated results.   One of the cases is as follows.

    **grad_shape = (1, 1, 5, 1)
    input_shape = (1, 1, 5, 1)
    kernel_size = [1, 1, 7, 1]
    stride_size = [1, 1, 1, 1]
    padding = 'SAME'**

For the convenience of calculation， I set the grad with all one value. 
Then the result is
```
tf.Tensor(
[[[[0.8 ]
   [1.05]
   [1.05]
   [1.05]
   [1.05]]]], shape=(1, 1, 5, 1), dtype=float32)
```
While the hand-calculated result is 
```
[[[[0.85 ]
   [1.1]
   [1.1]
   [1.1]
   [0.85]]]]
tips:
0.85 = 1/4 + 1*3/5
1.1 = 1*2/4 +1*3/5
```

The differences appear in following cases:
-kernel_h > input_h &  kernel_h // 2 < input_h - 1
-kernel_w > input_w &  kernel_w // 2 < input_w - 1

**Describe the expected behavior**
Following cases can have right calculation results.
-kernel_h > input_h &  kernel_h // 2 < input_h - 1
-kernel_w > input_w &  kernel_w // 2 < input_w - 1




**Standalone code to reproduce the issue**
```
import tensorflow as tf
from tensorflow.python.ops import gen_nn_ops

def test_tf_avg_pool_grad(input_shape, grad_shape, ksize, strides, padding, data_format):
    x = tf.Variable(tf.ones(shape=grad_shape), dtype=tf.float32)
    avg_pool_grad = gen_nn_ops.avg_pool_grad(orig_input_shape=input_shape,
                                             grad=x, ksize=ksize,
                                             strides=strides,
                                             padding=padding,
                                             data_format=data_format)

    return avg_pool_grad

if __name__ == '__main__':
    grad_shape = (1, 1, 5, 1)
    input_shape = (1, 1, 5, 1)
    kernel_size = [1, 1, 7, 1]
    stride_size = [1, 1, 1, 1]
    padding = 'SAME'
    exp_result = test_tf_avg_pool_grad(input_shape, grad_shape,
                                       kernel_size, stride_size, padding,
                                       'NHWC')
    print(""======================= the expect result of log:"", exp_result)
```

**Other info / logs** 
hand-caculated process
![image](https://user-images.githubusercontent.com/72602911/116206344-45da2780-a771-11eb-8a56-dd37b902b244.png)

"
48772,set_intra_op_parallelism_threads and set_inter_op_parallelism_threads has no impact on thread usage,"**System information**
- I am using a custom implementation of DepthwiseConv3D, extends the Conv3D class and is partially based on code from the following repository, https://github.com/alexandrosstergiou/keras-DepthwiseConv3D adapted to work in tensorflow 2.4.1
- CentOS Linux Version 7
- Installed from source
- Tensorflow version 2.4.1
- Python 3.8.8
- Cuda 11.0, CuDNN 8
- Happens on GTX1080, RTX2080

**Describe the current behavior**

I am running code on a compute cluster, hence the different GPUs. I am required by the compute cluster admin to restrict thread usage when possible and had been referred to use the functions from tf.config.threading in the tensorflow documentation. I set both intra and inter thread parallelism to 2 and used an interactive session on the node to monitor thread usage with top, however the usage of the thread parameters seems to have no impact on thread usage. I still observe the python process using all available threads. 

My understanding from the documentation for these functions is that all is required is to call them with the parameters wanted, no errors related to threading have been raised. 

My github repository is as follows, I use the mult.csh file under the EEGNet folder to execute the code, which runs the runMB3D.py file, using the network model from MB3DEEGNet.py.
https://github.com/matt-houk/MB3DCNN

I have attached both the stderr and stdout output, I canceled the code when I noticed it using excessive threads.

[err-mult.txt](https://github.com/tensorflow/tensorflow/files/6382379/err-mult.txt)
[out-mult.txt](https://github.com/tensorflow/tensorflow/files/6382380/out-mult.txt)

"
48771,Fatal Signal 11 (SIGSEGV) Error ,"I am trying to implement Tensor flow lite in my application. The code is attached below:

    package com.example.se;

import android.content.Context;
import android.content.Intent;
import android.content.res.AssetFileDescriptor;
import android.content.res.AssetManager;
import android.database.Cursor;
import android.net.Uri;
import android.os.Bundle;
import android.os.FileUtils;
import android.util.Log;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.Button;
import android.widget.Toast;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;
import androidx.fragment.app.Fragment;

import org.tensorflow.lite.Interpreter;

import java.io.BufferedInputStream;
import java.io.BufferedReader;
import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.net.URISyntaxException;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class Classify extends Fragment {
    private Button choose_file_button;
    private Button stop_classify;
    public static final int PICKFILE_RESULT_CODE = 1;
    private Uri fileUri;
    private String filePath; // This is the final file path
    View classify_view;

    // To load from asset folder
    private static final String LABEL_FILENAME = ""file:///android_asset/labels.txt"";
    private static final String MODEL_FILENAME = ""file:///android_asset/soundclassifier.tflite"";
    private static final String LOG_TAG = ""Log tagges is here"";

    // For label and modelfile
    private List<String> labels = new ArrayList<String>();
    private List<String> displayedLabels = new ArrayList<>();

    // For the audio file
    ByteArrayOutputStream out = new ByteArrayOutputStream();
    BufferedInputStream in;
    byte[] audioBytes;

    // For machine learning
    private final Interpreter.Options tfliteOptions = new Interpreter.Options();
    private MappedByteBuffer tfLiteModel;
    private Interpreter tfLite;
    private Map<Object,Object> outputMap = new HashMap<>();
    private final Interpreter.Options ftliteOptions = new Interpreter.Options();
    private RecognizeCommands recognizeCommands = null;
    // ToDo : Remove this if not needed

    @Nullable
    @Override
    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
        classify_view = inflater.inflate(R.layout.classify,container,false);

        // Both finds the classify and stop classify button
        choose_file_button = (Button) classify_view.findViewById(R.id.classify_button);
        stop_classify = (Button) classify_view.findViewById(R.id.stop_classify);

        // For labels file
        String actualLabelFilename = LABEL_FILENAME.split(""file:///android_asset/"",-1)[1];
        Log.i(LOG_TAG,""Reading labels from "" + actualLabelFilename);

        BufferedReader br = null;
        try{
            br = new BufferedReader(new InputStreamReader(classify_view.getContext().getAssets().open(actualLabelFilename)));
            String line;
            while ((line = br.readLine()) != null){
                labels.add(line);
                if (line.charAt(0) != '_'){
                    displayedLabels.add(line.substring(0,1).toUpperCase()+ line.substring(1));
                }
            }
        } catch (IOException e){
            throw new RuntimeException(""Problem reading the label file!"",e);
        }

        Log.i(LOG_TAG,""Labels file messages are :""+ displayedLabels);

        // ToDo : Implement Recognize Commands if not working

        // Opening the model file
        String actualModelFilename = MODEL_FILENAME.split(""file:///android_asset/"",-1)[1];
        try{
            tfLiteModel = loadModelFile(classify_view.getContext().getAssets(), actualModelFilename);
        } catch (Exception e){
            throw new RuntimeException(e);
        }

        Log.i(LOG_TAG,""The modal file is :""+actualModelFilename);
        Log.i(LOG_TAG,""The actual content is :""+tfLiteModel);

        // ToDo : Model file opened here
        try{
            ftliteOptions.setNumThreads(1);
            tfLite = new Interpreter(tfLiteModel,ftliteOptions);
        } catch (Exception e){
            throw new RuntimeException(e);
        }
        Log.i(LOG_TAG,""TF lite file loaded. "");

        choose_file_button.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                Intent chooseFile = new Intent(Intent.ACTION_GET_CONTENT);
                chooseFile.setType(""*/*"");
                chooseFile = Intent.createChooser(chooseFile, ""Choose a file"");
                startActivityForResult(chooseFile, PICKFILE_RESULT_CODE);
                // At this point we have the path of the file
                // File path working.
                /*
                    For pie chart we can have : https://github.com/PhilJay/MPAndroidChart
                 * */
            }
        });
        return classify_view;
    }
    // This gets the file path
    @Override
    public void onActivityResult(int requestCode, int resultCode, Intent data) {
        switch (requestCode) {
            case PICKFILE_RESULT_CODE:
                if (resultCode == -1) {
                    fileUri = data.getData();
                    filePath = fileUri.getPath();
                    System.out.println(""The selected file path is :""+filePath);
                    open_audio_file(fileUri);
                    // Opens main audio file
                    try{
                        outputMap.put(0,""outputScores"");
                        // Todo : Remove another loadModelFile @Depreciated
                        tfLite.run(audioBytes,outputMap);
                        Log.i(LOG_TAG,""The output is :""+ outputMap);
                    }catch(Exception e){
                        throw new RuntimeException(e);
                    }
                }
                break;
        }
    }

    public void open_audio_file(Uri filePath){
        try{
            in = new BufferedInputStream(getContext().getContentResolver().openInputStream(filePath));
            int read;
            byte[] buff = new byte[1024];
            while ((read = in.read(buff)) > 0)
            {
                out.write(buff, 0, read);
            }
            out.flush();
        }catch(Exception e){
            throw new RuntimeException(e);
        }
        audioBytes = out.toByteArray();
        Log.i(LOG_TAG,""The audio file is "" + audioBytes.toString());
    }

    // This method loads the TF lite file
    private static MappedByteBuffer loadModelFile(AssetManager assets, String modelFileName)
            throws IOException{
        AssetFileDescriptor fileDescriptor = assets.openFd(modelFileName);
        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());
        FileChannel fileChannel = inputStream.getChannel();
        long startOffset = fileDescriptor.getStartOffset();
        long declaredLength = fileDescriptor.getDeclaredLength();
        return fileChannel.map(FileChannel.MapMode.READ_ONLY,startOffset,declaredLength);
    }

}
      
The tflite application was created using the teachable machine. Currently, in the application, I have tried to use a depreciated version of the Interpreter constructor. However, there was no success. Therefore, I defined options and rendered the application, however, I constantly get the same error. Attached below:

04/27 00:44:57: Launching 'app' on Pixel 3a API 30.
Install successfully finished in 13 s 670 ms.
$ adb shell am start -n ""com.example.se/com.example.se.Login_page"" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER
Connected to process 12447 on device 'emulator-5554'.
Capturing and displaying logcat messages from application. This behavior can be disabled in the ""Logcat output"" section of the ""Debugger"" settings page.
D/NetworkSecurityConfig: No Network Security Config specified, using platform default
D/NetworkSecurityConfig: No Network Security Config specified, using platform default
W/ComponentDiscovery: Class com.google.firebase.dynamicloading.DynamicLoadingRegistrar is not an found.
I/FirebaseApp: Device unlocked: initializing all Firebase APIs for app [DEFAULT]
I/FirebaseInitProvider: FirebaseApp initialization successful
D/libEGL: loaded /vendor/lib/egl/libEGL_emulation.so
D/libEGL: loaded /vendor/lib/egl/libGLESv1_CM_emulation.so
D/libEGL: loaded /vendor/lib/egl/libGLESv2_emulation.so
I/FirebaseAuth: [FirebaseAuth:] Preparing to create service connection to fallback implementation
W/com.example.se: Accessing hidden method Landroid/view/View;->computeFitSystemWindows(Landroid/graphics/Rect;Landroid/graphics/Rect;)Z (greylist, reflection, allowed)
W/com.example.se: Accessing hidden method Landroid/view/ViewGroup;->makeOptionalFitsSystemWindows()V (greylist, reflection, allowed)
D/FirebaseAuth: Notifying id token listeners about a sign-out event.
D/FirebaseAuth: Notifying auth state listeners about a sign-out event.
D/HostConnection: HostConnection::get() New Host Connection established 0xf542d1f0, tid 12502
D/HostConnection: HostComposition ext ANDROID_EMU_CHECKSUM_HELPER_v1 ANDROID_EMU_native_sync_v2 ANDROID_EMU_native_sync_v3 ANDROID_EMU_native_sync_v4 ANDROID_EMU_dma_v1 ANDROID_EMU_direct_mem ANDROID_EMU_host_composition_v1 ANDROID_EMU_host_composition_v2 ANDROID_EMU_YUV_Cache ANDROID_EMU_async_unmap_buffer GL_OES_EGL_image_external_essl3 GL_OES_vertex_array_object GL_KHR_texture_compression_astc_ldr ANDROID_EMU_host_side_tracing ANDROID_EMU_async_frame_commands ANDROID_EMU_gles_max_version_3_0 
W/OpenGLRenderer: Failed to choose config with EGL_SWAP_BEHAVIOR_PRESERVED, retrying without...
D/EGL_emulation: eglCreateContext: 0xf542c9a0: maj 3 min 0 rcv 3
D/EGL_emulation: eglMakeCurrent: 0xf542c9a0: ver 3 0 (tinfo 0xf57788d0) (first time)
I/Gralloc4: mapper 4.x is not supported
D/HostConnection: createUnique: call
D/HostConnection: HostConnection::get() New Host Connection established 0xf542dd50, tid 12502
D/goldfish-address-space: allocate: Ask for block of size 0x100
D/goldfish-address-space: allocate: ioctl allocate returned offset 0x3fbdbc000 size 0x2000
D/HostConnection: HostComposition ext ANDROID_EMU_CHECKSUM_HELPER_v1 ANDROID_EMU_native_sync_v2 ANDROID_EMU_native_sync_v3 ANDROID_EMU_native_sync_v4 ANDROID_EMU_dma_v1 ANDROID_EMU_direct_mem ANDROID_EMU_host_composition_v1 ANDROID_EMU_host_composition_v2 ANDROID_EMU_YUV_Cache ANDROID_EMU_async_unmap_buffer GL_OES_EGL_image_external_essl3 GL_OES_vertex_array_object GL_KHR_texture_compression_astc_ldr ANDROID_EMU_host_side_tracing ANDROID_EMU_async_frame_commands ANDROID_EMU_gles_max_version_3_0 
I/com.example.se: Background young concurrent copying GC freed 30675(2242KB) AllocSpace objects, 8(224KB) LOS objects, 90% free, 2531KB/26MB, paused 2.806ms total 524.254ms
I/OpenGLRenderer: Davey! duration=1175ms; Flags=1, IntendedVsync=73082886249371, Vsync=73082886249371, OldestInputEvent=9223372036854775807, NewestInputEvent=0, HandleInputStart=73082894115840, AnimationStart=73082894159840, PerformTraversalsStart=73082894249840, DrawStart=73083121417840, SyncQueued=73083147195840, SyncStart=73083154696840, IssueDrawCommandsStart=73083154893840, SwapBuffers=73084012695840, FrameCompleted=73084068849840, DequeueBufferDuration=570000, QueueBufferDuration=3404000, GpuCompleted=72904454231491230, 
W/com.example.se: Verification of java.lang.String com.google.android.gms.common.ConnectionResult.getErrorMessage() took 198.255ms (15.13 bytecodes/s) (800B approximate peak alloc)
W/com.example.se: Verification of android.app.PendingIntent com.google.android.gms.common.ConnectionResult.getResolution() took 144.927ms (20.70 bytecodes/s) (808B approximate peak alloc)
I/Choreographer: Skipped 97 frames!  The application may be doing too much work on its main thread.
W/com.example.se: Verification of void com.google.android.gms.common.api.internal.zabo.run() took 101.075ms (999.26 bytecodes/s) (2312B approximate peak alloc)
I/AssistStructure: Flattened final assist data: 1548 bytes, containing 1 windows, 8 views
W/System: Ignoring header X-Firebase-Locale because its value was null.
W/System: Ignoring header X-Firebase-Locale because its value was null.
D/FirebaseAuth: Notifying id token listeners about user ( VJoKjTuIjuWGm96BBpRROS6SKFX2 ).
D/FirebaseAuth: Notifying auth state listeners about user ( VJoKjTuIjuWGm96BBpRROS6SKFX2 ).
D/CompatibilityChangeReporter: Compat change id reported: 147798919; UID 10154; state: ENABLED
I/Log tagges is here: Reading labels from labels.txt
I/Log tagges is here: Labels file messages are :[0 Background Noise, 1 Cow, 2 Dog, 3 Hen, 4 Sheep]
I/Log tagges is here: The modal file is :soundclassifier.tflite
    The actual content is :java.nio.DirectByteBuffer[pos=0 lim=5780044 cap=5780044]
I/tflite: Initialized TensorFlow Lite runtime.
W/native: cpu_feature_guard.cc:36 The TensorFlow library was compiled to use SSE instructions, but these aren't available on your machine.
A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xfffffff4 in tid 12447 (com.example.se), pid 12447 (com.example.se)
What would be the best method to resolve this error?

The Gradle file is :

plugins {
    id 'com.android.application'
    id 'com.google.gms.google-services'
}

android {
    compileSdkVersion 30
    buildToolsVersion ""30.0.3""

    defaultConfig {
        applicationId ""com.example.se""
        minSdkVersion 25
        targetSdkVersion 30
        versionCode 1
        versionName ""1.0""

        testInstrumentationRunner ""androidx.test.runner.AndroidJUnitRunner""
    }

    buildTypes {
        release {
            minifyEnabled false
            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'
        }
    }
    compileOptions {
        sourceCompatibility JavaVersion.VERSION_1_8
        targetCompatibility JavaVersion.VERSION_1_8
    }
}

dependencies {
    implementation 'androidx.appcompat:appcompat:1.2.0'
    implementation 'com.google.android.material:material:1.3.0'
    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'
    implementation 'com.google.firebase:firebase-auth:20.0.3'
    implementation 'com.google.firebase:firebase-database:19.7.0'
    implementation ""org.tensorflow:tensorflow-lite:2.3.0""
    implementation ""org.tensorflow:tensorflow-lite-gpu:2.3.0""
    implementation ""org.tensorflow:tensorflow-lite-select-tf-ops:2.3.0""
    implementation ""org.tensorflow:tensorflow-lite-support:0.1.0-rc1""
    implementation ""org.tensorflow:tensorflow-lite-metadata:0.1.0-rc2""
    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.2.0'
    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0'
    testImplementation 'junit:junit:4.+'
    androidTestImplementation 'androidx.test.ext:junit:1.1.2'
    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'
}"
48770,Error with SIGSEGV while building for teachable machine output ,"I am trying to implement Tensor flow lite in my application. The code is attached below: 
```
    package com.example.se;

import android.content.Context;
import android.content.Intent;
import android.content.res.AssetFileDescriptor;
import android.content.res.AssetManager;
import android.database.Cursor;
import android.net.Uri;
import android.os.Bundle;
import android.os.FileUtils;
import android.util.Log;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.Button;
import android.widget.Toast;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;
import androidx.fragment.app.Fragment;

import org.tensorflow.lite.Interpreter;

import java.io.BufferedInputStream;
import java.io.BufferedReader;
import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.net.URISyntaxException;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class Classify extends Fragment {
    private Button choose_file_button;
    private Button stop_classify;
    public static final int PICKFILE_RESULT_CODE = 1;
    private Uri fileUri;
    private String filePath; // This is the final file path
    View classify_view;

    // To load from asset folder
    private static final String LABEL_FILENAME = ""file:///android_asset/labels.txt"";
    private static final String MODEL_FILENAME = ""file:///android_asset/soundclassifier.tflite"";
    private static final String LOG_TAG = ""Log tagges is here"";

    // For label and modelfile
    private List<String> labels = new ArrayList<String>();
    private List<String> displayedLabels = new ArrayList<>();

    // For the audio file
    ByteArrayOutputStream out = new ByteArrayOutputStream();
    BufferedInputStream in;
    byte[] audioBytes;

    // For machine learning
    private final Interpreter.Options tfliteOptions = new Interpreter.Options();
    private MappedByteBuffer tfLiteModel;
    private Interpreter tfLite;
    private Map<Object,Object> outputMap = new HashMap<>();
    private final Interpreter.Options ftliteOptions = new Interpreter.Options();
    private RecognizeCommands recognizeCommands = null;
    // ToDo : Remove this if not needed

    @Nullable
    @Override
    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
        classify_view = inflater.inflate(R.layout.classify,container,false);

        // Both finds the classify and stop classify button
        choose_file_button = (Button) classify_view.findViewById(R.id.classify_button);
        stop_classify = (Button) classify_view.findViewById(R.id.stop_classify);

        // For labels file
        String actualLabelFilename = LABEL_FILENAME.split(""file:///android_asset/"",-1)[1];
        Log.i(LOG_TAG,""Reading labels from "" + actualLabelFilename);

        BufferedReader br = null;
        try{
            br = new BufferedReader(new InputStreamReader(classify_view.getContext().getAssets().open(actualLabelFilename)));
            String line;
            while ((line = br.readLine()) != null){
                labels.add(line);
                if (line.charAt(0) != '_'){
                    displayedLabels.add(line.substring(0,1).toUpperCase()+ line.substring(1));
                }
            }
        } catch (IOException e){
            throw new RuntimeException(""Problem reading the label file!"",e);
        }

        Log.i(LOG_TAG,""Labels file messages are :""+ displayedLabels);

        // ToDo : Implement Recognize Commands if not working

        // Opening the model file
        String actualModelFilename = MODEL_FILENAME.split(""file:///android_asset/"",-1)[1];
        try{
            tfLiteModel = loadModelFile(classify_view.getContext().getAssets(), actualModelFilename);
        } catch (Exception e){
            throw new RuntimeException(e);
        }

        Log.i(LOG_TAG,""The modal file is :""+actualModelFilename);
        Log.i(LOG_TAG,""The actual content is :""+tfLiteModel);

        // ToDo : Model file opened here
        try{
            ftliteOptions.setNumThreads(1);
            tfLite = new Interpreter(tfLiteModel,ftliteOptions);
        } catch (Exception e){
            throw new RuntimeException(e);
        }
        Log.i(LOG_TAG,""TF lite file loaded. "");

        choose_file_button.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                Intent chooseFile = new Intent(Intent.ACTION_GET_CONTENT);
                chooseFile.setType(""*/*"");
                chooseFile = Intent.createChooser(chooseFile, ""Choose a file"");
                startActivityForResult(chooseFile, PICKFILE_RESULT_CODE);
                // At this point we have the path of the file
                // File path working.
                /*
                    For pie chart we can have : https://github.com/PhilJay/MPAndroidChart
                 * */
            }
        });
        return classify_view;
    }
    // This gets the file path
    @Override
    public void onActivityResult(int requestCode, int resultCode, Intent data) {
        switch (requestCode) {
            case PICKFILE_RESULT_CODE:
                if (resultCode == -1) {
                    fileUri = data.getData();
                    filePath = fileUri.getPath();
                    System.out.println(""The selected file path is :""+filePath);
                    open_audio_file(fileUri);
                    // Opens main audio file
                    try{
                        outputMap.put(0,""outputScores"");
                        // Todo : Remove another loadModelFile @Depreciated
                        tfLite.run(audioBytes,outputMap);
                        Log.i(LOG_TAG,""The output is :""+ outputMap);
                    }catch(Exception e){
                        throw new RuntimeException(e);
                    }
                }
                break;
        }
    }

    public void open_audio_file(Uri filePath){
        try{
            in = new BufferedInputStream(getContext().getContentResolver().openInputStream(filePath));
            int read;
            byte[] buff = new byte[1024];
            while ((read = in.read(buff)) > 0)
            {
                out.write(buff, 0, read);
            }
            out.flush();
        }catch(Exception e){
            throw new RuntimeException(e);
        }
        audioBytes = out.toByteArray();
        Log.i(LOG_TAG,""The audio file is "" + audioBytes.toString());
    }

    // This method loads the TF lite file
    private static MappedByteBuffer loadModelFile(AssetManager assets, String modelFileName)
            throws IOException{
        AssetFileDescriptor fileDescriptor = assets.openFd(modelFileName);
        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());
        FileChannel fileChannel = inputStream.getChannel();
        long startOffset = fileDescriptor.getStartOffset();
        long declaredLength = fileDescriptor.getDeclaredLength();
        return fileChannel.map(FileChannel.MapMode.READ_ONLY,startOffset,declaredLength);
    }

}
      
```

The tflite application was created using the teachable machine. Currently, in the application, I have tried to use a depreciated version of the Interpreter constructor. However, there was no success. Therefore, I defined options and rendered the application, however, I constantly get the same error. Attached below: 

```
04/27 00:44:57: Launching 'app' on Pixel 3a API 30.
Install successfully finished in 13 s 670 ms.
$ adb shell am start -n ""com.example.se/com.example.se.Login_page"" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER
Connected to process 12447 on device 'emulator-5554'.
Capturing and displaying logcat messages from application. This behavior can be disabled in the ""Logcat output"" section of the ""Debugger"" settings page.
D/NetworkSecurityConfig: No Network Security Config specified, using platform default
D/NetworkSecurityConfig: No Network Security Config specified, using platform default
W/ComponentDiscovery: Class com.google.firebase.dynamicloading.DynamicLoadingRegistrar is not an found.
I/FirebaseApp: Device unlocked: initializing all Firebase APIs for app [DEFAULT]
I/FirebaseInitProvider: FirebaseApp initialization successful
D/libEGL: loaded /vendor/lib/egl/libEGL_emulation.so
D/libEGL: loaded /vendor/lib/egl/libGLESv1_CM_emulation.so
D/libEGL: loaded /vendor/lib/egl/libGLESv2_emulation.so
I/FirebaseAuth: [FirebaseAuth:] Preparing to create service connection to fallback implementation
W/com.example.se: Accessing hidden method Landroid/view/View;->computeFitSystemWindows(Landroid/graphics/Rect;Landroid/graphics/Rect;)Z (greylist, reflection, allowed)
W/com.example.se: Accessing hidden method Landroid/view/ViewGroup;->makeOptionalFitsSystemWindows()V (greylist, reflection, allowed)
D/FirebaseAuth: Notifying id token listeners about a sign-out event.
D/FirebaseAuth: Notifying auth state listeners about a sign-out event.
D/HostConnection: HostConnection::get() New Host Connection established 0xf542d1f0, tid 12502
D/HostConnection: HostComposition ext ANDROID_EMU_CHECKSUM_HELPER_v1 ANDROID_EMU_native_sync_v2 ANDROID_EMU_native_sync_v3 ANDROID_EMU_native_sync_v4 ANDROID_EMU_dma_v1 ANDROID_EMU_direct_mem ANDROID_EMU_host_composition_v1 ANDROID_EMU_host_composition_v2 ANDROID_EMU_YUV_Cache ANDROID_EMU_async_unmap_buffer GL_OES_EGL_image_external_essl3 GL_OES_vertex_array_object GL_KHR_texture_compression_astc_ldr ANDROID_EMU_host_side_tracing ANDROID_EMU_async_frame_commands ANDROID_EMU_gles_max_version_3_0 
W/OpenGLRenderer: Failed to choose config with EGL_SWAP_BEHAVIOR_PRESERVED, retrying without...
D/EGL_emulation: eglCreateContext: 0xf542c9a0: maj 3 min 0 rcv 3
D/EGL_emulation: eglMakeCurrent: 0xf542c9a0: ver 3 0 (tinfo 0xf57788d0) (first time)
I/Gralloc4: mapper 4.x is not supported
D/HostConnection: createUnique: call
D/HostConnection: HostConnection::get() New Host Connection established 0xf542dd50, tid 12502
D/goldfish-address-space: allocate: Ask for block of size 0x100
D/goldfish-address-space: allocate: ioctl allocate returned offset 0x3fbdbc000 size 0x2000
D/HostConnection: HostComposition ext ANDROID_EMU_CHECKSUM_HELPER_v1 ANDROID_EMU_native_sync_v2 ANDROID_EMU_native_sync_v3 ANDROID_EMU_native_sync_v4 ANDROID_EMU_dma_v1 ANDROID_EMU_direct_mem ANDROID_EMU_host_composition_v1 ANDROID_EMU_host_composition_v2 ANDROID_EMU_YUV_Cache ANDROID_EMU_async_unmap_buffer GL_OES_EGL_image_external_essl3 GL_OES_vertex_array_object GL_KHR_texture_compression_astc_ldr ANDROID_EMU_host_side_tracing ANDROID_EMU_async_frame_commands ANDROID_EMU_gles_max_version_3_0 
I/com.example.se: Background young concurrent copying GC freed 30675(2242KB) AllocSpace objects, 8(224KB) LOS objects, 90% free, 2531KB/26MB, paused 2.806ms total 524.254ms
I/OpenGLRenderer: Davey! duration=1175ms; Flags=1, IntendedVsync=73082886249371, Vsync=73082886249371, OldestInputEvent=9223372036854775807, NewestInputEvent=0, HandleInputStart=73082894115840, AnimationStart=73082894159840, PerformTraversalsStart=73082894249840, DrawStart=73083121417840, SyncQueued=73083147195840, SyncStart=73083154696840, IssueDrawCommandsStart=73083154893840, SwapBuffers=73084012695840, FrameCompleted=73084068849840, DequeueBufferDuration=570000, QueueBufferDuration=3404000, GpuCompleted=72904454231491230, 
W/com.example.se: Verification of java.lang.String com.google.android.gms.common.ConnectionResult.getErrorMessage() took 198.255ms (15.13 bytecodes/s) (800B approximate peak alloc)
W/com.example.se: Verification of android.app.PendingIntent com.google.android.gms.common.ConnectionResult.getResolution() took 144.927ms (20.70 bytecodes/s) (808B approximate peak alloc)
I/Choreographer: Skipped 97 frames!  The application may be doing too much work on its main thread.
W/com.example.se: Verification of void com.google.android.gms.common.api.internal.zabo.run() took 101.075ms (999.26 bytecodes/s) (2312B approximate peak alloc)
I/AssistStructure: Flattened final assist data: 1548 bytes, containing 1 windows, 8 views
W/System: Ignoring header X-Firebase-Locale because its value was null.
W/System: Ignoring header X-Firebase-Locale because its value was null.
D/FirebaseAuth: Notifying id token listeners about user ( VJoKjTuIjuWGm96BBpRROS6SKFX2 ).
D/FirebaseAuth: Notifying auth state listeners about user ( VJoKjTuIjuWGm96BBpRROS6SKFX2 ).
D/CompatibilityChangeReporter: Compat change id reported: 147798919; UID 10154; state: ENABLED
I/Log tagges is here: Reading labels from labels.txt
I/Log tagges is here: Labels file messages are :[0 Background Noise, 1 Cow, 2 Dog, 3 Hen, 4 Sheep]
I/Log tagges is here: The modal file is :soundclassifier.tflite
    The actual content is :java.nio.DirectByteBuffer[pos=0 lim=5780044 cap=5780044]
I/tflite: Initialized TensorFlow Lite runtime.
W/native: cpu_feature_guard.cc:36 The TensorFlow library was compiled to use SSE instructions, but these aren't available on your machine.
A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xfffffff4 in tid 12447 (com.example.se), pid 12447 (com.example.se)
```
What would be the best method to resolve this error? 

The Gradle file is : 
```
plugins {
    id 'com.android.application'
    id 'com.google.gms.google-services'
}

android {
    compileSdkVersion 30
    buildToolsVersion ""30.0.3""

    defaultConfig {
        applicationId ""com.example.se""
        minSdkVersion 25
        targetSdkVersion 30
        versionCode 1
        versionName ""1.0""

        testInstrumentationRunner ""androidx.test.runner.AndroidJUnitRunner""
    }

    buildTypes {
        release {
            minifyEnabled false
            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'
        }
    }
    compileOptions {
        sourceCompatibility JavaVersion.VERSION_1_8
        targetCompatibility JavaVersion.VERSION_1_8
    }
}

dependencies {
    implementation 'androidx.appcompat:appcompat:1.2.0'
    implementation 'com.google.android.material:material:1.3.0'
    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'
    implementation 'com.google.firebase:firebase-auth:20.0.3'
    implementation 'com.google.firebase:firebase-database:19.7.0'
    implementation ""org.tensorflow:tensorflow-lite:2.3.0""
    implementation ""org.tensorflow:tensorflow-lite-gpu:2.3.0""
    implementation ""org.tensorflow:tensorflow-lite-select-tf-ops:2.3.0""
    implementation ""org.tensorflow:tensorflow-lite-support:0.1.0-rc1""
    implementation ""org.tensorflow:tensorflow-lite-metadata:0.1.0-rc2""
    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.2.0'
    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0'
    testImplementation 'junit:junit:4.+'
    androidTestImplementation 'androidx.test.ext:junit:1.1.2'
    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'
}
```"
48769,Tensorflow latest GPU docker container doesn't include object detection API,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): From docker container
- TensorFlow version: latest docker container
- Python version: latest docker container
- Installed using virtualenv? pip? conda?: from docker container
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: last docker container, looks like 11.2
- GPU model and memory: Tesla P4

**Describe the problem**
I was under the impression (correct me if I am wrong about this) that I could use the docker container to do object detection tasks, mainly I would like to use the container to train models on my machine. However, it appears that this container does not include the Object Detection API and compiled protos that go along with it. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
48768,Request for an Efficient Way of handling NLP Tasks with Saving Model weights along with its tokenizer and architecture in JSON ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
- In the Current Feature of TensorFlow, when we work with Natural Language Processing Based Tasks, we have the ability to only save the ```model architecture``` and ``` model weights```, that too with two different function calls. We need to mention an explicit file handling operation to save the ```tokenizer```  in JSON format too. This might lead to a bit of inefficiency.

- Therefore , I would like to suggest and provide code for one single function , which would save the model weights , its architecture and the current tokenizer in JSON format ,  and along with it , a single load function to retrieve all these three files with one single function call. This will help to improve the efficiency and modular programming and ease of use of TensorFlow to save and load models with one single function call, rather than calling different function counterparts.

**Will this change the current api? How?**
Not to a great extent. Since these are two normal functions that will require ``` model``` as a parameter, it will save model architecture, its weights, and tokenizer.json will directly be saved from the tokenizer object created. 

**Who will benefit with this feature?**
All the developers who use TensorFlow for Natural Language Processing Tasks in deep learning.

**Any Other info.**
I already have the code snippet ready and have tested it with a couple of my models.
"
48767,C API Locking prevents custom gradient definition,"I am trying to add custom gradient support to the Java bindings (tensorflow/java#292).  This is currently being prevented by the fact that `TF_AddGradientsWithPrefix` requires a lock on the graph, but so do any operation creation methods (i.e. `TF_NewOperation`), so it is impossible to create ops in gradient functions.

Is there a way I can get around this?  I am considering calling `TF_NewOperationLocked` directly but I assume the locks are there for a reason.
"
48766,ModuleNotFoundError: No module named 'tensorflow.contrib',"from tensorflow.contrib.layers.python import layers as tf layers

ModuleNotFoundError: No module named 'tensorflow.contrib'

Do I need to change tensorflow2.41 to 1.14? Do I need to delete tensorflow2.4?
"
48765,"""Context not initialized"" exception when calling tf.experimental.dlpack.from_dlpack()","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2
- GPU model and memory: Quadro M1000M (2GB) /1080 Ti (11GB)

**Describe the current behavior**
Unhandled Exception: ""Context must be initialized first"" when executing a tf.experimental.dlpack.from_dlpack() before any other tf commands..

**Describe the expected behavior**
tf.experimental.dlpack.from_dlpack() should complete when called with valid arguments before other tf calls.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf
tensor = 1 #dummy argument to produce the error
OffsetData = tf.experimental.dlpack.from_dlpack(tensor)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

**workaround**
this produces the correct exception of ""incompatible function arguments""

```python
    import tensorflow as tf
    tensor = 1
    v = tf.constant([1])
    OffsetData = tf.experimental.dlpack.from_dlpack(tensor)
```"
48763,Clarify label_weights parameter in tf.keras.metrics.AUC,"### Summary of Documentation Issue in tf.keras.metrics.AUC

It is not clear whether or not the `label_weights` parameter in the [`tf.keras.metrics.AUC` documentation](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC) expects weights to  sum to 1 or not.  For example with multi-label data, you can take the sum of the occurrences of each label divided by the total number of samples to compute the following example weights:

![unscaled_label_weights](https://user-images.githubusercontent.com/17085758/116154273-13b3c180-a6ae-11eb-8f2a-242181de484f.png)

The weights above reflect the prevalence of each label.  You could also divide these weights by the sum of the weights array to put the weights in the range of [0, 1] like so:

![scaled_label_weights](https://user-images.githubusercontent.com/17085758/116154429-452c8d00-a6ae-11eb-8f6a-046856344dd8.png)

### Description of What to Clarify:

It would be helpful if the docs could be updated to clarify what these weights represent (the prevalence of each class, the scaled prevalence of each class on the range of [0, 1], or something else).  

If the docs seem straightforward to others and I am just missing something, please let me know.  I'm interested in computing micro-average PR AUC for my multi-label model, and it's not clear to me which of the following I should use for multi-hot encoded data.

##### Data Sample
```
>>> print(y_train)
>>> array([[1, 0, 1],
    [0, 1, 1],
    [0, 0, 0],
    [0, 1, 1]])
```

#### Unscaled Label Weights
```
n_samples = y_train.shape[0]
class_totals = y_train.sum(axis=0)
label_weights = class_totals / n_samples
```

#### Scaled Label Weights
```
n_samples = y_train.shape[0]
class_totals = y_train.sum(axis=0)
weights = class_totals / n_samples
label_weights = weights / sum(weights)
```

"
48762,gradient error when tf.concat is used on a list of 0-D tensors (should not allow 0-D tensors concatenation at the first place),"**System information**
Just a small corner case issue, not much related to OS, Python or hardware. 
- OS: Win10 and macOS 10.15.7
- TensorFlow version: 2.4.1
- Python version: 3.8.5

**Describe the current behavior**

When tf.concat is used to concat a list of 0-D tensors (although this very step should not be allowed), forward calculations have no issue, but reporting ZeroDivisionError when one tries to get the gradient.  

**Describe the expected behavior**

Either report error when tf.concat is used to concat a list of 0-D tensors as how numpy handles this situation (preferred), or fixed the gradient flow, or give more understandable error message (error message ZeroDivisionError seems somewhat misleading as /0 does not happen in the code).  

**Standalone code to reproduce the issue**
```
import tensorflow as tf

def this_works():
    x = tf.zeros([10])  
    with tf.GradientTape() as gt:
        gt.watch(x)
        a = []
        for i in range(10):
            a.append(x[i:i+1])
        y = tf.reduce_sum(tf.concat(a, axis=0))
    print(y)
    print(gt.gradient(y, x))

this_works()


def this_fails():
    x = tf.zeros([10])  
    with tf.GradientTape() as gt:
        gt.watch(x)
        a = []
        for i in range(10):
            a.append(x[i]) # should not allowed
        y = tf.reduce_sum(tf.concat(a, axis=0))
    print(y)
    print(gt.gradient(y, x)) # fails here, error message ZeroDivisionError 
    
this_fails()
```
"
48761,Error when import: Failed to load the native TensorFlow runtime version GLIBC_2.28 not found,"**System information**
- OS Platform and Distribution: Ubuntu 18.04.1
- TensorFlow version: 2.2.0
- Hardware: Raspberry Pi 4 Model B Rev 1.4
- Architecture: aarch64
- Python version: 3.7.5 [64-bit]
- Installed using: virtualenv and pip
- ldd version: ldd (Ubuntu GLIBC 2.27-3ubuntu1.4) 2.27

**Describe the problem**
I used the wheel referred to in this tutorial [tutorial](https://qengineering.eu/install-tensorflow-2.2.0-on-raspberry-64-os.html) and installed using pip successfully. However, when I tried to import TF I get this error:
ImportError: /lib/aarch64-linux-gnu/libc.so.6: version `GLIBC_2.28' not found (required by /home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
Some sources suggest downgrading python which is not an option for me as this wheel I'm using needs explicitly 3.7 (if there's another wheel I can use, I'm willing to use other version of python, but I prefer to stick with ubuntu 18.04)

**Provide the exact sequence of commands / steps that you executed before running into the problem**
`sudo apt-get install python3.7 python3.7-dev  python3.7-venv`
`python3.7 -m venv donkey` 
`source donkey/bin/activate`
`gdown https://drive.google.com/uc?id=1fR9lsi_bsI_npPFB-wZyvgjbO0V9FbMf`
`pip install tensorflow-2.2.0-cp37-cp37m-linux_aarch64.whl`

**Any other info / logs**
<pre>
Traceback (most recent call last):
  File ""/home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /lib/aarch64-linux-gnu/libc.so.6: version `GLIBC_2.28' not found (required by /home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /lib/aarch64-linux-gnu/libc.so.6: version `GLIBC_2.28' not found (required by /home/ubuntu/donkey/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)


Failed to load the native TensorFlow runtime.</pre>
"
48759,Change the default for num_epochs to 1 from None in make_csv_dataset,"The default for the num_epochs parameter in make_csv_dataset is None:

```
    num_epochs: An int specifying the number of times this dataset is repeated.
      If None, cycles through the dataset forever.
```

This is really confusing to the user (at least, it was very surprising and confusing to me). I could not tell why my training appeared to be 'hanging'. It turned out it was due to this default. I propose that this be changed to 1. Looping forever is highly unexpected and leads to many user time cycles left trying to debug and understand what's happening.

I'm filing this per the discussion in TFRS regarding this problem which took a long time to troubleshoot and fix. Per that discussion,

> [the]... default [...] goes against the compositional nature of tf.data APIs (where you'd normally stick a .repeat() at the end if you want an infinite dataset).

(Opening an issue here to replace https://github.com/tensorflow/io/issues/1377 per @yongtang 's suggestion)."
48757,Remove uint8 support in CMSIS-NN kernels,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source): 323d8b857216f20bf4266ea0a7876363d707aceb
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
Uint8 support is being removed in TFLM. CMSIS-NN kernels still have some uint8 support and it should be removed.

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
48756,"Build failed ""The command line is too long""","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
**Win10** 
- TensorFlow installed from (source or binary): 
**source**
- TensorFlow version: 
**2.4.0**
- Python version:
 **3.7**
- Installed using virtualenv? pip? conda?:
**conda**
- Bazel version (if compiling from source): 
**3.1.0**
- GCC/Compiler version (if compiling from source): 
**VS2019**
- CUDA/cuDNN version: 
**11.0/8.0**
- GPU model and memory:
- 



**Describe the problem**

Hello,
I'm trying to build Tensorflow.dll from source as described below with GPU support and without ROCm.
The build fails on ""Command is too long"" I can't reduce the sizes of the paths, it's all relative. 
I saw previous related issues and due to that I checked the official site and it's says bazel 3.1.0 compatible with tensor 2.4.0

I will appreciate any suggestions. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Ignore the dots in the path.
I tried with and without ""eigen strong inline for some C++""

set BAZEL_VC=C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC

C:\...\tensorflow-2.4.0>python ./configure.py
You have bazel 3.1.0 installed.
Please specify the location of python. [Default is C:\ProgramData\Anaconda3\python.exe]: C:\ProgramData\Anaconda3\python.exe


Found possible Python library paths:
  C:\ProgramData\Anaconda3\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\ProgramData\Anaconda3\lib\site-packages]
C:\ProgramData\Anaconda3\lib\site-packages
Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Found CUDA 11.0 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0/include
Found cuDNN 8 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as ""x.y"" or ""compute_xy"" to include both virtual and binary GPU code, or as ""sm_xy"" to only include the binary code.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 7.0


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:


Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y
Eigen strong inline overridden.

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=mkl_aarch64    # Build with oneDNN support for Aarch64.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=ngraph         # Build with Intel nGraph support.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=nonccl         # Disable NVIDIA NCCL support.

C:\..\tensorflow-2.4.0>bazel build --config=opt --config=cuda tensorflow:tensorflow.dll

**Any other info / logs**

**The error**
ERROR: C:/../tensorflow-2.4.0/tensorflow/compiler/xla/service/cpu/BUILD:130:1: C++ compilation of rule '//tensorflow/compiler/xla/service/cpu:cpu_compiler' failed (Exit 1): python.exe failed: error executing command
  cd C:/users/auadmin/_bazel_auadmin/q3fiaeg3/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.28.29910\ATLMFC\include;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.28.29910\include;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\cppwinrt
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.28.29910\ATLMFC\lib\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.28.29910\lib\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\um\x64
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\\Extensions\Microsoft\IntelliCode\CLI;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.28.29910\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\MSBuild\Current\bin\Roslyn;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.8 Tools\x64\;C:\Program Files (x86)\HTML Help Workshop;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\FSharp\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\Tools\devinit;C:\Program Files (x86)\Windows Kits\10\bin\10.0.19041.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\\MSBuild\Current\Bin;C:\WINDOWS\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\Tools\;;C:\WINDOWS\system32;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\Llvm\x64\bin;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/python.exe
    SET PYTHON_LIB_PATH=C:/ProgramData/Anaconda3/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\auadmin\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=7.0
    SET TF_NEED_CUDA=1
    SET TMP=C:\Users\auadmin\AppData\Local\Temp
  C:/ProgramData/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/libjpeg_turbo /Ibazel-out/x64_windows-opt/bin/external/libjpeg_turbo /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Iexternal/llvm-project /Ibazel-out/x64_windows-opt/bin/external/llvm-project /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_pattern_gen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/canonicalize_inc_gen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/chlo_ops_inc_gen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_base_inc_gen /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_inc_gen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineMemoryOpInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ViewLikeInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/CopyOpInterfaceIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredInterfacesIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/MLIRShapeCanonicalizationIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ShapeOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/TransformsPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ConversionPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LLVMOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/OpenMPOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LLVMConversionIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LLVMPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LLVMAVX512IncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/LLVMAVX512ConversionIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/AVX512IncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/AffinePassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/AsyncOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/GPUBaseIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/GPUOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/NVVMConversionIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/NVVMOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/GPUToNVVMGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/GPUPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ParallelLoopMapperAttrGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/GPUToROCDLTGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ROCDLOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/GPUToSPIRVIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVAvailabilityIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVCanonicalizationIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpUtilsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVSerializationGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/OpenACCOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLInterpOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/QuantOpsIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/QuantPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/ShapeTransformsPassIncGen /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsTransformsPassIncGen /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/gif/windows /Ibazel-out/x64_windows-opt/bin/external/gif/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/llvm-project/llvm/include /Ibazel-out/x64_windows-opt/bin/external/llvm-project/llvm/include /Iexternal/llvm-project/llvm/include/llvm/IR /Ibazel-out/x64_windows-opt/bin/external/llvm-project/llvm/include/llvm/IR /Iexternal/llvm-project/llvm/include/llvm/Frontend/OpenMP /Ibazel-out/x64_windows-opt/bin/external/llvm-project/llvm/include/llvm/Frontend/OpenMP /Iexternal/llvm-project/llvm/lib/Target/AMDGPU /Ibazel-out/x64_windows-opt/bin/external/llvm-project/llvm/lib/Target/AMDGPU /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Itensorflow/compiler/mlir/xla/include /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/xla/include /Itensorflow/compiler/mlir/hlo/include /Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/hlo/include /Iexternal/llvm-project/mlir/include /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/include /Iexternal/llvm-project/llvm/lib/Target/NVPTX /Ibazel-out/x64_windows-opt/bin/external/llvm-project/llvm/lib/Target/NVPTX /Iexternal/llvm-project/mlir/lib/Conversions/GPUToSPIRV /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/lib/Conversions/GPUToSPIRV /Iexternal/llvm-project/mlir/lib/Conversion/StandardToSPIRV /Ibazel-out/x64_windows-opt/bin/external/llvm-project/mlir/lib/Conversion/StandardToSPIRV /Iexternal/llvm-project/llvm/lib/Target/X86 /Ibazel-out/x64_windows-opt/bin/external/llvm-project/llvm/lib/Target/X86 /DMLIR_CUDA_CONVERSIONS_ENABLED /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_CRT_NONSTDC_NO_DEPRECATE /D_CRT_NONSTDC_NO_WARNINGS /D_SCL_SECURE_NO_DEPRECATE /D_SCL_SECURE_NO_WARNINGS /DUNICODE /D_UNICODE /DLLVM_ENABLE_STATS /D__STDC_LIMIT_MACROS /D__STDC_CONSTANT_MACROS /D__STDC_FORMAT_MACROS /DLLVM_BUILD_GLOBAL_ISEL /DTF_USE_SNAPPY /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /showIncludes /MD /O2 /DNDEBUG /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /arch:AVX /std:c++14 /Fobazel-out/x64_windows-opt/bin/tensorflow/compiler/xla/service/cpu/_objs/cpu_compiler/cpu_compiler.obj /c tensorflow/compiler/xla/service/cpu/cpu_compiler.cc
Execution platform: @local_execution_config_platform//:platform
The command line is too long.
Target //tensorflow:tensorflow.dll failed to build
INFO: Elapsed time: 4.811s, Critical Path: 0.83s
INFO: 1 process: 1 local.
FAILED: Build did NOT complete successfully
Also is there a  known way yo rub the build by parts? 

Thank you! 
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
48755,tf.keras.preprocessing.image_dataset_from_directory Error,"TensorFlow version: 2.4.1
python version: 3.7.10
CUDA version: 11.2
CUDA Driver version: 465.19.01


Document of the function
  `tf.keras.preprocessing.image_dataset_from_directory`
the parameter `directory` is: 
`Directory where the data is located. If labels is ""inferred"", it should contain subdirectories, each containing images for a class. Otherwise, the directory structure is ignored.`

But the directory structure is not ignored.


I read a code of  `tf.keras.preprocessing.dataset_utils.index_directory`,
and I found that it always care about subdirs even if labels are feed by list already. 

Sample code: 
```python
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    image_path,
    labels=labels,
    label_mode=""binary"",
    validation_split=0.2,
    subset='training',
)

len(labels) == 202599
len(os.listdir(image_path)) == 202599  # Every file in image_path are JPG format.
```

It raises an error: 
 Expected the lengths of `labels` to match the number of files in the target directory. `len(labels)` is 202599 while we found 0 files in `image_path`."
48753,tf.distribute.MirroredStrategy hangs when custom op used NCCL,"TensorFLow version: 2.4.1
python version: 3.8.5
CUDA version: 11.2
CUDA Driver version: 460.32.03
NCCL version: 2.8.4

Issue elaboration:
I implemented a custom op where NCCL API are used to exchange data among GPUs. And I used this custom op with `tf.distribute.MirroredStrategy`.
Here is the status:

- Situation 1:

```python
class CustomLayer(tf.keras.layers.Layer):
    ...
    def call(inputs, training=True):
        outputs = custom_op(inputs, training=training)
        return outputs

strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
     layer = CustomLayer()

@tf.function
def _step(input):
    return layer(input)

for iterations in range(10):
    output = strategy.run(_step, args=(inputs,)) # where inputs are an PerReplica data
```
I used 8 GPUs and set `NCCL_LAUNCH_MODE=PARALLEL` to run the above code snippet, **it works.**


- Situation 2:
```python
class CustomLayer(tf.keras.layers.Layer):
    ...
    def call(inputs, training=True):
        outputs = custom_op(inputs, training=training)
        return outputs

strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
     layer = CustomLayer()
     var = tf.Variable(initial_value=1.0, dtype=tf.float32)

@tf.function
def _step(input):
    return var * layer(input)

for iterations in range(10):
    output = strategy.run(_step, args=(inputs,)) # where inputs are an PerReplica data
```
I still used 8 GPUs and set `NCCL_LAUNCH_MODE=PARALLEL`  to run the above code snippet. But only 1 or 2 iterations will be executed successfully, then the program will **hang**.  <br>
I tried to add `std::cout` inside of my custom op to check which GPU's OpKernel is not executed. And it always shows that `GPU 0` 's OpKernel::Compute() is not executed. And other GPUs are waiting for GPU0 to arrive at NCCL API calling point.

- Situation 3:
```python
class CustomLayer(tf.keras.layers.Layer):
    ...
    def call(inputs, training=True):
        outputs = custom_op(inputs, training=training)
        return outputs

strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
     layer = CustomLayer()
     var = tf.Variable(initial_value=1.0, dtype=tf.float32)

@tf.function
def _step(input):
    return var * layer(input)

for iterations in range(10):
    output = strategy.run(_step, args=(inputs,)) # where inputs are an PerReplica data
```
The same code with situation 2, and 8 GPUs are used. But **not set** environment variable `NCCL_LAUNCH_MODE=PARALLEL`. And it **works**, all iterations are successfully executed.
<br>


**My question is:**
How can I find out why `GPU0` hangs after 1 or 2 iterations in situation 2?  <br>
How to find out which operation caused TensorFlow stucks for executing the Opkernel::Comput()?"
48752,microspeech pretrained model is uint8 quantized instead of int8 quantized and doesn't work properly,"## URL(s) with the issue:

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech/train#trained-models

## Description of issue (what needs changing):

There is a download link for the pre-trained microspeech model; speech_commands.zip.  When you download and unzip the files there are 3:
model.cc (encoded array is 18222 bytes long)
model.tflite (file is 18222 bytes long)
model.tb

The documentation says that this is a model that is int8 quantized at the inputs and outputs **but it is wrong**, the model in the zip file is actually uint8 quantified on the inputs and outputs.

The model used in the microspeech example is 18712 bytes long:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/micro_features/model.cc

I picked up the model.tflite from the zip file because I needed to load it as a bytestream instead of as an array.  

I just found out my code is not working because the quantization is wrong.  The spectrograms generate as int8 and because this model is uint8 I've been dropping out half my data when casting an int8 to an uint8.

I recreated the model using the https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb starting from the pretrained checkpoints and the output model is correctly quantized using int8's.

The zipfile needs to be updated with the correct model files and then the link in the page changed to point at the new zip file.

### Page
![image](https://user-images.githubusercontent.com/250942/116026221-3f886600-a620-11eb-9ded-f36fa633ef91.png)

### Contents of speech_commands.zip archive
![image](https://user-images.githubusercontent.com/250942/116026202-34cdd100-a620-11eb-93c4-efb54febc6aa.png)

### Neutron View of downloaded model
![image](https://user-images.githubusercontent.com/250942/116026326-79f20300-a620-11eb-8426-fc80d730b080.png)

### Neutron View of retrained model
![image](https://user-images.githubusercontent.com/250942/116026398-ab6ace80-a620-11eb-8033-2ab835c66060.png)
"
48749,Tensorflow_core.combat-v2 Has no attribute __Internal,"I get this error that says combat-v2 module has no __internal attribute.
Can someone help me how to solve this
Error
AttributeError: module 'tensorflow_core.compat.v2' has no attribute '__internal__'"
48748,win10  bazel Extracting Bazel installation...,"i wanna build the tf2.4 version with rtx3070,cuda11,cudnn8 on win10 system

according to the official tutorial, I have built the msys2, visual studio 2019,and all the configuration including the path set

however when i installed the bazel, when i open the cmd window, when i type bazel ,it just stagnate Extracting Bazel installation... and quit.

why was that?SOS"
48747,How to reopen eager_execution after close it ?,"system: Macos X
TF version: 2.4.1

After turn off eager_execution,  I get the follow error.


Traceback (most recent call last):
  File ""/Users/yanqing/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3418, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-52f64b3b4137>"", line 12, in <module>
    convert_variables_to_constants_v2(func)
  File ""/Users/yanqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 1068, in convert_variables_to_constants_v2
    converter_data = _FunctionConverterData(
  File ""/Users/yanqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 806, in __init__
    self._build_tensor_data()
  File ""/Users/yanqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 823, in _build_tensor_data
    data = map_index_to_variable[idx].numpy()
  File ""/Users/yanqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 619, in numpy
    raise NotImplementedError(
NotImplementedError: numpy() is only available when eager execution is enabled.


```python
import tensorflow as tf
from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2


tf.compat.v1.disable_eager_execution()

# do something with tf1

module = tf.keras.layers.PReLU()
func = tf.function(lambda x0: module(x0))
func = func.get_concrete_function(tf.TensorSpec((10, 24, 24, 3), dtype=tf.float32))
convert_variables_to_constants_v2(func)
```"
48746,"bugNodeDef expected inputs 'float, int32' do not match 1 inputs specified","### env
win10
py3.6
tf-1.15.2
gpu1070
-------------------------------------------------------------------------------------------------------------------------
This is the code I run. The failure caused by this function-- tf.train.import_meta_graph. i want to reload 'mobilenet_v2_1.4_224.ckpt.meta'. this pre-model is from [slim pre-model](https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz).

```python
def copy_var_from_ckpt(ckpt_path, meta_graph_path):
    with tf.Session() as sess:
        sess.run(tf.initialize_all_variables())
        saver = tf.train.import_meta_graph(meta_graph_path)
        saver.restore(sess, ckpt_path)
        graph = tf.Graph().as_default()
```

The following information is obtained

```python
 File ""C:\Program Files\Python36\lib\site-packages\tensorflow_core\python\framework\importer.py"", line 501, in _import_graph_def_internal
    graph._c_graph, serialized, options)  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT, DT_INT32, DT_UINT32]>; NodeDef: {{node TPUReplicate/loop/CrossReplicaSum}}
```
How to solve it?"
48745,TFlite on container problem,"Hello, I run inference model TFlite on this Github: https://github.com/Mjrovai/TFLite_IA_at_the_Edge 

It can run on raspbian 32 bit without any problem, but after I put it on the container. I got an error: 

Traceback (most recent call last):
  File ""TFLite_IA_at_the_Edge/mMobile.py"", line 42, in <module>
    model_path='./models/mobilenet_v1_1.0_224_quant.tflite')
  File ""/usr/local/lib/python3.7/dist-packages/tflite_runtime/interpreter.py"", line 204, in __init__
    model_path, self._custom_op_registerers))
ValueError: Could not open './models/mobilenet_v1_1.0_224_quant.tflite'.

I guess the problem may be TFlite doesn't support this image or something. I use base docker image jsurf/rpi-raspbian 

Any idea about this?"
48743,loss calculation for multi-dim samples in distributed strategy,"Hi, I was reading the distributed strategy and found one issue in the official doc
https://www.tensorflow.org/tutorials/distribute/custom_training

> If labels is multi-dimensional, then average the per_example_loss across the number of elements in each sample. For example, if the shape of predictions is (batch_size, H, W, n_classes) and labels is (batch_size, H, W), you will need to update per_example_loss like: per_example_loss /= tf.cast(tf.reduce_prod(tf.shape(labels)[1:]), tf.float32)

Since the last dimension is automatically reduced in ""NONE"" mode (https://github.com/tensorflow/tensorflow/issues/27190), then the manual reduce formula for the distributed.strategy should be
per_example_loss /= tf.cast(tf.reduce_prod(tf.shape(labels)[1:**-1**]), tf.float32) # notice the addition of -1 in shape() to remove the accumulation for the last axis

I don't know which place I should put this post to, but please update the relevant people who is in charge of the doc. Thanks."
48742,Tensorflow only sees a fraction of Tensorflow memory,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.4.1
- Python version: 3.8.8
- Installed using virtualenv? pip? conda?: Virtualenv inside docker
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): gcc 7.5.0
- CUDA/cuDNN version: CUDA 11.3 (host) CUDA 11.2 (docker), cuDNN8
- GPU model and memory: GT 730, 1gb



**Describe the problem**
My device has 1gb of memory but Tensorflow only sees 636mb:

```
+-----------------------------------------------------------------------------+
 | NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
 |-------------------------------+----------------------+----------------------+
 | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
 | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
 |                               |                      |               MIG M. |
 |===============================+======================+======================|
 |   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 N/A |                  N/A |
 | 30%   33C    P8    N/A /  N/A |    118MiB /   980MiB |     N/A      Default |
 |                               |                      |                  N/A |
 +-------------------------------+----------------------+----------------------+
```

```
>>> import tensorflow as tf
2021-04-24 12:33:23.660088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
>>> tf.test.is_gpu_available()
WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
2021-04-24 12:33:36.109192: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-24 12:33:36.112728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-24 12:33:36.163350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: NVIDIA GeForce GT 730 computeCapability: 3.5
coreClock: 0.9015GHz coreCount: 2 deviceMemorySize: 980.00MiB deviceMemoryBandwidth: 37.33GiB/s
2021-04-24 12:33:36.163429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-24 12:33:36.174055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-24 12:33:36.174941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-24 12:33:36.179867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-24 12:33:36.181045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-24 12:33:36.184262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2021-04-24 12:33:36.187118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-24 12:33:36.188172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-24 12:33:36.189819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-24 12:33:36.190342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-24 12:33:37.537902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-24 12:33:37.537984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0
2021-04-24 12:33:37.538003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N
2021-04-24 12:33:37.540130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 636 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GT 730, p
ci bus id: 0000:01:00.0, compute capability: 3.5)
True

```

Could this be the result of build config?"
48741,mbed/STM32F7 compiling issue with AllOpsResolver: undefined reference to `__SXTB16_RORn',"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 8cae746d8449c7dda5298327353d68613f16e798
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arm Mbed OS (ST-Discovery-STM32F746NG)
- Mbed version: mbed-cli==1.10.5
- GNU Arm embedded toolchain version: 10-2020-q4-major

**Describe the problem**
While running mbed compilation on the tflite micro example `hello_world`, I experienced errors relating to ``undefined reference to `__SXTB16_RORn'``. Investigating further, it seems to be a problem with the `AllOpsResolver`, specifically when it calls `AddConv2D()` (details below). 

**Please provide the exact sequence of commands/steps when you ran into the problem**
I followed the changes to `tensorflow/lite/micro/examples/hello_world` from the recent [pull request](https://github.com/tensorflow/tensorflow/pull/48659) for `tensorflow/lite/micro/examples/micro_speech` which updated the `make` command and `disco_f746ng/Makefile.inc` to use `TARGET` and `OPTIMIZED_KERNEL_DIR` instead of `TAGS`. See [changes here](https://github.com/tensorflow/tensorflow/pull/48740). 
```bash
$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=disco_f746ng OPTIMIZED_KERNEL_DIR=cmsis_nn generate_hello_world_mbed_project
$ cd tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed
$ mbed config root .
$ mbed deploy
$ mbed compile -m DISCO_F746NG -t GCC_ARM
```
And here is the output of the `mbed compile` command: 
```bash
[mbed] Working path ""/home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed"" (library)
[mbed] Program path ""/home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed""
[Warning] @,: Compiler version mismatch: Have 10.2.1; expected version >= 9.0.0 and < 10.0.0
Building project mbed (DISCO_F746NG, GCC_ARM)
Scan: mbed
Link: mbed
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: BUILD/DISCO_F746NG/GCC_ARM/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.o: in function `arm_nn_mat_mult_nt_t_s8':
/home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:109: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: /home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:110: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: /home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:116: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: /home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:123: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: /home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:134: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: BUILD/DISCO_F746NG/GCC_ARM/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.o:/home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:135: more undefined references to `__SXTB16_RORn' follow
collect2: error: ld returned 1 exit status
[ERROR] /usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: BUILD/DISCO_F746NG/GCC_ARM/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.o: in function `arm_nn_mat_mult_nt_t_s8':
/home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:109: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: /home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:110: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: /home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:116: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: /home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:123: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: /home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:134: undefined reference to `__SXTB16_RORn'
/usr/share/gcc-arm-none-eabi-10-2020-q4-major/bin/../lib/gcc/arm-none-eabi/10.2.1/../../../../arm-none-eabi/bin/ld: BUILD/DISCO_F746NG/GCC_ARM/tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.o:/home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/NN/Source/NNSupportFunctions/arm_nn_mat_mult_nt_t_s8.c:135: more undefined references to `__SXTB16_RORn' follow
collect2: error: ld returned 1 exit status

[mbed] ERROR: ""/home/user/.virtualenvs/mbed/bin/python"" returned error.
       Code: 1
       Path: ""/home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed""
       Command: ""/home/user/.virtualenvs/mbed/bin/python -u /home/user/Git/tensorflow/tensorflow/lite/micro/tools/make/gen/disco_f746ng_cortex-m4_default/prj/hello_world/mbed/mbed-os/tools/make.py -t GCC_ARM -m DISCO_F746NG --source . --build ./BUILD/DISCO_F746NG/GCC_ARM""
       Tip: You could retry the last command with ""-v"" flag for verbose output
---
```
If I [comment out `AddConv2D()` in `tensorflow/lite/micro/all_ops_resolver.cc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/all_ops_resolver.cc#L33), the problem goes away. 
Similarly in `tensorflow/lite/micro/examples/micro_speech`, if I replace the Op Resolver from `MicroMutableOpResolver` to `AllOpsResolver`, the same error above appears. 
I'm not sure if this is a problem upstream with [Mbed CLI](https://github.com/ARMmbed/mbed-cli/), or with the Arm CMSIS library. "
48738,"tfa.seq2seq.AttentionWrapperState : TypeError: __new__() missing 3 required positional arguments: 'alignments', 'alignment_history', and 'attention_state'","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64 bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.8
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**The following is my code block which uses AttentionWrapper:**

```
def decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, text_length, summary_length, 
                   max_summary_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers):
    '''Create the decoding cell and attention for the training and inference decoding layers'''
    
    for layer in range(num_layers):
        with tf.variable_scope('decoder_{}'.format(layer)):
            lstm = tf.compat.v1.nn.rnn_cell.LSTMCell(rnn_size,
                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))
            dec_cell = tf.compat.v1.nn.rnn_cell.DropoutWrapper(lstm, 
                                                     input_keep_prob = keep_prob)
    
    output_layer = Dense(vocab_size,
                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))
    
    attn_mech = tfa.seq2seq.BahdanauAttention(rnn_size,
                                                  enc_output,
                                                  text_length,
                                                  normalize=False,
                                                  name='BahdanauAttention')

    dec_cell = tfa.seq2seq.AttentionWrapper(dec_cell,
                                                          attn_mech,
                                                          rnn_size)
            
    
    initial_state = tfa.seq2seq.AttentionWrapperState(enc_state[0],_zero_state_tensors(rnn_size,batch_size,tf.float32))
     
    with tf.variable_scope(""decode""):
        training_logits = training_decoding_layer(dec_embed_input, 
                                                  summary_length, 
                                                  dec_cell, 
                                                  initial_state,
                                                  output_layer,
                                                  vocab_size, 
                                                  max_summary_length)
    with tf.variable_scope(""decode"", reuse=True):
        inference_logits = inference_decoding_layer(embeddings,  
                                                    vocab_to_int['<GO>'], 
                                                    vocab_to_int['<EOS>'],
                                                    dec_cell, 
                                                    initial_state, 
                                                    output_layer,
                                                    max_summary_length,
                                                    batch_size)

    return training_logits, inference_logits
```

When I run the below block:

```
# Build the graph
train_graph = tf.Graph()
# Set the graph to default to ensure that it is ready for training
with train_graph.as_default():
    
    # Load the model inputs    
    input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length = model_inputs()

    # Create the training and inference logits
    training_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),
                                                      targets, 
                                                      keep_prob,   
                                                      text_length,
                                                      summary_length,
                                                      max_summary_length,
                                                      len(vocab_to_int)+1,
                                                      rnn_size, 
                                                      num_layers, 
                                                      vocab_to_int,
                                                      batch_size)
    
    # Create tensors for the training logits and inference logits
    training_logits = tf.identity(training_logits.rnn_output, 'logits')
    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')
    
    # Create the weights for sequence_loss
    masks = tf.sequence_mask(summary_length, max_summary_length, dtype=tf.float32, name='masks')

    with tf.name_scope(""optimization""):
        # Loss function
        cost = tf.contrib.seq2seq.sequence_loss(
            training_logits,
            targets,
            masks)

        # Optimizer
        optimizer = tf.train.AdamOptimizer(learning_rate)

        # Gradient Clipping
        gradients = optimizer.compute_gradients(cost)
        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]
        train_op = optimizer.apply_gradients(capped_gradients)
print(""Graph is built."")
```

I get the following error:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-111-2482e3ce02af> in <module>
      8 
      9     # Create the training and inference logits
---> 10     training_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),
     11                                                       targets,
     12                                                       keep_prob,

<ipython-input-107-605aa3e33839> in seq2seq_model(input_data, target_data, keep_prob, text_length, summary_length, max_summary_length, vocab_size, rnn_size, num_layers, vocab_to_int, batch_size)
     12     dec_embed_input = tf.nn.embedding_lookup(embeddings, dec_input)
     13 
---> 14     training_logits, inference_logits  = decoding_layer(dec_embed_input, 
     15                                                         embeddings,
     16                                                         enc_output,

<ipython-input-106-b74ed3efc070> in decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, text_length, summary_length, max_summary_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers)
     24 
     25 
---> 26     initial_state = tfa.seq2seq.AttentionWrapperState(enc_state[0],_zero_state_tensors(rnn_size,batch_size,tf.float32))
     27 
     28     with tf.variable_scope(""decode""):

TypeError: __new__() missing 3 required positional arguments: 'alignments', 'alignment_history', and 'attention_state'
```

Please help.
"
48736,Allow different shapes for `y_true` and `y_pred` in graph mode,"**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Currently, running Keras in graph mode means that `y_true` and `y_pred` in the `loss` function passed to `Model.fit()` must have the same shape. Although this works in eager mode, I would like to be able to train models where `y_true` and `y_pred` are different shapes while benefiting from graph mode. My use case is that `y_true` has an extra final dimension of size 2, where index 0 gives the labels and index 1 gives a sample weight which I use for weighting my loss function (e.g. multiplying some pixels by zero).

This relates to the following issue in the Keras GitHub but there wasn't a satisfying solution provided: https://github.com/keras-team/keras/issues/4781

For the time being I'm simply adding an extra dimension of size 1 to the `y_pred` from my model using `tf.expand_dims`. However, this is inconvenient for the rest of my codebase where I now have to slice out the final dimension of my model's predictions.

Apologies if this has already been addressed in a later version of TF or if I've missed something...
"
48734,Question about Cannot Import,"This are parts of my code：
 
![image](https://user-images.githubusercontent.com/78319233/115960832-21e6ce00-a546-11eb-92c2-21a28665f3d8.png)
![image](https://user-images.githubusercontent.com/78319233/115960837-2b703600-a546-11eb-9027-ca04cc2e0a12.png)

from tensorflow.python.eager.context import get_config

ImportError: cannot import name 'get_config'
can someone tell me why?
"
48733,INSTALL ERROR: No matching distribution found for tensorflow on RASPERRY PI 4 ARM64 UBUNTU 18.04 ,"**System information**
- Hardware: Raspberry Pi 4 Model B Rev 1.4
- Architecture: aarch64
- OS Platform and Distribution: Ubuntu 18.04.1
- Python version: 3.7.5 [64-bit]
- Pip version: 21.0.1
- Installed using: virtualenv and pip

**Describe the problem**
I get the following error when I try to install: (I tried other versions of python including 3.5, 3.6, 3.7 and 3.8)
`ERROR: Could not find a version that satisfies the requirement tensorflow`
`ERROR: No matching distribution found for tensorflow`

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Created virtual environment, activated it and then:
`pip3 install tensorflow`



"
48732,Custom gradient tape-based fit() function is slower than Tf2 fit() and has memory leaking,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.1 LTS
- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1
- Python version: Python 3.8.5
- CUDA/cuDNN version: CUDA Version 11.0.207
- GPU model and memory: NVIDIA Quadro RTX 5000, 16 GB GDDR6

I wrote a custom `fit()` function using gradient tape in TF2. The `@tf.function` decorator has been used in a few specific locations to disable eager execution, which is supposed to speed up the whole code.

My custom fit has three main issues:

1-It's a lot slower than its TF2 counterpart (decorator `@tf.function` on the `train_batch` function does not improve the speed, while the decorator placed above the `fit()` function does). The time indicated on the output (see image attached below) of the custom `fit()` is wrong for some reason, in reality it is constant, around 10 seconds per each epoch.

2-Memory usage does increase linearly (see plot at the bottom).

3-Code gets killed even before reaching the maximum amount of GPU memory usage (see code output at the bottom).

Below you can find the complete code, you should be able to run it directly, as it does not require any data or any additional line of code.
```
import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, Flatten, MaxPooling1D
from tensorflow.keras.models import Model
import numpy as np
import warnings
import psutil
import time
import matplotlib.pyplot as plt


### DEFINE NEURAL NETWORK
def baseline_network():
    input = Input(shape=(128, 11))
    layer = Conv1D(64, 5, activation='relu', padding='same')(input) 
    layer = Flatten()(layer)
    layer = Dense(1024, activation='relu')(layer)
    output = Dense(257, activation=None)(layer)
                  
    model = Model(inputs=input, outputs=output)
    model.compile(optimizer='adam',
                  loss='mse', 
                  metrics=['mse'])
   
    return model


### DATA GENERATOR
def generator():
    
    # initialize numpy tensors
    X_out = np.zeros([6000, 128, 11])
    Y_out = np.zeros([6000, 257])

    ### CREATE DATA BATCHES ###
    while True:
        for i in range(32):
        
            yield X_out, Y_out


### CUSTOM FIT USING GRADIENT TAPE
class runGradientTape:
    
    def __init__(self, model, cost_function, iterator_train, steps_train, max_epochs, batch_size):
        
        self.model = model
        self.cost_function = cost_function
        self.iterator_train = iterator_train
        self.steps_train = steps_train
        self.max_epochs = max_epochs
        self.batch_size = batch_size


    def lossWrapper(self):
        
        #@tf.function
        def lossFunction(y_true, y_pred):
            # calculating loss and squeezing single dimensions away
            loss = tf.squeeze(self.cost_function(y_pred, y_true))
            # calculate mean over batches
            loss = tf.reduce_mean(loss)
            # return the loss
            return loss
        # returning the loss function as handle
        return lossFunction
    
    
    @tf.function
    def train_batch(self, x_batch_train, y_batch_train):
        # run gradient taping
        with tf.GradientTape() as tape:
            y_hat = self.model(x_batch_train, training=True)
            loss_value = self.loss_fn(y_batch_train, y_hat)

        # calculate gradients
        grads = tape.gradient(loss_value, self.model.trainable_variables)
        self.model.optimizer.apply_gradients(zip(grads, self.model.trainable_variables)) 
        
        return loss_value
    
    
    @tf.function
    def fit(self):
        
        # others
        warnings.filterwarnings(""ignore"")

        self.loss_fn = self.lossWrapper()
        progbar = tf.keras.utils.Progbar(self.steps_train)
        
        memory_used = []
        
        # ITERATE OVER EPOCHS 
        for epoch in range(self.max_epochs):
            
            print('Epoch = %d/%d' %(epoch+1, self.max_epochs))
            
            # iterate over steps in training generator
            for i in range(self.steps_train):
                
                x_batch_train, y_batch_train = next(self.iterator_train)
                
                loss_value = self.train_batch(x_batch_train, y_batch_train)
                progbar.update(i+1)
                
                memory_used.append(psutil.virtual_memory().used / 2 ** 30)
                #print('   memory used: ', memory_used[-1])
        
        #plt.plot(memory_used)
        #plt.title('Memory usage vs batch')
        #plt.savefig('mem_usage')

                
# parameters
steps_train = 100       
n_epochs = 5
batch_size = 32
baseline =  baseline_network()   
iterator_train = generator()

# TF2 fit()
print(""TF2 fit"")
start_time = time.time()
history = baseline.fit(iterator_train, steps_per_epoch=steps_train, epochs=n_epochs)
stop_time = time.time()
print(""time elapsed (TF2 fit): "", stop_time-start_time)

#reset parameters
del baseline, iterator_train
baseline =  baseline_network()   
iterator_train = generator()

# custom fit
print(""Custom fit"")
start_time = time.time()
run_gradient_tape = runGradientTape(baseline, keras.losses.MSE, iterator_train, steps_train, n_epochs, batch_size)  
run_gradient_tape.fit()
stop_time = time.time()
print(""time elapsed (custom fit): "", stop_time-start_time)
```

Some of the suggestions I tried so far:

1- `gs.collect()` does not give any improvement in this case.

2- profiling the code using tensorboard (check profile and memory usage below).

Could you please give me any suggestion on how to solve the three previously mentioned problems?

Code output
![](https://i.stack.imgur.com/LEZkN.png)

Memory usage
![](https://i.stack.imgur.com/IA4wr.png)
![](https://i.stack.imgur.com/Oj8Tc.png)

Timing:
![](https://i.stack.imgur.com/OpaD3.png)


"
48731,dow,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
48730,Tensorflow,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
48726,Tensorflow not working on Windows (Parallel) VM on Mac with M1 Chip,"**Error: ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.**

System info:
Cuda V11.3
cudnn V11.3
Pycharm
Python 3.7
VS2019 installed as well
Installed tensorflow by : `pip install tensorflow` (tensorflow version: 1.15.0) and also tried tensorflow 2.4.1

System is: windows10 installed by parallel on Mac with M1 Chip

When I test tensorflow by following commends, it gave me these error
`import tensorflow as tf`

Traceback (most recent call last):
File ""C:\Users\XXXXXXXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXXvenv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in
from tensorflow.python.pywrap_tensorflow_internal import *
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in
_pywrap_tensorflow_internal = swig_import_helper()
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\imp.py"", line 242, in load_module
return load_dynamic(name, filename, file)
File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\imp.py"", line 342, in load_dynamic
return _load(spec)
**ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:**

Traceback (most recent call last):
File ""C:/Users/XXXX/Documents/XXXX/Development/Application/WebVersion-Desktop/XXXX/XXXX/XXXXapp.py"", line 39, in
from model import KeyPointClassifier
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\model_init_.py"", line 1, in
from model.keypoint_classifier.keypoint_classifier import KeyPointClassifier
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXXr\model\keypoint_classifier\keypoint_classifier.py"", line 4, in
import tensorflow as tf
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\venv\lib\site-packages\tensorflow_init_.py"", line 99, in
from tensorflow_core import *
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\venv\lib\site-packages\tensorflow_core_init_.py"", line 28, in
from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\venv\lib\site-packages\tensorflow_init_.py"", line 50, in getattr
module = self.load()
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\venv\lib\site-packages\tensorflow_init.py"", line 44, in _load
module = importlib.import_module(self.name)
File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\importlib_init.py"", line 127, in import_module
return _bootstrap.gcd_import(name[level:], package, level)
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\venv\lib\site-packages\tensorflow_core\python_init.py"", line 49, in
from tensorflow.python import pywrap_tensorflow
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXX\XXXX\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in
from tensorflow.python.pywrap_tensorflow_internal import *
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXXr\XXXX\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in
_pywrap_tensorflow_internal = swig_import_helper()
File ""C:\Users\XXXX\Documents\XXXX\Development\Application\WebVersion-Desktop\XXXXXXXX\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\imp.py"", line 242, in load_module
return load_dynamic(name, filename, file)
File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\imp.py"", line 342, in load_dynamic
return _load(spec)
**ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

Failed to load the native TensorFlow runtime.**

See https://www.tensorflow.org/install/errors

for some common reasons and solutions. Include the entire stack trace
above this error message when asking for help.

Process finished with exit code 1

Can someone please give us some help? thanks a lot!

"
48722,Obsolete NVIDIA driver check for CUDA 11.2,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Ubuntu 20.04
- TensorFlow installed from: binary
- TensorFlow version: 2.5.0
- Python version: 3.8
- CUDA/cuDNN version: 11.2/8.1.1 (Docker image: `tensorflow/tensorflow:2.5.0-gpu`)

**Describe the current behavior**

```bash
docker run --gpus all --entrypoint python tensorflow/tensorflow:2.5.0-gpu -c ""import tensorflow as tf; tf.zeros([50])""
```

When running the Docker command above and GPU driver 455 installed on the host, the following error message is logged:

> `E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected`
> `I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: f7b7a8f85319`
> `I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: f7b7a8f85319`
> `I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.73.1`
> `I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 455.32.0`
> `E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 455.32.0 does not match DSO version 460.73.1 -- cannot find working devices in this configuration`

However, this driver version check is no longer accurate. Starting with CUDA 11.1, minor CUDA versions no longer require a driver update. So all CUDA 11.x versions are compatible with driver versions >= 450.

This change is referred as the ""CUDA Enhanced Compatibility"" in the [CUDA Compatibility](https://docs.nvidia.com/deploy/cuda-compatibility/index.html) guide.

**Describe the expected behavior**

TensorFlow binaries should comply with the [CUDA Compatibility](https://docs.nvidia.com/deploy/cuda-compatibility/index.html) guide. So TensorFlow with CUDA 11.2 should work with GPU drivers >= 450 instead of >= 460.

See in particular the Table 1 that specifies the driver requirement for each CUDA version:

CUDA Toolkit | Linux x86_64 Required Driver Version
-- | --
CUDA 11.3 | >= 450.80.02
CUDA 11.2 | >= 450.80.02
CUDA 11.1 (11.1.0) | >= 450.80.02
CUDA 11.0 (11.0.3) | >= 450.36.06
CUDA 10.2 (10.2.89) | >= 440.33
CUDA 10.1 (10.1.105) | >= 418.39
CUDA 10.0 (10.0.130) | >= 410.48"
48721,tf.RaggedTensor.bounding_shape: out_type argument is ignored,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.5.0-rc0-36-g0d1805aede0 2.5.0-rc1
- Python version: 3.9.2
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
`RaggedTensor.bounding_shape` has an argument out_type which is supposed to control the type of the output tensor. But it does not seem to have any effect:
```
>>> tf.RaggedTensor.from_tensor([[1,2,3]]).bounding_shape(1, out_type=tf.int32)  # output is not int32
<tf.Tensor: shape=(), dtype=int64, numpy=3>
```

**Describe the expected behavior**
```
>>> tf.RaggedTensor.from_tensor([[1,2,3]]).bounding_shape(1, out_type=tf.int32)
<tf.Tensor: shape=(), dtype=int32, numpy=3>
```

**Standalone code to reproduce the issue**
```
>>> tf.RaggedTensor.from_tensor([[1,2,3]]).bounding_shape(1, out_type=tf.int32)
<tf.Tensor: shape=(), dtype=int64, numpy=3>
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48720,Didn't find op for builtin opcode 'CAST' version '1',"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Platformio
- TensorFlow installed from (source or binary): Platformio Library
- Tensorflow version (commit SHA if source): TensorFlowLite_ESP32 0.9.0, model done on tensorflow 2.4
- 
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32

**Describe the problem**

When i try to run a custom model i get this error :
```Rebooting...
Didn't find op for builtin opcode 'CAST' version '1'

Failed to get registration from op code  d

AllocateTensors() failed
Guru Meditation Error: Core  1 panic'ed (LoadProhibited). Exception was unhandled.
Core 1 register dump:
PC      : 0x400d17f4  PS      : 0x00060130  A0      : 0x800e5830  A1      : 0x3ffb1f80  
A2      : 0x3ffd7c70  A3      : 0x00000000  A4      : 0x000003e8  A5      : 0x3ffc03b8  
A6      : 0x00000008  A7      : 0x00000001  A8      : 0x800d17e3  A9      : 0x3ffb1f70  
A10     : 0x00000000  A11     : 0x447a0000  A12     : 0x3ffc044c  A13     : 0x3ffc1470  
A14     : 0x7f800000  A15     : 0x447a0000  SAR     : 0x0000001f  EXCCAUSE: 0x0000001c  
EXCVADDR: 0x00000004  LBEG    : 0x400014fd  LEND    : 0x4000150d  LCOUNT  : 0xffffffff  

ELF file SHA256: 0000000000000000

Backtrace: 0x400d17f4:0x3ffb1f80 0x400e582d:0x3ffb1fb0 0x4008627e:0x3ffb1fd0
```


Thanks"
48719,Unclear if Debug build on Windows is supported,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/install/source_windows

## Description of issue (what needs changing):
Specify if building Debug verion of TF on Windows is possible. 
From looking at bugs here people are having problems, but it is unclear if it is officially not supported, or it is supported, clarifying that in docs would help.


"
48718,IOS version of TensorFlowLiteC expose symbol(s) not found error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

When attempting to use TensorFlow Lite on iOS  as the documentation, the linker raises an error that it found:

```
Undefined symbols for architecture arm64:
  ""_OBJC_CLASS_$_NSProcessInfo"", referenced from:
      objc-class-ref in TensorFlowLiteC
  ""_CFBundleGetVersionNumber"", referenced from:
      l5794 in TensorFlowLiteC
  ""___CFConstantStringClassReference"", referenced from:
      CFString in TensorFlowLiteC
  ""_objc_release"", referenced from:
      l4515 in TensorFlowLiteC
  ""_objc_msgSend"", referenced from:
      l4506 in TensorFlowLiteC
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
```

I build my app with cmake with cmakelist.txt and include ""tensorflow/lite/c/c_api.h"" in model.h as:
```
cmake_minimum_required(VERSION 3.5)
project(myapp)
set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -O2 -fPIC"")
include_directories(${CMAKE_SOURCE_DIR}/tflib/include)
link_directories(${CMAKE_SOURCE_DIR}/tflib/lib)
add_library(mylib_ios SHAREDsrc/model.cc src/model.h)
find_library(TFLiteC NAMES TensorFlowLiteC HINTS ${CMAKE_SOURCE_DIR}/tflib/lib)
target_link_libraries(mylib_ios ${TFLiteC})
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
48717,boosted tree classifier h-params,"<em>I am working with the [boosted tree classifier](https://github.com/tensorflow/estimator/blob/781c0d30c6bf100aa174591dd97cb70fc39d294d/tensorflow_estimator/python/estimator/canned/boosted_trees.py#L1933)</em>

**System information**
- TensorFlow installed from: pip
- TensorFlow version: 2.4.1
- Python version: 3.6.5


**Describe the current behavior**
There is a hyper-parameter in the model called `n_trees` which its 
default value is 100, also, there is a step parameter `max_step=100` in the training method.



**Describe the expected behavior**
Based on the gradient boosting classifier, `n_trees` refers to the number of trees, which we add at each boosting iteration.
The question is, what is the difference between these two parameters in the model?

**Standalone code to reproduce the issue**
I tried to plot the boosting accuracy and have the accuracy by adding a new tree at each iteration [here](https://github.com/samanemami/TFBoostedTree/blob/main/examples/Accuracy_plot.ipynb). 
I used `max_step` to have boosting iteration, so what is the **role of `max_step`** (in train method)?


**Other info / logs** Include any logs or source code that would be helpful to
[Boosted tree](https://github.com/tensorflow/estimator/blob/781c0d30c6bf100aa174591dd97cb70fc39d294d/tensorflow_estimator/python/estimator/canned/boosted_trees.py#L1933).
[train method](https://github.com/tensorflow/estimator/blob/781c0d30c6bf100aa174591dd97cb70fc39d294d/tensorflow_estimator/python/estimator/canned/boosted_trees_test.py#L403)."
48714,Adding a utility to penalize majority class pixels in the Segmentation tutorial,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/tutorials/images/segmentation

## Description of issue (what needs changing):

It's not really an issue, a suggestion rather. 

### Clear description

Semantic segmentation datasets can be highly imbalanced meaning that particular class pixels can be present more inside images than that of other classes. Since segmentation problems can be treated as per-pixel classification problems we can deal with the imbalance problem by weighing the loss function to account for this. It's a simple and elegant way to deal with this problem. Other solutions include always ensuring that a batch of samples (during training) always contain some proportion (which is prefixed) of positive classes. 

However, TensorFlow does not yet support the `class_weight` argument in `model.fit()` for targets that are 3D (for segmentation problems, we are essentially predicting a map of shape `[batch_size, height, width, nb_channels]`). One way to get around this problem is to use `sample_weight` instead. But then again, it's not very clear as to how to do that properly particularly with `tf.data` pipelines. 

Multiple folks have tried several hacks to get around this problem but it keeps coming back (see [here](https://github.com/keras-team/keras/issues/3653)). Therefore, I think the tutorial under question is a perfect opportunity to demonstrate the use case. 

Cc: @MarkDaoust "
48713,`Adadelta` optimizer throws error on GPU in apply_gradients,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: 
- GPU model and memory:


**Standalone code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
import random


def test_optimizer(optimizer):
  class Layer1(tf.keras.layers.Layer):

      def __init__(self, shape):
          super(Layer1, self).__init__()
          self.weight1 = self.add_weight(shape=shape)
          
      def call(self, inputs):
          return tf.gather(self.weight1, axis=0, indices=inputs)


  x = tf.keras.Input(shape=[1,])
  ind = tf.cast(x, ""int64"")
  y = Layer1(shape=(10, 2))(ind)
  model = tf.keras.Model(x, y)
  model.compile(optimizer=optimizer, loss='mse')

  x_data = np.array([[random.randint(0, 9),],])

  out = model(x_data)
  y_data = np.zeros(out.shape)
  with tf.GradientTape() as tape:
    y_pred = model(x_data)
    loss = tf.keras.losses.MeanSquaredError()(y_data, y_pred)

    gradients = tape.gradient(loss, model.trainable_weights)

  optimizer.apply_gradients(zip(gradients, model.trainable_weights))

test_optimizer(tf.optimizers.Adam())
print('Adam Passed')
test_optimizer(tf.optimizers.Adadelta())

```

**Outputs / logs** 
```
Adam Passed
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-16-69f396904fc3> in <module>()
      1 test_optimizer(tf.optimizers.Adam())
      2 print('Adam Passed')
----> 3 test_optimizer(tf.optimizers.Adadelta())
      4 print('Adadelta Passed')

16 frames
<ipython-input-13-fbaf6e8a2eb4> in test_optimizer(optimizer)
     31     gradients = tape.gradient(loss, model.trainable_weights)
     32 
---> 33   optimizer.apply_gradients(zip(gradients, model.trainable_weights))


NotFoundError: No registered 'ResourceSparseApplyAdadelta' OpKernel for 'GPU' devices compatible with node {{node ResourceSparseApplyAdadelta}}
	.  Registered:  device='CPU'; T in [DT_COMPLEX128]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_COMPLEX128]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_COMPLEX64]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_COMPLEX64]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_BFLOAT16]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_BFLOAT16]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT32]
 [Op:ResourceSparseApplyAdadelta]
```

**Describe the current behavior**

I am using `Adadelta` optimizer for training on GPU. During backpropagation `optimizer.apply_gradients()` I encounter this `NotFoundError`: No registered 'ResourceSparseApplyAdadelta' OpKernel for 'GPU' devices compatible with node {{node ResourceSparseApplyAdadelta}}.

However, if `Adam` optimizer is used, no error occurs.


**Describe the expected behavior**
The `Adadelta` optimizer works on CPU. I expect `Adamdelta` optimizer to work also on GPU.

"
48712,"Issue: Invalid argument:  assertion failed: [len requires non-zero rank, got 0]","I am experiencing the below issue on random occurrences.

I checked my data and it looks good. Please advise, as this is a production issue.

Thank you.

Nektarios

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Custom**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows and Linux**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.3.1 and 2.4.1** 
- Python version: **3.8**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: **11.0/8.05**
- GPU model and memory: **NVIDIA Titan Volta**
- 
```
Traceback (most recent call last):
  File ""C:\Development\Python\Python386\lib\contextlib.py"", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File ""C:\Development\Python\Python386\lib\site-packages\tensorflow\python\ops\variable_scope.py"", line 2825, in variable_creator_scope
    yield
  File ""C:\Development\Python\Python386\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""C:\Development\Python\Python386\lib\site-packages\tensorflow\python\eager\def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Development\Python\Python386\lib\site-packages\tensorflow\python\eager\def_function.py"", line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""C:\Development\Python\Python386\lib\site-packages\tensorflow\python\eager\function.py"", line 2942, in __call__
    return graph_function._call_flat(
  File ""C:\Development\Python\Python386\lib\site-packages\tensorflow\python\eager\function.py"", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""C:\Development\Python\Python386\lib\site-packages\tensorflow\python\eager\function.py"", line 555, in call
    outputs = execute.execute(
  File ""C:\Development\Python\Python386\lib\site-packages\tensorflow\python\eager\execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  assertion failed: [len requires non-zero rank, got 0]
	 [[{{node cond/else/_1157/cond/Assert/Assert}}]]
	 [[cond_1/pivot_f/_1168/_61]]
  (1) Invalid argument:  assertion failed: [len requires non-zero rank, got 0]
	 [[{{node cond/else/_1157/cond/Assert/Assert}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_110455]
Function call stack:
train_function -> train_function
 

```

<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>



You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
48711,Failed to load the native TensorFlow runtime.,"### System information

-   **OS Platform and Distribution (macOS 10.15.7)**:
-   **TensorFlow installed from (pip3 install tensorflow)**:
-   **TensorFlow version (2.4.1)**:
-   **Python version(3.8)**:

### Describe the problem
I tried install and re-install tensorflow many times. Including manually remove all the package folders. But I still could not import tensorflow in my terminal.

### Source code / logs
import tensorflow as tf
Traceback (most recent call last):
  File ""/Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: dlopen(/Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _PyThread_tss_alloc
  Referenced from: /Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
  Expected in: flat namespace
 in /Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/__init__.py"", line 39, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""/Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: dlopen(/Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _PyThread_tss_alloc
  Referenced from: /Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
  Expected in: flat namespace
 in /Users/zmengfan/Library/Python/3.8/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
48710,Python model to javascript model always return same prediction,"Hi and thanks in advance,

I create my own model in python and I get a 93% of accuracy,
then I convert my model to a js model using the command ""tensorflowjs_converter --input_format keras customModel_gs.h5 model/"", 

I add the model file to my angular project and then I try this:
![imagen](https://user-images.githubusercontent.com/43205522/115792840-e2dc3f80-a3c2-11eb-80a7-0a3d9f0e7861.png)

The model charge I can do a summary all is correct except the predition, doesn't care the img a upload, always return the same number 2.

My input_shape is a null,128,128,1 (grayscale), I have 4 classes
![imagen](https://user-images.githubusercontent.com/43205522/115793218-a78e4080-a3c3-11eb-9df2-20f3388335dc.png)
![imagen](https://user-images.githubusercontent.com/43205522/115793289-c391e200-a3c3-11eb-9b31-19ec655ea870.png)

"
48708,model.fit() should tell you if batch is not big enough to train with,"Suppose you train a model using model.fit() and your batch size is set to N.  If the input from a generator is < N, tf keras gives the following error which is difficult to interpret: **ValueError: Expect x to be a non-empty array or dataset.**

Reference second answer in : https://stackoverflow.com/questions/63231811/valueerror-expect-x-to-be-a-non-empty-array-or-dataset-tensor-flow-lite-model

Propose to have tf keras tell user that batch size is larger than data size in place of current error.  The current error implies that the x is empty which isnt this case for all x with size less than N."
48704, Error printed when calling tf.data.experimental.load,"**System information**
- OS Platform:  WSL2 Linux Ubuntu 20.04
- TensorFlow version: 2.5.0-rc1
- Python version: 3.9
- CUDA/cuDNN version: 11.2 
- GPU model and memory: RTX 3090

**Describe the current behavior**

When calling ` tf.data.experimental.load` the bellow error is printed, however, the dataset appears to load without issue

`Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement 'InputDatasets'.`


**Describe the expected behavior**

No error message should be printed

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

ds = tf.data.Dataset.from_tensor_slices([1, 2, 3])
for i in ds:
    print(i)

tf.data.experimental.save(ds, ""/mnt/d/load_issue.dataset"", compression=""GZIP"")
load_ds = tf.data.experimental.load(""/mnt/d/load_issue.dataset"", compression=""GZIP"")

for e in load_ds:
    print(e)
```
"
48703,Feature Request: adding class_weights to tfLite Model Maker,"## Description of issue (what needs changing):
It would be great if somebody could add class_weights to the `model maker` .create() arguments because it's pretty common to work with imbalanced datasets in real life. I'm trying to retrain a model with model maker for image classification and have about 15 labels with very different balances in classes. I'm trying to change the code myself and hoping to do a pull request but I can't my code to work.

### Clear description

For example, why should someone use this method? How is it useful?
Many datasets are imbalanced and having class_weights in the .create() method will help a lot to tackle that issue.

### Correct links

https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker/core/task

### Parameters defined

Description which could be added.
class_weight: : Optional dictionary mapping class indices (integers) to a 
        weight (float) value, used for weighting the loss function 
        (during training only). This can be useful to tell the model to 
        ""pay more attention"" to samples from an under-represented class.


Are you planning to also submit a pull request to fix the issue? See the docs

I'm trying to fix it myself and would like to do a pull request but my build never works after I changed the code. I've been trying to fix it for a while and finally just figured I should see if somebody else knows how to do it.
"
48702,About biLSTM model  different sequence lenght use padding & mask.,"About 「Variable Length Sequence Support for CUDNN LSTM #23269」

i have three question about biLSTM model have different sequence lenght that i will use padding & mask.

>In 2.0 alpha, the normal keras.layer.LSTM will use cudnn kernel if possible, so you don't need to use keras.layers.CuDNNLSTM layer any more.

(1)So in tf2 I can use lstm  don't need to use keras.layers.CuDNNLSTM layer,but why is the GPU running speed different tf2 LSTM slow then tf1 CuDNNLSTM?

> The cudnn kernel only support seqence_length parameter, so that it can skip the padding data on the tail. If your data has padding at the beginning of the sequence (left padded), then cudnn kernel will not be able to work correctly in this situation. The comment here is trying to point out that specific use case.

 (2)So if I use  tf2  layer→ tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM ....),input data already padding on the tail,then cudnn kernel will be able to work correctly in this situation? But how can i prove it about masked,about model runing loss not consider padded location  ? 

(3)If padding data then model output result I need to drop padding location  right? "
48701,Function used in many augmentations (convert_image_dtype) has an issue,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab default
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Colab default
- TensorFlow version (use command below): v2.4.1-0-g85c8b2a817f 2.4.1
- Python version: 3
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: No
- GPU model and memory: No


**Describe the current behavior**
There is a function convert_image_dtype that used in many augmentation ops like tf.image.stateless_random_brightness and etc.
That function has a rounding issue here https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/ops/image_ops_impl.py#L2290
Maybe other cases also have this bug (not checked).

When we casting float to int, we should use rounding. In convert_image_dtype rounding implemented as shift by 0.5 which is correct for max value, but is not correct for 0.
See example by link below.

**Describe the expected behavior**
Every time convert_image_dtype changes value scale following casting to int, it should use rounding before casting.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1xZqyuAlZu_xkDZZHNsr7K8g6MyapcNPi?usp=sharing
"
48699,autograph prevents tf.assert protection,"**System information**

    Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
    OS Platform and Distribution: Ubuntu 18.04.5 LTS
    TensorFlow installed from: binary
    TensorFlow version: 2.2.0
    Python version: 3.6.9
    CUDA/cuDNN version: 10.1.243 / 7.6.5
    GPU model and memory: NVidia Tesla V100-SXM2-32GB

**Describe the current behavior**
`tf.assert_xxx()` are not executed due to autograph (correct but unfortunate) error.

Assume we have a function taking a tensor and a bias to be added, supposedly having the same shape. We want a meaningful error message if the shapes are not the same.
First a function that doesn't do the add. Check that the error message works.

```python
@tf.function(input_signature=[tf.TensorSpec([None, None], tf.float32), tf.TensorSpec([None, None], tf.float32)])
def my_assert_func_1(x, bias):
    print('tracing...')
    tf.print('tf.shape(bias)[1]', tf.shape(bias)[1])
    tf.assert_equal(tf.shape(x)[1], tf.shape(bias)[1], message='bad shape')

    # just return x (does nothing useful)
    return x

# successful case
my_assert_func_1(tf.ones((2,5)), tf.ones((2,5)))
```
```
tracing...
tf.shape(bias)[1] 5

<tf.Tensor: shape=(2, 5), dtype=float32, numpy=
array([[1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.]], dtype=float32)>
```
```python
# error case : the 'bad shape' message is successfully reported
my_assert_func_1(tf.ones((2,5)), tf.ones((2,7)))
```
```
tf.shape(bias)[1] 7
InvalidArgumentError:  assertion failed: [bad shape] [Condition x == y did not hold element-wise:] [x (strided_slice_1:0) = ] [5] [y (strided_slice_2:0) = ] [7]
	 [[node assert_equal_1/Assert/Assert (defined at <ipython-input-9-f5089434d4c3>:5) ]] [Op:__inference_my_assert_func_1_234]
```

Now modify the function to **actually add** the bias

```python
@tf.function(input_signature=[tf.TensorSpec([None, None], tf.float32), tf.TensorSpec([None, None], tf.float32)])
def my_assert_func_2(x, bias):
    print('tracing...')
    tf.print('tf.shape(bias)[1]', tf.shape(bias)[1])
    tf.assert_equal(tf.shape(x)[1], tf.shape(bias)[1], message='bad shape')
    # add the bias
    return x + bias

# successful case: still works
my_assert_func_2(tf.ones((2,5)), tf.ones((2,5)))
```
```
tracing...
tf.shape(bias)[1] 5

<tf.Tensor: shape=(2, 5), dtype=float32, numpy=
array([[2., 2., 2., 2., 2.],
       [2., 2., 2., 2., 2.]], dtype=float32)>
```
```python
# error case : the 'bad shape' message is NOT reported.
# Probably due to autograph that catches the error before tf.assert has a chance to execute.
# (full stacktrace in the attached gist)
my_assert_func_2(tf.ones((3,5)), tf.ones((3,7)))
```
```
tf.shape(bias)[1] 7
InvalidArgumentError:  Incompatible shapes: [3,7] vs. [3,5]
	 [[node add (defined at <ipython-input-12-b2b31a707c39>:7) ]] [Op:__inference_my_assert_func_2_284]
```

**Describe the expected behavior**
`tf_assert_xxx()` should protect against those errors and report the error message.
Not sure if this is fixable (not sure if bug or feature request, but probably hard to fix).
The consequence is that we cannot reuse in a `tf.function` libraries of custom keras layers that use `tf.assert_xxx()`.  
The attached gist shows an example of that.

**Standalone code to reproduce the issue**
https://colab.research.google.com/gist/thierryherrmann/9d253dfd32a4ab9296fadb99f5ec3651/asserts_in_tf_functions.ipynb

**Other info / logs** Include any logs or source code that would be helpful to



"
48698,Cannot run tflite model on GPU after converting it into using Float16 quantization.,"### 1. System information

- Google Colab
-Tensorflow 2

### 2. Code
https://github.com/Akhilesh64/Image-Segmentation-U-2-Net/blob/main/U2-net.py

#### Option A: Reference code
1)  Reference 
https://www.tensorflow.org/lite/performance/post_training_quantization#float16_quantization

2) The warning i get while converting this model to tflite is.
```
WARNING:absl:Found untraced functions such as _defun_call, _defun_call, _defun_call, _defun_call, _defun_call while saving (showing 5 of 63). These functions will not be directly callable after loading.
WARNING:absl:Found untraced functions such as _defun_call, _defun_call, _defun_call, _defun_call, _defun_call while saving (showing 5 of 63). These functions will not be directly callable after loading.
```

### 3. Failure after conversion
But when i use this tflite model in my app using gpu delegate it shows the error as 
```
java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.

```

- Model is not getting loaded after converting to float16 quantizaton.
- Also, can anyone help me in implementing this model for real time inference.



### 5. (optional) Any other info / logs
I also found some stackoverflow answers regarding the same https://stackoverflow.com/questions/61406595/layer-up-sampling2dclass-tensorflow-python-keras-layers-convolutional-upsampl. But couldn't understand this in detail."
48697,"""libtensorflowlite_flex_jni.so"" crashes on x86 Android emulator","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
48695,Downloaded CMSIS version is a bit old,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source): 323d8b857216f20bf4266ea0a7876363d707aceb
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
Downloaded CMSIS version is a bit old. It should be updated.

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
48694,Import graph operation in C or C++,"Hi all,
I'm dealing with the following operations. I would like to export a graph from tensorflow python API to TF C API.  Based on TF 2, I'm using graph execution and @tf.function to build the graph with custom operation. Then I'm saving the graph using save_model. Next I would like to load this graph on C or C++ and run the graph to obtain the outputs. Which is the best procedure to do that at the moment?"
48693,How to build a dynamic library for ios tflite by cmake with Cross-compilation?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

I have successfully built the ios static library with the comand ""bash tensorflow/lite/tools/make/download_dependencies.sh"". But I find the generated static lib is over 17Mb for each architecture. 

Meanwhile, I also try to use the command ""bazel build --config=ios_x86_64 -c op //tensorflow/lite/ios:TensorFlowLiteC_framework"" to genenrate a ios static lib (.framework), but it is bigger (>23Mb).

 In my opinion, the dynamic lib can be smaller than the static lib (17Mb). How can I obtain it?



"
48692,multi-output keras models change metric names when reloading,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below): 2.4.1
- Python version: 3.79
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**

When reloading a multi-output model, the name of the output gets repeated  when calling `tf.keras.models.Model.evaluate`:

```
>>> import tensorflow as tf
>>> tf.__version__
'2.4.1'

>>> input_a = tf.keras.Input(shape=(1,))

>>> ifoo = tf.keras.layers.Dense(1, name=""foo"")(input_a)
>>> ibar = tf.keras.layers.Dense(1, name=""bar"")(input_a)

>>> imodel = tf.keras.Model(input_a, {""foo"": foo, ""bar"": bar})
>>> imodel.compile(loss=""mse"", optimizer=""adam"", metrics={""foo"": ""mae"", ""bar"": ""mae""})
>>> model.evaluate(tf.constant([[1]]), tf.constant([[1]]), return_dict=True)

1/1 [==============================] - 0s 236ms/step - loss: 4.0179 - bar_loss: 3.9153 - foo_loss: 0.1026 - bar_mae: 1.9787 - foo_mae: 0.3203
{'loss': 4.0179123878479,
 'bar_loss': 3.915294885635376,
 'foo_loss': 0.10261743515729904,
 'bar_mae': 1.978710412979126,
 'foo_mae': 0.320339560508728}

>>> model.save(""/tmp/model"")
>>> model_relaoded = tf.keras.models.load_model(""/tmp/model"")
>>> model_relaoded.evaluate(tf.constant([[1]]), tf.constant([[1]]), return_dict=True)

1/1 [==============================] - 0s 87ms/step - loss: 4.0179 - bar_loss: 3.9153 - foo_loss: 0.1026 - bar_bar_mae: 1.9787 - foo_foo_mae: 0.3203
{'loss': 4.0179123878479,
 'bar_loss': 3.915294885635376,
 'foo_loss': 0.10261743515729904,
 'bar_bar_mae': 1.978710412979126,
 'foo_foo_mae': 0.320339560508728}
```

**Describe the expected behavior**
I would expect the metrics' name to remain unchanged when reloading:

```
>>> model.save(""/tmp/model"")
>>> model_relaoded = tf.keras.models.load_model(""/tmp/model"")
>>> model_relaoded.evaluate(tf.constant([[1]]), tf.constant([[1]]), return_dict=True)

1/1 [==============================] - 0s 87ms/step - loss: 4.0179 - bar_loss: 3.9153 - foo_loss: 0.1026 - bar_mae: 1.9787 - foo_mae: 0.3203
{'loss': 4.0179123878479,
 'bar_loss': 3.915294885635376,
 'foo_loss': 0.10261743515729904,
 'bar_mae': 1.978710412979126,
 'foo_mae': 0.320339560508728}
```


**Standalone code to reproduce the issue**

Here is a collab with the above code: https://colab.research.google.com/drive/1rm2d51gXw0ZvxIs63Qu5ACyRDK5OAgoM?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
NA

PS: I have never contributed to TensorFlow but I would be glad to help resolve this issue.
"
48690,ValueError: Found two metrics with the same name: Dense_xx Accuracy. TensorFlow 2.4,"**System information**
- OS: Linux Ubuntu 20.04 as well as Windows 10
- TensorFlow version (use command below): 2.4.1
- Python version: 3.79
- CUDA version: 11.2
- GPU model and memory: RTX 3060

**Issue**
Previously I upgraded my Tensorflow to 2.4.
I got an error message like ""ValueError: Found two metrics with the same name: dense_xx_accuracy"". 
Then, I downgraded my TF to 2.1 and everything is working fine again.

**Log**
2021-04-22 14:36:23.743926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
Nt.2 Np.2 Nr.4 M.4 RIS.4
2021-04-22 14:36:24.521915: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-22 14:36:24.522409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-22 14:36:24.526771: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-04-22 14:36:24.526787: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: user-system-sharing
2021-04-22 14:36:24.526791: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: user-system-sharing
2021-04-22 14:36:24.526838: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.67.0
2021-04-22 14:36:24.526851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.67.0
2021-04-22 14:36:24.526855: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.67.0
2021-04-22 14:36:24.526974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-04-22 14:36:24.527331: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-22 14:36:24.605219: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-22 14:36:24.605238: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-22 14:36:24.607251: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-04-22 14:36:24.653744: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-04-22 14:36:24.654329: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2799925000 Hz
Epoch 1/50
Traceback (most recent call last):

  File ""/home/user/Documents/Python/RIS/RIS-DNN_Cosine_Training.py"", line 110, in <module>
    model.fit(np.transpose(D),train_labels_app, validation_split=0.25, batch_size=512, epochs=50, callbacks=[callbacks_list, tensorboard], shuffle=True)

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 726, in _initialize
    *args, **kwds))

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 3206, in _create_graph_function
    capture_by_value=self._capture_by_value),

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)

  File ""/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)

ValueError: in user code:

    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *
        return step_function(self, iterator)
    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **
        outputs = model.train_step(data)
    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:758 train_step
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state
        self.build(y_pred, y_true)
    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:329 build
        self._set_metric_names()
    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:349 _set_metric_names
        m._name))

    ValueError: Found two metrics with the same name: dense_3_accuracy"
48689,Post training quantization conversion log show: Optimization loop failed: Cancelled: Operation was cancelled,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installation (pip package or built from source): pip package install in anaconda virtual env
- TensorFlow library (version, if pip package or github SHA, if built from source):  tf-nightly 2.6.0.dev20210407

### 2. Code

```
import numpy as np
import tensorflow as tf

def representative_dataset():
    path = r'D:\Development\fruits_data\images\test'
    image_dataset = tf.data.Dataset.list_files(path + '/*.png')
    for i in range(15):
        image = next(iter(image_dataset))
        image = tf.io.read_file(image)
        image = tf.io.decode_jpeg(image, channels=3)
        image = tf.image.resize(image, [640, 640])
        image = tf.cast(image / 255., tf.float32)
        image = tf.expand_dims(image, 0)
        yield [image]
        
#import trained model from mobilenet 640 v2 fpn
converter = tf.lite.TFLiteConverter.from_saved_model('./exported_models/tflite/saved_model') #using tensorflow

#quantize the model to int8 for export
converter.experimental_new_converter = True #required for using experimental target_spec flags.
converter.optimizations = [tf.lite.Optimize.DEFAULT] #Currently only DEFAULT is supported by TF2.4.X or tf-nightly.
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

converter.target_spec.supported_types = [tf.int8]
converter.inference_input_type = tf.int8 
#converter.inference_output_type = tf.int8 
converter.allow_custom_ops = True 
tflite_int8_model = converter.convert()

# Save the model.
with open('test_model.tflite', 'wb') as f:
  f.write(tflite_int8_model)
```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

Conversion to TFLite is successful, but on the log states: `Optimization loop failed: Cancelled: Operation was cancelled`
and during inferences the model was not able to be used. The conversion model used is the pre-trained `mobilenet 640 v2 fpn` model found in tf zoo for object detection. 


### 4. (optional) RNN conversion support
~If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.~

### 5. (optional) Any other info / logs

Terminal log: 

```
Skipping registering GPU devices...
2021-04-22 12:08:07.890584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-22 12:08:07.890670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
2021-04-22 12:08:07.891405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
2021-04-22 12:08:09.301186: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:10.346812: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:11.392280: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:12.466013: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:13.526607: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:14.586672: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:15.633286: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:16.680019: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:17.754911: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:18.828891: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:19.905723: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:20.984154: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:22.027698: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
2021-04-22 12:08:23.097239: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled
```

"
48684,Error:  tf.device does not support functions,"Tensorflow crashes when following current guide.

**System information**
Tensorflow Version: 
v2.4.0-49-g85c8b2a817f 2.4.1

**Describe the current behavior**
Following the [guide](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/replica_device_setter) on how to use `replica_device_setter`, the code crashes with the error: `RuntimeError: tf.device does not support functions.`


**Describe the expected behavior**
It should not crash

**Standalone code to reproduce the issue**
```
import tensorflow as tf
cluster_spec = {""ps"": [""ps0:2222""],""worker"": [""worker0:2222"", ""worker1:2222""]}
with tf.device(tf.compat.v1.train.replica_device_setter(cluster=cluster_spec)):
    pass
```

**Other info / logs** Include any logs or source code that would be helpful to
```
...
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in device_v2(device_name)
   5271   """"""
   5272   if callable(device_name):
-> 5273     raise RuntimeError(""tf.device does not support functions."")
   5274   return device(device_name)
   5275 

RuntimeError: tf.device does not support functions.
```
"
48683,Issues loading saved model  - TypeError: __init__() got an unexpected keyword argument 'name',solved can be closed
48680,"ValueError: Shapes (8, 100) and (8, 1) are incompatible","![image](https://user-images.githubusercontent.com/53318795/115602332-7dffe700-a2e7-11eb-9f46-16b76d8bfdd5.png)
My model params is above. when i tried to get score metrics (Recall and Precision)  this error show up 
![image](https://user-images.githubusercontent.com/53318795/115603793-4134ef80-a2e9-11eb-92b4-ecd3323b8bd6.png)
model.fit code is :
![image](https://user-images.githubusercontent.com/53318795/115603861-56118300-a2e9-11eb-90d2-94e5c2b20b7b.png)

How can i solved this problem ? 
"
48678,Skipping timesteps with ConvLSTM2D layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux RHEL 7.9
- TensorFlow installed from: binary
- TensorFlow version: 2.0.0 and 2.2.0
- Python version: 3.6.13

**Describe the current behavior**
I am working with 2D data with a variable number of timesteps, so I padded my data with zeroes and use a masking layer with the ConvLSTM2D layer; however I get an error telling me my dimensions are mismatched (traceback below)

**Describe the expected behavior**
I would expect the ConvLSTM2D layer to correctly skip the timesteps that have a value of 0 like the regular LSTM layer does. 
Note that without the masking layer, the code below runs fine.

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, ConvLSTM2D, MaxPooling2D, Masking, Input

inputs = Input(shape=(None,11,11,1)) 
mask = Masking(mask_value=0)(inputs)
conv2d_1 = ConvLSTM2D(64, (3, 3), activation=""relu"", padding=""same"")(mask)
max_pool_1 = MaxPooling2D((2,2), padding=""same"")(conv2d_1)
flatten = Flatten()(max_pool_1)
out = Dense(1, activation=""sigmoid"")(flatten)

x = np.random.rand(64, 300, 11, 11, 1)
y = np.random.randint(2, size=(64,1))

model = Model(inputs=inputs, outputs=out)
model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])
model.summary()
model.fit(x, y, epochs=2, batch_size=16)
```

**Other info / logs**
```
Traceback (most recent call last):
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1610, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 1 in both shapes must be equal, but are 11 and 121. Shapes are [?,11,11,64] and [?,121,121,64]. for 'Select' (op: 'Select') with input shapes: [?,121,121,64], [?,11,11,64], [?,11,11,64].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""issue.py"", line 8, in <module>
    conv2d_1 = ConvLSTM2D(64, (3, 3), activation=""relu"", padding=""same"")(mask)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional_recurrent.py"", line 299, in __call__
    return super(ConvRNN2D, self).__call__(inputs, **kwargs)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent.py"", line 623, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 842, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional_recurrent.py"", line 939, in call
    initial_state=initial_state)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional_recurrent.py"", line 393, in call
    input_length=timesteps)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 4122, in rnn
    **while_loop_kwargs)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 2675, in while_loop
    back_prop=back_prop)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py"", line 198, in while_loop
    add_control_dependencies=add_control_dependencies)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py"", line 176, in wrapped_body
    outputs = body(*_pack_sequence_as(orig_loop_vars, args))
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 4099, in _step
    tiled_mask_t, flat_output, flat_mask_output))
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 4098, in <genexpr>
    array_ops.where(m, o, zo) for m, o, zo in zip(
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py"", line 3753, in where
    return gen_math_ops.select(condition=condition, x=x, y=y, name=name)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py"", line 9441, in select
    ""Select"", condition=condition, t=x, e=y, name=name)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 548, in create_op
    compute_device)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal
    op_def=op_def)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1773, in __init__
    control_input_ops)
  File ""/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1613, in _create_c_op
    raise ValueError(str(e))
ValueError: Dimension 1 in both shapes must be equal, but are 11 and 121. Shapes are [?,11,11,64] and [?,121,121,64]. for 'Select' (op: 'Select') with input shapes: [?,121,121,64], [?,11,11,64], [?,11,11,64].
```"
48677, Input and output tensor of .pb file,"Hi,

I have been trying to get the input and output tensor dtype for a pb model.
```

def printTensors(pb_file):

graph = tf.Graph()
with tf.io.gfile.GFile(pb_file, ""rb"") as f:
    graph_def = tf.compat.v1.GraphDef()
    graph_def.ParseFromString(f.read())
input_tensor = graph_def.node[0]
output_tensor = graph_def.node[-1]
print(input_tensor.name)
print(output_tensor.name)
```

when I use the above code and compare against the output of summarize_graph utility there seems to be a mismatch. So my query is graph_def.node[0] is always input and graph_def.node[-1] is output ?

Cheers,
Prabhakar"
48676,can not install tensorflow,"import tensorflow as tf
Traceback (most recent call last):

  File ""C:\Users\Home\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)

  File ""<ipython-input-13-64156d691fe5>"", line 1, in <module>
    import tensorflow as tf

  File ""C:\Users\Home\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import

  File ""C:\Users\Home\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *

  File ""C:\Users\Home\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 114
    def TFE_ContextOptionsSetAsync(arg1, async):
                                             ^
SyntaxError: invalid syntax"
48675,TFLite bug: RuntimeError: tensorflow/lite/kernels/conv.cc:329 input->dims->size != 4 (3 != 4)Node number 0 (CONV_2D) failed to prepare.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 LTS
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: Python 3.6.9 :: Anaconda, Inc.

**Describe the current behavior**
I am trying to convert some model to TFLite but the error `RuntimeError: tensorflow/lite/kernels/conv.cc:329 input->dims->size != 4 (3 != 4)Node number 0 (CONV_2D) failed to prepare.` is raised when I try to convert MobileNetV3Large.

**Describe the expected behavior**
I expect to be able to convert any basic model from `TensorFlow.Keras` to `TFLite`.

**Standalone code to reproduce the issue**
```
""""""
File to show the runtime error when trying to convert MobileNetV3 to TFLite.
""""""

import tensorflow as tf


mobile_net = tf.keras.applications.MobileNetV3Large(
    input_tensor=tf.keras.Input(shape=(224, 224, 3), batch_size=1, name=""input"", dtype=tf.float32)
)
model = tf.keras.Model(inputs=mobile_net.inputs, outputs=mobile_net(mobile_net.inputs))
model.compile()
model.summary(line_length=200)


def representative_dataset_generator():
    """"""Dataset generator that generates random tensor with the same shape as the input""""""
    for _ in range(100):
        yield tf.random.uniform(shape=(1, 224, 224, 3), dtype=tf.float32)


converter = tf.lite.TFLiteConverter.from_keras_model(model)

# Set the representative dataset in order to quantize the activations
converter.representative_dataset = representative_dataset_generator

converter.optimizations = [tf.lite.Optimize.DEFAULT]

converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.target_spec.supported_types = [tf.int8]

# Set the input and output tensors to uint8
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

# Experimental environment
converter.experimental_new_converter = True
converter.experimental_new_quantizer = True

tflite_model = converter.convert()

```
**Other infos**
The problem since to be coming from `converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]`. If I comment the `converter.inference_*_type = tf.uint8`, `converter.target_spec.supported_types = [tf.int8]` and also the `converter.optimizations`line, the error is still raised but go away if I change to `converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]`.
It comes back if I uncomment the line related to the converter.optimizations.
Anyway, I need to do an integer only quantization like in the [TF tutorial here](https://www.tensorflow.org/lite/performance/post_training_quantization#integer_only). I am quite lost. Would you have any idea?
"
48673,load_model fails for certain keras.layers.Add configurations,"**System information**
Python version: 3.7
TF 2.3 version: v2.3.0-54-gfcc4b966f1 2.3.1
TF 2.4 version: v2.4.0-49-g85c8b2a817f 2.4.1
TF-nightly version: v1.12.1-55314-g6a872f41130 2.6.0-dev20210421

**Describe the current behavior**
It's possible to create and infer model with Add layer (or OpLambdaLayer-Add) that adds the input to a constant, either with the constant as first input or the last. I can save it, but can't load it again

The following code works in TF 2.3, but fails both in TF 2.4 and the nightly versions

**Describe the expected behavior**
Seems like it should be able to load the saved model

**Standalone code to reproduce the issue**
`
import tensorflow as tf
import numpy as np

np_const = np.ones((1, 6))
outs = []
_in = tf.keras.layers.Input((6,))
outs.append(tf.keras.layers.Add()((_in, _in)))
outs.append(_in + np_const)
outs.append(tf.keras.layers.Add()((np_const, _in)))  # <=== problematic layer
outs.append(np_const + _in)  # <=== problematic layer

model = tf.keras.Model(inputs=_in, outputs=outs)

print('TF version:', tf.__version__)
print('model output:', model(np.arange(18).reshape(-1, 6)))

model_file = '/tmp/add_model.h5'
model.save(model_file)

loaded_model = tf.keras.models.load_model(model_file, compile=False)
print('loaded model output:', loaded_model(np.arange(18).reshape(-1, 6)))
`

"
48672,Efficient upsampling 3D Volume with linear interpolation options,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): tensorflow2.0
- Are you willing to contribute it (Yes/No): No. I was trying to vectorize it, but I failed with out of GPU memory error. My GPU is tesla V100, memory 32G. Volume size = [128, 256, 256, 3] / want to upsampling it to [256, 256, 512, 3] by interpolation. 

**Describe the feature and the current behavior/state.**
Upsample image by trilinear / cubic-spline interpolation

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Most of people who are working with 3D data.  

**Any Other info.**
I will appreciate any efficient implementation advices for implementing it in a vectorized way. "
48671,TFLite produces bogus results on GPU when setPrecisionLossAllowed(true),"### 1. System information

- OS Platform and Distribution: Android 10
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.0

### 2. Code

I am using a FC-DenseNet model trained with PyTorch, then converted to ONNX, Tensorflow .pb and finally TFLite.
Original torch code is here: https://github.com/petko-nikolov/pysemseg/blob/master/pysemseg/models/densenet.py

Additionally, I added a `permute` operation (equivalent to Numpy transpose), `Argmax` and conversion to `np.uint8` in the end of the model. 

### 3. Failure after conversion
Model converts **OK**.
Python tests on Desktop are **OK** both with Tensorflow and TFLite.
Model is **OK** on Android using CPU
Model is **NOT OK** on Android using GPU Delegate
Model is **OK** on Android using GPU Delegate and `setPrecisionLossAllowed(false)`

"
48670,SavedModel file does not exist at,"Cannot load model whereas it does exist at the specified location.

I'm using tf.keras.models.load_model(PATH_TO_FILE) to do so, like it's explained [here](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format), but it keeps on throwing:

Traceback (most recent call last):
  File ""C:\Rasp\project\main.py"", line 37, in <module>
    model = tf.keras.models.load_model(PATH_TO_FILE)
  File ""C:\Users\me\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\python\keras\saving\save.py"", line 206, in load_model
    return saved_model_load.load(filepath, compile, options)
  File ""C:\Users\me\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\python\keras\saving\saved_model\load.py"", line 121, in load
    meta_graph_def = loader_impl.parse_saved_model(path).meta_graphs[0]
  File ""C:\Users\me\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\python\saved_model\loader_impl.py"", line 113, in parse_saved_model
    raise IOError(
OSError: SavedModel file does not exist at: C:\Rasp\experts_bit_r50x1_in21k_bird_1\saved_model.pb\{saved_model.pbtxt|saved_model.pb}

I tried with some of the models [here](https://tfhub.dev/s?q=bird)."
48668,Missing support for Ethos-U for FVP target,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source): d73d688687e48a29f06c84404f9817876e4b6325
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): FVP (cortex_m_corstone_300)

**Describe the problem**
For the FVP (cortex_m_corstone_300) there is no support for Ethos-U. It is only possible to build the microlite lib with Ethos-U and with the FVP target one can build a binary but without Ethos-U enabled.

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
48665,Keras experimental preprocessing layers with random seed does not yield the same results after a few call,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tested on Linux Ubuntu 18.04 and Google Colab
- TensorFlow version (use command below): 2.4.1
- Python version: Tested on Python 3.6.12 and Python 3.7.10
- CUDA/cuDNN version: Tested on cuda 11.1 and cuda 11.2
- GPU model and memory: gtx TITAN V / Tesla T4 (for colab)


**Describe the current behavior**

Creating two sequential only with `tf.keras.layers.experimental.preprocessing.Random*` layers with the same seed start by producing the same output, but after a few calls they do not.

- First few calls:
![image](https://user-images.githubusercontent.com/25057256/115542065-28541c00-a2a0-11eb-8875-9f77248fca1d.png)
- After multiple calls:
![image](https://user-images.githubusercontent.com/25057256/115542168-4ae63500-a2a0-11eb-8d1a-9f3e87230895.png)

**Describe the expected behavior**

I expect the layers to produce the same output every time.

**Standalone code to reproduce the issue**

I have created a Colab Notebook to reproduce the bug. Please make sure that a gpu is enabled:
https://colab.research.google.com/drive/1Hi98IwkW466ziXlXKKx9uoQwe4jSrUqC?usp=sharing

**Other info / logs Include any logs or source code that would be helpful to**

It seems to work properly when not using a gpu intance on Google Colab.
Cloning the model (using `tf.keras.models.clone_model` or duplicating the model code produce the same bug."
48664,Eigen update needed to fix tensorflow build failure on ppc64le,"Request to update Eigen in TF to https://gitlab.com/libeigen/eigen/-/commit/06c2760bd1139711eeffa30266ead43423891698
to fix compilation issue on ppc64le.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source master branch
- TensorFlow version:
- Python version: 3.9
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): gcc 9, gcc8, gcc 7
- CUDA/cuDNN version: NO CUDA (CPU only)
- GPU model and memory:



**Describe the problem**
While building tensorflow on ibmcom/tensorflow-ppc64le:devel-manylinux2014 docker image for ppc64le and using gcc 9 (tried gcc 8 and gcc 7 too), we are seeing a compilation error related to Eigen. The fix for the same has been pushed to Eigen repository yesterday at https://gitlab.com/libeigen/eigen/-/commit/06c2760bd1139711eeffa30266ead43423891698
If TF updates the eigen version to the above mentioned commit, we will get the issue fixed without any patching.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
BAZEL_LINKLIBS=-l%:libstdc++.a bazel build -c opt --config=v2 --local_cpu_resources 4 --local_ram_resources 4096 \
    //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag --cpu $WORKSPACE/tensorflow_pkg```

```

Error:

```
tensorflow/compiler/xla/service/cpu/runtime_single_threaded_matmul.cc:121:76:   required from here
external/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:498:20: error: taking address of rvalue [-fpermissive]
  498 |             lhs0 = &lhs(j + 0, i);
      |                    ^~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:499:20: error: taking address of rvalue [-fpermissive]
  499 |             lhs1 = &lhs(j + 1, i);
      |                    ^~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:501:20: error: taking address of rvalue [-fpermissive]
  501 |             lhs0 = &lhs(j + 2, i);
      |                    ^~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:502:20: error: taking address of rvalue [-fpermissive]
  502 |             lhs1 = &lhs(j + 3, i);
      |                    ^~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:505:20: error: taking address of rvalue [-fpermissive]
  505 |             lhs0 = &lhs(i, j + 0);
      |                    ^~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:506:20: error: taking address of rvalue [-fpermissive]
  506 |             lhs1 = &lhs(i, j + 1);
      |                    ^~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:508:20: error: taking address of rvalue [-fpermissive]
  508 |             lhs0 = &lhs(i, j + 2);
      |                    ^~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:509:20: error: taking address of rvalue [-fpermissive]
  509 |             lhs1 = &lhs(i, j + 3);
      |                    ^~~~~~~~~~~~~~
```"
48663,RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS focal (kernel 5.4.0-70-generic)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.3 tag
- Python version: Python 3.8.5
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): Bazel 3.1.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: cuda 10.2, cuDNN 7.6
- GPU model and memory: Nvidia GeForce GTX 760 4gb

**Describe the problem**

I have old GPU (I don't know - 5 years old - that's old? GTA 5 and tons of games running without lags) and it supports Cuda capability is 3.0 only(Kepler core). Binary TensorFlow starts from 3.5, but I read on forums that if I'll compile TensorFlow I can get 3.0.

I allready solved tons of problems, including patching source code. (here is my wiki where I explained every step http://wiki.aleksashkin.net/wiki/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B8_%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D0%B5_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5#Installation)

I've tried:

- Install other numpy version but got this error ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
tensorflow 2.3.0 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.20.0 which is incompatible.
- Install binary TensorFlow 2.3 to have all dependecies.
- Remove binary

But this problem I can't solve. Please help me. GPUs are very expensive today and I want to use all possibilities.

Thank you!

**Provide the exact sequence of commands / steps that you executed before running into the problem**

git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout r2.3
./configure# + CUDA + TensorRT
bazel build --config=cuda --config=opt //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
In file included from ./tensorflow/lite/kernels/internal/optimized/neon_check.h:25:0,
                 from ./tensorflow/lite/kernels/internal/common.h:28,
                 from ./tensorflow/lite/toco/runtime/types.h:18,
                 from ./tensorflow/lite/toco/model.h:30,
                 from ./tensorflow/lite/toco/tooling_util.h:32,
                 from tensorflow/lite/toco/tooling_util.cc:15:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:14262:32: warning: ‘int64x2_t vqdmlsl_s32(int64x2_t, int32x2_t, int32x2_t)’ is deprecated: The function may be very slow due to the serial implementation, please try to avoid it [-Wdeprecated-declarations]
     return vqdmlsl_s32(a, b, vc);
                                ^
In file included from ./tensorflow/lite/kernels/internal/optimized/neon_check.h:25:0,
                 from ./tensorflow/lite/kernels/internal/common.h:28,
                 from ./tensorflow/lite/toco/runtime/types.h:18,
                 from ./tensorflow/lite/toco/model.h:30,
                 from ./tensorflow/lite/toco/tooling_util.h:32,
                 from tensorflow/lite/toco/tooling_util.cc:15:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5003:58: note: declared here
 _NEON2SSE_INLINE _NEON2SSE_PERFORMANCE_WARNING(int64x2_t vqdmlsl_s32(int64x2_t a, int32x2_t b, int32x2_t c), _NEON2SSE_REASON_SLOW_SERIAL)
                                                          ^
external/arm_neon_2_x86_sse/NEON_2_SSE.h:76:109: note: in definition of macro ‘_NEON2SSE_PERFORMANCE_WARNING’
     #define _NEON2SSE_PERFORMANCE_WARNING(function, explanation)   __attribute__((deprecated(explanation))) function
                                                                                                             ^~~~~~~~
INFO: From Compiling tensorflow/lite/kernels/internal/optimized/sse_tensor_utils.cc [for host]:
In file included from external/gemmlowp/public/../internal/../fixedpoint/fixedpoint.h:907:0,
                 from external/gemmlowp/public/../internal/output.h:27,
                 from external/gemmlowp/public/../internal/unpack.h:23,
                 from external/gemmlowp/public/../internal/single_thread_gemm.h:29,
                 from external/gemmlowp/public/../internal/multi_thread_gemm.h:27,
                 from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,
                 from external/gemmlowp/public/gemmlowp.h:19,
                 from ./tensorflow/lite/kernels/cpu_backend_context.h:21,
                 from ./tensorflow/lite/kernels/internal/optimized/sse_tensor_utils_impl.h:20,
                 from tensorflow/lite/kernels/internal/optimized/sse_tensor_utils.cc:15:
external/gemmlowp/public/../internal/../fixedpoint/./fixedpoint_sse.h:47:39: warning: ignoring attributes on template argument ‘__m128i {aka __vector(2) long long int}’ [-Wignored-attributes]
 struct FixedPointRawTypeTraits<__m128i> {
                                       ^
In file included from external/gemmlowp/public/../internal/simd_wrappers.h:664:0,
                 from external/gemmlowp/public/../internal/output.h:29,
                 from external/gemmlowp/public/../internal/unpack.h:23,
                 from external/gemmlowp/public/../internal/single_thread_gemm.h:29,
                 from external/gemmlowp/public/../internal/multi_thread_gemm.h:27,
                 from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,
                 from external/gemmlowp/public/gemmlowp.h:19,
                 from ./tensorflow/lite/kernels/cpu_backend_context.h:21,
                 from ./tensorflow/lite/kernels/internal/optimized/sse_tensor_utils_impl.h:20,
                 from tensorflow/lite/kernels/internal/optimized/sse_tensor_utils.cc:15:
external/gemmlowp/public/../internal/simd_wrappers_sse.h:31:72: warning: ignoring attributes on template argument ‘gemmlowp::Int32x4 {aka __vector(2) long long int}’ [-Wignored-attributes]
       typename std::conditional<ScalarCount >= 4, Int32x4, std::int32_t>::type;
                                                                        ^
external/gemmlowp/public/../internal/simd_wrappers_sse.h:37:72: warning: ignoring attributes on template argument ‘gemmlowp::Int16x8 {aka __vector(2) long long int}’ [-Wignored-attributes]
       typename std::conditional<ScalarCount >= 8, Int16x8, std::int16_t>::type;
                                                                        ^
external/gemmlowp/public/../internal/simd_wrappers_sse.h:45:52: warning: ignoring attributes on template argument ‘gemmlowp::Uint8x16 {aka __vector(2) long long int}’ [-Wignored-attributes]
                                 std::uint8_t>::type>::type;
                                                    ^
ERROR: /home/artem/ml/tensorflow/tensorflow/python/keras/api/BUILD:137:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Aborted): bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)
2021-04-02 08:03:25.855138: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd
RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd
ImportError: numpy.core._multiarray_umath failed to import
ImportError: numpy.core.umath failed to import
2021-04-02 08:03:26.277871: F tensorflow/python/lib/core/bfloat16.cc:705] Check failed: PyBfloat16_Type.tp_base != nullptr 
/bin/bash: line 1: 768875 Aborted                 bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2 --apidir=bazel-out/k8-opt/bin/tensorflow/python/keras/api_v2/ --apiname=keras --apiversion=2 --loading=default --package=tensorflow.python,tensorflow.python.keras,tensorflow.python.keras.activations,tensorflow.python.keras.applications.densenet,tensorflow.python.keras.applications.efficientnet,tensorflow.python.keras.applications.imagenet_utils,tensorflow.python.keras.applications.inception_resnet_v2,tensorflow.python.keras.applications.inception_v3,tensorflow.python.keras.applications.mobilenet,tensorflow.python.keras.applications.mobilenet_v2,tensorflow.python.keras.applications.nasnet,tensorflow.python.keras.applications.resnet,tensorflow.python.keras.applications.resnet_v2,tensorflow.python.keras.applications.vgg16,tensorflow.python.keras.applications.vgg19,tensorflow.python.keras.applications.xception,tensorflow.python.keras.backend,tensorflow.python.keras.backend_config,tensorflow.python.keras.callbacks,tensorflow.python.keras.callbacks_v1,tensorflow.python.keras.constraints,tensorflow.python.keras.datasets.boston_housing,tensorflow.python.keras.datasets.cifar10,tensorflow.python.keras.datasets.cifar100,tensorflow.python.keras.datasets.fashion_mnist,tensorflow.python.keras.datasets.imdb,tensorflow.python.keras.datasets.mnist,tensorflow.python.keras.datasets.reuters,tensorflow.python.keras.engine.base_layer,tensorflow.python.keras.engine.data_adapter,tensorflow.python.keras.engine.input_layer,tensorflow.python.keras.engine.input_spec,tensorflow.python.keras.engine.sequential,tensorflow.python.keras.engine.training,tensorflow.python.keras.estimator,tensorflow.python.keras.feature_column.sequence_feature_column,tensorflow.python.keras.initializers,tensorflow.python.keras.initializers.initializers_v1,tensorflow.python.keras.initializers.initializers_v2,tensorflow.python.keras.layers.advanced_activations,tensorflow.python.keras.layers.convolutional,tensorflow.python.keras.layers.convolutional_recurrent,tensorflow.python.keras.layers.core,tensorflow.python.keras.layers.cudnn_recurrent,tensorflow.python.keras.layers.dense_attention,tensorflow.python.keras.layers.embeddings,tensorflow.python.keras.layers.local,tensorflow.python.keras.layers.merge,tensorflow.python.keras.layers.noise,tensorflow.python.keras.layers.normalization,tensorflow.python.keras.layers.normalization_v2,tensorflow.python.keras.layers.preprocessing,tensorflow.python.keras.layers.pooling,tensorflow.python.keras.layers.recurrent,tensorflow.python.keras.layers.recurrent_v2,tensorflow.python.keras.layers.serialization,tensorflow.python.keras.layers.wrappers,tensorflow.python.keras.losses,tensorflow.python.keras.metrics,tensorflow.python.keras.mixed_precision.experimental.get_layer_policy,tensorflow.python.keras.mixed_precision.experimental.loss_scale_optimizer,tensorflow.python.keras.mixed_precision.experimental.policy,tensorflow.python.keras.models,tensorflow.python.keras.optimizer_v2.adadelta,tensorflow.python.keras.optimizer_v2.adagrad,tensorflow.python.keras.optimizer_v2.adam,tensorflow.python.keras.optimizer_v2.adamax,tensorflow.python.keras.optimizer_v2.ftrl,tensorflow.python.keras.optimizer_v2.gradient_descent,tensorflow.python.keras.optimizer_v2.learning_rate_schedule,tensorflow.python.keras.optimizer_v2.nadam,tensorflow.python.keras.optimizer_v2.optimizer_v2,tensorflow.python.keras.optimizer_v2.rmsprop,tensorflow.python.keras.optimizers,tensorflow.python.keras.premade.linear,tensorflow.python.keras.premade.wide_deep,tensorflow.python.keras.preprocessing.image,tensorflow.python.keras.preprocessing.sequence,tensorflow.python.keras.preprocessing.text,tensorflow.python.keras.regularizers,tensorflow.python.keras.saving.model_config,tensorflow.python.keras.saving.save,tensorflow.python.keras.saving.saved_model_experimental,tensorflow.python.keras.utils.data_utils,tensorflow.python.keras.utils.generic_utils,tensorflow.python.keras.utils.io_utils,tensorflow.python.keras.utils.layer_utils,tensorflow.python.keras.utils.losses_utils,tensorflow.python.keras.utils.multi_gpu_utils,tensorflow.python.keras.utils.np_utils,tensorflow.python.keras.utils.vis_utils,tensorflow.python.keras.wrappers.scikit_learn --output_package=tensorflow.python.keras.api._v2 --use_relative_imports=True bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/activations/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/densenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/efficientnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/imagenet_utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_v3/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/nasnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet50/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg16/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg19/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/xception/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/backend/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/constraints/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/boston_housing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar10/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar100/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/fashion_mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/imdb/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/reuters/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/estimator/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/initializers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/losses/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/metrics/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/premade/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/models/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/schedules/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/image/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/sequence/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/text/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/regularizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/scikit_learn/__init__.py
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/artem/ml/tensorflow/tensorflow/python/tools/BUILD:282:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Aborted): bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)
INFO: Elapsed time: 21814.590s, Critical Path: 340.21s
INFO: 11206 processes: 11206 local.
FAILED: Build did NOT complete successfully
"
48662,Gradient penalty with mixed precision training,"**System information**
- TensorFlow version (you are using): 2.5.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
I haven't found a way to implement a stable gradient penalty with mixed precision. I think it comes from the use of second order gradient (the penalty is computed inside the overall loss GradientTape context). Whether I scale the gradient penalty or not (avoiding underflow), the global loss scale quickly decreases to 1 during training. I don't know if this feature necessarily requires a new TensorFlow feature, but at least a tip not mentionned in [the mixed precision guide](https://www.tensorflow.org/guide/mixed_precision).

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
At least every programmer who would like to implement a Wassertein GAN with gradient penalty, which is now the most validated setup for GAN training actually."
48661,tf.data.Dataset from_generator w/ keras.utils.Sequence doesn't trigger on_epoch_end,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8
- CUDA/cuDNN version: 11.0 / 8.0.4
- GPU model and memory: RTX 3070

**Describe the current behavior**
I created a class from `tf.keras.util.Sequence` with `on_epoch_end()` function with a print inside it. Then I created a `tf.data.Dataset from_generator` using that class. Finally used that dataset as input for my `model.fit()`.

**Describe the expected behavior**
I expect the print inside `on_epoch_end()` appear on console, but it doesn't so I suppose it never trigger that function. 

**Standalone code to reproduce the issue**
Generator class:
```
class HDF5Generator(tf.keras.utils.Sequence):
    def __init__(self, hdf5_file):
        print(""GENERATED"")
        self.hdf5 = h5py.File(hdf5_file, 'r')
        self.indices = list(range(0, len(self.hdf5[""samples""])))
        random.Random().shuffle(self.indices)

    def __len__(self):
        return len(self.hdf5[""samples""])

    def __getitem__(self, idx):
        return self.hdf5[""samples""][self.indices[idx]], self.hdf5[""labels""][self.indices[idx]]

    def on_epoch_end(self):
        print(""SHUFFLE"")
        random.Random().shuffle(self.indices)
```

Used class in fit
```
d = tf.data.Dataset.from_generator(HDF5Generator, args=[dataset], output_signature=(...))
d = d.batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()
model.fit(d, epochs=epochs)
```
This is the output:
```
Epoch 1/40
GENERATED
1969/1969 [==============================] - 63s 29ms/step - loss: 0.4823 - accuracy: 0.8020 - f1_score: 0.7989
Epoch 2/40
1969/1969 [==============================] - 22s 11ms/step - loss: 0.1111 - accuracy: 0.9562 - f1_score: 0.9567
Epoch 3/40
1969/1969 [==============================] - 23s 12ms/step - loss: 0.0947 - accuracy: 0.9610 - f1_score: 0.9614
Epoch 4/40
```
As you can see no SHUFFLE string appear in output"
48660,"Why enforcing ""Make sure all arrays contain the same number of samples.""","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**: v2.4.0-rc4-71-g582c8d236cb 2.4.0
-   **Python version**: 3.7.5
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

If my inputs is like
```
x = {
  ""x1"": tf.ones([4, 6]),
  ""x2"": tf.ones([10])
}
y = tf.ones([4])
```

then in `model.fit(x, y)`, there will be an error 
```
ValueError: Data cardinality is ambiguous:
  x sizes: 4, 10
  y sizes: 4
Make sure all arrays contain the same number of samples.
```

why we need to enforce this? In my problem by nature the inputs are like that, and inside my model I have specially handlings to make sure it can correctly recognize which element in `x2` belong to which row in a batch.

plus if we delete the `_check_data_cardinality` function, the actual `x2` that fed into the model is wrong, it is truncated to have only 4 elements and is not even the first 4 elements

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
48657,How to Modify and Debug the TFLiteConverter,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installation (pip package or built from source): built from source
- TensorFlow library (version, if pip package or github SHA, if built from source): 0d1805aede03d25aa9d49adcef6903535fa5ad14

### 2. Code

Modify `tensorflow/compiler/mlir/lite/tests/end2end/add.pbtxt` to [this](https://drive.google.com/file/d/1UxTnG9kQ_SJSDQ7_1mZAttUTlGAY5Gxo/view?usp=sharing) (basically just change the data type from `DT_INT32` to `DT_FLOAT`), then try to convert `add.pbtxt` to a fully quantized `.tflite` model using the following command:
```
./tf_tfl_translate \
  --tf-input-arrays=input0,input1 \
  --tf-input-shapes=4:4 \
  --tf-input-data-types=DT_FLOAT,DT_FLOAT \
  --tf-output-arrays=Add \
  --tf-inference-type=DT_QINT8 \
  --tf-input-min-values='-1,-1' \
  --tf-input-max-values='1,1' \
  add.pbtxt \
  -o output.tflite
```

### 3. Failure after conversion
The [output model](https://drive.google.com/file/d/1P-6V_wKkdcH4nAdM6Gl2Tft9FMNUE0Id/view?usp=sharing) `output.tflite` is not fully quantized even though `--tf-inference-type=DT_QINT8` is specified. Here is `output.tflite` when inspected with Netron:

![add-netron](https://user-images.githubusercontent.com/19867281/115502332-5a1cb100-a2a7-11eb-89a2-2db9e3ee380d.png)

FYI, [here](https://drive.google.com/file/d/1Ojz3v2mZ4O_nA2iHVpQ0us_0JAcgErL0/view?usp=sharing) is a log of the MLIR after each pass.

### 4. Any other info / logs
To be honest, I'm not sure if I am using `tf_tfl_translate` correctly, so I would like to know if this is an issue with `tf_tfl_translate` or if there is another correct way to perform full-integer quantization on a TensorFlow model using `tf_tfl_translate`.

Currently, I'm trying to add an MLIR pass to the `TFLiteConverter` (more specifically, in the function `AddTFToTFLConversionPasses` in `tensorflow/compiler/mlir/lite/tf_tfl_passes.cc`), and I want to use `TFLiteConverter` to convert and perform full-integer quantization on a TensorFlow model while running the MLIR pass I added in the process. I want to avoid rebuilding the pip package every time I modify my pass, so I decided to use the internal tool `tf_tfl_translate`, which lead to this problem.

If there are any tips and tricks on how to modify the `TFLiteConverter` to add an MLIR pass and be able to debug it without having to rebuild the pip package every time, please let me know. Thanks for your time!



"
48652,bug while running bazel build,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian Sid
- TensorFlow installed from (source or binary): source r2.5
- TensorFlow version: r2.5
- Python version: 3.9
- Installed using virtualenv? pip? conda?: pip from the system (python3-pip) no venv
- Bazel version (if compiling from source): 3.7.2  (using bazelisk)
- GCC/Compiler version (if compiling from source): gcc (Debian 10.2.1-6) 10.2.1 20210110
- CUDA/cuDNN version: 11 / 8.1.1
- GPU model and memory: NVIDIA GeForce GTX 1070



**Describe the problem**
When building tensorflow, bazel fails with the following message:
```
ERROR: /home/nicolas/.cache/bazel/_bazel_nicolas/13cce9ab7cc322a6b7e908ff0026fedd/external/nccl_archive/BUILD.bazel:54:17: in _prune_relocatable_code rule @nccl_archive//:device_pruned:
Traceback (most recent call last):
        File ""/home/nicolas/.cache/bazel/_bazel_nicolas/13cce9ab7cc322a6b7e908ff0026fedd/external/local_config_nccl/build_defs.bzl"", line 207, column 15, in _prune_relocatable_code_impl
                output.append(outputs)
Error: 'File' value has no field or method 'append'
```
After looking at the file build_defs.bzl and at this [page](https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/e07069218c39cbfc4bbad79fc50c83d64b0546af%5E%21/third_party/nccl/build_defs.bzl.tpl),
I think that famous line 207 has a confusion between output and outputs. I tried swapping one for the other and it seems ok now. Bazel has started compiling at least. :-)

I'm not sure if it is really a Tensorflow issue or where is this build_defs.bzl file hosted so I'm not sure where to ask or do a PR. Sorry if Iḿ the wrong place.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
./configure
bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package

"
48650,Cannot allocate tf_uniform_replay_buffer to GPU - No registered 'ResourceScatterUpdate' OpKernel for 'GPU' devices compatible with node,"**System information**

tensorflow 2.4.1
tf-agents 0.7.1
Nvidia RTX 2080 Ti
Windows 10
Python 3.8

**Describe the current behavior**

I am trying to run the TFUniformReplayBuffer on the GPU based on the example outlined here:

[https://pathtopioneer.com/blog/2020/07/rl-3](https://pathtopioneer.com/blog/2020/07/rl-3)

When adding device='/device:CPU:0' to the initalisation of the replay buffer everything works. When specifying GPU device='/device:GPU:0', an error occurs. It appears there is no GPU op for ResourceScatterUpdate. But how can this be fixed?

Same error when running code on Colab with GPU enabled instead of my local machine.

**Describe the expected behavior**

Should give no error with GPU enabled.

**Standalone code to reproduce the issue**

```


import tensorflow as tf
from tf_agents.replay_buffers import tf_uniform_replay_buffer
import numpy as np

data_spec =  (
        tf.TensorSpec([1], tf.float32, 'action'),
        tf.TensorSpec([5], tf.float32, 'lidar'),
        tf.TensorSpec([3, 2], tf.float32, 'camera')
)

batch_size = 32
max_length = 1000

replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(
    data_spec,
    batch_size=batch_size,
    max_length=max_length,
    device='/device:GPU:0') # when using device='/device:CPU:0') everything works

action = tf.constant(1 * np.ones(
    data_spec[0].shape.as_list(), dtype=np.float32))
lidar = tf.constant(
    2 * np.ones(data_spec[1].shape.as_list(), dtype=np.float32))
camera = tf.constant(
    3 * np.ones(data_spec[2].shape.as_list(), dtype=np.float32))

values = (action, lidar, camera)
values_batched = tf.nest.map_structure(lambda t: tf.stack([t] * batch_size),
                                       values)

replay_buffer.add_batch(values_batched)

# Convert the replay buffer to a tf.data.Dataset and iterate through it
dataset = replay_buffer.as_dataset(
    sample_batch_size=4)

iterator = iter(dataset)
print(""Iterator trajectories:"")
trajectories = []
for _ in range(3):
  t, _ = next(iterator)
  trajectories.append(t)

print(tf.nest.map_structure(lambda t: t.shape, trajectories))
```

**Other info / logs**

Exception has occurred: NotFoundError
No registered 'ResourceScatterUpdate' OpKernel for 'GPU' devices compatible with node {{node ResourceScatterUpdate}}
	 (OpKernel was found, but attributes didn't match) Requested Attributes: Tindices=DT_INT64, dtype=DT_INT64
	.  Registered:  device='CPU'; dtype in [DT_UINT64]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_UINT64]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_INT64]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_INT64]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_UINT32]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_UINT32]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_UINT16]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_UINT16]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_INT16]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_INT16]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_UINT8]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_UINT8]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_INT8]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_INT8]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_INT32]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_INT32]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_HALF]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_HALF]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_BFLOAT16]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_BFLOAT16]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_DOUBLE]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_DOUBLE]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_COMPLEX64]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_COMPLEX64]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_COMPLEX128]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_COMPLEX128]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_STRING]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_STRING]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_BOOL]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_BOOL]; Tindices in [DT_INT64]
  device='CPU'; dtype in [DT_VARIANT]; Tindices in [DT_INT32]
  device='CPU'; dtype in [DT_VARIANT]; Tindices in [DT_INT64]
  device='GPU'; dtype in [DT_HALF]; Tindices in [DT_INT32]
  device='GPU'; dtype in [DT_HALF]; Tindices in [DT_INT64]
  device='GPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT32]
  device='GPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT64]
  device='GPU'; dtype in [DT_DOUBLE]; Tindices in [DT_INT32]
  device='GPU'; dtype in [DT_DOUBLE]; Tindices in [DT_INT64]
  device='GPU'; dtype in [DT_VARIANT]; Tindices in [DT_INT32]
  device='GPU'; dtype in [DT_BOOL]; Tindices in [DT_INT32]
  device='GPU'; dtype in [DT_VARIANT]; Tindices in [DT_INT64]
 [Op:ResourceScatterUpdate]
  File ""C:\Users\Martin\Documents\GitHub\rl-investing\helper\replay.py"", line 31, in <module>
    replay_buffer.add_batch(values_batched)
"
48649,tf.data.experimental.save,"My GIT version and tf.version: unknown, 2.2.0


**Describe the current behavior**
I am trying to use [tf.data.experimental.save ](https://www.tensorflow.org/api_docs/python/tf/data/experimental/save)to save a tf Dataset
**Describe the expected behavior**
Expected behaviour is that the dataset should be saved
**Standalone code to reproduce the issue**
The code is very simple:
```
import tensorflow as tf
dataset = tf.data.Dataset.range(2)
tf.data.experimental.save(dataset, path)
```
The error I got was:
`AttributeError: module 'tensorflow._api.v2.data.experimental' has no attribute '                                                                                                             save'
`
"
48647,Softmax layer unexpected behaviour for axis=0,"### Description:
The [Softmax layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Softmax) returns all ones when axis=0 is used. Perhaps this behaviour is not wrong, but it is really confusing since it is not what the user would expect from this layer. 
It would make sense to better explain in the documentation how the axis are numbered, especially since both negative and positive numbers can be used. Moreover, it might also make sense to add an error or warning message when axis=0 is used.


### Usage example
```
import tensorflow as tf
from tensorflow import keras
model = keras.Sequential([
keras.layers.Softmax(axis=0, input_shape=(3, 3))])
x = tf.constant([[[0.8055, 0.0083, 0.4057], [0.1249, 0.9762, 0.5402], [0.0637, 0.1539, 0.0282]]])
print (model.predict(x,steps=1))
```
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.8.5

"
48646,ReLU layer wrong result with negative threshold,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.8.5

**Describe the current behavior**
The [ReLu](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU) layer seems to have an issue with negative thresholds, even though it should support them according to the documentation. For example, for a  `max_value=1` and `threshold=-1`, ReLu should produce f(x)=0.5 for x=0.5 according to the following formula from the documentation  `f(x) = x if threshold <= x < max_value`. 
The issue is illustrated in the following code.

**Standalone code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras
model = keras.Sequential([
keras.layers.ReLU(max_value=1, threshold=-1, negative_slope=1, input_shape=(4,))])
x = tf.constant([[1.5, 0.5,-0.5, -1.5]])
print (model.predict(x,steps=1))
```
`Output: [[ 1.   0.5  0.  -0.5]] Expected Output: [[1   0.5  -0.5  -0.5]]`
"
48644,AveragePooling3D does not support float64 and produces confusing error message,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.8.5



**Description**
AveragePooling3D and MaxPool3D layer don't seem to support float64, i.e. they don't work with `tf.keras.backend.set_floatx('float64')`. The MaxPool3D layer shows a nice helpful error message, when it is used with float64, but AveragePooling3D only shows a strange error message that is not helpful: tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'AvgPool3D'

It would be great, if AveragePooling3D layer would also produce a similar helpful error message. 
Even better would be if both these layers would also support float64. It is quite strange that this is not supported since all other pool layers seem to support float64.


**Standalone code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras
import numpy as np
tf.keras.backend.set_floatx('float64')
model = keras.Sequential([
keras.layers.AveragePooling3D(pool_size=(3, 1, 3), input_shape=(3, 3, 3, 4))])
x = tf.constant([[[[[2, 2, 2, 1], [1, 1, 2, 2], [1, 1, 1, 1]], [[1, 1, 1, 2], [2, 1, 2, 2], [1, 2, 2, 2]], [[1, 1, 1, 2], [1, 1, 1, 1], [2, 1, 1, 1]]], [[[1, 2, 2, 1], [2, 2, 1, 1], [1, 2, 1, 1]], [[2, 2, 2, 1], [1, 1, 1, 1], [2, 2, 1, 2]], [[1, 2, 2, 1], [2, 2, 2, 1], [1, 1, 2, 1]]], [[[1, 1, 1, 1], [2, 2, 1, 2], [1, 1, 1, 2]], [[1, 1, 2, 1], [1, 1, 1, 1], [2, 2, 1, 2]], [[2, 2, 2, 1], [2, 1, 1, 2], [1, 1, 2, 2]]]]])
print (np.array2string(model.predict(x,steps=1), separator=', '))
```

The same example with a MaxPool3D layer shows a much more helpful error message (TypeError: Value passed to parameter 'input' has DataType float64 not in list of allowed values: float16, bfloat16, float32) as illustrated in the following code
```
import tensorflow as tf
from tensorflow import keras
import numpy as np
tf.keras.backend.set_floatx('float64')
model = keras.Sequential([
keras.layers.MaxPool3D(pool_size=(1, 2, 2), input_shape=(4, 4, 3, 3))])
x = tf.constant([[[[[1, 2, 2], [1, 2, 2], [2, 2, 1]], [[1, 2, 1], [1, 2, 2], [1, 1, 2]], [[2, 2, 1], [2, 1, 1], [1, 2, 1]], [[2, 1, 2], [1, 1, 2], [1, 1, 1]]], [[[2, 1, 2], [2, 2, 1], [1, 2, 2]], [[1, 2, 2], [2, 1, 1], [2, 2, 2]], [[2, 1, 1], [2, 1, 2], [2, 1, 2]], [[2, 1, 2], [2, 2, 1], [1, 1, 2]]], [[[1, 1, 1], [2, 1, 2], [1, 2, 2]], [[2, 2, 1], [1, 2, 1], [1, 1, 1]], [[1, 1, 2], [2, 2, 2], [2, 2, 1]], [[1, 2, 1], [1, 1, 2], [1, 1, 2]]], [[[2, 1, 1], [1, 1, 1], [2, 1, 2]], [[1, 2, 1], [2, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 1, 2], [2, 2, 2]], [[2, 1, 1], [2, 1, 1], [1, 2, 1]]]]])
print (np.array2string(model.predict(x,steps=1), separator=', '))
```

"
48643,"Why the same model has different behaviours? One requires training = True, the other one not?","I have Unet model used to train 2 different datasets; one with input_shape = (128,128,1) and the other with input_shape = (128,128,3). After training, model1 does not require training = True, while model2 requires training = True for image segmentation. Why is this happening even I am using the same settings except the input_shapes are different? You can find the model [here](https://github.com/tensorflow/tensorflow/issues/48448#issuecomment-818020142);  

```
>>> model1.summary()
Model: ""model_1""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_2 (InputLayer)            [(None, 128, 128, 1) 0
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 128, 128, 64) 640         input_2[0][0]
__________________________________________________________________________________________________
leaky_re_lu_19 (LeakyReLU)      (None, 128, 128, 64) 0           conv2d_20[0][0]
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 128, 128, 64) 36928       leaky_re_lu_19[0][0]
__________________________________________________________________________________________________
leaky_re_lu_20 (LeakyReLU)      (None, 128, 128, 64) 0           conv2d_21[0][0]
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 64)   0           leaky_re_lu_20[0][0]
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_4[0][0]
__________________________________________________________________________________________________
leaky_re_lu_21 (LeakyReLU)      (None, 64, 64, 128)  0           conv2d_22[0][0]
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 64, 64, 128)  147584      leaky_re_lu_21[0][0]
__________________________________________________________________________________________________
leaky_re_lu_22 (LeakyReLU)      (None, 64, 64, 128)  0           conv2d_23[0][0]
__________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 128)  0           leaky_re_lu_22[0][0]
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_5[0][0]
__________________________________________________________________________________________________
leaky_re_lu_23 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_24[0][0]
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 32, 32, 256)  590080      leaky_re_lu_23[0][0]
__________________________________________________________________________________________________
leaky_re_lu_24 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_25[0][0]
__________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 256)  0           leaky_re_lu_24[0][0]
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_6[0][0]
__________________________________________________________________________________________________
leaky_re_lu_25 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_26[0][0]
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_25[0][0]
__________________________________________________________________________________________________
leaky_re_lu_26 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_27[0][0]
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 16, 16, 512)  0           leaky_re_lu_26[0][0]
__________________________________________________________________________________________________
max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 512)    0           dropout_2[0][0]
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 1024)   4719616     max_pooling2d_7[0][0]
__________________________________________________________________________________________________
leaky_re_lu_27 (LeakyReLU)      (None, 8, 8, 1024)   0           conv2d_28[0][0]
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 8, 8, 1024)   9438208     leaky_re_lu_27[0][0]
__________________________________________________________________________________________________
leaky_re_lu_28 (LeakyReLU)      (None, 8, 8, 1024)   0           conv2d_29[0][0]
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 8, 8, 1024)   0           leaky_re_lu_28[0][0]
__________________________________________________________________________________________________
conv2d_transpose_4 (Conv2DTrans (None, 16, 16, 512)  4719104     dropout_3[0][0]
__________________________________________________________________________________________________
zero_padding2d_4 (ZeroPadding2D (None, 16, 16, 512)  0           conv2d_transpose_4[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 16, 16, 1024) 0           dropout_2[0][0]
                                                                 zero_padding2d_4[0][0]
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate_4[0][0]
__________________________________________________________________________________________________
leaky_re_lu_29 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_30[0][0]
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_29[0][0]
__________________________________________________________________________________________________
leaky_re_lu_30 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_31[0][0]
__________________________________________________________________________________________________
conv2d_transpose_5 (Conv2DTrans (None, 32, 32, 256)  1179904     leaky_re_lu_30[0][0]
__________________________________________________________________________________________________
zero_padding2d_5 (ZeroPadding2D (None, 32, 32, 256)  0           conv2d_transpose_5[0][0]
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 32, 32, 512)  0           leaky_re_lu_24[0][0]
                                                                 zero_padding2d_5[0][0]
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_5[0][0]
__________________________________________________________________________________________________
leaky_re_lu_31 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_32[0][0]
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 32, 32, 256)  590080      leaky_re_lu_31[0][0]
__________________________________________________________________________________________________
leaky_re_lu_32 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_33[0][0]
__________________________________________________________________________________________________
conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 128)  295040      leaky_re_lu_32[0][0]
__________________________________________________________________________________________________
zero_padding2d_6 (ZeroPadding2D (None, 64, 64, 128)  0           conv2d_transpose_6[0][0]
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 64, 64, 256)  0           leaky_re_lu_22[0][0]
                                                                 zero_padding2d_6[0][0]
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_6[0][0]
__________________________________________________________________________________________________
leaky_re_lu_33 (LeakyReLU)      (None, 64, 64, 128)  0           conv2d_34[0][0]
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 64, 64, 128)  147584      leaky_re_lu_33[0][0]
__________________________________________________________________________________________________
leaky_re_lu_34 (LeakyReLU)      (None, 64, 64, 128)  0           conv2d_35[0][0]
__________________________________________________________________________________________________
conv2d_transpose_7 (Conv2DTrans (None, 128, 128, 64) 73792       leaky_re_lu_34[0][0]
__________________________________________________________________________________________________
zero_padding2d_7 (ZeroPadding2D (None, 128, 128, 64) 0           conv2d_transpose_7[0][0]
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 128, 128 0           leaky_re_lu_20[0][0]
                                                                 zero_padding2d_7[0][0]
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_7[0][0]
__________________________________________________________________________________________________
leaky_re_lu_35 (LeakyReLU)      (None, 128, 128, 64) 0           conv2d_36[0][0]
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 128, 128, 64) 36928       leaky_re_lu_35[0][0]
__________________________________________________________________________________________________
leaky_re_lu_36 (LeakyReLU)      (None, 128, 128, 64) 0           conv2d_37[0][0]
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 128, 128, 2)  1154        leaky_re_lu_36[0][0]
__________________________________________________________________________________________________
leaky_re_lu_37 (LeakyReLU)      (None, 128, 128, 2)  0           conv2d_38[0][0]
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 128, 128, 2)  6           leaky_re_lu_37[0][0]
==================================================================================================
Total params: 34,513,288
Trainable params: 34,513,288
Non-trainable params: 0
__________________________________________________________________________________________________

```
```
>>> model2.summary()
Model: ""model""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(None, 128, 128, 3) 0
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 128, 128, 64) 1792        input_1[0][0]
__________________________________________________________________________________________________
leaky_re_lu (LeakyReLU)         (None, 128, 128, 64) 0           conv2d[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 128, 128, 64) 36928       leaky_re_lu[0][0]
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_1[0][0]
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           leaky_re_lu_1[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d[0][0]
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 128)  0           conv2d_2[0][0]
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 64, 64, 128)  147584      leaky_re_lu_2[0][0]
__________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)       (None, 64, 64, 128)  0           conv2d_3[0][0]
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0           leaky_re_lu_3[0][0]
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_1[0][0]
__________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 256)  0           conv2d_4[0][0]
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 256)  590080      leaky_re_lu_4[0][0]
__________________________________________________________________________________________________
leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 256)  0           conv2d_5[0][0]
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0           leaky_re_lu_5[0][0]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_2[0][0]
__________________________________________________________________________________________________
leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 512)  0           conv2d_6[0][0]
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 16, 16, 512)  2359808     leaky_re_lu_6[0][0]
__________________________________________________________________________________________________
leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 512)  0           conv2d_7[0][0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 16, 16, 512)  0           leaky_re_lu_7[0][0]
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)    0           dropout[0][0]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 8, 8, 1024)   4719616     max_pooling2d_3[0][0]
__________________________________________________________________________________________________
leaky_re_lu_8 (LeakyReLU)       (None, 8, 8, 1024)   0           conv2d_8[0][0]
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 8, 8, 1024)   9438208     leaky_re_lu_8[0][0]
__________________________________________________________________________________________________
leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 1024)   0           conv2d_9[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 8, 8, 1024)   0           leaky_re_lu_9[0][0]
__________________________________________________________________________________________________
conv2d_transpose (Conv2DTranspo (None, 16, 16, 512)  4719104     dropout_1[0][0]
__________________________________________________________________________________________________
zero_padding2d (ZeroPadding2D)  (None, 16, 16, 512)  0           conv2d_transpose[0][0]
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 16, 16, 1024) 0           dropout[0][0]
                                                                 zero_padding2d[0][0]
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate[0][0]
__________________________________________________________________________________________________
leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_10[0][0]
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_10[0][0]
__________________________________________________________________________________________________
leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_11[0][0]
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  1179904     leaky_re_lu_11[0][0]
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 32, 32, 256)  0           conv2d_transpose_1[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           leaky_re_lu_5[0][0]
                                                                 zero_padding2d_1[0][0]
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_1[0][0]
__________________________________________________________________________________________________
leaky_re_lu_12 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_12[0][0]
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 32, 32, 256)  590080      leaky_re_lu_12[0][0]
__________________________________________________________________________________________________
leaky_re_lu_13 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_13[0][0]
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  295040      leaky_re_lu_13[0][0]
__________________________________________________________________________________________________
zero_padding2d_2 (ZeroPadding2D (None, 64, 64, 128)  0           conv2d_transpose_2[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           leaky_re_lu_3[0][0]
                                                                 zero_padding2d_2[0][0]
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_2[0][0]
__________________________________________________________________________________________________
leaky_re_lu_14 (LeakyReLU)      (None, 64, 64, 128)  0           conv2d_14[0][0]
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 64, 64, 128)  147584      leaky_re_lu_14[0][0]
__________________________________________________________________________________________________
leaky_re_lu_15 (LeakyReLU)      (None, 64, 64, 128)  0           conv2d_15[0][0]
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 73792       leaky_re_lu_15[0][0]
__________________________________________________________________________________________________
zero_padding2d_3 (ZeroPadding2D (None, 128, 128, 64) 0           conv2d_transpose_3[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128, 128, 128 0           leaky_re_lu_1[0][0]
                                                                 zero_padding2d_3[0][0]
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_3[0][0]
__________________________________________________________________________________________________
leaky_re_lu_16 (LeakyReLU)      (None, 128, 128, 64) 0           conv2d_16[0][0]
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 128, 128, 64) 36928       leaky_re_lu_16[0][0]
__________________________________________________________________________________________________
leaky_re_lu_17 (LeakyReLU)      (None, 128, 128, 64) 0           conv2d_17[0][0]
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 128, 128, 2)  1154        leaky_re_lu_17[0][0]
__________________________________________________________________________________________________
leaky_re_lu_18 (LeakyReLU)      (None, 128, 128, 2)  0           conv2d_18[0][0]
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 128, 128, 2)  6           leaky_re_lu_18[0][0]
==================================================================================================
Total params: 34,514,440
Trainable params: 34,514,440
Non-trainable params: 0
__________________________________________________________________________________________________
```




"
48641,[TF.Keras]: plotting utilities,"The plot function is defined as follows 

```
tf.keras.utils.plot_model(
    model,
    to_file=""model.png"",
    show_shapes=False,
    show_dtype=False,
    show_layer_names=True,
    rankdir=""TB"",
    expand_nested=False,
    dpi=96,
)
```

Following features would be nice (IMO) to have with it:
- Plot subgroup (e.g. form layer index 5 to 20 or by layer's name) of `model`. For example: if we plot `EfficientNet`, this plot utils will plot the whole model from first to last. But let's say for some reason we manipulate intermediate block from `layer_id: 10` to `layer_id:30` and want to check or visualize."
48640,Tensorflow after 1.15 - No need to install tensorflow-gpu package,"This is basically an info question that was asked by [mon](https://stackoverflow.com/users/4281353/mon) in SO and we answered as far as we know, [here](https://stackoverflow.com/a/67088947/9215780).

In the official `tf` installation guide in documentation, it says, 

> For releases 1.15 and older, CPU and GPU packages are separate:

pip install tensorflow==1.15      # CPU
pip install tensorflow-gpu==1.15  # GPU

And for later version, e.g `tf : > = 2.0`, we simply need to do 

```
pip install tensorflow     # CPU or GPU 
```

But still, we have 

```
!pip install tensorflow-gpu 
....
Installing collected packages: tensorflow-gpu
Successfully installed tensorflow-gpu-2.4.1

# -------------------------------------------------------------

!pip install tensorflow-cpu
....
Installing collected packages: tensorflow-cpu
Successfully installed tensorflow-cpu-2.4.1
```

why `tf-gpu/cpu` for `2.4.1` still exits? what is the main reason here? is there any difference for `tf > = 2` installing them separately or the standalone way? "
48639,Is there any offical way of freezing graph to pb in Tensorflow2,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

To some reason I have to get a pb model. In TF1 I used following code to build a pd file.
```
from tensorflow.python.framework import graph_util
constant_graph = graph_util.convert_variables_to_constants(sess,sess.graph_def,FLAG.output_op)
with tf.gfile.GFile(FLAG.save_path + '\\PBModel.pb',mode='wb') as f:
    f.write(constant_graph.SerializeToString())
```
I tried every thing of savedModel to pb or .h5 to pb but failed. So is there any offical way of freezing graph to pb in Tensorflow2 ?"
48638,delete the eager execution check for shared_embedding_columns_v2,"at the line 901 of tensorflow/tensorflow/python/feature_column/feature_column_v2.py:
we have a eager execution  check:
if context.executing_eagerly():
    raise RuntimeError('shared_embedding_columns are not supported when eager '
                       'execution is enabled.')
but it shouldn't check because it's a tf2.X code and it use eager execution at default
"
48637,TFlite to 8 bit quantized TFLite conversion,"I have a TFLite model with me sans any pb model and it is operating on float32 (all the parameters including weights,biases and activaions).
I need to get the 8 bit integer quantized version of this.
Is there any way in which I can convert TFlite model to 8 bit quantized TFLite model without having pb file of it??"
48636,ERROR: Could not find a version that satisfies the requirement tensorflow for MAC m1 ,"**System information**
-MacBook Air (M1, 2020)
-version 11.2
-python version 3.8.2 
-pip version 21.0.1 



**Describe the problem**

I am trying to install tensorflow by below command 
`pip install tensorflow 
`
and getting below 

error 

**ERROR: Could not find a version that satisfies the requirement tensorflow
ERROR: No matching distribution found for tensorflow**


This is my all attempts log:

```
(venv) alimonkarim@Alimons-MacBook-Air ml % python -V
Python 3.8.2
(venv) alimonkarim@Alimons-MacBook-Air ml % pip -V
pip 21.0.1 from /Users/webnation/ml/venv/lib/python3.8/site-packages/pip (python 3.8)
(venv) alimonkarim@Alimons-MacBook-Air ml % pip install --upgrade pip

Requirement already satisfied: pip in ./venv/lib/python3.8/site-packages (21.0.1)
(venv) alimonkarim@Alimons-MacBook-Air ml % pip install tensorflow
ERROR: Could not find a version that satisfies the requirement tensorflow
ERROR: No matching distribution found for tensorflow
```

  

"
48635,How to call tf.compat.v1 from the C++ API?,"I have a frozen graph that was frozen in TensorFlow v1 from the python API, and I want to load it using TensorFlow v2.4 from the C++ API using something like tf.compat.v1 in python. I can do it in python with this script:
```python
def wrap_frozen_graph(graph_def, inputs, outputs):
  def _imports_graph_def():
    tf.compat.v1.import_graph_def(graph_def, name="""")
  wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])
  import_graph = wrapped_import.graph
  return wrapped_import.prune(
      tf.nest.map_structure(import_graph.as_graph_element, inputs),
      tf.nest.map_structure(import_graph.as_graph_element, outputs))


graph_def = tf.compat.v1.GraphDef()
loaded = graph_def.ParseFromString(open(path,'rb').read())


frozen_func = wrap_frozen_graph(graph_def=graph_def,
                                    inputs=[""x:0""],
                                    outputs=[""Identity:0"", ""Identity_1:0""])
```
But I didn't find any related document to do the same from the C++ API.
"
48632,TF to TFLite conversion clarification,"**What is  the difference between 

converter.target_spec.supported_ops =[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

and 

converter.target_spec.supported_ops =[tf.lite.OpsSet.TFLITE_BUILTINS]

performed during conversion of tf model to tflite model??**



I tried using converter.target_spec.supported_ops in 3 ways : 
1.  using 
converter.target_spec.supported_ops =[tf.lite.OpsSet.TFLITE_BUILTINS]

2. using 
converter.target_spec.supported_ops =[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

3. execeuting code without converter.target_spec.supported_ops

when I was converting pb model to 8 bit quantized tflite model.

All three of them  yielded me the same results in the output tflite model,which were identical in all respects.
**Why is this so?**"
48631,model_main.py,"I trained a model with TensorFlow object detection API (TF1) with model_main script but when the model finish training returns me a export/Servo/save_model.pb, when I run the export_inference_graph.py script returns me the frozen graph but when I run object_detection_runner the model doesn't detect anything, ( but when I trained the model with train.py script it detects everything)

Config:
Model: reste101
TFVersion : TF1
OS : Windows 10

```
# R-FCN with Resnet-101 (v1),  configuration for MSCOCO Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 23
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    second_stage_box_predictor {
      rfcn_box_predictor {
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
        crop_height: 18
        crop_width: 18
        num_spatial_bins_height: 3
        num_spatial_bins_width: 3
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0003
          schedule {
            step: 900000
            learning_rate: .00003
          }
          schedule {
            step: 1200000
            learning_rate: .000003
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint:""rfcn_resnet101_coco_2018_01_28/model.ckpt""
  from_detection_checkpoint: true
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  num_steps: 20000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""data/train.record""
  }
  label_map_path: ""training/labelmap.pbtxt""
}

eval_config: {
  num_examples: 120 #12959
  num_visualizations:20
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  #max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    
    input_path: ""data/test.record""
  }
  label_map_path: ""training/labelmap.pbtxt""
  shuffle: false
  num_readers: 1
}
```"
48630,TPU ops are compiled by default despite of if_libtpu or if_with_tpu_support configurations,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): UBUNTU18
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): SOURCE
- TensorFlow version: TF2.4.1
- Python version:  PY3.6
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source):  3.1
- GCC/Compiler version (if compiling from source): 7.5
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the problem**
TPU ops are compiled by default on any platform other than ``chromiumos`` despite of if_libtpu or if_with_tpu_support configurations

**Provide the exact sequence of commands / steps that you executed before running into the problem**
follow standard build from source procedure
https://www.tensorflow.org/install/source 

**Any other info / logs**

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/BUILD#L575

‘’‘
cc_library(
    name = ""ops"",
    visibility = [""//visibility:public""],
    deps = [
        "":user_ops_op_lib"",
        ""//tensorflow/c/kernels:bitcast_op_lib"",
        ""//tensorflow/c/kernels:histogram_summary_op_lib"",
        ""//tensorflow/c/kernels:merge_summary_op_lib"",
        ""//tensorflow/c/kernels:summary_op_lib"",
        ""//tensorflow/core/ops:ops"",
    ] + if_chromiumos(
        [],
        # Non-tpu platforms don't need tpu dependency.
        [
            ""//tensorflow/core/tpu/ops"",
        ],
    ) + if_tensorrt([
        ""//tensorflow/compiler/tf2tensorrt:trt_engine_resource_ops_op_lib"",
        ""//tensorflow/compiler/tf2tensorrt:trt_op_libs"",
    ]) + if_libtpu(
        if_false = [""//tensorflow/compiler/mlir/tensorflow:mlir_passthrough_op""],
        if_true = [],
    ),
)
’‘’
"
48629,Tesla V100 is slower than GTX 1660 super!?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8
- CUDA/cuDNN version: CUDA 11.0, cuDNN 8.0.4
- GPU model and memory: Tesla V100S-16Q / GTX 1660 super 8G

Recently I'm working on a detection project. The network I'm using is efficientdet-d0. When I'm training my network on company's server, it is slower than training it on my desktop, by 40%~50%. 

For example, with same code (same model, same data, same batch-size, same everything), my desktop (GTX 1660 super 8G) spends average 250ms each step, while on server (virtual machine, Tesla V100S-16Q), it needs average 360ms per step. And eventually, training time becomes hours more after many epochs.

Both task manage and nvidia-smi show that CUDA is working so I'm using GPU training. And my colleagues who use Darknet and Pytorch don't have such issue and they all speed up the training when using Tesla GPU.

Does the tf code need adjustment when using Tesla GPU?



**Standalone code to reproduce the issue**
The efficientdet code is from [bubbliiiing](https://github.com/bubbliiiing/efficientdet-tf2), except that I'm using tf.keras.applications.EfficientNetB0 as backbone.
"
48627,"Change ""Simple Audio Recognition"" to right link","@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**

The link of ""Simple Audio Recognition"" in  tensorflow/lite/micro/examples/micro_speech/train/README.md is not right anymore, it jumps to https://www.tensorflow.org/tutorials/sequences/audio_recognition before, but now is https://www.tensorflow.org/tutorials/audio/simple_audio .

So need to update.

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
48624,tf.ragged.stack doesn't work for multidimensional tensors,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS BigSur
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): installed by pip
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
```
a =tf.constant([[[3,4,5],[3,4,5]],[[3,4,5],[3,4,5]],[[3,4,5],[3,4,5]],[[3,4,5],[3,4,5]]])
b = tf.constant([[[3,3,4,5],[3,3,4,5],[3,3,4,5]],[[3,3,4,5],[3,3,4,5],[3,3,4,5]],[[3,3,4,5],[3,3,4,5],[3,3,4,5]]])
print(a.shape,b.shape)
c = tf.ragged.stack([a,b],axis=0)
```
When I attempt to stack two tensors of same rank. If the rank is $$\ge 2$$, it produces an error saying:
`tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [8,3] vs. shape[1] = [9,4] [Op:ConcatV2] name: concat`

I can workaround this by making a, b both ragged tensors

**Describe the expected behavior**

It should stack them without problem

I traced it into the definition of the tf.ragged.stack function; It appears that the code runs line 180. It seems to assume that I am trying to use normal tf.stack when I have all elements as tensors.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
  File ""/Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py"", line 201, in wrapper
    return target(*args, **kwargs)
  File ""/Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/ragged/ragged_concat_ops.py"", line 120, in stack
    return _ragged_stack_concat_helper(values, axis, stack_values=True)
  File ""/Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/ragged/ragged_concat_ops.py"", line 197, in _ragged_stack_concat_helper
    return _ragged_stack_concat_axis_0(rt_inputs, stack_values)
  File ""/Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/ragged/ragged_concat_ops.py"", line 222, in _ragged_stack_concat_axis_0
    concatenated_flat_values = array_ops.concat(flat_values, axis=0)
  File ""/Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py"", line 201, in wrapper
    return target(*args, **kwargs)
  File ""/Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1677, in concat
    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
  File ""/Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1193, in concat_v2
    _ops.raise_from_not_ok_status(e, name)
  File ""/Users/michaelhyh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 6862, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [8,3] vs. shape[1] = [9,4] [Op:ConcatV2] name: concat
```"
48615,TF/XLA ignores tf.config set_visible_devices API and initializes all GPUs in the system,"This leads to many superfluous memory allocations, possibly leading to OOM.

Reproduction instructions for the duplicate memory allocations when running with XLA on a multiGPU host.
Use https://github.com/horovod/horovod/blob/master/examples/tensorflow2/tensorflow2_mnist.py as test.py
this test uses the “set_visible_devices” TF API

when running with
TF_XLA_FLAGS=""--tf_xla_auto_jit=1 --tf_xla_enable_xla_devices=true""  python3 test.py
memory is allocated on the visible GPU only. This is the expected behavior, observed with TF 2.3

when running with
TF_XLA_FLAGS=""--tf_xla_auto_jit=1 --tf_xla_enable_xla_devices=false""  python3 test.py
memory is allocated on all GPUs in the system. This behavior does not honor the tf.config set_visible_devices API, observed with > TF2.4
 
This issues is similar to the closed horovod issue https://github.com/horovod/horovod/issues/2548.
That issue was closed prematurely, as the presumed fix was not compatible with distributed strategy.
"
48614,Connectionist Temporal Classification with Maximum Entropy Regularization (EnCTC),"**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

There is an extension to CTC (EnCTC) that introduces regularization in order to prevent ""peaky"" and overly confident distributions typical to CTC.

https://papers.nips.cc/paper/2018/file/e44fea3bec53bcea3b7513ccef5857ac-Paper.pdf
Connectionist Temporal Classification with Maximum Entropy Regularization
Hu Liu, Sheng Jin, Changshui Zhang

This approach has been shown to *""consistently improve over the CTC baseline without the need to adjust training settings""* on scene text recognition tasks.

**Will this change the current api? How?**

It would likely extend `tf.nn.ctc_loss` to have an optional regularization argument.

**Who will benefit with this feature?**

Anyone who uses CTC in Recurrent Neural Networks, e.g. in OCR, handwriting recognition or speech recognition

**Any Other info.**
"
48613,Why XLA leads to much more cuMemcpyHtoDAsync calls?,"I did some profiling shows that, for a resnet50 inference task, (V100 batch=64), xla jit will have 5000 more cuMemcpyHtoDAsync calls in average. For some research purpose, I would like to decrease the number of cuMemcpyHtoDAsync calls.

I notice that there is hlo memory scheduler in XLA that might do the same thing as described in Grapper's page: ""Memory optimizer - Analyzes the graph to inspect the peak memory usage for each operation and inserts CPU-GPU memory copy operations for swapping GPU memory to CPU to reduce the peak memory usage."" 

Does hlo memory scheduler minize the peak memory in the same way which leads to more  cuMemcpyHtoDAsync calls? If true, how to disable such optimization?

Would really appreciate any ideas on this.

"
48612,"@tf.function triggers ""AttributeError: 'Tensor' object has no attribute 'ndim'""","TensorFlow version: `v2.4.0-49-g85c8b2a817f 2.4.1`

**Minimal Example**
```python
import tensorflow as tf

@tf.function
def f(a):
    return a.ndim

x = tf.zeros((3, 4))
f(x)
```

**Describe the current behavior**
```python
AttributeError: 'Tensor' object has no attribute 'ndim'
```

**Describe the expected behavior**
```python
<tf.Tensor: shape=(), dtype=int32, numpy=2>
```

**This actually works**
```python
import tensorflow as tf

@tf.function
def f(a):
    return len(a.shape)

x = tf.zeros((3, 4))
f(x)
```

This problem occured in https://github.com/jonasrauber/eagerpy/issues/36
"
48611,"E tensorflow/core/grappler/clusters/utils.cc:87] Failed to get device properties, error code: 3","### System information
-   **OS Platform and Distribution (e.g., Linux Ubuntu 18.04)**:
-   **TensorFlow installed from (source or binary)**:source
-   **TensorFlow version (use command below)**:1.15.4
-   **Keras version()**:2.3.1
-   **Python version**:3.6.3
-   **GCC/Compiler version (if compiling from source)**:7.5
-   **CUDA/cuDNN version**:1.11.0 / 8.0.4
-   **GPU model and memory**:RTX3090 24GB


### Describe the problem
the code I run no problem as I use RTX2070 with tensorflow1.13 keras2.2.4 and cuda10.0,but when I transfer my code to the new machine which has RTX3090,I tried to enable the oldest code and model,which lead to error when use `normalization` and **stop at the tf.TF_SessionRun_wrapper()** and can not dive into the deeper code.

- segmentation code traceback(by manual track)
1 
/home/dell/anaconda3/envs/dxjc/lib/python3.6/site-packages/efficientnet/model.py 
line 390 
**x = layers.BatchNormalization(axis=bn_axis, name='stem_bn')(x)**
2 
/home/dell/anaconda3/envs/dxjc/lib/python3.6/site-packages/keras/layers/convolutional.py
line 156
3 
/home/dell/anaconda3/envs/dxjc/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py
line 1858
4
/home/dell/anaconda3/envs/dxjc/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py
line 292
5
/home/dell/anaconda3/envs/dxjc/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py
line 278
6
/home/dell/anaconda3/envs/dxjc/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py
line 198
7
/home/dell/anaconda3/envs/dxjc/lib/python3.6/site-packages/tensorflow_core/python/client/session.py
line 955
line 1091
line 1318
line 1441 
**return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
                                            fetch_list, target_list,
                                            run_metadata)**

- detection traceback(by manual track)
1
/home/dell/anaconda3/envs/dx/lib/python3.6/site-packages/keras_applications/mobilenet_v2.py
**x = layers.BatchNormalization(axis=channel_axis,epsilon=1e-3,momentum=0.999,name='bn_Conv1')(x)**
2
/home/dell/anaconda3/envs/dx/lib/python3.6/site-packages/keras/engine/base_layer.py
line 451
3
/home/dell/anaconda3/envs/dx/lib/python3.6/site-packages/keras/layers/normalization.py 
line 183
normed_training, mean, variance = K.normalize_batch_in_training(
            inputs, self.gamma, self.beta, reduction_axes,
            epsilon=self.epsilon)
4
/home/dell/anaconda3/envs/dx/lib/python3.6/site-packages/keras/layers/normalization.py 
line 296
_LOCAL_DEVICES = get_session().list_devices()
line 503
5
/home/dell/anaconda3/envs/dx/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py
line 903
6
/home/dell/anaconda3/envs/dxjc/lib/python3.6/site-packages/tensorflow_core/python/client/session.py
line 955
line 1091
line 1318
line 1441 
**return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
                                            fetch_list, target_list,
                                            run_metadata)**

### Source code / logs
```python
E tensorflow/core/grappler/clusters/utils.cc:87] Failed to get device properties, error code: 3
```"
48609,Bug in ragged version of tf.losses.SparseCategoricalCrossentropy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Debian Buster**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **v1.12.1-55105-ga7116dd3913 2.6.0-dev20210418**
- Python version: **3.7.10**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

The ragged version of `tf.losses.SparseCategoricalCrossentropy()` fails when the inner shape (the number of classes in the prediction) is not ragged (which is the default if the predictions are generated by a Dense layer).

In other words, while the following works,
```python
y_true = tf.ragged.constant([[0, 1], [2]])
y_pred = tf.ragged.constant([[[.9, .05, .05], [.5, .89, .6]], [[.05, .01, .94]]], dtype=tf.float32)
print(y_true.shape, y_pred.shape)
>>> (2, None) (2, None, None)
print(tf.losses.SparseCategoricalCrossentropy()(y_true, y_pred))
```
the following code fails:
```python
y_true = tf.ragged.constant([[0, 1], [2]])
y_pred = tf.ragged.constant([[[.9, .05, .05], [.5, .89, .6]], [[.05, .01, .94]]], ragged_rank=1, dtype=tf.float32)
print(y_true.shape, y_pred.shape)
>>> (2, None) (2, None, 3)
print(tf.losses.SparseCategoricalCrossentropy()(y_true, y_pred))
```

**Describe the expected behavior**

The computation should not crash.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1k8POHBqlHn4Q5_7GUuaINdmX4F-u3Ktb?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to

Adding @pedro-r-marques who wrote the code."
48608,Keras plot_model: AttributeError: 'ResourceVariable' object has no attribute '_keras_history',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1

The following things probably don't matter:
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- Python version: 3.8.5
- CUDA/cuDNN version: 11.2/8.1
- GPU model and memory: RTX3070, 8GB

**Describe the current behavior**
Error: `AttributeError: 'ResourceVariable' object has no attribute '_keras_history'`

**Describe the expected behavior**
Plot is saved to 'model.png'

**Standalone code to reproduce the issue**
Copy into colab or standalone file:
```python
import tensorflow as tf
from tensorflow.keras import Model, Input
from tensorflow.keras.layers import Add


class MyModel(Model):
    def __init__(self):
        super(MyModel, self).__init__()

        self.bias = self.add_weight(shape=(10, 64, 64, 256))
        self.add = Add()

    def call(self, x):
        return self.add([x, self.bias])


if __name__ == '__main__':
    mm = MyModel()

    x = Input(shape=(64, 64, 256), batch_size=10, name='Input')
    m = Model(inputs=[x], outputs=mm.call(x))
    tf.keras.utils.plot_model(m)

```

**Other info / logs** 
```
Traceback (most recent call last):
  File ""test.py"", line 22, in <module>
    tf.keras.utils.plot_model(m)
  File ""/home/benjs/Documents/projects/hpe/venv/lib/python3.8/site-packages/tensorflow/python/keras/utils/vis_utils.py"", line 322, in plot_model
    dot = model_to_dot(
  File ""/home/benjs/Documents/projects/hpe/venv/lib/python3.8/site-packages/tensorflow/python/keras/utils/vis_utils.py"", line 235, in model_to_dot
    for inbound_layer in nest.flatten(node.inbound_layers):
  File ""/home/benjs/Documents/projects/hpe/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/node.py"", line 258, in inbound_layers
    inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,
  File ""/home/benjs/Documents/projects/hpe/venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py"", line 867, in map_structure
    structure[0], [func(*x) for x in entries],
  File ""/home/benjs/Documents/projects/hpe/venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py"", line 867, in <listcomp>
    structure[0], [func(*x) for x in entries],
  File ""/home/benjs/Documents/projects/hpe/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/node.py"", line 258, in <lambda>
    inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,
AttributeError: 'ResourceVariable' object has no attribute '_keras_history'
```
"
48607,Old makefile target in person dection example README,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Debian Linux
- TensorFlow installed from source
- Tensorflow version  7e55a20
- Target platform: host

**Describe the problem**

The README documentation for the ""Run the tests on a development machine"" of the [person_detection example README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection/README.md#run-the-tests-on-a-development-machine) specifies a wrong make target. This PR shows the incorrect target and what it ought to be corrected to: #48594

**Please provide the exact sequence of commands/steps when you ran into the problem**

I was attempting to follow the instructions at [tensorflow/lite/micro/examples/person_detection/README.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection/README.md#run-the-tests-on-a-development-machine) for running person detection test on a development machine.

The second step is:

```
make -f tensorflow/lite/micro/tools/make/Makefile test_person_detection_test
```

This fails with the message

```
make: *** No rule to make target 'test_person_detection_test'.  Stop.
```
"
48606,Enhance GreedyMemoryPlanner::PrintMemoryPlan() format,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: all
- TensorFlow installed from source
- Tensorflow version: All
- Target platform: All

**Describe the problem**

While using the output of `GreedyMemoryPlanner::PrintMemoryPlan()` to better understand model memory use, I found myself tweaking the output to provide information in a more readily understandable way.

I have a PR that collects these changes: #48595 As noted there, the changes are:

Per-buffer info line improvements:

(a) Reduces text quantity to make it easier to scan for information.
(b) Moves size to near front line, to make it simpler for the eye to
find this information.
(c) Includes ordinal letter used in per-time display below to make it
simpler to cross-reference.

Per time improvements:

(a) Includes tick number. This is useful in larger models for cross
referencing to the per-buffer information and also for helping to
determine the actual operation being executed at that time.
(b) Includes total memory use of buffers, which helps to more clearly
identify memory bottlenecks.

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
48605,Make GreedyMemoryPlanner::PrintMemoryPlan accessible ,"@tensorflow/micro

**System information**
- All distributions
- Source
- All version to date
- Any platform with UART output

**Describe the problem**

[GreedyMemoryPlanner::PrintMemoryPlan()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/memory_planner/greedy_memory_planner.h#L84) prints information about head memory allocation to the console. It has proven quite useful for comparing memory usage by different model archtectures and understanding how to reduce memory use.

While asking questions about memory use, I was advised to add a call to GreedyMemoryPlanner() to [MicroAllocator::CommitPlan()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/micro_allocator.cc#L345) this worked, but required casting the `MemoryPlanner *` to a `GreedyMemoryPlanner *`. We can avoid this cast by moving the call to PrintMemoryPlanner() up the call stack to [MicroAllocator::CommitStaticPlan](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/micro_allocator.cc#L1080). 

Since not all users will benefit from seeing the memory plan, and since it is reasonable to use the user to make this choice at compile time, I suggest adding a new preprocessor define that will, when present, cause the memory plan to be printed.

There is a sample PR at #48596 

My immediate motivation for this issue is to be allow the memory plan to be printed (when requested) for users of the https://github.com/google/CFU-Playground, and I am working on a non-open source project that would also benefit.

**Please provide the exact sequence of commands/steps when you ran into the problem**

nil.

"
48604,Support for OV7675 camera module,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): not applicable (using the Arduino_TensorFlowLite installed from the Arduino IDE)
- Tensorflow version (commit SHA if source): Arduino_TensorFlowLite. 2.4.0-ALPHA
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arduino Nano 33 BLE Sense

The image provider source file for the person detection example under TFLite Micro, extends support only for the ArduCam camera module OV2640. 

Can the support be extended to camera module OV7675, since the TinyML starter kit contains this camera module?

Meanwhile, I made the following updates to hopefully get it up and running, but without any success:

File: Arduino\libraries\ArduCAM\memorysaver.h
Updates: 
1. Uncomment #define ARDUCAM_SHIELD_V2
2. Uncomment #define OV7675_CAM

File: Arduino\libraries\Arduino_TensorFlowLite\examples\person_detection\arduino_image_provider.cpp
Updates:
1. LOC 54: Replace OV2640_MINI_2MP_PLUS with OV7675_CAM
2. LOC 65: Replace OV2640 with OV7675

Upon uploading the compiled software to the microcontroller, the camera initialization fails with the following error:
Can't communicate with Arducam

I assume the registers are different for the OV7675 as compared to OV2640 and the arduino_image_provider.cpp needs to be updated with the correct register information.

Could you please provide me a solution to this issue?

Thank you.

"
48603,Unsupported data type 13 in tensor,"Hi everyone,
 I recently converted my custom object detection model from TensorFlow '1.15.0' to TensorFlow lite so I can implement it on a raspberry PI 3 model B. But, when I tried to test it I got this error 'Unsupported data type 13 in tensor'. 
 Can anyone help me understand this error?
ps:   I am using the latest TF Lite runtime version 2.5"
48602,Atrous/Dilated Convolutions cannot dynamically Compute Shape on TPU,"**System information**
- Colab Pro TPU Environment
- TF 2.4.1
- TPU v2-8

**Describe the current behavior**
tf.keras.layers.Conv2D(filters = 32, kernel_size=3, strides = 1, use_bias = False, dilation_rate = 2) does not compile on TPU. 

Building a custom layer using tf.nn.atrous_conv2d results in the same error. 

**Describe the expected behavior**
tf.nn.atrous_conv2d is a supported op based on this [list](https://cloud.google.com/tpu/docs/tensorflow-ops) of supported ops. 

**Standalone code to reproduce the issue**
Below notebook builds minimal model and trains on mnist. Works when dilation rate is not used for the conv2d. Otherwise generates the error. 

[colab notebook](https://colab.research.google.com/drive/1Hl5IZ9rnK6g58j0MSC3rGqTwrsXkrfHN?usp=sharing)

**Error code from Notebook**
```
InvalidArgumentError: 9 root error(s) found.
  (0) Invalid argument: {{function_node __inference_train_function_16413}} Compilation failure: Reshape's input dynamic dimension is decomposed into multiple output dynamic dimensions, but the constraint is ambiguous and XLA can't infer the output dimension %reshape.107 = f32[2,2,32,12,12,32]{5,4,3,2,1,0} reshape(f32[<=128,12,12,32]{3,2,1,0} %convolution.106), metadata={op_type=""BatchToSpaceND"" op_name=""sequential_5/conv2d_10/Conv2D/BatchToSpaceND""}. 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_7203248111506234482/_5}}]]
	 [[TPUReplicate/_compile/_757783574996934175/_4/_300]]
  (1) Invalid argument: {{function_node __inference_train_function_16413}} Compilation failure: Reshape's input dynamic dimension is decomposed into multiple output dynamic dimensions, but the constraint is ambiguous and XLA can't infer the output dimension %reshape.107 = f32[2,2,32,12,12,32]{5,4,3,2,1,0} reshape(f32[<=128,12,12,32]{3,2,1,0} %convolution.106), metadata={op_type=""BatchToSpaceND"" op_name=""sequential_5/conv2d_10/Conv2D/BatchToSpaceND""}. 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_7203248111506234482/_5}}]]
	 [[TPUReplicate/_compile/_757783574996934175/_4/_336]]
  (2) Invalid argument: {{function_node __inference_train_function_16413}} Compilation failure: Reshape's input dynamic dimension is decomposed into multiple output dynamic dimensions, but the constraint is ambiguous and XLA can't infer the output dimension %reshape.107 = f32[2,2,32,12,12,32]{5,4,3,2,1,0} reshape(f32[<=128,12,12,32]{3,2,1,0} %convolution.106), metadata={op_type=""BatchToSpaceND"" op_name=""sequential_5/conv2d_10/Conv2D/BatchToSpaceND""}. 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_7203248111506234482/_5}}]]
	 [[tpu_compile_succeeded_assert/_7203248111506234482/_5/_279]]
  (3) Invalid argument: {{function_node __inference_train_function_16413}} Compilation failure: Reshape's input dynamic dimension is decomposed into multiple output dynamic dimensions, but the constraint is ambiguous and XLA can't infer the output dimension %reshape.107 = f32[2,2,32,12,12,32]{5,4,3,2,1,0} reshape(f32[<=128,12,12,32]{3,2,1,0} %convolution.106), metadata={op_type=""BatchToSpaceND"" op_name=""sequential_5/conv2d_10/Conv2D/BatchToSpaceND""}. 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_7203248111506234482/_5}}]]
	 [[tpu_compile_succeeded_assert/_7203248111506234482/_5/_267]]
  (4) Invalid argument: {{function_node __inference_train_function_16413}} Compilation failure: Reshape's input dynamic dimension is decomposed into multiple output dynamic dimensions, but the constraint is ambiguous and XLA can't infer the output dimension %reshape.107 = f32[2,2,32,12,12,32]{5,4,3,2,1,0} reshape(f32[<=128,12,12,32]{3,2,1,0} %convolution.106), metadata={op_type=""BatchToSpaceND"" op_name=""sequential_5/conv2d_10/Conv2D/BatchToSpaceND""}. 
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_7203248111506234482/_5}}]]
	 [[tpu_compile_succeeded_assert/_7203248111506234482/_5/_291]]
  (5) ... [truncated]
```"
48600,NameError: name 'wait' is not defined when executing tf.distribute.MirroredStrategy(),"
**System information*
- TensorFlow version : 2.6.0
- Python version: 3.8
- GCC/Compiler version (if compiling from source):
- CUDA version:  11.2

I want to train the model using TensorFlow's MirroredStrategy on several GPUs. I've used `strategy = tf.distribute.MirroredStrategy()` many times before but this time when I executed it, I got an unusually long error and the mechanism became stuck for an extended period of time.

**Traceback (most recent call last)**
`File ""/research/dept8/gds/anafees/anaconda3/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
    self.run()
  File ""/research/dept8/gds/anafees/anaconda3/lib/python3.8/threading.py"", line 870, in run
    self._target(*self._args, **self._kwargs)
  File ""/research/dept8/gds/anafees/anaconda3/lib/python3.8/multiprocessing/pool.py"", line 519, in _handle_workers
    cls._wait_for_updates(current_sentinels, change_notifier)
  File ""/research/dept8/gds/anafees/anaconda3/lib/python3.8/multiprocessing/pool.py"", line 499, in _wait_for_updates
    wait(sentinels, timeout=timeout)
NameError: name 'wait' is not defined`
Note: It works flawlessly on a single GPU but causes the above problem on two GPUs."
48599,"Resnet50 pretrained model for fine tuning, the model is not convergence","Hi,

I'm using pretrained Resnet50 model for my own data's training.  The model is not convergence even the train accuracy looks good shown by the log, and validation loss and accuracy is not improved during the training phase.

I also test the trained model on training and val set, the accuracy is very pool(see below) 

And I try the tensorflow 1.15.0 and 2.4.0 different version, the problem is the same. Then I just change to VGG model, it works fine(no convergence problem). So could help on this issue?

My code is :
`   

    base_model = tf.keras.applications.ResNet50(include_top=False)
    base_model.trainable = False

    model = tf.keras.models.Sequential([
        base_model,
        #tf.keras.layers.Conv2D(filters=num_cat, kernel_size=1),
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dense(units=num_cat)
    ])
    model.summary()
    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)
    loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
    eval_func = tf.keras.metrics.CategoricalAccuracy()

    model.compile(
        optimizer=optimizer,
        loss=loss_func,
        metrics=[eval_func]
    )
    history = model.fit(train_ds, epochs=10, validation_data=val_ds)
    model.save_weights('./checkpoints/final')`

And the training log is:

>
Train on 156 steps, validate on 39 steps
Epoch 1/10
156/156 [==============================] - 183s 1s/step - loss: 1.8214 - categorical_accuracy: 0.5048 - val_loss: 3.5411 - val_categorical_accuracy: 0.0386
Epoch 2/10
156/156 [==============================] - 33s 211ms/step - loss: 0.4409 - categorical_accuracy: 0.8931 - val_loss: 3.6663 - val_categorical_accuracy: 0.0386
Epoch 3/10
156/156 [==============================] - 34s 219ms/step - loss: 0.2582 - categorical_accuracy: 0.9365 - val_loss: 3.8821 - val_categorical_accuracy: 0.0386
Epoch 4/10
156/156 [==============================] - 32s 203ms/step - loss: 0.1666 - categorical_accuracy: 0.9550 - val_loss: 3.9013 - val_categorical_accuracy: 0.0386
Epoch 5/10
156/156 [==============================] - 31s 201ms/step - loss: 0.1212 - categorical_accuracy: 0.9630 - val_loss: 4.2440 - val_categorical_accuracy: 0.0386
Epoch 6/10
156/156 [==============================] - 31s 201ms/step - loss: 0.0826 - categorical_accuracy: 0.9759 - val_loss: 4.2431 - val_categorical_accuracy: 0.0386
Epoch 7/10
156/156 [==============================] - 31s 198ms/step - loss: 0.0648 - categorical_accuracy: 0.9807 - val_loss: 4.3009 - val_categorical_accuracy: 0.0514
Epoch 8/10
156/156 [==============================] - 32s 205ms/step - loss: 0.0573 - categorical_accuracy: 0.9823 - val_loss: 4.3420 - val_categorical_accuracy: 0.0386
Epoch 9/10
156/156 [==============================] - 31s 196ms/step - loss: 0.0548 - categorical_accuracy: 0.9839 - val_loss: 4.4843 - val_categorical_accuracy: 0.0386
Epoch 10/10
156/156 [==============================] - 31s 200ms/step - loss: 0.0478 - categorical_accuracy: 0.9887 - val_loss: 4.7390 - val_categorical_accuracy: 0.0386

Run inference on training data and validation data:
156/156 [==============================] - 35s 227ms/step - loss: 4.7357 - categorical_accuracy: 0.0386
39/39 [==============================] - 11s 279ms/step - loss: 4.7326 - categorical_accuracy: 0.0386
Train Loss: 4.735676199961931; Train Acc: 0.03858520835638046
Val Loss: 4.732603843395527; Val Acc: 0.03858520835638046

"
