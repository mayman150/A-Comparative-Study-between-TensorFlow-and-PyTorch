Issue Number,Issue Title,Issue Body
42518,Python crashes when running inference (interpreter.invoke()) on BERT (official.nlp.bert) converted saved model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `YES`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Windows 10`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `NO`
- TensorFlow installed from (source or binary): `binary`
- TensorFlow version (use command below): `2.4.0-dev20200819`
- Python version: `Python 3.7.6`
- CUDA/cuDNN version: 
- GPU model and memory: `Quadro P2000 computeCapability: 6.1, 4Gb`

**Describe the current behavior**
Basically I'm trying to quantize a BERT model (with a classifier head) using the [dynamic range post training quantization technique](https://www.tensorflow.org/lite/performance/post_training_quant) in order to improve serving speed.
This is how I proceeded:
- I use the BERT code of [google official](https://github.com/tensorflow/models/tree/master/official/nlp/bert): I executed [this](https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb#scrollTo=y_ACvKPsVUXC)  notebook to obtain a BERT Classifier model in the `Saved Model` format. It's easy to obtain just run all cells and save the model, I can also link mine if need be.
- I am able to convert the model to a TFlite model (and serialize it to a FlatBuffer) (I get this log which kind of sounds like things are doing ok for the conversion part...: 
```INFO: TfLiteFlexDelegate delegate: 96 nodes delegated out of 620 nodes with 60 partitions.```

and then when trying out the inference (following the [basic TFLite inference tutorial in Python](https://www.tensorflow.org/lite/guide/inference) my program just crashes


**Describe the expected behavior**
I would like to be able to serve a TFLite model converted from a BERT Classifier of `official.nlp.bert` to be able to execute inference :D 

**Standalone code to reproduce the issue**
These are the few lines that I try to run but just can't seem to make work:
```
import numpy as np
import tensorflow as tf

path_saved = ""path\\to\\saved\\model""
converter = tf.lite.TFLiteConverter.from_saved_model(path_saved)
converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS]
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_quant_model = converter.convert()

interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.int32)

interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
```

Also I'm able to save the TFLite model to a FlatBuffer easily, I've tried loading it in a different process but I get the same crash.


**Other info / logs**

This is the full log I obtain:

```
2020-08-20 16:51:03.475275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-20 16:51:05.781037: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-20 16:51:05.782856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-08-20 16:51:06.621258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.468GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s
2020-08-20 16:51:06.621417: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-20 16:51:06.626743: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-20 16:51:06.630233: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-20 16:51:06.631445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-20 16:51:06.635791: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-20 16:51:06.637905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-20 16:51:06.646389: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-20 16:51:06.647139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-20 16:51:06.647268: I tensorflow/compiler/jit/xla_gpu_device.cc:69] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-20 16:51:06.647593: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-20 16:51:06.648170: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-20 16:51:06.649130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.468GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s
2020-08-20 16:51:06.649270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-20 16:51:06.649361: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-20 16:51:06.649436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-20 16:51:06.649597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-20 16:51:06.649683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-20 16:51:06.649799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-20 16:51:06.649901: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-20 16:51:06.650420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-20 16:51:07.326160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-20 16:51:07.326260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-08-20 16:51:07.327667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-08-20 16:51:07.328315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2984 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-08-20 16:51:07.329077: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-20 16:51:13.831685: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:315] Ignored output_format.
2020-08-20 16:51:13.831813: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:318] Ignored drop_control_dependency.
2020-08-20 16:51:13.835168: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: C:\tensorflow\models-master\saved_model
2020-08-20 16:51:13.884559: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
2020-08-20 16:51:13.885104: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: C:\tensorflow\models-master\saved_model
2020-08-20 16:51:13.886647: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-20 16:51:13.886780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-20 16:51:13.886911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]
2020-08-20 16:51:13.887017: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-20 16:51:14.027709: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:198] None of the MLIR optimization passes are enabled (registered 0 passes)
2020-08-20 16:51:14.046369: I tensorflow/cc/saved_model/loader.cc:190] Restoring SavedModel bundle.
2020-08-20 16:51:14.692613: I tensorflow/cc/saved_model/loader.cc:174] Running initialization op on SavedModel bundle at path: C:\tensorflow\models-master\saved_model
2020-08-20 16:51:14.805651: I tensorflow/cc/saved_model/loader.cc:261] SavedModel load for tags { serve }; Status: success: OK. Took 970481 microseconds.
2020-08-20 16:51:15.612211: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-20 16:51:15.612614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.468GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s
2020-08-20 16:51:15.614030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-20 16:51:15.614146: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-20 16:51:15.614256: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-20 16:51:15.614370: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-20 16:51:15.614484: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-20 16:51:15.614595: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-20 16:51:15.614705: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-20 16:51:15.615136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-20 16:51:15.615291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-20 16:51:15.615398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-08-20 16:51:15.615500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-08-20 16:51:15.615944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2984 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-08-20 16:51:15.616086: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
INFO: Created TensorFlow Lite delegate for select TF ops.
2020-08-20 16:51:20.577713: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-20 16:51:20.578074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.468GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s
2020-08-20 16:51:20.578209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-20 16:51:20.578327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-20 16:51:20.578447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-20 16:51:20.578568: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-20 16:51:20.578695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-20 16:51:20.578818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-20 16:51:20.578939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-20 16:51:20.579359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-20 16:51:20.579508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-20 16:51:20.579604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-08-20 16:51:20.579694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-08-20 16:51:20.580139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2984 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-08-20 16:51:20.580258: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
INFO: TfLiteFlexDelegate delegate: 96 nodes delegated out of 620 nodes with 60 partitions.

2020-08-20 16:51:20.586343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll

```

PS1: if that can help, when running it with PyCharm I get a weird exit code: `Process finished with exit code -1073741819 (0xC0000005)`

PS2: I've also linked the end of the logs when I activate CPP logging (with `TF_CPP_MIN_VLOG_LEVEL=2`) if that can help...

[logs_cpp.txt](https://github.com/tensorflow/tensorflow/files/5103844/logs_cpp.txt)

I guess my next step will be to try to run inference in CPP directly
"
42517,"Lite: Hello world, Sparkfun Edge","@tensorflow/micro

**System information**
- Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): git clone https://github.com/tensorflow/tensorflow.git
- Tensorflow version (commit SHA if source): commit 6787ce30efdfefbf69681ca9795959fb7244240b
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Sparkfun Edge

**Describe the problem**
Hello world example: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world

**Please provide the exact sequence of commands/steps when you ran into the problem**
$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge hello_world_bin
tensorflow/lite/micro/tools/make/Makefile:303: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/ruy'
tensorflow/lite/micro/tools/make/Makefile:303: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/ruy'
tensorflow/lite/micro/tools/make/Makefile:303: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'
tensorflow/lite/micro/tools/make/Makefile:303: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'
tensorflow/lite/micro/tools/make/Makefile:303: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'
tensorflow/lite/micro/tools/make/Makefile:303: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'
tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/arm-none-eabi-g++ -std=c++11 -Wstrict-aliasing -DTF_LITE_STATIC_MEMORY -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -DNDEBUG -O3 -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DNDEBUG -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-missing-field-initializers -Wno-strict-aliasing -Wno-type-limits -Wno-unused-function -Wno-unused-parameter -fno-delete-null-pointer-checks -fno-threadsafe-statics -fomit-frame-pointer -fno-use-cxa-atexit -nostdlib -ggdb -O3 -I. -Itensorflow/lite/micro/tools/make/downloads/ -Itensorflow/lite/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include -Itensorflow/lite/micro/tools/make/downloads/ruy -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/boards_sfe/common/third_party/hm01b0 -isystemtensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/mcu/apollo3/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/mcu/apollo3/regs -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/mcu/apollo3/hal -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/boards_sfe/edge/bsp -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/devices/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/utils/  -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/boards_sfe/common/third_party/lis2dh12/ -Itensorflow/lite/micro/tools/make/downloads/kissfft -c tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc -o tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.o
tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc: In function 'void HandleOutput(tflite::ErrorReporter*, float, float)':
tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:58:17: error: implicit conversion from 'float' to 'double' to match other operand of binary expression [-Werror=double-promotion]
     if (y_value <= -0.75) {
         ~~~~~~~~^~~~~~~~
tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:71:17: error: implicit conversion from 'float' to 'double' to match other operand of binary expression [-Werror=double-promotion]
     if (y_value >= 0.75) {
         ~~~~~~~~^~~~~~~
In file included from ./tensorflow/lite/micro/micro_error_reporter.h:20:0,
                 from ./tensorflow/lite/micro/examples/hello_world/output_handler.h:20,
                 from tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:16:
./tensorflow/lite/core/api/error_reporter.h:53:70: error: implicit conversion from 'float' to 'double' when passing argument to function [-Werror=double-promotion]
     static_cast<tflite::ErrorReporter*>(reporter)->Report(__VA_ARGS__); \
                                                                      ^
tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:78:3: note: in expansion of macro 'TF_LITE_REPORT_ERROR'
   TF_LITE_REPORT_ERROR(error_reporter, ""x_value: %f, y_value: %f\n"", x_value,
   ^~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/core/api/error_reporter.h:53:70: error: implicit conversion from 'float' to 'double' when passing argument to function [-Werror=double-promotion]
     static_cast<tflite::ErrorReporter*>(reporter)->Report(__VA_ARGS__); \
                                                                      ^
tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:78:3: note: in expansion of macro 'TF_LITE_REPORT_ERROR'
   TF_LITE_REPORT_ERROR(error_reporter, ""x_value: %f, y_value: %f\n"", x_value,
   ^~~~~~~~~~~~~~~~~~~~
cc1plus: all warnings being treated as errors
make: *** [tensorflow/lite/micro/tools/make/Makefile:315: tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.o] Error 1

"
42515,"LSTM don't work with RuntimeError: Attempting to capture an EagerTensor without building a function, but GRU work","*System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Mac OS 10.14.4 ):
- tensorflow-2.1.0 
-Keras 2.3.1
- Python 3.6 :,


**Describe the current behavior**
LSTM occur error:""raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.""
However, If I change LSTM to GRU(as shown in comment code), it work! 

**Standalone code to reproduce the issue**
from Logger import log
from keras.models import Model
from keras.layers import LSTM, Dense, Conv1D, Flatten, Reshape,Lambda, dot, Activation, concatenate, Bidirectional, GRU
from keras.utils import print_summary, plot_model
import numpy as np
import keras.backend as K
import os
import tensorflow as tf

import tensorflow.compat.v1 as tf
tf.disable_eager_execution()
   F = 16
    K = 4
    H = 512
    #window_length = L = 1536
    reshape = Reshape((window_length, 1),
                      )(input_tensor)
    cnn1 = Conv1D(F, K, activation=""linear"", strides=1)(reshape)
    cnn2 = Conv1D(F, K, activation=""linear"", strides=1)(cnn1)
    # Bi-directional LSTM
    # lstm1 = Bidirectional(GRU(H, activation='tanh',return_sequences=True), merge_mode='concat')(cnn2)
    lstm1 = Bidirectional(LSTM(H, return_sequences=True))(cnn2)
    attention1 = attention_3d_block(lstm1)
    dense1 = Dense(window_length*F, use_bias=False, activation='relu')(attention1)
    dense2 = Dense(window_length*F, use_bias=False, activation='relu')(dense1)
    r = Reshape((window_length*F, 1))(dense2)
    cnn3 = Conv1D(F, K, activation=""linear"", strides=1)(r)
    cnn4 = Conv1D(1, K, activation=""linear"", strides=1)(cnn3)
    # x = Reshape((window_length,), input_shape=(window_length, 1))(cnn4)
    flat = Flatten(name='flatten')(cnn4)
    d_out = Dense(window_length)(flat)
    model = Model(inputs=input_tensor, outputs=d_out)

**Other info / logs** 
2020-08-20 22:15:03,052 [INFO ]  Parameters: 
2020-08-20 22:15:03,053 [INFO ]  Machine name: Ziyues-MacBook-Pro.local
Using TensorFlow backend.
2020-08-20 22:15:05,618 [WARNI]  From /Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2020-08-20 22:15:05,669 [DEBUG]  CACHEDIR=/Users/Ziyue/.matplotlib
2020-08-20 22:15:05,673 [DEBUG]  Using fontManager instance from /Users/Ziyue/.matplotlib/fontlist-v310.json
2020-08-20 22:15:05,799 [DEBUG]  Loaded backend module://backend_interagg version unknown.
2020-08-20 22:15:05,802 [INFO ]  Arguments: 
2020-08-20 22:15:05,802 [INFO ]  Namespace(appliance_name='washingmachine', batchsize=128, cnn='kettle', crop_dataset=None, datadir='./dataset_management/redd/', dense_layers=1, gpus=-1, n_epoch=2, pretrainedmodel_dir='./pretrained_model', ram=500000, save_dir='./trained_model_s2swA', save_model=-1, transfer_cnn=False, transfer_model=False)
2020-08-20 22:15:05.803552: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-20 22:15:05.817249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2a6b92740 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-20 22:15:05.817263: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-20 22:15:05,817 [INFO ]  Training dataset: ./dataset_management/redd/washingmachine/washingmachine_training_.csv
2020-08-20 22:15:05,817 [INFO ]  washingmachine_validation_.csv
2020-08-20 22:15:05,817 [INFO ]  Validation dataset: ./dataset_management/redd/washingmachine/washingmachine_validation_.csv
2020-08-20 22:15:05,838 [WARNI]  From /Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Traceback (most recent call last):
  File ""/Users/Ziyue/Desktop/BitcnNILM-master/s2swA_train.py"", line 189, in <module>
    pretrainedmodel_dir=args.pretrainedmodel_dir)
  File ""/Users/Ziyue/Desktop/BitcnNILM-master/s2swA_Model.py"", line 70, in get_model
    lstm1 = Bidirectional(LSTM(512, return_sequences=True, stateful=True))(cnn2)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/layers/wrappers.py"", line 437, in __call__
    return super(Bidirectional, self).__call__(inputs, **kwargs)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 75, in symbolic_fn_wrapper
    return func(*args, **kwargs)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 463, in __call__
    self.build(unpack_singleton(input_shapes))
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/layers/wrappers.py"", line 581, in build
    self.forward_layer.build(input_shape)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 502, in build
    self.cell.build(step_input_shape)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 1942, in build
    constraint=self.bias_constraint)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 282, in add_weight
    constraint=constraint)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 620, in variable
    value, dtype=dtype, name=name, constraint=constraint)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 814, in variable
    constraint=constraint)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 260, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 254, in _variable_v2_call
    shape=shape)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 235, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py"", line 2645, in default_variable_creator_v2
    shape=shape)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 262, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1411, in __init__
    distribute_strategy=distribute_strategy)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1543, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1280, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.
"
42514,How to get the MKL version linked with Tensorflow,"**System information**
- OS Platform and Distribution : Windows 10
- TensorFlow installed from: Both binary and source
- TensorFlow version: 2.1.0
- Python version: 3.7.0
- Installed using virtualenv? pip? conda?: pip and conda
- Bazel version (if compiling from source): 0.29.1


**Describe the problem**
I am able to check whether mkl is installed or not, but how to get the mkl version installed with tensorflow? I see some performance difference across tensorflow versions so want to know mkl versions supported. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
conda create -n ""TFMKL"" tensorflow-mkl python==3.7


"
42513,Discrepancy between available operation semantics documentation and documentation of `tf2xla.python.xla.conv`,"## URL(s) with the issue:

https://www.tensorflow.org/xla/operation_semantics#conv_convolution

https://github.com/tensorflow/tensorflow/blob/5f2e159a58d1ef3414b2c34339266449574d8f94/tensorflow/compiler/tf2xla/python/xla.py#L239:L269

## Description of issue (what needs changing):

### Clear description

 [tf2xla.python.xla.conv](https://github.com/tensorflow/tensorflow/blob/5f2e159a58d1ef3414b2c34339266449574d8f94/tensorflow/compiler/tf2xla/python/xla.py#L239:L269) points to the operation semantics for `ConvWithGeneralPadding` but actually wraps the more general `ConvGeneralDilated`. It would make sense to actually have documentation about the operation semantics of this more general operation.
"
42512,tensorflow.keras Conv2D layers complain if the input is a sparse Input layer.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
TensorFlow installed from (source or binary): conda installed from source
TensorFlow version (use command below): 2.1.0
Python version: 3.7
CUDA/cuDNN version: CUDA 10.1
GPU model and memory: Quadro M1200. 8GB RAM

**Describe the current behavior**
See code below. 

model = create_model_sparse()
Traceback (most recent call last):

  File ""<ipython-input-78-9c562e12ef50>"", line 1, in <module>
    model = create_model_sparse()

  File ""C:\Users\Floor\Documents\Basic model\Model1.py"", line 59, in create_model_sparse
    C1 = Conv2D(32, (6, 6),activation='relu')(input_img)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 748, in __call__
    self._maybe_build(inputs)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 2116, in _maybe_build
    self.build(input_shapes)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\keras\layers\convolutional.py"", line 148, in build
    input_channel = self._get_input_channel(input_shape)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\keras\layers\convolutional.py"", line 295, in _get_input_channel
    raise ValueError('The channel dimension of the inputs '

ValueError: The channel dimension of the inputs should be defined. Found `None`.


**Describe the expected behavior**
I expect the model to compile. 

**Standalone code to reproduce the issue**
def create_model_sparse(img_width=108, imgh_height=71, dim=10):
    input_img = Input(shape=(img_width, imgh_height, dim), dtype = 'float32', sparse = True)

    C1 = Conv2D(32, (6, 6),activation='relu')(input_img)
    M1 = MaxPooling2D(pool_size=(2,2))(C1)
    
    C2 = Conv2D(32, (6, 6),activation='relu')(M1)
    M2 = MaxPooling2D(pool_size=(2,2))(C2)
    
    C3 = Conv2D(32, (6, 6),activation='relu')(M2)
    M3 = MaxPooling2D(pool_size=(2,2))(C3)

    F = Flatten()(M3)
    D1 = Dense(256, activation='relu')(F)
    D2 = Dense(1, activation = ""sigmoid"")(D1)
    model = Model(x,D2)
    
    model.compile(optimizer=Adam(lr=0.0005), loss='mean_squared_error')
    return(model) 

"
42511,Native crash when using GpuDelegate() on Android 11,"We found out that issue is reproducing on Android 11, and works fine for Android 10 and less.
However this is our current crash rate distribution, maybe it can vary when we will get more data.

**System information**
- OS Platform and Distribution: Android 11: 100%
- Mobile device: Google Pixel 4 XL (34.35%), Google Pixel 3 (17.54%), Google Pixel 3 XL (14.84%), Google Pixel 3a (11.0%), Other devices (22.27%)
- TensorFlowLite installed from binary
- TensorFlowLite version:
""org.tensorflow:tensorflow-lite:0.0.0-nightly""
""org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly""

**Describe the current behavior**
Crash happens when we are trying to access `org.tensorflow.lite.gpu.GpuDelegate()` constructor.

**Describe the expected behavior**
No crash

**Other info / logs**
```
java.lang.Runtime.loadLibrary0(Runtime.java:1067)
java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file ""/data/app/com.bumble.app-8irvW4hQxSV1mR3fxr2zRQ==/base.apk"", zip file ""/data/app/com.bumble.app-8irvW4hQxSV1mR3fxr2zRQ==/split_config.en.apk"", zip file ""/data/app/com.bumble.app-8irvW4hQxSV1mR3fxr2zRQ==/split_config.xxhdpi.apk""],nativeLibraryDirectories=[/data/app/com.bumble.app-8irvW4hQxSV1mR3fxr2zRQ==/lib/arm64, /system/lib64, /system/product/lib64]]] couldn't find ""libtensorflowlite_gpu_jni.so""
```

```
java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""log2"" referenced by ""/data/app/~~_HPfJLFw-mGTIuaom9KTxg==/com.bumble.app-_q0StbZdkqA1sVAJw4oWDQ==/lib/arm64/libtensorflowlite_gpu_jni.so""...
  at java.lang.Runtime.loadLibrary0(Runtime.java:1087)
  at java.lang.Runtime.loadLibrary0(Runtime.java:1008)
  at java.lang.System.loadLibrary(System.java:1664)
  at org.tensorflow.lite.gpu.GpuDelegate.<clinit>(:165)
```"
42510,Cannot confine TensorFlow C API to use not more than 1 threads in total,"<em>TensorFlow C API is generating at least one thread on each of the available CPUs. The available instructions/guidlines do not take effect to confine TensorFlow C API to only one CPU. I have 8 CPUs and want TensorFlow C API to use only 1, thus generating one and only one thread. How can I confine TensorFlow to use only one CPU (and only one thread) out of available CPUs?</em>
Processor (lscpu command on Ubuntu):
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    2
Core(s) per socket:    4
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 142
Model name:            Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz
Stepping:              10
CPU MHz:               1122.143
CPU max MHz:           3400.0000
CPU min MHz:           400.0000
BogoMIPS:              3600.00
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              6144K
NUMA node0 CPU(s):     0-7
The following code can reduce the number of threads to 1 per core and the top command cou

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7.6.1810
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): https://www.tensorflow.org/install/lang_c
- TensorFlow version (use command below): TensorFlow C API 1.15.0
- Python version:3.6
- Bazel version (if compiling from source):No
- GCC/Compiler version (if compiling from source):4.8.5 20150623 (Red Hat 4.8.5-39) (GCC)
- CUDA/cuDNN version:NO
- GPU model and memory:No

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
TensorFlow C API is generating multiple threads, at least one thread on each of the available CPUs. 

**Describe the expected behavior**
One and only one thread for tensorflow, no matter how many cpus, cores or sockets.

**Standalone code to reproduce the issue**
Graph = TF_NewGraph();
Status = TF_NewStatus();
SessionOpts = TF_NewSessionOptions();  
  
  // limit number of threads  
  uint8_t intra_op_parallelism_threads = 1;
  uint8_t inter_op_parallelism_threads = 1;
  uint8_t device_count = 1;  
  uint8_t config[15] = {0xa, 0x7, 0xa, 0x3, 0x43, 0x50, 0x55, 0x10, device_count, 0x10, intra_op_parallelism_threads, 0x28, intra_op_parallelism_threads,0x40, 0x1};
  TF_SetConfig(SessionOpts, (void*)config, 13, Status);

  if (TF_GetCode(Status)!= TF_OK)
    std::cout << ""\nERROR: "" << TF_Message(Status);
  RunOpts = NULL;

  // load model
  Session = TF_LoadSessionFromSavedModel(SessionOpts, RunOpts, saved_model_dir, &tags, ntags, Graph, NULL, Status);
  if( TF_GetCode(Status) != TF_OK ) {
    std::cout << ""\nERROR: Failed to load SavedModel."" << TF_Message(Status);
    return -1;  }
  assert( TF_GetCode(Status) == TF_OK);

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42507,changes,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Oneplus 5, Oppo F11 Pro
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 10.1
- GPU model and memory: RTX 2060 6 GB

**Describe the current behavior**

I have created a Super Resolution model using tf 1.13.1 and used the tflite benchmark tool to benchmark the timing on my android device. The timing which I'm getting is around 31-35ms by using the command ``` adb shell taskset f0 /data/local/tmp/benchmark_model \
  --graph=/data/local/tmp/main.tflite \
  --enable_op_profiling=true --num_threads=4 ``` 

**Here is the output from the benchmark tool -** 
"
42506,tf.keras.applications.EfficientNetB- not running as expected,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow version (use command below): v2.3.0-0-gb36436b087 2.3.0

**Describe the current behavior**

[tf.keras.applications.EfficientNetB-](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0) not behaving like other tf.keras.applications modules.

In seems any of the EfficientNet modules I try to use don't function as expected as when using other modules such as [ResNet50V2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50V2) (using the same code/data setups).

Unless this is stated somewhere, I'm not sure what I'm getting wrong.

I've tried the TF Hub versions of EfficientNetB- and as feature extractors and they seem to be working fine.

**Describe the expected behavior**

EfficientNetB- modules should function like other modules in tf.keras.applications.

**Standalone code to reproduce the issue**
Running Colab notebook: https://colab.research.google.com/drive/1m3U3wREqWLCKqLhh5Gzuy_mdq5mk6h_r?usp=sharing

**Other info / logs** 

ResNetV250 output:
```Epoch 1/10
24/24 [==============================] - 17s 701ms/step - loss: 2.2448 - accuracy: 0.2240 - val_loss: 2.0786 - val_accuracy: 0.4660
Epoch 2/10
24/24 [==============================] - 16s 674ms/step - loss: 1.9990 - accuracy: 0.5800 - val_loss: 1.8562 - val_accuracy: 0.6896
Epoch 3/10
24/24 [==============================] - 16s 665ms/step - loss: 1.8456 - accuracy: 0.7000 - val_loss: 1.7827 - val_accuracy: 0.7476
Epoch 4/10
24/24 [==============================] - 16s 672ms/step - loss: 1.7713 - accuracy: 0.7667 - val_loss: 1.7561 - val_accuracy: 0.7608
Epoch 5/10
24/24 [==============================] - 16s 664ms/step - loss: 1.7313 - accuracy: 0.8053 - val_loss: 1.7457 - val_accuracy: 0.7616
Epoch 6/10
24/24 [==============================] - 16s 667ms/step - loss: 1.7049 - accuracy: 0.8187 - val_loss: 1.7340 - val_accuracy: 0.7712
Epoch 7/10
24/24 [==============================] - 16s 668ms/step - loss: 1.6779 - accuracy: 0.8347 - val_loss: 1.7246 - val_accuracy: 0.7824
Epoch 8/10
24/24 [==============================] - 16s 667ms/step - loss: 1.6577 - accuracy: 0.8520 - val_loss: 1.7222 - val_accuracy: 0.7760
Epoch 9/10
24/24 [==============================] - 16s 665ms/step - loss: 1.6476 - accuracy: 0.8747 - val_loss: 1.7189 - val_accuracy: 0.7772
Epoch 10/10
24/24 [==============================] - 16s 661ms/step - loss: 1.6372 - accuracy: 0.8853 - val_loss: 1.7163 - val_accuracy: 0.7764
```


EfficientNetB0 output (using same code and data as above, except for EfficientNetB0 not ResNet50V2):
```
Epoch 1/10
24/24 [==============================] - 18s 735ms/step - loss: 2.3056 - accuracy: 0.0787 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 2/10
24/24 [==============================] - 16s 654ms/step - loss: 2.3048 - accuracy: 0.0827 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 3/10
24/24 [==============================] - 16s 654ms/step - loss: 2.3048 - accuracy: 0.0907 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 4/10
24/24 [==============================] - 15s 639ms/step - loss: 2.3051 - accuracy: 0.0867 - val_loss: 2.3027 - val_accuracy: 0.1000
Epoch 5/10
24/24 [==============================] - 15s 631ms/step - loss: 2.3052 - accuracy: 0.0773 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 6/10
24/24 [==============================] - 15s 632ms/step - loss: 2.3052 - accuracy: 0.0800 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 7/10
24/24 [==============================] - 15s 634ms/step - loss: 2.3059 - accuracy: 0.1040 - val_loss: 2.3027 - val_accuracy: 0.1000
Epoch 8/10
24/24 [==============================] - 15s 623ms/step - loss: 2.3055 - accuracy: 0.0907 - val_loss: 2.3027 - val_accuracy: 0.1000
Epoch 9/10
24/24 [==============================] - 15s 631ms/step - loss: 2.3037 - accuracy: 0.0947 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 10/10
24/24 [==============================] - 15s 621ms/step - loss: 2.3044 - accuracy: 0.0907 - val_loss: 2.3026 - val_accuracy: 0.1000
```
"
42505,Custom Constraint not working,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
If I use custom constraint as `kernel_constraint` when I create a model:

    model = keras.Sequential([keras.layers.Dense(y.shape[1], activation='softplus',
                                                 kernel_constraint=SumConstraint(axis=0),
                                                 # kernel_constraint=keras.constraints.MinMaxNorm(),
                                                 bias_constraint=keras.constraints.MinMaxNorm(min_value=-100,
                                                                                              max_value=100),
                                                 input_shape=[x.shape[1]])])

I always got this `ValueError: Unknown constraint: SumConstraint`.

Even if I use the same class as @ymodak showed or use the example in document https://keras.io/api/layers/constraints/.

refer to: https://github.com/tensorflow/tensorflow/issues/39009
**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42504,Duplicated target in TFLite Makefile ?,"**Describe the current behavior**
It seems that there is a duplicated target in `lite/tools/make/Makeflie`

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/make/Makefile#L318-L320

```makefile
# For normal manually-created TensorFlow Lite C++ source files.
$(OBJDIR)%.o: %.cpp
	@mkdir -p $(dir $@)
	$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@

$(OBJDIR)%.o: %.cc
	@mkdir -p $(dir $@)
	$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@

# For normal manually-created TensorFlow Lite C source files.
$(OBJDIR)%.o: %.c
	@mkdir -p $(dir $@)
	$(CC) $(CFLAGS) $(INCLUDES) -c $< -o $@
$(OBJDIR)%.o: %.cpp  # Is this proper target?
	@mkdir -p $(dir $@)
	$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@
```

**Describe the expected behavior**

```makefile
# For normal manually-created TensorFlow Lite C++ source files.
$(OBJDIR)%.o: %.cpp
	@mkdir -p $(dir $@)
	$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@

$(OBJDIR)%.o: %.cc
	@mkdir -p $(dir $@)
	$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@

# For normal manually-created TensorFlow Lite C source files.
$(OBJDIR)%.o: %.c
	@mkdir -p $(dir $@)
	$(CC) $(CFLAGS) $(INCLUDES) -c $< -o $@
#$(OBJDIR)%.o: %.cpp
#	@mkdir -p $(dir $@)
#	$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@
```
"
42807,cannot load the datasets,"when i run: 
import tensorflow_datasets as tfds
mnist_train = tfds.load(name=""mnist"", split=""train"")
wrong occured like this:
2020-08-20 09:52:45.879679: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"".
2020-08-20 09:53:46.902189: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396edb1ff0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.038829 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)
2020-08-20 09:54:48.722926: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396eeb1ef0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.070107 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)
2020-08-20 09:55:50.452114: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396edee160 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.039491 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)
2020-08-20 09:56:57.020900: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396efbecd0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 5.08334 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)
2020-08-20 09:57:59.414296: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396f20f780 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.039584 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)
i want to know how can i solve it , thank you"
42502,Missing momentum in documentation of ResourceApplyCenteredRMSProp,"The issue is for this page: https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/resource-apply-centered-r-m-s-prop

`momentum` is missing from the list of arguments.

Current doc has this:

```
scope: A Scope object
var: Should be from a Variable().
mg: Should be from a Variable().
ms: Should be from a Variable().
mom: Should be from a Variable().
lr: Scaling factor. Must be a scalar.
rho: Decay rate. Must be a scalar.
epsilon: Ridge term. Must be a scalar.
grad: The gradient.
```

This should be instead like this (momentum added after rho):

```
scope: A Scope object
var: Should be from a Variable().
mg: Should be from a Variable().
ms: Should be from a Variable().
mom: Should be from a Variable().
lr: Scaling factor. Must be a scalar.
rho: Decay rate. Must be a scalar.
momentum: momentum scale. Must be a scalar.
epsilon: Ridge term. Must be a scalar.
grad: The gradient.
```

### Clear description
This could be due to a bug in the scripts that auto-generate the api-def.

This is the op registration from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/training_ops.cc#L1056-L1069 

```
REGISTER_OP(""ResourceApplyCenteredRMSProp"")
    .Input(""var: resource"")
    .Input(""mg: resource"")
    .Input(""ms: resource"")
    .Input(""mom: resource"")
    .Input(""lr: T"")
    .Input(""rho: T"")
    .Input(""momentum: T"")
    .Input(""epsilon: T"")
    .Input(""grad: T"")
    .Attr(""T: numbertype"")
    .Attr(""use_locking: bool = false"")
    .SetShapeFn(
        ApplyCenteredRMSPropShapeFn</*is_sparse=*/false, /*is_resource=*/true>);
```
"
42500,tf.dynamic_partition causes crash when using multiple GPUs via tf.distribute.MirroredStrategy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04.2**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.3.0**
- Python version: **3.6.9**
- Bazel version (if compiling from source): **N/A**
- GCC/Compiler version (if compiling from source): **N/A**
- CUDA/cuDNN version: **CUDA 10.1 / cuDNN 7.6.1**
- GPU model and memory: **RTX 2080 8GB**

**Describe the current behavior**

The `tf.dynamic_partition` operation crashes when running on multiple GPUs using `tf.distribute.MirroredStrategy`.

**Describe the expected behavior**

The same code, also using `tf.distribute.MirroredStrategy` runs succesfully when limited to a single GPU by setting `CUDA_VISIBLE_DEVICES=0`.

**Standalone code to reproduce the issue**

    import tensorflow as tf

    N = 100
    M = 4

    distribute_strategy = tf.distribute.MirroredStrategy()

    def op():
      data = tf.random.uniform((N,))
      partitions = tf.random.uniform((N,), maxval=M, dtype=tf.int32)
      return tf.dynamic_partition(data, partitions, M)

    distribute_strategy.run(op)

**Other info / logs**

Full output of the above code:

```
2020-08-19 12:05:36.898086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-19 12:05:37.828508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-08-19 12:05:37.900555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:09:00.0 name: GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.83GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s
2020-08-19 12:05:37.901044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
pciBusID: 0000:42:00.0 name: GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.83GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s
2020-08-19 12:05:37.901070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-19 12:05:37.902404: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-19 12:05:37.903988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-19 12:05:37.904184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-19 12:05:37.905511: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-19 12:05:37.906204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-19 12:05:37.908753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-19 12:05:37.910997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
2020-08-19 12:05:37.911427: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-19 12:05:37.938447: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2994045000 Hz
2020-08-19 12:05:37.941540: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49ac240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-19 12:05:37.941596: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-19 12:05:42.073849: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a182c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-19 12:05:42.073925: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5
2020-08-19 12:05:42.073967: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080, Compute Capability 7.5
2020-08-19 12:05:42.075578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:09:00.0 name: GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.83GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s
2020-08-19 12:05:42.076318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
pciBusID: 0000:42:00.0 name: GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.83GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s
2020-08-19 12:05:42.076367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-19 12:05:42.076406: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-19 12:05:42.076433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-19 12:05:42.076457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-19 12:05:42.076478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-19 12:05:42.076499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-19 12:05:42.076524: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-19 12:05:42.079838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
2020-08-19 12:05:42.079887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-19 12:05:42.939356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-19 12:05:42.939406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
2020-08-19 12:05:42.939413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
2020-08-19 12:05:42.939417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
2020-08-19 12:05:42.941258: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-08-19 12:05:42.941298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7252 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:09:00.0, compute capability: 7.5)
2020-08-19 12:05:42.942216: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-08-19 12:05:42.942237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 2566 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080, pci bus id: 0000:42:00.0, compute capability: 7.5)
WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.
2020-08-19 12:05:42.972712: F tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc:108] Non-OK-status: GpuLaunchKernel(GatherOpKernel<T, int32, true>, config.block_count, config.thread_per_block, 0, d.stream(), params, indices, out, gather_dim_size, indices_size, slice_size, out_size) status: Internal: invalid resource handle
Aborted (core dumped)
```

"
42499,multi-dimensional array frequency count TF API  ,"**System information** 

     OS Platform and Distribution : macOS Catalina 10.15.3

    TensorFlow installed from : binary

    TensorFlow version : 1.15.0

    Python version: 3.7.3

**Describe the current behavior**

We have a tensor 

input = `tf.Tensor([[1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6],
 [1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6]], shape=(2, 29), dtype=int64)`

output = `tf.Tensor([[0,2,1, ... 0. 0. 0.][0, 2, 1, ... 0, 0, 0]], shape=(2, 10000), dtype=float32)`

Here 10000 is the dictionary size. 

**Describe the expected behavior**

We want vector output such that for each index it tell the frequency of each element 
ie in 
`[1296  266  504  190   44   60   13    2  337 6742 2667   14    1  119
   580  338  785  739  855  200   37    1    3    4    5    6]` ie we see 0 occurs 0 times , 1 occurs 2 times and so on .

Currently what we are getting is `tf.Tensor([[0. 4. 2. ... 0. 0. 0.]], shape=(1, 10000), dtype=float32)` we want of shape (2,10000)


Please tell us the right TF API transformation to do this . We tried code in https://github.com/tensorflow/tensorflow/issues/42374 but with no luck. 
"
42498,ConnectionResetByPeer using MultiWorkerMirroredStrategy with Native Keras BERT Model,"**Describe the current behavior**

I am trying to use the following script to run multi-worker distributed training on a Google Kubernetes Engine (GKE) cluster. The script completes and uploads the trained model when there is only one worker. However, it fails with a connection reset by peer error after some arbitrary number of steps when I use multiple nodes.

**Standalone code to reproduce the issue**

Training script: https://gist.github.com/Eric-Le-Ge/21fe4df4c8e361c60d20a683b08aa743
Original example: https://github.com/tensorflow/tfx/tree/master/tfx/examples/bert/cola

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Container-Optimized OS (cos) (default)
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.9
- Docker Image: tensorflow/tensorflow:latest-gpu
- GPU model and memory: NVIDIA K80

**Other info / logs** 
Pod execution logs:
https://gist.github.com/Eric-Le-Ge/693640219f54cb6350e2ea1cc4d97547
"
42495,error while importing tensorflow,"ImportError                               Traceback (most recent call last)
~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     63   try:
---> 64     from tensorflow.python._pywrap_tensorflow_internal import *
     65   # This try catch logic is because there is no bazel equivalent for py_extension.

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-64156d691fe5> in <module>
----> 1 import tensorflow as tf

~\anaconda3\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\anaconda3\lib\site-packages\tensorflow\python\__init__.py in <module>
     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top
     39 
---> 40 from tensorflow.python.eager import context
     41 
     42 # pylint: enable=wildcard-import

~\anaconda3\lib\site-packages\tensorflow\python\eager\context.py in <module>
     33 from tensorflow.core.protobuf import config_pb2
     34 from tensorflow.core.protobuf import rewriter_config_pb2
---> 35 from tensorflow.python import pywrap_tfe
     36 from tensorflow.python import tf2
     37 from tensorflow.python.client import pywrap_tf_session

~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tfe.py in <module>
     26 
     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import
---> 28 from tensorflow.python import pywrap_tensorflow
     29 from tensorflow.python._pywrap_tfe import *

~\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     81 for some common reasons and solutions.  Include the entire stack trace
     82 above this error message when asking for help."""""" % traceback.format_exc()
---> 83   raise ImportError(msg)
     84 
     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\sooraj rawat\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime."
42493,TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType',"batch_size = 32
patch_size = 48
sess = tf.Session(config=config)
input_low = tf.placeholder(tf.float32, [None, None, None, 3], name='input_low')
input_high = tf.placeholder(tf.float32, [None, None, None, 3], name='input_high')
out_image = network(input_low)
def network(input):
......
conv_transition_01 = slim.conv2d(concat01,32,[3,3], rate=1, activation_fn=lrelu)#b,h,w,32
conv_transition_01 = NonLocalBlock(conv_transition_01, subsample=True)
.........
def NonLocalBlock(input, subsample=True):
""""""
@Non-local Neural Networks
Non-local Block
""""""
_, height, width, channel = input.get_shape().as_list()     # (B, H, W, C)

theta = tf.layers.conv2d(input, channel // 2, 1)    # (B, H, W, C // 2)
theta = tf.reshape(theta, [-1, height*width, channel // 2])  # (B, H*W, C // 2)
..................
But there is such a problem
File ""train.py"", line 25, in 
out_image = network(input_low)
File ""D:\DeepLearningCode\hjc\memnet.py"", line 45, in network
conv_transition_01 = NonLocalBlock(conv_transition_01, subsample=True)
File ""D:\DeepLearningCode\hjc\NonLocalblock.py"", line 115, in NonLocalBlock
theta = tf.reshape(theta, [-1, heightwidth, channel // 2]) # (B, HW, C // 2)
TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'
I don't know where is the problem."
42492,Missing headers when using the C++ library,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.3
- Python version: 3.6
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): clang 6.0.0

**Describe the problem**

I'm having a hard time using the C++ library of TensorFlow. First, is there an official documentation about how to compile it? I couldn't find anything on the official TensorFlow website. I used to use the `contrib/cmake` folder but it was removed. I only manage to compile the C++ library by gathering information here and there and following issues, but it's really hard to tell what is the correct procedure.

Anyway, I did manage to compile it using bazel (see below), but then when I try to compile my C++ program, I run into a missing file problem:

```sh
In file included from /home/simon/programs/third_party/tensorflow/tensorflow/cc/client/client_session.h:24:
In file included from /home/simon/programs/third_party/tensorflow/tensorflow/cc/framework/ops.h:21:
In file included from /home/simon/programs/third_party/tensorflow/tensorflow/core/framework/tensor.h:23:
/home/simon/programs/third_party/tensorflow/tensorflow/core/framework/allocator.h:24:10: fatal error: 'absl/strings/string_view.h' file not found
#include ""absl/strings/string_view.h""
```

I found some issues on the tracker, but all of them seem to concern TensorFlow 1.x. It's not clear to me why this file is not included (and if it should be?). Anyway, I downloaded _absl_ by hand and included the files on my project. Now I run on this other missing file error:

```sh
In file included from /home/simon/programs/third_party/tensorflow/tensorflow/cc/client/client_session.h:24:
In file included from /home/simon/programs/third_party/tensorflow/tensorflow/cc/framework/ops.h:21:
In file included from /home/simon/programs/third_party/tensorflow/tensorflow/core/framework/tensor.h:24:
/home/simon/programs/third_party/tensorflow/tensorflow/core/framework/tensor_shape.h:22:10: fatal error: 'tensorflow/core/framework/types.pb.h' file not found
#include ""tensorflow/core/framework/types.pb.h""
```

From what I found in the issues, this is a file that is supposed to be generated by bazel.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I used `./configure` with all default options, and I don't have Cuda/GPU support.

Then I tried:

```sh
bazel build -j 4 -c opt --verbose_failures //tensorflow:libtensorflow_cc.so
```

and also:

```sh
bazel build -j 4 -c opt --verbose_failures  //tensorflow:tensorflow_cc
```

but both give me the same error when using the library after compilation.

"
42491,TFLite - enable XNNPACK with dynamic shapes of tensors,"**System information**
- TensorFlow version (you are using): 2.3.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
In 2.3.0, dynamic shapes  were fixed in TFLite (""TFLite now properly supports dynamic shapes during conversion and inference.""). We can now process tensors with varying batch size, everything works, great. 

However, running on Windows 10 64b, the processing is slower than base TF2. Using TFLite with XNNPACK and fixed batch size 1, the processing is about 2x faster than with base TF2. So the final difference is about 3x in latency. My request is to enable XNNPACK Delegate to process dynamic shaped tensors to enjoy fast processing with variable batch size.

**Will this change the current api? How?**
No.

**Who will benefit with this feature?**
Anyone wishing to process batches of images of various size.

**Any Other info.**
"
42490,Minimum requirement for Tensorflow Lite,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  source
- TensorFlow version: N/A
- Python version: N/A
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

I tried to make an inference program with C/C++ (TF Lite Microcontroller) in ARMv7(32-bit) environment at the very beginning, but the model that I converted includes complex bidirectional LSTM and DNN, and it was hard to use with the C/C++ environment. 
I got errors when my codes load the converted model in C/C++ even though there was no error while conversion.

Before converting the model, I checked that  simple exmaple binary such as hello_world (TF Lite example) is running well on c/c++ with armv7 environment, and the converted model is also running well on python with x86 environment.

I changed my plan into using Python, but my embedded board has no tools like pip, wget, python, and other basic binaries to use. (Thus, now I'm trying to build python for my board.) Additionally, there is only 300 MB that I can use in the board.
I want to know the minimum requirement of Tensorflow Lite for Python and Microcontroller (C/C++).

The board has nxp4330(ARM32) chipset and it has only minimum binaries to run, so I have no idea what I have to do first for using TF Lite with this board. 
Thank you in advance.


**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
42488,Questions about ctc_decode in tensorflow&keras,"https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/ops/ctc_ops.py#L288-L335

About this function: tf.nn.ctc_greedy_decoder
[https://www.tensorflow.org/api_docs/python/tf/nn/ctc_greedy_decoder]

I want to know how this function specifies the Class Index to be used for the BLANK LABEL
Beacuse:  
  # gen_ctc_ops.ctc_loss_v2 differs from gen_ctc_ops.ctc_loss. v2 assumes the blank index to be 0, but v1 views it as the last index.
If it doesn't know which is the BLANK LABEL, how to combine and del BLANK LABEL for the final result?
If it takes the last index as a blank label by default, there is a contradiction with the new version of the API

"
42487,Application crash when using SetNumThreads from tflite::impl::Interpreter,"**The issue**

We handle worker threads with different TFLite sessions in our mobile application and we set mInterpreter->SetNumThreads(0).
In this case, the call of mInterpreter->Invoke() causes an application crash (see the log below) regularly on a 32-bit application version (armeabi-v7a), but works as expected on a 64-bit version.

**System information**
- OS Android 8, 9, 10:
- Mobile device (Samsung Galaxy Notes 9, 10)
- TensorFlow installed from TF2.0 branch:
- TensorFlow version (use command below):
- Python version: 3.7
- Android NDK 19

**Describe the current behavior**
32-bit application crash

**Standalone code to reproduce the issue**

// some init and allocates
mModel = tflite::FlatBufferModel::BuildFromBuffer((const char*)modelInfo.modelData, modelInfo.modelSize);
tflite::InterpreterBuilder(*mModel, mResolver)(&mInterpreter);
mInterpreter->UseNNAPI(false);
mInterpreter->ResizeInputTensor(0, sizes);
mInterpreter->AllocateTensors();
int input = mInterpreter->inputs()[0];
float* inputArr = mInterpreter->typed_tensor<float>(input);

// fill in inputArr 
inputArr[array_iter++] = ...

// crash here
if(mInterpreter == NULL || mInterpreter->Invoke() != kTfLiteOk) {
...
}

**Other info / logs** 

case 1:
#00 pc 00056e28  /system/lib/libc.so (tgkill+12)
 #02 pc 0010e411  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (_ZN14EigenForTFLite15TensorEvaluatorIKNS_19TensorContractionOp
 #03 pc 0010e1a9  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (_ZNK14EigenForTFLite15TensorEvaluatorIKNS_19TensorContractionO
 #04 pc 0010e047  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (_ZN14EigenForTFLite30TensorContractionEvaluatorBaseINS_15Tenso
 #05 pc 0010d78f  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (_ZN14EigenForTFLite8internal14TensorExecutorIKNS_14TensorAssig
 #06 pc 001076d9  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (_ZN14EigenForTFLite12TensorDeviceINS_9TensorMapINS_6TensorIfLi
 #07 pc 001075a1  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (tflite::multithreaded_ops::EigenTensorConvFunctor<float>::oper
 #08 pc 00106669  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (tflite::multithreaded_ops::Conv(EigenForTFLite::ThreadPoolDevi
 #09 pc 00121a5b  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (_ZN6tflite3ops7builtin4conv9EvalFloatILNS2_10KernelTypeE2EEEvP
 #10 pc 0010527f  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (_ZN6tflite3ops7builtin4conv4EvalILNS2_10KernelTypeE2EEE12TfLit
 #11 pc 000e4e25  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (tflite::Subgraph::Invoke()+248)
 #12 pc 000dcc7f  /data/app/com.android.app.notes-wVTuDe5vEFmIodYgMItUjQ==/lib/arm/libTFLite.so (tflite::Interpreter::Invoke()+14)

"
42486,AttributeError: module 'tensorflow' has no attribute 'python',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): 
- TensorFlow version: 2.3.0
- Python version: 3.6.10
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Nvidia 920MX



**AttributeError: module 'tensorflow' has no attribute 'python'**

**I am working on a siamese model with tensorflow keras backend. When i tried to import keras backend, t shows above error.**
`import tensorflow.python.keras.backend as K`
`AttributeError: module 'tensorflow' has no attribute 'python'`

**Any other info / logs**
Followings are some of other packages installed in the conda environment.

- keras                    2.3.1
- pip                       20.2.2
- python                 3.6.10
- tensorflow            2.3.0

"
42485,how to get a tensorflow tf by index?,"```
    object_for_each_prior = tf.constant([1 for i in range(8732)])
    -><tf.Tensor: shape=(8732,), dtype=int32, numpy=array([1, 1, 1, ..., 1, 1, 1], dtype=int32)>
```

Then if I want to get the position 1148,1149<br/>

```
    prior_for_each_object = tf.constant([1148,1149])
    object_for_each_prior[prior_for_each_object]
```

Then I got the following error <br/>

`    TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1148, 1149], dtype=int32)>
`
If I want to get the tensor's number by index how should I approach it?"
42484,non-zero `bias` of `Conv2D` in tflite file,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 1.15.0

All information is in [Colab](https://colab.research.google.com/drive/1yWwmAXHyBjNIivJKwmMMJT5V-37TEgph?usp=sharing)

Question:

Why the `Conv2D` op has non-zero `bias` input while they were setup `use_bias=False`.
"
42483,ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported.,"in tensorflow-gpu1.13.0，
def _phase_shift(I, r):

    bsize, w, h, c = I.get_shape().as_list()

    bsize = tf.shape(I)[0]

    X = tf.reshape(I, (bsize, w, h, r, r))

But there is such a problem
  File ""D:\DeepLearningCode\hjc\model.py"", line 236, in _phase_shift
    X = tf.reshape(I, (bsize, w, h, r, r))
  File ""D:\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 8462, in reshape
    ""Reshape"", tensor=tensor, shape=shape, name=name)
  File ""D:\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 529, in _apply_op_helper
    (input_name, err))
ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported.

I don't know where is the problem"
42482,"Missing masOS Big Sur build, Could not find a version that satisfies the requirement tensorflow","**System information**
- OS Platform and Distribution: masOS Big Sur
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.3.0
- Python version: 3.7/3.8
- Installed using virtualenv? pip? conda?: virtualenv + pip

**Describe the problem**
Could not find a version that satisfies the requirement tensorflow (from versions: none)

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```bash
$ pip install tensorflow
ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow
```

```bash
$ pip install tensorflow==2.3.0
ERROR: Could not find a version that satisfies the requirement tensorflow==2.3.0 (from versions: none)
ERROR: No matching distribution found for tensorflow==2.3.0
```

```bash
$ pip install /Users/brikerman/Downloads/tensorflow-2.3.0-cp38-cp38-macosx_10_11_x86_64.whl
ERROR: tensorflow-2.3.0-cp38-cp38-macosx_10_11_x86_64.whl is not a supported wheel on this platform.
```"
42481,TensorFlow Lite converter emits incorrect mask for StridedSlice when using ellipsis,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): tf-nightly-cpu-2.4.0.dev20200818

**Command used to run the converter or code if you’re using the Python API**
```python
import tensorflow as tf


def main():
    graph = tf.Graph()

    # Create a basic graph with only an overlap_and_add on some random data.
    shape = (1, 1, 1024, 512)
    with graph.as_default():
        _input = tf.random.uniform(shape)
        ola = tf.signal.overlap_and_add(_input, 256, name='output')

    # Try executing that graph in regular TensorFlow.
    with tf.compat.v1.Session(graph=graph) as session:
        print(f""With regular TensorFlow, result is: {session.run(ola)}"")

    # Convert to TFLite (using the V1 interface for simplicity)
    converter = tf.compat.v1.lite.TFLiteConverter(graph.as_graph_def(), [_input], [ola])
    tflite_model = converter.convert()

    # Write the model to disk...
    model_path = f'./{__file__}.tflite'
    with open(model_path, 'wb') as f:
        f.write(tflite_model)

    # ...so that we can load it into an interpreter and see the error!
    interpreter = tf.lite.Interpreter(model_path=model_path)
    interpreter.allocate_tensors()

    # This line should throw (as of tf-nightly-cpu-2.4.0.dev20200818):
    #   RuntimeError: tensorflow/lite/kernels/reshape.cc:66 \
    #   num_input_elements != num_output_elements (0 != 524800) \
    #   Node number 5 (RESHAPE) failed to prepare.
    interpreter.invoke()
    print(""If we got here, the bug did not appear!"")


if __name__ == ""__main__"":
    main()

```

**Failure details**
The provided graph works in regular TensorFlow, and the TensorFlow Lite converter executes with no errors, but the TFLite model fails at runtime with:
```
RuntimeError: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (0 != 524800)Node number 5 (RESHAPE) failed to prepare.
```

A visualization of the resulting graph in Netron shows that the node in question should have an input shape of `(1, 1, 2050, 256)` with no unknown dimensions:
![image](https://user-images.githubusercontent.com/213293/90586031-3519f080-e1a4-11ea-85d0-0539ace7fa7a.png)

"
42480,SetNumThreads makes inference slower!,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Android 9
- Mobile device: Vsmart JOY 3
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.0
- Python version:
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the current behavior**

Inference time when using SetNumThreads (numThreads = 4):

![image](https://user-images.githubusercontent.com/16491585/90585698-a5099480-e1ff-11ea-831e-a1294f910b68.png)

Inference time without SetNumThreads:

![image](https://user-images.githubusercontent.com/16491585/90585816-f74ab580-e1ff-11ea-9490-87cfb3304b44.png)

Currently, I'm using 2 tflite models in our project, the first one runs normally without any performance degradation,

**Describe the expected behavior**

SetNumThreads shouldn't make the inference slower.

**Standalone code to reproduce the issue**

```c++
FaceDetector::FaceDetector(void *modelBuff, int size, int threadNum)
{
    if (size < 1)
        return;

    this->_modelBytes = (char *)malloc(sizeof(char) * size);
    memcpy(this->_modelBytes, modelBuff, sizeof(char) * size);

    // Build the model
    this->_model = tflite::FlatBufferModel::BuildFromBuffer(this->_modelBytes, size);

    // Build the interpreter
    tflite::ops::builtin::BuiltinOpResolver resolver;
    tflite::InterpreterBuilder builder(*this->_model, resolver);
    builder(&this->_interpreter);

    // Allocate tensor buffers.
    this->_interpreter->AllocateTensors();

    // Set threads num
    this->_interpreter->SetNumThreads(threadNum);

    this->_ready = true;
}

FaceDetector::~FaceDetector()
{
    free(this->_modelBytes);
    this->_modelBytes = nullptr;
}

bool FaceDetector::isReady()
{
    return this->_ready;
}

void FaceDetector::detect(void *data, int width, int height, int channel)
{
    // Set input/output tensor ptr
    float* _inputTensor = this->_interpreter->typed_input_tensor<float>(0);
    float* _boxesTensor = this->_interpreter->typed_output_tensor<float>(0);
    float* _scoresTensor = this->_interpreter->typed_output_tensor<float>(1);

    Mat image = Mat(height, width, CV_8UC3, data);
    Mat scaled, fImage;
    resize(image, scaled, Size(128, 128), 0, 0, INTER_AREA); // Scale RGB image to model input size
    float IMAGE_STD = 127.5f, IMAGE_MEAN = 127.5f;
    scaled.convertTo(fImage, CV_32FC3, 1 / IMAGE_STD, -IMAGE_MEAN / IMAGE_STD);

    memcpy(_inputTensor, fImage.data, 128*128*3*sizeof(float));

    this->_interpreter->Invoke();
}
```
"
42479,"Build Failure of version 2.3.0 in macOS, MacPorts #42090","**Describe the current behavior**

Version 2.3.0 fails to build on macOS.

**Describe the expected behavior**

First issue, `Action failed to execute: java.io.IOException: Cannot run program… error=24, Too many open files`:
```
ERROR: /opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py37-tensorflow/work/tensorflow-tensorflow-b36436b/tensorflow/core/common_runtime/BUILD:328:11: C++ compilation of rule '//tensorflow/core/common_runtime:collective_executor_mgr' failed (Exit -1): wrapped_clang failed: error executing command 
  (cd /opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py37-tensorflow/work/e3571a779784f9da03a7824d69817047/execroot/org_tensorflow && \
  exec env - \
    APPLE_SDK_PLATFORM=MacOSX \
    APPLE_SDK_VERSION_OVERRIDE=10.15 \
    PATH=/opt/local/bin:/opt/local/sbin:/bin:/sbin:/usr/bin:/usr/sbin \
    XCODE_VERSION_OVERRIDE=11.6.0.11E708 \
  external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG '-std=c++11' -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/gif -iquote bazel-out/host/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/host/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/host/bin/external/com_google_protobuf -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib -iquote bazel-out/host/bin/external/zlib -iquote external/double_conversion -iquote bazel-out/host/bin/external/double_conversion -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/gif -isystem bazel-out/host/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/host/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/host/bin/external/zlib -isystem external/double_conversion -isystem bazel-out/host/bin/external/double_conversion -MD -MF bazel-out/host/bin/tensorflow/core/common_runtime/_objs/collective_executor_mgr/collective_executor_mgr.d -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' '-frandom-seed=bazel-out/host/bin/tensorflow/core/common_runtime/_objs/collective_executor_mgr/collective_executor_mgr.o' -isysroot __BAZEL_XCODE_SDKROOT__ -F__BAZEL_XCODE_SDKROOT__/System/Library/Frameworks -F__BAZEL_XCODE_DEVELOPER_DIR__/Platforms/MacOSX.platform/Developer/Library/Frameworks '-mmacosx-version-min=10.15' -g0 '-march=x86-64' -g0 '-std=c++14' -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions '-DTENSORFLOW_USE_XLA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/common_runtime/collective_executor_mgr.cc -o bazel-out/host/bin/tensorflow/core/common_runtime/_objs/collective_executor_mgr/collective_executor_mgr.o)
Execution platform: @local_execution_config_platform//:platform. Note: Remote connection/protocol failed with: execution failed
Action failed to execute: java.io.IOException: Cannot run program ""/opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py37-tensorflow/work/install/1eb24b6f9fb447fbef56fd6c7521f126/process-wrapper"" (in directory ""/opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py37-tensorflow/work/e3571a779784f9da03a7824d69817047/execroot/org_tensorflow""): error=24, Too many open files
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

This is with system settings:
```bash
$ ulimit -n
65536
$ launchctl limit maxfiles
	maxfiles    65536          200000   
```

Starting the build again, another issue is encountered, apparently arising from https://github.com/tensorflow/tensorflow/pull/40654.

Second issue, `error: no matching function for call to object of type '(lambda at tensorflow/python/lib/core/bfloat16.cc:637:25)`:
```
:info:build tensorflow/python/lib/core/bfloat16.cc:678:8: error: no matching function for call to object of type '(lambda at tensorflow/python/lib/core/bfloat16.cc:637:25)'
:info:build   if (!register_ufunc(""less_equal"", CompareUFunc<Bfloat16LeFunctor>,
:info:build        ^~~~~~~~~~~~~~
:info:build tensorflow/python/lib/core/bfloat16.cc:637:25: note: candidate function not viable: no overload of 'CompareUFunc' matching 'PyUFuncGenericFunction' (aka 'void (*)(char **, const long *, const long *, void *)') for 2nd argument
:info:build   auto register_ufunc = [&](const char* name, PyUFuncGenericFunction fn,
:info:build                         ^
:info:build tensorflow/python/lib/core/bfloat16.cc:682:8: error: no matching function for call to object of type '(lambda at tensorflow/python/lib/core/bfloat16.cc:637:25)'
:info:build   if (!register_ufunc(""greater_equal"", CompareUFunc<Bfloat16GeFunctor>,
:info:build        ^~~~~~~~~~~~~~
```

macOS 10.15.6 19G73
Xcode 11.6 11E708 

Related:
* https://trac.macports.org/ticket/60960
* https://github.com/macports/macports-ports/pull/7575
* https://github.com/tensorflow/tensorflow/pull/40654

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

MacPorts Portfile:
[Portfile_py-tensorflow-2.3.0.txt](https://github.com/tensorflow/tensorflow/files/5093501/Portfile_py-tensorflow-2.3.0.txt)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

logs using `port -vst build py37-tensorflow-2.3.0`:

[py37-tensorflow-2.3.0_stdout0.log](https://github.com/tensorflow/tensorflow/files/5093661/py37-tensorflow-2.3.0_stdout0.log)
[py37-tensorflow-2.3.0_stdout1.log](https://github.com/tensorflow/tensorflow/files/5093678/py37-tensorflow-2.3.0_stdout1.log)

The full log files are 40MB and too large to attach to GitHub."
42478,Extremely Large Slow Down in Performance Between 21th July & 22nd July Nightly Release,"**System information**
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): Tf-Nightly-GPU
- TensorFlow version (use command below): 2.4.0.dev
- Python version: 3.7
- CUDA/cuDNN version: 10.1 / 7.6
- GPU model and memory: nVidia 2070 Max-Q

It appears some change was made between the nightly release of the 21st and the 22nd July 2020 that has caused a dramatic (over x10) slow down in the time to complete an epoch of training apart of an optimization I am running. Furthermore, I have checked right up to the current date and this slow down still exists. As well as up to TF2.4 (21st July), TF 2.3 release also runs fine.

Unfortunately, for both reasons of IP and that the code is rather involved I can't share it publicly on here. And thus I appreciate trying to resolve this issue is challenging. However, is there anything in particular that was changed over these two dates that stands that out that could potential cause such a large change in time to optimize and  / or anything I could do further to investigate and thus assist with what might have resulted in this issue? 

Between the two release, when running the code, there is no obvious difference in the start-up debug output that is displayed in terms of adding gpu device, successfully opening the cuda libraries, etc."
42476,Incorrect output for unit test example in tensorflow/tensorflow/lite/micro/examples/hello_world/hello_world_test.cc ,"@tensorflow/micro

**System information**
Laptop Model: Inspiron-7370 
OS: Ubuntu 18.04.5 LTS x86_64 
Host: Inspiron 7370 
Kernel: 5.4.0-42-generic 
Uptime: 4 hours, 48 mins 
Packages: 2256 
Shell: bash 4.4.20 
Resolution: 1920x1080, 1920x1080 
DE: GNOME 3.28.4 
WM: GNOME Shell 
WM Theme: Adwaita 
Theme: Ambiance [GTK2/3] 
Icons: Ubuntu-mono-dark [GTK2/3] 
Terminal: gnome-terminal 
CPU: Intel i7-8550U (8) @ 4.000GHz 
RAM: 8GB
GPU: Intel UHD Graphics 620 
Memory: 4790MiB / 7573MiB 

- TensorFlow installed from (source or binary): git clone https://github.com/tensorflow/tensorflow.git
- Tensorflow version (commit SHA if source): 
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Mbed OS board (but this is irrelevant since this test runs locally)

**Describe the problem**
When I make a change in the hello_world_test.cc file such as for example changing a value to something that I know should return an error such as checking:
```C++
input->data.f[0] = 4.f;
  invoke_status = interpreter.Invoke();
  TF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, invoke_status);

  value = output->data.f[0];
  TF_LITE_MICRO_EXPECT_NEAR(-0.959f, value, 0.05f);
```
when I run this test 
```
run make -f tensorflow/lite/micro/tools/make/Makefile test_hello_world_test 
```
I should obtain:
```
Testing LoadModelAndPerformInference
[whatever this value is] near value failed at tensorflow/lite/micro/examples/hello_world/hello_world_test.cc:94
0/1 tests passed
~~~SOME TESTS FAILED~~~
```
Instead, I obtain the following:
```
~~~ALL TESTS PASSED~~~'
tensorflow/lite/micro/examples/hello_world/Makefile.inc:33: recipe for target 'test_hello_world_test' failed
make: *** [test_hello_world_test] Error 1
```
>In other words, the ""tensorflow/lite/micro/testing/micro_test.h"" framework incorrectly asserts if tests have passed and prints ""ALL TESTS PASSED"" when some tests have in fact failed. Also, it doesn't specify which tests failed (or the line in hello_world_test.cc). As seen in the error message this is probably a problem with the Makefile.

**Please provide the exact sequence of commands/steps when you ran into the problem**

```
me$ git clone https://github.com/tensorflow/tensorflow.git
me$ ls 
/tensorflow
me$ cd tensorflow/tensorflow/lite/micro/examples/hello_world/
me$ nano hello_world_test.cc 
```

**Changed the test comparison values at the bottom to make them fail on purpose i.e**
```C++
input->data.f[0] = 4.f; // this was ""input->data.f[0] = 5.f;"" so setting it to 4 should cause an error as sin(4) != sin(5)
  invoke_status = interpreter.Invoke();
  TF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, invoke_status);

  value = output->data.f[0];
  TF_LITE_MICRO_EXPECT_NEAR(-0.959f, value, 0.05f);
```

```
me$ cd ~
me$ cd tensorflow
me$ run make -f tensorflow/lite/micro/tools/make/Makefile test_hello_world_test 
~~~ALL TESTS PASSED~~~'
tensorflow/lite/micro/examples/hello_world/Makefile.inc:33: recipe for target 'test_hello_world_test' failed
make: *** [test_hello_world_test] Error 1"
42475,Tensorflow 2.3.0 is much slower than PyTorch 1.4.0 in backward propagation. (20 times slower),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
   Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
   Win10
- CUDA/cuDNN version: 
   CUDA 10.1/cuDNN 7
- TensorFlow version (use command below): 
   2.3.0
- Python version: 
   3.7.4
- GPU model and memory: 
   Geforce GTX 1660Ti (6GB)

**Describe the current behavior**

- I tried to use both TF2 and PyTorch to train SkipGram model with negative sampling. But notice a huge training speed difference. 
- TF2 takes ~0.5s to finish one step while PyTorch takes ~0.01s. One step refers to use 1 batch data to do forward and backward and update the weights. 
- The main difference is in backward propagation. 
- **More specifically, 'apply_gradients()' in TF2 is much slower than counterpart 'step()' in PyTorch. Does anyone know why?**


- Notes:
1. Both versions use GPU.
2. tf.function is used.
3. Training batch size and data is exactly the same.
4. Model size (vocab_size, emb_size) is the same.


- TF2:

```
@tf.function
def train_step_tf(pos_w, pos_v, neg_v):
    print('-'*50)
    with tf.GradientTape() as tape:  
        loss = skip_gram_model_tf(pos_w, pos_v, neg_v)
    
    start_time = time.time()
    variables = skip_gram_model_tf.trainable_variables
    print('getting variables time = {}'.format(time.time() - start_time))

    start_time = time.time()
    gradients = tape.gradient(loss, variables)
    print('init gradient time = {}'.format(time.time() - start_time))

    start_time = time.time()
    optimizer.apply_gradients(zip(gradients, variables))  # !!!!! this is where the major speed difference happens!!!!!
    print('apply gradient time = {}'.format(time.time() - start_time))
    
    print('-'*50)

    return loss
```

- PyTorch:

```
def train_step_torch(pos_w, pos_v, neg_v):  
    print('-'*50)
    start_time = time.time()
    optimizer_torch.zero_grad()
    loss = skip_gram_model_torch.forward(pos_w, pos_v, neg_v)
    print('getting variables time = {}'.format(time.time() - start_time))

    start_time = time.time()
    loss.backward()
    print('init gradient time = {}'.format(time.time() - start_time))
    
    start_time = time.time()
    optimizer_torch.step() # !!!!this is fast!!!!
    print('apply gradient time = {}'.format(time.time() - start_time))
    print('-'*50)

    return loss
```

**Describe the expected behavior**
I expect the performance shouldn't be that different. Is there anything I miss to use in TF2?


**Standalone code to reproduce the issue**
Colab link of full code:
https://colab.research.google.com/drive/17QsTkV271LPvo6aJf1QOGuumdU8OXmVj?usp=sharing
"
42474,tensorflow.python.framework.errors_impl.NotFoundError:  No algorithm worked!,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux -  Linux 5.8.1
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8
- CUDA/cuDNN version: 11.0.2 / 8.0.2.39
- GPU model and memory: RTX 2060 6 GB

**Describe the current behavior**
Crashing on conv_ops.cc when running on basic MNIST dataset

**Standalone code to reproduce the issue**
https://gist.github.com/Ashiix/9b00c28ee11411de4f052c0733fcbffd

**Other info / logs**
https://gist.github.com/Ashiix/053749aed670c3c2f3de02c3b193e5d3"
42471,TFLite Shared Library build error on Raspberry Pi 4 (native build with Bazel). Trying to build with XNNPACK enabled,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Raspbian Buster
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Raspberry Pi 4
- TensorFlow installed from (source or binary): source (attempt to compile tensorflow lite libraries)
- TensorFlow version: 2.3
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: --
- Bazel version (if compiling from source): Bazel 3.4.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 8.3.0
- GPU model and memory: not relevant



**Describe the problem**

Trying to compile the shared library for Raspberry Pi 4 using Bazel to enable XNNPACK doesn't work (**doing a native build on the Raspberry Pi 4**). I have used the instructions from https://blog.tensorflow.org/2020/07/accelerating-tensorflow-lite-xnnpack-integration.html to enable XNNPACK and https://www.tensorflow.org/lite/guide/build_rpi as instructed.


**Provide the exact sequence of commands / steps that you executed before running into the problem**

`bazel build --define tflite_with_xnnpack=true -c opt //tensorflow/lite/c:libtensorflowlite_c.so`

I have removed the cross compile option mentioned in https://www.tensorflow.org/lite/guide/build_rpi  which is `https://www.tensorflow.org/lite/guide/build_rpi` and added `--define tflite_with_xnnpack=true` to enable xnnpack.


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
ERROR: /home/lahiru/workfolder/bazel_patch_test/tensorflow/tensorflow/lite/c/BUILD:22:24: Linking of rule '//tensorflow/lite/c:libtensorflowlite_c.so' failed (Exit 1)
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunKernel<(ruy::Path)4, signed char, signed char, int, ruy::MulParams<int, int> >(ruy::Tuning,
ruy::SidePair<ruy::PEMat> const&, void*, ruy::SidePair<int> const&, ruy::SidePair<int> const&, ruy::EMat*): error: undefined reference to 'ruy::Kernel8bitNeonOutOfOrder(ruy::KernelParams8bit<4, 2> const&)'
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunKernel<(ruy::Path)4, signed char, signed char, int, ruy::MulParams<int, int> >(ruy::Tuning,
ruy::SidePair<ruy::PEMat> const&, void*, ruy::SidePair<int> const&, ruy::SidePair<int> const&, ruy::EMat*): error: undefined reference to 'ruy::Kernel8bitNeonOutOfOrder1Col(ruy::KernelParams8bit<4, 2> const&)'
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunPack<(ruy::Path)4, ruy::FixedKernelLayout<(ruy::Order)0, 16, 2>, signed char, signed char>(r
uy::Tuning, ruy::EMat const&, ruy::PEMat*, int, int): error: undefined reference to 'ruy::Pack8bitNeonOutOfOrder2Cols(ruy::PackParams8bit const&)'
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunPack<(ruy::Path)4, ruy::FixedKernelLayout<(ruy::Order)0, 16, 2>, signed char, signed char>(r
uy::Tuning, ruy::EMat const&, ruy::PEMat*, int, int): error: undefined reference to 'ruy::Pack8bitNeonOutOfOrder2Cols(ruy::PackParams8bit const&)'
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunPack<(ruy::Path)4, ruy::FixedKernelLayout<(ruy::Order)0, 16, 2>, signed char, signed char>(r
uy::Tuning, ruy::EMat const&, ruy::PEMat*, int, int): error: undefined reference to 'ruy::Pack8bitNeonOutOfOrder2Cols(ruy::PackParams8bit const&)'
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunPack<(ruy::Path)4, ruy::FixedKernelLayout<(ruy::Order)0, 16, 2>, signed char, signed char>(r
uy::Tuning, ruy::EMat const&, ruy::PEMat*, int, int): error: undefined reference to 'ruy::Pack8bitNeonOutOfOrder2Cols(ruy::PackParams8bit const&)'
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunPack<(ruy::Path)4, ruy::FixedKernelLayout<(ruy::Order)0, 16, 4>, signed char, signed char>(r
uy::Tuning, ruy::EMat const&, ruy::PEMat*, int, int): error: undefined reference to 'ruy::Pack8bitNeonOutOfOrder4Cols(ruy::PackParams8bit const&)'
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunPack<(ruy::Path)4, ruy::FixedKernelLayout<(ruy::Order)0, 16, 4>, signed char, signed char>(r
uy::Tuning, ruy::EMat const&, ruy::PEMat*, int, int): error: undefined reference to 'ruy::Pack8bitNeonOutOfOrder4Cols(ruy::PackParams8bit const&)'
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunPack<(ruy::Path)4, ruy::FixedKernelLayout<(ruy::Order)0, 16, 4>, signed char, signed char>(r
uy::Tuning, ruy::EMat const&, ruy::PEMat*, int, int): error: undefined reference to 'ruy::Pack8bitNeonOutOfOrder4Cols(ruy::PackParams8bit const&)'
bazel-out/arm-opt/bin/tensorflow/lite/kernels/internal/_objs/neon_tensor_utils/neon_tensor_utils.pic.o:neon_tensor_utils.cc:function void ruy::RunPack<(ruy::Path)4, ruy::FixedKernelLayout<(ruy::Order)0, 16, 4>, signed char, signed char>(r
uy::Tuning, ruy::EMat const&, ruy::PEMat*, int, int): error: undefined reference to 'ruy::Pack8bitNeonOutOfOrder4Cols(ruy::PackParams8bit const&)'
collect2: error: ld returned 1 exit status
Target //tensorflow/lite/c:libtensorflowlite_c.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1574.126s, Critical Path: 260.79s
INFO: 1088 processes: 1088 local.
FAILED: Build did NOT complete successfully
```



"
42468,Compiler crash with clang 7.1,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): LLVM Clang 7.1.0
- CUDA/cuDNN version:
- GPU model and memory:


When building TF Micro I get a compiler crash on micro_allocator.cc (commit  d5ed5f9).
[dump.txt](https://github.com/tensorflow/tensorflow/files/5091697/dump.txt)
(See attached dump)
The issue apparently is unstable support in clang 7.1 for flexible members.

defining data[] as data[0] in TfLiteIntArray definition solves the issue.
See PR:
https://github.com/tensorflow/tensorflow/pull/42464




"
42467,no kernel image is available for execution on the device,"I've installed TensorFlow 2.3.0 on windows 10 but cant run any python scrips contain TensorFlow codes!
GPU card : NVIDIA 960m
OS : Windows 10
Cuda : 10.1
cudnn : 7.6.5.32
python: 3.7.7

this is log output when I run script :
 ```
py main.py
2020-08-18 21:19:56.898389: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-18 21:19:59.658108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-08-18 21:20:00.194181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-18 21:20:00.207551: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-18 21:20:00.213582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-18 21:20:00.218522: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-18 21:20:00.224225: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-18 21:20:00.236176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-18 21:20:00.244819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-18 21:20:00.251416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-18 21:20:00.257794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-18 21:20:00.263340: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-18 21:20:00.286389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e0eb7cb660 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-18 21:20:00.297402: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-18 21:20:00.302999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-18 21:20:00.317067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-18 21:20:00.323311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-18 21:20:00.329936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-18 21:20:00.335930: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-18 21:20:00.341258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-18 21:20:00.348285: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-18 21:20:00.354092: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-18 21:20:00.360523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-18 21:20:00.439805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-18 21:20:00.447079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-08-18 21:20:00.452262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-08-18 21:20:00.456464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3121 MB memory) -> physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-08-18 21:20:00.480959: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e0eb7ca5e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-18 21:20:00.493404: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0
2020-08-18 21:20:00.797182: F .\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device

```
I've had this problem since I tried install TensorFlow version +2 , If I install TensorFlow 15.3.1 I wont have this problem !!!
but since TensorFlow 1+ wont have supported next year I want to install TensorFlow 2+.
"
42465,Using a model with LeakyRelu in Tensorflow lite micro not supported?,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
I created a CNN model for analyzing a sensor grid that uses LeakyReLU.  Now I've been tasked to make the trained model work on a microcontroller.  The model loads fine ( after converting it etc. ), but as soon as I have it instatiate the micro interpreter it tells me that LeakyRelu is not supported mainly by saying ""
Didn't find op for builtin opcode 'LEAKY_RELU' version '1'
Failed to get registration from op code LEAKY_RELU
""
**Please provide the exact sequence of commands/steps when you ran into the problem**

The following is the setup code I have so far

    static tflite::MicroErrorReporter micro_error_reporter;
    mErrorReporter = &micro_error_reporter;
    
    mModel = tflite::GetModel(model_kara_cnn_tflite);
    if (mModel->version() != TFLITE_SCHEMA_VERSION) {
      TF_LITE_REPORT_ERROR(mErrorReporter, ""Model provided is schema version %d not equal to supported version %d."", mModel->version(), TFLITE_SCHEMA_VERSION);
      return false;
    }
    
    constexpr int tensor_arena_size = 16 * 1024;
    uint8_t tensor_arena[tensor_arena_size];
    tflite::MicroMutableOpResolver<5> resolver;
    resolver.AddConv2D();
    resolver.AddFullyConnected();
    resolver.AddMaxPool2D();
    resolver.AddSoftmax();
    resolver.AddBuiltin(tflite::BuiltinOperator_LEAKY_RELU, *tflite::ops::builtin::Register_LEAKY_RELU());

    tflite::MicroInterpreter interpreter(mModel, resolver, tensor_arena, tensor_arena_size, mErrorReporter);
    TfLiteStatus allocate_status = interpreter.AllocateTensors();
    if (allocate_status != kTfLiteOk) {
      TF_LITE_REPORT_ERROR(mErrorReporter, ""AllocateTensors() failed"");
      return false;
    }
    
    std::cout << ""Setup complete"" << std::endl;
    return true;
"
42463,Error executing quickstart noteboook,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win 10
-   **TensorFlow installed from (source or binary)**: conda gpu version
-   **TensorFlow version (use command below)**: 2.1.0
-   **Python version**: 3.7.7
-   **CUDA/cuDNN version**: cudatoolkit - 10.1.243 - h74a9793_0 - anaconda
                                                cudnn - 7.6.5 - cuda10.1_0 - anaconda
-   **GPU model and memory**: GTX 750 TI - 2GB

### Describe the problem
I wanted to test the tf quick start notebook: https://tensorflow.google.cn/tutorials/quickstart/advanced and got the following error message:
```UnknownError                              Traceback (most recent call last)
<ipython-input-10-cdcc13267505> in <module>
      9 
     10   for images, labels in train_ds:
---> 11     train_step(images, labels)
     12 
     13   for test_images, test_labels in test_ds:

~\anaconda3\envs\tf\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

~\anaconda3\envs\tf\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    630         # Lifting succeeded, so variables are initialized and we can run the
    631         # stateless function.
--> 632         return self._stateless_fn(*args, **kwds)
    633     else:
    634       canon_args, canon_kwds = \

~\anaconda3\envs\tf\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   2361     with self._lock:
   2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 
   2365   @property

~\anaconda3\envs\tf\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1609          if isinstance(t, (ops.Tensor,
   1610                            resource_variable_ops.BaseResourceVariable))),
-> 1611         self.captured_inputs)
   1612 
   1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~\anaconda3\envs\tf\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1690       # No tape is watching; skip to running the function.
   1691       return self._build_call_outputs(self._inference_function.call(
-> 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(
   1694         args,

~\anaconda3\envs\tf\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    543               inputs=args,
    544               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 545               ctx=ctx)
    546         else:
    547           outputs = execute.execute_with_cancellation(

~\anaconda3\envs\tf\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~\anaconda3\envs\tf\lib\site-packages\six.py in raise_from(value, from_value)

UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node my_model/conv2d/Conv2D (defined at <ipython-input-5-1e051998210b>:10) ]] [Op:__inference_train_step_566]

Errors may have originated from an input operation.
Input Source operations connected to node my_model/conv2d/Conv2D:
 images (defined at <ipython-input-10-cdcc13267505>:11)

Function call stack:
train_step
```

I installed tf, cuda and cudnn using ```conda install -c anaconda tensorflow-gpu```"
42459,Accuracy is lost after save/load,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): See below.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, 1909
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.7.7
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: Not relevant.

**Describe the current behavior**
When saving a pre-trained model and loading it again, the accuracy drops to its default value. Minimal example:
```
import tensorflow as tf

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(units=2, activation='softmax', name='output'))
model.compile(optimizer=tf.keras.optimizers.Adam(lr=10),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
dummy_data_x = [[0, 0],
                [1, 0],
                [0, 1],
                [1, 1]]
dummy_data_y = [0, 1, 0, 1]
print(model.evaluate(x=dummy_data_x, y=dummy_data_y))
model.fit(x=dummy_data_x, y=dummy_data_y, epochs=10)
print(model.evaluate(x=dummy_data_x, y=dummy_data_y))
model.save('test_model')
model = tf.keras.models.load_model('test_model')
print(model.evaluate(x=dummy_data_x, y=dummy_data_y))
```
The model is extremely simple (read: bad/useless) for comparison's sake. Before training it, the evaluation results in:
```
1/1 [==============================] - 0s 0s/step - loss: 0.9013 - accuracy: 0.5000
[0.9013183116912842, 0.5]
```
The loss is obviously random at first, but crucially the accuracy is 50% because it guesses 0 every time. After training, it evaluates to:
```
1/1 [==============================] - 0s 0s/step - loss: 0.0000e+00 - accuracy: 1.0000
[0.0, 1.0]
```
The loss dropped to zero and the model can perfectly interpret the data. Now I save the model to the disk and immediately load it from the same location. When I now evaluate it, I get:
```
1/1 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.5000
[0.0, 0.5]
```
Even though the model has the same structure, weights, and loss, and all four example inputs are evaluated correctly, TensorFlow says the accuracy is 50%, which is not true.

**Describe the expected behavior**
The accuracy should remain the same when loading a previously trained and saved model.

**Standalone code to reproduce the issue**
See above.

**Other info / logs**
See above.
"
42458,CosineSimilarity documentation range incorrect,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/losses/CosineSimilarity

## Description of issue (what needs changing):

### Clear description

""Note that it is a negative quantity between -1 and 0"" should be changed to ""Note that it is a negative quantity between -1 and 1""

### Correct links

### Parameters defined

### Returns defined

### Raises listed and defined

### Usage example

### Request visuals, if applicable

### Submit a pull request?

Don't plan to submit pull request
"
42457,AttributeError: module 'tensorflow.python.keras' has no attribute 'abs',"<em>I am working on a multi-class image classification problem by using a siamese model.</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1.0
- Python version: 3.6.10
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Nvidia 920MX



I am working on a image classification problem with multiple classes and i follow a siamese face recognition sample in here. I have saved processed data in **.npy** format and i have used **Lambda** in the siamese model. It shows an error in `lambda `:

**`distance_euclid = Lambda( lambda tensors : K.abs( tensors[0] - tensors[1] ))( [output_x1 , output_x2] )`**
"
42456,Error Importing Tensorflow,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution:  (Windows 10 64 bits)
- Mobile device: None
- TensorFlow installed from (source or binary):
- TensorFlow version:  2.3.0
- Python version: 3.8.4
- Installed using virtualenv? pip? conda? : pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Nvidia GeForce 920M 2GB



**Describe the problem**
When trying to import tensorflow, i got the following error:

> Traceback (most recent call last):
>   File ""C:\Users\Muril\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
>     from tensorflow.python._pywrap_tensorflow_internal import *
> ImportError: DLL load failed while importing _pywrap_tensorflow_internal: Não foi possível encontrar o módulo especificado.
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""deep_versions.py"", line 2, in <module>
>     import tensorflow
>   File ""C:\Users\Muril\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
>     from tensorflow.python.tools import module_util as _module_util
>   File ""C:\Users\Muril\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
>     from tensorflow.python.eager import context
>   File ""C:\Users\Muril\Anaconda3\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
>     from tensorflow.python import pywrap_tfe
>   File ""C:\Users\Muril\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
>     from tensorflow.python import pywrap_tensorflow
>   File ""C:\Users\Muril\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
>     raise ImportError(msg)
> ImportError: Traceback (most recent call last):
>   File ""C:\Users\Muril\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
>     from tensorflow.python._pywrap_tensorflow_internal import *
> ImportError: DLL load failed while importing _pywrap_tensorflow_internal: Não foi possível encontrar o módulo especificado.
> 
> 
> Failed to load the native TensorFlow runtime.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
# tensorflow
import tensorflow
print('tensorflow: %s' % tensorflow.__version__)
```
**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I'm using Anaconda, and installed through pip in the command prompt. Using `python -VV` i got the following:

`Python 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]`

Later, i tried install using `conda install -c conda-forge tensorflow`, and got the following:

```
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: |
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
failed

UnsatisfiableError: The following specifications were found
to be incompatible with the existing python installation in your environment:

Specifications:

  - tensorflow -> python[version='3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.6,<3.7.0a0|>=3.7,<3.8.0a0|3.7.*']

Your python: python=3.8

If python is on the left-most side of the chain, that's the version you've asked for.
When python appears to the right, that indicates that the thing on the left is somehow
not available for the python version you are constrained to. Note that conda will not
change your python version to a different minor version unless you explicitly specify
that.

The following specifications were found to be incompatible with your system:

  - feature:/win-64::__cuda==10.1=0

Your installed version is: 10.1
```
"
42455,I have facing below mention error in new version of python 3.8. Can any suggest how to solve it?,"
  File ""C:\Anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File ""C:\Anaconda\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from tensorflow.keras.layers.experimental.preprocessing import RandomRotation

  File ""C:\Anaconda\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util

  File ""C:\Anaconda\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context

  File ""C:\Anaconda\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe

  File ""C:\Anaconda\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow

  File ""C:\Anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)

ImportError: Traceback (most recent call last):
  File ""C:\Anaconda\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File ""F:\Prognica Work\Application Code\unet_keras-master\New_UNET.py"", line 20, in <module>
    from keras.models import Model, load_model

  File ""C:\Anaconda\lib\site-packages\keras\__init__.py"", line 5, in <module>
    raise ImportError(

ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
42454,Keras 'Random' preprocessing layers do not work on cloud TPU,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Simple demo available in colab [here](https://colab.research.google.com/drive/1lZBE7bDvRxRoEijYkx8Zch3JU9xug6V3?usp=sharing).

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Google Colab with TPU

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A

- TensorFlow installed from (source or binary):
Google Colab

- TensorFlow version (use command below):
2.3.0

- Python version:
3.6.9

- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
Cloud TPU

** Current Behaviour **
'Random' layers within tf.keras.layers.preprocessing.experimental (e.g. RandomRotation, RandomTranslation) fail with `Detected unsupported operations when trying to compile graph` ... `No registered 'ImageProjectiveTransformV2' OpKernel for XLA_TPU_JIT devices compatible with node` when using a cloud TPU, either in colab or from a VM

** Expected Behaviour **
New layers should use ops that are implemented on TPUs, or at least carry a health warning that they are not (yet) available on TPU.

**Standalone code to reproduce the issue**
See [this colab](https://colab.research.google.com/drive/1lZBE7bDvRxRoEijYkx8Zch3JU9xug6V3?usp=sharing). Or run the following code with a TPU:
```
import tensorflow as tf

# establish connection to TPU
tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)
strategy = tf.distribute.TPUStrategy(tpu)
print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  

with strategy.scope():
  # define model layers
  model_input = tf.keras.layers.Input(shape=(224, 224, 1))
  x = tf.keras.layers.experimental.preprocessing.RandomRotation((-0.1, 0.1))(model_input)
  x = tf.keras.layers.MaxPool2D((224, 224))(x)
  x = tf.keras.layers.Flatten()(x)
  x = tf.keras.layers.Dense(1, activation='sigmoid')(x)

  # compile model
  model = tf.keras.Model(inputs=model_input, outputs=x)
  model.summary(line_length=120)
  model.compile(optimizer='adam', loss='binary_crossentropy')

  # generate some random data and fit the model
  images = tf.random.uniform((10, 224, 224, 1))
  labels = tf.zeros((10, 1))
  model.fit(images, labels)

  # predict on the data
  print(model.predict(images))
```

**Other info / logs**
I appreciate that these are 'experimental' features, so I am not sure if this constitutes a bug or a feature request. It would be helpful to indicate if TPU support for these new keras layers is in the pipeline - I have been looking for an image augmentation solution in tf2.0+ for some time, and was hopeful these new layers would be it. Without TPU support the feature has limited use at this time. It would also have been helpful to put a health warning in the docs that TPU support is not yet available, as I would not have wasted my time on this. Someone has recently [asked a question about this](https://stackoverflow.com/questions/63302446/colabtpu-not-supporting-tf-2-3-0-tf-keras-layers-experimental-preprocessing) on StackOverflow, but in the absence of an official reply there I chose to raise it here.

Note that I tried using a VM with tf-nightly (2.4.0-dev20200817) installed, but I get the same error message. Since I can only create TPUs at version 2.3, this is not altogether surprising.

Thanks"
42453,"SeparableConv1D fails with padding=""causal""","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux/amd64 tensorflow/tensorflow:2.3.0-gpu-jupyter
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):  v1.12.1-39480-g36dabea898 2.4.0-dev20200817
- Python version: 3.6

**Describe the current behavior**
`tf.keras.layers.SeparableConv1D` fails on build with `padding=causal`

**Standalone code to reproduce the issue**
```
import tensorflow as tf
print(tf.__version__)
print(tf.version.GIT_VERSION, tf.version.VERSION)

model = tf.keras.Sequential()
model.add(tf.keras.Input((None,None,3)))
model.add(tf.keras.layers.SeparableConv1D(
                    dilation_rate=1,
                    filters = 3,
                    kernel_size=2,
                    padding='causal',
))
```
```
2.4.0-dev20200817
v1.12.1-39480-g36dabea898 2.4.0-dev20200817
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-1-f2de2533598a> in <module>
      9                     filters = 3,
     10                     kernel_size=2,
---> 11                     padding='causal',
     12 ))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    462     self._self_setattr_tracking = False  # pylint: disable=protected-access
    463     try:
--> 464       result = method(self, *args, **kwargs)
    465     finally:
    466       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)
    220       # If the model is being built continuously on top of an input layer:
    221       # refresh its output.
--> 222       output_tensor = layer(self.outputs[0])
    223       if len(nest.flatten(output_tensor)) != 1:
    224         raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    929     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):
    930       return self._functional_construction_call(inputs, args, kwargs,
--> 931                                                 input_list)
    932 
    933     # Maintains info about the `Layer.call` stack.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)
   1067         # Check input assumptions set after layer building, e.g. input shape.
   1068         outputs = self._keras_tensor_symbolic_call(
-> 1069             inputs, input_masks, args, kwargs)
   1070 
   1071         if outputs is None:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in _keras_tensor_symbolic_call(self, inputs, input_masks, args, kwargs)
    799       return nest.map_structure(keras_tensor.KerasTensor, output_signature)
    800     else:
--> 801       return self._infer_output_signature(inputs, args, kwargs, input_masks)
    802 
    803   def _infer_output_signature(self, inputs, args, kwargs, input_masks):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in _infer_output_signature(self, inputs, args, kwargs, input_masks)
    840           # TODO(kaftan): do we maybe_build here, or have we already done it?
    841           self._maybe_build(inputs)
--> 842           outputs = call_fn(inputs, *args, **kwargs)
    843 
    844         self._handle_activity_regularization(inputs, outputs)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py in call(self, inputs)
   2030   def call(self, inputs):
   2031     if self.padding == 'causal':
-> 2032       inputs = array_ops.pad(inputs, self._compute_causal_padding())
   2033     if self.data_format == 'channels_last':
   2034       strides = (1,) + self.strides * 2 + (1,)

TypeError: _compute_causal_padding() missing 1 required positional argument: 'inputs'
```

Here's where it [fails](https://github.com/tensorflow/tensorflow/blob/75801da4cd321aabbf79e78da1e5de1a10ba4c2a/tensorflow/python/keras/layers/convolutional.py#L249)

Same thing happens in stable version 2.3.0."
42451,ModuleNotFoundError: No module named 'tensorflow_examples',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Just trying to import and check**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Win10**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**
- TensorFlow installed from (source or binary): **pip with GPU support**
- TensorFlow version (use command below): **2.0.0**
- Python version: **3.5**
- Bazel version (if compiling from source): **No**
- GCC/Compiler version (if compiling from source):**No**
- CUDA/cuDNN version: **Cuda compilation tools, release 10.1, V10.1.243**(nvcc --version)
- GPU model and memory: **GeForce 920M**

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

version - 2.0.0

**Describe the current behavior**

In my Notebook's first cell, I wrote :
```
!pip install git+https://github.com/tensorflow/examples.git
!pip install -U tfds-nightly
```
On the next cell :
```
import tensorflow as tf
from tensorflow_examples.models.pix2pix import pix2pix
```
But it gives me : *ModuleNotFoundError: No module named 'tensorflow_examples'*

**Describe the expected behavior**

It should have exported the module.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.


Here is the pip install log :
```
Collecting git+https://github.com/tensorflow/examples.git
  Cloning https://github.com/tensorflow/examples.git to c:\users\mua\appdata\local\temp\pip-req-build-qtmqgj7m
Requirement already satisfied (use --upgrade to upgrade): tensorflow-examples===b30a40f9416fc38cfa91ca03d835ba1fc432a824- from git+https://github.com/tensorflow/examples.git in e:\software\python 3.5\lib\site-packages
Requirement already satisfied: absl-py in e:\software\python 3.5\lib\site-packages (from tensorflow-examples===b30a40f9416fc38cfa91ca03d835ba1fc432a824-) (0.8.1)
Requirement already satisfied: six in e:\software\python 3.5\lib\site-packages (from tensorflow-examples===b30a40f9416fc38cfa91ca03d835ba1fc432a824-) (1.14.0)
Building wheels for collected packages: tensorflow-examples
  Building wheel for tensorflow-examples (setup.py): started
  Building wheel for tensorflow-examples (setup.py): finished with status 'done'
  Created wheel for tensorflow-examples: filename=tensorflow_examples-b30a40f9416fc38cfa91ca03d835ba1fc432a824_-py3-none-any.whl size=136427 sha256=40d5b23f277f4634313116bf6205588e8668a499798fe1c7fdad143fc6144b68
  Stored in directory: C:\Users\MUA\AppData\Local\Temp\pip-ephem-wheel-cache-5wvvxv8d\wheels\e2\f1\08\a5d8eb62f62cc814d511a70115a5467b1135ec8270dd16d620
Successfully built tensorflow-examples
  Running command git clone -q https://github.com/tensorflow/examples.git 'C:\Users\MUA\AppData\Local\Temp\pip-req-build-qtmqgj7m'
WARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.
You should consider upgrading via the 'e:\software\python 3.5\python.exe -m pip install --upgrade pip' command.
Collecting tfds-nightly
  Downloading tfds_nightly-3.2.1.dev202007220105-py3-none-any.whl (3.4 MB)
Requirement already satisfied, skipping upgrade: wrapt in e:\software\python 3.5\lib\site-packages (from tfds-nightly) (1.11.2)
Requirement already satisfied, skipping upgrade: numpy in e:\software\python 3.5\lib\site-packages (from tfds-nightly) (1.17.4)
Requirement already satisfied, skipping upgrade: tqdm in e:\software\python 3.5\lib\site-packages (from tfds-nightly) (4.45.0)
Collecting tensorflow-metadata
  Downloading tensorflow_metadata-0.23.0-py3-none-any.whl (43 kB)
Collecting promise
  Downloading promise-2.3.tar.gz (19 kB)
Collecting dill
  Downloading dill-0.3.2.zip (177 kB)
Requirement already satisfied, skipping upgrade: six in e:\software\python 3.5\lib\site-packages (from tfds-nightly) (1.14.0)
Collecting attrs>=18.1.0
  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)
Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in e:\software\python 3.5\lib\site-packages (from tfds-nightly) (3.10.0)
Requirement already satisfied, skipping upgrade: absl-py in e:\software\python 3.5\lib\site-packages (from tfds-nightly) (0.8.1)
Requirement already satisfied, skipping upgrade: termcolor in e:\software\python 3.5\lib\site-packages (from tfds-nightly) (1.1.0)
Requirement already satisfied, skipping upgrade: requests>=2.19.0 in e:\software\python 3.5\lib\site-packages (from tfds-nightly) (2.23.0)
Collecting future
  Downloading future-0.18.2.tar.gz (829 kB)
Collecting googleapis-common-protos
  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)
Requirement already satisfied, skipping upgrade: setuptools in e:\software\python 3.5\lib\site-packages (from protobuf>=3.6.1->tfds-nightly) (41.6.0)
Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in e:\software\python 3.5\lib\site-packages (from requests>=2.19.0->tfds-nightly) (1.25.8)
Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in e:\software\python 3.5\lib\site-packages (from requests>=2.19.0->tfds-nightly) (2.9)
Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in e:\software\python 3.5\lib\site-packages (from requests>=2.19.0->tfds-nightly) (2019.11.28)
Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in e:\software\python 3.5\lib\site-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)
Building wheels for collected packages: promise, dill, future
  Building wheel for promise (setup.py): started
  Building wheel for promise (setup.py): finished with status 'done'
  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21498 sha256=82af1fb81258e76c2ddec82ec8870ec0901b560e2547ddff0f81e096cd65fdc2
  Stored in directory: c:\users\mua\appdata\local\pip\cache\wheels\b6\3e\4e\d80f74df03a8059f631b23ec49939d8fa0a2633522596b6ffd
  Building wheel for dill (setup.py): started
  Building wheel for dill (setup.py): finished with status 'done'
  Created wheel for dill: filename=dill-0.3.2-py3-none-any.whl size=78977 sha256=22a67eb861aca650bc9f1e039c15cb8ef9a87fbe88a139952868f352dd8f51aa
  Stored in directory: c:\users\mua\appdata\local\pip\cache\wheels\5c\4b\fd\db4143df7b4a4301b4068a2ed49f300b76b13d87b23bf375da
  Building wheel for future (setup.py): started
  Building wheel for future (setup.py): finished with status 'done'
  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491061 sha256=f19a6fd742fd80f4a1995a132c1c10b6de14b112ef5110bcb31eff13a2379306
  Stored in directory: c:\users\mua\appdata\local\pip\cache\wheels\c4\f0\ae\d4689c4532d1f111462ed6a884a7767d502e511ee65f0d8e1b
Successfully built promise dill future
Installing collected packages: googleapis-common-protos, tensorflow-metadata, promise, dill, attrs, future, tfds-nightly
Successfully installed attrs-19.3.0 dill-0.3.2 future-0.18.2 googleapis-common-protos-1.52.0 promise-2.3 tensorflow-metadata-0.23.0 tfds-nightly-3.2.1.dev202007220105
WARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.
You should consider upgrading via the 'e:\software\python 3.5\python.exe -m pip install --upgrade pip' command.
```
"
42450,What Grappler optimizers turned on by default?,"## URL(s) with the issue:
https://www.tensorflow.org/guide/graph_optimization

## Description of issue (what needs changing):
It should be cleared which optimizers Grappler applies by default. 
For now it's not clear if i should turn on a lot of features by myself

### Parameters defined

Are all parameters defined and formatted correctly? - No.
"
42449,No module named 'tensorflow.python.platform',"Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary):binary
TensorFlow version: Version 2.3
Python version:3.8
Installed using virtualenv? pip? conda?: in a conda eviroment with pip
I want to import tensorflow but everytime I get
tensorflow.python.platform import self_check
ModuleNotFoundError: No module named 'tensorflow.python.platform'

Provide the exact sequence of commands / steps that you executed before running into the problem
I have already tried different tensorflow 2.x version and also completed uninstalled anconda and reinstall it. I also tried it in different enviorments.
Also I had tensorflow running, but I update and also deleted some of the Microsoft Visual C++ Redistributable due to another problem. I did update and reinstalled all of the version but tensorflow is still not working.

Also I looked in the file and there is no python.plattform. Is there anyway to copy it or does anyone have some other solution?"
42447,ValueError: `tape` is required when a `Tensor` loss is passed.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (macOS Catalina):
- TensorFlow installed from pip:
- TensorFlow version 2.3.0:
- Python version 2.8:

**Describe the current behavior**

Getting the following error:
```
Traceback (most recent call last):
  File ""train.py"", line 277, in <module>
    k3
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 385, in minimize
    loss, var_list=var_list, grad_loss=grad_loss, tape=tape)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 440, in _compute_gradients
    raise ValueError(""`tape` is required when a `Tensor` loss is passed."")
ValueError: `tape` is required when a `Tensor` loss is passed.
```
whereas `loss` is a number.

**Describe the expected behavior**
Since `loss` is a number, we expect tensorflow to not say that `Tensor` loss has been passed.
**Standalone code to reproduce the issue**

```
def loss(ground_truth, output):
    return np.sum(np.positive(ground_truth - output))

def kernel(*args):
  return tf.Variable(np.random.rand(*args), dtype=tf.float32) # kernel 1
color_channels = 3
feature_size = 32
k1 = kernel(5, 5, color_channels, feature_size)
k2 = kernel(3, 3, feature_size, feature_size) # kernel 2
k3 = kernel(3, 3, feature_size, feature_size) # kernel 3
width = 100
height = 200
y_train_left_nod = np.random.rand(width, height, 3)

y_train_left_noc = tf.keras.preprocessing.image.load_img(""/img/path"")
y_train_left_noc = tf.keras.preprocessing.image.img_to_array(y_train_left_noc)
soft_argmin = np.random.rand(y_train_left_noc.shape[0], y_train_left_noc.shape[1])  
loss = loss(y_train_left_noc[:,:,0], soft_argmin).tolist() # y

train = tf.keras.optimizers.Adam().minimize(loss, [
    k1,
    k2,
    k3])
```
"
42446,Should the custom loss function in Keras return a single loss value for the batch or an arrary of losses for every sample in the training batch?,"I asked a question on [StackOverflow](https://stackoverflow.com/questions/63390725/should-the-custom-loss-function-in-keras-return-a-single-loss-value-for-the-batc) regarding as the return value of a custom loss funtion. But I didn't get a clear answer.

In this [guide](https://www.tensorflow.org/guide/keras/train_and_evaluate#custom_losses) on tensorflow website, I found an example of custom loss funciton:

        def custom_mean_squared_error(y_true, y_pred):
            return tf.math.reduce_mean(tf.square(y_true - y_pred))

The `reduce_mean` function in this custom loss function will return an scalar. But I think the custom loss function should return an array of losses for every example in a training batch, rather than a single loss value. 

According to the source code of [Model](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/engine/training.py#L159-L2634) class, the custom loss function is used to constructed a `LossFunctionWrapper` object. I read the source code of the [loss](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/losses.py) module. I think it's `LossFunctionWrapper.__call()__` method that is responsible for getting the mean loss value for the training batch. `LossFunctionWrapper.__call()__` method first calls the `LossFunctionWrapper.call()` method to get an array of losses for every example in the training batch. It's in the  `LossFunctionWrapper.call()` method that our custom loss function is called.

In addition, in the souece code of [losses](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/losses.py) module, the `MeanAbsoluteError` class uses the `mean_squared_error` function to construct a `LossFunctionWrapper` class. We can see that the `mean_squared_error` function returns `K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)`, which is an array, not a single value. I think our custom loss function shoud just be like this.

So, why does the custom loss function in the [guide](https://www.tensorflow.org/guide/keras/train_and_evaluate#custom_losses) on tensorflow website return a scalar? Is it wrong to define a custom function like this?"
42445,Setting multithreading  for tensorflowlite does not work！,"Hi guys,
I set up tensorflowlite for four threads,but compared with single thread, the time consumption has not decreased. by the way, i quantizate my models.
Hope to get your help,ths!"
42444,Can I specify the version of NAPI ?,"Can I specify the version of nAPI? In my environment, Node 10.15.x only supports NAPi-v4, but tensorFlow is actually NAPi-V6 (/node_modules/_@tensorflow_tfjs-node@2.1.0@@tensorflow/tfjs-node/lib/ NAPi-v6) after My deployment.

- tensorflowVersion：2.1.0

![image](https://user-images.githubusercontent.com/12997948/90458256-7e305d00-e130-11ea-8dee-98dccb97bd3f.png)

"
42443,Keras Model accepts unnamed ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Colab.

- TensorFlow installed from (source or binary):
colab

- TensorFlow version (use command below):

tf 2.3.0

- Python version:
colab default

**Describe the current behavior**

Keras model (in eager mode at least) accepts a dictionary for named input, but will accept without warning any dictionary of the correct length regardless of the key names.

**Describe the expected behavior**

A warning or error if the keys provided as input when running a keras model do not match the named input.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf

# Define a simple model with named input
a = tf.keras.Input(shape=[1], name='a')
b = tf.keras.Input(shape=[1], name='b')
out = tf.concat([a, b], axis=0)
out = tf.reduce_sum(out, axis=0)
model = tf.keras.Model([a, b], [out])

# As expected models runs with named input
model({'a': tf.convert_to_tensor([1]), 'b': tf.convert_to_tensor([1])})

# However, model will silently accept any dictionary with two tensors
# (of appropriate shape) without warning.
model({'c': tf.convert_to_tensor([1]), 'd': tf.convert_to_tensor([1])})

# It will warn if the dictionary has too many entries
model({'c': tf.convert_to_tensor([1]), 'd': tf.convert_to_tensor([1]), 'e': tf.convert_to_tensor([1])})

# Or raise an Assertion if the dictionary has too few entries.
model({'c': tf.convert_to_tensor([1])})
```"
42441,Erroneously triggering tf.function retracing warnings when rapidly creating new TF models.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04, Google Colab
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): occurs in v2.3.0 and tf-nightly v2.4.0a20200817; NOT in v2.2.0
- Python version: 3.7.7


**Related Issues**
- https://github.com/tensorflow/tensorflow/issues/34025
- https://github.com/tensorflow/tensorflow/issues/38561


**Describe the current behavior**
The function retracing warning (see below) is triggered constantly when creating multiple independent models. Similar bugs occured recently in the above mentioned issues, though while those occur when doing rapid predictions on the same model does this bug occur solely when creating and predicting multiple new models rapidly (which is necessary e.g. for TF evolutionary frameworks). The tf.function retracing warning is triggered after the creation of the first 5 models. The bug occurs in v2.3.0 and todays tf-nightly, though not in v2.2.0. I attempted workarounds mentioned in previous issues (setting `experimental_relax_shapes` to True, disabling eager execution and setting `step` to 1), though none worked. I also attempted to provide fixed input shape and batch_size as mentioned in the warning message, though this was also unsuccessful. 
While I am no expert in tf.function does it seem to me that the counter to trigger the warning seems to be a global variable and not seperate for each model, therefore triggering the warning that excessive retracings for the current model occured even though it was only fast consecutive initial retracing for each one of multiple models. Just a hunch though.

Exact warning message:

> WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c67c45a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.

**Standalone code to reproduce the issue**

```
import numpy as np
import tensorflow as tf

x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([[0], [1], [1], [0]])

for i in range(50):
    tf.print(f'Model {i}...')

    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(units=2))
    model.add(tf.keras.layers.Dense(units=1))

    prediction = model.predict(x)
```

Google colab reproducing code: https://colab.research.google.com/drive/1QLFNCDWw37x6kP2AajB4g3Lidn1oLRx7?usp=sharing"
42440,Problem running tensorflow in Pycharm - ImportError: DLL load failed: The specified module could not be found.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (Windows 10, 4GB Ram, 64-bit OS, x64 basedprocessor, Microsoft Visual C++ 2015-19 Re....installed):
- Mobile device (N/A):
- TensorFlow installed from (pip install tensorflow Pycharm Terminal):
- TensorFlow version: latest
- Python version: 3.7.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
Installation seems to work fine (successfully installed absl.....). But when I run import tensorflow as tf

**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow as tf

**Any other info / logs**
C:\Users\D'AVON\PycharmProjects\Test\venv\Scripts\python.exe C:/Users/D'AVON/PycharmProjects/Test/start.py
Traceback (most recent call last):
  File ""C:\Users\D'AVON\PycharmProjects\Test\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/D'AVON/PycharmProjects/Test/start.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\D'AVON\PycharmProjects\Test\venv\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\D'AVON\PycharmProjects\Test\venv\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""C:\Users\D'AVON\PycharmProjects\Test\venv\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe
  File ""C:\Users\D'AVON\PycharmProjects\Test\venv\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\D'AVON\PycharmProjects\Test\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\D'AVON\PycharmProjects\Test\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

Process finished with exit code 1

"
42439,Modil.fit() issue,"Can you provide me the full code?

I have this error:
""ValueError: Calling Model.fit in graph mode is not supported when the Model instance was constructed with eager mode enabled. Please construct your Model instance in graph mode or call Model.fit with eager mode enabled.""
When I tried to execute this code:

hist = model.fit(X_train, y_train, batch_size=16, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))

How can I exceed it?

tensorflow  2.3.0
Keras          2.4.3

The code of CNN modal:
[CNN modal.txt](https://github.com/tensorflow/tensorflow/files/5086399/CNN.modal.txt)
"
42438,No module named 'tensorflow.python.platform' ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary):binary
- TensorFlow version: Version 2.3
- Python version:3.8
- Installed using virtualenv? pip? conda?: in a conda eviroment with pip


I want to import tensorflow but everytime  I get 
tensorflow.python.platform import self_check
ModuleNotFoundError: No module named 'tensorflow.python.platform' 


**Provide the exact sequence of commands / steps that you executed before running into the problem**
I have already tried different tensorflow 2.x version and also completed uninstalled anconda and reinstall it. I also tried it in different enviorments. 
Also I had tensorflow running, but I update and also deleted some of the Microsoft Visual C++ Redistributable due to another problem. I did update and reinstalled all of the version but tensorflow is still not working.

Also I looked in the file and there is no python.plattform. Is there anyway to copy it or does anyone have some other solution?


"
42437,sparkfun-tensorflow-codelab,"Page: https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#3
Broken commands:

is: make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge micro_speech_bin
should be: make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge micro_speech_bin

is: test -f tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech.bin && echo ""Binary was successfully created"" || echo ""Binary is missing""
should be: test -f tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech.bin && echo ""Binary was successfully created"" || echo ""Binary is missing""

And so on. All command where is lite/experimental/micro/ > lite/micro/

Where is /AmbiqSuite-Rel2.0.0/ > /AmbiqSuite-Rel2.2.0/


And also ""Report a mistake"" link is broken.
"
42436,cudart64_101.dll and nvcuda.dll not found,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
42435,Keras `Layer.call` args signature inconsistent with actual code,"## URL(s) with the issue:

<https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call>

## Description of issue (what needs changing):

### Clear description

The `call` method is listed as `call(inputs, **kwargs)`, and documents
that `inputs` is an “Input tensor, or list/tuple of input tensors.” But
actual code usage shows that `call` may accept multiple positional
arguments depending on the actual layer implementation. For instance:

  - <https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_add_metric_method>
  - <https://github.com/tensorflow/models/blob/27bda1fc2d3557555ee8a48bbf1fb04f5c2f59e8/official/nlp/bert/bert_models.py#L68-L73>

This is confusing when reviewing code that defines a custom layer,
because the docs for `call` don’t reflect the actual usage.


### Submit a pull request?

> Are you planning to also submit a pull request to fix the issue?

No; I don’t have enough domain expertise to be confident about the
details.
"
42432,TFLiteConverter fails when converting a quantized model trained with distributed strategy,"most of the code is taken from tensorflow tutorials
running on Linux 18.04
TF version: v2.3.0-rc2-23-gb36436b087 2.3.0 (installed with pip)
python 3.7
CUDA 10.1

after training a quantized model, i'm trying to to convert to TFLite but it fails. same code with quant_enable=False works fine

**Standalone code to reproduce the issue**
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Input, Model, regularizers, models, optimizers, losses
import tensorflow_model_optimization as tfmot
from functools import partial
from pathlib import Path
from models.network_factory import get_network


def get_model():
    conv_params = {'padding': 'same', 'use_bias': False, 'strides': 2,
                   'kernel_regularizer': regularizers.l2(0.01)}

    inputs = Input(shape=(32, 32, 3))
    x = layers.Conv2D(16, 3, **conv_params)(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Conv2D(32, 3, **conv_params)(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Conv2D(64, 3, **conv_params)(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Flatten()(x)
    x = layers.Dropout(0.7)(x)
    x = layers.Dense(10, kernel_regularizer=regularizers.l2(0.01))(x)
    return Model(inputs=inputs, outputs=x, name=""SimpleNet"")


def apply_quantization_to_layer(layer):
    # default quantization
    if type(layer) in [layers.Conv2D, layers.DepthwiseConv2D,
                       layers.Dense, layers.BatchNormalization,
                       layers.Add, layers.ReLU]:
        return tfmot.quantization.keras.quantize_annotate_layer(layer)
    return layer


def quantize_model(in_model, clone_fn=apply_quantization_to_layer):
    annotated_model = models.clone_model(in_model, clone_function=partial(clone_fn))
    with tfmot.quantization.keras.quantize_scope():
        quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)
    return quant_aware_model


quant_enable = True
strategy = tf.distribute.MirroredStrategy()
print(f""\nnumber of GPUs: {strategy.num_replicas_in_sync}\n"")
with strategy.scope():
    model = get_model()
    model.summary()

    # Quantize the model.
    if quant_enable:
        # raise Exception(""need to debug distributed training with quantization"")
        model = quantize_model(model)

    model.compile(optimizer=optimizers.Adam(),
                  loss=losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])
num_replicas_in_sync = strategy.num_replicas_in_sync

batch_size, val_batch_size = 5, 5
ds_train = tf.data.Dataset.from_tensor_slices(([np.random.normal(size=(32, 32, 3)) for _ in range(100)],
                                               [np.random.randint(10) for _ in range(100)]))
ds_train = ds_train.batch(batch_size)
ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)
ds_test = tf.data.Dataset.from_tensor_slices(([np.random.normal(size=(32, 32, 3)) for _ in range(20)],
                                              [np.random.randint(10) for _ in range(20)]))
ds_test = ds_test.batch(val_batch_size)
ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)

history = model.fit(ds_train, epochs=4, validation_data=ds_test, verbose=1)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = False
tflite_model = converter.convert()"
42430,Pre-trained weights channel ordering clarification.,"Hello!

My question is about the pre-trained mobilenet-v1 model weights provided in tensorflow.keras.applications. When I use it in the TF default HWC format, everything seems to be fine, but when I set the keras backend to `'channels_first'` the weights doesn't seem to change. **Does this setting change the weight ordering, or does it only change the way the layers are interpreted?** 

I already asked it on Stackoverflow with the tensorflow TAG but no answers so far:
https://stackoverflow.com/q/63284543/10453391

If it doesn't change, what is the correct way to change the pre-trained weights ordering?` keras.utils.conv_utils.convert_kernel` is deprecated but TensorRT leans on channels first ordering heavly so I do not understand the lack of support for this.

This issue was already asked long ago but it is pretty outdated:
https://github.com/keras-team/keras/issues/3994

Thanks in advance!
"
42429,Why is Graph 4x slower than Eager on large model? (TF 2.3.0),"[Follow-up](https://github.com/tensorflow/tensorflow/issues/39665). Plots are from running TF on Colab GPU.

What's the deal? Isn't Graph supposed to be speed-optimized?

<img src=""https://user-images.githubusercontent.com/16495490/90391241-d8cca900-e09d-11ea-9233-ee9b8906105e.png"" width=""650"">

<hr>

<details>
  <summary><b>Test code</b></summary>

```python
import numpy as np
import tensorflow as tf
import random
import matplotlib.pyplot as plt
from termcolor import cprint
from time import time

from tensorflow.keras.layers import Input, Dense, Conv1D
from tensorflow.keras.layers import Dropout, GlobalAveragePooling1D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import tensorflow.keras.backend as K

# tf.compat.v1.disable_eager_execution()

###############################################################################
def reset_seeds(reset_graph_with_backend=None, verbose=1):
    if reset_graph_with_backend is not None:
        K = reset_graph_with_backend
        K.clear_session()
        tf.compat.v1.reset_default_graph()
        if verbose:
            print(""KERAS AND TENSORFLOW GRAPHS RESET"")

    np.random.seed(1)
    random.seed(2)
    tf.compat.v1.set_random_seed(3)
    if verbose:
        print(""RANDOM SEEDS RESET"")

print(""TF version: {}"".format(tf.__version__))
reset_seeds()

def timeit(func, iterations, *args, _verbose=0, **kwargs):
    times = []
    t0 = time()
    for _ in range(iterations):
        t1 = time()
        func(*args, **kwargs)
        times.append(time() - t1)
        print(end='.'*int(_verbose))
    print(""Time/iter: %.4f sec"" % ((time() - t0) / iterations))
    plt.stem(times)
    plt.ylim(0, 15)

###############################################################################
def make_model_large(batch_shape):
    ipt   = Input(batch_shape=batch_shape)
    x     = Conv1D(64,  400, strides=4, padding='valid')(ipt)
    x     = Conv1D(128, 200, strides=1, padding='valid')(x)
    for _ in range(40):
        x = Conv1D(256,  12, strides=1, padding='same')(x)
    x     = Conv1D(512,  20, strides=2, padding='valid')(x)
    x     = Conv1D(1028, 10, strides=2, padding='valid')(x)
    x     = Conv1D(256,   1, strides=1, padding='valid')(x)
    x     = GlobalAveragePooling1D()(x)
    x     = Dense(256, activation='relu')(x)
    x     = Dropout(0.5)(x)
    x     = Dense(128, activation='relu')(x)
    x     = Dense(64,  activation='relu')(x)
    out   = Dense(1,   activation='sigmoid')(x)
    model = Model(ipt, out)
    model.compile(Adam(lr=1e-4), 'binary_crossentropy')
    return model

def make_data(batch_shape):
    return np.random.randn(*batch_shape), \
           np.random.randint(0, 2, (batch_shape[0], 1))

def test_all():
    for model_fn, model_name, iters in zip(make_model_fns, model_names,
                                           iterations):
        for batch_shape, shape_name in zip(batch_shapes, shape_names):
            reset_seeds(reset_graph_with_backend=K)
            data = make_data(batch_shape)
            model = model_fn(batch_shape)

            model.train_on_batch(*data)
            timeit(model.train_on_batch, iters, *data, _verbose=1)
            
            cprint("">> {}, {} done <<\n"".format(model_name, shape_name), 'blue')
            del model
###############################################################################

batch_shape_large  = (32, 14000, 30)
batch_shape = batch_shape_large
model_fn = make_model_large

batch_shapes = batch_shape_large,
make_model_fns = make_model_large,
iterations = [200]
shape_names = [""Large data""]
model_names = [""Large model""]

test_all()
```

</details>"
42428,tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Linux Ubuntu 18.04:
- TensorFlow installed from binary:
- TensorFlow version : 2.3
- Python version: 3.7
- Installed using  pip:
- CUDA/cuDNN version: 10.1
- GPU model and memory: nvidia GTX 960 M 4GB 



**problem**
after installing TensorFlow object detection tf2  mentioned in the documentation and after I tried to run:
```python object_detection/builders/model_builder_tf2_test.py``` 
to test the installation I get this error log 

```
python object_detection/builders/model_builder_tf2_test.py
2020-08-17 13:10:21.225777: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Running tests under Python 3.7.8: /usr/bin/python3
[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model
2020-08-17 13:10:22.824358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-08-17 13:10:22.851969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:22.852268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:22.852290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:22.853853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:22.854843: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:22.855102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:22.856654: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:22.857867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:22.861423: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:22.861615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:22.861964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:22.862213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-17 13:10:22.862466: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-17 13:10:22.868196: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz
2020-08-17 13:10:22.868535: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56384f304fe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-17 13:10:22.868552: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-17 13:10:22.900165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:22.900633: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56384f398e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-17 13:10:22.900669: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0
2020-08-17 13:10:22.900888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:22.901165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:22.901207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:22.901232: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:22.901260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:22.901275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:22.901290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:22.901304: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:22.901319: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:22.901400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:22.901698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:22.901920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-17 13:10:22.901949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 0.25s
I0817 13:10:22.908455 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 0.25s
[  FAILED  ] ModelBuilderTF2Test.test_create_center_net_model
[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s
I0817 13:10:22.913183 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s
[       OK ] ModelBuilderTF2Test.test_create_experimental_model
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)
2020-08-17 13:10:22.999558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:22.999942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:22.999975: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.000010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.000030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.000048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.000067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.000085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.000102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.000169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.000491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.000758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)): 0.09s
I0817 13:10:23.004207 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)): 0.09s
[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)
2020-08-17 13:10:23.019474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.019798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:23.019830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.019888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.019906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.019922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.019939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.019955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.019972: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.020037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.020339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.020594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)): 0.02s
I0817 13:10:23.023944 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)): 0.02s
[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner
2020-08-17 13:10:23.038026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.038352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:23.038381: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.038411: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.038427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.038443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.038459: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.038475: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.038490: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.038550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.038828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.039064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s
I0817 13:10:23.041950 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s
[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul
2020-08-17 13:10:23.054686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.054981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:23.055017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.055045: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.055061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.055075: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.055090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.055104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.055118: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.055170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.055425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.055642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.02s
I0817 13:10:23.058731 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.02s
[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul
2020-08-17 13:10:23.071706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.072017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:23.072062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.072104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.072120: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.072135: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.072170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.072197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.072213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.072268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.072563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.072785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.02s
I0817 13:10:23.076769 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.02s
[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul
2020-08-17 13:10:23.096834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.097437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:23.097544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.097675: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.097731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.097811: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.097845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.097895: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.097944: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.098055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.098505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.098873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.03s
I0817 13:10:23.103684 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.03s
[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul
2020-08-17 13:10:23.123831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.124163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:23.124220: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.124245: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.124258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.124268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.124279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.124290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.124321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.124407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.124841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.125292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.02s
I0817 13:10:23.128272 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.02s
[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul
[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config
2020-08-17 13:10:23.142464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.142849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:23.142915: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.142995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.143023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.143060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.143087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.143097: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.143108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.143195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.143486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.143737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.02s
I0817 13:10:23.146383 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.02s
[  FAILED  ] ModelBuilderTF2Test.test_create_rfcn_model_from_config
[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config
2020-08-17 13:10:23.153174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.153561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:23.153604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.153644: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.153656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.153666: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.153676: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.153707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.153718: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.153781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.154044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.154298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.01s
I0817 13:10:23.156916 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.01s
[  FAILED  ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config
[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config
2020-08-17 13:10:23.163432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.163782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s
2020-08-17 13:10:23.163826: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-17 13:10:23.163880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-17 13:10:23.163893: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-17 13:10:23.163923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-17 13:10:23.163949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-17 13:10:23.163994: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-17 13:10:23.164006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-17 13:10:23.164086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.164724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-17 13:10:23.164977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 0.01s
I0817 13:10:23.167692 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 0.01s
[  FAILED  ] ModelBuilderTF2Test.test_create_ssd_models_from_config
[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s
I0817 13:10:23.169691 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s
[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update
[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s
I0817 13:10:23.171179 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s
[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold
[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s
I0817 13:10:23.171630 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s
[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto
[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s
I0817 13:10:23.173022 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s
[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size
[ RUN      ] ModelBuilderTF2Test.test_session
[  SKIPPED ] ModelBuilderTF2Test.test_session
[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s
I0817 13:10:23.174277 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s
[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor
[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s
I0817 13:10:23.174678 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s
[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture
[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s
I0817 13:10:23.175496 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s
[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor
======================================================================
ERROR: test_create_center_net_model (__main__.ModelBuilderTF2Test)
test_create_center_net_model (__main__.ModelBuilderTF2Test)
Test building a CenterNet model from proto txt.
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""object_detection/builders/model_builder_tf2_test.py"", line 224, in test_create_center_net_model
    model = model_builder.build(config, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 956, in _build_center_net_model
    center_net_config.feature_extractor)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1026, in _build_center_net_feature_extractor
    bgr_ordering=feature_extractor_config.bgr_ordering
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/models/center_net_resnet_feature_extractor.py"", line 145, in resnet_v2_101
    bgr_ordering=bgr_ordering
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/models/center_net_resnet_feature_extractor.py"", line 47, in __init__
    bgr_ordering=bgr_ordering)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/center_net_meta_arch.py"", line 71, in __init__
    super(CenterNetFeatureExtractor, self).__init__(name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_faster_rcnn_from_config_with_crop_feature(True) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(True) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(True)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py"", line 267, in bound_param_test
    test_method(self, testcase_params)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 292, in test_create_faster_rcnn_from_config_with_crop_feature
    _ = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 789, in _build_faster_rcnn_model
    **common_kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 508, in __init__
    ], name='FirstStageRPNFeatures'))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py"", line 117, in __init__
    name=name, autocast=False)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_faster_rcnn_from_config_with_crop_feature(False) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(False) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py"", line 267, in bound_param_test
    test_method(self, testcase_params)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 292, in test_create_faster_rcnn_from_config_with_crop_feature
    _ = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 789, in _build_faster_rcnn_model
    **common_kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 508, in __init__
    ], name='FirstStageRPNFeatures'))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py"", line 117, in __init__
    name=name, autocast=False)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_faster_rcnn_model_from_config_with_example_miner (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_model_from_config_with_example_miner (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 271, in test_create_faster_rcnn_model_from_config_with_example_miner
    model = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 789, in _build_faster_rcnn_model
    **common_kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 508, in __init__
    ], name='FirstStageRPNFeatures'))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py"", line 117, in __init__
    name=name, autocast=False)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul(use_matmul_crop_and_resize=False, enable_mask_prediction=False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 789, in _build_faster_rcnn_model
    **common_kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 508, in __init__
    ], name='FirstStageRPNFeatures'))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py"", line 117, in __init__
    name=name, autocast=False)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul(use_matmul_crop_and_resize=True, enable_mask_prediction=False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 789, in _build_faster_rcnn_model
    **common_kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 508, in __init__
    ], name='FirstStageRPNFeatures'))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py"", line 117, in __init__
    name=name, autocast=False)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul(use_matmul_crop_and_resize=False, enable_mask_prediction=True)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 789, in _build_faster_rcnn_model
    **common_kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 508, in __init__
    ], name='FirstStageRPNFeatures'))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py"", line 117, in __init__
    name=name, autocast=False)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul(use_matmul_crop_and_resize=True, enable_mask_prediction=True)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 789, in _build_faster_rcnn_model
    **common_kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 508, in __init__
    ], name='FirstStageRPNFeatures'))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py"", line 117, in __init__
    name=name, autocast=False)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_rfcn_model_from_config (__main__.ModelBuilderTF2Test)
test_create_rfcn_model_from_config (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 282, in test_create_rfcn_model_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 764, in _build_faster_rcnn_model
    **common_kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/rfcn_meta_arch.py"", line 248, in __init__
    output_final_box_features=output_final_box_features)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 508, in __init__
    ], name='FirstStageRPNFeatures'))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py"", line 117, in __init__
    name=name, autocast=False)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_ssd_fpn_model_from_config (__main__.ModelBuilderTF2Test)
test_create_ssd_fpn_model_from_config (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 220, in test_create_ssd_fpn_model_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 375, in _build_ssd_model
    is_training=is_training)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 350, in _build_ssd_feature_extractor
    return feature_extractor_class(**kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py"", line 317, in __init__
    name=name)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py"", line 120, in __init__
    name=name)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py"", line 194, in __init__
    super(SSDKerasFeatureExtractor, self).__init__(name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

======================================================================
ERROR: test_create_ssd_models_from_config (__main__.ModelBuilderTF2Test)
test_create_ssd_models_from_config (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py"", line 212, in test_create_ssd_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 375, in _build_ssd_model
    is_training=is_training)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py"", line 350, in _build_ssd_feature_extractor
    return feature_extractor_class(**kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py"", line 88, in __init__
    name=name)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py"", line 194, in __init__
    super(SSDKerasFeatureExtractor, self).__init__(name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 256, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2646, in default_variable_creator_v2
    shape=shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1652, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1499, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 275, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 300, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 97, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 539, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid

----------------------------------------------------------------------
Ran 20 tests in 0.516s

FAILED (errors=11, skipped=1)

```
also even when I tried to run inside docker container using the build instruction in the documentation I get the same message 
```tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid```

I tried to reinstall cuda and nvidia drivers but with the same issue 

"
42427,Failed to build v2.3.0 from source in debug mode,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.3.0
- Python version: Python 3.6.9
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 10.2/NA
- GPU model and memory:
RTX 2080 Ti 11G


**Describe the problem**
I built v2.3.0 debug version with
```
bazel build --config=dbg --strip never //tensorflow/compiler/mlir/...
```

while bazel complains

```
ERROR: /workspace/tensorflow/tensorflow/compiler/mlir/BUILD:139:1: Linking of rule '//tensorflow/compiler/mlir:tf-mlir-translate' failed (Exit 1)                               
tensorflow/core/kernels/data/experimental/io_ops.cc:120: error: undefined reference to 'tensorflow::data::experimental::SaveDatasetOp::kFileFormatVersion'                      
tensorflow/core/kernels/data/experimental/io_ops.cc:234: error: undefined reference to 'tensorflow::data::experimental::LoadDatasetOp::kCompression'                            
tensorflow/core/kernels/data/experimental/io_ops.cc:234: error: undefined reference to 'tensorflow::data::experimental::LoadDatasetOp::kReaderFunc'                             
tensorflow/core/kernels/data/experimental/io_ops.cc:234: error: undefined reference to 'tensorflow::data::experimental::LoadDatasetOp::kReaderFuncTarguments'                   
tensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kCompression'         
tensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kReaderFunc'          
tensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kShardFunc'           
tensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kReaderFuncTarguments'
tensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kShardFuncTarguments' 
tensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:696: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kFileFormatVersion'   
collect2: error: ld returned 1 exit status                                                                                                                                      
INFO: Elapsed time: 1469.870s, Critical Path: 372.47s                                                                                                                           
INFO: 7815 processes: 7815 local.                                                                                                                                               
FAILED: Build did NOT complete successfully                                                                                                                                     
```

On contrast, I can build successfully with 

```
bazel build //tensorflow/compiler/mlir/...
```
"
42426,Full integer Quantization of SSD-Mobilenet V2 doesn't work,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary):  binary
- Tensorflow version (commit SHA if source): '2.4.0-dev20200805'
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arm Mbed OS

**Describe the problem**

I need to convert a SSD-Mobilenet V2 model for an 8-bit microcontroller which runs Mbed OS and would like to use optimized CMSIS-NN kernels. Model was trained and exported with [Tensorflow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection). 

However, the saved and exported model cannot be converted to TfLite. Truncated error message is as follows: 
```
Exception: <unknown>:0: error: loc(callsite(callsite(""Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/SortByField_1/Size@__inference___call___8168"" at ""StatefulPartitionedCall@__inference_signature_wrapper_9547"") at ""StatefulPartitionedCall"")): 'tf.Size' op is neither a custom op nor a flex op
```

**Please provide the exact sequence of commands/steps when you ran into the problem**

Code to replicate the problem can be found here: 
https://colab.research.google.com/drive/1vR6L0uUQQb3PTL8Ze0keIVGjSLusa_WI?usp=sharing"
42425,Convert savedmodel to h5 Keras format - AttributeError: 'AutoTrackable' object has no attribute 'summary',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.1

**Describe the current behavior**
I used Google AI-Platform to train a model for object detection. The result is a model in the savedmodel format. I wan't to convert it to h5 Keras format so I can import into Matlab. 

**Standalone code to reproduce the issue**
Here is the output folder directly from the bucket:

https://drive.google.com/file/d/1mgVGG_WNGC9gxZSgn1G2_YdQTVkJJInM/view?usp=sharing


**Other info / logs** 

I tried to do this:

`New_Model = load_model('model')`, or this `New_Model = tf.keras.models.load_model('model')` or this `New_Model = tf.saved_model.load(export_dir='model')` and lastly this `New_Model.summary()` and I always get the same error: 

`AttributeError: 'AutoTrackable' object has no attribute 'summary'`

If the model would had loaded correctly I would try to do `tf.keras.models.save_model(New_Model, 'New_Model.h5')`

Which will end up throwing this error:

`AttributeError: 'AutoTrackable' object has no attribute '_is_graph_network'`

Please help, as I said the model is saved in the savedmodel format, so I guess every piece needed is there

Complete log for summary:

```
2020-08-17 01:48:46.011995: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-08-17 01:48:46.016769: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-08-17 01:48:53.754437: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2020-08-17 01:48:53.758821: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-17 01:48:53.780897: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: EC2347417W3
2020-08-17 01:48:53.785702: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: EC2347417W3
2020-08-17 01:48:53.789520: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-17 01:48:53.820077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16799c381d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-17 01:48:53.832027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/conv2d/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/conv2d/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/conv2d/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/conv2d/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet50/batch_normalization/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
Traceback (most recent call last):
  File ""savedmodel_to_h5.py"", line 15, in <module>
    New_Model.summary()
AttributeError: 'AutoTrackable' object has no attribute 'summary'

```"
42424,```tf.stack``` returns different shapes when run in eager and graph mode,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.3
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
```tf.stack(list(np.ones([2,0,3]))).shape```
returns EagerTensor with shape [2,0]
**Describe the expected behavior**
```tf.stack(list(np.ones([2,0,3]))).shape```
returns EagerTensor with shape [2,0,3] which same as graph mode

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Eager mode:
``` python
import tensorflow as tf
print(tf.stack(list(np.ones([2,0,3]))).shape)
tf.compat.v1.disable_eager_execution()
print(tf.stack(list(np.ones([2,0,3]))).shape)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42423,`tf.data.experimental.sample_from_datasets` imports all the dataset into GPU memory,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes
-   **OS Platform and Distribution**: Ubuntu 18.04.5 LTS 
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: 2.3.0
-   **Python version**: 3.7.3
-   **CUDA/cuDNN version**: CUDA 10.1 & cuDNN 7.6.5
-   **GPU model and memory**: NVIDIA RTX 2070 8GB (Single GPU)

### Describe the problem
I was using `tf.data` API to build an input pipeline for my inbalanced dataset. So I used `tf.data.experimental.sample_from_datasets` function as [the tutorial](https://tensorflow.google.cn/tutorials/structured_data/imbalanced_data?hl=en#using_tfdata) recommended. 

My dataset's shape is shown below:
```python
>>> print(x.shape)
(63, 1330, 3001, 8)
>>> print(y.shape)
(63, 5)
```

Before I use `tf.data.experimental.sample_from_datasets` function. My system memory usage was approximately 9 GB, and **GPU Memory Usage** only 15 MiB /  7949MiB . Which I had did before `sample_from_datasets` was:
```python
import tensorflow as tf
import numpy as np
from sklearn.model_selection import ShuffleSplit

# load dataset from files
x = np.load('result/experiment_2_0816/x.npy')
y = np.load('result/experiment_2_0816/y.npy')

# there is five classes
A = []
B = []
C = []
D = []
E = []

# distribute dataset by labels
# A,B,C,D,E are just indices of the data (not slices)
for i in range(63):
    if y[i].argmax() == 0:
        A.append(i)
    elif y[i].argmax() == 1:
        B.append(i)
    elif y[i].argmax() == 2:
        C.append(i)
    elif y[i].argmax() == 3:
        D.append(i)
    elif y[i].argmax() == 4:
        E.append(i) 

# split validation set
A = next(ShuffleSplit(n_splits=1, test_size=0.1).split(A))
B = next(ShuffleSplit(n_splits=1, test_size=0.1).split(B))
C = next(ShuffleSplit(n_splits=1, test_size=0.1).split(C))
D = next(ShuffleSplit(n_splits=1, test_size=0.1).split(D))
E = next(ShuffleSplit(n_splits=1, test_size=0.1).split(E))

def make_dataset(features, labels):
    ds = tf.data.Dataset.from_tensor_slices((features, labels)).cache()
    ds = ds.shuffle(100).repeat()
    return ds

# using `tf.data.Dataset.from_tensor_slices` function to build pipelines
A_train = make_dataset(x[A[0]], y[A[0]])
B_train = make_dataset(x[B[0]], y[B[0]])
C_train = make_dataset(x[C[0]], y[C[0]])
D_train = make_dataset(x[D[0]], y[D[0]])
E_train = make_dataset(x[E[0]], y[E[0]])
A_val = make_dataset(x[A[1]], y[A[1]])
B_val = make_dataset(x[B[1]], y[B[1]])
C_val = make_dataset(x[C[1]], y[C[1]])
D_val = make_dataset(x[D[1]], y[D[1]])
E_val = make_dataset(x[E[1]], y[E[1]])

# collect garbage
del x,y
import gc
gc.collect()
```

However, once we execute
```python
resampled_train = tf.data.experimental.sample_from_datasets([A_train, B_train, C_train, D_train, E_train], weights=[0.84, 3.15, 0.9, 0.54782609, 1.8])
resampled_val = tf.data.experimental.sample_from_datasets([A_val, B_val, C_val, D_val, E_val], weights=[0.84, 3.15, 0.9, 0.54782609, 1.8])
```
the **GPU memory usage** suddenly rise to **7491MiB /  7949MiB **. The function loaded all the data into GPU memory, which was unnecessary and waste of GPU resources. Here we were doing nothing about Neural Network Models. The model hasn't been created at all.

So I wonder whether it is a bug or necessary step to load data into GPU. Or I've done some steps wrong?"
42422,fp16/bf16 is much slower than fp32,"I tested `fp16` and `bf16` training performance on `Intel(R) Xeon(R) Gold 6242 CPU @ 2.80GHz` CPU, which I guess does not support `fp16` or `bf16` computation, however, the training went through without throwing me any errors, but the performance was much worse than `fp32`. I was wondering how TensorFlow handles such case, i.e. running `fp16` or `bf16` on a `Intel(R) Xeon(R) Gold 6242 CPU @ 2.80GHz` CPU."
42421,Segmentation fault in tf.image.combined_non_max_suppression,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-38999-g56548c2425 2.4.0-dev20200811
- Python version: 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
A segfault occurs when `max_total_size` is large.  If I execute the same input repetitively, I get different errors in different executions such as `Segmentation Fault`, `what():  vector::_M_fill_insert`, and `what():  terminate called recursively`.

**Describe the expected behavior**
I would expect a runtime exception in python rather than a segfault.  

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
tf.image.combined_non_max_suppression(boxes=tf.ones((11,8,2,4)), scores=tf.ones((11,8,2)), max_output_size_per_class=5, max_total_size=311452676677046672)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Segmentation fault (core dumped)
```
```
what():  terminate called recursively
```
```
what():  vector::_M_fill_insert
```"
42420,Error in Validation split percentage - Image Classification tutorial,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):
Under Load using Keras.preprocessing > Create Dataset, the percentage under training_ds for validation_split is set to 0.2. I believe is supposed to be 0.8.


### Clear description

When you used 0.8 on the number of images in the directory, it will result to 2936, but 0.2 is way smaller. 

"
42419,"parallel_for: No converter defined for UniqueWithCounts, SegmentSum, Range, Where, Tile in tf.vectorized_map()","- **TensorFlow version tested:** _(all installed using binary)_
    - TensorFlow 2.3.0
    - TensorFlow 2.2.0
    - TensorFlow 1.15.0

- **Issue:** I'm trying to decrease the latency of `my_func()` (code below) by replacing `tf.map_fn()` with `tf.vectorized_map()`. But it seems like not all ops are ported in as of now. Any idea when above mentioned ops will be available for vectorized_map? Feel free to suggest any alternative.

- **Code:** 
```python
def my_func(tensor_x):
    label_tensor = tensor_x[:, 0]
    score_tensor = tensor_x[:, 1]
    unique_labels, unique_labels_idx, unique_labels_counts = tf.unique_with_counts(label_tensor)
    score_sum_flatten = tf.math.segment_sum(score_tensor, unique_labels_idx)
    repeated_label_tensor = tf.repeat(unique_labels, unique_labels_counts)
    repeated_score_tensor = tf.repeat(score_sum_flatten, unique_labels_counts)
    label_score_tensor = tf.stack((repeated_label_tensor, repeated_score_tensor), axis=1)
    label_score_tensor = tf.reshape(label_score_tensor, shape=tensor_x.shape)
    return label_score_tensor
```
- **Expected behavior with tf.map_fn():** 
```python
>> input_tensor = tf.constant([[[2.0, 0.5], [2.0, 0.5], [3.0, 0.4000000059604645], [1.0, 0.10000000149011612]], [[4.0, 0.800000011920929], [2.0, 0.5], [1.0, 0.5], [1.0, 0.5]], [[4.0, 0.800000011920929], [3.0, 0.699999988079071], [3.0, 0.30000001192092896], [1.0, 0.10000000149011612]]])
>> tf.map_fn(my_func, input_tensor)

<tf.Tensor: shape=(3, 4, 2), dtype=float32, numpy=
array([[[2. , 1. ],
        [2. , 1. ],
        [3. , 0.4],
        [1. , 0.1]],

       [[4. , 0.8],
        [2. , 0.5],
        [1. , 1. ],
        [1. , 1. ]],

       [[4. , 0.8],
        [3. , 1. ],
        [3. , 1. ],
        [1. , 0.1]]], dtype=float32)>
```

- **TF 2.3.0 [WARNING -- no speedup]:** Using tf.vectorized_map() with TF 2.3.0 I get following warnings and I'm not getting required speedup.
```python
>> tf.vectorized_map(my_func, input_tensor)

WARNING:tensorflow:Using a while_loop for converting UniqueWithCounts
WARNING:tensorflow:Using a while_loop for converting SegmentSum
WARNING:tensorflow:Using a while_loop for converting Range
WARNING:tensorflow:Using a while_loop for converting Where
WARNING:tensorflow:Using a while_loop for converting Tile
WARNING:tensorflow:Using a while_loop for converting Range
WARNING:tensorflow:Using a while_loop for converting Where
WARNING:tensorflow:Using a while_loop for converting Tile

<tf.Tensor: shape=(3, 4, 2), dtype=float32, numpy=
array([[[2. , 1. ],
        [2. , 1. ],
        [3. , 0.4],
        [1. , 0.1]],

       [[4. , 0.8],
        [2. , 0.5],
        [1. , 1. ],
        [1. , 1. ]],

       [[4. , 0.8],
        [3. , 1. ],
        [3. , 1. ],
        [1. , 0.1]]], dtype=float32)>
```

- **TF2.2.0/TF1.15.0 [ERROR -- not working]:** tf.vectorized_map() fails on TF 2.2.0 and TF 1.15.0 since there is no `fallback_to_while_loop=True` argument available on previous versions of TF.
```python
>> tf.vectorized_map(my_func, input_tensor)

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-11-9f5af9e23eb8> in <module>
----> 1 tf.vectorized_map(sum_me, sorted_tensor)

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in vectorized_map(fn, elems)
    405   if batch_size is None:
    406     batch_size = array_ops.shape(first_elem)[0]
--> 407   return pfor(loop_fn, batch_size)

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in pfor(loop_fn, iters, parallel_iterations)
    196       def_function.run_functions_eagerly(False)
    197     f = def_function.function(f)
--> 198   outputs = f()
    199   if functions_run_eagerly is not None:
    200     def_function.run_functions_eagerly(functions_run_eagerly)

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--> 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    625       # This is the first call of __call__, so we have to initialize.
    626       initializers = []
--> 627       self._initialize(args, kwds, add_initializers_to=initializers)
    628     finally:
    629       # At this point we know that the initialization is complete (or less

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    504     self._concrete_stateful_fn = (
    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 506             *args, **kwds))
    507 
    508     def invalid_creator_scope(*unused_args, **unused_kwds):

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2444       args, kwargs = None, None
   2445     with self._lock:
-> 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2447     return graph_function
   2448 

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2775 
   2776       self._function_cache.missed.add(call_context_key)
-> 2777       graph_function = self._create_graph_function(args, kwargs)
   2778       self._function_cache.primary[cache_key] = graph_function
   2779       return graph_function, args, kwargs

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2665             arg_names=arg_names,
   2666             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2667             capture_by_value=self._capture_by_value),
   2668         self._function_attributes,
   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--> 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    440         # the function a weak reference to itself to avoid a reference cycle.
--> 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    442     weak_wrapped_fn = weakref.ref(wrapped_fn)
    443 

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:
/Users/snehal/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:183 f  *
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    /Users/snehal/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:269 _pfor_impl  **
        outputs.append(converter.convert(loop_fn_output))
    /Users/snehal/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1284 convert
        output = self._convert_helper(y)
    /Users/snehal/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1464 _convert_helper
        (y_op.type, y_op, converted_inputs))

    ValueError: No converter defined for UniqueWithCounts
    name: ""loop_body/UniqueWithCounts""
    op: ""UniqueWithCounts""
    input: ""loop_body/strided_slice""
    attr {
      key: ""T""
      value {
        type: DT_FLOAT
      }
    }
    attr {
      key: ""out_idx""
      value {
        type: DT_INT32
      }
    }
    
    inputs: [WrappedTensor(t=<tf.Tensor 'loop_body/strided_slice/pfor/StridedSlice:0' shape=(3, 4) dtype=float32>, is_stacked=True, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower
```"
42418,Tensorflow 2.3 modules not found,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Windows 10
- TensorFlow installed from conda
- TensorFlow version: 2.3
- Python version: 3.7
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: None
- GPU model and memory: None



**Describe the problem**

When installing Tensorflow via conda to my machine, Keras fails to load models properly, returning KeyError 0.  Conda installs Tensorflow 2.1, and it was recommended that I upgrade to the lastest tf/keras versions, which I did via pip:
`pip install tensorflow --upgrade`

However, this then produced the following errors when I attempted to run a file which imported tensorflow:
`Traceback (most recent call last):
  File ""C:\Users\Thomas DeWitt\Anaconda3\envs\tf\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bot_2.py"", line 12, in <module>
    import tensorflow as tf
  File ""C:\Users\Thomas DeWitt\Anaconda3\envs\tf\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Thomas DeWitt\Anaconda3\envs\tf\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""C:\Users\Thomas DeWitt\Anaconda3\envs\tf\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe
  File ""C:\Users\Thomas DeWitt\Anaconda3\envs\tf\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Thomas DeWitt\Anaconda3\envs\tf\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Thomas DeWitt\Anaconda3\envs\tf\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found.

Failed to load the native TensorFlow runtime.`

I've uninstalled Tensorflow and reinstalled it twice, once with pip and once with conda.  The pip install returns a warning about the assorted .exe files not being associated with PATH:
`WARNING: The scripts estimator_ckpt_converter.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\Users\Thomas DeWitt\AppData\Roaming\Python\Python37\Scripts' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.`

The conda install works, but again fails to load models with tf.keras.models.load_model('model')

I'm not sure if this is a problem on my machine or with the latest Tensorflow release, as I usually operate in Colab and I've never needed to run Tensorflow locally before."
42417,tf.keras.layers.Conv1D fails for RaggedTensor input,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS, probably not relevant
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
I'm not sure if this is a bug or feature request, but I would expect/hope the below to work.

tf.keras.layers.Conv1D fails on a batch of type `tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor`. Specifically it appears to fail on the `convert_to_tensor` step in the same manner as in https://github.com/tensorflow/tensorflow/issues/37351.

**Describe the expected behavior**

Ideally the convolution would execute as expected and produce a RaggedTensor output that reflects the shape of the input RaggedTensor and the convolution applied.

To get some insight on my use case, I am working on an unsupervised time series classification problem where the length of each input could be a giveaway and provide useless downstream embeddings. Specifically, I am using dilated convolutions to compress information about the series and using final pooling layers over the temporal dimension to produce equal size embeddings from unequal length input tensors. My first implementation used Conv1D layers with a batch size of 1, and runs fine, except that using batch size 1 limits training speed and the size of the dataset I can work with. I was hoping RaggedTensor would allow me to scale up my implementation. I suspect the lack of non-uniform sizes would preclude a GPU implementation, but I believe even using simple batching would provide a much needed speed up.

I would also be open to workarounds, if one knows of a better way to formulate this. Perhaps there is a way to operate on the padded tensor and then trim off the Conv outputs that had access to the padding as part of their input on an element-by-element basis within the batch (probably as a function of each of their true length passed in parallel)?

**Standalone code to reproduce the issue**
```
import numpy as np
import tensorflow as tf
x = tf.ragged.constant([np.random.random(10+x) for x in range(5)])
x = tf.expand_dims(x, -1)
tf.keras.layers.Conv1D(7, 3)(x)
```

**Other info / logs**
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-209-09f9a8bce491> in <module>
      4 x = tf.ragged.constant([np.random.random(10+x) for x in range(5)])
      5 x = tf.expand_dims(x, -1)
----> 6 tf.keras.layers.Conv1D(7, 3)(x)

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    983 
    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):
--> 985           outputs = call_fn(inputs, *args, **kwargs)
    986 
    987         if self._activity_regularizer:

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py in call(self, inputs)
    245       inputs = array_ops.pad(inputs, self._compute_causal_padding(inputs))
    246 
--> 247     outputs = self._convolution_op(inputs, self.kernel)
    248 
    249     if self.use_bias:

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    200     try:
--> 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py in convolution_v2(input, filters, strides, padding, data_format, dilations, name)
   1016       data_format=data_format,
   1017       dilations=dilations,
-> 1018       name=name)
   1019 
   1020 

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py in convolution_internal(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)
   1146           data_format=data_format,
   1147           dilations=dilations,
-> 1148           name=name)
   1149     else:
   1150       if channel_index == 1:

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    200     try:
--> 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    572                   func.__module__, arg_name, arg_value, 'in a future version'
    573                   if date is None else ('after %s' % date), instructions)
--> 574       return func(*args, **kwargs)
    575 
    576     doc = _add_deprecated_arg_value_notice_to_docstring(

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    572                   func.__module__, arg_name, arg_value, 'in a future version'
    573                   if date is None else ('after %s' % date), instructions)
--> 574       return func(*args, **kwargs)
    575 
    576     doc = _add_deprecated_arg_value_notice_to_docstring(

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py in conv1d(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)
   1887           data_format=data_format,
   1888           dilations=dilations,
-> 1889           name=name)
   1890     else:
   1891       result = squeeze_batch_dims(

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)
    943           input, filter, strides=strides, use_cudnn_on_gpu=use_cudnn_on_gpu,
    944           padding=padding, explicit_paddings=explicit_paddings,
--> 945           data_format=data_format, dilations=dilations, name=name, ctx=_ctx)
    946     except _core._SymbolicException:
    947       pass  # Add nodes to the TensorFlow graph.

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py in conv2d_eager_fallback(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)
   1023         ""'conv2d' Op, not %r."" % dilations)
   1024   dilations = [_execute.make_int(_i, ""dilations"") for _i in dilations]
-> 1025   _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter], ctx)
   1026   (input, filter) = _inputs_T
   1027   _inputs_flat = [input, filter]

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in args_to_matching_eager(l, ctx, default_dtype)
    265         dtype = ret[-1].dtype
    266   else:
--> 267     ret = [ops.convert_to_tensor(t, dtype, ctx=ctx) for t in l]
    268 
    269   # TODO(slebedev): consider removing this as it leaks a Keras concept.

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in <listcomp>(.0)
    265         dtype = ret[-1].dtype
    266   else:
--> 267     ret = [ops.convert_to_tensor(t, dtype, ctx=ctx) for t in l]
    268 
    269   # TODO(slebedev): consider removing this as it leaks a Keras concept.

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1497 
   1498     if ret is None:
-> 1499       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1500 
   1501     if ret is NotImplemented:

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    336                                          as_ref=False):
    337   _ = as_ref
--> 338   return constant(v, dtype=dtype, name=name)
    339 
    340 

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)
    262   """"""
    263   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 264                         allow_broadcast=True)
    265 
    266 

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    273       with trace.Trace(""tf.constant""):
    274         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
--> 275     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    276 
    277   g = ops.get_default_graph()

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    298 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):
    299   """"""Implementation of eager constant.""""""
--> 300   t = convert_to_eager_tensor(value, ctx, dtype)
    301   if shape is None:
    302     return t

~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
     96       dtype = dtypes.as_dtype(dtype).as_datatype_enum
     97   ctx.ensure_initialized()
---> 98   return ops.EagerTensor(value, ctx.device_name, dtype)
     99 
    100 

ValueError: TypeError: object of type 'RaggedTensor' has no len()
```"
42412,InternalError : failed to call ThenRNNBackward... on version 2.3 but not 2.1,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:/
- TensorFlow installed from (source or binary): Installed with pip
- TensorFlow version (use command below): tensorflow 2.3
- Python version: 3.6
- Bazel version (if compiling from source): /
- GCC/Compiler version (if compiling from source): /
- CUDA/cuDNN version: CUDA 10.1 and CuDnn 7.5
- GPU model and memory: GeForce GTX 1070 with 6,2Gb memory

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

In march, i coded the Tacotron-2 model with tensorflow 2.1 and trained it without issue (but some strange thing but not the subject of this issue)
Now i want to retrain it with version 2.3 and at random step (less than 250), i have an error : « InternalError : failed to call ThenRnnBackward with model config ... »

Today i downgraded tensorflow to version 2.1 and run the training loop and i am actually at step 1500 without the issue

I also tried to downgrade at version 2.2 but the error still occurs

**Describe the expected behavior**

**Standalone code to reproduce the issue**

Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

I can’t share the whole code because it’s too big (part of a big project) but here is a small description : 
- Model is tacotron-2 implementation inspired from pytorch NVIDIA so it has 1 BidirectionalLSTM in the encoder and 2 LSTMCell in the decoder
- I use K.rnn to use a custom decoder step
- The error occurs at the tape.gradient() call
- I use custom training loop where i split the whole input frames into sub frames (because memory issue) so for a mel-spec of 400 frames, i make 8 optimization step of 50 frames (with passing the last LSTM-states to the next 50-frames block optimization step (it’s really strange that my 6Gb memory only accepts 50 frames with batch_size 16 (75 frames run OOM))

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The model is actually training but i will share my training loop code and anything other you want when it’s finished... i can also check my CuDnn version but i’m pretty sure it’s 7.5
"
42410,"ConverterError: input resource[0] expected type resource != float, the type of while_model_embed_gather_resource_0[0]","**System information**
- OS Platform and Distribution: Linux archlinux 5.8.1-arch1-1 x86_64 GNU/Linux (using Anaconda3)
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): >=2.2.0


**Command used to run the converter or code if you’re using the Python API**

```python
import tensorflow as tf
print(tf.__version__)


class Embed(tf.keras.layers.Layer):
    def __init__(self, vocab_size, embed_dim, **kwargs):
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim
        super().__init__(**kwargs)

    def build(self, input_shape):
        self.embeddings = self.add_weight(
            ""weight"",
            shape=[self.vocab_size, self.embed_dim],
            initializer=tf.keras.initializers.GlorotNormal(),
        )

    def call(self, inputs):
        return tf.gather(self.embeddings, tf.cast(inputs, tf.int32))


class Model(tf.keras.Model):
    def __init__(self, vocab_size, embed_dim, **kwargs):
        super().__init__(**kwargs)
        self.embed = Embed(vocab_size, embed_dim)
        self.dense = tf.keras.layers.Dense(350)

    def _build(self):
        self(tf.keras.Input([None], dtype=tf.int32))

    def call(self, inputs, training=False):
        outputs = self.embed(inputs, training=training)
        return self.dense(outputs, training=training)


model = Model(29, 320)
model._build()
model.summary()


@tf.function(
    input_signature=[
        tf.TensorSpec([1, None], dtype=tf.int32)
    ]
)
def func(inputs):
    i = tf.constant(0, dtype=tf.int32)
    T = tf.constant(100, dtype=tf.int32)

    def _cond(i, T): return tf.less(i, T)

    def _body(i, T):
        _ = model(inputs)
        return i + 1, T

    _, _ = tf.while_loop(
        _cond,
        _body,
        loop_vars=(i, T),
        shape_invariants=(
            tf.TensorShape([]),
            tf.TensorShape([])
        )
    )

    return inputs


print(func(tf.zeros([1, 100], tf.int32)))

concrete_func = func.get_concrete_function()
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
tflite = converter.convert()
```

**The output from the converter invocation**

[log.txt](https://github.com/tensorflow/tensorflow/files/5080482/log.txt)

Short output:

```
Traceback (most recent call last):
  File ""test.py"", line 77, in <module>
    tflite = converter.convert()
  File ""/home/nlhuy/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 1076, in convert
    return super(TFLiteConverterV2, self).convert()
  File ""/home/nlhuy/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 899, in convert
    return super(TFLiteFrozenGraphConverterV2,
  File ""/home/nlhuy/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 629, in convert
    result = _toco_convert_impl(
  File ""/home/nlhuy/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 569, in toco_convert_impl
    data = toco_convert_protos(
  File ""/home/nlhuy/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 202, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: input resource[0] expected type resource != float, the type of while_model_embed_gather_resource_0[0]
	In {{node while/model/embed/Gather}}
```

**Failure details**
If I don't use `tf.while_loop`, the conversion works. However, it doesn't if I use `tf.gather` inside `tf.while_loop`

**Any other info / logs**
This bug also occurs in `tf.keras.layers.Embedding`"
42409,Cannot initialize variables on GPU with keras?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.1 LTS
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.2
- CUDA/cuDNN version: 10.2/7.4.2
- GPU model and memory: Tesla V100-PCIe 32GB

**Describe the current behavior**
When I call `model.fit()` for a Keras model on the GPU, I get the following error message:
```python
InvalidArgumentError: Cannot assign a device for operation quantum_circuit/quantum_layer/ReadVariableOp: Could not satisfy explicit device specification '' because the node {{colocation_node quantum_circuit/quantum_layer/ReadVariableOp}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. 
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU XLA_CPU XLA_GPU 
_Arg: GPU CPU XLA_CPU XLA_GPU 
ReadVariableOp: GPU CPU XLA_CPU XLA_GPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  quantum_circuit_quantum_layer_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  adam_adam_update_resourceapplyadam_m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  adam_adam_update_resourceapplyadam_v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  quantum_circuit/quantum_layer/ReadVariableOp (ReadVariableOp) 
  Adam/Adam/update/ResourceApplyAdam (ResourceApplyAdam) 

	 [[{{node quantum_circuit/quantum_layer/ReadVariableOp}}]] [Op:__inference_train_function_6330]
```

I can avoid it if in the `build()` method of my custom Keras layers I call `add_weight()` inside a `tf.device('/CPU:0')` context (I tried this after I read the top post in issue https://github.com/tensorflow/tensorflow/issues/1310, from 2016!)

Is this what should be done? It seems that the GPU is heavily underused if I do that.

**Describe the expected behavior**
I would expect Keras/TF to handle device assignment on its own, and not force me to adapt the code for each machine where it runs.

**Standalone code to reproduce the issue**
Code is way too long"
42408,TensorflowJs Incompatible shapes Error,"I build Unet architecture with TensorFlow Js.
But I faced a problem with Incompatible shapes error.
My input was [512, 512, 3] 3d tensor and label is [512, 512] 2d tensor.

my model was

    const input_layer = tf.input({ shape: [512, 512, 3], name: 'image_input'});
    
    const conv1 = tf.layers.conv2d({ filters: filter, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(input_layer);
    const batch1 = tf.layers.batchNormalization().apply(conv1);
    const act1 =  tf.layers.activation({activation: 'relu'}).apply(batch1);
    const conv11 = tf.layers.conv2d({ filters: filter, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(act1);
    const batch11 = tf.layers.batchNormalization().apply(conv11);
    const act11 =  tf.layers.activation({activation: 'relu'}).apply(batch11);
    const conv1_out = tf.layers.maxPooling2d({ poolSize: [2, 2] }).apply(act11);
    
    const conv2 = tf.layers.conv2d({ filters: filter*2, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(conv1_out);
    const batch2 = tf.layers.batchNormalization().apply(conv2);
    const act2 =  tf.layers.activation({activation: 'relu'}).apply(batch2);
    const conv22 = tf.layers.conv2d({ filters: filter*2, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(act2);
    const batch22 = tf.layers.batchNormalization().apply(conv22);
    const act22 =  tf.layers.activation({activation: 'relu'}).apply(batch22);
    const conv2_out = tf.layers.maxPooling2d({ poolSize: [2, 2] }).apply(act22);
    
    const conv3 = tf.layers.conv2d({ filters: filter*4, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(conv2_out);
    const batch3 = tf.layers.batchNormalization().apply(conv3);
    const act3 =  tf.layers.activation({activation: 'relu'}).apply(batch3);
    const conv33 = tf.layers.conv2d({ filters: filter*4, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(act3);
    const batch33 = tf.layers.batchNormalization().apply(conv33);
    const act33 =  tf.layers.activation({activation: 'relu'}).apply(batch33);
    const conv3_out = tf.layers.maxPooling2d({ poolSize: [2, 2] }).apply(act33);
    
    const conv4 = tf.layers.conv2d({ filters: filter*8, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(conv3_out);
    const batch4 = tf.layers.batchNormalization().apply(conv4);
    const act4 =  tf.layers.activation({activation: 'relu'}).apply(batch4);
    const conv44 = tf.layers.conv2d({ filters: filter*8, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(act4);
    const batch44 = tf.layers.batchNormalization().apply(conv44);
    const act44 =  tf.layers.activation({activation: 'relu'}).apply(batch44);
    const conv4_out = tf.layers.maxPooling2d({ poolSize: [2, 2] }).apply(act44);
    const conv4_dropout = tf.layers.dropout({rate: 0.5}).apply(conv4_out);
    
    const conv5 = tf.layers.conv2d({ filters: filter*16, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(conv4_dropout);
    const batch5 = tf.layers.batchNormalization().apply(conv5);
    const act5 =  tf.layers.activation({activation: 'relu'}).apply(batch5);
    const conv55 = tf.layers.conv2d({ filters: filter*16, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(act5);
    const batch55 = tf.layers.batchNormalization().apply(conv55);
    const act55 =  tf.layers.activation({activation: 'relu'}).apply(batch55);
    const conv5_dropout = tf.layers.dropout({rate: 0.5}).apply(act55);
    
    //Second part (up climb)
    const deconv6 = tf.layers.conv2dTranspose({ filters: filter*8, kernelSize: [3, 3], strides: [2, 2], padding: ""same"" }).apply(conv5_dropout);
    const deconv6_con = tf.layers.concatenate({axis: 3}).apply([deconv6, act44]);
    const deconv6_conv1 = tf.layers.conv2d({ filters: filter*8, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(deconv6_con);
    const deconv6_batch1 = tf.layers.batchNormalization().apply(deconv6_conv1);
    const deconv6_act1 =  tf.layers.activation({activation: 'relu'}).apply(deconv6_batch1);
    const deconv6_conv11 = tf.layers.conv2d({ filters: filter*8, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(deconv6_act1);
    const deconv6_batch11 = tf.layers.batchNormalization().apply(deconv6_conv11);
    const deconv6_act11 =  tf.layers.activation({activation: 'relu'}).apply(deconv6_batch11);
    const deconv6_dropout = tf.layers.dropout({rate: 0.5}).apply(deconv6_act11);
    
    const deconv7 = tf.layers.conv2dTranspose({ filters: filter*4, kernelSize: [3, 3], strides: [2, 2], padding: ""same"" }).apply(deconv6_dropout);
    const deconv7_con = tf.layers.concatenate({axis: 3}).apply([deconv7, act33]);
    const deconv7_conv1 = tf.layers.conv2d({ filters: filter*4, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(deconv7_con);
    const deconv7_batch1 = tf.layers.batchNormalization().apply(deconv7_conv1);
    const deconv7_act1 =  tf.layers.activation({activation: 'relu'}).apply(deconv7_batch1);
    const deconv7_conv11 = tf.layers.conv2d({ filters: filter*4, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(deconv7_act1);
    const deconv7_batch11 = tf.layers.batchNormalization().apply(deconv7_conv11);
    const deconv7_act11 =  tf.layers.activation({activation: 'relu'}).apply(deconv7_batch11);
    const deconv7_dropout = tf.layers.dropout({rate: 0.5}).apply(deconv7_act11);
    
    const deconv8 = tf.layers.conv2dTranspose({ filters: filter*2, kernelSize: [3, 3], strides: [2, 2], padding: ""same"" }).apply(deconv7_dropout);
    const deconv8_con = tf.layers.concatenate({axis: 3}).apply([deconv8, act22]);
    const deconv8_conv1 = tf.layers.conv2d({ filters: filter*2, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(deconv8_con);
    const deconv8_batch1 = tf.layers.batchNormalization().apply(deconv8_conv1);
    const deconv8_act1 =  tf.layers.activation({activation: 'relu'}).apply(deconv8_batch1);
    const deconv8_conv11 = tf.layers.conv2d({ filters: filter*2, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(deconv8_act1);
    const deconv8_batch11 = tf.layers.batchNormalization().apply(deconv8_conv11);
    const deconv8_act11 =  tf.layers.activation({activation: 'relu'}).apply(deconv8_batch11);
    
    const deconv9 = tf.layers.conv2dTranspose({ filters: filter, kernelSize: [3, 3], strides: [2, 2], padding: ""same"" }).apply(deconv8_act11);
    const deconv9_con = tf.layers.concatenate({axis: 3}).apply([deconv9, act11]);
    const deconv9_conv1 = tf.layers.conv2d({ filters: filter, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(deconv9_con);
    const deconv9_batch1 = tf.layers.batchNormalization().apply(deconv9_conv1);
    const deconv9_act1 =  tf.layers.activation({activation: 'relu'}).apply(deconv9_batch1);
    const deconv9_conv11 = tf.layers.conv2d({ filters: filter, kernelSize: [3, 3], activation: ""relu"", padding: ""same"", kernelInitializer: ""heNormal"" }).apply(deconv9_act1);
    const deconv9_batch11 = tf.layers.batchNormalization().apply(deconv9_conv11);
    const deconv9_act11 =  tf.layers.activation({activation: 'relu'}).apply(deconv9_batch11);
    
    const output_layer = tf.layers.conv2d({ kernelSize: [1, 1], activation: ""softmax"", filters: 5}).apply(deconv9_act11);
    
    const model = tf.model({ inputs: input_layer, outputs: output_layer, name: ""Unet"" });
    
    model.compile({ loss: 'categoricalCrossentropy', optimizer: 'adam', metrics: ['accuracy'] });

and my train code was

    const xs = await tf.data.generator(data);        // input tensor3d [512, 512, 3]
    const ys = await tf.data.generator(labels);      // input tensor2d [512, 512]
    
    const ds = await tf.data.zip({xs, ys}).shuffle(2).batch(2);
    
    const model = await initModel();
    model.summary();
    
    await model.fitDataset(ds, {epochs: 5}).then(info => {
      console.log('Accuracy', info.history.acc);
    });

And I got this error message

    Incompatible shapes: [2,512,512] vs. [2,512,512,5]

"
42407,Failed to load the native TensorFlow runtime.,"Hi,

After pip installing tensorflow I get the following message when importing it.

import tensorflow
Traceback (most recent call last):

  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *

  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()

  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)

  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)

  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)

ImportError: DLL load failed: The specified module could not be found.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File ""<ipython-input-9-d6579f534729>"", line 1, in <module>
    import tensorflow

  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util

  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow

  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)

ImportError: Traceback (most recent call last):
  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\yaniv_cfrphva\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
42405,Pybind11 exception with tensorflow 2.2 env in python cpp communication,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.2
- TensorFlow version (use command below):2.2
- Python version:3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10, 10.1,8.0 / 7.6.5
- GPU model and memory:  NVIDIA Geforce GTX 1050 Ti & 12 GB

**Describe the current behavior**
Problem : 

Below code is working fine while running through tensorflow2.0 env but same code if I run through tensorflow2.2 env then it's give below exception at PYObject_CallObject(pFunc, NULL)

Error : Microsoft c++ exception : pybind11::error_already_set at memory location XXXXXX

**Describe the expected behavior**
should not through pybind11::error_already_set while just importing tensorflow library

**Standalone code to reproduce the issue**
Below is CPP calling python file source code for a reference.
       #define PY_SSIZE_T_CLEAN
       #include <Python.h>
       using namespace std;
    	int main(int argc, char *argv[])
	{
	PyObject *pName, *pModule, *pFunc;
	PyObject *pArgs, *pValue;
	int i;
	string pythonFunction = ""sample_fun"";
	string pythonFile     = ""sample""
    string tensoflow_env  = ""tensorflow_env_path"";
    wchar  *env = Py_DecodeLocale(tensoflow_env.c_str(),NULL);
    Py_SetPythonHome(env);
	Py_Initialize();
	pName = PyUnicode_DecodeFSDefault(pythonFile.c_str());
	/* Error checking of pName left out */

	pModule = PyImport_Import(pName);
	Py_DECREF(pName);

	if (pModule != NULL) {
    pFunc = PyObject_GetAttrString(pModule, pythonFunction.c_str());
    /* pFunc is a new reference */

    if (pFunc && PyCallable_Check(pFunc)) {
        
        pValue = PyObject_CallObject(pFunc, NULL);
        if (pValue != NULL) {
            Py_DECREF(pValue);
        }
        else {
            Py_DECREF(pFunc);
            Py_DECREF(pModule);
            PyErr_Print();
            fprintf(stderr,""Call failed\n"");
            return 1;
        }
    }
    else {
        if (PyErr_Occurred())
            PyErr_Print();
        fprintf(stderr, ""Cannot find function \""%s\""\n"", argv[2]);
    }
    Py_XDECREF(pFunc);
    Py_DECREF(pModule);
	}
	else {
		PyErr_Print();
		fprintf(stderr, ""Failed to load \""%s\""\n"", argv[1]);
		return 1;
	}
	if (Py_FinalizeEx() < 0) {
    return 120;
	}
	return 0;
}

Below is sample.py file for a reference.

    def sample_fun():
	   import tensorflow as tf
       return 'Success'


**Other info / logs** Include any logs or source code that would be helpful to
By running above code with tensorflow 2.2 then issue is easily reproduce. 
"
42403,mode.save() API raises AttributeError: 'Tensor' object has no attribute '_keras_mask',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly==2.4.0-dev20200815
- Python version: 3.6
- GPU model and memory: Tesla T4, memory_limit: 14611321984

**Describe the current behavior**
I've created an encoder-decoder model. I'm using LSTM in both the encoder and decoder architecture. I'm applying tf.keras.layers.Masking() on the encoder's LSTM output and hidden state and passing both of the masks (using the attribute _keras_mask) to tf.keras.layers.AdditiveAttention(). The model trains successfully using the teacher-forcing technique.

Next, I am trying to save both the model in SavedModel format using the model.save() API.
I'm getting the below error:
```
INFO:tensorflow:Assets written to: attention_two_encoder/assets
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-118-f4fbf19e2bf7> in <module>()
      1 encoder.save(ENC_SAVED_MODEL_DIR)
----> 2 decoder.save(DEC_SAVED_MODEL_DIR)

26 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
   1948     """"""
   1949     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
-> 1950                     signatures, options)
   1951 
   1952   def save_weights(self,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    133   else:
    134     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--> 135                           signatures, options)
    136 
    137 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     78     # we use the default replica context here.
     79     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access
---> 80       save_lib.save(model, filepath, signatures, options)
     81 
     82   if not include_optimizer:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    998 
    999   _, exported_graph, object_saver, asset_info = _build_meta_graph(
-> 1000       obj, export_dir, signatures, options, meta_graph_def)
   1001   saved_model.saved_model_schema_version = constants.SAVED_MODEL_SCHEMA_VERSION
   1002 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def)
   1146   with save_context.save_context(options):
   1147     return _build_meta_graph_impl(obj, export_dir, signatures, options,
-> 1148                                   meta_graph_def)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in _build_meta_graph_impl(obj, export_dir, signatures, options, meta_graph_def)
   1093   if signatures is None:
   1094     signatures = signature_serialization.find_function_to_export(
-> 1095         checkpoint_graph_view)
   1096 
   1097   signatures, wrapped_functions = (

/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_serialization.py in find_function_to_export(saveable_view)
     73   # If the user did not specify signatures, check the root object for a function
     74   # that can be made into a signature.
---> 75   functions = saveable_view.list_functions(saveable_view.root)
     76   signature = functions.get(DEFAULT_SIGNATURE_ATTR, None)
     77   if signature is not None:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in list_functions(self, obj, extra_functions)
    145     if obj_functions is None:
    146       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access
--> 147           self._serialization_cache)
    148       self._functions[obj] = obj_functions
    149     if extra_functions:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _list_functions_for_serialization(self, serialization_cache)
   2559     self.predict_function = None
   2560     functions = super(
-> 2561         Model, self)._list_functions_for_serialization(serialization_cache)
   2562     self.train_function = train_function
   2563     self.test_function = test_function

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in _list_functions_for_serialization(self, serialization_cache)
   3045   def _list_functions_for_serialization(self, serialization_cache):
   3046     return (self._trackable_saved_model_saver
-> 3047             .list_functions_for_serialization(serialization_cache))
   3048 
   3049   def __getstate__(self):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py in list_functions_for_serialization(self, serialization_cache)
     85         `ConcreteFunction`.
     86     """"""
---> 87     fns = self.functions_to_serialize(serialization_cache)
     88 
     89     # The parent AutoTrackable class saves all user-defined tf.functions, and

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in functions_to_serialize(self, serialization_cache)
     77   def functions_to_serialize(self, serialization_cache):
     78     return (self._get_serialized_attributes(
---> 79         serialization_cache).functions_to_serialize)
     80 
     81   def _get_serialized_attributes(self, serialization_cache):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in _get_serialized_attributes(self, serialization_cache)
     93 
     94     object_dict, function_dict = self._get_serialized_attributes_internal(
---> 95         serialization_cache)
     96 
     97     serialized_attr.set_and_validate_objects(object_dict)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py in _get_serialized_attributes_internal(self, serialization_cache)
     49     # cache (i.e. this is the root level object).
     50     if len(serialization_cache[constants.KERAS_CACHE_KEY]) == 1:
---> 51       default_signature = save_impl.default_save_signature(self.obj)
     52 
     53     # Other than the default signature function, all other attributes match with

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in default_save_signature(layer)
    203   original_losses = _reset_layer_losses(layer)
    204   fn = saving_utils.trace_model_call(layer)
--> 205   fn.get_concrete_function()
    206   _restore_layer_losses(original_losses)
    207   return fn

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in get_concrete_function(self, *args, **kwargs)
   1174       ValueError: if this object has not yet been called on concrete values.
   1175     """"""
-> 1176     concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
   1177     concrete._garbage_collector.release()  # pylint: disable=protected-access
   1178     return concrete

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)
   1080       if self._stateful_fn is None:
   1081         initializers = []
-> 1082         self._initialize(args, kwargs, add_initializers_to=initializers)
   1083         self._initialize_uninitialized_variables(initializers)
   1084 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    715     self._concrete_stateful_fn = (
    716         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 717             *args, **kwds))
    718 
    719     def invalid_creator_scope(*unused_args, **unused_kwds):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2953       args, kwargs = None, None
   2954     with self._lock:
-> 2955       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2956     return graph_function
   2957 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3331 
   3332       self._function_cache.missed.add(call_context_key)
-> 3333       graph_function = self._create_graph_function(args, kwargs)
   3334       self._function_cache.primary[cache_key] = graph_function
   3335 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3186             arg_names=arg_names,
   3187             override_flat_arg_shapes=override_flat_arg_shapes,
-> 3188             capture_by_value=self._capture_by_value),
   3189         self._function_attributes,
   3190         function_spec=self.function_spec,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    985         _, original_func = tf_decorator.unwrap(python_func)
    986 
--> 987       func_outputs = python_func(*func_args, **func_kwargs)
    988 
    989       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    623             xla_context.Exit()
    624         else:
--> 625           out = weak_wrapped_fn().__wrapped__(*args, **kwds)
    626         return out
    627 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py in _wrapped_model(*args)
    132     with base_layer_utils.call_context().enter(
    133         model, inputs=inputs, build_graph=False, training=False, saving=True):
--> 134       outputs = model(inputs, training=False)
    135 
    136     # Outputs always has to be a flat dict.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    988 
    989         with ops.enable_auto_cast_variables(self._compute_dtype_object):
--> 990           outputs = call_fn(inputs, *args, **kwargs)
    991 
    992         if self._activity_regularizer:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    615   def wrapper(*args, **kwargs):
    616     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
--> 617       return func(*args, **kwargs)
    618 
    619   if inspect.isfunction(func) or inspect.ismethod(func):

<ipython-input-104-f3868e3dd449> in call(self, y)
    162 
    163         context_vector = self.attention(inputs=[hidden_with_time_axis, enc_output],
--> 164                                         mask=[hidden_with_time_axis_mask._keras_mask, enc_output_mask._keras_mask])
    165         # context_vector shape == (batch_size, 1, enc_units)
    166 

AttributeError: 'Tensor' object has no attribute '_keras_mask'
```

**Describe the expected behavior**
model.save() API should allow me to save the encoder-decoder model.
After saving the models, I want to apply post-training float16 quantization.

**Standalone code to reproduce the issue**

Encoder-Decoder model architecture
```
class Encoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):
        super(Encoder, self).__init__()
        self.batch_sz = batch_sz
        self.enc_units = enc_units
        
        self.embedding_ques = tf.keras.layers.Embedding(vocab_size, embedding_dim, 
                                                        input_length=max_ques_length, 
                                                        weights=[embedding_matrix], 
                                                        trainable=False, mask_zero=True)
        self.embedding_title = tf.keras.layers.Embedding(vocab_size, embedding_dim, 
                                                         input_length=max_title_length, 
                                                         weights=[embedding_matrix], 
                                                         trainable=False, mask_zero=True)
        
        self.lstm_ques = tf.keras.layers.LSTM(self.enc_units,
                                   return_sequences=True,
                                   return_state=True)
        self.lstm_title = tf.keras.layers.LSTM(self.enc_units,
                                   return_sequences=True,
                                   return_state=True)
        
        self.dense_state_h_ques = tf.keras.layers.Dense(int(self.enc_units/2))
        self.dense_state_h_title = tf.keras.layers.Dense(int(self.enc_units/2))
        self.dense_state_c_ques = tf.keras.layers.Dense(int(self.enc_units/2))
        self.dense_state_c_title = tf.keras.layers.Dense(int(self.enc_units/2))

        self.conv2d_image = tf.keras.layers.Conv2D(32, (3, 3), 
                                    activation = 'relu',
                                    kernel_initializer = tf.keras.initializers.HeNormal(seed=SEED),
                                    padding = 'same')
        self.flatten_image = tf.keras.layers.Flatten()
        self.dense_image = tf.keras.layers.Dense(self.enc_units)

        self.dense_price = tf.keras.layers.Dense(self.enc_units)
        
    def call(self, x):   
        question, title, price, image, hidden = x[0], x[1], x[2], x[3], x[4]
        # question shape == (batch_size, max_ques_length)
        # title shape == (batch_size, max_title_length)
        # price shape == (batch_size, 1)
        # image shape == (batch_size, img_width, img_height, channels)

        question_e = self.embedding_ques(question)
        # question_e shape == (batch_size, max_ques_length, embedding_dim)
        
        question_mask = self.embedding_ques.compute_mask(question)
        # question_mask shape == (batch_size, max_ques_length)
        output_ques, state_h_ques, state_c_ques = self.lstm_ques(question_e, initial_state = hidden, mask=question_mask)
        # output_ques shape == (batch_size, max_ques_length, enc_units)
        # state_h_ques shape == (batch_size, enc_units)
        # state_c_ques shape == (batch_size, enc_units)

        title_e = self.embedding_title(title)
        # title_e shape == (batch_size, max_title_length, embedding_dim)
        
        title_mask = self.embedding_title.compute_mask(title)
        # title_mask shape == (batch_size, max_title_length)
        output_title, state_h_title, state_c_title = self.lstm_title(title_e, initial_state = hidden, mask=title_mask)
        # output_title shape == (batch_size, max_title_length, enc_units)
        # state_h_title shape == (batch_size, enc_units)
        # state_c_title shape == (batch_size, enc_units)

        price = self.dense_price(price)
        # price shape == (batch_size, enc_units)

        image = self.conv2d_image(image)
        # image shape ==  (batch_size, img_width, img_height, filters=32)
        image = self.flatten_image(image)
        # image shape == (batch_size, 51200)
        image = self.dense_image(image)
        # image shape == (batch_size, enc_units)
        
        output = tf.concat([output_ques, output_title], axis=1)
        # output shape == (batch_size, max_ques_length + max_title_length, enc_units)
        output = tf.concat([tf.expand_dims(price, 1), output], axis=1)
        # output shape == (batch_size, max_ques_length + max_title_length + 1, enc_units)
        output = tf.concat([tf.expand_dims(image, 1), output], axis=1)
        # output shape == (batch_size, max_ques_length + max_title_length + 1 + 1, enc_units)

        state_h_ques = self.dense_state_h_ques(state_h_ques)
        # state_h_ques shape == (batch_size, int(enc_units/2))
        state_h_title = self.dense_state_h_title(state_h_title)
        # state_h_title shape == (batch_size, int(enc_units/2))
        state_h = tf.concat([state_h_ques, state_h_title], axis=-1)
        # state_h shape == (batch_size, enc_units)

        state_c_ques = self.dense_state_c_ques(state_c_ques)
        # state_c_ques shape == (batch_size, int(enc_units/2))
        state_c_title = self.dense_state_c_title(state_c_title)
        # state_c_title shape == (batch_size, int(enc_units/2))
        state_c = tf.concat([state_c_ques, state_c_title], axis=-1)
        # state_c shape == (batch_size, enc_units + enc_units)

        return output, state_h, state_c


    def initialize_hidden_state(self):
        return (tf.zeros((self.batch_sz, self.enc_units)),
                tf.zeros((self.batch_sz, self.enc_units)))

class Decoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):
        super(Decoder, self).__init__()
        self.batch_sz = batch_sz
        self.dec_units = dec_units
        
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, 
                                                   input_length=max_ans_length, 
                                                   weights=[embedding_matrix], 
                                                   trainable=False, mask_zero=True)
        
        self.lstm = tf.keras.layers.LSTM(self.dec_units,
                                   return_sequences=True,
                                   return_state=True)
        self.fc = tf.keras.layers.Dense(vocab_size)
        
        self.attention = tf.keras.layers.AdditiveAttention()

        
        self.masking_hidden = tf.keras.layers.Masking()
        self.masking_enc_output = tf.keras.layers.Masking()
        
    def call(self, y):
        inputs, hidden, enc_output = y[0], y[1], y[2]
        # 1 in each of the dimension means timesteps
        # decoding is happening at each timesteps

        # inputs shape == (batch_size, 1)
        # hidden shape == tuple of two (batch_size, enc_units) [lstm state_h and state_c]
        # enc_output shape == (batch_size, max_ques_length, enc_units)

        # hidden == lstm state_h
 
        hidden_with_time_axis = tf.expand_dims(hidden[0], 1)
        # hidden_with_time_axis shape == (batch_size, 1, enc_units)
        
        hidden_with_time_axis_mask = self.masking_hidden(hidden_with_time_axis)
        # hidden_with_time_axis_mask._keras_mask shape == (batch_size, 1)
        
        enc_output_mask = self.masking_enc_output(enc_output)
        # enc_output_mask._keras_mask shape == (batch_size, max_ques_length)
        
        context_vector = self.attention(inputs=[hidden_with_time_axis, enc_output],
                                        mask=[hidden_with_time_axis_mask._keras_mask, enc_output_mask._keras_mask])
        # context_vector shape == (batch_size, 1, enc_units)

        
        # x shape after passing through embedding == (batch_size, 1, embedding_dim)
        x = self.embedding(inputs)

        
        mask = self.embedding.compute_mask(inputs)
        # mask shape == (batch_size, 1)

        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)
        x = tf.concat([context_vector, x], axis=-1)
        
        # passing the concatenated vector to the LSTM
        output, state_h, state_c = self.lstm(x, initial_state=hidden, mask=mask)
        # output shape == (batch_size, 1, dec_units)
        # state_h shape == (batch_size, dec_units)
        # state_c shape == (batch_size, dec_units)
 
        output = tf.reshape(output, (-1, output.shape[2]))
        # output shape == (batch_size * 1, dec_units)
        
        x = self.fc(output)
        # output shape == (batch_size, vocab)
        
        return x, state_h, state_c

    def initialize_hidden_state(self):
        return (tf.zeros((self.batch_sz, self.dec_units)),
                tf.zeros((self.batch_sz, self.dec_units)))
```

Attempt to save the models using the below code
```
encoder.save(ENC_SAVED_MODEL_DIR)
decoder.save(DEC_SAVED_MODEL_DIR) # Stacktrace posted above 
```"
42402,[new feature]: Roll slice of a tensor,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):2.30
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**

I want tf.roll to do the following, I want to roll only one row. out of all the rows.
[[0,1,2,3,4],
[5,6,7,8,9]]
I want to roll only the bottom row by 2. i.e. the result will be 
[[0,1,2,3,4]
[8,9,5,6,7]]
 
Currently, tf.roll can do 
[[3,4,0,1,2]
[8,9,5,6,7]]
but not be specific row

**Will this change the current api? How?**
Add new feature to tensorflow
**Who will benefit with this feature?**

Many System biologists and physicist who want to use TensorFlow to compute Transcription Models. A key breakthrough on this idea. 
I am planning to implement the algorithms in this paper at larger scale for much harder problems. 
https://academic.oup.com/bioinformatics/article/36/Supplement_1/i499/5870526


**Any Other info.**
"
42401,Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6


**Describe the current behavior**
Throws the following error when calling **model.predict(dataset)** on TPUs.
```
Traceback (most recent call last):
  File ""bl_model.py"", line 188, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""bl_model.py"", line 158, in main
    emb, _, label, dataset = model.predict(test_dataset)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 130, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1601, in predict
    context.async_wait()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py"", line 2319, in async_wait
    context().sync_executors()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py"", line 658, in sync_executors
    pywrap_tfe.TFE_ContextSyncExecutors(self._context_handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 9 root error(s) found.
  (0) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA
	 [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]
	 [[cluster_predict_function/control_after/_1/_347]]
  (1) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA
	 [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6/_209]]
  (2) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA
	 [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]
	 [[cluster_predict_function/control_after/_1/_363]]
  (3) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA
	 [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6/_223]]
  (4) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA
	 [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]
	 [[cluster_predict_function/control_after/_1/_355]]
  (5) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA
	 [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6/_251]]
  (6) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA
	 [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]
	 [[tpu_compile_succeeded_assert/_16053711828520823699/_6/_307]]
  (7) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride y ... [truncated]
```

**Describe the expected behavior**
There is no error under TF 2.2.0. Is there any way to turn off XLA for TPUs in TF 2.3.0?

"
42399,Adding Conv3DLSTM and depth-wise separable Conv3D layers to tensorflow.keras API,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.3
- Are you willing to contribute it (Yes/No): Yes (but may not have the technical coding skills)



**Describe the feature and the current behavior/state.**
Thank you for creating this wonderful tool for researchers. It would be extremely helpful to have implementations of Conv3DLSTM and depth-wise separable Conv3D layers to the API for 3D medical image analysis.

**Will this change the current api? How?**
Yes, these layers would extend the features currently available in 2D within the current API making it more useful to researchers working with 3D data

**Who will benefit with this feature?**
Researchers working with 3D imaging data, particularly in the medical field

**Any Other info.**
I would appreciate any available tips or advice on how I could go by extending these features myself or how I could contribute to adding those features to the API"
42398,"TFA can't load _image_ops.so - says file doesn't exist, but its there?","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): TF 2.1.0 installed via conda
- TensorFlow version: 2.1.0
- Python version: 3.7.0
- Installed using virtualenv? pip? conda?: TF installed via conda, TFA via pip.
TFA installed via pip install tensorflow_addons==0.9.1

- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
# packages in environment at C:\ProgramData\Anaconda3\envs\tf:
#
# Name                    Version                   Build  Channel
cudnn                     7.6.5                cuda10.1_0
- GPU model and memory:
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 442.19       Driver Version: 442.19       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108... WDDM  | 00000000:01:00.0  On |                  N/A |
| 23%   38C    P8    17W / 250W |   1049MiB / 11264MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108... WDDM  | 00000000:03:00.0 Off |                  N/A |
| 23%   29C    P8     9W / 250W |    137MiB / 11264MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+



**Describe the problem**

TFA can't load _image_ops.so

File ""C:\ProgramData\Anaconda3\envs\tf\lib\site-packages\tensorflow_addons\image\distance_transform.py"", line 69, in euclidean_dist_transform
    output = _image_so.ops.addons_euclidean_distance_transform(images)
  File ""C:\ProgramData\Anaconda3\envs\tf\lib\site-packages\tensorflow_addons\utils\resource_loader.py"", line 56, in ops
    self._ops = tf.load_op_library(get_path_to_datafile(self.relative_path))
  File ""C:\ProgramData\Anaconda3\envs\tf\lib\site-packages\tensorflow_core\python\framework\load_library.py"", line 57, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: C:\ProgramData\Anaconda3\envs\tf\lib\site-packages\tensorflow_addons\custom_ops\image\_image_ops.so not found

The file exists in the specified directory

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

As you can see, the library file is clearly there...

(tf) C:\ProgramData\Anaconda3\envs\tf\Lib\site-packages\tensorflow_addons\custom_ops\image>dir
 Volume in drive C has no label.
 Volume Serial Number is 62E0-530C

 Directory of C:\ProgramData\Anaconda3\envs\tf\Lib\site-packages\tensorflow_addons\custom_ops\image

08/15/2020  02:19 PM    <DIR>          .
08/15/2020  02:19 PM    <DIR>          ..
08/15/2020  02:19 PM           172,544 _distort_image_ops.so
08/15/2020  02:19 PM           977,408 _image_ops.so
08/15/2020  02:19 PM           169,984 _resampler_ops.so
               3 File(s)      1,319,936 bytes
               2 Dir(s)  255,060,709,376 bytes free


Here is the code.

```
""""""
    Debug Euclidean distance
""""""
from silence_tensorflow import silence_tensorflow
silence_tensorflow()

import os
os.system('cls' if os.name == 'nt' else 'clear')

import warnings
warnings.filterwarnings('ignore', category=FutureWarning)

import tensorflow
import numpy as np
import tensorflow_addons as tfa
import matplotlib.pyplot as plt

with tensorflow.device('/GPU:1'):

    M = 500
    img = np.zeros((M, M))
    top = 50
    bottom = 270
    left = 300
    right = 450
    img[np.ix_(np.arange(top, bottom + 1), np.arange(left, right + 1))] = 1
    img = tensorflow.convert_to_tensor(img)
    img = tensorflow.expand_dims(img, -1)
    img = img.numpy()

    # TFA - Euclidean distance transform
    img = tensorflow.cast(img, dtype=tensorflow.uint8)
    d_img = tfa.image.euclidean_dist_transform(img)  # See https://github.com/tensorflow/addons

    # Plot it
    plt.figure()
    plt.title('True TFA Distance Image')
    _ = plt.imshow(d_img)

    # Tell user how to end code.
    print(""\nPress ctrl-c or ctrl-break or close windows to exit.\n"")
    plt.show()
```

Thanks for the help. I can't understand why the system is telling me this library doesn't exist.
"
42396,Model.fit() issue,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
42395,"Hi everybody, I 'm trying to excute a free avialble code for CNN model to classify 4 classes of dogs, cats, horses and humans. Unfortunatly, I faced this issue: ""ValueError: Calling `Model.fit` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.fit` with eager mode enabled."" how can I handle it?","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
42394,ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version: 3.8.3
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: Not Installed
- GPU model and memory: NVIDIA GeForce MX250 2 GB



**Describe the problem**

While running this sample tensorflow program, 

import tensorflow as tf
tf.add(1, 2).numpy()
hello = tf.constant('Hello, TensorFlow!')
hello.numpy()

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I encountered below error message:

from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

Failed to load the native TensorFlow runtime.
--------------------------------------------------------

Tensorflow Installation:
Successfully installed Tensorflow-2.3.0 absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.20.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.31.0 keras-preprocessing-1.1.2 markdown-3.2.2 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-estimator-2.3.0 termcolor-1.1.0

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
42393,Add Object Detection EfficientDet/Retinanet Model(s) to tf.keras.applications,"**System information**
- TensorFlow version (2.3): Although this request feels very TF 2.4.
- Are you willing to contribute it: I could be involved in testing. 

**Describe the feature and the current behavior/state.**

`tf.keras.applications` is amazing. With all the model architectures and the pre-trained weights there is a lot
of possibilities for transfer learning and feature extraction. However, there are not any object detection models.

I would love to see some object detection models baked into 
`tf.keras.applications`  as well as pre-trained weights (trained on object detection tasks like coco for example) that would make it possible for training new object detection models, via transfer learning, on custom data. Very much like how the current API works for classification models for example i.e. (import resnet, remove top/head, add layer, freeze, train).

Since we already have Resnet backbones and Efficient backbones (as of TF 2.3), would it be possible to add object detection architectures on top of these such as [Retinanet](https://arxiv.org/abs/1708.02002) or [EfficientDet](https://arxiv.org/abs/1911.09070). As well as have the pre-trained weights trained on coco for example for such models. Then having some sort of easy way to adjust these for training on custom object detection data. Much like with the current models we can remove the top/head and add on top for custom classifiers. 

It's not straight forward to get started with object detection using tf.keras.  I am also aware of the newly designed TF Models Detection API but it still feels bloated and very disconnected from TF main library. It would be lovely to see something built into tf.keras.applications.

**Will this change the current api? How?**
Just by adding the new feature request.

**Who will benefit with this feature?**
All users of tf.keras.applications. Anyone working in industry with current TF 2 in their tech stack looking to add object detection functionality.

**Any Other info.**
I think this would be amazing! 

There is the project https://github.com/google/automl/tree/master/efficientdet which is Google and it seems like they are trying to use tf.keras there some. There is also https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md but it has so much else going on in it. How can we take these projects and pick out the pieces and build for example EfficientDet into tf.keras.applications. At the moment things are convoluted and lots of outside projects. Having this within tf.keras.applications main code would be nice and easier to build off in existing tech stacks that already use Tensorflow. "
42392,tf-nightly: 'bfloat16' in namespace 'Eigen' does not name a type.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, custom op
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly==2.4.0.dev20200815
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 7.6.5.32
- GPU model and memory: t4


**Describe the current behavior**

Attempting to compile a custom op (Horovod) with the latest tf-nightly produces numerous error messages of the form:

```

In file included from /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/platform/types.h:21:0,

from /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,
from /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/platform/status.h:24,
from /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/lib/core/status.h:19,
from /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:25,
from /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/op.h:23,
from horovod/tensorflow/mpi_ops.cc:24:
/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/platform/bfloat16.h:25:16: error: 'bfloat16' in namespace 'Eigen' does not name a type
typedef Eigen::bfloat16 bfloat16;
^~~~~~~~
```

This may be related to https://github.com/tensorflow/tensorflow/commit/576d1d395d01a24483a9ebf66ba704ba38043e63 and https://github.com/tensorflow/tensorflow/commit/dab490a8bfb0cf1f289c9352c4d086356d0e5949 which were merged yesterday.

Looks like there may be some missing headers.
"
42391,distributed training,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
42390,Error. Converter does not support Quantization NN with 'tanh' activation,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.3.0 (Google Collab)


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/12K7FKEFvbJx7gUuI93hsS6si1n0zYRSO?usp=sharing

```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: /tmp/tmpnq1srnbk/assets
INFO:tensorflow:Assets written to: /tmp/tmpnq1srnbk/assets
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-27-89960d743844> in <module>()
      9 converter.representative_dataset = representative_dataset_generator
     10 
---> 11 tflite_model = converter.convert()

3 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py in calibrate_and_quantize(self, dataset_gen, input_type, output_type, allow_float, activations_type, resize_input)
     96         np.dtype(input_type.as_numpy_dtype()).num,
     97         np.dtype(output_type.as_numpy_dtype()).num, allow_float,
---> 98         np.dtype(activations_type.as_numpy_dtype()).num)
     99 
    100   def calibrate_and_quantize_single(self,

RuntimeError: Quantization not yet supported for op: 
```

**Also, please include a link to the saved model or GraphDef**

```
See in Google Collab notebook.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Converter fails during conversion


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

My network uses 'tanh' activation.
If I use 'tanh' activation the converter fails.
If I use only 'relu' activations the converter does conversion successfully.
"
42389,Undocumented S3_DISABLE_MULTI_PART_DOWNLOAD variable and its behavior,"## URL(s) with the issue:

S3 environment variables are partially documented here: https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/s3.md.
However, there doesn't seem to be a complete documentation of this feature anywhere.

## Description of issue (what needs changing):

TensorFlow's S3 client use `S3_DISABLE_MULTI_PART_DOWNLOAD` environment variable (see [s3_file_system.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system.cc#L482)). However, it's not documented anywhere.

### Clear description

This environment variable disables multi-part download from S3, and S3-like storage systems (like [AIStore](https://github.com/NVIDIA/aistore/)). Neither it's documented in this repository, nor google returns any valid result when searching it.

It's not clear for users (including me) if it's safe to use this variable. It does work, however, is it deprecated or is it going to be supported continuously?

Additionally, the required value of this variable, for multi-part download to be disabled, is any string with the first character `1`, which is not a perfect solution (having in mind lack of documentation).

### Correct links

Source code using this environment variable: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system.cc#L482

### Usage example

There is no documentation, nor usage examples.
"
42388,Image-Scaling Attacks: Discuss threat and mention secure scaling options to prevent attacks,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/image/resize

## Description of issue:
TensorFlow is vulnerable to image-scaling attacks if specific scaling algorithms and parameters are used. These attacks
allow an adversary to arbitrarily change the output image of a downscaling operation. It is a threat for machine learning applications, similar to adversarial examples. 

The resize documentation should therefore at least mention the risk of scaling attacks with specific resize settings, and motivate the usage of secure algorithms/parameters.

### Clear description
Downscaling is an important step in machine learning, as deep neural networks usually expect small fixed-sized inputs. An adversary can control the output of the downscaling step by slightly manipulating the input image. We see another image what the ML system uses for learning. This allows an attack, similar to adversarial examples. The attack is easy to deploy with a considerable impact on the security of machine learning. It is relevant whenever TF scales images that users did not create themselves.

We verified that TensorFlow provides vulnerable scaling algorithms, such as nearest, bilinear or bicubic scaling. In the default settings, many pixels are hardly or not at all included in the reduction. Attacks can thus only change those pixels that are relevant to the scaling. The remaining pixels are not changed, so that the attack is rather unnoticeable. A secure scaling algorithm should thus consider all pixels (equally).

To prevent the attack in TensorFlow, a user can either choose area scaling or set ```antialias = True``` with TensorFlow 2.x. This parameter was introduced in TF 2.x, but it is set to False by default (probably for compatibility to older version). Nearest neighbor scaling is still vulnerable if ```antialias = True``` (antialias is here ignored as documented). For older TensorFlow versions, only area scaling prevents the attack without changing the code base.

Our project website ([https://scaling-attacks.net](https://scaling-attacks.net)) shows some examples and gives more information. In our research paper on scaling attacks [1], presented at the USENIX Security Symposium, we provide a detailed root-cause analysis and discuss possible defenses.

_All in all, the resize documentation should raise the awareness for the risk of scaling attacks in machine learning. 
In the long run, scaling algorithms with secure parameters should be used as default (e.g. ```antialias = True``` as default)._



[1] Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning, Erwin Quiring et al., USENIX Security Symposium 2020. [Paper-Link](https://www.sec.cs.tu-bs.de/pubs/2020-sec.pdf)
"
42387,Tensorflow Aborted due to tensorflow/core/lib/monitoring/sampler.cc:42,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version (use command below):
- Python version:
All versions
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
Can't import

**Describe the current behavior**
2020-08-15 13:43:45.726668: F tensorflow/core/lib/monitoring/sampler.cc:42] Check failed: bucket_limits_[i] >
Aborted

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42386,GradientTape.gradient needs to check target type.,"https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/eager/backprop.py#L991

Recently, I wrote some code below which is very simple,
```python
tape.gradient(loss, model.trainable_variables)
```
but it raises `TypeError: Cannot convert value None to a Tensorflow DType.`
It turns out my custom loss function is returning None. yes, I know I was dumb.

I had to check all of the related tensorflow code lines to find this dumb problem.

So, I suggest the type checking block inside of this code.
I think this suggestion can be helpful for fools like me.

Thanks in advance :)"
42384,Cannot install with pip,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home
- TensorFlow version: 2.3
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip




**Describe the problem**
Cannot install any tensorflow version.

ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow

**Provide the exact sequence of commands / steps that you executed before running into the problem**
venv\Scripts\python -m pip install tensorflow

"
42383,"`metrics=['accuracy']` works, `metrics=['Accuracy']` gives `ValueError: Shapes (None, 10) and (None, 1) are incompatible`","I want to use [`tf.keras.metrics`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) the same way I use [`tf.keras.optimizers`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). I can pass `'Adam'` and it'll work. I can pass an instantiation of [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and it'll work.

Unfortunately the same isn't true for `tf.keras.metrics`, making it difficult to derive the full list of builtin metrics…

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Use this example and just replace `'accuracy'` with `'Accuracy'` https://github.com/tensorflow/datasets/blob/8723d84/docs/keras_example.ipynb
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.5

**Describe the current behavior**
Error

**Describe the expected behavior**
No error. Looking here it doesn't appear they they are different:
https://www.tensorflow.org/api_docs/python/tf/keras/metrics
https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy

Or is one the class and one an instance? - Should we be able to pass `'Accuracy'` as a string, or is the expected behaviour?

**Standalone code to reproduce the issue**
Use this example and just replace `'accuracy'` with `'Accuracy'` https://github.com/tensorflow/datasets/blob/8723d84/docs/keras_example.ipynb

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
File ""lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 1098, in fit
    tmp_logs = train_function(iterator)
  File ""lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 823, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 696, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2855, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3065, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 973, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **
        outputs = model.train_step(data)
    lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:759 train_step
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:409 update_state
        metric_obj.update_state(y_t, y_p, sample_weight=mask)
    lib/python3.8/site-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated
        update_op = update_state_fn(*args, **kwargs)
    lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:176 update_state_fn
        return ag_update_state(*args, **kwargs)
    lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:612 update_state  **
        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)
    lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:3208 accuracy  **
        y_pred.shape.assert_is_compatible_with(y_true.shape)
    lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with
        raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))

    ValueError: Shapes (None, 10) and (None, 1) are incompatible
```"
42382,Sparsemax & tf.Cumsum,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): 2.3
- TensorFlow version (or github SHA if from source): 


**Provide the text output from tflite_convert**

```
# INFO:tensorflow:Assets written to: C:\Users\The-author\AppData\Local\Temp\tmp1ty7mqo0\assets
INFO:tensorflow:Assets written to: C:\Users\The-author\AppData\Local\Temp\tmp1ty7mqo0\assets
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    198                                                  debug_info_str,
--> 199                                                  enable_mlir_converter)
    200       return model_str

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
     37       debug_info_str,
---> 38       enable_mlir_converter)
     39 

Exception: C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\ops\math_ops.py:3736:0: error: 'tf.Cumsum' op is neither a custom op nor a flex op
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\util\dispatch.py:201:0: note: called from
c:\users\The-author\appdata\local\programs\python\python37\lib\site-packages\tensorflow_addons\activations\sparsemax.py:105:0: note: called from
c:\users\The-author\appdata\local\programs\python\python37\lib\site-packages\tensorflow_addons\activations\sparsemax.py:47:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\layers\convolutional.py:269:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\base_layer.py:985:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\functional.py:508:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\functional.py:386:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\base_layer.py:985:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\saving\saving_utils.py:134:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\ops\math_ops.py:3736:0: note: see current operation: %12 = ""tf.Cumsum""(%values, %cst_1) {device = """", exclusive = false, reverse = false} : (tensor<?x?xf32>, tensor<i32>) -> tensor<?x?xf32>
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	tf.Cumsum {device = """", exclusive = false, reverse = false}
<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<?x256x256x3xf32>):  // no predecessors
  %cst = ""std.constant""() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>
  %cst_0 = ""std.constant""() {value = dense<0x7FC00000> : tensor<f32>} : () -> tensor<f32>
  %cst_1 = ""std.constant""() {value = dense<-1> : tensor<i32>} : () -> tensor<i32>
  %cst_2 = ""std.constant""() {value = dense<0> : tensor<i32>} : () -> tensor<i32>
  %cst_3 = ""std.constant""() {value = dense<1> : tensor<i32>} : () -> tensor<i32>
  %cst_4 = ""std.constant""() {value = dense<1.000000e+00> : tensor<f32>} : () -> tensor<f32>
  %cst_5 = ""std.constant""() {value = dense<""0xB2936CBE88F3B63E70265B3ED3BFC5BEDB44C63E4365F43E241B69BE14CBD0BDE4A013BE81638FBEAECCF8BE1FF1ADBEA9CB8ABE019BBD3E6ED7753DF441F53D01D5143FA511A6BE5F2A97BEE01FCFBEEBC3E23C99C39F3E6C510E3FD29ACD3E5E5F94BE26B3C2BE5BE612BF09CAB6BD97D9A83E0076BFBEE1950C3FEC438ABD41F56EBE33D299BECCFCEEBE70D91A3E3C6FD6BD7440483E123E17BDA734813EB9A9103E98BFB3BC6FA1BFBE00B5BE3E0E84AABE07AE0BBE6385B63D5B9B08BE7506263EDC6FA93ECF488EBC046AAFBE32B567BC9B356CBEFC4C803E12A3973EF17A333ECE1E1C3E4F85C7BDFA8AA6BEF72768BC53141F3B0E1D213EAD543BBE37F004BD2720973E078C2D3EEC62913E2D23863D2BF081BE4B3FC5BD4BEABFBDD257DA3ED93FA2BE20C04BBE3A34583EB16BD43E36CCCBBE318360BE3007823E26DF61BED0CA423E866A8FBE435DAC3DFD61DF3D29CD723E67DECDBE79B99EBD3870183CC82A863E8BB9C83D57CFE1BE4A8D99BE42BD263ECBAA2CBDFBF3EA3E809D4EBE2E7E04BFB6DB2BBE6D670BBE7642B5BE1A9EA0BD7C9C3ABE7074623E51C034BE10F3093E460FB1BE7F2E99BE""> : tensor<4x3x3x3xf32>} : () -> tensor<4x3x3x3xf32>
  %cst_6 = ""std.constant""() {value = dense<0.000000e+00> : tensor<4xf32>} : () -> tensor<4xf32>
  %cst_7 = ""std.constant""() {value = dense<-1> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_8 = ""std.constant""() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_9 = ""std.constant""() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_10 = ""std.constant""() {value = dense<[0, -1]> : tensor<2xi32>} : () -> tensor<2xi32>
  %cst_11 = ""std.constant""() {value = dense<0> : tensor<2xi32>} : () -> tensor<2xi32>
  %cst_12 = ""std.constant""() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>
  %0 = ""tfl.conv_2d""(%arg0, %cst_5, %cst_6) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""SAME"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x256x256x3xf32>, tensor<4x3x3x3xf32>, tensor<4xf32>) -> tensor<?x256x256x4xf32>
  %1 = ""tfl.shape""(%0) : (tensor<?x256x256x4xf32>) -> tensor<4xi32>
  %2 = ""tfl.strided_slice""(%1, %cst_8, %cst_7, %cst_9) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 0 : i32} : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<3xi32>
  %3 = ""tfl.reduce_prod""(%2, %cst_8) {keep_dims = false} : (tensor<3xi32>, tensor<1xi32>) -> tensor<i32>
  %4 = ""tfl.range""(%cst_2, %3, %cst_3) : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<?xi32>
  %5 = ""tfl.strided_slice""(%1, %cst_7, %cst_8, %cst_9) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>
  %6 = ""tfl.cast""(%5) : (tensor<i32>) -> tensor<f32>
  %7 = ""tfl.add""(%6, %cst_4) {fused_activation_function = ""NONE""} : (tensor<f32>, tensor<f32>) -> tensor<f32>
  %8 = ""tfl.range""(%cst_4, %7, %cst_4) : (tensor<f32>, tensor<f32>, tensor<f32>) -> tensor<?xf32>
  %9 = ""tfl.pack""(%3, %5) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>
  %10 = ""tfl.fill""(%9, %cst_0) : (tensor<2xi32>, tensor<f32>) -> tensor<?x?xf32>
  %11 = ""tfl.reshape""(%0, %9) : (tensor<?x256x256x4xf32>, tensor<2xi32>) -> tensor<?x?xf32>
  %values, %indices = ""tfl.topk_v2""(%11, %5) : (tensor<?x?xf32>, tensor<i32>) -> (tensor<?x?xf32>, tensor<?x?xi32>)
  %12 = ""tf.Cumsum""(%values, %cst_1) {device = """", exclusive = false, reverse = false} : (tensor<?x?xf32>, tensor<i32>) -> tensor<?x?xf32>
  %13 = ""tfl.strided_slice""(%12, %cst_10, %cst_11, %cst_12) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor<?x?xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?xf32>
  %14 = ""tf.IsNan""(%13) {device = """"} : (tensor<?xf32>) -> tensor<?xi1>
  %15 = ""tfl.mul""(%8, %values) {fused_activation_function = ""NONE""} : (tensor<?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %16 = ""tfl.add""(%15, %cst_4) {fused_activation_function = ""NONE""} : (tensor<?x?xf32>, tensor<f32>) -> tensor<?x?xf32>
  %17 = ""tfl.greater""(%16, %12) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xi1>
  %18 = ""tfl.cast""(%17) : (tensor<?x?xi1>) -> tensor<?x?xi32>
  %19 = ""tfl.sum""(%18, %cst_1) {keep_dims = false} : (tensor<?x?xi32>, tensor<i32>) -> tensor<?xi32>
  %20 = ""tfl.cast""(%19) : (tensor<?xi32>) -> tensor<?xf32>
  %21 = ""tfl.equal""(%19, %cst_2) : (tensor<?xi32>, tensor<i32>) -> tensor<?xi1>
  %22 = ""tfl.logical_or""(%21, %14) : (tensor<?xi1>, tensor<?xi1>) -> tensor<?xi1>
  %23 = ""tfl.expand_dims""(%22, %cst_1) : (tensor<?xi1>, tensor<i32>) -> tensor<?x1xi1>
  %24 = ""tfl.maximum""(%19, %cst_3) : (tensor<?xi32>, tensor<i32>) -> tensor<?xi32>
  %25 = ""tfl.sub""(%24, %cst_3) {fused_activation_function = ""NONE""} : (tensor<?xi32>, tensor<i32>) -> tensor<?xi32>
  %26 = ""tfl.reshape""(%25, %cst_7) : (tensor<?xi32>, tensor<1xi32>) -> tensor<?xi32>
  %27 = ""tfl.pack""(%4, %26) {axis = 1 : i32, values_count = 2 : i32} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?x2xi32>
  %28 = ""tfl.gather_nd""(%12, %27) : (tensor<?x?xf32>, tensor<?x2xi32>) -> tensor<?xf32>
  %29 = ""tfl.sub""(%28, %cst_4) {fused_activation_function = ""NONE""} : (tensor<?xf32>, tensor<f32>) -> tensor<?xf32>
  %30 = ""tfl.div""(%29, %20) {fused_activation_function = ""NONE""} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>
  %31 = ""tfl.expand_dims""(%30, %cst_1) : (tensor<?xf32>, tensor<i32>) -> tensor<?x1xf32>
  %32 = ""tfl.sub""(%11, %31) {fused_activation_function = ""NONE""} : (tensor<?x?xf32>, tensor<?x1xf32>) -> tensor<?x?xf32>
  %33 = ""tfl.maximum""(%32, %cst) : (tensor<?x?xf32>, tensor<f32>) -> tensor<?x?xf32>
  %34 = ""tfl.select_v2""(%23, %10, %33) : (tensor<?x1xi1>, tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %35 = ""tfl.reshape""(%34, %1) : (tensor<?x?xf32>, tensor<4xi32>) -> tensor<?x?x?x?xf32>
  ""std.return""(%35) : (tensor<?x?x?x?xf32>) -> ()
}) {sym_name = ""main"", tf.entry_function = {control_outputs = """", inputs = ""input_8"", outputs = ""Identity""}, type = (tensor<?x256x256x3xf32>) -> tensor<?x?x?x?xf32>} : () -> ()


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
<ipython-input-31-e001f5ecf3f4> in <module>
      4 converter.experimental_new_converter = True
      5 
----> 6 tflite_model = converter.convert()

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\lite.py in convert(self)
    829 
    830     return super(TFLiteKerasModelConverterV2,
--> 831                  self).convert(graph_def, input_tensors, output_tensors)
    832 
    833 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\lite.py in convert(self, graph_def, input_tensors, output_tensors)
    631         input_tensors=input_tensors,
    632         output_tensors=output_tensors,
--> 633         **converter_kwargs)
    634 
    635     calibrate_and_quantize, flags = quant_mode.quantizer_flags(

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    572       input_data.SerializeToString(),
    573       debug_info_str=debug_info_str,
--> 574       enable_mlir_converter=enable_mlir_converter)
    575   return data
    576 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    200       return model_str
    201     except Exception as e:
--> 202       raise ConverterError(str(e))
    203 
    204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\ops\math_ops.py:3736:0: error: 'tf.Cumsum' op is neither a custom op nor a flex op
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\util\dispatch.py:201:0: note: called from
c:\users\The-author\appdata\local\programs\python\python37\lib\site-packages\tensorflow_addons\activations\sparsemax.py:105:0: note: called from
c:\users\The-author\appdata\local\programs\python\python37\lib\site-packages\tensorflow_addons\activations\sparsemax.py:47:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\layers\convolutional.py:269:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\base_layer.py:985:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\functional.py:508:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\functional.py:386:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\base_layer.py:985:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\saving\saving_utils.py:134:0: note: called from
C:\Users\The-author\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\ops\math_ops.py:3736:0: note: see current operation: %12 = ""tf.Cumsum""(%values, %cst_1) {device = """", exclusive = false, reverse = false} : (tensor<?x?xf32>, tensor<i32>) -> tensor<?x?xf32>
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	tf.Cumsum {device = """", exclusive = false, reverse = false}
<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<?x256x256x3xf32>):  // no predecessors
  %cst = ""std.constant""() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>
  %cst_0 = ""std.constant""() {value = dense<0x7FC00000> : tensor<f32>} : () -> tensor<f32>
  %cst_1 = ""std.constant""() {value = dense<-1> : tensor<i32>} : () -> tensor<i32>
  %cst_2 = ""std.constant""() {value = dense<0> : tensor<i32>} : () -> tensor<i32>
  %cst_3 = ""std.constant""() {value = dense<1> : tensor<i32>} : () -> tensor<i32>
  %cst_4 = ""std.constant""() {value = dense<1.000000e+00> : tensor<f32>} : () -> tensor<f32>
  %cst_5 = ""std.constant""() {value = dense<""0xB2936CBE88F3B63E70265B3ED3BFC5BEDB44C63E4365F43E241B69BE14CBD0BDE4A013BE81638FBEAECCF8BE1FF1ADBEA9CB8ABE019BBD3E6ED7753DF441F53D01D5143FA511A6BE5F2A97BEE01FCFBEEBC3E23C99C39F3E6C510E3FD29ACD3E5E5F94BE26B3C2BE5BE612BF09CAB6BD97D9A83E0076BFBEE1950C3FEC438ABD41F56EBE33D299BECCFCEEBE70D91A3E3C6FD6BD7440483E123E17BDA734813EB9A9103E98BFB3BC6FA1BFBE00B5BE3E0E84AABE07AE0BBE6385B63D5B9B08BE7506263EDC6FA93ECF488EBC046AAFBE32B567BC9B356CBEFC4C803E12A3973EF17A333ECE1E1C3E4F85C7BDFA8AA6BEF72768BC53141F3B0E1D213EAD543BBE37F004BD2720973E078C2D3EEC62913E2D23863D2BF081BE4B3FC5BD4BEABFBDD257DA3ED93FA2BE20C04BBE3A34583EB16BD43E36CCCBBE318360BE3007823E26DF61BED0CA423E866A8FBE435DAC3DFD61DF3D29CD723E67DECDBE79B99EBD3870183CC82A863E8BB9C83D57CFE1BE4A8D99BE42BD263ECBAA2CBDFBF3EA3E809D4EBE2E7E04BFB6DB2BBE6D670BBE7642B5BE1A9EA0BD7C9C3ABE7074623E51C034BE10F3093E460FB1BE7F2E99BE""> : tensor<4x3x3x3xf32>} : () -> tensor<4x3x3x3xf32>
  %cst_6 = ""std.constant""() {value = dense<0.000000e+00> : tensor<4xf32>} : () -> tensor<4xf32>
  %cst_7 = ""std.constant""() {value = dense<-1> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_8 = ""std.constant""() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_9 = ""std.constant""() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_10 = ""std.constant""() {value = dense<[0, -1]> : tensor<2xi32>} : () -> tensor<2xi32>
  %cst_11 = ""std.constant""() {value = dense<0> : tensor<2xi32>} : () -> tensor<2xi32>
  %cst_12 = ""std.constant""() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>
  %0 = ""tfl.conv_2d""(%arg0, %cst_5, %cst_6) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""SAME"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x256x256x3xf32>, tensor<4x3x3x3xf32>, tensor<4xf32>) -> tensor<?x256x256x4xf32>
  %1 = ""tfl.shape""(%0) : (tensor<?x256x256x4xf32>) -> tensor<4xi32>
  %2 = ""tfl.strided_slice""(%1, %cst_8, %cst_7, %cst_9) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 0 : i32} : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<3xi32>
  %3 = ""tfl.reduce_prod""(%2, %cst_8) {keep_dims = false} : (tensor<3xi32>, tensor<1xi32>) -> tensor<i32>
  %4 = ""tfl.range""(%cst_2, %3, %cst_3) : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<?xi32>
  %5 = ""tfl.strided_slice""(%1, %cst_7, %cst_8, %cst_9) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>
  %6 = ""tfl.cast""(%5) : (tensor<i32>) -> tensor<f32>
  %7 = ""tfl.add""(%6, %cst_4) {fused_activation_function = ""NONE""} : (tensor<f32>, tensor<f32>) -> tensor<f32>
  %8 = ""tfl.range""(%cst_4, %7, %cst_4) : (tensor<f32>, tensor<f32>, tensor<f32>) -> tensor<?xf32>
  %9 = ""tfl.pack""(%3, %5) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>
  %10 = ""tfl.fill""(%9, %cst_0) : (tensor<2xi32>, tensor<f32>) -> tensor<?x?xf32>
  %11 = ""tfl.reshape""(%0, %9) : (tensor<?x256x256x4xf32>, tensor<2xi32>) -> tensor<?x?xf32>
  %values, %indices = ""tfl.topk_v2""(%11, %5) : (tensor<?x?xf32>, tensor<i32>) -> (tensor<?x?xf32>, tensor<?x?xi32>)
  %12 = ""tf.Cumsum""(%values, %cst_1) {device = """", exclusive = false, reverse = false} : (tensor<?x?xf32>, tensor<i32>) -> tensor<?x?xf32>
  %13 = ""tfl.strided_slice""(%12, %cst_10, %cst_11, %cst_12) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor<?x?xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?xf32>
  %14 = ""tf.IsNan""(%13) {device = """"} : (tensor<?xf32>) -> tensor<?xi1>
  %15 = ""tfl.mul""(%8, %values) {fused_activation_function = ""NONE""} : (tensor<?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %16 = ""tfl.add""(%15, %cst_4) {fused_activation_function = ""NONE""} : (tensor<?x?xf32>, tensor<f32>) -> tensor<?x?xf32>
  %17 = ""tfl.greater""(%16, %12) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xi1>
  %18 = ""tfl.cast""(%17) : (tensor<?x?xi1>) -> tensor<?x?xi32>
  %19 = ""tfl.sum""(%18, %cst_1) {keep_dims = false} : (tensor<?x?xi32>, tensor<i32>) -> tensor<?xi32>
  %20 = ""tfl.cast""(%19) : (tensor<?xi32>) -> tensor<?xf32>
  %21 = ""tfl.equal""(%19, %cst_2) : (tensor<?xi32>, tensor<i32>) -> tensor<?xi1>
  %22 = ""tfl.logical_or""(%21, %14) : (tensor<?xi1>, tensor<?xi1>) -> tensor<?xi1>
  %23 = ""tfl.expand_dims""(%22, %cst_1) : (tensor<?xi1>, tensor<i32>) -> tensor<?x1xi1>
  %24 = ""tfl.maximum""(%19, %cst_3) : (tensor<?xi32>, tensor<i32>) -> tensor<?xi32>
  %25 = ""tfl.sub""(%24, %cst_3) {fused_activation_function = ""NONE""} : (tensor<?xi32>, tensor<i32>) -> tensor<?xi32>
  %26 = ""tfl.reshape""(%25, %cst_7) : (tensor<?xi32>, tensor<1xi32>) -> tensor<?xi32>
  %27 = ""tfl.pack""(%4, %26) {axis = 1 : i32, values_count = 2 : i32} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?x2xi32>
  %28 = ""tfl.gather_nd""(%12, %27) : (tensor<?x?xf32>, tensor<?x2xi32>) -> tensor<?xf32>
  %29 = ""tfl.sub""(%28, %cst_4) {fused_activation_function = ""NONE""} : (tensor<?xf32>, tensor<f32>) -> tensor<?xf32>
  %30 = ""tfl.div""(%29, %20) {fused_activation_function = ""NONE""} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>
  %31 = ""tfl.expand_dims""(%30, %cst_1) : (tensor<?xf32>, tensor<i32>) -> tensor<?x1xf32>
  %32 = ""tfl.sub""(%11, %31) {fused_activation_function = ""NONE""} : (tensor<?x?xf32>, tensor<?x1xf32>) -> tensor<?x?xf32>
  %33 = ""tfl.maximum""(%32, %cst) : (tensor<?x?xf32>, tensor<f32>) -> tensor<?x?xf32>
  %34 = ""tfl.select_v2""(%23, %10, %33) : (tensor<?x1xi1>, tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %35 = ""tfl.reshape""(%34, %1) : (tensor<?x?xf32>, tensor<4xi32>) -> tensor<?x?x?x?xf32>
  ""std.return""(%35) : (tensor<?x?x?x?xf32>) -> ()
}) {sym_name = ""main"", tf.entry_function = {control_outputs = """", inputs = ""input_8"", outputs = ""Identity""}, type = (tensor<?x256x256x3xf32>) -> tensor<?x?x?x?xf32>} : () -> ()
```

**Standalone code to reproduce the issue** 

inputs = Input((256,256,3))
outputs = tf.keras.layers.Conv2D(activation=tfa.activations.sparsemax,filters=4, kernel_size=(3,3), strides=1, padding=""same"",kernel_initializer=tf.keras.initializers.HeNormal())(inputs)

model = Model(inputs=[inputs], outputs=[outputs])

model.compile(tf.keras.optimizers.Nadam(name=""Nadam""),
              loss=tfa.losses.SparsemaxLoss(from_logits=True), 
              metrics=tf.keras.metrics.MeanIoU(4,name='mean_iou'))

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()


It can be ""fixed"" ( if we call that fixing ) by switching from the "" Sparsemax "" to the "" Softmax "" activation, but of course the softmax doesn't give the same results as the sparsemax.
I also tried the "" tfa.**layers**.Sparsemax "" but i guess that they have the same root implementation since i got an equivalent error.

**Thanks for your attention **

"
42381,Subclass model can't restore weights from h5 format,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2
- GPU model and memory: GTX 1060 6GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
The last two prints should print a tensor of random numbers.

**Describe the expected behavior**
The last two prints should print a tensor of ones. It works if we save it as TF format.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf


class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.a = tf.Variable(initial_value=tf.random.normal([5]), trainable=False, name='a')
        self.call = tf.function(func=self.call, input_signature=[
            tf.TensorSpec(shape=[None, 5], dtype=tf.float32)
        ])
        self.prod = tf.function(func=self.prod, input_signature=[
            tf.TensorSpec(shape=[None, 5], dtype=tf.float32)
        ])
        self.set = tf.function(func=self.set, input_signature=[
            tf.TensorSpec(shape=[5], dtype=tf.float32)
        ])
        self.build(input_shape=tf.TensorShape(dims=[None, 5]))

    def call(self, inputs):
        print(f'Tracing call with inputs={inputs}')
        return self.a + inputs

    def prod(self, inputs):
        print(f'Tracing prod with inputs={inputs}')
        return self.a * inputs

    def set(self, value):
        print(f'Tracing set with inputs={value}')
        self.a.assign(value)


if __name__ == '__main__':
    model = Model()
    print(model(tf.zeros(shape=[2, 5])))
    print(model.prod(tf.ones(shape=[2, 5])))
    model.set(tf.ones(shape=[5]))
    print(model(tf.zeros(shape=[2, 5])))
    print(model.prod(tf.ones(shape=[2, 5])))
    print(model.weights)
    model.save_weights('/tmp/a.h5')
    del model
    model = Model()
    model.load_weights('/tmp/a.h5')
    print(model(tf.zeros(shape=[2, 5])))
    print(model.prod(tf.ones(shape=[2, 5])))

```
The bahavior persists in Google colab: https://colab.research.google.com/drive/1b8WuO_hBvYynY5gkH_MSI0FJS0Qrj3MF?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42380,"Embedding for Embedding Projector works on one computer, not on another.","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 1909
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): Version: 2.3.0 (same problem with 2.2.0)
- Python version: 3.7, 3.8
Working computer
- CUDA/cuDNN version: 10.1
- GPU model and memory: GTX1080 8 GB
Non-working computer 1 (Lenovo Y470P)
- CUDA/cuDNN version 10.1
- GPU model and memory: GTX950M, variable memory
Non-working computer 2 (Dell XPS 8500)
- CUDA/cuDNN version 10.1
-GPU model and memory: GTX970, 4 GB (actually only 3.5 GB)

Projections for use with Embedding Projector works on one computer, doesn't work on two others. On computer 1 I get the ""No checkpoint found."" message; on computer 2 I get a blank screen in the Projecter area, nothing at all. Computer 1 used to be able to display Embedding Projector with Tensorflow 1.x.  I've never tried running Tensorboard on Computer 2 until now. All systems are 64-bit Windows 10, same version.

Expected behavior was that Embedding projector would work on computers other than my main desktop.

Embedding folders can be downloaded at this link:
https://drive.google.com/file/d/18Zojdf50CmwsS-YulwMMOBYFY-3_YORI/view?usp=sharing

No significant error or logging messages show up.
"
42379,Cube root of negative number returns nan,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-0-gb36436b087 2.3.0
- Python version: 3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: P100, 16GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
tf.constant(-1.)**(1/3.) returns nan

**Describe the expected behavior**
It should return -1

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
tf.constant(-1.)**(1/3.)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Odd roots are defined while even roots are imaginary
"
42378,The estimated size for TPUEstimatorSpec.predictions is too large. ,"I have designed a model by using [TPUEstimator API](https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/tpu/TPUEstimator). The outputs (TPUEstimatorSpec.predictions) of this model are very large (> 2GB). I got the following error:
```
# ValueError: The estimated size for TPUEstimatorSpec.predictions is too large. The transfer size is larger than the protobuf limit. Please consider using Tensors with smaller shapes or reduce batch size.
```
I am wondering if there is anyway which can bypass this limit so that I can output large results for the predictions by using 
`return tpu_estimator.TPUEstimatorSpec(mode, predictions={'outputs': tf_results})`"
42376,Exception when concatenating empty flattened layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, attached in colab.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab & local Ubuntu 20.04 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not tried
- TensorFlow installed from (source or binary): Colab: bundled, local: using pip install
- TensorFlow version (use command below): Colab: v2.3.0-0-gb36436b087, local: 2.2.0
- Python version: local: 3.8.2

**Describe the current behavior**
Using keras bundled with tensorflow, from one input with shape (None, num > 0) and another input with shape (None, num2 > 0, 0), the second is flattened, obtaining shape (None, 0), and, when trying to concatenate both, it fails during training because it assumes the shape of the second has double number of rows. Interestingly, the summary description of the model after compiling is correct. A minimum code example is in this [colab](https://colab.research.google.com/drive/1oSFd_4MBvX0-e3-S3PEpnZeJyz_RNSAY?usp=sharing).

The exception in colab is,
```
InvalidArgumentError:  ConcatOp : Dimensions of inputs should match: shape[0] = [5,1] vs. shape[1] = [10,0]
	 [[node functional_5/concatenate_2/concat (defined at <ipython-input-3-f5c5cd6d4c13>:29) ]] [Op:__inference_train_function_1468]

Function call stack:
train_function
```
While locally, I get
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: All dimensions except 1 must match. Input 1 has shape [256 0] and doesn't match input 0 with shape [128 10].
	 [[{{node training/Adam/gradients/gradients/concatenate_1/concat_grad/ConcatOffset}}]]
```

**Describe the expected behavior**
The flattened version of the input with a zero dimension should have the same number of rows.

**Standalone code to reproduce the issue**
[Colab example](https://colab.research.google.com/drive/1oSFd_4MBvX0-e3-S3PEpnZeJyz_RNSAY?usp=sharing).

**Other info / logs**
```
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1096                 batch_size=batch_size):
   1097               callbacks.on_train_batch_begin(step)
-> 1098               tmp_logs = train_function(iterator)
   1099               if data_handler.should_sync:
   1100                 context.async_wait()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    838         # Lifting succeeded, so variables are initialized and we can run the
    839         # stateless function.
--> 840         return self._stateless_fn(*args, **kwds)
    841     else:
    842       canon_args, canon_kwds = \

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2827     with self._lock:
   2828       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2829     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2830 
   2831   @property

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1846                            resource_variable_ops.BaseResourceVariable))],
   1847         captured_inputs=self.captured_inputs,
-> 1848         cancellation_manager=cancellation_manager)
   1849 
   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1922       # No tape is watching; skip to running the function.
   1923       return self._build_call_outputs(self._inference_function.call(
-> 1924           ctx, args, cancellation_manager=cancellation_manager))
   1925     forward_backward = self._select_forward_and_backward_functions(
   1926         args,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    548               inputs=args,
    549               attrs=attrs,
--> 550               ctx=ctx)
    551         else:
    552           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError:  ConcatOp : Dimensions of inputs should match: shape[0] = [5,1] vs. shape[1] = [10,0]
	 [[node functional_5/concatenate_2/concat (defined at <ipython-input-3-f5c5cd6d4c13>:29) ]] [Op:__inference_train_f
```
"
42375,"InvalidArgumentError:  indices[28,46] = -1 is not in [0, 1000) 	 [[node functional_3/embedding_4/embedding_lookup (defined at <ipython-input-64-77fdd54ae821>:5) ]] [Op:__inference_train_function_387521]","I am not sure why this error pops out, New to deep learning, Trying to add bert embedding to the LSTM model.
 Input is CSV of 2 columns - 1st column words, 2nd column labels

Problem: classification problem
"
42374,unique_with_counts() ON MULTI-DIMENSIONAL TENSOR? ,"**System information** 

     OS Platform and Distribution : macOS Catalina 10.15.3

    TensorFlow installed from : binary

    TensorFlow version : 1.15.0

    Python version: 3.7.3

**Describe the current behavior**

We have a tensor 

input = `tf.Tensor([[1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6],
 [1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6]], shape=(2, 29), dtype=int64)`

output = `tf.Tensor([[0,2,1, ... 0. 0. 0.][0, 2, 1, ... 0, 0, 0]], shape=(2, 10000), dtype=float32)`

Here 10000 is the dictionary size. 

**Describe the expected behavior**

We want vector output such that for each index it tell the frequency of each element 
ie in 
`[1296  266  504  190   44   60   13    2  337 6742 2667   14    1  119
   580  338  785  739  855  200   37    1    3    4    5    6]` ie we see 0 occurs 0 times , 1 occurs 2 times and so on .

Currently what we are getting is `tf.Tensor([[0. 4. 2. ... 0. 0. 0.]], shape=(1, 10000), dtype=float32)` we want of shape (2,10000)

The Code we are trying is 

````
import tensorflow as tf

tf.enable_eager_execution()


def get_count(feature, vocab_size):
  t1d = tf.reshape(feature, shape=(-1,))
  unique_ids = tf.unique_with_counts(tf.sort(t1d))
  #print("" -------- unique_ids --------"")
  #print(unique_ids)

  dense_vector = tf.sparse_to_dense(unique_ids.y, [vocab_size], tf.to_float(unique_ids.count))
  #print("" -------- dense_vector --------"")
  #print(dense_vector)

  feature_batch = tf.reshape(dense_vector, [1, vocab_size])
  #print("" --- vocab count feature ---"")
  #print(feature_batch)

  return feature_batch


a=tf.constant([[1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6],
 [1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6]])
print(get_count(a,10000))
````


Please tell us the right TF API transformation to do this . 
"
42372,ImportError: DLL load failed: The specified module could not be found - while importing tensorflow ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version:2.2
- Python version: checked 3.6,3.7,3.8
- Installed using virtualenv? pip? conda?: both pip and conda
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: AMD Radeon(TM) Vega 8 Graphics



**Describe the problem**
facing the problem of module not found while loding DLL when importing tensorflow.
Tried with multiple options like python version, tensorflow versions etc.

is tesnorflow also supports ADM graphic drivers ?
![Tensorflow issue](https://user-images.githubusercontent.com/37170486/90266971-7a6fb280-de72-11ea-86d3-d100f24ce971.png)

**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow as tf

**Any other info / logs**

import tensorflow
Traceback (most recent call last):

  File ""<ipython-input-1-d6579f534729>"", line 1, in <module>
    import tensorflow

  File ""C:\Users\SaiKoushik\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util

  File ""C:\Users\SaiKoushik\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context

  File ""C:\Users\SaiKoushik\Anaconda3\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe

  File ""C:\Users\SaiKoushik\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow

  File ""C:\Users\SaiKoushik\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)

ImportError: Traceback (most recent call last):
  File ""C:\Users\SaiKoushik\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
42371,No difference in time for Conv1DTranspose before and after post training quantization,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu19.04 Linux
- TensorFlow installed from (source or binary): Source
- TensorFlow version (or github SHA if from source):  2.4.0-dev20200715


**Command used to run the converter or code if you’re using the Python API**

```
class TFConvTranspose1d(tf.keras.Model):

    def __init__(self, channels, ksize, stride, padding):
        super(TFConvTranspose1d, self).__init__()
        self.conv1d_transpose = tf.keras.layers.Conv2DTranspose(
            filters = channels,
            kernel_size = (ksize, 1),
            strides = (stride, 1),
            padding = ""same"",
        )

    def call(self, x):
#         x = tf.expand_dims(x, axis=2)
        
#         print("" CONV TRANSPOSE 1D "", x.shape)
        x = self.conv1d_transpose(x)
#         print("" CONV TRANSPOSE 1D "", x.shape)
#         x = tf.squeeze(x, axis=2)
        return x
```

**The output from the converter invocation**

```
checkModel = TFConvTranspose1d(256, 16, 8, ""same"")
input_shape = (1, 100,1,  512)
checkModel.build(input_shape)

x = np.random.rand(1, 100,1,  512)
x = x.astype('float32')

out = checkModel.predict(x)
print( ""KERAS OUTPUT : "", out.shape)

print("" Number of Params : "", checkModel.count_params())

tflite_converter = tf.lite.TFLiteConverter.from_keras_model(checkModel)
tflite_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_converter.allow_custom_ops = True
tflite_converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_converter.post_training_quantize = True
tfmodel = tflite_converter.convert()

open(""convTranspose.tflite"", ""wb"").write(tfmodel)
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
-  No difference in time in Raspberry PI before and after quantization
- Producing correct results, but the model is slower than expected (model generated from old converter)
"
42370,Changing hyper parameters during training based on scalars,"I'm training a model and logging values to tensorboard. Based on these values, I would like to tune hyperparameters (in code, not by hand). For example, one could think about switching to a different loss function, or changing a coefficient in the loss function, as a function of the loss.

It is not hard to find _some_ way to do it: one way would be to simply:

1. Work with eager execution
2. Save the scalars I'm logging to tensorboard also to a python list
3. Do computations on those lists in between batches
4. Execute different eager tensorflow logic, or assign different hyperparameters, based on those computation

Is there a way that is more idiomatic? For example, it would be nice to:

- Not have to save all these scalars to python lists myself. Can they be retrieved from tensorboard in a performant way?
- Use the tf.function api for better performance

This was originally a [Stack Overflow question](https://stackoverflow.com/questions/63403109/changing-hyper-parameters-during-training-based-on-scalars).
"
42369,Fast row by row multiplication method,"So I have a vector dimension X, and a 2D array of dimensions X,Y. I need to multiply each row in the 2D array by the numbers in the vector. So technically you need to construct an identity matrix with diagonal made of the vector components, then matmul by the 2D array. But where speed is critical constructing a matrix just to perform such an operation is too expensive. Is there any smart way to do this using one of the functions of tensorflow?"
42368,"Why add the parameter ‘fallback_to_while_loop’ in the 2.3 API tf.vectorized_map( fn, elems, fallback_to_while_loop=True)","Hello,
       Does the parameter 'fallback_to_while_loop' is to fix some bugs so as to the function could perform normally?"
42367,"""No module named tensorflow"" though it is installed","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code:
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): ""pip install tensorflow-gpu""
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.10
- CUDA/cuDNN version: Cuda==10.1, cuDNN==7.6.5
- GPU model and memory: NVIDIA GeForce GT 710


**Describe the current behavior**
Tensorflow is installed and works if run it from the Terminal. ""Hello World"" test for Tensorflow also works. 
When Running code from Jupyter an error occurs (described lower) 

**Describe the expected behavior**
Code from Jupyter must run and give a default output photo.

**Standalone code to reproduce the issue**
The code is taken from your examples. The name: ""object_detection_tutorial.ipynb""

**Other info / logs** 
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-1-cdfb01024084> in <module>
      4 import sys
      5 import tarfile
----> 6 import tensorflow as tf
      7 import zipfile
      8 

ModuleNotFoundError: No module named 'tensorflow'
"
42366,Error converting multilingual universal sentence encoder to TFLite. Input 1 of node StatefulPartitionedCall was passed float from statefulpartitionedcall_args_1:0 incompatible with expected resource.,"**System information**
- OS Platform and Distribution: Ubuntu 19.10
- TensorFlow installed from (source or binary): pip install tensorflow==2.3.0

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# I've downloaded model and unarchived it to save_path
converter = tf.lite.TFLiteConverter.from_saved_model(save_path)
tflite_model = converter.convert()
```
```
InvalidArgumentError                      Traceback (most recent call last)
~/.local/lib/python3.7/site-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)
    496         results = c_api.TF_GraphImportGraphDefWithResults(
--> 497             graph._c_graph, serialized, options)  # pylint: disable=protected-access
    498         results = c_api_util.ScopedTFImportGraphDefResults(results)

InvalidArgumentError: Input 1 of node StatefulPartitionedCall/sequential/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall was passed float from Func/StatefulPartitionedCall/sequential/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/input/_1007:0 incompatible with expected resource.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-10-55fd8585264a> in <module>
      1 #convert model to tensorflow lite
      2 converter = tf.lite.TFLiteConverter.from_saved_model(save_path)
----> 3 tflite_model = converter.convert()
      4 # open(""converted_model.tflite"", ""wb"").write(tflite_model)

~/.local/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)
   1074         Invalid quantization parameters.
   1075     """"""
-> 1076     return super(TFLiteConverterV2, self).convert()
   1077 
   1078 

~/.local/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)
    876     frozen_func, graph_def = (
    877         _convert_to_constants.convert_variables_to_constants_v2_as_graph(
--> 878             self._funcs[0], lower_control_flow=False))
    879 
    880     input_tensors = [

~/.local/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py in convert_variables_to_constants_v2_as_graph(func, lower_control_flow, aggressive_inlining)
   1107 
   1108   frozen_func = _construct_concrete_function(func, output_graph_def,
-> 1109                                              converted_input_indices)
   1110   return frozen_func, output_graph_def
   1111 

~/.local/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py in _construct_concrete_function(func, output_graph_def, converted_input_indices)
    999   new_func = wrap_function.function_from_graph_def(output_graph_def,
   1000                                                    new_input_names,
-> 1001                                                    new_output_names)
   1002 
   1003   # Manually propagate shape for input tensors where the shape is not correctly

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in function_from_graph_def(graph_def, inputs, outputs)
    648     importer.import_graph_def(graph_def, name="""")
    649 
--> 650   wrapped_import = wrap_function(_imports_graph_def, [])
    651   import_graph = wrapped_import.graph
    652   return wrapped_import.prune(

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in wrap_function(fn, signature, name)
    626           signature=signature,
    627           add_control_dependencies=False,
--> 628           collections={}),
    629       variable_holder=holder,
    630       signature=signature)

~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--> 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in __call__(self, *args, **kwargs)
     85 
     86   def __call__(self, *args, **kwargs):
---> 87     return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)
     88 
     89   def call_with_variable_creator_scope(self, fn):

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in wrapped(*args, **kwargs)
     91     def wrapped(*args, **kwargs):
     92       with variable_scope.variable_creator_scope(self.variable_creator_scope):
---> 93         return fn(*args, **kwargs)
     94 
     95     return wrapped

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in _imports_graph_def()
    646 
    647   def _imports_graph_def():
--> 648     importer.import_graph_def(graph_def, name="""")
    649 
    650   wrapped_import = wrap_function(_imports_graph_def, [])

~/.local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    505                 'in a future version' if date is None else ('after %s' % date),
    506                 instructions)
--> 507       return func(*args, **kwargs)
    508 
    509     doc = _add_deprecated_arg_notice_to_docstring(

~/.local/lib/python3.7/site-packages/tensorflow/python/framework/importer.py in import_graph_def(***failed resolving arguments***)
    403       return_elements=return_elements,
    404       name=name,
--> 405       producer_op_list=producer_op_list)
    406 
    407 

~/.local/lib/python3.7/site-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)
    499       except errors.InvalidArgumentError as e:
    500         # Convert to ValueError for backwards compatibility.
--> 501         raise ValueError(str(e))
    502 
    503     # Create _DefinedFunctions for any imported functions.

ValueError: Input 1 of node StatefulPartitionedCall/sequential/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall was passed float from Func/StatefulPartitionedCall/sequential/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/input/_1007:0 incompatible with expected resource.
```

**https://tfhub.dev/google/universal-sentence-encoder-multilingual/3**

I've tried the large model also and got the same error. Can someone help me?"
42364,`tf.data.experimental.snapshot()` hangs when using GCS paths,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9.12 stretch
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3
- Python version: 3.5.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: CUDA 10.1
- GPU model and memory: Nvidia Tesla T4

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.data.experimental.snapshot()` hangs when using a Google Storage path.

**Describe the expected behavior**
`tf.data.experimental.snapshot()` works.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
for _ in tf.data.Dataset.range(10).apply(tf.data.experimental.snapshot('gs://my-bucket/my-path')): break
```

hangs. Using a local path

```
for _ in tf.data.Dataset.range(10).apply(tf.data.experimental.snapshot('gs://my-bucket/deleteme')): break
```

works as expected.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42363,SimpleRNN possibly not using GPU,"**System information**
Colab with K80 GPU

TensorFlow git version: v2.3.0-0-gb36436b087 2.3.0

**Describe the current behavior**
The SimpleRNN cell is taking close to 15 longer to run compared to the GRU, and so it appears that the simpleRNN is not using the GPU

**Describe the expected behavior**
It should be faster, or at least as fast as the GRU layer. 
**Standalone code to reproduce the issue**
Here's the [Colab](https://colab.research.google.com/drive/1SiLNLSweAMVf5O8i5UUDShv5Jf5AWtEA?usp=sharing) to reproduce the issue."
42361,Googleapis no longer usable as a system lib with ignored com_github_googleapis_googleapis,"**Describe the problem**

TF 2.3.0 introduced a regression with https://github.com/tensorflow/tensorflow/commit/b9e1252bcb8cf8247e7393a0df65adf5b0a18c16:

Although a `com_github_googleapis_googleapis` value is still valid for `TF_SYSTEM_LIBS` it is no longer used and the project is always downloaded which might conflict with system installed versions of it.

Note how the name changed from com_github_googleapis_googleapis to com_google_googleapis and the system_build_file option is gone: https://github.com/tensorflow/tensorflow/commit/b9e1252bcb8cf8247e7393a0df65adf5b0a18c16#diff-455a4c7f8e22d7c514e8c2caa27506c5"
42360,Inference for two or more neural networks on gpu,"I am using tensorflow 1.15.0 and built a library from source with GPU gl delegates. I am using the native C ++ API. With Android NDK I am building an executable for Android.

I want to make inference for two or more networks. To do this, I create an instance of the class, in which the interpreter is created during initialization, the GPU delegate is applied and the inference is executed. The first instance with a neural network is created and performs the inference perfectly. But when the second instance of the class is initialized, 

**Problem**: I get an error when calling the ModifyGraphWithDelegate method:

`Assertion failed (TfLiteGpuDelegate Prepare: Shader compilation failed: 0:8: L0001: Typename expected, found 'unknown' : Node number 69 (TfLiteGpuDelegate) failed to prepare.`

or

`Assertion failed (TfLiteGpuDelegate Prepare: Shader compilation failed: ERROR: 0:6: 'data' : Syntax error:  syntax error INTERNAL ERROR: no main() function! ERROR: 1 compilation errors.  No code generated. Node number 69 (TfLiteGpuDelegate) failed to prepare.`

I have verified that for the second EGL thread the context is created normally and set as current. Devices supports OpenGL ES 3.2

<details>
<summary>Some code:</summary>

<code><pre>
class Model
{
public:
	typedef std::shared_ptr<ModelInterpreter> Ptr;

	Model(const std::string tflite_model_path)
	{
                auto model = FlatBufferModel::BuildFromFile(tflite_model_path);
                if (!model) return false;

                tflite::ops::builtin::BuiltinOpResolver resolver;

                tflite::InterpreterBuilder interpreter_builder(
                	*model,
                	resolver);

                const TfLiteStatus build_status = interpreter_builder(&interpreter, 1);

                TfLiteGpuDelegateOptions delegate_options = TfLiteGpuDelegateOptionsDefault();
                delegate_options.metadata = nullptr;
                delegate_options.compile_options.precision_loss_allowed = true; // FP16
                delegate_options.compile_options.preferred_gl_object_type = TFLITE_GL_OBJECT_TYPE_FASTEST;
                delegate_options.compile_options.dynamic_batch_enabled = 0;

                gl_delegate = TfLiteGpuDelegateCreate(&delegate_options);

                interpreter->ModifyGraphWithDelegate(gl_delegate);

                interpreter->SetAllowFp16PrecisionForFp32(true);
        }

        ~Model()
        {
                interpreter = nullptr;
                TfLiteGpuDelegateDelete(gl_delegate);
        }

        void predict(
                const Size input_size,
                float const* const input_data,
                const Size output_size,
                float* const output_data)
        {
               WriteToInputTensor(interpreter->typed_input_tensor<float>(0));
               interpreter->Invoke();
               ReadFromOutputTensor(interpreter->typed_output_tensor<float>(0));
        }

        private:
                std::unique_ptr<tflite::Interpreter> interpreter;
                TfLiteDelegate* gl_delegate;

                Model(const Model&) = delete;
                Model& operator=(const Model&) = delete;
};

</pre></code>

</details>

Why does this error occur, tell me?"
42359,How to connect or use my dataset to put in a CNN LSTM model,"I am a beginner and need guidance in writing the code to connect my dataset to the model i found somewhere in Github.

My dataset looks like:

This is How it look in my directory which shows the number of samples i have
![1](https://user-images.githubusercontent.com/35618437/90235614-3f07c080-de3f-11ea-9744-809c3c82d5ef.jpg)

Inside each sample there are 2 category AM/PM in which my model have to finally classify
![2](https://user-images.githubusercontent.com/35618437/90235644-48912880-de3f-11ea-95c6-d4d480405153.jpg)

This is the time series images, I have 8 images with certail time interval
![3](https://user-images.githubusercontent.com/35618437/90235664-5181fa00-de3f-11ea-8251-3423671c9038.jpg)

`epochs = 52`
 `time = 8`
 `n_classes = 2`
 `width,height,color_channels = 210,140,3`
 `number_of_hiddenunits = 32`
` batch_size = 16`

` def get_conv_vgg(self,input_batch):`

    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu') )(input_batch)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='SAME',strides=(2,2)))(conv_model)

    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu') )(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='SAME',strides=(2,2)))(conv_model)

    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu') )(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu') )(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='SAME',strides=(2,2)))(conv_model)

    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu') )(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu') )(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu') )(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(conv_model)
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='SAME',strides=(2,2)))(conv_model)

    #embedded
    conv_model = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(conv_model)

    return conv_model`

`def create_network(self,model_name):`
    
    input_batch = tf.keras.layers.Input(shape = (time,height,width,color_channels))
    if model_name == 'vgg':
        image_features = self.get_conv_vgg(input_batch)
        lstm_network = tf.keras.layers.LSTM(number_of_hiddenunits, return_sequences=True,dropout=0.5,recurrent_dropout=0.5)(image_features)
        lstm_network = tf.keras.layers.LSTM(number_of_hiddenunits, return_sequences=False,dropout=0.5,recurrent_dropout=0.5)(lstm_network)
        lstm_network = tf.keras.layers.Dense(1024,activation='relu')(lstm_network)
        lstm_network = tf.keras.layers.BatchNormalization()(lstm_network)
        lstm_network = tf.keras.layers.Dropout(0.5)(lstm_network)
        lstm_network = tf.keras.layers.Dense(512,activation='relu')(lstm_network)
        lstm_network = tf.keras.layers.Dropout(0.5)(lstm_network)
        lstm_network = tf.keras.layers.Dense(64,activation='relu')(lstm_network)
        lstm_network = tf.keras.layers.Dropout(0.5)(lstm_network)    
        lstm_network = tf.keras.layers.Dense(n_classes,activation='softmax')(lstm_network)

    elif model_name == 'inception':
        image_features = self.get_conv_inception(input_batch)
        lstm_network = tf.keras.layers.LSTM(number_of_hiddenunits, return_sequences=True,dropout=0.5,recurrent_dropout=0.5)(image_features)
        lstm_network = tf.keras.layers.LSTM(number_of_hiddenunits, return_sequences=False,dropout=0.5,recurrent_dropout=0.5)(lstm_network)
        lstm_network = tf.keras.layers.Dense(512,activation='relu')(lstm_network)
        lstm_network = tf.keras.layers.Dense(64,activation='relu')(lstm_network)
        lstm_network = tf.keras.layers.Dropout(0.5)(lstm_network)    
        lstm_network = tf.keras.layers.Dense(n_classes,activation='softmax')(lstm_network)

    full_network = tf.keras.Model([input_batch],lstm_network)
    full_network.summary()
    return full_network`

`def _trainer(network,train_generator,val_generator):`

    network.compile(optimizer = 'adam', loss= 'binary_crossentropy',metrics = ['accuracy'])
    network.save_weights(checkpoint_path.format(epoch=0))
    history =network.fit_generator(train_generator,epochs=epochs,steps_per_epoch=len(os.listdir(train_folder)) // batch_size,validation_data=val_generator,validation_steps=1,callbacks=[cp_callback,tensorboard_callback])`

**After seeing above situation my question is how to create train_generator and val_generator if looking my above dataset format

It is CNN LSTM architecture in which the 8 images sequence is passed through vgg and LSTM

My doubt is how can i pass this 8 images of each category in my model to train it**"
42358,"tf.data.Dataset.list_files(file_path, shuffle=True) fails (on Windows w/ CUDA)","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WIN 10 LTSC BUILD 17763
- TensorFlow installed from (source or binary): BINARY - https://pypi.org/project/tensorflow/2.3.0/
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1, CUDNN 7.6.5
- GPU model and memory: Quadro M2000M, 4096MiB

TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v2.3.0-rc2-23-gb36436b087 2.3.0 


**Describe the current behavior**
Specifically on this Windows system, with CUDA enabled (not happening w/ `os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""`, and not happening on my Linux system at all), calling tf.data.Dataset.list_files(tfrecord_path, shuffle=True) produces the following error message:

Traceback (most recent call last):
  File ""C:/lbortolotti/PerformanceMethods/python_generic_toolbox/bad_list_files.py"", line 22, in <module>
    tf.data.Dataset.list_files(tfrecord_path, shuffle=True)
  File ""C:\Python\36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1125, in list_files
    dataset = dataset.shuffle(buffer_size, seed=seed)
  File ""C:\Python\36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1240, in shuffle
    return ShuffleDataset(self, buffer_size, seed, reshuffle_each_iteration)
  File ""C:\Python\36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 3676, in __init__
    **self._flat_structure)
  File ""C:\Python\36\lib\site-packages\tensorflow\python\ops\gen_dataset_ops.py"", line 6215, in shuffle_dataset_v3
    _ops.raise_from_not_ok_status(e, name)
  File ""C:\Python\36\lib\site-packages\tensorflow\python\framework\ops.py"", line 6843, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: buffer_size must be greater than zero. [Op:ShuffleDatasetV3]

**Describe the expected behavior**
No errors, shuffled file list returned.

**Standalone code to reproduce the issue**
Gist: https://gist.github.com/optiluca/d84d169315035b8a1dadc97d52b88f24"
42357,tfl.cast cannot convert tensor to uint8 while tfv1 works without problems,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): Conda
- TensorFlow version (or github SHA if from source): 2.2.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/16zUebMOvR4vvF3GxlxTWXUy8iMzsAQbO?usp=sharing
```python
# Copy and paste here the exact command
import tensorflow.keras as keras 
import tensorflow as tf
ipt=keras.Input(shape=(256,256,3),dtype=""float32"")
tmp=tf.cast(ipt,""uint8"")
model=keras.Model(inputs=ipt,outputs=tmp)
converter=tf.lite.TFLiteConverter.from_keras_model(model)
converter.inference_output_type = tf.uint8
tflite_model=converter.convert()
```

**The output from the converter invocation**

```
# Copy and paste the output here.
ConverterError: See console for info.
2020-08-14 08:31:08.628838: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.
2020-08-14 08:31:08.628892: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.
2020-08-14 08:31:08.636532: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-14 08:31:08.641744: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200145000 Hz
2020-08-14 08:31:08.642003: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2719480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-14 08:31:08.642043: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-14 08:31:08.644263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-14 08:31:08.647089: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-08-14 08:31:08.647135: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (e497356b9cd3): /proc/driver/nvidia/version does not exist
loc(callsite(""model_5/tf_op_layer_Cast_5/Cast_5""(""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"":865:0) at callsite(""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"":959:0 at callsite(""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py"":435:0 at callsite(""<ipython-input-7-93af565c8972>"":6:0 at callsite(""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"":2882:0 at callsite(""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"":2822:0 at callsite(""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"":2718:0 at callsite(""/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py"":537:0 at callsite(""/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py"":208:0 at ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py"":399:0)))))))))): error: 'tfl.cast' op result #0 must be tensor of 32-bit float or 1-bit integer or 32-bit integer or 64-bit integer or complex type with 32-bit float elements values, but got 'tensor<1x256x256x3x!tf.uint8>'
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:865:9: error: 'tfl.cast' op result #0 must be tensor of 32-bit float or 1-bit integer or 32-bit integer or 64-bit integer or complex type with 32-bit float elements values, but got 'tensor<1x256x256x3x!tf.uint8>'
        self._initialize(args, kwargs, add_initializers_to=initializers)
        ^
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:959:5: note: called from
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
    ^
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py:435:5: note: called from
    concrete_func = func.get_concrete_function()
    ^
<ipython-input-7-93af565c8972>: note: called from
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:17: note: called from
                exec(code_obj, self.user_global_ns, self.user_ns)
                ^
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:17: note: called from
                if self.run_code(code, result):
                ^
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:20: note: called from
                   interactivity=interactivity, compiler=compiler, result=result)
                   ^
/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:9: note: called from
        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
        ^
/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:13: note: called from
            res = shell.run_cell(code, store_history=store_history, silent=silent)
            ^
/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:41: note: called from
                                        user_expressions, allow_stdin)
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
# See embedded model definition
```


"
42356,Indexing into EagerTensor returns zeros (on Windows with CUDA),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WIN 10 LTSC BUILD 17763
- TensorFlow installed from (source or binary): BINARY - https://pypi.org/project/tensorflow/2.3.0/
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1, CUDNN 7.6.5
- GPU model and memory: Quadro M2000M, 4096MiB

TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v2.3.0-rc2-23-gb36436b087 2.3.0 

**Describe the current behavior**
Specifically on this Windows system, with CUDA enabled (not happening w/ os.environ[""CUDA_VISIBLE_DEVICES""] = ""1"", and not happening on my Linux system at all), reading a tfrecord with tf.data.* returns an EagerTensor which attempting to index results in incorrect zero output.

**Describe the expected behavior**
Indexing into the EagerTensor should return the correct output!


**Standalone code to reproduce the issue**
Gist: https://gist.github.com/optiluca/ff34d153c9ff339adedf5f905cdc8240

On a working system the output is:
tf.Tensor([100. 105. 110. 115. 120.], shape=(5,), dtype=float32)
100.0
100.0

On my windows system:
tf.Tensor([100. 105. 110. 115. 120.], shape=(5,), dtype=float32)
0.0
100.0


"
42355,Indexing into EagerTensor returns all zeros (on Windows w/ CUDA),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WIN 10 LTSC BUILD 17763
- TensorFlow installed from (source or binary): BINARY - https://pypi.org/project/tensorflow/2.3.0/
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1, CUDNN 7.6.5
- GPU model and memory: Quadro M2000M, 4096MiB

TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v2.3.0-rc2-23-gb36436b087 2.3.0 

**Describe the current behavior**
Specifically on this Windows system, with CUDA enabled (not happening w/ `os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""`, and not happening on my Linux system at all), reading a tfrecord with tf.data.* returns an EagerTensor which attempting to index results in incorrect zero output.

**Describe the expected behavior**
Indexing into the EagerTensor should return the correct output!


**Standalone code to reproduce the issue**
Gist: https://gist.github.com/optiluca/ff34d153c9ff339adedf5f905cdc8240

On a working system the output is:
tf.Tensor([100. 105. 110. 115. 120.], shape=(5,), dtype=float32)
100.0
100.0

On my windows system:
tf.Tensor([100. 105. 110. 115. 120.], shape=(5,), dtype=float32)
0.0
100.0


"
42354,pip install tensorflow - dlerror: cudart64_101.dll not found,"I check my error by 'python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""' and receive the notice: 'dlerror: cudart64_101.dll not found', help me, please

2020-08-14 14:25:24.281317: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-08-14 14:25:24.282305: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-08-14 14:25:28.855733: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-08-14 14:25:29.708195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
2020-08-14 14:25:29.709324: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-08-14 14:25:29.710114: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found
2020-08-14 14:25:29.804134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-14 14:25:29.847868: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-14 14:25:30.189676: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-14 14:25:30.190778: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found
2020-08-14 14:25:30.191709: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found
2020-08-14 14:25:30.191873: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-08-14 14:25:30.195810: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-14 14:25:30.227477: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20de40d74e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-14 14:25:30.227660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-14 14:25:30.229248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-14 14:25:30.229390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]
tf.Tensor(-742.7283, shape=(), dtype=float32)

**System information**
- OS: Windows10 64 bit
- TensorFlow version:  2.3.0
- Python version: 3.8
- Installed using: pip
- CUDA/cuDNN version:  V11.0.167
- GPU model and memory: Name	NVIDIA GeForce GTX 1050 Ti
"
42353,tf.keras.losses has no attribute 'SparseCategoricalCrossentropy',"`model.compile(optimizer='adam',
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
            metrics=['accuracy'])`
Use above code, something went wrong:
![image](https://user-images.githubusercontent.com/42128459/90222246-48dcf400-de3e-11ea-93bc-2a5c8ecd8ecc.png)
Looking forward for your help.
Thank you!"
42352,How to add TFLite_Detection_PostProcess ops for my own detection model?,"I have built the efficientdet-lite model using tf.keras, and it can predict the boxes, scores, classes, but it need postprocess,such as NMS. Now I have the frozen pb file, what should i do to add TFLite_Detection_PostProcess, what's the input for TFLite_Detection_PostProcess ops"
42351,How to add TFLite_Detection_PostProcess ops,
42349,tf.data.experimental.dense_to_ragged_batch fails with inputs from generator with unspecified shape in TF 2.3,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Both
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows + Linux (Colab)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary (PyPI)
- TensorFlow version (use command below): 2.1, 2.2, 2.3
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1/7.6
- GPU model and memory: Titan RTX/P100

**Describe the expected behavior**
In TF 2.1, 2.2, and 2.3 batching variable length elements work fine when generated from tensor slices:
```python
ds = tf.data.Dataset.from_tensor_slices(tf.range(4))

# Generate variable length elements via map.
# First batch will have length 1. Subsequent batches will have length 2.
def f(x):
  if x == 0:
    return tf.ones([1,])
  else:
    return tf.ones([2,])
ds = ds.map(f)

# Inspect individual elements.
print(""Unbatched shapes:"")
for batch in ds:
  print(batch.shape)
print()

# Batch into ragged tensors.
ds = ds.apply(tf.data.experimental.dense_to_ragged_batch(batch_size=2))

# Inspect batched elements.
print(""Batched shapes:"")
for batch in ds:
  print(batch.to_tensor().shape)
```
Outputs:
```
Unbatched shapes:
(1,)
(2,)
(2,)
(2,)

Batched shapes:
(2, 2)
(2, 2)
```

Now, in TF 2.1 and 2.2, this also works when the dataset consumes elements from a generator:
```python
# Generate elements via a generator.
# First batch will have length 1. Subsequent batches will have length 2.
def gen():
  for i in range(4):
    if i == 0:
      yield tf.ones((1,))
    else:
      yield tf.ones((2,))
ds = tf.data.Dataset.from_generator(gen, output_types=tf.float32)

# Inspect individual elements.
print(""Unbatched shapes:"")
for batch in ds:
  print(batch.shape)
print()

# Batch into ragged tensors.
ds = ds.apply(tf.data.experimental.dense_to_ragged_batch(batch_size=2))

# Inspect batched elements.
print(""Batched shapes:"")
for batch in ds:
  print(batch.to_tensor().shape)
```

Outputs:
```
Unbatched shapes:
(1,)
(2,)
(2,)
(2,)

Batched shapes:
(2, 2)
(2, 2)
```
As expected, we get identical outputs both before and after batching.


**Describe the current behavior**
In TF 2.3, the generator version results in an error:
```
[...]
InvalidArgumentError: Cannot batch tensors with different shapes in component 0. First element had shape [1] and element 1 had shape [2]. [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-4-313ce2c9fab5> in <module>()
     16 
     17 print(""Batched shapes:"")
---> 18 for batch in ds:
     19   print(batch.to_tensor().shape)
[...]
InvalidArgumentError: Cannot batch tensors with different shapes in component 0. First element had shape [1] and element 1 had shape [2].
```

The release notes for 2.3 mention:

> - tf.data.experimental.dense_to_ragged_batch works correctly with tuples.
> - tf.data.experimental.dense_to_ragged_batch to output variable ragged rank.

Presumably this issue is related to these changes.

Here's the relevant implementation for the actual batching in TF 2.2:
https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/data/experimental/ops/batching.py#L371-L426

And in TF 2.3:
https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/data/experimental/ops/batching.py#L380-L452

As suggested by the changes above, the behavior prior to 2.3 is achieved again when the output shape is specified, even if unknown:
```python
# Generate elements via a generator.
# First batch will have length 1. Subsequent batches will have length 2.
def gen():
  for i in range(4):
    if i == 0:
      yield tf.ones((1,))
    else:
      yield tf.ones((2,))

# Creating the generator explicitly specifying the unknown shape.
ds = tf.data.Dataset.from_generator(
    gen,
    output_types=tf.float32,
    output_shapes=tf.TensorShape([None])
)

# Inspect individual elements.
print(""Unbatched shapes:"")
for batch in ds:
  print(batch.shape)
print()

# Batch into ragged tensors.
ds = ds.apply(tf.data.experimental.dense_to_ragged_batch(batch_size=2))

# Inspect batched elements.
print(""Batched shapes:"")
for batch in ds:
  print(batch.to_tensor().shape)
```

Outputs:
```
Unbatched shapes:
(1,)
(2,)
(2,)
(2,)

Batched shapes:
(2, 2)
(2, 2)
```

It's definitely less convenient to have to specify the output shapes in the generator, requiring some refactoring when updating to 2.3 -- maybe the shapes could just default to unknown when batching if unspecified in the generator?

I appreciate that this is an experimental function, which is noted in the [tf.data.experimental](https://www.tensorflow.org/api_docs/python/tf/data/experimental) docs:

> Note that the tf.data.experimental API is not subject to the same backwards compatibility guarantees as tf.data, but **we will provide deprecation advice in advance of removing existing functionality**.

If this is intended behavior, then perhaps it could be documented somewhere as it does remove the ""functionality"" of being able to ragged batch elements from a generator without specified output shape :)


**Standalone code to reproduce the issue**
- [Colab: TF 2.1](https://colab.research.google.com/drive/1lm9aOqtGob7PD_LMflmCONuXrpA-M1Kg?usp=sharing) (Works)
- [Colab: TF 2.2](https://colab.research.google.com/drive/1clcicwg22-DVYirFlR_IAlbWaAn-NfUf?usp=sharing) (Works)
- [Colab: TF 2.3](https://colab.research.google.com/drive/1NK5SWwqUaMsisDBjsRe8E-gpc3kcLI5S?usp=sharing) (Fails)
- [Colab: TF 2.3 with `output_shape` specified](https://colab.research.google.com/drive/1WKYYNm96xHIMfdBn_nNwAaN_BmurVuM1?usp=sharing) (Works)


**Other info / logs**
Full traceback of the error in TF 2.3:
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py in execution_mode(mode)
   2101       ctx.executor = executor_new
-> 2102       yield
   2103     finally:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    757             output_types=self._flat_output_types,
--> 758             output_shapes=self._flat_output_shapes)
    759 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py in iterator_get_next(iterator, output_types, output_shapes, name)
   2609     except _core._NotOkStatusException as e:
-> 2610       _ops.raise_from_not_ok_status(e, name)
   2611     except _core._FallbackException:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6842   # pylint: disable=protected-access
-> 6843   six.raise_from(core._status_to_exception(e.code, message), None)
   6844   # pylint: enable=protected-access

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Cannot batch tensors with different shapes in component 0. First element had shape [1] and element 1 had shape [2]. [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-4-313ce2c9fab5> in <module>()
     16 
     17 print(""Batched shapes:"")
---> 18 for batch in ds:
     19   print(batch.to_tensor().shape)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in __next__(self)
    734 
    735   def __next__(self):  # For Python 3 compatibility
--> 736     return self.next()
    737 
    738   def _next_internal(self):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in next(self)
    770   def next(self):
    771     try:
--> 772       return self._next_internal()
    773     except errors.OutOfRangeError:
    774       raise StopIteration

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    762         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access
    763       except AttributeError:
--> 764         return structure.from_compatible_tensor_list(self._element_spec, ret)
    765 
    766   @property

/usr/lib/python3.6/contextlib.py in __exit__(self, type, value, traceback)
     97                 value = type()
     98             try:
---> 99                 self.gen.throw(type, value, traceback)
    100             except StopIteration as exc:
    101                 # Suppress StopIteration *unless* it's the same exception that

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py in execution_mode(mode)
   2103     finally:
   2104       ctx.executor = executor_old
-> 2105       executor_new.wait()
   2106 
   2107 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py in wait(self)
     65   def wait(self):
     66     """"""Waits for ops dispatched in this executor to finish.""""""
---> 67     pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
     68 
     69   def clear_error(self):

InvalidArgumentError: Cannot batch tensors with different shapes in component 0. First element had shape [1] and element 1 had shape [2].
```
"
42348,Issue with iou_threshold in non_max_suppression,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2
- GPU model and memory: 2060


**Describe the current behavior**

With TF 2.2.0, it looks like the threshold is weak (i.e. it excludes all the boxes if their iou is greater or equal than the threshold).

**Describe the expected behavior**

With TF 1.15, this threshold is strong.
In general, it doesn't make a lot of difference, except in one particular use case.
If I do a NMS to keep only non overlapping boxes, I would use a threshold of 0.
With TF 1.15, the result is the list of all non-overlapping boxes as expected.
With TF 2.2, the ouput is a single box, the one with the highest score.
There is an easy workaround of adding a small epsilon, but it's not very intuitive.

**Standalone code to reproduce the issue**

    boxes = tf.constant([[0.1, 0.1, 0.3, 0.3], [0.5, 0.5, 0.7, 0.7], [0.6, 0.6, 0.8, 0.8]], dtype=tf.float32)
    scores = tf.constant([0.9, 0.8, 0.7], dtype=tf.float32)

    print('Expected indices')
    print(tf.image.non_max_suppression(boxes, scores, 100, iou_threshold=1e-5))

    print('Actual indices')
    print(tf.image.non_max_suppression(boxes, scores, 100, iou_threshold=0.))


Output

```
Expected indices
tf.Tensor([0 1], shape=(2,), dtype=int32)
Actual indices
tf.Tensor([0], shape=(1,), dtype=int32)
```"
42347,Deploy micro_speech to ESP32 using ESP IDF,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Esp32
- esp-idf version: 4.0.1

**Describe the problem**
Unable to build the micro_speech in Tensorflow using esp-idf.

**Please provide the exact sequence of commands/steps when you ran into the problem**

Generate examples
```
cd tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/micro_speech/esp-idf
```
Building the example
```
idf.py build 
```
**Error**

```
Checking Python dependencies...
Python requirements from /home/george/esp/esp-idf/requirements.txt are satisfied.
Executing action: all (aliases: build)
Running ninja in directory /home/george/Documents/MLANDAI/tensorflow/tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/micro_speech/esp-idf/build
Executing ""ninja all""...
[3/265] cd /home/george/Documents/MLANDAI/tensorflow/tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp...data/bin/cmake -E echo ""*******************************************************************************""
Partition table binary generated. Contents:
*******************************************************************************
# Espressif ESP32 Partition Table
# Name, Type, SubType, Offset, Size, Flags
nvs,data,nvs,0x9000,24K,
phy_init,data,phy,0xf000,4K,
factory,app,factory,0x10000,1M,
*******************************************************************************
[4/265] Performing build step for 'bootloader'
ninja: no work to do.
[13/263] Building C object esp-idf/freemodbus/CMakeFiles/__idf_freemodbus.dir/serial_slave/modbus_controller/mbc_serial_slave.c.obj
FAILED: esp-idf/freemodbus/CMakeFiles/__idf_freemodbus.dir/serial_slave/modbus_controller/mbc_serial_slave.c.obj 
/home/george/.espressif/tools/xtensa-esp32-elf/esp-2020r2-8.2.0/xtensa-esp32-elf/bin/xtensa-esp32-elf-gcc  -Iconfig -I/home/george/esp/esp-idf/components/freemodbus/common/include -I/home/george/esp/esp-idf/components/freemodbus/common -I/home/george/esp/esp-idf/components/freemodbus/port -I/home/george/esp/esp-idf/components/freemodbus/modbus -I/home/george/esp/esp-idf/components/freemodbus/modbus/ascii -I/home/george/esp/esp-idf/components/freemodbus/modbus/functions -I/home/george/esp/esp-idf/components/freemodbus/modbus/rtu -I/home/george/esp/esp-idf/components/freemodbus/modbus/tcp -I/home/george/esp/esp-idf/components/freemodbus/modbus/include -I/home/george/esp/esp-idf/components/freemodbus/serial_slave/port -I/home/george/esp/esp-idf/components/freemodbus/serial_slave/modbus_controller -I/home/george/esp/esp-idf/components/freemodbus/serial_master/port -I/home/george/esp/esp-idf/components/freemodbus/serial_master/modbus_controller -I/home/george/esp/esp-idf/components/newlib/platform_include -I/home/george/esp/esp-idf/components/freertos/include -I/home/george/esp/esp-idf/components/heap/include -I/home/george/esp/esp-idf/components/log/include -I/home/george/esp/esp-idf/components/soc/esp32/include -I/home/george/esp/esp-idf/components/soc/include -I/home/george/esp/esp-idf/components/esp_rom/include -I/home/george/esp/esp-idf/components/esp_common/include -I/home/george/esp/esp-idf/components/xtensa/include -I/home/george/esp/esp-idf/components/xtensa/esp32/include -I/home/george/esp/esp-idf/components/esp32/include -I/home/george/esp/esp-idf/components/driver/include -I/home/george/esp/esp-idf/components/esp_ringbuf/include -I/home/george/esp/esp-idf/components/esp_event/include -I/home/george/esp/esp-idf/components/tcpip_adapter/include -I/home/george/esp/esp-idf/components/lwip/include/apps -I/home/george/esp/esp-idf/components/lwip/include/apps/sntp -I/home/george/esp/esp-idf/components/lwip/lwip/src/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include/arch -I/home/george/esp/esp-idf/components/vfs/include -I/home/george/esp/esp-idf/components/esp_wifi/include -I/home/george/esp/esp-idf/components/esp_wifi/esp32/include -I/home/george/esp/esp-idf/components/esp_eth/include -I/home/george/esp/esp-idf/components/efuse/include -I/home/george/esp/esp-idf/components/efuse/esp32/include -I/home/george/esp/esp-idf/components/app_trace/include -mlongcalls -Wno-frame-address   -ffunction-sections -fdata-sections -fstrict-volatile-bitfields -nostdlib -Wall -Werror=all -Wno-error=unused-function -Wno-error=unused-but-set-variable -Wno-error=unused-variable -Wno-error=deprecated-declarations -Wextra -Wno-unused-parameter -Wno-sign-compare -ggdb -Og -std=gnu99 -Wno-old-style-declaration -D_GNU_SOURCE -DIDF_VER=\""v4.0.1\"" -DGCC_NOT_5_2_0 -DESP_PLATFORM -MD -MT esp-idf/freemodbus/CMakeFiles/__idf_freemodbus.dir/serial_slave/modbus_controller/mbc_serial_slave.c.obj -MF esp-idf/freemodbus/CMakeFiles/__idf_freemodbus.dir/serial_slave/modbus_controller/mbc_serial_slave.c.obj.d -o esp-idf/freemodbus/CMakeFiles/__idf_freemodbus.dir/serial_slave/modbus_controller/mbc_serial_slave.c.obj   -c /home/george/esp/esp-idf/components/freemodbus/serial_slave/modbus_controller/mbc_serial_slave.c
/home/george/esp/esp-idf/components/freemodbus/serial_slave/modbus_controller/mbc_serial_slave.c: In function 'mbc_serial_slave_start':
/home/george/esp/esp-idf/components/freemodbus/serial_slave/modbus_controller/mbc_serial_slave.c:99:28: error: 'MB_SLAVE_ID_SHORT' undeclared (first use in this function); did you mean 'MB_SLAVE_ASSERT'?
     status = eMBSetSlaveID(MB_SLAVE_ID_SHORT, TRUE, (UCHAR*)mb_slave_id, sizeof(mb_slave_id));
                            ^~~~~~~~~~~~~~~~~
                            MB_SLAVE_ASSERT
/home/george/esp/esp-idf/components/freemodbus/serial_slave/modbus_controller/mbc_serial_slave.c:99:28: note: each undeclared identifier is reported only once for each function it appears in
/home/george/esp/esp-idf/components/freemodbus/serial_slave/modbus_controller/mbc_serial_slave.c:99:61: error: 'mb_slave_id' undeclared (first use in this function); did you mean 'mbc_slave_init'?
     status = eMBSetSlaveID(MB_SLAVE_ID_SHORT, TRUE, (UCHAR*)mb_slave_id, sizeof(mb_slave_id));
                                                             ^~~~~~~~~~~
                                                             mbc_slave_init
[22/263] Building C object esp-idf/libsodium/CMakeFiles/__idf_libsodium.dir/libsodium/src/libsodium/crypto_core/curve25519/ref10/curve25519_ref10.c.obj
ninja: build stopped: subcommand failed.
ninja failed with exit code 1


```
"
42346,Different inference values tensorflow vs tflite model,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS High Sierra-10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not checked
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.8.5
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
Model built using tensorflow and later converter to tflite gives different results for same input. See code provided to reproduce the error.

**Describe the expected behavior**
Must produce same output. 

**Standalone code to reproduce the issue**
```
from tensorflow.keras.models import Model, Sequential, load_model
from tensorflow.keras import layers, Input
import tensorflow.keras.backend as K
import tensorflow as tf
import numpy as np
import imutils
import tflite
import cv2


def get_laplacian_kernel(shape, dtype=None):
    h, w, nr_channels, channel_multiplier  = shape
    assert channel_multiplier == 1
    assert h == w == 3
    laplacian_mask = np.array([[ 0,  1, 0],
                               [ 1, -4, 1],
                               [ 0,  1, 0]])
    mask = np.zeros(shape)
    for ch in range(nr_channels):
        mask[:, :, ch, 0] = laplacian_mask
    laplacian_kernel = K.variable(mask, dtype=dtype)
    return laplacian_kernel


def build_laplacian_model():
    # allow input image to be of any size
    input_shape = (1200, 1800, 3)
    input_layer = Input(shape=input_shape, )
    layer_conv_laplacian = layers.DepthwiseConv2D(kernel_size=3,
                                                  depthwise_initializer=get_laplacian_kernel, 
                                                  depth_multiplier=1,
                                                  bias_initializer='zeros',
                                                  strides=1, padding='same',
                                                  trainable=False
                                                  )(input_layer)
    layer_variance = layers.Lambda(lambda tensor: K.var(tensor), trainable=False)(layer_conv_laplacian)
    laplacian_model = Model(inputs=input_layer, outputs=layer_variance)
    return laplacian_model

blur_model = build_laplacian_model()
print(blur_model.summary())


converter = tf.lite.TFLiteConverter.from_keras_model(blur_model)
fpath = 'model.tflite'
with open(fpath, 'wb') as fw:
    fw.write(converter.convert())
print(f'tflite model fpath: {fpath}')


interpreter = tf.lite.Interpreter(model_path=fpath)

def tflite_inference(model, imdata):
    input_details = model.get_input_details()
    output_details = model.get_output_details()
    model.resize_tensor_input(input_details[0][""index""], imdata.shape)
    model.allocate_tensors()
    model.set_tensor(input_details[0]['index'], imdata)
    model.invoke()
    result = model.get_tensor(output_details[0]['index'])
    return result


# inference using both tensorflow and tflite models
print('\n\nInference using both models')
urls = ['https://images.unsplash.com/photo-1470020337050-543c4e581988',
        'https://images.unsplash.com/photo-1516811108838-030371f93644',
        'https://zipbooks.com/wp-content/uploads/2017/05/royalty-free-images-free-of-charge.jpeg',
       ]

for url in urls:
    imdata = imutils.url_to_image(url)
    imdata = cv2.resize(imdata, dsize=(1800, 1200))
    imdata = np.array([imdata]).astype(np.float32)
    pred0 = blur_model.predict(imdata)
    pred1 = tflite_inference(interpreter, imdata)
    print(f'tensorflow: {pred0} \t tflite: {pred1}')
```

**Other info / logs** 
Output
```
Model: ""functional_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 1200, 1800, 3)]   0         
_________________________________________________________________
depthwise_conv2d (DepthwiseC (None, 1200, 1800, 3)     30        
_________________________________________________________________
lambda (Lambda)              ()                        0         
=================================================================
Total params: 30
Trainable params: 0
Non-trainable params: 30
_________________________________________________________________
None
WARNING:tensorflow:From /Users/<...>/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /Users/<...>/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: /var/<...>/assets
tflite model fpath: model.tflite


Inference using both models
tensorflow: 981.5494995117188 	 tflite: 976.8895874023438
tensorflow: 289.7860412597656 	 tflite: 285.5138854980469
tensorflow: 57.03384017944336 	 tflite: 56.148902893066406
```
"
42345,using tensorflow images in kubernetes got permission denied when accessing a hostpath(PV),"First, i'm sorry for my poor English ( sad

the following is my pod's yaml

```
apiVersion: v1
kind: Pod
metadata:
  name: aNameOfPods
  labels:
    app: tensorflow-runtime
spec:
  restartPolicy: Never
  containers:
    - name: tensorflow-runtime
      image: 'tensorflow/tensorflow:1.8.0'
      imagePullPolicy: IfNotPresent
      command:
        - /bin/sh
      args:
        - '-c'
        - >-
          cd /catdog;
          ;echo ""your application log start below..."" > $LogPath;
          sh ./do.sh >> $LogPath 2>&1;
          ;echo ""Console diconnected!..."" >> $LogPath;done
      volumeMounts:
        - mountPath: /catdog/
          name: data
        - mountPath: /logs/
          name: log
      resources:
        limits:
          nvidia.com/gpu: 0
  volumes:
    - name: data
      hostPath:
        path:  /<hidden>/
        type: Directory
    - name: log
      hostPath:
        path: /<hidden>/
        type: Directory
```

When ""cd /catdog;"" run, i got an `/bin/sh: 1: ./do.sh: Permission denied`.

But, if I mounting data under `/tmp`, and then `cd /tmp` is works. 

Is there any solution, or it is the point that i should always put my data in `/tmp`?

"
42343,CQT implementation - Feature request,"Hi TF,

I noticed that TF currently does not offer an implementation for CQT (constant-q transform). Are you planning to add this functionality?

Thank you!
"
42342,Help!! Unable to predict CNN model: How to resolve incompatible layers?,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8.4rc1

**Describe the current behavior**
Can't predict model due to unexpected layer (expects 100,352 instead gets 131,072)

**Standalone code to reproduce the issue**
Will provide a jupyternotebook link soon

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.



**ISSUE**
Help!! I can't predict my model because it's giving me the error:
`ValueError: Input 0 of layer dense_3 is incompatible with the layer: expected axis -1 of input shape to have value 100352 but received input with shape [None, 131072]`

I just finished training a CNN using a ResNet50 architecture and a few top layers.
This is the code I used for creating the model...

```
base_model = ResNet50(weights = None, include_top=False, input_shape=(200, 200, 3))

x = base_model.output
x = Flatten()(x)
x = Dropout(0.2)(x)
x = Dense(32, activation='relu')(x)
x = Dense(16, activation='relu')(x)
predictions = Dense(num_class, activation='softmax')(x)

# The model to be trained
model = Model(inputs=base_model.input, outputs=predictions)

model.compile(loss='binary_crossentropy', 
              optimizer='rmsprop', 
              metrics=['accuracy'])

callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', verbose=1)]
model.summary()
```

As you can see, I only used a few layers on top of the ResNet50 architecture. I also used an image size input of 200, 200, 3
Went it calls back, this is the summary for the FLATTEN to the 2ND LAST DENSE LAYER.

```
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 100352)       0           conv5_block3_out[0][0]           
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 100352)       0           flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 32)           3211296     dropout_1[0][0]                  
__________________________________________________________________________________________________
```

The dense layer expects an input of shape 100,352 but instead it receives an input of 131,072!! Hence, the value error when running the predict code via...

```
img_path = 'train/10_right.jpeg'
img = image.load_img(img_path, target_size =(256,256))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)

preds = model.predict(x)
```"
42340,TF 2.3 fails to build with CUDA 11.0 using only 7.5 compute,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro x64 2004 Edition
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: No, a direct accessible installation
- Bazel version (if compiling from source): 3.4.1
- GCC/Compiler version (if compiling from source): MSVC 2019 C++ compiler
- CUDA/cuDNN version: 11.0/ cuDNN ver 8.0
- GPU model and memory: RTX 2080 GPU memory : 8 GB , system memory 32 GB



**Describe the problem**
ERROR: An error occurred during the fetch of repository 'local_config_cuda':
Repository command failed
'C:/Program' is not recognized as an internal or external command, operable program or batch file.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Step 0 : git cloned the master, cd tensorflow, git checkout r2.3
Step 1 : python ./configure.py
   -> specified : (1) Python and default library path to the installed python 3.8.5 64 bit with all requisite keras packages.
  -> yes to CUDA : Found CUDA 11.0 and Found cuDNN 8.0, specified a compute capability of 7.5 (only one)
  -> optimization flags : /arch:AVX2 and /std:c++17
  -> eigen inline : N (longer compile time acceptable).
 -> no to ROCm, and no to android.
Step 2 :  bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package

Proceeded a few steps for one minute and then failed.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

 PS C:\Users\gautam\tensorflow> bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [cuda, using_cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from c:\users\gautam\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Program Files/Python3/python.exe
INFO: Reading rc options for 'build' from c:\users\gautam\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from c:\users\gautam\tensorflow\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=C:/Program Files/Python3/python.exe --action_env PYTHON_LIB_PATH=C:/Program Files/Python3/lib/site-packages --python_path=C:/Program Files/Python3/python.exe --config=xla --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0 --action_env TF_CUDA_COMPUTE_CAPABILITIES=7.5 --config=cuda --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file c:\users\gautam\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file c:\users\gautam\tensorflow\.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:cuda in file c:\users\gautam\tensorflow\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file c:\users\gautam\tensorflow\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:opt in file c:\users\gautam\tensorflow\.tf_configure.bazelrc: --copt=/arch:AVX2 --copt=/std:c++17 --define with_default_optimizations=true
INFO: Found applicable config definition build:cuda in file c:\users\gautam\tensorflow\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file c:\users\gautam\tensorflow\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:windows in file c:\users\gautam\tensorflow\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file c:\users\gautam\tensorflow\.bazelrc: --define framework_shared_object=false
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule git_repository defined at:
  C:/users/gautam/_bazel_gautam/4wn3vkrp/external/bazel_tools/tools/build_defs/repo/git.bzl:195:33: in <toplevel>
INFO: Repository local_config_cuda instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule cuda_configure defined at:
  C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl:1399:33: in <toplevel>
ERROR: An error occurred during the fetch of repository 'local_config_cuda':
   Traceback (most recent call last):
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1369
                _create_local_cuda_repository(<1 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1051, in _create_local_cuda_repository
                _find_libs(repository_ctx, <2 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 598, in _find_libs
                _check_cuda_libs(repository_ctx, <2 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 500, in _check_cuda_libs
                execute(repository_ctx, <1 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
                fail(<1 more arguments>)
Repository command failed
'C:/Program' is not recognized as an internal or external command,
operable program or batch file.
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1369
                _create_local_cuda_repository(<1 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1051, in _create_local_cuda_repository
                _find_libs(repository_ctx, <2 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 598, in _find_libs
                _check_cuda_libs(repository_ctx, <2 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 500, in _check_cuda_libs
                execute(repository_ctx, <1 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
                fail(<1 more arguments>)
Repository command failed
'C:/Program' is not recognized as an internal or external command,
operable program or batch file.
WARNING: Target pattern parsing failed.
ERROR: no such package '@local_config_cuda//cuda': Traceback (most recent call last):
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1369
                _create_local_cuda_repository(<1 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1051, in _create_local_cuda_repository
                _find_libs(repository_ctx, <2 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 598, in _find_libs
                _check_cuda_libs(repository_ctx, <2 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/gpus/cuda_configure.bzl"", line 500, in _check_cuda_libs
                execute(repository_ctx, <1 more arguments>)
        File ""C:/users/gautam/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
                fail(<1 more arguments>)
Repository command failed
'C:/Program' is not recognized as an internal or external command,
operable program or batch file.
INFO: Elapsed time: 55.288s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package
19:14:49 PS C:\Users\gautam\tensorflow>"
42336,Error when trying decode_raw for FixedLenSequenceFeature in TFRecord dataset,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: Python 3.6.10 :: Anaconda, Inc.

**Describe the current behavior**
```python
def _bytes_feature(value):
    if isinstance(value, type(tf.constant(0))):
        value = value.numpy()

    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

sequence_dict = {
    'frames': tf.train.FeatureList(feature=frames),
    ""label"": tf.train.FeatureList(feature=[tf.train.Feature(int64_list=tf.train.Int64List(value=[token])) for token in tokens]),
}
context_dict = {
    ""frames_count"": tf.train.Feature(int64_list=tf.train.Int64List(value=[frames_count])),
    ""num_tokens"": num_tokens,
}

sequence_context = tf.train.Features(feature=context_dict)
sequence_list = tf.train.FeatureLists(feature_list=sequence_dict)
example = tf.train.SequenceExample(context=sequence_context, feature_lists=sequence_list)
```
- `frames` is a sequence of `112x112` single-channel gray images, represented by a list of `results of _bytes_feature function`.
- `label` is a sequence of tokens.

My task is `seq2seq`, so the whole sequence of tokens corresponds to the whole sequence of frames `(len(frames) != len(label))`. The task is lip-reading, if that makes more sense.
I'm loading the dataset this way:
```python
sequence_features = {
    'frames': tf.io.FixedLenSequenceFeature([], dtype=tf.string),
    ""label"": tf.io.FixedLenSequenceFeature([], dtype=tf.int64),
}
context_features = {
    ""frames_count"": tf.io.FixedLenFeature([], dtype=tf.int64),
    ""num_tokens"":  tf.io.FixedLenFeature([], dtype=tf.int64),
}
dataset = tf.data.TFRecordDataset(""train-0.tfrecord"")
dataset = dataset.padded_batch(3)
dataset = dataset.map(_parse_function)
```
```python
def _parse_function(example_proto):
    context, sequence, _ = tf.io.parse_sequence_example(example_proto, context_features=context_features, sequence_features=sequence_features)
    image = tf.io.decode_raw(sequence[""frames""], tf.int8)
    label = sequence[""label""]

    return image, label
```
When I'm trying to iterate over the dataset, I receive
```
for item in dataset:
    print(item)
    break
```
```
InvalidArgumentError: DecodeRaw requires input strings to all be the same size, but element 1 has size 2444 != 2456  [[{{node DecodeRaw}}]]
```
**Describe the expected behavior**
I want to iterate over padded batches of sequences of tf.int8 tensors representing frames for one video along with batches of corresponding labels. Also I want to avoid using VarLenFeature, because sparse tensors [don't play well](https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss#notes_2) with CTC loss on GPU.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1trJ8zxQO7rtISTmYoDS24jzzONdIpvsS?usp=sharing
```python
sequence_features = {
    'frames': tf.io.FixedLenSequenceFeature([], dtype=tf.string),
    ""label"": tf.io.FixedLenSequenceFeature([], dtype=tf.int64),
}
context_features = {
    ""frames_count"": tf.io.FixedLenFeature([], dtype=tf.int64),
    ""num_tokens"":  tf.io.FixedLenFeature([], dtype=tf.int64),
}

def _parse_function(example_proto):
    context, sequence, _ = tf.io.parse_sequence_example(example_proto, context_features=context_features, sequence_features=sequence_features)
    image = tf.io.decode_raw(sequence[""frames""], tf.int8)
    label = sequence[""label""]

    return image, label

dataset = tf.data.TFRecordDataset(""train-0.tfrecord"")
dataset = dataset.map(_parse_function)
dataset = dataset.padded_batch(3)

for item in dataset:
    print(item)
    break
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
<details>
  <summary>Click to expand the error log</summary>

```
nvalidArgumentErrorTraceback (most recent call last)
/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/context.py in execution_mode(mode)
   2101       ctx.executor = executor_new
-> 2102       yield
   2103     finally:

/opt/conda/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    757             output_types=self._flat_output_types,
--> 758             output_shapes=self._flat_output_shapes)
    759 

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py in iterator_get_next(iterator, output_types, output_shapes, name)
   2609     except _core._NotOkStatusException as e:
-> 2610       _ops.raise_from_not_ok_status(e, name)
   2611     except _core._FallbackException:

/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6842   # pylint: disable=protected-access
-> 6843   six.raise_from(core._status_to_exception(e.code, message), None)
   6844   # pylint: enable=protected-access

/opt/conda/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: DecodeRaw requires input strings to all be the same size, but element 1 has size 2444 != 2456
	 [[{{node DecodeRaw}}]] [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:

InvalidArgumentErrorTraceback (most recent call last)
<ipython-input-196-f8a40c965ca8> in <module>
     29 dataset = dataset.map(_parse_image_function)
     30 
---> 31 for item in dataset:
     32     print(item)
     33     break

/opt/conda/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py in __next__(self)
    734 
    735   def __next__(self):  # For Python 3 compatibility
--> 736     return self.next()
    737 
    738   def _next_internal(self):

/opt/conda/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py in next(self)
    770   def next(self):
    771     try:
--> 772       return self._next_internal()
    773     except errors.OutOfRangeError:
    774       raise StopIteration

/opt/conda/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    762         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access
    763       except AttributeError:
--> 764         return structure.from_compatible_tensor_list(self._element_spec, ret)
    765 
    766   @property

/opt/conda/lib/python3.6/contextlib.py in __exit__(self, type, value, traceback)
     97                 value = type()
     98             try:
---> 99                 self.gen.throw(type, value, traceback)
    100             except StopIteration as exc:
    101                 # Suppress StopIteration *unless* it's the same exception that

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/context.py in execution_mode(mode)
   2103     finally:
   2104       ctx.executor = executor_old
-> 2105       executor_new.wait()
   2106 
   2107 

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/executor.py in wait(self)
     65   def wait(self):
     66     """"""Waits for ops dispatched in this executor to finish.""""""
---> 67     pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
     68 
     69   def clear_error(self):

InvalidArgumentError: DecodeRaw requires input strings to all be the same size, but element 1 has size 2444 != 2456
	 [[{{node DecodeRaw}}]]
```
</details>"
42335,When converting tf to tflite it changes the dtypes so operations like add won't work beacuse of different dtypes RuntimeError: tensorflow/lite/kernels/add.cc:93 input1->type != input2->type (INT32 != FLOAT32)Node number 296 (ADD) failed to prepare.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04.5 LTS
- TensorFlow installed from (source or binary):
tensorflow 1.15 installed with pip. altough I have tried with older versions


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
tflite_convert --graph_def_file=./saved_model2.pb --output_file=./mask-rcnn-model2.tflite --output_format=TFLITE --input_arrays=input_image,input_image_meta,input_anchors --input_shapes=1,1024,1024,3:1,14:1,261888,4 --output_arrays=mrcnn_class/Softmax,mrcnn_bbox/Reshape --enable_select_tf_ops --allow_custom_ops --target_ops=TFLITE_BUILTINS,SELECT_TF_OPS
```

**The output from the converter invocation**

```
# Copy and paste the output here.
2020-08-12 16:57:53.877756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-12 16:57:53.899894: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW
2020-08-12 16:57:53.899966: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: AI
2020-08-12 16:57:53.899989: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: AI
2020-08-12 16:57:53.900089: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.57.0
2020-08-12 16:57:53.900150: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.100.0
2020-08-12 16:57:53.900158: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 440.100.0 does not match DSO version 450.57.0 -- cannot find working devices in this configuration
2020-08-12 16:57:53.900446: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-12 16:57:53.905236: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2799925000 Hz
2020-08-12 16:57:53.905657: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x58a7850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-12 16:57:53.905678: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
/home/tensorbook/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py:854: UserWarning: Property target_ops is deprecated, please use target_spec.supported_ops instead.
  ""target_spec.supported_ops instead."" % name)
2020-08-12 16:57:55.568703: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-08-12 16:57:55.568867: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-08-12 16:58:22.490992: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize
2020-08-12 16:58:22.491020: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1967 nodes (-1026), 2180 edges (-1093), time = 26054.7871ms.
2020-08-12 16:58:22.491025: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1967 nodes (0), 2180 edges (0), time = 410.548ms.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
https://drive.google.com/file/d/17JF-Gco7xSbszPXAL-qjFbdDdlW73QJM/view?usp=sharing        ""saved frozed model""
https://drive.google.com/file/d/1t2sNK8wBatOUum3XHprO0EejWaGoMKGB/view?usp=sharing     ""tflite converted model""
```

**Failure details**
I'm working with instance segmentation keras/tensorflow model ""https://github.com/matterport/Mask_RCNN"", I'm not using the standard model but retrained or transfer learned to a different dataset... 

the model was converted successfully, but when I try to infer with this code:

```
interpreter = tf.lite.Interpreter(model_path=""../../logs/mask-rcnn-model2.tflite"")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

image = cv2.imread('./655.png')
image = image[..., ::-1]
image = image.astype(np.float32)
resized = cv2.resize(image, (1024,1024))

interpreter.set_tensor(input_details[0]['index'], [resized])

interpreter.invoke()

output_data = interpreter.get_tensor(output_details[0]['index'])
```

but if fails at interpreter.invoke() as I said in the title:

```
Traceback (most recent call last):
  File ""infer_tflite.py"", line 529, in <module>
    interpreter.invoke()
  File ""/home/tensorbook/Documents/Mask_RCNN_Kikes/tf_night_env/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py"", line 525, in invoke
    self._interpreter.Invoke()
RuntimeError: tensorflow/lite/kernels/add.cc:93 input1->type != input2->type (INT32 != FLOAT32)Node number 296 (ADD) failed to prepare.
```

I've tried using tf.cast() or even keras K.cast() from tf.float32 to tf.int32 cause later I will bump with a tf.gather_ND which only accepts int32 as index... I'm able to advance and solve the error if I cast to tf.float32 but when I try to cast it back to int32 it does it in tf but in tflite it doesn't cast it. the model architecture is something like this...

```
image_area = tf.cast(image_shape[0] * image_shape[1], tf.float32)
roi_level = log2_graph(tf.sqrt(h * w) / (224.0 / tf.sqrt(image_area)))
roi_level_2 = K.cast(tf.round(roi_level), tf.int32)
sum_to_roi_level = K.cast(4, tf.int32)
roi_level = tf.minimum(5, tf.maximum(
    2, sum_to_roi_level + roi_level_2))
roi_level = tf.squeeze(roi_level, 2)

# Loop through levels and apply ROI pooling to each. P2 to P5.
pooled = []
box_to_level = []
for i, level in enumerate(range(2, 6)):
    ix = tf.where(tf.equal(roi_level, level))
    level_boxes = tf.gather_nd(boxes, ix)
```

Any toughts on this ? I have tried many cast to many elements in the model but the casts to int32 doesn't seem to make effect on tflite. I would greatly appreciate your help. thanks a lot in advance.
"
42332,tf.tile feature parity with np.tile/torch.tile/jax.tile,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Darwin ghost.lan 18.7.0 Darwin Kernel Version 18.7.0: Mon Apr 27 20:09:39 PDT 2020; root:xnu-4903.278.35~1/RELEASE_X86_64 x86_64`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary (wheel/pip install)
- TensorFlow version (use command below): `v2.2.0-rc4-8-g2b96f3662b 2.2.0`
- Python version: `Python 3.7.5`
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**

```python
>>> import numpy as np
>>> import tensorflow as tf
>>> input = [10, 20]
>>> np.tile(input, (2,))
array([10, 20, 10, 20])
>>> tf.tile(input, (2,))
<tf.Tensor: shape=(4,), dtype=int32, numpy=array([10, 20, 10, 20], dtype=int32)>
>>> np.tile(input, (2,2))
array([[10, 20, 10, 20],
       [10, 20, 10, 20]])
>>> tf.tile(input, (2,2))
Traceback (most recent call last):
  File ""/Users/kratsg/.virtualenvs/pyhf-dev/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 11036, in tile
    input, multiples)
tensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/kratsg/.virtualenvs/pyhf-dev/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 11041, in tile
    input, multiples, name=name, ctx=_ctx)
  File ""/Users/kratsg/.virtualenvs/pyhf-dev/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 11081, in tile_eager_fallback
    ctx=ctx, name=name)
  File ""/Users/kratsg/.virtualenvs/pyhf-dev/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected multiples argument to be a vector of length 1 but got length 2 [Op:Tile]
```

**Describe the expected behavior**

I expected tensorflow to return the same thing that numpy does (or at least has the same behavior).

**Standalone code to reproduce the issue**

See above.

**Other questions**

Is there a clever workaround that mimics the behavior using `tf.stack` and `tf.repeat` somehow?"
42331,tf.nest.flatten crashes (abort) when expand_composites's constraints are violated,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.nest.flatten` crashes (abort) when `expand_composites` is 0D boolean is violated.


**Describe the expected behavior**
Expect no crash

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
import numpy as np
tf.nest.flatten(structure = np.zeros((1)), expand_composites=tf.ones((2)))
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
terminate called after throwing an instance of 'pybind11::error_already_set'
  what():  SystemError: <class 'type'> returned a result with an error set

At:
  /root/miniconda3/lib/python3.7/site-packages/numpy/core/arrayprint.py(1388): _array_repr_implementation
  /root/miniconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py(338): flatten
  <stdin>(1): <module>

Aborted (core dumped)
~~~"
42329,tf.nest.assert_same_structure crashes (abort) when some constraints are violated,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.nest.assert_same_structure` crashes (abort, systemerror) when some either `check_types` or `expand_composites` is 0d bool is violated.

**Describe the expected behavior**
Expect no crash

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

When `check_types` is boolean is violated
~~~python
import tensorflow as tf
import numpy as np
tf.nest.assert_same_structure(nest1=np.zeros((1)), nest2=tf.ones((1,1,1)), check_types=tf.ones((2)))
~~~
When `expand_composites` is boolean is violated
~~~python
import tensorflow as tf
import numpy as np
tf.nest.assert_same_structure(nest1=np.zeros((1)), nest2=tf.ones((1,1,1)), expand_composites=tf.ones((2)))
~~~

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
terminate called after throwing an instance of 'pybind11::error_already_set'
  what():  SystemError: <class 'type'> returned a result with an error set

At:
  /root/miniconda3/lib/python3.7/site-packages/numpy/core/arrayprint.py(1388): _array_repr_implementation
  /root/miniconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py(397): assert_same_structure
  <stdin>(1): <module>

Aborted (core dumped)
~~~"
42328,Build Error at Building 'tensorflow/core/distributed_runtime/eager:remote_tensor_handle_data',"

**System information**
- OS Platform and Distribution : **Linux UBUNTU 18.04**
- My device (Platform): **Odroid XU4**
- TensorFlow installed from **Source**
- TensorFlow version: **1.15.3** (and this issue appear in 1.15.0, 1.15.1)
- Python version: **3**
- Installed using virtualenv? pip? conda?: No pip package, **Only C++ lib**
- Bazel version : **0.26.1**
- GCC/Compiler version : **7**
- CUDA/cuDNN version: No CUDA Suppot, **CPU-Only**
- GPU model and memory: Armhf with 1GB Ram and 4G SWAP Memory



**Describe the problem**
I'm Trying instatal TensorFlow 1.15 on `ODROID XU4`, I'm success in installing TensorFlow 1.13 by Source Compiling on my Hardware but for TF 1.15 after few days and many efforts get an Error that i don't know what caused and how fixes.

My Bazel Command:
`bazel --output_base=/media/odroid/ExternalHard/CacheFolder build --config=opt             --config=monolithic --config=noaws      --jobs 1    --copt=""-funsafe-math-optimizations"" --copt=""-ftree-vectorize"" --copt=""-fomit-frame-pointer""  --cpu=armeabi       --local_resources 2024,0.5,1.0 --define tensorflow_mkldnn_contraction_kernel=0    tensorflow:libtensorflow_cc.so        --discard_analysis_cache --verbose_failures
`
But I get this Error:
`ERROR: /home/odroid/buildFile/tensorflow/tensorflow/tensorflow/core/distributed_runtime/eager/BUILD:148:1: C++ compilation of rule '//tensorflow/core/distributed_runtime/eager:remote_tensor_handle_data' failed (Exit 1): gcc failed: error executing command 
  (cd '/media/odroid/ExternalHard/CacheFolder/execroot/org_tensorflow' && \
  exec env - \
    PATH=/home/odroid/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=0 \
    TF_CONFIGURE_IOS=0 \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/arm-opt/bin/tensorflow/core/distributed_runtime/eager/_objs/remote_tensor_handle_data/remote_tensor_handle_data.pic.d '-frandom-seed=bazel-out/arm-opt/bin/tensorflow/core/distributed_runtime/eager/_objs/remote_tensor_handle_data/remote_tensor_handle_data.pic.o' -fPIC '-DPB_FIELD_32BIT=1' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -DCURL_STATICLIB -iquote . -iquote bazel-out/arm-opt/bin -iquote external/com_google_protobuf -iquote bazel-out/arm-opt/bin/external/com_google_protobuf -iquote external/zlib_archive -iquote bazel-out/arm-opt/bin/external/zlib_archive -iquote external/grpc -iquote bazel-out/arm-opt/bin/external/grpc -iquote external/com_github_nanopb_nanopb -iquote bazel-out/arm-opt/bin/external/com_github_nanopb_nanopb -iquote external/boringssl -iquote bazel-out/arm-opt/bin/external/boringssl -iquote external/com_google_absl -iquote bazel-out/arm-opt/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/arm-opt/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/arm-opt/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/arm-opt/bin/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/arm-opt/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/arm-opt/bin/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/arm-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/arm-opt/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/arm-opt/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/arm-opt/bin/external/highwayhash -iquote external/double_conversion -iquote bazel-out/arm-opt/bin/external/double_conversion -iquote external/snappy -iquote bazel-out/arm-opt/bin/external/snappy -iquote external/hwloc -iquote bazel-out/arm-opt/bin/external/hwloc -iquote external/curl -iquote bazel-out/arm-opt/bin/external/curl -iquote external/jsoncpp_git -iquote bazel-out/arm-opt/bin/external/jsoncpp_git -iquote external/local_config_cuda -iquote bazel-out/arm-opt/bin/external/local_config_cuda -iquote external/local_config_tensorrt -iquote bazel-out/arm-opt/bin/external/local_config_tensorrt -Ibazel-out/arm-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/arm-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -isystem external/com_google_protobuf/src -isystem bazel-out/arm-opt/bin/external/com_google_protobuf/src -isystem external/zlib_archive -isystem bazel-out/arm-opt/bin/external/zlib_archive -isystem external/grpc/include -isystem bazel-out/arm-opt/bin/external/grpc/include -isystem external/grpc/third_party/address_sorting/include -isystem bazel-out/arm-opt/bin/external/grpc/third_party/address_sorting/include -isystem external/boringssl/src/include -isystem bazel-out/arm-opt/bin/external/boringssl/src/include -isystem external/nsync/public -isystem bazel-out/arm-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/arm-opt/bin/external/eigen_archive -isystem external/gif_archive -isystem bazel-out/arm-opt/bin/external/gif_archive -isystem external/farmhash_archive/src -isystem bazel-out/arm-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/arm-opt/bin/external/double_conversion -isystem external/hwloc/hwloc -isystem bazel-out/arm-opt/bin/external/hwloc/hwloc -isystem external/hwloc/include -isystem bazel-out/arm-opt/bin/external/hwloc/include -isystem external/curl/include -isystem bazel-out/arm-opt/bin/external/curl/include -isystem external/jsoncpp_git/include -isystem bazel-out/arm-opt/bin/external/jsoncpp_git/include -isystem external/local_config_cuda/cuda -isystem bazel-out/arm-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/arm-opt/bin/external/local_config_cuda/cuda/cuda/include -w '-march=native' -Wno-sign-compare -funsafe-math-optimizations -ftree-vectorize -fomit-frame-pointer -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc -o bazel-out/arm-opt/bin/tensorflow/core/distributed_runtime/eager/_objs/remote_tensor_handle_data/remote_tensor_handle_data.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc: In function 'void tensorflow::{anonymous}::DestoryRemoteTensorHandle(tensorflow::EagerContext*, tensorflow::eager::EagerClient*, tensorflow::uint64, tensorflow::uint64, int)':
tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:30:12: error: 'class tensorflow::EagerContext' has no member named 'GetContextId'; did you mean 'NewContextId'?
   if (ctx->GetContextId() != context_id) {
            ^~~~~~~~~~~~
            NewContextId
Target //tensorflow:libtensorflow_cc.so failed to build
INFO: Elapsed time: 5417.963s, Critical Path: 60.17s
INFO: 1043 processes: 1043 local.
FAILED: Build did NOT complete successfully
`
I think main error log is this LIne:
`tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:30:12: error: 'class tensorflow::EagerContext' has no member named 'GetContextId'; did you mean 'NewContextId'?
   if (ctx->GetContextId() != context_id) {
            ^~~~~~~~~~~~
            NewContextId`


![Screenshot from 2020-08-13 21-53-40](https://user-images.githubusercontent.com/38716150/90166519-9f4f2180-ddaf-11ea-96d9-c6455652d559.png)
"
42327,data.Dataset.as_numpy_iterator is non-reentrant compared to tensorflow data iterator.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac 10.15.5 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.8.5
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
When using the numpy iterator returned from tensorflow Dataset, the iterator is not reentrant. This is different compared to the dataset iterator in tensorflow.

**Describe the expected behavior**
the numpy iterator should be reentrant which shares the same behaviour as tensorflow

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
ds = (
    tf.data.Dataset.from_tensor_slices((np.arange(2))))

iterator = ds
for elem in iterator:
    print(elem)
for elem in iterator:
    print(elem)
```
gives 
```
tf.Tensor(0, shape=(), dtype=int64)
tf.Tensor(1, shape=(), dtype=int64)
tf.Tensor(0, shape=(), dtype=int64)
tf.Tensor(1, shape=(), dtype=int64)
```
whereas 
```
ds = (
    tf.data.Dataset.from_tensor_slices((np.arange(2))))

iterator = ds.as_numpy_iterator()
for elem in iterator:
    print(elem)
for elem in iterator:
    print(elem)
```
gives 
```
0
1
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
NA"
42325,Error with exporting TF2.2.0 model with tf.lookup.StaticHashTable for Serving,"I'm using `StaticHashTable` as in one Lambda layer after the output layer of my tf.keras model. It's quite simple actually: I've a text classification models and I'm adding a simple lambda layer that takes the `model.output` and convert the model_id to more general labels. I can save this version of model with model.save(... as H5 format..) without any issue, and can load it back and use it without any problem.

Issue is, when I try to export my TF2.2.0 model for TF-Serving, I can't find how I can export it. Here is what I can do with TF1.X or with `TF2.X + tf.compat.v1.disable_eager_execution()`

```python
tf.compat.v1.disable_eager_execution()
version = 1
name = 'tmp_model'
export_path = f'/opt/tf_serving/{name}/{version}'
builder = saved_model_builder.SavedModelBuilder(export_path)

model_signature = tf.compat.v1.saved_model.predict_signature_def(
    inputs={
        'input': model.input
    }, 
    outputs={
        'output': model.output
    }
)

with tf.compat.v1.keras.backend.get_session() as sess:
    builder.add_meta_graph_and_variables(
        sess=sess,
        tags=[tf.compat.v1.saved_model.tag_constants.SERVING],
        signature_def_map={
            'predict': model_signature
        },
        # For initializing Hashtables
        main_op=tf.compat.v1.tables_initializer()
    )
    builder.save()
```

This will save my models with TF1.X format for serving and I can use it without any issue. Things is, I'm using LSTM layer and I want to use my model on GPU. By the documentation, if I disable the eager mode, I can't use the GPU-version of LSTM with TF2.2. And without going through above mentioned code, I can't save my model for serving wrt TF2.2 standard and StaticHashTables. 

Here is how I'm trying to export my TF2.2 model which is using StaticHashTables in final layer; and which is giving error as below:

```python
class MyModule(tf.Module):

    def __init__(self, model):
        super(MyModule, self).__init__()
        self.model = model
    
    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 16), dtype=tf.int32, name='input')])
    def predict(self, input):
        result = self.model(input)
        return {""output"": result}

version = 1
name = 'tmp_model'
export_path = f'/opt/tf_serving/{name}/{version}'

module = MyModule(model)
tf.saved_model.save(module, export_path, signatures={""predict"": module.predict.get_concrete_function()})
```

**Error:**
```bash
AssertionError: Tried to export a function which references untracked object Tensor(""2907:0"", shape=(), dtype=resource).
TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.
```

Any suggestion or am I missing anything on exporting TF2.2 model which is using the `StaticHashTables` in final Lambda layer for TensorFlow Serving? 

Thanks!"
42323,How to load a tflite model directly from a link or aws s3?,"In order to deploy an aws-lambda function, I want to load a large tflite model from s3 or a web_link using 'tflite.interpreter' function. This function has 'model_path' and 'model_content' arguments. I don't have enough space in the local '/tmp' was lambda folder to store the model there (with 500 MB limitation)  and use the 'model_path' argument. Is it possible to load the model directly from s3 or another web link? For example, can we use file streaming with BytesIO and the 'model_content' argument? 

Note that I'm using python=3.7 

#s3 #aws-lambda #tflite "
42321,Optimising functions with Openfermion ,"I am working on some quantum generative adversarial networks code and have a discriminator which is a function of some parameters multiplied by some expectation value measurements. For example (see below the code) the variable parameters which I would like to optimise given a loss function are the disc_weights which are multiplied by openfermion commands which measure the X and Y expectation values on qubit 0 and 1 respectively.

psi = (disc_weights[0] * QubitOperator('X0') + disc_weights[1] * QubitOperator('Y0') )

When I use a keras optimiser, it recognises disc_weights as a tf.variable but clearly has trouble with the QubitOperator commands. How do I exclude these from the optimisation routine?
"
42320,Ragged Tensors in Keras Model Output,"**System information**
- TensorFlow version (you are using): 2.3.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
I don't think ragged tensors are supported as the outputs to a model. For example the following code does not work

import tensorflow as tf

y_pred = tf.ragged.constant([[0], [0, 0]])
y_true = tf.ragged.constant([[1], [1,1]])

model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(None,), ragged=True)
])

model.compile(loss='MSE', optimizer='adam')
model.evaluate(x=y_pred, y=y_true)

Returns error:
 TypeError: Failed to convert object of type <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'> to Tensor. Contents: tf.RaggedTensor(values=Tensor(""sequential_1/Cast_1:0"", shape=(None,), dtype=float32), row_splits=Tensor(""RaggedFromVariant/RaggedTensorFromVariant:0"", shape=(None,), dtype=int64)). Consider casting elements to a supported type.

**Will this change the current api? How?**
yes. implement support for ragged tensors in keras model output

**Who will benefit with this feature?**
People who want to use ragged tensors in output, for example sequence to sequence models with variable lengths.

**Any Other info.**
No.
"
42319,How to convert a image caption model to tensorflow Lite model?ValueError: Python inputs incompatible with input_signature:,"**System information**
- OS Platform and Distribution :CentOS Linux release 7.7.1908
-TensorFlow version:2.3.0


I am following this example:<https://www.tensorflow.org/tutorials/text/image_captioning?hl=en>

It is working as it should be and saving checkpoints and I want to now convert this to a TF Lite model.

Here is the Link of full convert code:<https://colab.research.google.com/drive/1GJkGcwWvDAWMooTsECzuSRUSPbirADhb?usp=sharing>

Here is the Link of full train code:
<https://colab.research.google.com/drive/1X2d9WW1EMEzN8Rgva3rtjevP0T_jFccj?usp=sharing>

I also following the [isssue#32999](https://github.com/tensorflow/tensorflow/issues/32999)

Here is what I am running to save and them convert the inference graph:


```
@tf.function
def evaluate(image):
    hidden = decoder.reset_states(batch_size=1)

    temp_input = tf.expand_dims(load_image(image)[0], 0)
    img_tensor_val = image_features_extract_model(temp_input)
    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))

    features = encoder(img_tensor_val)

    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)
    result = []

    for i in range(max_length):
        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)

        predicted_id = tf.random.categorical(predictions, 1)[0][0]
        # print(tokenizer.index_word)
        print(predicted_id,predicted_id.dtype)

        # for key,value in tokenizer.index_word.items():
        #     key = tf.convert_to_tensor(key)
        #     tf.dtypes.cast(key,tf.int64)
        #     print(key)

        # print(tokenizer.index_word)

        result.append(predicted_id)

        # if tokenizer.index_word[predicted_id] == '<end>':
        #     return result

        dec_input = tf.expand_dims([predicted_id], 0)

    return result

export_dir = ""./""
tflite_enc_input = ''
ckpt.f = evaluate
to_save = evaluate.get_concrete_function('')

converter = tf.lite.TFLiteConverter.from_concrete_functions([to_save])
tflite_model = converter.convert()
```
but I get this error
```
ValueError: in user code:

    convert2savedmodel.py:310 evaluate  *
        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__  **
        outputs = call_fn(inputs, *args, **kwargs)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:780 __call__
        result = self._call(*args, **kwds)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:840 _call
        return self._stateless_fn(*args, **kwds)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2828 __call__
        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3171 _maybe_define_function
        *args, **kwargs)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2622 canonicalize_function_inputs
        self._flat_input_signature)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2713 _convert_inputs_to_signature
        format_error_message(inputs, input_signature))

    ValueError: Python inputs incompatible with input_signature:
      inputs: (
        Tensor(""ExpandDims_1:0"", shape=(1, 1), dtype=int32),
        Tensor(""cnn__encoder/StatefulPartitionedCall:0"", shape=(1, 64, 256), dtype=float32),
        Tensor(""zeros:0"", shape=(1, 512), dtype=float32))
      input_signature: (
        TensorSpec(shape=(1, 1), dtype=tf.int64, name=None),
        TensorSpec(shape=(1, 64, 256), dtype=tf.float32, name=None),
        TensorSpec(shape=(1, 512), dtype=tf.float32, name=None))

```

Encoder Model:
```
class CNN_Encoder(tf.keras.Model):
    def __init__(self, embedding):
        super(CNN_Encoder, self).__init__()
        # shape after fc == (batch_size, 64, embedding_dim)
        self.fc = tf.keras.layers.Dense(embedding_dim)

    @tf.function(input_signature=[tf.TensorSpec(shape=(1, 64, features_shape),dtype=tf.dtypes.float32)])
    def call(self, x):
        x = self.fc(x)
        x = tf.nn.relu(x)
        return x
```
Decoder model:
```
class RNN_Decoder(tf.keras.Model):
    def __init__(self, embedding_dim, units, vocab_size):
        super(RNN_Decoder, self).__init__()
        self.units = units

        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.gru = tf.keras.layers.GRU(self.units,
                                       return_sequences=True,
                                       return_state=True,
                                       recurrent_initializer='glorot_uniform',
                                       unroll = True)
        self.fc1 = tf.keras.layers.Dense(self.units)
        self.fc2 = tf.keras.layers.Dense(vocab_size)

        self.attention = BahdanauAttention(self.units)


    @tf.function(input_signature=[tf.TensorSpec(shape=[1, 1], dtype=tf.int64),
                                  tf.TensorSpec(shape=[1, 64, 256], dtype=tf.float32),
                                  tf.TensorSpec(shape=[1, 512], dtype=tf.float32)])
    def call(self, x , features, hidden):

        context_vector, attention_weights = self.attention(features, hidden)

        #x shape after passing through embedding == (batch_size, 1, embedding_dim)
        x = self.embedding(x)

        #x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)
        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)


        output, state = self.gru(x)

        #shape == (batch_size, max_length, hidden_size)
        x = self.fc1(output)

        #x shape == (batch_size, max_length, hidden_size)
        x = tf.reshape(x, (-1, x.shape[2]))

        # output shape == (batch_size * max_length, vocab)
        x = self.fc2(x)

        return x, state, attention_weights

    def reset_states(self, batch_size):
        return tf.zeros((batch_size, self.units))
```"
42782,Any tutorial that does not use keras or eager execution?,"Hi, first of all, thanks for this amazing tutorial, it really clarifies many concepts.

The keras API are obviously convenient for users, except that they hide many details for learners too, which causes extra difficulty when debugging. For example, what happens inside DenseFeatures, what is the argument requirement and how does keras.layers.DenseFeatures differ from old input_layer api?

Lots of existing tutorials elsewhere are still based on tf 1.x, but some of 1.x components(e.g. Session, input_layer) are gone in 2.x API. The detailed usage of 2.x apis are not widely explored and documented, so currently both 1.x and 2.x api are used in my code. I and not sure if it will cause some problems in the future.

Eager execution sounds like great feature, but I've got feedbacks from others that it will cause compatibility and performance issues. I am unaware of the exact details but I guess this feature will not be enabled for a while.

So I wonder if there are some 2.x examples that do not heavily rely on keras of eager execution? I'd really appreciate if there are some.

Thanks."
42318,Could not load dynamic library 'libcusparse.so.10,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  binary
- TensorFlow version:  2.4.0
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?:virtualenv
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 10/9
- CUDA/cuDNN version: 11/8
- GPU model and memory: nvidia 2060



**Describe the problem**
I can't figure out how to install the module:__Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory__
**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
 I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
 I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
 I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
 I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
 W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory
I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
 W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices..
"
42316,Poor code on Docs,"Code doesn't work, imports aren't listed and K.dot is just too vague
https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN"
42315,"[TensorFlow 1.14] : Use tf.data.TFRecordDataset to obtain hdfs data, and the network can reach a maximum of 600Mb/s. However, the network is dual 10G.","1. description：
    **Machine environment**: 4U40C128G.
    When num_parallel_calls is set to 4, 10, 32, and the network  can reach 600Mb/s. The parameter(num_parallel_calls) does not take effect. 
    At the same time, the network card is dual 10G, using hadoop fs -copyToLocal, the network can reach 2g/s.
    Using tf.data.TFRecordDataset to load hdfs data, the network did not reach the bottleneck, and cores did not reach the bottleneck(Use less than 5 cores).
2. code
def input_fn(input_files, num_epochs=1, shuffle=True, batch_size=1000, buffer_size=100000):
    dataset = tf.data.TFRecordDataset(input_files)
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(buffer_size=batch_size * 10)
    dataset = dataset.repeat(num_epochs)
    dataset = dataset.map(decode, num_parallel_calls=32)
    iterator = dataset.make_one_shot_iterator()
    example,lables = iterator.get_next()
    return example,lables

pls why?
Is it a performance problem with TensorFlow loading data, or is it the wrong way to use it? 

"
42313,TF 2.3.0 build failure when its conda package is built using Anaconda's toolchain ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux RHEL 7 ppc64le
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source v2.3.0
- TensorFlow version: 2.3.0
- Python version: 3.6/3.7
- Installed using virtualenv? pip? conda?: Building conda package of TF 2.3
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 7.3
- CUDA/cuDNN version: 10.2/7

**Describe the problem**
I'm trying to build conda package of TF 2.3 using Anaconda's toolchain with gcc 7.3 on ppc64le. And with gpu variant build, I'm getting following error -

```
ERROR: /home/builder/.cache/bazel/_bazel_builder/738bada2dae39de8837b3ef244ba3e1e/external/flatbuffers/BUILD.bazel:64:1: Linking of rule '@flatbuffers//:flatc' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /home/builder/.cache/bazel/_bazel_builder/738bada2dae39de8837b3ef244ba3e1e/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla \
    GCC_HOST_COMPILER_PATH=/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_build_env/bin/powerpc64le-conda_cos7-linux-gnu-cc \
    LD_LIBRARY_PATH=::/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/extras/CUPTI/lib64::/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/cuda/lib: \
    PATH=/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_build_env/bin:/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin:/opt/anaconda3/condabin:/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_build_env:/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_build_env/bin:/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla:/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin:/opt/anaconda3/bin:/opt/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python \
    PYTHON_LIB_PATH=/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib/python3.6/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0,7.5 \
    TF_CUDA_PATHS=/opt/anaconda3/conda-bld/tensorflow-base_1597311086398/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla \
    TF_CUDA_VERSION=10.2 \
    TF_CUDNN_VERSION=7 \
    TF_ENABLE_XLA=1 \
    TF_NCCL_VERSION=2 \
    TF_NEED_CUDA=1 \
    TF_SYSTEM_LIBS=org_sqlite \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/ppc-opt/bin/external/flatbuffers/flatc-2.params)
Execution platform: @local_execution_config_platform//:platform
powerpc64le-conda_cos7-linux-gnu-cc: error: bazel-out/ppc-opt/bin/external/flatbuffers/flatc: No such file or directory
Target @flatbuffers//:flatc failed to build
```

Even on Linux x86_64 with gcc 5.4 I'm seeing similar issue with some or other shared library being generated by build. Also, note that only GPU build is getting affected. CPU builds are working fine. And this error occurs only within conda environment. Standalone build of TF using gcc 7.4 works fine on ppc64le.

**Any other info / logs**
When I digged into the TF commits that went into 2.3.0, I found the change done in this commit https://github.com/tensorflow/tensorflow/commit/e0b19f6ef223af40e2e6d1d21b8464c1b2ebee8f#diff-ee64a9d8638aa0a655dfaac625f72bb2 has been causing the above problem. Since the exact problem is not mentioned in the bazel output, I am unable to find out what has gone wrong in the above commit. Reverting the change done in this cc_toolchain_config.bzl.tpl file fixes the problem for me.

If somebody could help me figure out what (specifically from above commit) might caused this error, it would be really appreciated.
"
42312,Input and output tensors of converted TFLite model do not accord with trained model in TF,"@tensorflow/micro

**System information**
Hardware : Freescale i.MX6 Quad/DualLite
Processor: ARMv7 Processor rev 10 (v71)
OS Platform and Distribution: Yocto built Linux distribution (kernel 4.9.4+)
The tf-lite library was built with flex delegate enabled and using default makefile: https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/lite/tools/make/Makefile
API : CPP

**Describe the problem**
I developed a custom image segmentation model (based on ENet's architecture) that works with 320x240x3 images and outputs 320x240 images. The pixel values range from 0 to 2, corresponding with one of the three classes. During training and evaluation everything went fine. Converting the graph to pb and then to TF Lite format messes up the input and output sizes.



**Please provide the exact sequence of commands/steps when you ran into the problem**

I trained the ENet based model locally on a GPU. Everything went fine. I then followed the guidelines and then froze the graph (the inputs and outputs) so ended up with a model in protobuf format (.pb). In the last step I converted the model to .lite (using integer quantization). When examining statistics of the model with the TFLite interpreter on my embedded device, I see that the output corresponds to one float only (instead of the expected 320x240 ints) and that the input tensor is of size 921600. (exactly four times the amount of pixels in 320x240x3 images - because, during training, the batch size was 5 I see no link with the batch size). The same is true for the output tensor (`ENET/logits_to_softmax` - node 286) : 
![image](https://user-images.githubusercontent.com/29673343/90166030-df0b0e80-dd99-11ea-9547-a583bbd6da19.png)


My main question is thus why the input and output tensors are so 4 times too big to account for the input and output data? 
"
42311,Lambda layer with custom function gives gradient error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below): 2.2.0
- Python version: 3.5.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2
- GPU model and memory: Geforce RTX 2080 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I have created a GAN style model with a weightless transformation layer as the final layer in the generator. This layer is a Lambda layer, and the function it calls uses only Tensorflow ops. When running a training loop using train_on_batch, I get the following error (the layers mentioned in the error are layers of the generator):
```
ValueError: No gradients provided for any variable: ['dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'dense_5/kernel:0', 'dense_5/bias:0'].
```

The model is meant to take in latent noise and produce 4 outputs corresponding to two (x, y) pairs representing the top left and bottom right corners of a square on a canvas. The Lambda layer converts these coordinates into an image of a square which is then fed into the discriminator.

**Describe the expected behavior**
I expect the model to be able to train using my training loop with no issues and to be able to use the custom Lambda function / layer that I wrote to transform the Dense layer outputs into an image Tensor.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

I have included two main GitHub gists with my code. One file is the training file and the other builds the GAN models:

Train.py: https://gist.github.com/micahreich/13208980a22be2f53e3f8eba05c0db72
Models.py: https://gist.github.com/micahreich/80e44710417707bf3fb6327cb9946b79

It should be noted that the train.py training file loads a numpy file which contains the dataset. If you want to create some data, use the data loader: https://gist.github.com/micahreich/fde2024365ec91c818af6e5203d4f98e (change n_samples to a small number for testing)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The full error traceback is below:
```
Traceback (most recent call last):
  File ""train.py"", line 95, in <module>
    TL.train()
  File ""train.py"", line 83, in train
    g_loss = self.gan.train_on_batch(noise, valid)
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py"", line 1348, in train_on_batch
    logs = train_function(iterator)
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/distribute/mirrored_strategy.py:770 _call_for_each_replica
        fn, args, kwargs)
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/distribute/mirrored_strategy.py:201 _call_for_each_replica
        coord.join(threads)
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py:389 join
        six.reraise(*self._exc_info_to_raise)
    /nethome/mreich8/.local/lib/python3.5/site-packages/six.py:703 reraise
        raise value
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception
        yield
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/distribute/mirrored_strategy.py:998 run
        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py:541 train_step  **
        self.trainable_variables)
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py:1804 _minimize
        trainable_variables))
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:521 _aggregate_gradients
        filtered_grads_and_vars = _filter_grads(grads_and_vars)
    /nethome/mreich8/.local/lib/python3.5/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1219 _filter_grads
        ([v.name for _, v in grads_and_vars],))

    ValueError: No gradients provided for any variable: ['dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'dense_5/kernel:0', 'dense_5/bias:0'].
```

Thank you."
42310,tensorflow lite inference via c++ : interpreter->output_tensor(0) gives wrong tensor value,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.4 and windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  Samsung  Galaxy S8
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.8
- Bazel version (if compiling from source):  3.1.0
- GCC/Compiler version (if compiling from source): c++11
- CUDA/cuDNN version: Non
- GPU model and memory: Tesla V100, 16G memory

**Describe the current behavior**
I tried to run a TensorFlow (v2.3.0) lite inference of Mobilentnet v2 in various languages, such as python, Android (Java), and C++ (Android JNI). It works well for python and Android(Java), but the output in C++ (Android JNI) is a mess.

If I roll back to Tensorflow v2.0.0, it works well in python, Android, and c++.

The code in Android JNI c++  is as below:
_model = tflite::FlatBufferModel::BuildFromBuffer(data,numBytesRead );
tflite::ops::builtin::BuiltinOpResolver resolver;  
tflite::InterpreterBuilder(*_model, resolver)(&interpreter);
if (interpreter->AllocateTensors() != kTfLiteOk ){ 
        return false;
    }
interpreter->SetNumThreads(1);

if (interpreter->outputs().size() != 1) {  
     return false;
}
outputs = interpreter->output_tensor(0);

I debugged the code and found several issues:
a. interpreter->outputs().size() = 18446743945091386451
b. outputs->dims->shape = 4
c. [pseudo code] outputs->dims->data[0,1,2,3] = 1, 224, 224, 3

I debugged it and found the issue of 
**Describe the expected behavior**
a. interpreter->outputs().size() = 1
b. outputs->dims->shape = 2
c. [pseudo code] outputs->dims->data[0,1] = 1, 1000


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Mobilenet V2 is from keras_applications.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

NA."
42309,Ubuntu 20.04 libcudnn.so.7,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.2
- CUDA/cuDNN version: 10.2, 8.0.2
- GPU model and memory: nVidia GeForce GT 710, 1GB of memory


**Describe the current behavior**

When i import tensorflow with `import tensorflow as tf` everything is fine. But when I try to test the if the gpu is working, this error shows up.
`
Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
`
It says that the directories don't exist so i thought it was a permission problem. I added the permission with `chmod a+r` but nothing changed.

**Describe the expected behavior**
I want it to work with my GPU.

**Standalone code to reproduce the issue**
`import tensorflow as tf`
`print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))`
"
42308,Exception on converting the 'stacked LSTM model' as a 'TF Lite' format.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, FULLY_CONNECTED, LESS, LOGICAL_AND, LOGISTIC, MUL, RANGE, RESHAPE, SPLIT, TANH, TRANSPOSE. Here is a list of operators for which you will need custom implementations: Enter, Exit, LoopCond, Merge, Switch, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

The exception was triggered when I try to convert the stacked LSTM model.
The original source code is provided as following URL.
 -> https://github.com/YeongHyeon/FARED_for_Anomaly_Detection
For making 'tflite' file, I have already trained the above neural network.
Also, I have prepared the 'pbtxt' and 'pb' files
Please give me some solution!
Thank you and have a nice day.
:)
"
42306,InvalidArgumentError: Operation 'while' has no attr named '_XlaCompile',"**System information**
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow):** Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**  Google Colab (Ubuntu 18.04.3 LTS)
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:** N/A
- **TensorFlow installed from (source or binary):** Pre-installed / source
- **TensorFlow version (use command below):** 2.3.0 (and tried tf-nightly with 2.4.0-dev20200812)
- **Python version:** 3.6.9
- **Bazel version (if compiling from source):** N/A
- **GCC/Compiler version (if compiling from source):** N/A
- **CUDA/cuDNN version:** CUDA Version = 10.1
- **GPU model and memory:** Tesla T4 and 12G

**Describe the problem**
I am trying to implement a custom multi-input and -output model which uses a learning algorithm as proposed in a research paper. The model itself works fine without the custom learning algorithm which I use as a baseline. The problem I encounter is that the code got stuck in ```mc_pred = self.main_classifier([xu, xs], training=True)``` in the train_step function in the DebiasModel class.

It did not return an error. After running for an hour, I interrupted the kernel and it returns the error message saying:

```
InvalidArgumentError: Operation 'while' has no attr named '_XlaCompile'.
```
I am not sure what the issue is and I have tried it with ```tf-nighly``` and to use ```persistent=True``` in tf.GradientTape as well instead of declaring two gradientTapes in single watch. But, exactly the same error occurs.

Does anyone have any idea what this issue is? And how it can be solved?

**Source code**
```
import string
import nltk
import time

nltk.download('punkt')

import pandas as pd
import numpy as np
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

from keras.layers import Embedding
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import *

# Load dataset
example_df = pd.read_csv('example.csv')

# Sample train/validation/test data
np.random.seed(100)
train, validation, test = np.split(example_df.sample(frac=1), [int(.7*len(example_df)), int(.85*len(example_df))])

# Class Weight Function
def compute_sample_weights(df, target, t_expect, weight_name):
  # Setup mitigator_weight
  df[weight_name] = 0

  # Get frequencies per target level
  targets = df.groupby(target).size()

  # Compute sample weights
  target_weights = t_expect / (targets / targets.sum())

  # Convert to dictionary
  target_dict = target_weights.to_dict()

  # Add sample weights to dataframe
  for i in target_dict:
    df[weight_name] = np.where((df[target] == i), target_dict[i], df[weight_name])
  
  return df

# Compute Main Class Weights
train = compute_sample_weights(df=train, target='target', t_expect=(1/3), weight_name='mainClass_weight')

# Compute Protect Class Weights
train = compute_sample_weights(df=train, target='protect', t_expect=(1/2), weight_name='protectClass_weight')

# Preprocess Text Data
vocab_size = 25000
max_length = 300
padding_type = 'post'
trunc_type = 'post'
oov_tok = '<unk>'

def Text_to_Seq(train, val, test, vocab_size, max_length, padding_type, trunc_type, oov_tok):
    # Text tokenization
    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
    tokenizer.fit_on_texts(train)

    # Create word_index
    word_index = tokenizer.word_index

    # Transforms each text doc to a sequence of integers in train, val and test
    x = tokenizer.texts_to_sequences(train)
    y = tokenizer.texts_to_sequences(val)
    z = tokenizer.texts_to_sequences(test)

    # Pad sequences to the same length
    x = pad_sequences(x, maxlen=max_length, padding=padding_type, truncating=trunc_type)
    y = pad_sequences(y, maxlen=max_length, padding=padding_type, truncating=trunc_type)
    z = pad_sequences(z, maxlen=max_length, padding=padding_type, truncating=trunc_type)

    return x, y, z, word_index

train_text = train['reviewText']
val_text = validation['reviewText']
test_text = test['reviewText']

train_text, val_text, test_text, word_index = Text_to_Seq(train_text, val_text, test_text, vocab_size, max_length, padding_type, trunc_type, oov_tok)

# Create input, target, protect, sample_weights for Train
xu_train = np.array(train_text, dtype=np.int32)
xs_train = np.array(train.iloc[:, np.r_[0, 2, 10:30]], dtype=np.int32)
y_train = np.array(train[['target_negative', 'target_neutral', 'target_positive']], dtype=np.float32)
z_train = np.array(train['protect_m'], dtype=np.float32).reshape((-1,1))
mainClass_weight = np.array(train['mainClass_weight'], dtype=np.float32).reshape((-1,1))
protectClass_weight = np.array(train['protectClass_weight'], dtype=np.float32).reshape((-1,1))

# Create input, target, protect for Validation
xu_val = np.array(val_text, dtype=np.int32)
xs_val = np.array(validation.iloc[:, np.r_[0, 2, 8:28]], dtype=np.int32)
y_val = np.array(validation[['target_negative', 'target_neutral', 'target_positive']], dtype=np.float32)
z_val = np.array(validation['protect_m'], dtype=np.float32).reshape((-1,1))

# Create input, target, protect for Test
xu_test = np.array(test_text, dtype=np.int32)
xs_test = np.array(test.iloc[:, np.r_[0, 2, 8:28]], dtype=np.int32)
y_test = np.array(test[['target_negative', 'target_neutral', 'target_positive']], dtype=np.float32)
z_test = np.array(test['protect_m'], dtype=np.float32).reshape((-1,1))
```
```
# Setup Pretrained GloVe Embedding
def load_embedding(file_path):
    # Initialize embeddings_index
    embeddings_index = {}

    # Store pretrained word vectors in embeddings_index
    with open(file_path) as f:
        for line in f:
            values = line.split("" "")
            word = values[0]
            coefs = np.asarray(values[1:], dtype='float32')
            embeddings_index[word] = coefs

    # Print number of word vectors found
    print(""Found %s word vectors."" % len(embeddings_index))

    return embeddings_index

embeddings_index = load_embedding('glove.840B.300d.txt') # obtained from https://nlp.stanford.edu/projects/glove/

# Create Embedding matrix
num_tokens = min(vocab_size, len(word_index))+1
embed_dim = 300

def embedding_matrix(word_index, embeddings_index, num_tokens, embed_dim):
    # Initialize embedding_matrix and counters
    hits = 0
    misses = 0
    embedding_matrix = np.zeros((num_tokens, embed_dim))

    # Create embedding_matrix
    for word, i in word_index.items():
      if i > vocab_size:
        continue
      embedding_vector = embeddings_index.get(word)
      if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector
        hits += 1
      else:
        misses += 1

    # Print number of hits and misses
    print(""Converted %d words (%d misses)"" % (hits, misses))

    return embedding_matrix

embedding_matrix = embedding_matrix(word_index, embeddings_index, num_tokens, embed_dim)
```
```
class model_components:

  def mitigation_expert():
    inputs = Input(shape=(300,), dtype=tf.int32, name=""me_input"")
    x = Embedding(num_tokens, 300, weights=[embedding_matrix], input_length=max_length, trainable=False, name=""me_embedding"")(inputs)
    x = LSTM(300, return_sequences=False, name=""me_lstm"")(x)

    model = Model(inputs, x)

    return model

  def control_expert():
    inputs = Input(shape=(22,), dtype=tf.int32, name=""ce_input"")
    y = Dense(19, activation='relu', name=""ce_hidden"")(inputs)

    model = Model(inputs, y)

    return model

  def main_classifier():
    # Expert components
    me = model_components.mitigation_expert()
    ce = model_components.control_expert()

    # Main classifier
    ensemble = concatenate([me.output, ce.output], name=""pred_ensemble"")
    pred_output = Dense(319, activation=""relu"", name=""pred_hidden"")(ensemble)
    pred_output = Dense(3, activation=""softmax"", name=""pred_output"")(pred_output)

    model = Model(inputs=[me.input, ce.input], outputs=pred_output, name=""main_classifier"")

    return model
  
  def adversary_classifier():
    # Mitigation Expert component
    me = model_components.mitigation_expert()

    # Adversary classifier
    adv_output = Dense(300, activation='relu', name=""adv_hidden"")(me.output)
    adv_output = Dense(1, activation='sigmoid', name=""adv_output"")(adv_output)

    model = Model(inputs=me.input, outputs=adv_output, name=""adversary_classifier"")

    return model

def tf_normalize(x):
  return x / (tf.norm(x) + np.finfo(np.float32).tiny)

class DebiasModel(keras.Model):
    def __init__(self, main_classifier, adversary_classifier):
        super(DebiasModel, self).__init__()
        self.main_classifier = main_classifier
        self.adversary_classifier = adversary_classifier

    def compile(self, mc_optimizer, adv_optimizer, mc_loss, adv_loss, debias_param):
        super(DebiasModel, self).compile()
        self.mc_optimizer = mc_optimizer
        self.adv_optimizer = adv_optimizer
        self.mc_loss = mc_loss
        self.adv_loss = adv_loss
        self.debias_param = debias_param

    def train_step(self, data):
      # Unpack data from model.fit()
      x, y, sample_weight = data

      # Unpack input and output features
      xu, xs = x
      y_mc = y['pred_output']
      z_adv = y['adv_output']

      # Unpack sample_weights
      mainClass_weights = sample_weight[""pred_output""]
      protectClass_weights = sample_weight[""adv_output""]

      # Generate prediction and compute loss for Main_Classifier
      with tf.GradientTape() as mc_tape, tf.GradientTape() as me_mc_tape:
        mc_pred = self.main_classifier([xu, xs], training=True)
        mc_loss = self.mc_loss(y_mc, mc_pred, sample_weight=mainClass_weights)
      
      # Compute and Apply Gradients for CE & Main Classifier
      mc_trainable_vars = self.main_classifier.trainable_weights[3:]
      mc_grads = mc_tape.gradient(mc_loss, mc_trainable_vars)
      self.mc_optimizer.apply_gradients(zip(mc_grads, mc_trainable_vars))

      # Generate prediction and compute loss for Adversary_Classifier
      with tf.GradientTape() as adv_tape, tf.GradientTape() as me_adv_tape:
        adv_pred = self.adversary_classifier(xu)
        adv_loss = self.adv_loss(z_adv, adv_pred, sample_weight=protectClass_weights)
      
      # Compute and Apply Gradients for CE & Main Classifier
      adv_trainable_vars = self.adversary_classifier.trainable_weights[3:]
      adv_grads = adv_tape.gradient(adv_loss, adv_trainable_vars)
      self.adv_optimizer.apply_gradients(zip(adv_grads, adv_trainable_vars))

      # Compute and Apply Gradients to debias ME
      me_adv_debias_trainable_vars = self.adversary_classifier.trainable_weights[:3]
      adv_debias_grads = me_adv_tape.gradient(adv_loss, me_adv_debias_trainable_vars)
      adv_debias_dict = tf.lookup.StaticHashTable(
          tf.lookup.KeyValueTensorInitializer(me_adv_debias_trainable_vars, adv_debias_grads), 0)
      
      me_mc_debias_trainable_vars = self.main_classifier.trainable_weights[:3]
      mc_debias_grads = me_mc_tape.gradient(mc_loss, me_mc_debias_trainable_vars)

      me_grads = []

      for g, v in zip(mc_debias_grads, me_mc_debias_trainable_vars):
        unit_adv = tf_normalize(adv_debias_dict.lookup(v))
        g -= tf.math.reduce_sum(g * unit_adv) * unit_adv
        g -= self.debias_param * adv_debias_dict.lookup(v)
        me_grads.append(zip(g, v))
      
      self.mc_optimizer.apply_gradients(me_grads)
      
      return {""pred_loss"": mc_loss, ""adv_loss"": adv_loss}

# Build and Fit Model
model = DebiasModel(model_components.main_classifier(),
                    model_components.adversary_classifier())

model.compile(mc_optimizer=tf.keras.optimizers.Adam(),
              adv_optimizer=tf.keras.optimizers.Adam(),
              mc_loss=tf.keras.losses.CategoricalCrossentropy(),
              adv_loss=tf.keras.losses.BinaryCrossentropy(),
              debias_param=1)

epoch = 5
sample_weights = {
    ""pred_output"": mainClass_weight,
    ""adv_output"": protectClass_weight,}

model.fit(x=[xu_train, xs_train],
          y={""pred_output"": y_train, ""adv_output"": z_train},
          validation_data=([xu_val, xs_val], {""pred_output"": y_val, ""adv_output"": z_val}),
          sample_weight=sample_weights,	epochs=epoch, batch_size=256, verbose=1)
```

**Error Traceback Log**
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2485       with c_api_util.tf_buffer() as buf:
-> 2486         pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2487         data = pywrap_tf_session.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'while' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
54 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    330     try:
--> 331       xla_compile = op.get_attr(""_XlaCompile"")
    332       xla_separate_compiled_gradients = op.get_attr(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2489       # Convert to ValueError for backwards compatibility.
-> 2490       raise ValueError(str(e))
   2491     x = attr_value_pb2.AttrValue()

ValueError: Operation 'while' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-43-e00f829ae927> in <module>()
      8           y={""pred_output"": y_train, ""adv_output"": z_train},
      9           validation_data=([xu_val, xs_val], {""pred_output"": y_val, ""adv_output"": z_val}),
---> 10           sample_weight=sample_weights,	epochs=epoch, batch_size=256, verbose=1)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1096                 batch_size=batch_size):
   1097               callbacks.on_train_batch_begin(step)
-> 1098               tmp_logs = train_function(iterator)
   1099               if data_handler.should_sync:
   1100                 context.async_wait()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    821       # This is the first call of __call__, so we have to initialize.
    822       initializers = []
--> 823       self._initialize(args, kwds, add_initializers_to=initializers)
    824     finally:
    825       # At this point we know that the initialization is complete (or less

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    695     self._concrete_stateful_fn = (
    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 697             *args, **kwds))
    698 
    699     def invalid_creator_scope(*unused_args, **unused_kwds):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2853       args, kwargs = None, None
   2854     with self._lock:
-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2856     return graph_function
   2857 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3211 
   3212       self._function_cache.missed.add(call_context_key)
-> 3213       graph_function = self._create_graph_function(args, kwargs)
   3214       self._function_cache.primary[cache_key] = graph_function
   3215       return graph_function, args, kwargs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3073             arg_names=arg_names,
   3074             override_flat_arg_shapes=override_flat_arg_shapes,
-> 3075             capture_by_value=self._capture_by_value),
   3076         self._function_attributes,
   3077         function_spec=self.function_spec,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--> 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    599         # the function a weak reference to itself to avoid a reference cycle.
--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    601     weak_wrapped_fn = weakref.ref(wrapped_fn)
    602 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    967                     recursive=True,
    968                     optional_features=autograph_options,
--> 969                     user_requested=True,
    970                 ))
    971           except Exception as e:  # pylint:disable=broad-except

/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, args, kwargs, caller_fn_scope, options)
    594     try:
    595       if kwargs is not None:
--> 596         result = converted_f(*effective_args, **kwargs)
    597       else:
    598         result = converted_f(*effective_args)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in tf__train_function(iterator)
     14                 try:
     15                     do_return = True
---> 16                     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
     17                 except:
     18                     do_return = False

/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, args, kwargs, caller_fn_scope, options)
    530 
    531   if not options.user_requested and conversion.is_whitelisted(f):
--> 532     return _call_unconverted(f, args, kwargs, options)
    533 
    534   # internal_convert_user_code is for example turned off when issuing a dynamic

/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in _call_unconverted(f, args, kwargs, options, update_cache)
    338   if kwargs is not None:
    339     return f(*args, **kwargs)
--> 340   return f(*args)
    341 
    342 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in step_function(model, iterator)
    794 
    795       data = next(iterator)
--> 796       outputs = model.distribute_strategy.run(run_step, args=(data,))
    797       outputs = reduce_per_replica(
    798           outputs, self.distribute_strategy, reduction='first')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in run(***failed resolving arguments***)
   1209       fn = autograph.tf_convert(
   1210           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)
-> 1211       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
   1212 
   1213   # TODO(b/151224785): Remove deprecated alias.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)
   2583       kwargs = {}
   2584     with self._container_strategy().scope():
-> 2585       return self._call_for_each_replica(fn, args, kwargs)
   2586 
   2587   def _call_for_each_replica(self, fn, args, kwargs):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)
   2943         self._container_strategy(),
   2944         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):
-> 2945       return fn(*args, **kwargs)
   2946 
   2947   def _reduce_to(self, reduce_op, value, destinations, experimental_hints):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    253       try:
    254         with conversion_ctx:
--> 255           return converted_call(f, args, kwargs, options=options)
    256       except Exception as e:  # pylint:disable=broad-except
    257         if hasattr(e, 'ag_error_metadata'):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, args, kwargs, caller_fn_scope, options)
    530 
    531   if not options.user_requested and conversion.is_whitelisted(f):
--> 532     return _call_unconverted(f, args, kwargs, options)
    533 
    534   # internal_convert_user_code is for example turned off when issuing a dynamic

/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in _call_unconverted(f, args, kwargs, options, update_cache)
    337 
    338   if kwargs is not None:
--> 339     return f(*args, **kwargs)
    340   return f(*args)
    341 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in run_step(data)
    787 
    788       def run_step(data):
--> 789         outputs = model.train_step(data)
    790         # Ensure counter is updated only if `train_step` succeeds.
    791         with ops.control_dependencies(_minimum_control_deps(outputs)):

<ipython-input-41-7d8c3d718a99> in train_step(self, data)
     39       # Generate prediction and compute loss for Main_Classifier
     40       with tf.GradientTape() as mc_tape, tf.GradientTape() as me_mc_tape:
---> 41         mc_pred = self.main_classifier([xu, xs], training=True)
     42         mc_loss = self.mc_loss(y_mc, mc_pred, sample_weight=mainClass_weights)
     43 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    983 
    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):
--> 985           outputs = call_fn(inputs, *args, **kwargs)
    986 
    987         if self._activity_regularizer:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in call(self, inputs, training, mask)
    384     """"""
    385     return self._run_internal_graph(
--> 386         inputs, training=training, mask=mask)
    387 
    388   def compute_output_shape(self, input_shape):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in _run_internal_graph(self, inputs, training, mask)
    506 
    507         args, kwargs = node.map_arguments(tensor_dict)
--> 508         outputs = node.layer(*args, **kwargs)
    509 
    510         # Update tensor_dict.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)
    661 
    662     if initial_state is None and constants is None:
--> 663       return super(RNN, self).__call__(inputs, **kwargs)
    664 
    665     # If any of `initial_state` or `constants` are specified and are Keras

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    983 
    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):
--> 985           outputs = call_fn(inputs, *args, **kwargs)
    986 
    987         if self._activity_regularizer:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py in call(self, inputs, mask, training, initial_state)
   1181       else:
   1182         (last_output, outputs, new_h, new_c,
-> 1183          runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)
   1184 
   1185       states = [new_h, new_c]

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py in lstm_with_backend_selection(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)
   1556   # grappler will kick in during session execution to optimize the graph.
   1557   last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(
-> 1558       **params)
   1559   function.register(defun_gpu_lstm, **params)
   1560 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2827     with self._lock:
   2828       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2829     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2830 
   2831   @property

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1846                            resource_variable_ops.BaseResourceVariable))],
   1847         captured_inputs=self.captured_inputs,
-> 1848         cancellation_manager=cancellation_manager)
   1849 
   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1927         possible_gradient_type,
   1928         executing_eagerly)
-> 1929     forward_function, args_with_tangents = forward_backward.forward()
   1930     if executing_eagerly:
   1931       flat_outputs = forward_function.call(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in forward(self)
   1431     """"""Builds or retrieves a forward function for this call.""""""
   1432     forward_function = self._functions.forward(
-> 1433         self._inference_args, self._input_tangents)
   1434     return forward_function, self._inference_args + self._input_tangents
   1435 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in forward(self, inference_args, input_tangents)
   1187       (self._forward, self._forward_graph, self._backward,
   1188        self._forwardprop_output_indices, self._num_forwardprop_outputs) = (
-> 1189            self._forward_and_backward_functions(inference_args, input_tangents))
   1190     return self._forward
   1191 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _forward_and_backward_functions(self, inference_args, input_tangents)
   1387       outputs = list(self._func_graph.outputs)
   1388       self._build_functions_for_outputs(
-> 1389           outputs, inference_args, input_tangents)
   1390     (forward_function, forward_graph,
   1391      backward_function, output_indices, num_output_tangents) = (

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _build_functions_for_outputs(self, outputs, inference_args, input_tangents)
    897             self._func_graph.inputs,
    898             grad_ys=gradients_wrt_outputs,
--> 899             src_graph=self._func_graph)
    900 
    901       captures_from_forward = [

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    667                 # functions.
    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--> 669                                          lambda: grad_fn(op, *out_grads))
    670               else:
    671                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    334       xla_scope = op.get_attr(""_XlaScope"").decode()
    335     except ValueError:
--> 336       return grad_fn()  # Exit early
    337 
    338   if not xla_compile:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in <lambda>()
    667                 # functions.
    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--> 669                                          lambda: grad_fn(op, *out_grads))
    670               else:
    671                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/while_v2.py in _WhileGrad(op, *grads)
    395   cond_grad_graph = func_graph_module.func_graph_from_py_func(
    396       grad_cond_name, grad_cond, loop_vars, {},
--> 397       func_graph=util.WhileCondFuncGraph(grad_cond_name))
    398 
    399   _check_num_inputs_outputs(cond_grad_graph, body_grad_graph, len(loop_vars))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    901       kwarg_shapes = None
    902     func_args = _get_defun_inputs_from_args(
--> 903         args, arg_names, flat_shapes=arg_shapes)
    904     func_kwargs = _get_defun_inputs_from_kwargs(
    905         kwargs, flat_shapes=kwarg_shapes)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in _get_defun_inputs_from_args(args, names, flat_shapes)
   1137   """"""Maps Python function positional args to graph-construction inputs.""""""
   1138   return _get_defun_inputs(
-> 1139       args, names, structure=args, flat_shapes=flat_shapes)
   1140 
   1141 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in _get_defun_inputs(args, names, structure, flat_shapes)
   1210           placeholder = graph_placeholder(
   1211               arg.dtype, placeholder_shape,
-> 1212               name=requested_name)
   1213         except ValueError:
   1214           # Sometimes parameter names are not valid op names, so fall back to

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/graph_only_ops.py in graph_placeholder(dtype, shape, name)
     38   op = g._create_op_internal(  # pylint: disable=protected-access
     39       ""Placeholder"", [], [dtype], input_types=[],
---> 40       attrs=attrs, name=name)
     41   result, = op.outputs
     42   if op_callbacks.should_invoke_op_callbacks():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)
    591     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    592         op_type, inputs, dtypes, input_types, name, attrs, op_def,
--> 593         compute_device)
    594 
    595   def capture(self, tensor, name=None, shape=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)
   3483           input_types=input_types,
   3484           original_op=self._default_original_op,
-> 3485           op_def=op_def)
   3486       self._create_op_helper(ret, compute_device=compute_device)
   3487     return ret

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)
   1985       tf_output = c_api_util.tf_output(self._c_op, i)
   1986       output_type = pywrap_tf_session.TF_OperationOutputType(tf_output)
-> 1987       tensor = Tensor._create_with_tf_output(self, i, output_type, tf_output)  # pylint: disable=protected-access
   1988       self._outputs.append(tensor)
   1989 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_with_tf_output(op, value_index, dtype, tf_output)
    386   @staticmethod
    387   def _create_with_tf_output(op, value_index, dtype, tf_output):
--> 388     ret = Tensor(op, value_index, dtype)
    389     ret._tf_output = tf_output
    390     return ret

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in __init__(self, op, value_index, dtype)
    373     self._op = op
    374     self._value_index = value_index
--> 375     self._dtype = dtypes.as_dtype(dtype)
    376     # This will be set by self._as_tf_output().
    377     self._tf_output = None

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py in as_dtype(type_value)
    623     TypeError: If `type_value` cannot be converted to a `DType`.
    624   """"""
--> 625   if isinstance(type_value, DType):
    626     return _INTERN_TABLE[type_value.as_datatype_enum]
    627 
```"
42305,tflite after quantization : Didn't find op for builtin opcode 'CONV_2D' version '5',"**System information**
- OS Platform and Distribution : Linux Ubuntu 19.04
- TensorFlow installed from (source or binary): Model was generated with TF from binary
- TensorFlow version (or github SHA if from source): Tensorflow version 2.4.0-dev20200715, for conversion to tflite and also in C++ for executing.

** Error logs **
Its working completely fine, when running in model in float32 format, it is giving error when performing a post-training quantization on the model.
```
ERROR: Didn't find op for builtin opcode 'CONV_2D' version '5'
ERROR: Registration failed.
```

** Loading Model **

```
    ...
    M1 = TfLiteModelCreateFromFile(modelPath.c_str());
    TfLiteInterpreterOptions* options1 = TfLiteInterpreterOptionsCreate();
    TfLiteInterpreterOptionsSetNumThreads(options1, 2);
    
    I1 = TfLiteInterpreterCreate((TfLiteModel*)M1, options1);
    TfLiteInterpreterOptionsDelete(options1);
    TfLiteModelDelete((TfLiteModel*)M1);
    ...
```


**Any other info / logs**

A similar issue flutter_tflite has been reported here #41943 . 
"
42304,Keras Accuracy with sequence auto-encoder is different than manual calculation,"Hi,

I'm using GRU-based seq2seq model with byte pair encoding for spelling correction problem. 
_This is my model architecture/code:_

```
encoder_inputs = Input(shape=(padding_length,), name=""EncoderInput_1"")
embedded_encoder_inputs = Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)
encoder = GRU(latent_dim, return_state=True)
_, state_h = encoder(embedded_encoder_inputs)

encoder_states = state_h

decoder_inputs = Input(shape=(padding_length,), name=""DecoderInput_1"")
embedded_decoder_inputs = Embedding(num_decoder_tokens, latent_dim, mask_zero=True)(decoder_inputs)
decoder_lstm = GRU(latent_dim, return_sequences=True, return_state=True)
x, _ = decoder_lstm(embedded_decoder_inputs, initial_state=encoder_states)
decoder_dense = TimeDistributed(Dense(num_decoder_tokens, activation='softmax'))
decoder_outputs = decoder_dense(x)

model = Model([encoder_inputs, decoder_inputs], decoder_outputs)

model.compile(optimizer='adam', loss=sparse_categorical_crossentropy,metrics=[""accuracy""])
model.fit([ip_encoded,op_encoded],
              op_offset_encoded,
              epochs=epochs,
              verbose=1,
              batch_size=batch_size,
              validation_split=0.2,
```
I trained it for 10 epochs with ~700K training examples and the final validation accuracy was ~97%.

I looked into the sample predictions and accuracies (I am using model.evaluate to get single example accuracy), but it is deviating from manual calculations. 

I'd like to mention my understanding of the accuracy calculation which I'm using during manual calculation:
- For all Input tokens to decoder, it predicts the next token. If predicted token == expected token, the ""count"" of correctly predicted is increased by 1. I apply the same for all decoder Input tokens and at the last calculate accuracy by dividing ""count"" with the count of total Input tokens.

Examples: ( ip: input to model, op: model output, ex: expected)
_(Note: I'm assuming padding tokens are not considered for metric calculation)_
_(Note: \<start\>: 1, \<pad\>: 0, \<end\>: 2)_

Code used for finding accuracy for single example:
`model.evaluate([ip_encoded[idx:idx+1],op_encoded[idx:idx+1]],op_offset_encoded[idx:idx+1],batch_size=64)`

1. (all tokens are predicted correctly, manual and Keras accuracies are same)
```
ip:  Do you get a pattern similar to t hat shown in Fig.
op:  Do you get a pattern similar to that shown in Fig.
ex:  Do you get a pattern similar to that shown in Fig.

ip:  [1, 1313, 416, 742, 261, 1953, 1239, 299, 259, 308, 270, 911, 283, 814, 16, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
op:  [1313, 416, 742, 261, 1953, 1239, 299, 336, 911, 283, 814, 16, 2]
ex:  [1313, 416, 742, 261, 1953, 1239, 299, 336, 911, 283, 814, 16, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

1/1 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000
[0.003069164464250207, 1.0]
```
2. (manual accuracy: 17/23=0.73, keras: 0.95)
```
ip:  The equal part that we get in is, therefore, larger than the equal part we get in.
op:  The equal part that we get in  is, therefore, larger than the equal part in which we get .
ex:  The equal part that we get in  is, therefore, larger than the equal part we get in .

ip:  [1, 316, 752, 496, 336, 370, 742, 283, 294, 14, 1578, 14, 2115, 621, 264, 752, 496, 370, 742, 283, 16, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
op:  [316, 752, 496, 336, 370, 742, 283, 223, 294, 14, 1578, 14, 2115, 621, 264, 752, 496, 283, 406, 370, 742, 1964, 2]
ex:  [316, 752, 496, 336, 370, 742, 283, 223, 294, 14, 1578, 14, 2115, 621, 264, 752, 496, 370, 742, 283, 1964, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

1/1 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9565
[0.028948727995157242, 0.95652174949646]
```
3. (manual: 10/13=0.77, Keras: 0.92)
```
ip:  Can you tell what advanxtage the fungus derives from this association?
op:  Can you tell what advantage affect the sewage from this association?
ex:  Can you tell what advantage the fungus derives from this association?

ip:  [1, 1321, 416, 2797, 985, 2923, 282, 1424, 596, 264, 9590, 19016, 389, 428, 6330, 33, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
op:  [1321, 416, 2797, 985, 6089, 2211, 264, 4739, 389, 428, 6330, 33, 2]
ex:  [1321, 416, 2797, 985, 6089, 264, 9590, 19016, 389, 428, 6330, 33, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

1/1 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9286
[0.012137999758124352, 0.9285714030265808]
```

- It'd be really helpful if community can help me understand Keras accuracy metrics internals and verify my manual metric calculation process."
42303,Don't include json headers as include/json/json.h,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Bazel version (if compiling from source): 3.1

**Describe the problem**

Currently the JsonCPP headers are all included by `#include ""include/json/json.h""`. This is very unusual as in pretty much all cases the ""include"" folder is added to the compiler include paths and does not appear in `#include` statements

Due to this workarounds are required such as symlinking the ""system headers"" into a folder structure such that the above include works which may lead to e.g. #42267

What is the reasoning to use this include scheme?

I'd like to propose using ""standard"" include schemes like `#include ""json/json.h""` and adjust the include paths appropriately. By doing so the symlinking is avoided which would resolve #42267 "
42302, java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.nnapi.NnApiDelegate.createDelegate(),"  java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.nnapi.NnApiDelegate.createDelegate() (tried Java_org_tensorflow_lite_nnapi_NnApiDelegate_createDelegate and Java_org_tensorflow_lite_nnapi_NnApiDelegate_createDelegate__)
        at org.tensorflow.lite.nnapi.NnApiDelegate.createDelegate(Native Method)


How can i resolve this problem? Thanks very much!"
42301,Loading model with tf.linalg.band_part in regularisation,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Model trained on linux, loading fails on windows
- Model trained on tf 2.2.0, but loading on 2.3.0 also doesn't work - Py 3.7

**Describe the current behavior**

`tf.keras.models.load_model(model_path)` results in 

```
ValueError: Inconsistent values for attr 'Tindex' DT_INT32 vs. DT_INT64 while building NodeDef 'tf_op_layer_MatrixBandPart_3/MatrixBandPart' using Op<name=MatrixBandPart; signature=input:T, num_lower:Tindex, num_upper:Tindex -> band:T; attr=T:type; attr=Tindex:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
```

Which probably comes from this custom regularisation that has been added to the model

```
def orthog_reg(weight_matrix):
    """""" The orthogonality inducing regularization. Compute: |upper_triang(dot_prod(W,W))| """"""
    # weight_matrix shape is batch_size x latent_dim so we have row vectors so dot prod is WW^T
    dot_prod = tf.linalg.matmul(weight_matrix, tf.transpose(weight_matrix))
    # we only care about the upper triangular matrix, because the matrix is symmetric and the diagonal represents
    # orthogonality of vectors with itself which we do not care about
    # https://www.tensorflow.org/api_docs/python/tf/linalg/band_part
    upper_triang_dot_prod = tf.linalg.band_part(dot_prod, -1, 0) - tf.linalg.band_part(dot_prod, 0, 0)
    return tf.reduce_sum(upper_triang_dot_prod)
```

It is added like this

```
   # get regularisation
    weights = embedding_one_layer.get_weights()[0]
    weights_relu = tf.nn.relu(weights)
    orthog_reg_result = orthog_reg(weights_relu)

    # add orthogonal regularisation loss to model loss
    orthog_reg_result = 0.01 * orthog_reg_result
    model.add_loss(orthog_reg_result)
``` 

**Describe the expected behavior**

Expect it to load ;)

**Standalone code to reproduce the issue**
(Will add this soon) 
"
42298,CUBLAS_STATUS_NOT_INITIALIZED,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: tf-nightly
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: GeFroce 2080 Ti (X2)

**Describe the problem**
I'm struggling to get off the ground here with multi-gpu tensorflow.  I've eventually gotten stuck with""cublas not initialized.""  Thank you for having a look. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  # Create 2 virtual GPUs with 1GB memory each
  try:
    tf.config.experimental.set_virtual_device_configuration(
        gpus[0],
        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),
         tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPU,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Virtual devices must be set before GPUs have been initialized
    print(e)

mirrored_strategy = tf.distribute.MirroredStrategy()

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
x_train = x_train[:,:,:,np.newaxis] / 255.0
x_test = x_test[:,:,:,np.newaxis] / 255.0
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

with mirrored_strategy.scope():
    model4 = Sequential()
    model4.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28, 1))) 
    model4.add(Conv2D(filters=64, kernel_size=2))
    model4.add(MaxPooling2D(pool_size=2))
    model4.add(Flatten())
    model4.add(Dense(10, activation='softmax'))

model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model4.summary()

model4.fit(x_train, y_train, epochs=2, validation_split=0.1)

_, test_acc = model4.evaluate(x_test, y_test)
print(test_acc)

model4.save_weights('cnn.h5')

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


(base_gpu) C:\Users\Mo\BTC>python test.py
2020-08-12 23:09:37.482332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-12 23:09:40.326028: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-08-12 23:09:40.483740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:67:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
2020-08-12 23:09:40.497852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
pciBusID: 0000:68:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
2020-08-12 23:09:40.515569: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-12 23:09:40.530217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-12 23:09:40.545759: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll 
2020-08-12 23:09:40.552588: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-12 23:09:40.566705: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-12 23:09:40.574656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-12 23:09:40.597844: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-12 23:09:40.602568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
Num GPUs Available:  2
2020-08-12 23:09:40.606521: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-12 23:09:40.672282: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x227a512f230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-12 23:09:40.700825: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-12 23:09:41.131362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:67:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
2020-08-12 23:09:41.146897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
pciBusID: 0000:68:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
2020-08-12 23:09:41.183979: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-12 23:09:41.228784: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-12 23:09:41.251706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-12 23:09:41.259688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-12 23:09:41.303717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-12 23:09:41.328316: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-12 23:09:41.353029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-12 23:09:41.379921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
2020-08-12 23:09:42.687780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-12 23:09:42.695670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
2020-08-12 23:09:42.700946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N
2020-08-12 23:09:42.723277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
2020-08-12 23:09:42.747771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1024 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
2020-08-12 23:09:42.782663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 1024 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
2020-08-12 23:09:42.814118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 8582 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5)
2020-08-12 23:09:42.864267: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22831d21960 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-12 23:09:42.889142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-08-12 23:09:42.914052: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5
2 Physical GPU, 3 Logical GPUs
WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 64)        320
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 27, 27, 64)        16448     
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0
_________________________________________________________________
flatten (Flatten)            (None, 10816)             0
_________________________________________________________________
dense (Dense)                (None, 10)                108170
=================================================================
Total params: 124,938
Trainable params: 124,938
Non-trainable params: 0
_________________________________________________________________
2020-08-12 23:09:44.300510: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
Epoch 1/2
2020-08-12 23:09:47.355213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-12 23:09:47.364005: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.387331: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.431316: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.473173: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.491439: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.499352: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.539511: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.569205: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.593318: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.605302: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-12 23:09:47.643972: E tensorflow/stream_executor/cuda/cuda_dnn.cc:325] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.643972: E tensorflow/stream_executor/cuda/cuda_dnn.cc:325] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.673588: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
2020-08-12 23:09:47.649853: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
2020-08-12 23:09:47.700174: E tensorflow/stream_executor/cuda/cuda_dnn.cc:325] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.723925: E tensorflow/stream_executor/cuda/cuda_dnn.cc:325] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.746358: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
2020-08-12 23:09:47.769343: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
2020-08-12 23:09:47.819798: E tensorflow/stream_executor/cuda/cuda_dnn.cc:325] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.844975: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
2020-08-12 23:09:47.870709: E tensorflow/stream_executor/cuda/cuda_dnn.cc:325] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2020-08-12 23:09:47.880941: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
Traceback (most recent call last):
  File ""test.py"", line 55, in <module>
    model4.fit(x_train, y_train, epochs=2, validation_split=0.1)
  File ""C:\Users\Mo\anaconda3\envs\base_gpu\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 103, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""C:\Users\Mo\anaconda3\envs\base_gpu\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1102, in fit
    tmp_logs = self.train_function(iterator)
  File ""C:\Users\Mo\anaconda3\envs\base_gpu\lib\site-packages\tensorflow\python\eager\def_function.py"", line 787, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\Mo\anaconda3\envs\base_gpu\lib\site-packages\tensorflow\python\eager\def_function.py"", line 847, in _call
    return self._stateless_fn(*args, **kwds)
  File ""C:\Users\Mo\anaconda3\envs\base_gpu\lib\site-packages\tensorflow\python\eager\function.py"", line 2922, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""C:\Users\Mo\anaconda3\envs\base_gpu\lib\site-packages\tensorflow\python\eager\function.py"", line 1853, in _filtered_call
    return self._call_flat(
  File ""C:\Users\Mo\anaconda3\envs\base_gpu\lib\site-packages\tensorflow\python\eager\function.py"", line 1933, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""C:\Users\Mo\anaconda3\envs\base_gpu\lib\site-packages\tensorflow\python\eager\function.py"", line 552, in call
    outputs = execute.execute(
  File ""C:\Users\Mo\anaconda3\envs\base_gpu\lib\site-packages\tensorflow\python\eager\execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: 4 root error(s) found.
  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node replica_2/sequential/conv2d/Conv2D (defined at C:\Users\Mo\anaconda3\envs\base_gpu\lib\threading.py:932) ]]
         [[div_no_nan_1/ReadVariableOp_4/_88]]
  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node replica_2/sequential/conv2d/Conv2D (defined at C:\Users\Mo\anaconda3\envs\base_gpu\lib\threading.py:932) ]]
  (2) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node replica_2/sequential/conv2d/Conv2D (defined at C:\Users\Mo\anaconda3\envs\base_gpu\lib\threading.py:932) ]]
         [[gradient_tape/replica_1/sequential/conv2d/BiasAdd/BiasAddGrad/_144]]
  (3) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node replica_2/sequential/conv2d/Conv2D (defined at C:\Users\Mo\anaconda3\envs\base_gpu\lib\threading.py:932) ]]
         [[AddN_2/_132]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_3014]
"
42297,import tensorflow  issue,"Hi guys,

I have reinstalled my python 3.8.5 64 bit and use pip installed tensorflow 2.3.0. on my window 10 intel Core i7-6700HQ CPU @2.6Ghz.  And I can see it installed successfully using pip list

however whenever I try to import : import tensorflow   in jupyter notebook.

It shows following error:
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-3-bc8d927cf602> in <module>
      1 import import_ipynb
----> 2 import tensorflow

ModuleNotFoundError: No module named 'tensorflow'

Any one can help me ? how can I get over it?

thanks

<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42296,How to set different learning rate at different layers when using tf.keras.model.fit,"hello:
I am wondering if there is a way that I can use different learning rate for different layers. I am trying to modify a pre-trained model and use it for other tasks. What I want is to speed up the training for new added layers and keep the trained layers at low learning rate in order to prevent them from being distorted. for example, I have a 5-conv-layer pre-trained model. Now I add a new conv layer and fine tune it. The first 5 layers would have learning rate of 0.00001 and the last one would have 0.001. Any idea how to achieve this? another important part is I want to use model.fit().
thanks

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
42294,"Huge CPU, GPU output diff after updates to fully_connected GpuDelegate gl kernel.","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Android

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
Tested on Pixel2

- TensorFlow installed from (source or binary):
Built from source

- TensorFlow version (use command below):
v2.3.0

- Python version:
3.7

- Bazel version (if compiling from source):
3.1.0

- GCC/Compiler version (if compiling from source):
7.5.0

- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
There seems to be a bug in tensorflow/lite/delegates/gpu/gl/kernels/fully_connected.cc that was first updated in [this commit](https://github.com/tensorflow/tensorflow/commit/7c7d924821a8b1b20433c2f3f484bbd409873a84#diff-a1d24db3e0ad4103e389ffed433cf470R82).

The test itself in tensorflow/lite/delegates/gpu/gl/kernels/fully_connected_test.cc passes but when running
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks/inference_diff on a simple custom model, the avg_error between the CPU and the GPU delegate piles up and leads to completely different results.

**Describe the expected behavior**
The avg_error between the CPU and the GPU delegate should stay the same even after the updates to fully_connected code, and it should not produce weird outputs.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

1. Prepare `run_eval` in v2.3.0
```
bazel build -c opt \
  --config=android_arm64 \
  //tensorflow/lite/tools/evaluation/tasks/inference_diff:run_eval
cp bazel-bin/tensorflow/lite/tools/evaluation/tasks/inference_diff/run_eval ./run_eval_1
```

2. Change the fully_connected shader implementation to the one prior to commit `7c7d9248`
The simple implementation without the usage of shared variables, memoryBarrierShared, etc.

3. Prepare `run_eval` after second step
```
bazel build -c opt \
  --config=android_arm64 \
  //tensorflow/lite/tools/evaluation/tasks/inference_diff:run_eval
cp bazel-bin/tensorflow/lite/tools/evaluation/tasks/inference_diff/run_eval ./run_eval_2
```

4. Connect android device and push the tflite models below, run_eval_1 and run_eval_2 to device
```
adb push [] /data/local/tmp
```
[simple.zip](https://github.com/tensorflow/tensorflow/files/5066647/simple.zip)
The models in the zip file are submodels from a custom model that was sliced from the input layer to deeper layers accumulatively, so that running `run_eval` on them would show how the error changes in the subsequent layers.


5. Run both eval scripts on the models and save the output
```
# For example
adb shell find /data/local/tmp/simple -type f -name ""*.tflite"" | sort -V | xargs -L 1 -I{} sh -c ""echo {}; adb shell /data/local/tmp/run_eval_1 --model_file={} --delegate=gpu --gpu_precision_loss_allowed=false --num_runs=5"" > eval_1.txt
```

6. Compare output from both eval results
```
[Output from run_eval_1]

/data/local/tmp/simple/0_layer.tflite (input)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=350.6(us), std_dev=182(us)
Test run latency: avg=7788.33(us), std_dev=1361(us)
OutputDiff[0]: avg_error=0, std_dev=0

/data/local/tmp/simple/1_layer.tflite (conv2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=51505.2(us), std_dev=19231(us)
Test run latency: avg=76189.3(us), std_dev=21566(us)
OutputDiff[0]: avg_error=5.65735e-08, std_dev=1.23668e-10

/data/local/tmp/simple/2_layer.tflite (conv2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=156689(us), std_dev=34476(us)
Test run latency: avg=91240.9(us), std_dev=20015(us)
OutputDiff[0]: avg_error=2.88166e-07, std_dev=4.7596e-10

/data/local/tmp/simple/3_layer.tflite (average_pooling2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=154217(us), std_dev=49214(us)
Test run latency: avg=63426.3(us), std_dev=3858(us)
OutputDiff[0]: avg_error=2.06003e-07, std_dev=5.04424e-10

/data/local/tmp/simple/4_layer.tflite (average_pooling2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=154598(us), std_dev=56655(us)
Test run latency: avg=43006.3(us), std_dev=8692(us)
OutputDiff[0]: avg_error=8.01869e-08, std_dev=8.87667e-09

/data/local/tmp/simple/5_layer.tflite (dense)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=156916(us), std_dev=54132(us)
Test run latency: avg=36966.8(us), std_dev=1220(us)
OutputDiff[0]: avg_error=0, std_dev=0

/data/local/tmp/simple/6_layer.tflite (dense)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=152091(us), std_dev=53248(us)
Test run latency: avg=36698(us), std_dev=1180(us)
OutputDiff[0]: avg_error=0.00405404, std_dev=8.56487e-06

/data/local/tmp/simple/7_layer.tflite (reshape)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=157181(us), std_dev=52575(us)
Test run latency: avg=39436.9(us), std_dev=2816(us)
OutputDiff[0]: avg_error=0.00405404, std_dev=8.56487e-06

/data/local/tmp/simple/8_layer.tflite (mul)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=151318(us), std_dev=51893(us)
Test run latency: avg=47089.9(us), std_dev=3074(us)
OutputDiff[0]: avg_error=0.00415553, std_dev=1.17143e-05

/data/local/tmp/simple/9_layer.tflite (conv2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=176098(us), std_dev=49177(us)
Test run latency: avg=51363.7(us), std_dev=933(us)
OutputDiff[0]: avg_error=0.0141088, std_dev=9.8753e-05

/data/local/tmp/simple/10_layer.tflite (conv2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=194176(us), std_dev=42305(us)
Test run latency: avg=56783.7(us), std_dev=942(us)
OutputDiff[0]: avg_error=0.116762, std_dev=0.00102424
```

```
[Output from run_eval_2]

/data/local/tmp/simple/0_layer.tflite (input)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=404.067(us), std_dev=291(us)
Test run latency: avg=9060.07(us), std_dev=2928(us)
OutputDiff[0]: avg_error=0, std_dev=0

/data/local/tmp/simple/1_layer.tflite (conv2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=49690.5(us), std_dev=18876(us)
Test run latency: avg=76622.3(us), std_dev=16760(us)
OutputDiff[0]: avg_error=5.65735e-08, std_dev=1.23668e-10

/data/local/tmp/simple/2_layer.tflite (conv2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=154928(us), std_dev=37358(us)
Test run latency: avg=91402.5(us), std_dev=20801(us)
OutputDiff[0]: avg_error=2.88166e-07, std_dev=4.7596e-10

/data/local/tmp/simple/3_layer.tflite (average_pooling2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=156680(us), std_dev=51722(us)
Test run latency: avg=63421.1(us), std_dev=5300(us)
OutputDiff[0]: avg_error=2.06003e-07, std_dev=5.04424e-10

/data/local/tmp/simple/4_layer.tflite (average_pooling2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=168827(us), std_dev=51702(us)
Test run latency: avg=42583.5(us), std_dev=9370(us)
OutputDiff[0]: avg_error=8.01869e-08, std_dev=8.87667e-09

/data/local/tmp/simple/5_layer.tflite (dense)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=153892(us), std_dev=54096(us)
Test run latency: avg=38346.1(us), std_dev=2488(us)
OutputDiff[0]: avg_error=0, std_dev=0

/data/local/tmp/simple/6_layer.tflite (dense)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=158208(us), std_dev=54326(us)
Test run latency: avg=38795.7(us), std_dev=2783(us)
OutputDiff[0]: avg_error=2.78233e-08, std_dev=0

/data/local/tmp/simple/7_layer.tflite (reshape)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=159020(us), std_dev=56125(us)
Test run latency: avg=36865.9(us), std_dev=1231(us)
OutputDiff[0]: avg_error=2.78233e-08, std_dev=0

/data/local/tmp/simple/8_layer.tflite (mul)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=155681(us), std_dev=51329(us)
Test run latency: avg=46260.3(us), std_dev=2496(us)
OutputDiff[0]: avg_error=3.92487e-08, std_dev=9.90499e-11

/data/local/tmp/simple/9_layer.tflite (conv2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=192473(us), std_dev=49285(us)
Test run latency: avg=68372(us), std_dev=8581(us)
OutputDiff[0]: avg_error=1.127e-07, std_dev=2.97108e-10

/data/local/tmp/simple/10_layer.tflite (conv2d)
GPU delegate is created.
Num evaluation runs: 5
Reference run latency: avg=184917(us), std_dev=50705(us)
Test run latency: avg=57926.3(us), std_dev=4106(us)
OutputDiff[0]: avg_error=6.8757e-07, std_dev=1.08467e-09
```

in `run_eval_1`, the `avg_error` rises high after the dense layers, when compared to `run_eval_2`.

This leads to a weird output in the custom model that I'm using in an Android app. When I rollback the changes in the `fully_connected` code and build the aar myself, it works as expected and I can benefit the performance enhancements on devices that support OpenCL.

Could you please have a look at it?


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42293,tf.keras.backend.temporal_padding crashes(bad_alloc) when padding is large,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.keras.backend.temporal_padding` crashes(abort, bad_alloc) when `padding` is large

**Describe the expected behavior**
Expect no crashes

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python

import tensorflow as tf
tf.keras.backend.temporal_padding(x=tf.ones((2,1,1)), padding=(6400000000000000000, 4314310000000000000))
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

In TF2.1
~~~python
  what():  std::bad_alloc
Aborted (core dumped)
~~~
In TF nightly
~~~
2020-08-13 01:04:13.669045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-13 01:04:13.683160: F tensorflow/core/framework/tensor_shape.cc:345] Check failed: size >= 0 (-7732434073709551615 vs. 0)
Aborted (core dumped)

~~~"
42291,[ROCm] sh: /opt/rocm/bin/hipcc: No such file or directory,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 3.4.1
- GCC/Compiler version (if compiling from source): 10.1.0
- CUDA/cuDNN version: N/A
- ROCm version: 3.5.0
- GPU model and memory:



**Describe the problem**

When building I am getting the following error:
```
ERROR: /home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.3.0-rocm/tensorflow/core/kernels/BUILD:3132:18: error while parsing .d file: /home/acxz/.cache/bazel/_bazel_acxz/032a3a4c537da51b5f6f596867eba382/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/non_max_suppression_op_gpu/non_max_suppression_op.cu.pic.d (No such file or directory)
sh: /opt/rocm/bin/hipcc: No such file or directory
INFO: Elapsed time: 784.106s, Critical Path: 142.83s
INFO: 773 processes: 773 local.
FAILED: Build did NOT complete successfully
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. git clone
2. `export TF_NEED_ROCM=1`
3. `./configure`
4. 
```
  bazel \
        build --config=mkl --config=avx2_linux -c opt \
          //tensorflow:libtensorflow.so \
          //tensorflow:libtensorflow_cc.so \
          //tensorflow:install_headers \
          //tensorflow/tools/pip_package:build_pip_package
      bazel-bin/tensorflow/tools/pip_package/build_pip_package --gpu ""${srcdir}""/tmpoptrocm
```

To be exactly precise I am using the following build script (PKGBUILD):
https://aur.archlinux.org/cgit/aur.git/tree/PKGBUILD?h=tensorflow-rocm

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Downstream issue: https://github.com/rocm-arch/tensorflow-rocm/issues/9
"
42290,Deploy micro_speech  to ESP32 using ESP IDF,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- Target platform: esp32

**Describe the problem**
Unable to build the micro_speech in Tensorflow using esp-idf. 
**Please provide the exact sequence of commands/steps when you ran into the problem**
Generate examples

```
cd tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/micro_speech/esp-idf
```
Building the example
```
idf.py build
```

Executing action: all (aliases: build)
Running ninja in directory /home/george/Documents/MLANDAI/tensorflow/tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/micro_speech/esp-idf/build
Executing ""ninja all""...
[1/367] Performing build step for 'bootloader'
ninja: no work to do.
[6/365] Building CXX object esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/round.cc.obj
FAILED: esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/round.cc.obj 
/home/george/.espressif/tools/xtensa-esp32-elf/esp-2020r2-8.2.0/xtensa-esp32-elf/bin/xtensa-esp32-elf-g++   -Iconfig -I../components/tfmicro -I../components/tfmicro/third_party/gemmlowp -I../components/tfmicro/third_party/flatbuffers/include -I../components/tfmicro/third_party/ruy -I../components/tfmicro/third_party/kissfft -I/home/george/esp/esp-idf/components/newlib/platform_include -I/home/george/esp/esp-idf/components/freertos/include -I/home/george/esp/esp-idf/components/freertos/xtensa/include -I/home/george/esp/esp-idf/components/heap/include -I/home/george/esp/esp-idf/components/log/include -I/home/george/esp/esp-idf/components/lwip/include/apps -I/home/george/esp/esp-idf/components/lwip/include/apps/sntp -I/home/george/esp/esp-idf/components/lwip/lwip/src/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include/arch -I/home/george/esp/esp-idf/components/soc/src/esp32/. -I/home/george/esp/esp-idf/components/soc/src/esp32/include -I/home/george/esp/esp-idf/components/soc/include -I/home/george/esp/esp-idf/components/esp_rom/include -I/home/george/esp/esp-idf/components/esp_common/include -I/home/george/esp/esp-idf/components/esp_system/include -I/home/george/esp/esp-idf/components/xtensa/include -I/home/george/esp/esp-idf/components/xtensa/esp32/include -I/home/george/esp/esp-idf/components/esp32/include -I/home/george/esp/esp-idf/components/driver/include -I/home/george/esp/esp-idf/components/driver/esp32/include -I/home/george/esp/esp-idf/components/esp_ringbuf/include -I/home/george/esp/esp-idf/components/efuse/include -I/home/george/esp/esp-idf/components/efuse/esp32/include -I/home/george/esp/esp-idf/components/espcoredump/include -I/home/george/esp/esp-idf/components/esp_timer/include -I/home/george/esp/esp-idf/components/esp_ipc/include -I/home/george/esp/esp-idf/components/soc/soc/esp32/. -I/home/george/esp/esp-idf/components/soc/soc/esp32/include -I/home/george/esp/esp-idf/components/soc/soc/esp32/../include -I/home/george/esp/esp-idf/components/vfs/include -I/home/george/esp/esp-idf/components/esp_wifi/include -I/home/george/esp/esp-idf/components/esp_wifi/esp32/include -I/home/george/esp/esp-idf/components/esp_event/include -I/home/george/esp/esp-idf/components/esp_netif/include -I/home/george/esp/esp-idf/components/esp_eth/include -I/home/george/esp/esp-idf/components/tcpip_adapter/include -I/home/george/esp/esp-idf/components/app_trace/include -mlongcalls -Wno-frame-address   -ffunction-sections -fdata-sections -fstrict-volatile-bitfields -Wall -Werror=all -Wno-error=unused-function -Wno-error=unused-but-set-variable -Wno-error=unused-variable -Wno-error=deprecated-declarations -Wextra -Wno-unused-parameter -Wno-sign-compare -ggdb -O2 -std=gnu++11 -fno-exceptions -fno-rtti -D_GNU_SOURCE -DIDF_VER=\""v4.3-dev-771-gc77c4ccf6\"" -DESP_PLATFORM -Wno-maybe-uninitialized -Wno-missing-field-initializers -Wno-type-limits -std=c11 -DTF_LITE_STATIC_MEMORY -DNDEBUG -O3 -Wno-nonnull -std=c++11 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wno-return-type -Wno-strict-aliasing -Wno-ignored-qualifiers -MD -MT esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/round.cc.obj -MF esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/round.cc.obj.d -o esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/round.cc.obj -c ../components/tfmicro/tensorflow/lite/micro/kernels/round.cc
cc1plus: error: command line option '-std=c11' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: all warnings being treated as errors
[8/365] Building CXX object esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/neg.cc.obj
FAILED: esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/neg.cc.obj 
/home/george/.espressif/tools/xtensa-esp32-elf/esp-2020r2-8.2.0/xtensa-esp32-elf/bin/xtensa-esp32-elf-g++   -Iconfig -I../components/tfmicro -I../components/tfmicro/third_party/gemmlowp -I../components/tfmicro/third_party/flatbuffers/include -I../components/tfmicro/third_party/ruy -I../components/tfmicro/third_party/kissfft -I/home/george/esp/esp-idf/components/newlib/platform_include -I/home/george/esp/esp-idf/components/freertos/include -I/home/george/esp/esp-idf/components/freertos/xtensa/include -I/home/george/esp/esp-idf/components/heap/include -I/home/george/esp/esp-idf/components/log/include -I/home/george/esp/esp-idf/components/lwip/include/apps -I/home/george/esp/esp-idf/components/lwip/include/apps/sntp -I/home/george/esp/esp-idf/components/lwip/lwip/src/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include/arch -I/home/george/esp/esp-idf/components/soc/src/esp32/. -I/home/george/esp/esp-idf/components/soc/src/esp32/include -I/home/george/esp/esp-idf/components/soc/include -I/home/george/esp/esp-idf/components/esp_rom/include -I/home/george/esp/esp-idf/components/esp_common/include -I/home/george/esp/esp-idf/components/esp_system/include -I/home/george/esp/esp-idf/components/xtensa/include -I/home/george/esp/esp-idf/components/xtensa/esp32/include -I/home/george/esp/esp-idf/components/esp32/include -I/home/george/esp/esp-idf/components/driver/include -I/home/george/esp/esp-idf/components/driver/esp32/include -I/home/george/esp/esp-idf/components/esp_ringbuf/include -I/home/george/esp/esp-idf/components/efuse/include -I/home/george/esp/esp-idf/components/efuse/esp32/include -I/home/george/esp/esp-idf/components/espcoredump/include -I/home/george/esp/esp-idf/components/esp_timer/include -I/home/george/esp/esp-idf/components/esp_ipc/include -I/home/george/esp/esp-idf/components/soc/soc/esp32/. -I/home/george/esp/esp-idf/components/soc/soc/esp32/include -I/home/george/esp/esp-idf/components/soc/soc/esp32/../include -I/home/george/esp/esp-idf/components/vfs/include -I/home/george/esp/esp-idf/components/esp_wifi/include -I/home/george/esp/esp-idf/components/esp_wifi/esp32/include -I/home/george/esp/esp-idf/components/esp_event/include -I/home/george/esp/esp-idf/components/esp_netif/include -I/home/george/esp/esp-idf/components/esp_eth/include -I/home/george/esp/esp-idf/components/tcpip_adapter/include -I/home/george/esp/esp-idf/components/app_trace/include -mlongcalls -Wno-frame-address   -ffunction-sections -fdata-sections -fstrict-volatile-bitfields -Wall -Werror=all -Wno-error=unused-function -Wno-error=unused-but-set-variable -Wno-error=unused-variable -Wno-error=deprecated-declarations -Wextra -Wno-unused-parameter -Wno-sign-compare -ggdb -O2 -std=gnu++11 -fno-exceptions -fno-rtti -D_GNU_SOURCE -DIDF_VER=\""v4.3-dev-771-gc77c4ccf6\"" -DESP_PLATFORM -Wno-maybe-uninitialized -Wno-missing-field-initializers -Wno-type-limits -std=c11 -DTF_LITE_STATIC_MEMORY -DNDEBUG -O3 -Wno-nonnull -std=c++11 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wno-return-type -Wno-strict-aliasing -Wno-ignored-qualifiers -MD -MT esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/neg.cc.obj -MF esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/neg.cc.obj.d -o esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/neg.cc.obj -c ../components/tfmicro/tensorflow/lite/micro/kernels/neg.cc
cc1plus: error: command line option '-std=c11' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: all warnings being treated as errors
[9/365] Building CXX object esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/unpack.cc.obj
FAILED: esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/unpack.cc.obj 
/home/george/.espressif/tools/xtensa-esp32-elf/esp-2020r2-8.2.0/xtensa-esp32-elf/bin/xtensa-esp32-elf-g++   -Iconfig -I../components/tfmicro -I../components/tfmicro/third_party/gemmlowp -I../components/tfmicro/third_party/flatbuffers/include -I../components/tfmicro/third_party/ruy -I../components/tfmicro/third_party/kissfft -I/home/george/esp/esp-idf/components/newlib/platform_include -I/home/george/esp/esp-idf/components/freertos/include -I/home/george/esp/esp-idf/components/freertos/xtensa/include -I/home/george/esp/esp-idf/components/heap/include -I/home/george/esp/esp-idf/components/log/include -I/home/george/esp/esp-idf/components/lwip/include/apps -I/home/george/esp/esp-idf/components/lwip/include/apps/sntp -I/home/george/esp/esp-idf/components/lwip/lwip/src/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include/arch -I/home/george/esp/esp-idf/components/soc/src/esp32/. -I/home/george/esp/esp-idf/components/soc/src/esp32/include -I/home/george/esp/esp-idf/components/soc/include -I/home/george/esp/esp-idf/components/esp_rom/include -I/home/george/esp/esp-idf/components/esp_common/include -I/home/george/esp/esp-idf/components/esp_system/include -I/home/george/esp/esp-idf/components/xtensa/include -I/home/george/esp/esp-idf/components/xtensa/esp32/include -I/home/george/esp/esp-idf/components/esp32/include -I/home/george/esp/esp-idf/components/driver/include -I/home/george/esp/esp-idf/components/driver/esp32/include -I/home/george/esp/esp-idf/components/esp_ringbuf/include -I/home/george/esp/esp-idf/components/efuse/include -I/home/george/esp/esp-idf/components/efuse/esp32/include -I/home/george/esp/esp-idf/components/espcoredump/include -I/home/george/esp/esp-idf/components/esp_timer/include -I/home/george/esp/esp-idf/components/esp_ipc/include -I/home/george/esp/esp-idf/components/soc/soc/esp32/. -I/home/george/esp/esp-idf/components/soc/soc/esp32/include -I/home/george/esp/esp-idf/components/soc/soc/esp32/../include -I/home/george/esp/esp-idf/components/vfs/include -I/home/george/esp/esp-idf/components/esp_wifi/include -I/home/george/esp/esp-idf/components/esp_wifi/esp32/include -I/home/george/esp/esp-idf/components/esp_event/include -I/home/george/esp/esp-idf/components/esp_netif/include -I/home/george/esp/esp-idf/components/esp_eth/include -I/home/george/esp/esp-idf/components/tcpip_adapter/include -I/home/george/esp/esp-idf/components/app_trace/include -mlongcalls -Wno-frame-address   -ffunction-sections -fdata-sections -fstrict-volatile-bitfields -Wall -Werror=all -Wno-error=unused-function -Wno-error=unused-but-set-variable -Wno-error=unused-variable -Wno-error=deprecated-declarations -Wextra -Wno-unused-parameter -Wno-sign-compare -ggdb -O2 -std=gnu++11 -fno-exceptions -fno-rtti -D_GNU_SOURCE -DIDF_VER=\""v4.3-dev-771-gc77c4ccf6\"" -DESP_PLATFORM -Wno-maybe-uninitialized -Wno-missing-field-initializers -Wno-type-limits -std=c11 -DTF_LITE_STATIC_MEMORY -DNDEBUG -O3 -Wno-nonnull -std=c++11 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wno-return-type -Wno-strict-aliasing -Wno-ignored-qualifiers -MD -MT esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/unpack.cc.obj -MF esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/unpack.cc.obj.d -o esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/unpack.cc.obj -c ../components/tfmicro/tensorflow/lite/micro/kernels/unpack.cc
cc1plus: error: command line option '-std=c11' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: all warnings being treated as errors
[15/365] Building CXX object esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/add.cc.obj
FAILED: esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/add.cc.obj 
/home/george/.espressif/tools/xtensa-esp32-elf/esp-2020r2-8.2.0/xtensa-esp32-elf/bin/xtensa-esp32-elf-g++   -Iconfig -I../components/tfmicro -I../components/tfmicro/third_party/gemmlowp -I../components/tfmicro/third_party/flatbuffers/include -I../components/tfmicro/third_party/ruy -I../components/tfmicro/third_party/kissfft -I/home/george/esp/esp-idf/components/newlib/platform_include -I/home/george/esp/esp-idf/components/freertos/include -I/home/george/esp/esp-idf/components/freertos/xtensa/include -I/home/george/esp/esp-idf/components/heap/include -I/home/george/esp/esp-idf/components/log/include -I/home/george/esp/esp-idf/components/lwip/include/apps -I/home/george/esp/esp-idf/components/lwip/include/apps/sntp -I/home/george/esp/esp-idf/components/lwip/lwip/src/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include -I/home/george/esp/esp-idf/components/lwip/port/esp32/include/arch -I/home/george/esp/esp-idf/components/soc/src/esp32/. -I/home/george/esp/esp-idf/components/soc/src/esp32/include -I/home/george/esp/esp-idf/components/soc/include -I/home/george/esp/esp-idf/components/esp_rom/include -I/home/george/esp/esp-idf/components/esp_common/include -I/home/george/esp/esp-idf/components/esp_system/include -I/home/george/esp/esp-idf/components/xtensa/include -I/home/george/esp/esp-idf/components/xtensa/esp32/include -I/home/george/esp/esp-idf/components/esp32/include -I/home/george/esp/esp-idf/components/driver/include -I/home/george/esp/esp-idf/components/driver/esp32/include -I/home/george/esp/esp-idf/components/esp_ringbuf/include -I/home/george/esp/esp-idf/components/efuse/include -I/home/george/esp/esp-idf/components/efuse/esp32/include -I/home/george/esp/esp-idf/components/espcoredump/include -I/home/george/esp/esp-idf/components/esp_timer/include -I/home/george/esp/esp-idf/components/esp_ipc/include -I/home/george/esp/esp-idf/components/soc/soc/esp32/. -I/home/george/esp/esp-idf/components/soc/soc/esp32/include -I/home/george/esp/esp-idf/components/soc/soc/esp32/../include -I/home/george/esp/esp-idf/components/vfs/include -I/home/george/esp/esp-idf/components/esp_wifi/include -I/home/george/esp/esp-idf/components/esp_wifi/esp32/include -I/home/george/esp/esp-idf/components/esp_event/include -I/home/george/esp/esp-idf/components/esp_netif/include -I/home/george/esp/esp-idf/components/esp_eth/include -I/home/george/esp/esp-idf/components/tcpip_adapter/include -I/home/george/esp/esp-idf/components/app_trace/include -mlongcalls -Wno-frame-address   -ffunction-sections -fdata-sections -fstrict-volatile-bitfields -Wall -Werror=all -Wno-error=unused-function -Wno-error=unused-but-set-variable -Wno-error=unused-variable -Wno-error=deprecated-declarations -Wextra -Wno-unused-parameter -Wno-sign-compare -ggdb -O2 -std=gnu++11 -fno-exceptions -fno-rtti -D_GNU_SOURCE -DIDF_VER=\""v4.3-dev-771-gc77c4ccf6\"" -DESP_PLATFORM -Wno-maybe-uninitialized -Wno-missing-field-initializers -Wno-type-limits -std=c11 -DTF_LITE_STATIC_MEMORY -DNDEBUG -O3 -Wno-nonnull -std=c++11 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wno-return-type -Wno-strict-aliasing -Wno-ignored-qualifiers -MD -MT esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/add.cc.obj -MF esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/add.cc.obj.d -o esp-idf/tfmicro/CMakeFiles/__idf_tfmicro.dir/tensorflow/lite/micro/kernels/add.cc.obj -c ../components/tfmicro/tensorflow/lite/micro/kernels/add.cc
cc1plus: error: command line option '-std=c11' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: all warnings being treated as errors
ninja: build stopped: subcommand failed.
ninja failed with exit code 1





"
42287,graph_util.remove_training_nodes removes library from graphdef,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: only cpu
- GPU model and memory: only on cpu

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
graph_util.remove_training_nodes will remove library from graphdef, which is needed for operator like StatefulPartitionedCall. 

**Describe the expected behavior**
The library should not be removed when freezing graph.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42286,In TF2.3 Reshape is not converted correctly,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): 2.3.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()
```

**Also, please include a link to the saved model or GraphDef**

Attached to issue 
[saved_model.zip](https://github.com/tensorflow/tensorflow/files/5065959/saved_model.zip)

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:

When converting a reshape, the resulting model has extra ops. Here's the expected output, as produced with `converter.experimental_new_converter = False`:

![image](https://user-images.githubusercontent.com/379235/90071187-f8349200-dca9-11ea-882f-1ed354fbe36a.png)

And here's the output with the new converter, note the extra ops before the reshape:

![image](https://user-images.githubusercontent.com/379235/90071275-1f8b5f00-dcaa-11ea-90e6-0ee502e148c6.png)
"
42284,(please help) model.predict  Error   ,"Hello, I am new to coding but I keep running into an error with what should be a very simple code (I have pasted below)

**import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Reshape
from tensorflow.keras import layers
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
from keras import backend as K
plt.style.use('fivethirtyeight')

from tensorflow.keras.datasets import cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()


print(type(x_train))
print(type(y_train))
print(type(x_test))
print(type(y_test))

print('x_train shape:', x_train.shape)
print('y_train shape:', y_train.shape)
print('x_test shape:', x_test.shape)
print('y_test shape:', y_test.shape)

index = 1
x_train[index]

img = plt.imshow(x_train[index])

classification = ['airplane', 'automobile','bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
                  
print('the image class is:', classification[y_train[index][0]])

y_train_one_hot = to_categorical(y_train)
y_test_one_hot = to_categorical(y_train)

print('the new one hot label is:', y_train_one_hot)

x_train = x_train / 255
x_test = x_train / 255

x_train[index]

model = Sequential()

model.add( Conv2D(32, (5,5), activation='relu', input_shape=(32,32,3)) )

model.add(MaxPooling2D(pool_size = (2,2)))

model.add( Conv2D(32, (5,5), activation='relu') )

model.add(MaxPooling2D(pool_size = (2,2)))

model.add(Flatten())

model.add(Dense(1000, activation='relu'))

model.add(Dropout(0.5))

model.add(Dense(500, activation='relu'))

model.add(Dropout(0.5))

model.add(Dense(250, activation='relu'))

model.add(Dense(10, activation='softmax'))


model.compile(loss = 'categorical_crossentropy',
              optimizer = 'adam',
              metrics = ['accuracy'])
#hist = model.fit(x_train, y_train_one_hot,
               #batch_size = 256,
               #epochs = 10,
               #validation_split = 0.2)
#model.evaluate(x_test, y_test_one_hot)[1]

#plt.plot(hist.history['accuracy'])
#plt.plot(hist.history['val_accuracy'])
#plt.title('Model Accuracy')
#plt.ylabel('Accuracy')
#plt.xlabel('Epoch')
#plt.legend(['Train','Val'],loc='upper right')
#plt.show()

new_image = plt.imread('/Users/home/Sunflower_from_Silesia2.jpg')
img=plt.imshow(new_image)
from skimage.transform import resize
resized_image = resize(new_image, (32,32,3))
img = plt.imshow(resized_image)

predictions = model.predict(np.array([resized_image]))

predictions**


The error I am recieving is:

**INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x155eb1680>
    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)
    kwargs: {}

Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x155eb1680>
    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)
    kwargs: {}

INFO:tensorflow:Allowlisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x155eb1680>: DoNotConvert rule for tensorflow
Allowlisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x155eb1680>: DoNotConvert rule for tensorflow
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x155eb1830>
    args: (<tf.Tensor 'args_0:0' shape=(1,) dtype=int64>,)
    kwargs: {}

Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x155eb1830>
    args: (<tf.Tensor 'args_0:0' shape=(1,) dtype=int64>,)
    kwargs: {}

INFO:tensorflow:Allowlisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x155eb1830>: DoNotConvert rule for tensorflow
Allowlisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x155eb1830>: DoNotConvert rule for tensorflow
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x155eb1d40>
    args: (<tf.Tensor 'args_0:0' shape=(None,) dtype=int64>, <tf.Tensor 'args_1:0' shape=(1, 32, 32, 3) dtype=float32>)
    kwargs: {}

Converted call: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x155eb1d40>
    args: (<tf.Tensor 'args_0:0' shape=(None,) dtype=int64>, <tf.Tensor 'args_1:0' shape=(1, 32, 32, 3) dtype=float32>)
    kwargs: {}

INFO:tensorflow:Allowlisted: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x155eb1d40>: DoNotConvert rule for tensorflow
Allowlisted: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x155eb1d40>: DoNotConvert rule for tensorflow
INFO:tensorflow:Converted call: <function Model.make_predict_function.<locals>.predict_function at 0x156df00e0>
    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x155e9a050>,)
    kwargs: {}

Converted call: <function Model.make_predict_function.<locals>.predict_function at 0x156df00e0>
    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x155e9a050>,)
    kwargs: {}

INFO:tensorflow:<function Model.make_predict_function.<locals>.predict_function at 0x156df00e0> is not cached for subkey ConversionOptions[{}]
<function Model.make_predict_function.<locals>.predict_function at 0x156df00e0> is not cached for subkey ConversionOptions[{}]
INFO:tensorflow:Source code of <function Model.make_predict_function.<locals>.predict_function at 0x156df00e0>:

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
def predict_function(iterator):
  """"""Runs an evaluation execution with one step.""""""
  return step_function(self, iterator)


Source code of <function Model.make_predict_function.<locals>.predict_function at 0x156df00e0>:

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
def predict_function(iterator):
  """"""Runs an evaluation execution with one step.""""""
  return step_function(self, iterator)


INFO:tensorflow:Error transforming entity <function Model.make_predict_function.<locals>.predict_function at 0x156df00e0>
Traceback (most recent call last):
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 444, in converted_call
    converted_f = _convert_actual(target_entity, program_ctx)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 284, in _convert_actual
    transformed, module, source_map = _TRANSPILER.transform(entity, program_ctx)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 286, in transform
    return self.transform_function(obj, user_context)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 470, in transform_function
    nodes, ctx = super(PyToPy, self).transform_function(fn, user_context)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 363, in transform_function
    result = self.transform_ast(node, context)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 252, in transform_ast
    node = self.initial_analysis(node, ctx)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 240, in initial_analysis
    node = activity.resolve(node, ctx, None)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 708, in resolve
    return ActivityAnalyzer(context, parent_scope).visit(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py"", line 445, in visit
    result = super(Base, self).visit(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/ast.py"", line 271, in visit
    return visitor(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 578, in visit_FunctionDef
    node = self._visit_arg_annotations(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 554, in _visit_arg_annotations
    node = self._visit_arg_declarations(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 559, in _visit_arg_declarations
    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)
AttributeError: 'arguments' object has no attribute 'posonlyargs'
Error transforming entity <function Model.make_predict_function.<locals>.predict_function at 0x156df00e0>
WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x156df00e0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x156df00e0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
INFO:tensorflow:Converted call: <function Model.make_predict_function.<locals>.step_function.<locals>.run_step at 0x156df0950>
    args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 32, 32, 3) dtype=float32>,)
    kwargs: {}

Converted call: <function Model.make_predict_function.<locals>.step_function.<locals>.run_step at 0x156df0950>
    args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 32, 32, 3) dtype=float32>,)
    kwargs: {}

INFO:tensorflow:Allowlisted: <function Model.make_predict_function.<locals>.step_function.<locals>.run_step at 0x156df0950>: DoNotConvert rule for tensorflow
Allowlisted: <function Model.make_predict_function.<locals>.step_function.<locals>.run_step at 0x156df0950>: DoNotConvert rule for tensorflow
WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x156df00e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Traceback (most recent call last):
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 444, in converted_call
    converted_f = _convert_actual(target_entity, program_ctx)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 284, in _convert_actual
    transformed, module, source_map = _TRANSPILER.transform(entity, program_ctx)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 286, in transform
    return self.transform_function(obj, user_context)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 470, in transform_function
    nodes, ctx = super(PyToPy, self).transform_function(fn, user_context)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 363, in transform_function
    result = self.transform_ast(node, context)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 252, in transform_ast
    node = self.initial_analysis(node, ctx)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 240, in initial_analysis
    node = activity.resolve(node, ctx, None)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 708, in resolve
    return ActivityAnalyzer(context, parent_scope).visit(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py"", line 445, in visit
    result = super(Base, self).visit(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/ast.py"", line 271, in visit
    return visitor(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 578, in visit_FunctionDef
    node = self._visit_arg_annotations(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 554, in _visit_arg_annotations
    node = self._visit_arg_declarations(node)
  File ""/Users/home/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 559, in _visit_arg_declarations
    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)
AttributeError: 'arguments' object has no attribute 'posonlyargs'**


Everything works except for the predictions line. Are there any idea how to fix this? I am running this on Spyder on Anaconda-Navigator. Thank you!"
42283,[breaking? change] Concatenate dict of keras layers breaks on tf 2.3 (but worked in 2.2),"**System information**
- Have I written custom code : **No**
- OS Platform and Distribution : **macos-latest, ubuntu-latest (github actions)** , macOS Mojave 10.14.1 (locally)
- TensorFlow installed from (source or binary): **pip install**
- TensorFlow version (use command below): *2.2 -> 2.3*
- Python version: **3.6 and 3.7**

**Describe the current behavior**
(this is on `tensorflow 2.2.0`)
```python
features_in = ['a', 'b']
input_layers = {
    colname: tf.keras.layers.Input(
        name=colname, shape=(1,), dtype=tf.float32)
    for colname in features_in
}

# the following line just works
x = tf.keras.layers.Concatenate(axis=-1)(input_layers.values())
x
```
`<tf.Tensor 'concatenate_1/Identity:0' shape=(None, 2) dtype=float32>`



**Describe the expected behavior**


(The following is in tensorflow 2.3.0)
`<the same snippet from above>`

The following error occurs:
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-2-332d856dc8d7> in <module>
      6 }
      7 
----> 8 x = tf.keras.layers.Concatenate(axis=-1)(input_layers.values())
      9 x

/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    924     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):
    925       return self._functional_construction_call(inputs, args, kwargs,
--> 926                                                 input_list)
    927 
    928     # Maintains info about the `Layer.call` stack.

/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)
   1115           try:
   1116             with ops.enable_auto_cast_variables(self._compute_dtype_object):
-> 1117               outputs = call_fn(cast_inputs, *args, **kwargs)
   1118 
   1119           except errors.OperatorNotAllowedInGraphError as e:

/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py in call(self, inputs)
    120   def call(self, inputs):
    121     if not isinstance(inputs, (list, tuple)):
--> 122       raise ValueError('A merge layer should be called on a list of inputs.')
    123     if self._reshape_required:
    124       reshaped_inputs = []

ValueError: A merge layer should be called on a list of inputs.
```
"
42282,How can i solve data transferred from slave to master using SPI?,"I tried to make a communication between two AVR (ATmega128) using SPI. Data transferred correctly from master to slave but data transferred wrong from slave to master, the first sampled bit is always wrong. Slave sends (0X7E) to master but the received data is (0X3F). Where is the mistake?

Code of MASTER

#define F_CPU 16000000UL

#include <avr/io.h>
#include <util/delay.h>

#define DDR_SPI DDRB
#define DD_MOSI PB2
#define DD_SCK PB1
#define DD_SS PB0

#define ACK 0x7E

void SPI_MasterInit(void)
{
/* Set MOSI and SCK output /
DDR_SPI |= (1<<DD_MOSI) | (1<<DD_SCK) | (1<<DD_SS);
PORTB |= 1;
/ Enable SPI, Master, set clock rate fck/128 */
SPCR |= (1<<SPE)|(1<<MSTR)|(1<<SPR0)|(1<<SPR1);
}

unsigned char SPI_MasterTransmit(unsigned char cData)
{
PORTB &= ~(1<<0);
while( (PORTB & (1<<0)) );
/* Start transmission /
SPDR = cData;
/ Wait for transmission complete */
while(!(SPSR & (1<<SPIF)));
PORTB |= 1;
return SPDR;
}

void ADC_Init()
{
//ADC enable
ADCSRA |= (1<<ADEN);
//division factor --> 128
ADCSRA |= (1<<ADPS0) | (1<<ADPS1) | (1<<ADPS2);
//left adjusted (8 bit mode) (ADCH)
ADMUX |= (1<<ADLAR);
//input channel --> ADC2 (only one channel can be used in the conversion at a time)
ADMUX |= (1<<MUX1);
}

unsigned char ADC_StartConversion()
{
ADCSRA |= (1 << ADSC);
while(ADCSRA & (1<<ADSC));
return ADCH;
}

int main(void)
{
DDRC = 1;
ADC_Init();
SPI_MasterInit();
unsigned char data;
unsigned char ret;

while (1) 
{
	data = ADC_StartConversion();
	ret = SPI_MasterTransmit(data);
	
	if(ret == ACK)
	{
		PORTC = 1;
	}
	
	else
	{
		PORTC = 0;
	}
	
}
}

Code of SLAVE

#define F_CPU 16000000UL

#include <avr/io.h>
#include <util/delay.h>

#define DDR_SPI DDRB
#define DD_MISO 3
#define LED PC0

#define ACK 0x7E

void SPI_SlaveInit(void)
{
/* Set MISO output, all others input /
DDR_SPI = (1<<DD_MISO);
/ Enable SPI */
SPCR = (1<<SPE);
}

unsigned char SPI_SlaveReceive(char data)
{
SPDR = data;
/* Wait for reception complete /
while(!(SPSR & (1<<SPIF)));
/ Return data register */
return SPDR;
}

int main(void)
{
DDRC |= (1<<LED);
SPI_SlaveInit();
unsigned char data;

while (1) 
{	
	data = SPI_SlaveReceive(ACK);
	if(data >= 128)
	{
		PORTC |= (1<<LED);
	}
	else
	{
		PORTC &= ~(1<<LED);
	}
	//_delay_ms(100);	
}
}"
42281,tf.nn.ctc_beam_search_decoder crashes(bad_alloc) when top_paths is large,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.nn.ctc_beam_search_decoder` crashes(bad_alloc) when `top_paths` is extremely large

**Describe the expected behavior**
Expect no crashes

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
tf.nn.ctc_beam_search_decoder(inputs=tf.ones((1,1,1)), sequence_length=[1], top_paths=1000000000000)
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
  what():  std::bad_alloc
Aborted (core dumped)
~~~
"
42280,Predict on batch being able to do the prediction with inputs of different first shapes,"**System information**
- TensorFlow version (you are using): 2.3
- Are you willing to contribute it (Yes/No): yes


**Describe the feature and the current behavior/state.**
For a recommender system usage we want to be able to have a keras model that takes inputs with different first dimensions, for example one input with N rows and another with one row.
That feature was also asked here https://github.com/keras-team/keras/issues/13646 for another use case.

Until https://github.com/tensorflow/tensorflow/commit/56a0ce87911236765633d2a873e706ebc6401ef9 predict on batch did not check the cardinality of tensors before creating the dataset so our usage fits in the Keras api.
but now there is an additional _check_data_cardinality(data):
https://github.com/tensorflow/tensorflow/commit/56a0ce87911236765633d2a873e706ebc6401ef9#diff-f8dd40712ac721c1b363e1a1ec44c1a3R1523
that will break if you pass two inputs one with one row and one with N rows. 

**Will this change the current api? How?**
Provide a way to disable that check, either making it a warning or removing it. 

**Who will benefit with this feature?**
Users with non static input shapes, recommenders systems where we want to take into advantage the fact that we do a prediction on 1 movie for all the users to use broadcasting instead of running N times the same embedding. 
**Any Other info.**
"
42279,tf.keras.backend.ctc_decode crashes(bad_alloc) when top_paths is large,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A
You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.keras.backend.ctc_decode` crashes(abort, bad_alloc) when `top_paths` is large and greedy is `False`

**Describe the expected behavior**
Expect no crashes

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python

import tensorflow as tf
tf.keras.backend.ctc_decode(y_pred=tf.ones((1,1,1)), input_length=1, top_paths=1000000000, greedy=False)

~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~
  what():  std::bad_alloc
Aborted (core dumped)
~~~"
42278,tf.nn.fractional_max_pool aborts when pooling_ratio is negative,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

`tf.nn.fractional_max_pool` aborts when `pooling_ratio` is negative in tf2.1. It throws segfault in nightly version.

**Describe the expected behavior**
Expect no crashes or aborts. 
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
tf.nn.fractional_max_pool(value=tf.ones((1,1,1,1)), seed=1, pooling_ratio=-1)
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Error message in TF2.1:
~~~python
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted (core dumped)
~~~
Error message in TF nightly:
~~~
Segmentation fault (core dumped)
~~~"
42277,XNNPACK delegate performs much slower than default TFLite backend if multi-threading is configured according to documentation,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 16.04, Android 10**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **Any Android smarthphone**
- TensorFlow installed from (source or binary): **Source**
- TensorFlow version (use command below): **2.3.0**
- Python version: **-** 
- Bazel version (if compiling from source): **3.1.0**
- GCC/Compiler version (if compiling from source): GCC 5.4.0 / Clang shipped with Android NDK 21
- CUDA/cuDNN version: **-** 
- GPU model and memory: **-**

When TFLite is built with XNNPACK, performance improvement is expected. However, seems like the code provided in `/tensorflow/lite/examples/minimal` with a minor change of interpreter settings leads to performance degradation comparing to the default build.

So here is the code taken from minimal example with my changes:

```cpp
  ...

  // Load model
  std::unique_ptr<tflite::FlatBufferModel> model =
      tflite::FlatBufferModel::BuildFromFile(filename);
  TFLITE_MINIMAL_CHECK(model != nullptr);

  // Build the interpreter
  tflite::ops::builtin::BuiltinOpResolver resolver;
  InterpreterBuilder builder(*model, resolver);
  std::unique_ptr<Interpreter> interpreter;
  builder(&interpreter);
  TFLITE_MINIMAL_CHECK(interpreter != nullptr);

  // Allocate tensor buffers.
  TFLITE_MINIMAL_CHECK(interpreter->AllocateTensors() == kTfLiteOk);
  printf(""=== Pre-invoke Interpreter State ===\n"");
  tflite::PrintInterpreterState(interpreter.get());

  // Set number of threads (added by me)
  interpreter->SetNumThreads(8);

  // Run inference
  TFLITE_MINIMAL_CHECK(interpreter->Invoke() == kTfLiteOk);
  printf(""\n\n=== Post-invoke Interpreter State ===\n"");
  tflite::PrintInterpreterState(interpreter.get());

  ...
```

This code performs slower if executed with TFLite + XNNPACK build. I've tested it both on x64 desktop and arm64 Android using ResNet-34 FP32 TFLite model and observed the exact same performance degradation.

I was able to fix the behavior and achieve 30% performance improvement only after I spent few hours with TFLite code and found out that **tflite::Interpreter::SetNumThreads is not applied to XNNPACK delegate (maybe to other delegates as well)**, because XNNPACK delegate is only initialized in `builder(&interpreter)` with number of threads passed to this invocation and then is not being updated on `interpreter->SetNumThreads(8)` call! In the  case is illustrated by the code above), XNNPACK work in single-threaded mode or so. So the fix is to initialize interpreter as the following:

```cpp
  builder(&interpreter, 8);
```

Then XNNPACK really introduces significant performance improvement.

I'm OK with the solution that I found, but I was really confused with this issue and spent almost a day figuring out why can't I achieve claimed performance, because neither official documentation nor TFLite code commentary does not mention `InterpreterBuilder`'s `num_threads` argument as something necessary or mention it at least. Thus, following [""Tweak the number of threads""](https://www.tensorflow.org/lite/performance/best_practices#tweak_the_number_of_threads) documentation section in combination with using XNNPACK will lead anyone to this pitfall and will result with a very poor performance.

If it's need I can provide more standalone example, point to the parts of TFLite code, which are responsible for this behavior, and detailed measurements obtained on different devices.

"
42276,"tensorflow lite native app, undefined reference to `NnApiImplementation()'","I am getting the following error on these line:

```
uint32_t device_count = 0;
auto nnapi_result = NnApiImplementation()->ANeuralNetworks_getDeviceCount(&device_count);
```
.../benchmark_jni.cpp:413: undefined reference to `NnApiImplementation()'

NnApiImplementation() is referenced in nnapi_implementation.h:
```
/**
 * Load the NNAPI implementation from the shared libraries.
 * The NnApi structure is filled with all the pointers. If one function doesn't
 * exist, a null pointer is stored.
 */
const NnApi* NnApiImplementation();
```

I had previously built the arm64-v8a shared library as illustrated in this guide: 
https://www.tensorflow.org/lite/guide/android#build_in_android_studio 

using the docker image method and finally building with this command:

`bazel build -c opt --config=android_arm64 //tensorflow/lite:libtensorflowlite.so`

However when I try to find the NnApiImplementation in the .so file using:
`nm -gDC libtensorflowlite.so | grep ""NnApiImplementation""
`
Nothing is returned. 

"
42272,checkpoint.restore  can't work,"version: tensorflow2.2  2.3

```python
class MyModel(tf.keras.Model):
    def __init__(self, **kwargs):
        super(MyModel, self).__init__(**kwargs)

    def build(self, input_shape):
        self.dense = tf.keras.layers.Dense(2)

    def call(self, inputs):
        out = self.dense(inputs)
        return out

if __name__ == '__main__':
    data = tf.constant(tf.ones((10, 20)))

    tag = tf.constant(tf.ones((10)))
    testmodel = MyModel()
    optimizer = tf.keras.optimizers.Adam()
    checkpoint = tf.train.Checkpoint(tmodel=testmodel)
    with tf.GradientTape() as tape:
        out = testmodel(data)
        loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(tag, out))
    grad = tape.gradient(loss, testmodel.trainable_variables)
    optimizer.apply_gradients(zip(grad, testmodel.trainable_variables))

    checkpoint.save(""test/model.ckpt"")
```

Then I load the model. It reports an error

```python
if __name__ == '__main__':
    testmodel = MyModel()
    checkpoint = tf.train.Checkpoint(tmodel=testmodel)
    checkpoint.restore(tf.train.latest_checkpoint('test'))
```
 It reports an error.

WARNING:tensorflow:Unresolved object in checkpoint: (root).tmodel.dense
WARNING:tensorflow:Unresolved object in checkpoint: (root).tmodel.dense.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).tmodel.dense.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.

How to fix it?

and in here ,also have this error  https://www.tensorflow.org/tutorials/keras/save_and_load?hl=zh-cn
![image](https://user-images.githubusercontent.com/19524544/90044790-be42aa80-dd00-11ea-9c2c-c937d5a29b27.png)



"
42271,Model using Conv1D returns socket closed error on TPU while with SeparableConv1D works,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): GCP instance Debian 9
- TensorFlow installed from (source or binary): installed via pip 
- TensorFlow version (use command below): 2.3
- Python version: 3.7.6
- **TPU** model: TPU v3-8

**Describe the current behavior**
I am executing a deep CNN model to handle sequences using TPUs. The exact same model, if layers are Conv1D, does not work returning a specific error, while, if I use SeparableConv1D, the model works fine.

**Describe the expected behavior**
The model should work using Conv1D layers.

**Other info / logs** 

> /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
>     106   def _method_wrapper(self, *args, **kwargs):
>     107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
> --> 108       return method(self, *args, **kwargs)
>     109 
>     110     # Running inside `run_distribute_coordinator` already.
> 
> /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
>    1098               tmp_logs = train_function(iterator)
>    1099               if data_handler.should_sync:
> -> 1100                 context.async_wait()
>    1101               logs = tmp_logs  # No error, now safe to assign to logs.
>    1102               end_step = step + data_handler.step_increment
> 
> /opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py in async_wait()
>    2317   an error state.
>    2318   """"""
> -> 2319   context().sync_executors()
>    2320 
>    2321 
> 
> /opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py in sync_executors(self)
>     656     """"""
>     657     if self._context_handle:
> --> 658       pywrap_tfe.TFE_ContextSyncExecutors(self._context_handle)
>     659     else:
>     660       raise ValueError(""Context is not initialized."")
> 
> UnavailableError: 2 root error(s) found.
>   (0) Unavailable: Socket closed
>   (1) Invalid argument: Unable to find a context_id matching the specified one (5208125777247716751). Perhaps the worker was restarted, or the context was GC'd?
> 0 successful operations.
> 0 derived errors ignored.
"
42267,Debundled/System JsonCPP uses wrong header path,"**Describe the problem**

When using TF_SYSTEM_LIBS=jsoncpp_git the build scripts will try linking headers from `$(INCLUDEDIR)/jsoncpp/json/` which has 2 problems:

1. INCLUDEDIR cannot be set for JsonCPP only making it impossible to install jsoncpp to a custom prefix (e.g. /opt/jsoncpp), see #37835
2. When installing JsonCPP there will be headers `<prefix>/include/json/*.h`. I.e. there is no additional folder ""jsoncpp"". See https://github.com/open-source-parsers/jsoncpp/blob/5be07bdc5e2d5b7715ecbc73749af3e625674dcb/include/CMakeLists.txt#L4

Hence the ""system installed"" version of JsonCPP is not usable with TensorFlow

Possible solution: Do NOT symlink the headers but rely on CPATH being set correctly "
42265,x,x
42264,"Using system NASM results in ""cycle in dependency graph"" error","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.x (all from 2.0 to 2.3)
- Bazel version (if compiling from source): 0.29.1


**Describe the problem**

Using system NASM makes the build error with:
```
ERROR: /tmp/easybuild-tmp/eb-K85jaZ/tmpnpNkyO-bazel-build/external/nasm/BUILD.bazel:8:1: in sh_binary rule @nasm//:nasm: cycle in dependency graph:
    //tensorflow/tools/pip_package:build_pip_package
    //tensorflow/tools/pip_package:simple_console
    //tensorflow:tensorflow_py
    //tensorflow:tensorflow_py_no_contrib
    //tensorflow:tf_python_api_gen_v2
    //tensorflow:create_tensorflow.python_api_2_tf_python_api_gen_v2
    //tensorflow/python:no_contrib
    //tensorflow/python:control_flow_ops
    //tensorflow/python:platform
    //tensorflow/python:_pywrap_util_port
    //tensorflow/python:_pywrap_util_port.so
    //tensorflow/python:_pywrap_tensorflow_internal_linux
    //tensorflow/python:lib_pywrap_tensorflow_internal.so
    //tensorflow/python:lib_pywrap_tensorflow_internal.so_rule
    //tensorflow/python:_pywrap_tensorflow_internal.so
    //tensorflow/python:py_record_writer_lib
    //tensorflow/c:tf_status_helper
    //tensorflow/core:lib
    //tensorflow/core:lib_internal
    //tensorflow/core/platform/default/build_config:platformlib
    //tensorflow/core/platform/default/build_config:jpeg
    @libjpeg_turbo//:jpeg
    @libjpeg_turbo//:simd_x86_64
    @libjpeg_turbo//:simd/x86_64/jsimdcpu.o
    @libjpeg_turbo//:simd_x86_64_assemblage23
.-> @nasm//:nasm [self-edge]
`--
This cycle occurred because of a configuration option
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Set `TF_SYSTEM_LIBS=nasm` before building as instructed

**Any other info / logs**

The problem is an erroneous build script: https://github.com/tensorflow/tensorflow/blob/3ae4ccf38c9731343bd7a39db7bac8067335646a/third_party/nasm/BUILD.system#L10

This sets the `name` and `src` to ""nasm"" which is forbidden: https://docs.bazel.build/versions/master/be/shell.html

> do not give the rule and the file the same name. 
"
42263,"Custom TF metric: ""Graph"" tensor leakage","System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.2
Python version: 3.6.9
CUDA/cuDNN version: v10.2
GPU model and memory: GeForce GTX 1070 - 8117MiB

Describe the current behavior:
My custom metric works on sample inputs; yet after model compilation breaks down due to an error related to eager and graph tensors. I did not find anything specific which helps me resolve the issue.

Issue: 
```An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: Max:0
```

Describe the expected behavior:
Custom metric is usable as a metric in a TF2 model, logging to tensorboard as well.  

Standalone code to reproduce the issue
https://colab.research.google.com/drive/1FPGz3dK2zSI2wjuTYrywaUG0UlHnej6c?usp=sharing 
"
42262,has no attr named '_XlaCompile',"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
42260,ValueError: Unknown activation: ELU,"
from keras.models import load_model
model = load_model('discriminator_model_800.h5')

above got  this error ValueError: Unknown activation: ELU"
42259,Helloworld example on esp32 not working,"@tensorflow/micro


After building andd flashing the helloworld example for esp32. esp32 keeps on rebooting with the reason as mofying a null pointer


Logs From esp-32:

rst:0x1 (POWERON_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)
configsip: 0, SPIWP:0xee
clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00
mode:DIO, clock div:2
load:0x3fff0018,len:4
load:0x3fff001c,len:6864
ho 0 tail 12 room 4
load:0x40078000,len:14076
load:0x40080400,len:4304
entry 0x400806e8
I (74) boot: Chip Revision: 1
I (74) boot_comm: chip revision: 1, min. bootloader chip revision: 0
I (41) boot: ESP-IDF v4.0.1-dirty 2nd stage bootloader
I (41) boot: compile time 20:11:51
I (41) boot: Enabling RNG early entropy source...
I (46) boot: SPI Speed      : 40MHz
I (50) boot: SPI Mode       : DIO
I (54) boot: SPI Flash Size : 4MB
I (58) boot: Partition Table:
I (62) boot: ## Label            Usage          Type ST Offset   Length
I (69) boot:  0 nvs              WiFi data        01 02 00009000 00006000
I (76) boot:  1 phy_init         RF data          01 01 0000f000 00001000
I (84) boot:  2 factory          factory app      00 00 00010000 00100000
I (91) boot: End of partition table
I (96) boot_comm: chip revision: 1, min. application chip revision: 0
I (103) esp_image: segment 0: paddr=0x00010020 vaddr=0x3f400020 size=0x09cb0 ( 40112) map
I (126) esp_image: segment 1: paddr=0x00019cd8 vaddr=0x3ffb0000 size=0x020f0 (  8432) load
I (130) esp_image: segment 2: paddr=0x0001bdd0 vaddr=0x40080000 size=0x00400 (  1024) load
0x40080000: _WindowOverflow4 at I:/Resources/esp-idf/components/freertos/xtensa_vectors.S:1778

I (133) esp_image: segment 3: paddr=0x0001c1d8 vaddr=0x40080400 size=0x03e38 ( 15928) load
I (148) esp_image: segment 4: paddr=0x00020018 vaddr=0x400d0018 size=0x4f054 (323668) map
0x400d0018: _stext at ??:?

I (266) esp_image: segment 5: paddr=0x0006f074 vaddr=0x40084238 size=0x059a4 ( 22948) load
0x40084238: memspi_host_read_status_hs at I:/Resources/esp-idf/components/spi_flash/memspi_host_driver.c:67

I (283) boot: Loaded app from partition at offset 0x10000
I (283) boot: Disabling RNG early entropy source...
I (283) cpu_start: Pro cpu up.
I (287) cpu_start: Application information:
I (292) cpu_start: Project name:     slick-AIoT
I (297) cpu_start: App version:      1
I (301) cpu_start: Compile time:     Aug  1 2020 20:11:33
I (307) cpu_start: ELF file SHA256:  4e8a9f0ccd7e777b...
I (313) cpu_start: ESP-IDF:          v4.0.1-dirty
I (319) cpu_start: Starting app cpu, entry point is 0x40081128
0x40081128: call_start_cpu1 at I:/Resources/esp-idf/components/esp32/cpu_start.c:271

I (0) cpu_start: App cpu up.
I (329) heap_init: Initializing. RAM available for dynamic allocation:
I (336) heap_init: At 3FFAE6E0 len 00001920 (6 KiB): DRAM
I (342) heap_init: At 3FFB5210 len 0002ADF0 (171 KiB): DRAM
I (348) heap_init: At 3FFE0440 len 00003AE0 (14 KiB): D/IRAM
I (355) heap_init: At 3FFE4350 len 0001BCB0 (111 KiB): D/IRAM
I (361) heap_init: At 40089BDC len 00016424 (89 KiB): IRAM
I (367) cpu_start: Pro cpu start user code
I (385) spi_flash: detected chip: generic
I (386) spi_flash: flash io: dio
I (386) cpu_start: Starting scheduler on PRO CPU.
I (0) cpu_start: Starting scheduler on APP CPU.
intrptr before 0, value :1073434788

intrptr after 1073426328, value :1073434788

Guru Meditation Error: Core  0 panic'ed (StoreProhibited). Exception was unhandled.
Core 0 register dump:
PC      : 0x400d45e0  PS      : 0x00060630  A0      : 0x800d459d  A1      : 0x3ffb6ff0  
0x400d45e0: loop at i:\slick-aiot\esp32\build/../main/main_functions.cc:103

A2      : 0x00000000  A3      : 0x00000014  A4      : 0x40c90fdb  A5      : 0x00000000  
A6      : 0x3ffaffe0  A7      : 0x3ffb8980  A8      : 0x00000000  A9      : 0x3ffb6fe0  
A10     : 0x00000000  A11     : 0x41a00000  A12     : 0x00000008  A13     : 0x00000005  
A14     : 0x00000005  A15     : 0x0000000c  SAR     : 0x00000001  EXCCAUSE: 0x0000001d  
EXCVADDR: 0x00000000  LBEG    : 0x4010ba41  LEND    : 0x4010ba48  LCOUNT  : 0x00000000  
0x4010ba41: tflite::BytesRequiredForTensor(tflite::Tensor const&, unsigned int*, unsigned int*, tflite::ErrorReporter*) at i:\slick-aiot\esp32\build/../components/tfmicro/tensorflow/lite/micro/memory_helpers.cc:92

0x4010ba48: tflite::BytesRequiredForTensor(tflite::Tensor const&, unsigned int*, unsigned int*, tflite::ErrorReporter*) at i:\slick-aiot\esp32\build/../components/tfmicro/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:2431
 (inlined by) ?? at i:\slick-aiot\esp32\build/../components/tfmicro/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:2435
 (inlined by) ?? at i:\slick-aiot\esp32\build/../components/tfmicro/tensorflow/lite/schema/schema_generated.h:3612
 (inlined by) tflite::BytesRequiredForTensor(tflite::Tensor const&, unsigned int*, unsigned int*, tflite::ErrorReporter*) at i:\slick-aiot\esp32\build/../components/tfmicro/tensorflow/lite/micro/memory_helpers.cc:97


ELF file SHA256: 4e8a9f0ccd7e777b

Backtrace: 0x400d45dd:0x3ffb6ff0 0x400d459a:0x3ffb7010 0x400d14ca:0x3ffb7030 0x40087281:0x3ffb7050
0x400d45dd: loop at i:\slick-aiot\esp32\build/../main/main_functions.cc:103

0x400d459a: app_main at i:\slick-aiot\esp32\build/../main/esp/main.cc:21 (discriminator 1)

0x400d14ca: main_task at I:/Resources/esp-idf/components/esp32/cpu_start.c:553

0x40087281: vPortTaskWrapper at I:/Resources/esp-idf/components/freertos/port.c:143


Rebooting...
ets Jun  8 2016 00:22:57

rst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)
configsip: 0, SPIWP:0xee
clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00
mode:DIO, clock div:2
load:0x3fff0018,len:4
load:0x3fff001c,len:6864
ho 0 tail 12 room 4
load:0x40078000,len:14076
load:0x40080400,len:4304
entry 0x400806e8
I (75) boot: Chip Revision: 1
I (75) boot_comm: chip revision: 1, min. bootloader chip revision: 0
I (41) boot: ESP-IDF v4.0.1-dirty 2nd stage bootloader
I (41) boot: compile time 20:11:51
I (41) boot: Enabling RNG early entropy source...
I (47) boot: SPI Speed      : 40MHz
I (51) boot: SPI Mode       : DIO
I (55) boot: SPI Flash Size : 4MB
I (59) boot: Partition Table:
I (62) boot: ## Label            Usage          Type ST Offset   Length
I (70) boot:  0 nvs              WiFi data        01 02 00009000 00006000
I (77) boot:  1 phy_init         RF data          01 01 0000f000 00001000
I (85) boot:  2 factory          factory app      00 00 00010000 00100000
I (92) boot: End of partition table
I (96) boot_comm: chip revision: 1, min. application chip revision: 0
I (103) esp_image: segment 0: paddr=0x00010020 vaddr=0x3f400020 size=0x09cb0 ( 40112) map
I (127) esp_image: segment 1: paddr=0x00019cd8 vaddr=0x3ffb0000 size=0x020f0 (  8432) load
I (130) esp_image: segment 2: paddr=0x0001bdd0 vaddr=0x40080000 size=0x00400 (  1024) load
0x40080000: _WindowOverflow4 at I:/Resources/esp-idf/components/freertos/xtensa_vectors.S:1778

I (134) esp_image: segment 3: paddr=0x0001c1d8 vaddr=0x40080400 size=0x03e38 ( 15928) load
I (149) esp_image: segment 4: paddr=0x00020018 vaddr=0x400d0018 size=0x4f054 (323668) map
0x400d0018: _stext at ??:?

I (267) esp_image: segment 5: paddr=0x0006f074 vaddr=0x40084238 size=0x059a4 ( 22948) load
0x40084238: memspi_host_read_status_hs at I:/Resources/esp-idf/components/spi_flash/memspi_host_driver.c:67

I (283) boot: Loaded app from partition at offset 0x10000
I (283) boot: Disabling RNG early entropy source...
I (284) cpu_start: Pro cpu up.
I (287) cpu_start: Application information:
I (292) cpu_start: Project name:     slick-AIoT
I (297) cpu_start: App version:      1
I (302) cpu_start: Compile time:     Aug  1 2020 20:11:33
I (308) cpu_start: ELF file SHA256:  4e8a9f0ccd7e777b...
I (314) cpu_start: ESP-IDF:          v4.0.1-dirty
I (319) cpu_start: Starting app cpu, entry point is 0x40081128
0x40081128: call_start_cpu1 at I:/Resources/esp-idf/components/esp32/cpu_start.c:271

I (305) cpu_start: App cpu up.
I (330) heap_init: Initializing. RAM available for dynamic allocation:
I (337) heap_init: At 3FFAE6E0 len 00001920 (6 KiB): DRAM
I (343) heap_init: At 3FFB5210 len 0002ADF0 (171 KiB): DRAM
I (349) heap_init: At 3FFE0440 len 00003AE0 (14 KiB): D/IRAM
I (355) heap_init: At 3FFE4350 len 0001BCB0 (111 KiB): D/IRAM
I (362) heap_init: At 40089BDC len 00016424 (89 KiB): IRAM
I (368) cpu_start: Pro cpu start user code
I (386) spi_flash: detected chip: generic
I (387) spi_flash: flash io: dio
I (387) cpu_start: Starting scheduler on PRO CPU.
I (0) cpu_start: Starting scheduler on APP CPU.
intrptr before 0, value :1073434788

intrptr after 1073426328, value :1073434788

Guru Meditation Error: Core  0 panic'ed (StoreProhibited). Exception was unhandled.
Core 0 register dump:
PC      : 0x400d45e0  PS      : 0x00060630  A0      : 0x800d459d  A1      : 0x3ffb6ff0  
0x400d45e0: loop at i:\slick-aiot\esp32\build/../main/main_functions.cc:103

A2      : 0x00000000  A3      : 0x00000014  A4      : 0x40c90fdb  A5      : 0x00000000  
A6      : 0x3ffaffe0  A7      : 0x3ffb8980  A8      : 0x00000000  A9      : 0x3ffb6fe0  
A10     : 0x00000000  A11     : 0x41a00000  A12     : 0x00000008  A13     : 0x00000005  
A14     : 0x00000005  A15     : 0x0000000c  SAR     : 0x00000001  EXCCAUSE: 0x0000001d  
EXCVADDR: 0x00000000  LBEG    : 0x4010ba41  LEND    : 0x4010ba48  LCOUNT  : 0x00000000  
0x4010ba41: tflite::BytesRequiredForTensor(tflite::Tensor const&, unsigned int*, unsigned int*, tflite::ErrorReporter*) at i:\slick-aiot\esp32\build/../components/tfmicro/tensorflow/lite/micro/memory_helpers.cc:92

0x4010ba48: tflite::BytesRequiredForTensor(tflite::Tensor const&, unsigned int*, unsigned int*, tflite::ErrorReporter*) at i:\slick-aiot\esp32\build/../components/tfmicro/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:2431
 (inlined by) ?? at i:\slick-aiot\esp32\build/../components/tfmicro/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:2435
 (inlined by) ?? at i:\slick-aiot\esp32\build/../components/tfmicro/tensorflow/lite/schema/schema_generated.h:3612
 (inlined by) tflite::BytesRequiredForTensor(tflite::Tensor const&, unsigned int*, unsigned int*, tflite::ErrorReporter*) at i:\slick-aiot\esp32\build/../components/tfmicro/tensorflow/lite/micro/memory_helpers.cc:97


ELF file SHA256: 4e8a9f0ccd7e777b

Backtrace: 0x400d45dd:0x3ffb6ff0 0x400d459a:0x3ffb7010 0x400d14ca:0x3ffb7030 0x40087281:0x3ffb7050
0x400d45dd: loop at i:\slick-aiot\esp32\build/../main/main_functions.cc:103

0x400d459a: app_main at i:\slick-aiot\esp32\build/../main/esp/main.cc:21 (discriminator 1)

0x400d14ca: main_task at I:/Resources/esp-idf/components/esp32/cpu_start.c:553

0x40087281: vPortTaskWrapper at I:/Resources/esp-idf/components/freertos/port.c:143

"
42258,Unable to build tflite aar file on windows,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): tensorflow github repo
- TensorFlow version: 2.0
- Python version: 3.6.0
- Installed using virtualenv? pip? conda?: NA
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): MSVC 2017
- CUDA/cuDNN version: NA
- GPU model and memory: NA



**Describe the problem**
I am unable to build the tflite aar files using this build command: 
 bazel build //tensorflow/lite/java:tensorflow-lite --cxxopt=--std=c++14 -c opt --fat_apk_cpu=armeabi-v7a  --verbose_failures 

This warning pops up a lot of times
cl : Command line warning D9002 : ignoring unknown option '--std=c++14'
And I get this error in the end 
Exception in thread ""main"" java.nio.file.InvalidPathException: Illegal character [:] in path at index 4: ///C:/Users/nikhil/AppData/Local/Temp/android_resources_tmp11744088656958341427/linked/bin.-pb.apk


"
42257,Resource exhausted error during training on GPU with tensorflow 2.1.0,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom code, but nothing really fancy
- TensorFlow installed from (source or binary): conda installed from source
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- CUDA/cuDNN version: CUDA 10.1
- GPU model and memory:  Quadro M1200. 8GB RAM

**Describe the current behavior**
I get an ResourceExhaustedError during my training. Even if I have a batch size of one. I have to predict and fit my data seperately, because in between I have to create a return function based on my predictions, which is input for the model.fit(). When I train my model, it starts with 4000 MB free memory in the GPU, after initialization it goes to 2022 MB free memory. It stays like this till 92 epochs, after 92 epochs it goes to 949 MB free memory. After 186 epochs it goes to 730 MB free memory in the GPU and after 197 epochs I get the error: 

ResourceExhaustedError:  OOM when allocating tensor with shape[108,32,103,66] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node MaxPoolGrad_2 (defined at C:\Users\Floor\Documents\Basic model\testmap\test.py:233) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
 [Op:__inference_distributed_function_3945]


**Standalone code to reproduce the issue**
import tensorflow as tf
tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)
import numpy as np
import sys
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten,MaxPooling2D

def create_model(): 
   
    model = Sequential()
    model.add(Conv2D(32, (6, 6), input_shape=( 108, 71, 9)))
    model.add(Activation(""relu""))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(32, (6, 6)))
    model.add(Activation(""relu""))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(32, (6, 6)))
    model.add(Activation(""relu""))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Flatten())
    model.add(Dense(256, activation='relu'))
    model.add(Dense(1, activation = ""sigmoid""))

    model.compile(optimizer=Adam(lr=0.00001/10), loss='mean_squared_error')  
    return(model)
For i in range(N) #amount of epochs
    model.predict(EpisodesP.reshape([-1,img_w, img_h, dim]))

    #Return function G 

    model.fit(EpisodesP, G, epochs = 1, verbose = 0, batch_size=1)

**Other info / logs** 
raceback (most recent call last):

  File ""C:\Users\Floor\Documents\Basic model\testmap\test.py"", line 267, in <module>
    history,value,model,loss, loss_episode= basic_code(Episodes, Success, N = 1000, P = 1)

  File ""C:\Users\Floor\Documents\Basic model\testmap\test.py"", line 233, in basic_code
    model.fit(EpisodesP, GP, epochs = 1, verbose = 0, batch_size=sum(TP)) #model fitted to get the loss

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 342, in fit
    total_epochs=epochs)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 599, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py"", line 2363, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1611, in _filtered_call
    self.captured_inputs)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py"", line 545, in call
    ctx=ctx)

  File ""C:\Users\Floor\anaconda3\lib\site-packages\tensorflow_core\python\eager\execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)

  File ""<string>"", line 3, in raise_from

ResourceExhaustedError:  OOM when allocating tensor with shape[108,32,103,66] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node MaxPoolGrad_2 (defined at C:\Users\Floor\Documents\Basic model\testmap\test.py:233) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
 [Op:__inference_distributed_function_3945]

Function call stack:
distributed_function
"
42256,How to avoid AddV2 op in TFLite model?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 18.04`
- TensorFlow installed from (source or binary): `pip/binary`
- TensorFlow version (or github SHA if from source):
`2.3.0`
`tflite 2.3.0 aar`

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf                                                 
if not tf.__version__.startswith('1'):                                  
    import tensorflow.compat.v1 as tf                                   
tf.disable_v2_behavior()                                                
# Path to the frozen graph file                                         
graph_def_file = 'weights/yolov5s.pb'                                   
# A list of the names of the model's input tensors                      
input_arrays = ['images']                                               
# A list of the names of the model's output tensors                     
output_arrays = ['Concat_442']                                          
# Load and convert the frozen graph                                     
converter = tf.lite.TFLiteConverter.from_frozen_graph(                  
    graph_def_file, input_arrays, output_arrays)                        
# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
#                                        tf.lite.OpsSet.SELECT_TF_OPS]  
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]
converter.allow_custom_ops = True                                     
# converter.experimental_new_converter = False                            
tflite_model = converter.convert()                                      
# Write the converted model to disk                                     
open(""weights/yolov5s.tflite"", ""wb"").write(tflite_model)                
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
I try to convert a Tensorflow GraphDef model to TFLite model, and I want to void AddV2 op.
If I use `tf.lite.OpsSet.SELECT_TF_OPS` option, FlexAddV2 will be generated instead of AddV2, which I would like to avoid too.
AddV2 is unsupported in tflite 2.3.0 aar.
FlexAddV2 is supported by flex delegate, but cannot work on Android Emulator (Pixel 2 API 24) .

The last thing I tried is substituting 'AddV2' with 'Add' manually in pbtxt format (AddV2 is in the original GraphDef ).
After I convert the processed GraphDef with tflite converter, the 'AddV2' ops emerge again.

PS:
https://github.com/tensorflow/tensorflow/issues/33393 says that TensorFlow 1.15 can resolve this problem.


"
42255,Seg fault after installing version 2.3.0,"I test my tensorflow by using the official guide:
`python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""`

It crashed with the info below:
```
2020-08-12 15:48:11.443235: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-12 15:48:11.443280: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

2020-08-12 15:48:13.930797: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-12 15:48:13.930842: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-12 15:48:13.930871: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c4-miui-sec-preview0.bj): /proc/driver/nvidia/version does not exist
2020-08-12 15:48:13.931321: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-12 15:48:13.946009: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2399965000 Hz
2020-08-12 15:48:13.949467: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x59646e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-12 15:48:13.949501: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
tf.Tensor(-19.847946, shape=(), dtype=float32)
段错误
```
**段错误 means  seg fault**
I also test with my own code in Python and it also crashed randomly. 

Python Ver: 3.6.5






"
42254,tf.signal.stft throws RuntimeException when pad_end=True,"**System information**
- OS Platform and Distribution: Ubuntu 16.04
- TensorFlow installed from: binary
- TensorFlow version: v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.8 (Conda)

**Describe the current behavior**

`pad_end` of `tf.signal.stft` throws `RuntimeError` when set to `True`.

**Describe the expected behavior**

Should not throw a `RuntimeException` - just pad the end of the signal.

**Standalone code to reproduce the issue**

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np


def main():
    inputs = layers.Input(shape=(None,))
    x = tf.signal.stft(inputs, 512, 20, pad_end=True)
    model = keras.Model(inputs=inputs, outputs=x)
    signals = tf.constant(np.random.rand(2, 511))
    print(model(signals))
    print('All done.')


if __name__ == '__main__':
    main()
```

**Other info / logs** 

```none
Traceback (most recent call last):
  File ""/home/sfalk/tmp/speech-v2/asr/bin/tmp.py"", line 17, in <module>
    main()
  File ""/home/sfalk/tmp/speech-v2/asr/bin/tmp.py"", line 9, in main
    x = tf.signal.stft(inputs, 512, 20, pad_end=True)
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py"", line 201, in wrapper
    return target(*args, **kwargs)
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/signal/spectral_ops.py"", line 86, in stft
    framed_signals = shape_ops.frame(
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py"", line 201, in wrapper
    return target(*args, **kwargs)
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/signal/shape_ops.py"", line 162, in frame
    paddings = array_ops.concat(
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py"", line 201, in wrapper
    return target(*args, **kwargs)
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py"", line 1654, in concat
    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1221, in concat_v2
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py"", line 409, in _apply_op_helper
    values = ops.internal_convert_n_to_tensor(
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 1561, in internal_convert_n_to_tensor
    convert_to_tensor(
  File ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 1465, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.

Process finished with exit code 1
```

### Workaround

Do the padding yourself:

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np


def main():
    frame_length = 512
    inputs = layers.Input(shape=(None,))
    x = inputs

    pad = frame_length - tf.math.mod(tf.shape(x)[1], frame_length)
    x = tf.pad(x, [(0, 0), (0, pad)])
    x = tf.signal.stft(x, 512, 20, pad_end=False)

    model = keras.Model(inputs=inputs, outputs=x)
    signals = tf.constant(np.random.rand(2, 511))
    print(model(signals))
    print('All done.')


if __name__ == '__main__':
    main()
```"
42253,Dose quantization aware training support tf.GradientTape() training?,"I'm using **tensorflow-gpu==2.3.0**, and I run below code for quantization aware training, seems that using tf.GradientTape() do nothing when run quantization aware training. Here is useful code which is tensorflow example [code](https://www.tensorflow.org/model_optimization/guide/quantization/training_example):
```
import os
import tensorflow as tf
from tensorflow import keras
import numpy as np

# Load MNIST dataset
# Mine network to download this is too slow, so I download it handly. You can also use this command line:

# mnist = keras.datasets.mnist
# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()

def load_mnist(path):
    with np.load(path, allow_pickle=True) as f:
        x_train, y_train = f['x_train'], f['y_train']
        x_test, y_test = f['x_test'], f['y_test']

        return (x_train, y_train), (x_test, y_test)
(train_images, train_labels), (test_images, test_labels) = load_mnist(path='mnist.npz')

# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images / 255.0
test_images = test_images / 255.0

# Define the model architecture.
model = keras.Sequential([
  keras.layers.InputLayer(input_shape=(28, 28)),
  keras.layers.Reshape(target_shape=(28, 28, 1)),
  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),
  keras.layers.MaxPooling2D(pool_size=(2, 2)),
  keras.layers.Flatten(),
  keras.layers.Dense(10)
])

# Train the digit classification model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(
  train_images,
  train_labels,
  epochs=1,
  validation_split=0.1,
)

import tensorflow_model_optimization as tfmot

quantize_model = tfmot.quantization.keras.quantize_model

# q_aware stands for for quantization aware.
q_aware_model = quantize_model(model)

# `quantize_model` requires a recompile.
q_aware_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

q_aware_model.summary()
train_images_subset = train_images[0:1000] # out of 60000
train_labels_subset = train_labels[0:1000]
q_aware_model.fit(train_images_subset, train_labels_subset,
                  batch_size=500, epochs=1, validation_split=0.1)
_, baseline_model_accuracy = model.evaluate(
    test_images, test_labels, verbose=0)

_, q_aware_model_accuracy = q_aware_model.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Quant test accuracy:', q_aware_model_accuracy)
```
which you will get this output finally:
```
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
quantize_layer (QuantizeLaye (None, 28, 28)            3         
_________________________________________________________________
quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         
_________________________________________________________________
quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       
_________________________________________________________________
quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         
_________________________________________________________________
quant_flatten (QuantizeWrapp (None, 2028)              1         
_________________________________________________________________
quant_dense (QuantizeWrapper (None, 10)                20295     
=================================================================
Total params: 20,448
Trainable params: 20,410
Non-trainable params: 38
_________________________________________________________________
2/2 [==============================] - 0s 98ms/step - loss: 0.1444 - accuracy: 0.9589 - val_loss: 0.1748 - val_accuracy: 0.9800
Baseline test accuracy: 0.9613000154495239
Quant test accuracy: 0.961899995803833
```

If using tf.GradientTape() for quant-aware-training (using same `model` trained before):
```
# q_aware stands for for quantization aware.
q_aware_model2 = quantize_model(model)

# `quantize_model` requires a recompile.
q_aware_model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

q_aware_model2.summary()

batch_size = 500
train_dataset = tf.data.Dataset.from_tensor_slices((train_images_subset, train_labels_subset))
train_dataset = train_dataset.batch(batch_size=batch_size, drop_remainder=False)

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optimizer = tf.keras.optimizers.Adam()

for epoch in range(1):
    for x, y in train_dataset:
        with tf.GradientTape() as tape:
            preds = q_aware_model2(x)
            loss = loss_fn(y, preds)
        grads = tape.gradient(loss, q_aware_model2.trainable_variables)
        optimizer.apply_gradients(zip(grads, q_aware_model2.trainable_variables))
        
_, baseline_model_accuracy = model.evaluate(
    test_images, test_labels, verbose=0)

_, q_aware_model_accuracy = q_aware_model2.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Quant test accuracy:', q_aware_model_accuracy)
```
you will get output like this:
```
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
quantize_layer_5 (QuantizeLa (None, 28, 28)            3         
_________________________________________________________________
quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         
_________________________________________________________________
quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       
_________________________________________________________________
quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         
_________________________________________________________________
quant_flatten (QuantizeWrapp (None, 2028)              1         
_________________________________________________________________
quant_dense (QuantizeWrapper (None, 10)                20295     
=================================================================
Total params: 20,448
Trainable params: 20,410
Non-trainable params: 38
_________________________________________________________________
Baseline test accuracy: 0.9613000154495239
Quant test accuracy: 0.11349999904632568
```
And the `q_aware_model2` results is soo smaller than `q_aware_model` results. By the way, the  `q_aware_model2` results is as same as when you did not do `tf.GradientTape()` training:
```
# q_aware stands for for quantization aware.
q_aware_model2 = quantize_model(model)

# `quantize_model` requires a recompile.
q_aware_model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

q_aware_model2.summary()

batch_size = 500
train_dataset = tf.data.Dataset.from_tensor_slices((train_images_subset, train_labels_subset))
train_dataset = train_dataset.batch(batch_size=batch_size, drop_remainder=False)

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optimizer = tf.keras.optimizers.Adam()

# for epoch in range(1):
#     for x, y in train_dataset:
#         with tf.GradientTape() as tape:
#             preds = q_aware_model2(x)
#             loss = loss_fn(y, preds)
#         grads = tape.gradient(loss, q_aware_model2.trainable_variables)
#         optimizer.apply_gradients(zip(grads, q_aware_model2.trainable_variables))
        
_, baseline_model_accuracy = model.evaluate(
    test_images, test_labels, verbose=0)

_, q_aware_model_accuracy = q_aware_model2.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Quant test accuracy:', q_aware_model_accuracy)
```
You will get same output as using `tf.GradientTape()` training. Seems like `tf.GradientTape()` do nothing when `quantization-aware-training`:
```
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
quantize_layer_6 (QuantizeLa (None, 28, 28)            3         
_________________________________________________________________
quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         
_________________________________________________________________
quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       
_________________________________________________________________
quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         
_________________________________________________________________
quant_flatten (QuantizeWrapp (None, 2028)              1         
_________________________________________________________________
quant_dense (QuantizeWrapper (None, 10)                20295     
=================================================================
Total params: 20,448
Trainable params: 20,410
Non-trainable params: 38
_________________________________________________________________
Baseline test accuracy: 0.9613000154495239
Quant test accuracy: 0.11349999904632568
```"
42252,There is memory leak in Invoke() of gpu delegate (OpenCL) in Tensorflow lite v2.3.0,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android armv8
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): tag v2.3.0
- Python version:
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source):  android-ndk-r18b
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I use tflite with delegate creating by TfLiteGpuDelegateV2Create(&options), and call ModifyGraphWithDelegate and AllocateTensors, and when I call interpreter->Invoke() in a loop, I see the memory increasing continuously.
**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

std::unique_ptr<tflite::FlatBufferModel> model;
tflite::ops::builtin::BuiltinOpResolver op_resolver;
std::unique_ptr<tflite::Interpreter> interpreter;
TfLiteDelegate* delegate = nullptr;

        struct : public tflite::ErrorReporter {
            virtual int Report(const char *format, va_list args) {
                return __android_log_vprint(ANDROID_LOG_INFO, ""native_jni"", format, args);
            }
        } er;
        model = tflite::FlatBufferModel::BuildFromFile(
                ""/storage/emulated/0/Android/data/com.example.myapplication2/files/model.tflite"",
                &er);
        if (!model) {
            LOG(""build model error"");
            return;
        } else {
            LOG(""build model success:%p"", model.get());
        }
        tflite::InterpreterBuilder(*model, op_resolver)(&interpreter);

        TfLiteGpuDelegateOptionsV2 options = TfLiteGpuDelegateOptionsV2Default();
        options.is_precision_loss_allowed = 1;
        options.inference_preference = TFLITE_GPU_INFERENCE_PREFERENCE_SUSTAINED_SPEED;
        options.inference_priority1 = TFLITE_GPU_INFERENCE_PRIORITY_MIN_LATENCY;
        options.inference_priority2 = TFLITE_GPU_INFERENCE_PRIORITY_AUTO;
        options.inference_priority3 = TFLITE_GPU_INFERENCE_PRIORITY_AUTO;
        options.experimental_flags = TFLITE_GPU_EXPERIMENTAL_FLAGS_CL_ONLY;
        options.max_delegated_partitions = 1;
        delegate = TfLiteGpuDelegateV2Create(&options);

        if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) {
            __android_log_print(ANDROID_LOG_INFO, ""native_jni"", ""ModifyGraphWithDelegate error"");
            return;
        }
        __android_log_print(ANDROID_LOG_INFO, ""native_jni"", ""ModifyGraphWithDelegate success"");
        if (interpreter->AllocateTensors() == kTfLiteOk) {
            __android_log_print(ANDROID_LOG_INFO, ""native_jni"", ""allocate success"");
        } else {
            __android_log_print(ANDROID_LOG_INFO, ""native_jni"", ""allocate error"");
        }
        while (true)
            interpreter->Invoke();

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I suspect that the bug is something about using opencl. In  CLCommandQueue::DispatchImplicit (tensorflow/lite/delegates/gpu/cl/cl_command_queue.cc)，if I comment the code calling clEnqueueNDRangeKernel, the memory leak disappears.

"
42251,[Toco]freeze Min Max information by Post-Quantization,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): tf1.14


**Command used to run the converter or code if you’re using the Python API**


```
usage: tensorflow/bazel-bin/tensorflow/lite/toco/toco
Flags:
	--input_array=""""                 	string	Deprecated: use --input_arrays instead. Name of the input array. If not specified, will try to read that information from the input file.
	--input_arrays=""""                	string	Names of the input arrays, comma-separated. If not specified, will try to read that information from the input file.
	--output_array=""""                	string	Deprecated: use --output_arrays instead. Name of the output array, when specifying a unique output array. If not specified, will try to read that information from the input file.
	--output_arrays=""""               	string	Names of the output arrays, comma-separated. If not specified, will try to read that information from the input file.
	--input_shape=""""                 	string	Deprecated: use --input_shapes instead. Input array shape. For many models the shape takes the form batch size, input array height, input array width, input array depth.
	--input_shapes=""""                	string	Shapes corresponding to --input_arrays, colon-separated. For many models each shape takes the form batch size, input array height, input array width, input array depth.
	--batch_size=1                   	int32	Deprecated. Batch size for the model. Replaces the first dimension of an input size array if undefined. Use only with SavedModels when --input_shapes flag is not specified. Always use --input_shapes flag with frozen graphs.
	--input_data_type=""""             	string	Deprecated: use --input_data_types instead. Input array type, if not already provided in the graph. Typically needs to be specified when passing arbitrary arrays to --input_arrays.
	--input_data_types=""""            	string	Input arrays types, comma-separated, if not already provided in the graph. Typically needs to be specified when passing arbitrary arrays to --input_arrays.
	--mean_value=0.000000            	float	Deprecated: use --mean_values instead. mean_value parameter for image models, used to compute input activations from input pixel data.
	--mean_values=""""                 	string	mean_values parameter for image models, comma-separated list of doubles, used to compute input activations from input pixel data. Each entry in the list should match an entry in --input_arrays.
	--std_value=1.000000             	float	Deprecated: use --std_values instead. std_value parameter for image models, used to compute input activations from input pixel data.
	--std_values=""""                  	string	std_value parameter for image models, comma-separated list of doubles, used to compute input activations from input pixel data. Each entry in the list should match an entry in --input_arrays.
	--variable_batch=false           	bool	If true, the model accepts an arbitrary batch size. Mutually exclusive with the 'batch' field: at most one of these two fields can be set.
	--rnn_states=""""                  	string	
	--model_checks=""""                	string	A list of model checks to be applied to verify the form of the model.  Applied after the graph transformations after import.
	--dump_graphviz=""""               	string	Dump graphviz during LogDump call. If string is non-empty then it defines path to dump, otherwise will skip dumping.
	--dump_graphviz_video=false      	bool	If true, will dump graphviz at each graph transformation, which may be used to generate a video.
	--allow_nonexistent_arrays=false 	bool	If true, will allow passing inexistent arrays in --input_arrays and --output_arrays. This makes little sense, is only useful to more easily get graph visualizations.
	--allow_nonascii_arrays=false    	bool	If true, will allow passing non-ascii-printable characters in --input_arrays and --output_arrays. By default (if false), only ascii printable characters are allowed, i.e. character codes ranging from 32 to 127. This is disallowed by default so as to catch common copy-and-paste issues where invisible unicode characters are unwittingly added to these strings.
	--arrays_extra_info_file=""""      	string	Path to an optional file containing a serialized ArraysExtraInfo proto allowing to pass extra information about arrays not specified in the input model file, such as extra MinMax information.
	--model_flags_file=""""            	string	Path to an optional file containing a serialized ModelFlags proto. Options specified on the command line will override the values in the proto.
	--change_concat_input_ranges=true	bool	Boolean to change the behavior of min/max ranges for inputs and output of the concat operators.
```

**TODO**

I try to use toco to freeze MinMax information into my model, but the default_ranges decrease the accuracy of model.
```
	--default_ranges_min=0.000000    	
	--default_ranges_max=6.000000 
```
How to create a file for (--arrays_extra_info_file="""") so that  can set the Min Max information in the process.
"
42250,What means 'the resulting model is quantization aware but not quantized',"Can anybody explain me what means 'the resulting model is quantization aware but not quantized' on [tutorial](https://www.tensorflow.org/model_optimization/guide/quantization/training_example?hl=en)
Is there no way to use Quantization-Aware-Training without tflite?

Thank you."
42249,RuntimeError: tensorflow/lite/kernels/conv.cc:316 input->dims->data[3] != filter->dims->data[3] (4 != 3)Node number 1 (CONV_2D) failed to prepare.,"ubuntu18.04
tf-nightly-gpu : '2.4.0-dev20200811'
numpy  :  1.18.3

I follow the official website to convert the file (https://www.tensorflow.org/lite/performance/post_training_integer_quant)
The first step is to convert .h5 files to tflite files(success!!),but When performing integer quantization This error occurred：

[RuntimeError: tensorflow/lite/kernels/conv.cc:316 input->dims->data[3] != filter->dims->data[3] (4 != 3)Node number 1 (CONV_2D) failed to prepare.]

My model:
[hdf5.zip](https://github.com/tensorflow/tensorflow/files/5060690/hdf5.zip)
[tflite.zip](https://github.com/tensorflow/tensorflow/files/5060695/tflite.zip)

One of my training materials:
[train_img.zip](https://github.com/tensorflow/tensorflow/files/5060699/train_img.zip)
"
42248,tf.keras.backend.reverse crashes (floating point exception) when first dimension of `x` is 0,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.keras.backend.reverse` crashes (segfault) when first dimension of `x` is 0
**Describe the expected behavior**
expect no crashes
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
import numpy as np
tf.keras.backend.reverse(x=np.ndarray(shape=[0, 1, 1]), axes=1)
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
Floating point exception (core dumped)
~~~"
42247,tf.random.gamma crashes(segfault) when `alpha`'s constraint is violated,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.random.gamma` crashes(segfault) when `alpha` is an integer instead of a `dtype`
**Describe the expected behavior**
expect no crashes except invalid input
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
tf.random.gamma(shape = [100, 100, 100, 100, 100], alpha=1)
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42246,tf.signal.inverse_stft segfault when frame_length is a large value,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

`tf.signal.inverse_stft` segfault when `frame_length` is a large value.

**Describe the expected behavior**
expect no crashes

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
stfts = tf.ones((1,1), dtype=tf.complex64)
tf.signal.inverse_stft(stfts=stfts, frame_length=2700000000, frame_step=1)
~~~


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
Segmentation fault (core dumped)
~~~"
42244,"Using custom, non-trainable layers in the middle of Keras model yields gradient error","### Problem
I am writing a GAN-style model which uses an untrained / weightless layer in the middle of the GAN (a transformation is performed on the generator output which is then fed into the discriminator). The transformation operation is done with a custom layer, but I'm getting the following error at runtime when trying to train (after compiling both the discriminator and GAN model):

```bash
ValueError: No gradients provided for any variable: ['dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'dense_5/kernel:0', 'dense_5/bias:0'].
```

### Code
My **Custom Layer** code is as follows (is meant to convert top left, bottom right coordinates into a square shape):
```python
class ImagePaste(tf.keras.layers.Layer):
    def __init__(self,  **kwargs):
        super(ImagePaste, self).__init__(**kwargs)
        self.canvas_size = 72

    def build(self, input_shape):
        self.batch_s = input_shape[0]

        super(ImagePaste, self).build(input_shape)
    
    def call(self, input_data, t_val=255):
        positions = tf.convert_to_tensor(input_data)
        positions = tf.reshape(positions, [-1, 2, 2])

        canvas = tf.Variable(tf.ones([self.batch_s, 72, 72, 3]) * t_val,
                             dtype=tf.float32,
                             trainable=False, validate_shape=True)

        for i in tf.range(0, self.batch_s):
            color = tf.convert_to_tensor(np.eye(3)[np.random.choice(3)] * 250, dtype=tf.float32)
            tl, br = tf.cast(positions[i], dtype=tf.int64)

            for r in tf.range(min(tl[0], self.canvas_size), min(br[0], self.canvas_size)):
                for c in tf.range(min(tl[1], self.canvas_size), min(br[1], self.canvas_size)):
                    canvas[i, r, c, :].assign(color)

        return tf.convert_to_tensor(canvas)
```

My **Generator** code is as follows (turns latent space into top left, bottom right square coordinates then image of square on a canvas):
```python
    def build_composer(self):
        latent_input = Input(shape=100, batch_size=64)

        p = Dense(units=128)(latent_input)
        p = Dense(units=256)(p)
        p = Dense(units=512)(p)
        p = Dense(units=1024)(p)

        out = Dropout(0.4)(p)
        out = Dense(units=4, activation='relu')(out)  # TOP LEFT, BOTTOM RIGHT COORDINATE

        composed_image = ImagePaste(trainable=False, dynamic=True)(out)

        return tf.keras.Model(inputs=latent_input, outputs=composed_image)
```

My **Generator + Discriminator (GAN)** code is as follows:
```python
    def build_full_model(self, composer, discriminator):
        latent_input = Input(shape=100, batch_size=64)

        composed_image = composer(latent_input)

        discriminator.trainable = False
        valid = discriminator(composed_image)

        return tf.keras.Model(inputs=latent_input, outputs=valid)
```

**And the error shown above occurs when calling ``` .predict() ``` on the compiled GAN model.**

It seems like my ImagePaste Layer is preventing gradients from reaching the generator layers -- how can I get the gradient calculation to ignore the layer (even though its already set to trainable = False) when training? Can anyone help me solve this? Thank you very much."
42243,How can i solve data transferred from slave to master using SPI?,"I tried to make a communication between two AVR (ATmega128) using SPI. Data transferred correctly from master to slave but data transferred wrong from slave to master, the first sampled bit is always wrong. Slave sends (0X7E) to master but the received data is (0X3F). Where is the mistake?

Code of MASTER

#define F_CPU 16000000UL

#include <avr/io.h>
#include <util/delay.h>

#define DDR_SPI DDRB
#define DD_MOSI PB2
#define DD_SCK PB1
#define DD_SS PB0

#define ACK 0x7E

void SPI_MasterInit(void)
{
	/* Set MOSI and SCK output */
	DDR_SPI |= (1<<DD_MOSI) | (1<<DD_SCK) | (1<<DD_SS);
	PORTB |= 1;
	/* Enable SPI, Master, set clock rate fck/128 */
	SPCR |= (1<<SPE)|(1<<MSTR)|(1<<SPR0)|(1<<SPR1);
}

unsigned char SPI_MasterTransmit(unsigned char cData)
{
	PORTB &= ~(1<<0);
	while( (PORTB & (1<<0)) );
	/* Start transmission */
	SPDR = cData;
	/* Wait for transmission complete */
	while(!(SPSR & (1<<SPIF)));
	PORTB |= 1;
	return SPDR;
}

void ADC_Init()
{
	//ADC enable
	ADCSRA |= (1<<ADEN);		
	//division factor --> 128
	ADCSRA |= (1<<ADPS0) | (1<<ADPS1) | (1<<ADPS2);		
	//left adjusted (8 bit mode) (ADCH)
	ADMUX |= (1<<ADLAR);	
	//input channel --> ADC2 (only one channel can be used in the conversion at a time)
	ADMUX |= (1<<MUX1);		
}

unsigned char ADC_StartConversion()
{
	ADCSRA |= (1 << ADSC);
	while(ADCSRA & (1<<ADSC));
	return ADCH;
}

int main(void)
{
	DDRC = 1;
	ADC_Init();
	SPI_MasterInit();
	unsigned char data;
	unsigned char ret;
	
    while (1) 
    {
		data = ADC_StartConversion();
		ret = SPI_MasterTransmit(data);
		
		if(ret == ACK)
		{
			PORTC = 1;
		}
		
		else
		{
			PORTC = 0;
		}
		
    }
}


Code of SLAVE

#define F_CPU 16000000UL

#include <avr/io.h>
#include <util/delay.h>

#define DDR_SPI DDRB
#define DD_MISO 3 
#define LED PC0

#define ACK 0x7E

void SPI_SlaveInit(void)
{
	/* Set MISO output, all others input */
	DDR_SPI = (1<<DD_MISO);
	/* Enable SPI */
	SPCR = (1<<SPE);
}

unsigned char SPI_SlaveReceive(char data)
{
	SPDR = data;
	/* Wait for reception complete */
	while(!(SPSR & (1<<SPIF)));
	/* Return data register */
	return SPDR;
}


int main(void)
{
	DDRC |= (1<<LED);
	SPI_SlaveInit();
	unsigned char data;
   
    while (1) 
    {	
		data = SPI_SlaveReceive(ACK);
		if(data >= 128)
		{
			PORTC |= (1<<LED);
		}
		else
		{
			PORTC &= ~(1<<LED);
		}
		//_delay_ms(100);	
	}
}

"
42242,tf.convert_to_tensor and tf.constant ignoring tf.device,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/device

## Description of issue (what needs changing):

At least on 2.3.0, it seems to me that 
```
import numpy.random as npr
import tensorflow as tf
with tf.device(""GPU""):
  A=tf.convert_to_tensor(npr.randn(500))
```
will create an eager tensor `A` on the CPU device (it will not allocate ram on the gpu).  This is counter-intuitive to someone who has only read the doc as it is written.  My understanding is that this happens because tf.convert_to_tensor isn't an op, and tf.device only deals with ops.  

### Clear description

The doc is pretty short now, and I don't think it would hurt to add a little remark, something like this:

*Note* -- `tf.convert_to_tensor` does not create an op.  As such, it ignores the contexts created by tf.device.  To ensure a given tensor is assigned memory on a particular device, one can wrap convert_to_tensor inside a `tf.identity` op.

Thoughts?"
42238,tf.ones returns zeroes in tf-nightly 2.4.0-dev20200811,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit
- TensorFlow installed from (source or binary): binary 
- TensorFlow version (use command below): 2.4.0-dev20200811
- Python version: 3.7.7
- CUDA/cuDNN version: 10.1.243
- GPU model and memory: Nvidia GeForce 960M Notebooks

**Describe the current behavior**
```
>>> import tensorflow as tf
>>> tf.ones((3, 3))
```

> <tf.Tensor: shape=(3, 3), dtype=float32, numpy=
> array([[0., 0., 0.],
>           [0., 0., 0.],
>           [0., 0., 0.]], dtype=float32)>

**Describe the expected behavior**

It should return ones!

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. 

"
42236,Unrecognized device error when setting memory growth,"
**System information**
- OS Platform and Distribution : Windows 10
- TensorFlow installed from: PIP
- TensorFlow version: tf-nightly-gpu 2.4.0-dev20200808
- Python version: 3.7.4
- Installed using virtualenv? PIP
- CUDA/cuDNN version: CUDA 10.2
- GPU model and memory: GeForce GTX 1050 Ti

**Describe the problem**
When listing available physical devices GPU does appear. Nonetheless, when setting memory growth (tf.config.experimental.set_memory_growth(gpu, True)), python does not recognize the device. 

**Any other info / logs**
ValueError: Unrecognized device: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]

"
42234,ValueError when using dictionary format for input of optimizer options in Tensorflow 2.2.0 Keras models,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (but very basic)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): I used pip
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.10
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: More than one machine

**Describe the current behavior**
I am using the dictionary format (see code below) to input options to an optimizer when compiling a Tensorflow Keras model. However, in Tensorflow 2.2.0 this throws an error. I fixed this issue for now by switching back to Tensorflow 2.1.0. Another workaround is to define the loss beforehand as tf.keras.losses.Nadam(**config). Neither of those is a final solution so I thought it best to report this bug. 

**Describe the expected behavior**
The dictionary format should work for easy input of non-default options of optimizers when compiling Keras models with Tensorflow 2.2.0.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python script
import tensorflow as tf
model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(3, activation='sigmoid'))
compiler_params = {
    ""optimizer"": {
        'class_name': 'Nadam',
        'config': {
            'lr': 0.0001
        }
    }
}
model.compile(**compiler_params)
```

**Other info / logs** 
Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```python script
ValueError                                Traceback (most recent call last)
<ipython-input-2-187c8cc52bd6> in <module>
     11     }
     12 }
---> 13 model.compile(**compiler_params)
     14

~\AppData\Local\Continuum\anaconda3\envs\cinc3\lib\site-packages\tensorflow\python\keras\engine\training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, **kwargs)
    326       self._run_eagerly = kwargs.pop('run_eagerly', None)
    327
--> 328       self.optimizer = self._get_optimizer(optimizer)
    329       self.compiled_loss = compile_utils.LossesContainer(
    330           loss, loss_weights, output_names=self.output_names)

~\AppData\Local\Continuum\anaconda3\envs\cinc3\lib\site-packages\tensorflow\python\keras\engine\training.py in _get_optimizer(self, optimizer)
    348       return opt
    349
--> 350     return nest.map_structure(_get_single_optimizer, optimizer)
    351
    352   @trackable.no_automatic_dependency_tracking

~\AppData\Local\Continuum\anaconda3\envs\cinc3\lib\site-packages\tensorflow\python\util\nest.py in map_structure(func, *structure, **kwargs)
    615
    616   return pack_sequence_as(
--> 617       structure[0], [func(*x) for x in entries],
    618       expand_composites=expand_composites)
    619

~\AppData\Local\Continuum\anaconda3\envs\cinc3\lib\site-packages\tensorflow\python\util\nest.py in <listcomp>(.0)
    615
    616   return pack_sequence_as(
--> 617       structure[0], [func(*x) for x in entries],
    618       expand_composites=expand_composites)
    619

~\AppData\Local\Continuum\anaconda3\envs\cinc3\lib\site-packages\tensorflow\python\keras\engine\training.py in _get_single_optimizer(opt)
    342
    343     def _get_single_optimizer(opt):
--> 344       opt = optimizers.get(opt)
    345       if (self._dtype_policy.loss_scale is not None and
    346           not isinstance(opt, lso.LossScaleOptimizer)):

~\AppData\Local\Continuum\anaconda3\envs\cinc3\lib\site-packages\tensorflow\python\keras\optimizers.py in get(identifier)
    900     return deserialize(config)
    901   else:
--> 902     raise ValueError('Could not interpret optimizer identifier:', identifier)

ValueError: ('Could not interpret optimizer identifier:', 0.0001)
```"
42233,ModuleNotFoundError: No module named 'tensorflow.python',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.3
- Python version: 3.7.7
- Installed using virtualenv? pip? conda?: Neither `pip` or `conda` worked
- CUDA/cuDNN version: 10.1, V10.1.243
- GPU model and memory: Nvidia GeForce 960M Notebook



**Describe the problem**

I get this when I import tensorflow:

> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""C:\Users\nicol\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 41, in <module>
>     from tensorflow.python.tools import module_util as _module_util
> ModuleNotFoundError: No module named 'tensorflow.python'

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
conda create -n tf python=3.7
pip install tensorflow
python
```
```
import tensorflow
```

**Any other info / logs**

If I run `help('modules')` in Python, I get:

> Failed to import TensorFlow. Please note that TensorFlow is not installed by default when you install Gin-Config. This is so that users can decide whether to install the GPU-enabled TensorFlow package. To use Gin-Config, please install the most recent version of TensorFlow, by following instructions at https://tensorflow.org/install.
"
42231,Quantization TOCO implementation,"Hi,

i am trying to understand how exactly TOCO does quantize an annotated model. Assume we have a keras model:
```
Conv2D
MaxPool
Conv2D
MaxPool
Flatten
Dense
Dense(SoftMax)
```
where the Conv2D layers have been annotated with for post-training quantization using a QuantizeConfig for quantizing weights and activations based on the following Quantizer: 

```
LastValueQuantizer(num_bits=8, symmetric=True,
 narrow_range=False,
per_axis=False)
```

As far as i understand, converting a such annotated keras model to TFLite using TOCO should yield a a model where the Conv2D layers have been quantized to 8bit integers while the rest stays at 32bit float. Is that correct? If yes, how is the rounding from the input keras Conv2D layers in 32bit to int8 accomplished? Is the situation the same when using float16 instead of int8? What abot the siutuation where i set num_bits=4?

Thanks for your help!"
42229,Tf-nightly 2.4.0 does not recognize Cuda 10.2,"### System information
-   **TF-nightly 2.4.0-dev20200808 installed with PIP**:
-   **OS Platform and Distribution: Windows 10**:
-   **Python version:  3.8.5**:
-   **CUDA/cuDNN version: 10.2**:
-   **GPU model and memory: GeForce GTX 1050 Ti**:

### Describe the problem
After installing tf-nightly and cuda 10.2 and changing the corresponding environmental variables, tensorflow does not recognize CUDA 10.2.
### Source code / logs
While importing tensorflow:
2020-08-11 10:04:37.795114: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-08-11 10:04:37.798451: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
"
42228,[colab TPU] [TF2.x] UnavailableError: Socket closed with LayerNormalization,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab environment with TPU  
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA 
- TensorFlow installed from (source or binary): binary 
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.9
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA 
- CUDA/cuDNN version: NA 
- GPU model and memory: High RAM

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I encountered this UnavailableError when running a classifier on the Colab TPU environment (with tensorflow.version = 2.3.0; Python version = 3.6.9). I was able to reproduce this error with the minimum lines of code. It turns out that the error stems from the LayerNormalization layer, and after removing this layer, the rest of the code just works fine.

**Describe the expected behavior**

**Standalone code to reproduce the issue**
```python
import tensorflow as tf 
import numpy as np
from tensorflow.keras.layers import LSTM, Dense, ReLU
from tensorflow.keras.layers import LayerNormalization, GlobalAveragePooling1D, TimeDistributed
from tensorflow.keras.models import Sequential
from tensorflow.keras import regularizers
resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)
```

```python
with strategy.scope():
  model = Sequential()
  model.add(LSTM(units=50, return_sequences=True))
  model.add(LayerNormalization())
  model.add(GlobalAveragePooling1D(data_format='channels_last'))
  model.add(Dense(7, activation='softmax'))
  model.compile(optimizer='adam', 
                loss='categorical_crossentropy', 
                experimental_steps_per_execution=100,
                metrics=['accuracy'])
```

```python
x=-np.ones((150, 100, 4)).astype(np.float32)
y=np.ones((150, 7)).astype(np.float32)
model.fit(x, y, epochs=10)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Here are the detailed log messages
```
Epoch 1/10
---------------------------------------------------------------------------
UnavailableError                          Traceback (most recent call last)
<ipython-input-20-cf653c7d94da> in <module>()
      3 y=np.ones((150, 7)).astype(np.float32)
      4 # Train the model
----> 5 model.fit(x, y, epochs=10)

14 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1101               logs = tmp_logs  # No error, now safe to assign to logs.
   1102               end_step = step + data_handler.step_increment
-> 1103               callbacks.on_train_batch_end(end_step, logs)
   1104         epoch_logs = copy.copy(logs)
   1105 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)
    438     """"""
    439     if self._should_call_train_batch_hooks:
--> 440       self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)
    441 
    442   def on_test_batch_begin(self, batch, logs=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)
    287       self._call_batch_begin_hook(mode, batch, logs)
    288     elif hook == 'end':
--> 289       self._call_batch_end_hook(mode, batch, logs)
    290     else:
    291       raise ValueError('Unrecognized hook: {}'.format(hook))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_end_hook(self, mode, batch, logs)
    307       batch_time = time.time() - self._batch_start_time
    308 
--> 309     self._call_batch_hook_helper(hook_name, batch, logs)
    310 
    311     if self._check_timing:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook_helper(self, hook_name, batch, logs)
    340       hook = getattr(callback, hook_name)
    341       if getattr(callback, '_supports_tf_logs', False):
--> 342         hook(batch, logs)
    343       else:
    344         if numpy_logs is None:  # Only convert once.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)
    959 
    960   def on_train_batch_end(self, batch, logs=None):
--> 961     self._batch_update_progbar(batch, logs)
    962 
    963   def on_test_batch_end(self, batch, logs=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _batch_update_progbar(self, batch, logs)
   1014     if self.verbose == 1:
   1015       # Only block async when verbose = 1.
-> 1016       logs = tf_utils.to_numpy_or_python_type(logs)
   1017       self.progbar.update(self.seen, list(logs.items()), finalize=False)
   1018 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py in to_numpy_or_python_type(tensors)
    535     return t  # Don't turn ragged or sparse tensors to NumPy.
    536 
--> 537   return nest.map_structure(_to_single_numpy_or_python_type, tensors)
    538 
    539 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)
    633 
    634   return pack_sequence_as(
--> 635       structure[0], [func(*x) for x in entries],
    636       expand_composites=expand_composites)
    637 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in <listcomp>(.0)
    633 
    634   return pack_sequence_as(
--> 635       structure[0], [func(*x) for x in entries],
    636       expand_composites=expand_composites)
    637 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py in _to_single_numpy_or_python_type(t)
    531   def _to_single_numpy_or_python_type(t):
    532     if isinstance(t, ops.Tensor):
--> 533       x = t.numpy()
    534       return x.item() if np.ndim(x) == 0 else x
    535     return t  # Don't turn ragged or sparse tensors to NumPy.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in numpy(self)
   1061     """"""
   1062     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
-> 1063     maybe_arr = self._numpy()  # pylint: disable=protected-access
   1064     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
   1065 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _numpy(self)
   1029       return self._numpy_internal()
   1030     except core._NotOkStatusException as e:  # pylint: disable=protected-access
-> 1031       six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
   1032 
   1033   @property

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnavailableError: Socket closed
Additional GRPC error information from remote target /job:worker/replica:0/task:0:
:{""created"":""@1597132573.936732336"",""description"":""Error received from peer ipv4:10.43.145.10:8470"",""file"":""external/com_github_grpc_grpc/src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""Socket closed"",""grpc_status"":14}
```
and the successful running log messages with the LayerNormalization removed 
```
Epoch 1/10
5/5 [==============================] - 2s 448ms/step - loss: 13.7076 - accuracy: 0.0000e+00
Epoch 2/10
5/5 [==============================] - 0s 10ms/step - loss: 13.7256 - accuracy: 0.0000e+00
Epoch 3/10
5/5 [==============================] - 0s 9ms/step - loss: 13.8872 - accuracy: 0.0000e+00
Epoch 4/10
5/5 [==============================] - 0s 9ms/step - loss: 14.1986 - accuracy: 0.0000e+00
Epoch 5/10
5/5 [==============================] - 0s 9ms/step - loss: 14.5464 - accuracy: 0.0000e+00
Epoch 6/10
5/5 [==============================] - 0s 8ms/step - loss: 14.8935 - accuracy: 0.0000e+00
Epoch 7/10
5/5 [==============================] - 0s 9ms/step - loss: 15.2337 - accuracy: 0.0000e+00
Epoch 8/10
5/5 [==============================] - 0s 9ms/step - loss: 15.5591 - accuracy: 0.0000e+00
Epoch 9/10
5/5 [==============================] - 0s 8ms/step - loss: 15.9003 - accuracy: 0.0000e+00
Epoch 10/10
5/5 [==============================] - 0s 10ms/step - loss: 16.2539 - accuracy: 0.0000e+00
<tensorflow.python.keras.callbacks.History at 0x7f78b8ad6ac8>
```

There is a same issue that I created under tensorflow/tpu https://github.com/tensorflow/tpu/issues/821, sorry if this has been repetitive "
42227,TensorFlow model in commercial projects,"Hi, I  don't understand the various licenses well. Now I am working with my mobile app, and I would like to know: can I use tensorflow models (like posenet) in commercial projects? Thank you
"
42226,tensorflow.python.framework.errors_impl.NotFoundError : when trying to run rasa init --no-prompt,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): **pip3 install --upgrade tensorflow rasa**
**pip3 install --upgrade tensorflow-addons rasa**
- TensorFlow version (use command below):tensorflow 2.3.0  , **v2.3.0-rc2-23-gb36436b087 2.3.0**
- Python version: **Python 3.6.9**

**Describe the current behavior**
When I am trying to run rasa init command it throws me error tensorflow.python.framework.errors_impl.NotFoundError

**Describe the expected behavior**
It should train the model.



**Other info / logs** Include any logs or source code that would be helpful to
tensorflow.python.framework.errors_impl.NotFoundError: /home/aman/meraklis-pocs/RASA_POC/venv/lib/python3.6/site-packages/tensorflow_addons/custom_ops/activations/_activation_ops.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl11string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS8_EE"
42224,[TFLite micro] Max number of channels (kMaxChannels) for DepthwiseConv should be updated (CMSIS-NN),"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): f63877d6371aa5e47391e520a29a6aa1ef2e0199
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Any

**Describe the problem**
The current implementation of DepthwiseConv based on CMSIS-NN [defines the maximum number of channels as a constant value (set to 256)](https://github.com/tensorflow/tensorflow/blob/b4ab032959b2fb68022b2cf70de46e9564a50d6f/tensorflow/lite/micro/kernels/cmsis-nn/depthwise_conv.cc#L40). This can be a limitation for someone that want to run a model having one or more DepthwiseConv ops with a number of channels greater than 256. In fact, in that case, the assertion `TFLITE_DCHECK_LE(num_channels, kMaxChannels);` will become false and inference will stop.
There are several ways to solve this limitation, each having some pros and cons:

- The simplest way is to increase the value of `kMaxChannels`, for example to 1024. This will increase the set of models that can be run such as MobileNet v1 with alpha=100 or 75. On the other hand, when we need to run a DepthwiseConv op with a number of channels less than 1024, we will allocate more memory (for `per_channel_output_multiplier` and `per_channel_output_shift`) than what is needed.
I am also aware that when designing a model for a MCU, the 'keep-it-simple' (I would also say 'keep-it-small') principle is very important and useful in order to reduce memory and computational requirements. So, in this case, the value of `kMaxChannels` represent an important trade-off.
A variant of this approach is to allow the user to set the max number of channels of all DepthwiseConv ops through compile-time constants and macros. For example, we can use the following code snippet to set it:
```
#if defined(TFLITE_DEPTHWISECONV_MAX_CHANNELS) && TFLITE_DEPTHWISECONV_MAX_CHANNELS > 0
  constexpr int kMaxChannels = TFLITE_DEPTHWISECONV_MAX_CHANNELS;
#else 
  constexpr int kMaxChannels = 256;
#endif
```
The user can re-define it at compile time according to the model to be run (for example compiling the source code with `-DTFLITE_DEPTHWISECONV_MAX_CHANNELS=1024`).

- Another way is to use dynamic allocation in order to allocate only the needed memory for the temp buffers. On the other hand, dynamic memory allocation can result in memory fragmentation or runtime issues (especially when memory is not managed by a  RTOS or because it is general quite small in size), and so it is generally avoided (think about the use of the `tensor_arena`). However this approach could be quite useful to save memory and if the number of channels is not very high heap issues like overflow should not happen.
I'm also wondering if it is possible to allocate memory for the needed buffers in the `tensor_arena`.

- Other suggestions ?

So, my question is: can we handle `kMaxChannels` in a better way ?

Best regards,
Biagio."
42223,Wrong output when decorating functions with @tf.function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
    Complete test code(minimum version for reproducing the problem) below 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10, tf 2.2.0 py 3.6.8
- TensorFlow installed from (source or binary): pip install tensorflow=2.2.0
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.8
- CUDA/cuDNN version: Using cpu


**Describe the current/expected behavior**
The following is a simple example for writing an iterative method to solve `Ax=b`, as the iterative step is
```math
x_{k+1} = x_k + \alpha * (b - A x_k)
```
while adding/removing the `@tf.function` decorator in `Line 12` will result in different output.
The output with `@tf.function`:
```
Step  0: loss 1.00000000e+00
Step  1: loss 1.00000000e+00
Step  2: loss 1.00000000e+00
Step  3: loss 1.00000000e+00
Step  4: loss 1.00000000e+00
...
```
The output without `@tf.function` (correct):
```
Step  0: loss 1.00000000e+00
Step  1: loss 7.73297510e-01
Step  2: loss 6.05587767e-01
Step  3: loss 4.81463411e-01
Step  4: loss 3.89456113e-01
...
```

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
import numpy as np


class MyFakeNN(tf.keras.Model):
    def __init__(self, max_num_iter=100, **kwargs):
        super(MyFakeNN, self).__init__(**kwargs)
        self.max_num_iter  = max_num_iter
        self.func = func
        self.curr_iter = 0

    @tf.function
    def train_one_step(self, x, y):
        x_next = self(x, y)
        loss = loss_func(x_next, y)
        return loss

    def train(self, x, y):
        for it in range(self.max_num_iter):
            self.curr_iter = it
            self.trainable = False
            loss = self.train_one_step(x, y)
            print(""Step %2d: loss %14.8e"" % (it, loss.numpy()))

    def call(self, x, y):
        for _ in range(self.curr_iter):
            r = y - self.func(x)
            x += r * 2e-3
        return x


n = 8
tf.keras.backend.set_floatx('float64')

a = np.eye(n, k=0) * 2 - np.eye(n, k=1) - np.eye(n, k=-1)
a[-1, 0] = -1
a[0, -1] = -1
a *= n ** 2
func = lambda x: tf.matmul(x, a)


def loss_func(x, y):
    return tf.reduce_mean(tf.norm(func(x) - y, axis=1)/tf.norm(y, axis=1))


model = MyFakeNN()
model.trainable = False

y = np.array([[-9.38155831, -28.13152345, 7.78468155, 29.26619534,
               -4.5831364, -25.87319867, 6.18001317, 24.73852678], [-9.83892541, -20.53029054, 20.69956084, 28.01860432,
               -20.97012137, -35.88954846, 10.10948594, 28.40123469], [-21.04290567, -8.05650662, 16.85368166, 1.02738802,
               -22.60513251, -2.13204921, 26.79435652, 9.16116781], [2.04530187, -2.93405974, -2.79706502, -1.04454986,
               -2.07777548, -1.87090609, 2.82953863, 5.84951569], [-4.84959288, 6.48666613, 8.21196668, -4.87053449,
               -9.2887852, 1.73155149, 5.92641139, -3.34768314], [7.66043654, 6.05170581, -3.87066543, 0.99382044,
               10.04477309, 0.69216011, -13.8345442, -7.73768635], [2.54742214, -13.73492348, 0.23540163, 14.91811095,
               -1.34494564, -17.6704306, -1.43787813, 16.48724313], [12.9314438, 3.94013919, -22.58640847, -11.10766707,
               22.104958, 17.59432117, -12.44999333, -10.42679329]])
x = np.zeros(y.shape, dtype='float64')

model.train(x=x, y=y)
```
"
42222,Please add tf 1.15's related cuda/cudnn version,"Hi, the official documentation webpage gives the version table for tensorflow version and cuda/cudnn version:

https://www.tensorflow.org/install/source#common_installation_problems

However, there's no information about tensorflow 1.15.

Please consider adding it. Thanks."
42221,version 2.3.0 build error: user_ops_gen_cc: undefined symbol,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  CentOS Linux release 7.8.2003
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: build from source
- Bazel version (if compiling from source): 3.4.1 or 3.1.0 (both give the same error shown below)
- GCC/Compiler version (if compiling from source): gcc 8.4.0
- CUDA/cuDNN version: 11.0
- GPU model and memory: RTX2080; 10GB



**Describe the problem**

I am building version 2.3.0 from source and get this error:
```
bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/cc/ops/user_ops_gen_cc: symbol lookup error: bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/cc/ops/user_ops_gen_cc: undefined symbol: _ZN10tensorflow8OpKernel11TraceS
tringB5cxx11EPNS_15OpKernelContextEb
```
The exact command that fails is:
```
cd ../tensorflow_cache_dir/_bazel_aznb/73fa4b3fd284d99232eec1bc01a9093d/execroot/org_tensorflow &&
exec env - \
CUDA_TOOLKIT_PATH=/home/aznb/.linuxbrew/Cellar/cuda/11.0 \
CUDNN_INSTALL_PATH=/home/aznb/.linuxbrew/Cellar/cuda/11.0 \
GCC_HOST_COMPILER_PATH=/home/aznb/.linuxbrew/Cellar/gcc@8/8.4.0_1/bin/gcc-8 \
PATH=/usr/bin:/bin:/home/aznb/.linuxbrew/bin \
PYTHONPATH=/home/aznb/.pyenv/versions/venv-tensorflow-py3.8.5-cuda11.0/lib/python3.8/site-packages \
PYTHON_BIN_PATH=/home/aznb/.pyenv/shims/python3 \
PYTHON_LIB_PATH=/home/aznb/.pyenv/versions/venv-tensorflow-py3.8.5-cuda11.0/lib/python3.8/site-packages \
TF2_BEHAVIOR=1 \
TF_CONFIGURE_IOS=0 \
TF_CUDA_COMPUTE_CAPABILITIES=6.1,7.5 \
TF_CUDA_PATHS=/home/aznb/.linuxbrew/Cellar/cuda/11.0 \
TF_CUDA_VERSION=11.0 \
TF_CUDNN_VERSION='' \
TF_NEED_CUDA=1 \
/bin/bash bazel-out/k8-opt/bin/tensorflow/cc/user_ops_genrule.genrule_script.sh
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
export CUDA_TOOLKIT_PATH=$CUDAPATH                                                                                                                                                                                 
export CUDNN_INSTALL_PATH=$CUDA_TOOLKIT_PATH                                                                                                                                                                       
export TF_CUDA_VERSION=""$($CUDA_TOOLKIT_PATH/bin/nvcc --version | sed -n 's/^.*release \(.*\),.*/\1/p')""
export TF_CUDA_COMPUTE_CAPABILITIES=$CUDACC
export TF_CUDA_PATHS=$CUDAPATH
export TF_NEED_CUDA=1

export TF_CUDA_CLANG=0
export TF_NEED_GCP=0
export TF_NEED_HDFS=0
export TF_NEED_OPENCL=0
export TF_NEED_JEMALLOC=1
export TF_ENABLE_XLA=0
export TF_NEED_VERBS=0
export TF_CUDNN_VERSION=""$(sed -n 's/^#define CUDNN_MAJOR\s*\(.*\).*/\1/p' $CUDNN_INSTALL_PATH/include/cudnn.h)""
export TF_NEED_MKL=0
export TF_DOWNLOAD_MKL=0
export TF_DOWNLOAD_CLANG=0
export TF_NEED_AWS=0
export TF_NEED_MPI=0
export TF_NEED_GDR=0
export TF_NEED_S3=0
export TF_NEED_ROCM=0
export TF_NEED_OPENCL_SYCL=0
export TF_SET_ANDROID_WORKSPACE=0
export TF_NEED_COMPUTECPP=0
# for some reason, this gcc path can't be a symlink to the actual path
export GCC_HOST_COMPILER_PATH=$LINUXBREWHOME/bin/gcc-8
export CC_OPT_FLAGS=""-march=native""
#export TF_SET_ANDROID_WORKSPACE=0
export TF_NEED_KAFKA=0
export TF_NEED_TENSORRT=0
#output cache dir
export TEST_TMPDIR=""../tensorflow_cache_dir""
export TEMPOUTPUT=""./output_dir""
bazel clean --async --expunge
rm -rf ~/.cache/bazel
./configure

bazel build --explain=buildwhl.txt --verbose_explanations -s --verbose_failures --jobs 24 --crosstool_top=@local_config_cuda//crosstool:toolchain --config=noaws --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
42219,Wheel size increase from 2.0 to 2.1 onward,"I am asking this here because I could not find any centralized patch notes that explain this.

If we go to pypi and look at tensorflow 2.0 for py3.6 win64 it has a big, but reasonable wheel size of ~50MB:

https://pypi.org/project/tensorflow/2.0.0/#files

However release 2.1 jumps that number to ~355 MB and release 2.2 goes to ~460 MB. This is an almost x10 size increase!

I highly doubt that almost half a GB of raw code was added (was it?) so I am wondering what exactly was added since a Google search seems to yield no results."
42218,"[comp:data] link invalid in the ""Analyze tf.data performance with the TF Profiler"" guide","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue: https://www.tensorflow.org/guide/data_performance_analysis

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/guide/data_performance_analysis#3_are_you_reaching_high_cpu_utilization

## Description of issue (what needs changing):

Referring to the following line:

> tf.data achieves high throughput by trying to make the best possible use of available resources. In general, even when running your model on an accelerator like a GPU or TPU, the tf.data pipelines are run on the CPU. You can check your utilization with tools like sar and htop, or in the cloud monitoring console if you’re running on GCP.

The link attached to ""cloud monitoring console"" is invalid.
"
42217,Typo in TFLite CoreML framework build command example,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
There is a single typo in build command example:

https://github.com/tensorflow/tensorflow/blob/4b901e2a7ea0b849ad1d1cea311cd131bc089ebe/tensorflow/lite/experimental/ios/BUILD.apple#L82-L94

This introduce bazel build fails to newbies:

```
ERROR: Skipping '//tensorflow/lite/experimental/ios:TensorFlowLiteCCoreMl_framework': no such target '//tensorflow/lite/experimental/ios:TensorFlowLiteCCoreMl_framework': target 'TensorFlowLiteCCoreMl_framework' not declared in package 'tensorflow/lite/experimental/ios' (did you mean 'TensorFlowLiteCCoreML_framework'?) defined by /Users/mumu/hpcnt/tensorflow/tensorflow/lite/experimental/ios/BUILD
WARNING: Target pattern parsing failed.
ERROR: no such target '//tensorflow/lite/experimental/ios:TensorFlowLiteCCoreMl_framework': target 'TensorFlowLiteCCoreMl_framework' not declared in package 'tensorflow/lite/experimental/ios' (did you mean 'TensorFlowLiteCCoreML_framework'?) defined by /Users/mumu/hpcnt/tensorflow/tensorflow/lite/experimental/ios/BUILD
INFO: Elapsed time: 21.011s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded)
```

**Describe the expected behavior**

At Line 82, `TensorFlowLiteCCoreMl_framework` should be fixed to `TensorFlowLiteCCoreML_framework`

**Standalone code to reproduce the issue**

**Other info / logs** Include any logs or source code that would be helpful to
"
42216,make failed and it print this . The keywords is Undefine Reference,"../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `void HugeCTR::create_pipeline_internal<long long>(std::unique_ptr<HugeCTR::DataReader<long long>, std::default_delete<HugeCTR::DataReader<long long> > >&, std::unique_ptr<HugeCTR::DataReader<long long>, std::default_delete<HugeCTR::DataReader<long long> > >&, std::vector<std::unique_ptr<HugeCTR::Embedding<long long>, std::default_delete<HugeCTR::Embedding<long long> > >, std::allocator<std::unique_ptr<HugeCTR::Embedding<long long>, std::default_delete<HugeCTR::Embedding<long long> > > > >&, std::vector<std::unique_ptr<HugeCTR::Network, std::default_delete<HugeCTR::Network> >, std::allocator<std::unique_ptr<HugeCTR::Network, std::default_delete<HugeCTR::Network> > > >&, std::shared_ptr<HugeCTR::GPUResourceGroup> const&, nlohmann::basic_json<std::map, std::vector, std::string, bool, long, unsigned long, double, std::allocator, nlohmann::adl_serializer>, unsigned long, bool, float)':
parser.cpp:(.text+0xc233): undefined reference to `HugeCTR::EmbeddingCreator::create_localized_sparse_embedding_hash(std::vector<std::shared_ptr<HugeCTR::Tensor<long long> >, std::allocator<std::shared_ptr<HugeCTR::Tensor<long long> > > > const&, std::vector<std::shared_ptr<HugeCTR::Tensor<long long> >, std::allocator<std::shared_ptr<HugeCTR::Tensor<long long> > > > const&, HugeCTR::SparseEmbeddingHashParams_, std::string, std::shared_ptr<HugeCTR::GPUResourceGroup> const&)'
../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `void HugeCTR::create_pipeline_internal<unsigned int>(std::unique_ptr<HugeCTR::DataReader<unsigned int>, std::default_delete<HugeCTR::DataReader<unsigned int> > >&, std::unique_ptr<HugeCTR::DataReader<unsigned int>, std::default_delete<HugeCTR::DataReader<unsigned int> > >&, std::vector<std::unique_ptr<HugeCTR::Embedding<unsigned int>, std::default_delete<HugeCTR::Embedding<unsigned int> > >, std::allocator<std::unique_ptr<HugeCTR::Embedding<unsigned int>, std::default_delete<HugeCTR::Embedding<unsigned int> > > > >&, std::vector<std::unique_ptr<HugeCTR::Network, std::default_delete<HugeCTR::Network> >, std::allocator<std::unique_ptr<HugeCTR::Network, std::default_delete<HugeCTR::Network> > > >&, std::shared_ptr<HugeCTR::GPUResourceGroup> const&, nlohmann::basic_json<std::map, std::vector, std::string, bool, long, unsigned long, double, std::allocator, nlohmann::adl_serializer>, unsigned long, bool, float)':
parser.cpp:(.text+0x10df3): undefined reference to `HugeCTR::EmbeddingCreator::create_localized_sparse_embedding_hash(std::vector<std::shared_ptr<HugeCTR::Tensor<unsigned int> >, std::allocator<std::shared_ptr<HugeCTR::Tensor<unsigned int> > > > const&, std::vector<std::shared_ptr<HugeCTR::Tensor<unsigned int> >, std::allocator<std::shared_ptr<HugeCTR::Tensor<unsigned int> > > > const&, HugeCTR::SparseEmbeddingHashParams_, std::string, std::shared_ptr<HugeCTR::GPUResourceGroup> const&)'
../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `HugeCTR::DataReader<long long>::create_heap_workers_()':
parser.cpp:(.text._ZN7HugeCTR10DataReaderIxE20create_heap_workers_Ev[_ZN7HugeCTR10DataReaderIxE20create_heap_workers_Ev]+0x6f1): undefined reference to `tensorflow::io::RecordReaderOptions::CreateRecordReaderOptions(std::string const&)'
../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `HugeCTR::DataReader<unsigned int>::create_heap_workers_()':
parser.cpp:(.text._ZN7HugeCTR10DataReaderIjE20create_heap_workers_Ev[_ZN7HugeCTR10DataReaderIjE20create_heap_workers_Ev]+0x6f1): undefined reference to `tensorflow::io::RecordReaderOptions::CreateRecordReaderOptions(std::string const&)'
../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `HugeCTR::TFrecordFileSource::process_features(float*)':
parser.cpp:(.text._ZN7HugeCTR18TFrecordFileSource16process_featuresEPf[_ZN7HugeCTR18TFrecordFileSource16process_featuresEPf]+0x41): undefined reference to `tensorflow::io::RecordReader::ReadRecord(unsigned long long*, std::string*)'
parser.cpp:(.text._ZN7HugeCTR18TFrecordFileSource16process_featuresEPf[_ZN7HugeCTR18TFrecordFileSource16process_featuresEPf]+0x36a): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&)'
parser.cpp:(.text._ZN7HugeCTR18TFrecordFileSource16process_featuresEPf[_ZN7HugeCTR18TFrecordFileSource16process_featuresEPf]+0x1259): undefined reference to `google::protobuf::io::CodedInputStream::ReadString(std::string*, int)'
../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `HugeCTR::TFrecordFileSource::next_source()':
parser.cpp:(.text._ZN7HugeCTR18TFrecordFileSource11next_sourceEv[_ZN7HugeCTR18TFrecordFileSource11next_sourceEv]+0x54): undefined reference to `tensorflow::Env::NewRandomAccessFile(std::string const&, std::unique_ptr<tensorflow::RandomAccessFile, std::default_delete<tensorflow::RandomAccessFile> >*)'
collect2: error: ld returned 1 exit status
utest/parser/CMakeFiles/parser_test.dir/build.make:110: recipe for target 'bin/parser_test' failed
make[2]: *** [bin/parser_test] Error 1
CMakeFiles/Makefile2:1781: recipe for target 'utest/parser/CMakeFiles/parser_test.dir/all' failed
make[1]: *** [utest/parser/CMakeFiles/parser_test.dir/all] Error 2
Makefile:129: recipe for target 'all' failed
make: *** [all] Error 2"
42215,"Testing Operator ""raw_ops.ApplyAdam"" ","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Conda install
- TensorFlow version (use command below): r2.2
- Python version:  python3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2
- GPU model and memory: Teslav100 / 32G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I'd like to test raw_ops.ApplyAdam in TensorFlow r2.2, yet  
```c++
""TypeError: 'ApplyAdam' Op requires that input 'var' be a mutable tensor (e.g.: a tf.Variable) "" 
```
raises even if I define var as a variable like 
```c++
""var = tf.Variable([[1.], [2.]])""
``` 
So what is exactly a mutable tensor looks like? 

**Describe the expected behavior**
I expected this operator could work correctly?

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import tensorflow as tf

tf.compat.v1.disable_eager_execution()
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth=True
sess= tf.compat.v1.Session(config = config)

var = tf.Variable([[1.], [2.]]) 
m = tf.Variable([[1.], [2.]]) 
v = tf.Variable([[1.], [2.]]) 
beta1_power = tf.Variable(0.5)
beta2_power = tf.Variable(0.5)
lr = tf.Variable(0.5)
beta1 = tf.Variable(0.5)
beta2 = tf.Variable(0.5)
epsilon = tf.Variable(0.5)
grad =tf.Variable([[1.], [2.]]) 
use_locking = False
use_nesterov = False

sess.run(tf.compat.v1.global_variables_initializer())

sess.run(tf.compat.v1.raw_ops.ApplyAdam(var=var, m=m, v=v, beta1_power=beta1_power, beta2_power=beta2_power, lr= lr, beta1 = beta1, beta2 = beta2, epsilon = epsilon, grad =grad,
    use_locking=False, use_nesterov=False, name=None))
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42214,TfLiteFlexDelegate invoke failed！,"**System information**
- OS Platform and Distribution : MacOS TFLiteConverter ->TFLiteModel 
   && Android TF C++ library with FlexDelegate
- TensorFlow installed from (source or binary): Source
- TensorFlow version (or github SHA if from source): tf-nightly 2.4.0
- Python version: 3.7
- CPU version

**TfliteConverter part**
We have a deeplabv3+ model with resnetv2-101 base-architecture, and we have successfully converted it to tflite model based on tf-nightly 2.4 version。here is the python code： 
  ```
     model = tf.saved_model.load(saved_model_dir)

    concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]

    concrete_func.inputs[0].set_shape([1, 257, 257, 3])

    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])

    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]

    converter.allow_custom_ops = True

    converter.experimental_new_converter = True

    tflite_model = converter.convert()

    open('model_tflite.tflite', 'wb').write(tflite_model)

```
**Then we build TF C++ library with FlexDelegate, and we got libtensorflow_flex.so.**
   
Here is the C++ test code :

```
   TfLiteModel *model = TfLiteModelCreate(modelPath);

    options = TfLiteInterpreterOptionsCreate();
	
    TfLiteInterpreterOptionsSetNumThreads(options, 4);

    interpreter = TfLiteInterpreterCreate(model, options);

    TfLiteStatus status = TfLiteInterpreterAllocateTensors(interpreter);

    TfLiteTensor *input_tensor = TfLiteInterpreterGetInputTensor(interpreter, 0);

    TfLiteStatus cpystatus = TfLiteTensorCopyFromBuffer(input_tensor, inputData, input_tensor->bytes);

    TfLiteStatus status = TfLiteInterpreterInvoke(interpreter);
```

But we will get an error when executing the invoke：

```
2020-08-11 10:17:44.612 14278-15583/com.kimguo.tensorflow2 I/tflite: Initialized TensorFlow Lite runtime.
2020-08-11 10:17:44.621 14278-15583/com.kimguo.tensorflow2 I/tflite: Created TensorFlow Lite delegate for select TF ops.
2020-08-11 10:17:44.623 14278-14278/com.kimguo.tensorflow2 E/GraphicExt: GraphicExtModuleLoader::CreateGraphicExtInstance false
2020-08-11 10:17:44.625 14278-14307/com.kimguo.tensorflow2 D/Surface: Surface::connect(this=0xe3eac000,api=1)
2020-08-11 10:17:44.626 14278-15583/com.kimguo.tensorflow2 I/tflite: TfLiteFlexDelegate delegate: 5 nodes delegated out of 241 nodes with 3 partitions.
2020-08-11 10:17:44.630 14278-14307/com.kimguo.tensorflow2 D/mali_winsys: EGLint new_window_surface(egl_winsys_display *, void *, EGLSurface, EGLConfig, egl_winsys_surface **, EGLBoolean) returns 0x3000
2020-08-11 10:17:44.631 14278-14307/com.kimguo.tensorflow2 D/Surface: Surface::setBufferCount(this=0xe3eac000,bufferCount=3)
2020-08-11 10:17:44.633 14278-14307/com.kimguo.tensorflow2 D/Surface: Surface::allocateBuffers(this=0xe3eac000)
2020-08-11 10:17:44.709 14278-15583/com.kimguo.tensorflow2 I/tflite: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.
2020-08-11 10:17:44.709 14278-15583/com.kimguo.tensorflow2 I/tflite: TfLiteFlexDelegate delegate: 2 nodes delegated out of 9 nodes with 2 partitions.
2020-08-11 10:17:44.823 14278-15583/com.kimguo.tensorflow2 W/native: op_kernel.cc:1772 OP_REQUIRES failed at tensor_array_ops.cc:1035 : Not found: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)
2020-08-11 10:17:44.823 14278-15583/com.kimguo.tensorflow2 E/tflite: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)
    	 (while executing 'TensorArrayScatterV3' via Eager)
2020-08-11 10:17:44.824 14278-15583/com.kimguo.tensorflow2 E/tflite: Node number 241 (TfLiteFlexDelegate) failed to invoke.
```
 **There are some flex operators in our model，such as “FlexTensorArrayV3”，“FlexTensorArrayScatterV3”,
“FlexTensorArraySizeV3”，“FlexTensorArrayGatherV3”.. and I can find them from allowlisted_flex_ops.cc.  They can be well “Allocate”, But when ""invoke"", this error will be prompted，Does anyone have a problem like this？**。

"
42213,tf.nn.max_pool3d crashes(floating point exception) when strides=0,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.6.9
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

`tf.nn.max_pool3d` crashes(floating point exception) when `input` is of type `np.float16` **AND** `strides=0` **AND** `padding='SAME'`

**Describe the expected behavior**
expect no crashes

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
import numpy as np
input = tf.ones((1,1,1,1,1), dtype=np.float16)
tf.nn.max_pool3d(input=input, ksize=1, strides=0, padding='SAME')
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
Floating point exception (core dumped)
~~~"
42212,tf.random.learned_unigram_candidate_sampler crashes(segfault) when true_classes contain large value,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.random.learned_unigram_candidate_sampler` crashes(segfault) when `true_classes` containa large value AND `num_true=rank(true_classes)[-1]`.

**Describe the expected behavior**
expect no crashes

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
true_classes = [[1, 100000]]  # shape(1,2)
num_true = 2
tf.random.learned_unigram_candidate_sampler(true_classes=true_classes, num_true=num_true, num_sampled=10, unique=False, range_max=1)
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
Segmentation fault (core dumped)
~~~"
42211,/usr/bin/env: 'python': No such file or directory,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Built from Github source
- TensorFlow version: Latest (2.2)
- Python version: 3.8
- Installed using virtualenv? pip? conda?: No virtual or conda used
- Bazel version (if compiling from source): 3.4.1
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

Issue ""Tensorflow does not build in a python3 only environment #15618"" is still a problem. 

Rather than have to trawl through google posts and forums to find a solution it would be preferable if the build instructions mentioned the simple work-around of creating a Sym link to Python3 using the following

sudo link /usr/bin/python3 /usr/bin/python

"
42210,module 'tensorflow' has no attribute 'get_default_graph',"Hello, I have a problem when I run a github code.

Installed using pip: tensorflow version = 2.3.0

keras = 2.2.4

I imported so

_`import keras`_

and use these methods

 keras.utils.get_file

````
import keras

from .models.all_models import model_from_name


def model_from_checkpoint_path(model_config, latest_weights):

    model = model_from_name[model_config['model_class']](
        model_config['n_classes'], input_height=model_config['input_height'],
        input_width=model_config['input_width'])
    model.load_weights(latest_weights)
    return model


def resnet_pspnet_VOC12_v0_1():
```

    model_config = {
        ""output_height"": 96,
        ""input_height"": 384,
        ""input_width"": 576,
        ""n_classes"": 151,
        ""model_class"": ""resnet50_pspnet"",
        ""output_width"": 144
    }

    REPO_URL = ""https://github.com/divamgupta/image-segmentation-keras""
    MODEL_PATH = ""pretrained_model_1/r2_voc12_resnetpspnet_384x576.24""
    model_url = ""{0}/releases/download/{1}"".format(REPO_URL, MODEL_PATH)
    latest_weights = keras.utils.get_file(model_url.split(""/"")[-1], model_url)

    return model_from_checkpoint_path(model_config, latest_weights)`


Does anyone know another way for me to run this code?"
42209,Issue with batch size in backpropagation,"I'm trying to implement a custom loss function related to Triplet Loss. Triplet loss has a provision to give custom distance metric, that returns pairwise distances between embeddings. I have defined a custom function that works fine on forward-propagation. But on backpropagation (that is what I assume ) it is throwing some error. Following is the error.

`InvalidArgumentError:  slice index 16 of dimension 1 out of bounds.
 [[{{node TripletSemiHardLoss/PartitionedCall/while_1/body/_226/while_1/strided_slice}}]] [Op:__inference_train_function_31232]
Function call stack: train_function
`

16 is the batch size,my input had. I'm not using any while loop in the custom code. However, there is a for loop.

I have tried the following.

I retrieve the batch size using tf.size(input). Works fine on forward prop.
I have tried both while loop and for loop. On forward propagation, both are working fine. Both are producing same results. Yet on backprop, both are throwing the same error.

A sample of the code if below. I retrieved batch size from input from a previously calling function. Bt below, I have also gathered the same value by calling tf.size(hist_values). That also supposed to give the batch size only. It does work on forward propagation. But on backprop ( I'm assuming , it is backprop only) , it fails.

`@tf.function'
def divide_one_row(hist_values,result,row_num,batch_size):
    reshaped = tf.reshape(hist_values[:,row_num],shape=(hist_values.shape[0],1))
    duplicated = tf.repeat(reshaped,repeats=tf.size(hist_values),axis=1)
    r = tf.math.divide_no_nan(duplicated,hist_values)
    result = result.write(row_num,r)
    
    return hist_values,result,row_num+1,batch_size
`
` 
@tf.function
def get_division_matrix(hist_values,batch_size):
        
    i = tf.constant(0)
    result = tf.TensorArray(tf.float32,size=0,dynamic_size=True,clear_after_read=False)
    
    for i in tf.range(tf.size(hist_values)):        
        hist_values,result,_,batch_size = divide_one_row(hist_values,result,i,tf.size(hist_values))
        
    return result.stack()`


Following is the entire error stack : 

`InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-24-70c4ddc79f73> in <module>
     11                            epochs=25,
     12                            callbacks=[checkpoint],
---> 13                            verbose=1)

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    322               'in a future version' if date is None else ('after %s' % date),
    323               instructions)
--> 324       return func(*args, **kwargs)
    325     return tf_decorator.make_decorator(
    326         func, new_func, 'deprecated',

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1827         use_multiprocessing=use_multiprocessing,
   1828         shuffle=shuffle,
-> 1829         initial_epoch=initial_epoch)
   1830 
   1831   @deprecation.deprecated(

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1096                 batch_size=batch_size):
   1097               callbacks.on_train_batch_begin(step)
-> 1098               tmp_logs = train_function(iterator)
   1099               if data_handler.should_sync:
   1100                 context.async_wait()

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    838         # Lifting succeeded, so variables are initialized and we can run the
    839         # stateless function.
--> 840         return self._stateless_fn(*args, **kwds)
    841     else:
    842       canon_args, canon_kwds = \

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2827     with self._lock:
   2828       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2829     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2830 
   2831   @property

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1846                            resource_variable_ops.BaseResourceVariable))],
   1847         captured_inputs=self.captured_inputs,
-> 1848         cancellation_manager=cancellation_manager)
   1849 
   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1922       # No tape is watching; skip to running the function.
   1923       return self._build_call_outputs(self._inference_function.call(
-> 1924           ctx, args, cancellation_manager=cancellation_manager))
   1925     forward_backward = self._select_forward_and_backward_functions(
   1926         args,

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    548               inputs=args,
    549               attrs=attrs,
--> 550               ctx=ctx)
    551         else:
    552           outputs = execute.execute_with_cancellation(

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError:  slice index 16 of dimension 1 out of bounds.
	 [[{{node TripletSemiHardLoss/PartitionedCall/PartitionedCall/PartitionedCall_1/while/body/_258/while/PartitionedCall/strided_slice}}]] [Op:__inference_train_function_42705]

Function call stack:
train_function
`

"
42208,tf.nn.conv2d crashes(Floating_Point_Exception) when there is 0 in filters.shape,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.6.9
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.nn.conv2d` crashes(Floating_Point_Exception) when any of the first three dimensions of `filters.shape`(4D) is 0
**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
tf.nn.conv2d(input=tf.ones((1,1,1,1)), filters=tf.ones((1,1,0,1)), strides=1, padding='SAME')
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python 
Floating point exception (core dumped)
~~~"
42207,Reduction is average step time when disabling certain HLO passes,"**System information**
- Model: ResNet50 with Cifar-10
- OS Platform and Distribution : Linux Ubuntu 18.04
- TensorFlow: installed from source
- TensorFlow version : v2.2.0
- Python version: 3.6.9
- Bazel version : 2.0.0
- GCC/Compiler version : 7.5.0
- CUDA/cuDNN version: 10.1/7.6
- GPU model and memory: GeForce RTX 2080 / 7982MiB


**Describe the current behavior**

Hi all,

I am currently trying to find way if a model execution time can be reduced further . For instance I saw 5 ms reduction in average step time (Tensorboard Profile Summary) at times when I disabled certain HLO passes like  gpu-conv-padding-legalization, transpose-folding while running ResNet50 with Cifar 10 . Now I understand that entire set of 51 HLO passes(Target Dependent and Target Independent) are there for a reason. But considering the reduction in step time , is this normal behavior if not can some of these passes be avoided depending on the model we execute ? 

I tried disabling some HLO passes 
- convolution_4d_expander
- gpu-conv-padding-legalization
- multi_output_fusion
- reduction-degenerate-dim-remover
- reduction-dimension-grouper
- transpose-folding


** plots with some results obtained **
https://github.com/mmadala95/xla_analysis/tree/master/results


**Describe the expected behavior**

probably execution time of model might not improve when disabling certain HLO passes (which might not be useful to a model).  

**Standalone code to reproduce the issue**
https://github.com/mmadala95/xla_analysis/blob/master/ResNet50_xla.py



"
42206,tf.nn.avg_pool3d crashes (floating point exception) in NDHWC mode,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.6.9
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.nn.avg_pool3d` crashes (floating point exception) when `data_format` = NDHWC AND 0 in input.shape, such as `(1,1,0,1,1)`.  Related #42205

**Describe the expected behavior**
expect no crashes
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
input=tf.ones((1,1,0,1,1))
tf.nn.avg_pool3d(input=input,ksize=1,strides=1,padding='SAME', data_format='NDHWC')
~~~

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
Floating point exception (core dumped)
~~~

Related #42205"
42205,tf.nn.avg_pool3d crashes(floating point exception) when `input` contain large value and stride=0,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.6.9
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

`tf.nn.avg_pool3d` crashes(floating point exception) when `input` contain large value and `stride=0`. Related #42206

**Describe the expected behavior**

Expect no crashes

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
import numpy as np
input = tf.constant( [[[[[1e+40]]]]], dtype=np.float64)
tf.nn.avg_pool3d(input=input,ksize=1,strides=0,padding='SAME')
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
Floating point exception (core dumped)
~~~
Related #42206"
42204,Add random shear to keras.layers.experimental.preprocessing,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.3
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Right now, keras.layers.experimental.preprocessing contains layers for random contrast, width, height, rotation etc but not for random shears. Wouldn't this be a good home for a preprocessing layer that randomly shears an image?

**Will this change the current api? How?**
It will add another class to the public outward facing tf.keras.layers.experimental.preprocessing namespace, something along the lines of `class RandomShear`

**Who will benefit with this feature?**
Users who build image preprocessing into their networks. A layer like this one will allow users to easily preprocess images with random shears, rather than creating custom layers.

**Any Other info.**
"
42203,tf.nn.space_to_depth and tf.nn.depth_to_space crashes (segfault) in `NCHW_VECT_C ` mode with certain input,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.6.9
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

`tf.nn.space_to_depth ` and `tf.nn.depth_to_space` crashes (segfault) in when `input` is of length EXACTLY 4, `block_size>1` and `data_format=NCHW_VECT_C`.

**Describe the expected behavior**

Expect no segfault


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

~~~python
import tensorflow as tf
tf.nn.space_to_depth(input=tf.zeros((4)), block_size = 2, data_format ='NCHW_VECT_C')
tf.nn.depth_to_space(input=tf.zeros((4)), block_size = 2, data_format ='NCHW_VECT_C')
~~~

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
Segmentation fault (core dumped)
~~~"
42201,Confusing error in gradient of assign_add + while_loop + gather,"**Describe the current behavior**
Autograph produces a static graph with the wrong number of inputs when a trainable variable is in a separate class. I also get a warning about converting a sparse op to a dense one, which seems to be related (while to gather, problem goes away when removed).

**Describe the expected behavior**
The function should execute without errors.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1x36cCyKsSxsOCw1Z4mnR4AzbwDSuXzTY#scrollTo=O6GzPt2gZiPF"
42200,GPUs idle between batches during multi-worker training with Keras ,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux 7 (Core)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla K40 11441MiB
 
**Describe the current behavior**
I have a setup of two workers in a cluster, and each worker has 4 GPUs. I have slightly changed the network in ""Mnist Multi-worker training with Keras"" tutorial to a deeper network. The training progress is way slower than just training on a single machine using tf.distribute.MirroredStrategy. Looking at GPU loads using nvidia-smi, I see that the GPUs are Idle for about 2 seconds before the load goes to 99%.  I also ran profiling on the workers between batch 10 and 11 using Tensorboard, and I can see that the majority of time is spent on colelctive_ops.

**Describe the expected behavior**
I was expecting 2X speed up on training with two workers(Total 8 GPUS) than training on a single machine(4 GPUs) using MirroredStrategy.

**Standalone code to reproduce the issue**
**Worker 1:** 
```
from datetime import datetime
from packaging import version
import os
import tensorflow as tf
import numpy as np
import json
import tensorflow as  tf


os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""node72:12345"", ""node67:23456""]
    },
    'task': {'type': 'worker', 'index': 0}
})

# Create a TensorBoard callback
logs = ""logs/"" + datetime.now().strftime(""%Y%m%d-%H%M%S"")

tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,
                                                 histogram_freq = 1,
                                                 profile_batch = '10,11')

def mnist_dataset(batch_size):
    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()
    # The `x` arrays are in uint8 and have values in the range [0, 255].
    # We need to convert them to float32 with values in the range [0, 1]
    x_train = x_train / np.float32(255)
    y_train = y_train.astype(np.int64)
    train_dataset = tf.data.Dataset.from_tensor_slices(
      (x_train, y_train)).shuffle(60000).cache().repeat().batch(batch_size)
    return train_dataset


def build_and_compile_cnn_model():
    model = tf.keras.Sequential([
      tf.keras.Input(shape=(28, 28)),
      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
      tf.keras.layers.Conv2D(256, 2, activation='relu'),
      tf.keras.layers.Conv2D(128, 2, activation='relu'),
      tf.keras.layers.Conv2D(32, 1, activation='relu'),  
      tf.keras.layers.Conv2D(32, 2, activation='relu'),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(2048, activation='relu'),        
      tf.keras.layers.Dense(1024, activation='relu'),        
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dense(10)
    ])
    model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
      metrics=['accuracy'])
    return model

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

num_workers = 2
per_worker_batch_size = 2048
# Here the batch size scales up by number of workers since 
# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, 
# and now this becomes 128.
global_batch_size = per_worker_batch_size * num_workers
multi_worker_dataset = mnist_dataset(global_batch_size)

with strategy.scope():
  # Model building/compiling need to be within `strategy.scope()`.
  multi_worker_model = build_and_compile_cnn_model()

# Keras' `model.fit()` trains the model with specified number of epochs and
# number of steps per epoch. Note that the numbers here are for demonstration
# purposes only and may not sufficiently produce a model with good quality.
multi_worker_model.fit(multi_worker_dataset, epochs=20, steps_per_epoch=20,callbacks = [tboard_callback])

```


**Worker 2:** 

```
from datetime import datetime
from packaging import version
import os
import tensorflow as tf
import numpy as np
import json
import tensorflow as  tf


os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""node72:12345"", ""node67:23456""]
    },
    'task': {'type': 'worker', 'index': 1}
})

# Create a TensorBoard callback
logs = ""logs/"" + datetime.now().strftime(""%Y%m%d-%H%M%S"")

tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,
                                                 histogram_freq = 1,
                                                 profile_batch = '10,11')

def mnist_dataset(batch_size):
    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()
    # The `x` arrays are in uint8 and have values in the range [0, 255].
    # We need to convert them to float32 with values in the range [0, 1]
    x_train = x_train / np.float32(255)
    y_train = y_train.astype(np.int64)
    train_dataset = tf.data.Dataset.from_tensor_slices(
      (x_train, y_train)).shuffle(60000).cache().repeat().batch(batch_size)
    return train_dataset


def build_and_compile_cnn_model():
    model = tf.keras.Sequential([
      tf.keras.Input(shape=(28, 28)),
      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
      tf.keras.layers.Conv2D(256, 2, activation='relu'),
      tf.keras.layers.Conv2D(128, 2, activation='relu'),
      tf.keras.layers.Conv2D(32, 1, activation='relu'),  
      tf.keras.layers.Conv2D(32, 2, activation='relu'),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(2048, activation='relu'),        
      tf.keras.layers.Dense(1024, activation='relu'),        
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dense(10)
    ])
    model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
      metrics=['accuracy'])
    return model

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

num_workers = 2
per_worker_batch_size = 2048
# Here the batch size scales up by number of workers since 
# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, 
# and now this becomes 128.
global_batch_size = per_worker_batch_size * num_workers
multi_worker_dataset = mnist_dataset(global_batch_size)

with strategy.scope():
  # Model building/compiling need to be within `strategy.scope()`.
  multi_worker_model = build_and_compile_cnn_model()

# Keras' `model.fit()` trains the model with specified number of epochs and
# number of steps per epoch. Note that the numbers here are for demonstration
# purposes only and may not sufficiently produce a model with good quality.
multi_worker_model.fit(multi_worker_dataset, epochs=20, steps_per_epoch=20,callbacks = [tboard_callback])


```



**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
<img width=""987"" alt=""image"" src=""https://user-images.githubusercontent.com/3833065/89832661-a9fa8400-db2d-11ea-848b-fa34ef9c26a6.png"">
<img width=""966"" alt=""image"" src=""https://user-images.githubusercontent.com/3833065/89832872-01005900-db2e-11ea-984e-a4a264508080.png"">"
42199,Cannot find libcudnn.so.7 ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: 10.1/8.0.2.39
- GPU model and memory: NVIDIA GeForce GTX 1050 Mobile

**Describe the current behavior**

I get the following error when I check my GPU with tensorflow:
`W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory`

I found this forum thread and it was suggest to create symlinks as follows:
https://github.com/tensorflow/tensorflow/issues/20271
`cd /usr/local/cuda-10.1/lib64
sudo ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5 libcudnn.so.7
sudo ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5 libcudnn.so`

I tried this but I'm still getting an error. I should note that I linked `libcudnn.so.8` and `libcudnn.so.8.0.2` instead of 7.6.5. (7.6.5 and .so.7 were not included in my installation). Do I need to download libcudnn.so.7 separately?

Any advice is appreciated


**Describe the expected behavior**
I assume that this error should not appear. 

**Standalone code to reproduce the issue**
I get this issue after checking the status of my GPU with: `tf.config.list_physical_devices('GPU')` 

**Other info / logs** 
This is the full message that I get when I check the status of my GPU:
`2020-08-10 14:40:36.820491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-10 14:40:36.821735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-08-10 14:40:36.821834: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-10 14:40:36.821900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-10 14:40:36.821953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-10 14:40:36.822004: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-10 14:40:36.822054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-10 14:40:36.822103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-10 14:40:36.822367: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory
2020-08-10 14:40:36.822401: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...`


**EDIT:** I'm not sure if this constitutes a ""bug"", happy to repost as a request for support if necessary."
42198,How to load onnx model in Keras,"Hello!
Keras version: 2.4.3
Tensorflow version: 2.2.0
Python version:  3.7.7
OS: Windows 10 x64

I want to load onnx model [(this yolov3 model)](https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3) in keras.
I download this model and run command to convert onnx to pb file, like this:
**nnx-tf convert -i yolov3.onnx -o saved_model.pb**
this command was taken from [link](https://github.com/onnx/onnx-tensorflow)
Command finished with success!
Then i try to load pb file like this:
` from tensorflow import keras
  model = keras.models.load_model('my path to folder with saved_model.pb file')`

And result is error:
 **String field 'tensorflow.MetaGraphDef.MetaInfoDef.meta_graph_version' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes.**

Please help"
42197,"After updtae Anaconda, tf is not working","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
42193,Keras RNNs do not respect get_initial_state if stateful=True,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**

RNNs created with `stateful=True` always start with all-zero initial state, even if there is a `get_initial_state` function defined.

**Describe the expected behavior**

The state variables should be initialized with the values returned by `get_initial_state`

**Standalone code to reproduce the issue**

``` python
import tensorflow as tf
import numpy as np


class TestCell(tf.keras.layers.Layer):
    state_size = 1
    output_size = 1

    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):
        return tf.ones((batch_size, 1), dtype=dtype)

    def call(self, inputs, states):
        tf.assert_equal(states, 1.0)
        return inputs, states


layer = tf.keras.layers.RNN(TestCell(), stateful=True)

x = np.ones((1, 10, 1), dtype=np.float32)

layer(x)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Condition x == y did not hold.
First 1 elements of x:
[0.]
First 1 elements of y:
[1.]
```
"
42192,"DLL load failed for Tensorflow-GPU==1.14, with CUDA 10.0","**System information**
CUDA Version: 10.0
CUDNN Version: 7
OS: Windows 10
Python version: 3.6
GPU: Geforce mx150

I cloned a github repository that requires tensorflow 1.13-1.14, so I just made a new virtual environment and installed tensorflow-gpu==1.14, which installed without any problems.

Then I tried to run a session in order to see that things were working:

```
import tensorflow as tf
sess = tf.Session()

```
However, when I run the above, I get the following error:

```
Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2020.1.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\alyfl\.virtualenvs\trRosetta_gpu\lib\site-packages\tensorflow\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2020.1.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\alyfl\.virtualenvs\trRosetta_gpu\lib\site-packages\tensorflow\python\__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2020.1.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\alyfl\.virtualenvs\trRosetta_gpu\lib\site-packages\tensorflow\core\framework\graph_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2020.1.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\alyfl\.virtualenvs\trRosetta_gpu\lib\site-packages\google\protobuf\descriptor.py"", line 48, in <module>
    from google.protobuf.pyext import _message
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2020.1.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
ImportError: DLL load failed: The specified procedure could not be found.
```
I just installed CUDA 10.0, since I realized that this old version of tensorflow would require that version (and restarted afterwards). I have confirmed that CUDA 10.0 is in my path environment, and that it seems to be the version linked in python as shown below:

```
from tensorflow.python.platform import build_info as tf_build_info
print(tf_build_info.cuda_version_number)
>10.0
print(tf_build_info.cudnn_version_number)
>7

```

I'm not really sure what exactly is going wrong here, and the error messages aren't much help either at this point"
42190,[TFlite]: Failed to instantiate the interpreter with a StyleGAN2 generator model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel4, Samsung Galaxy S9+
- TensorFlow installed from (source or binary): binary
- TensorFlow version on desktop (use command below): tensorflow 2.2.0 + tensorflow-gpu 2.2.0
- TensorFlow lite version on mobile: tensorflow-lite:0.0.0-nightly + tensorflow-lite-gpu:0.0.0-nightly
- Python version: 3.6.10
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: V10.2.89
- GPU model and memory: 4* TITAN RTX 24GB

**Describe the current behavior**
I used `tf.compat.v1.lite.TFLiteConverter.from_session` to convert StyleGAN2 generator in Tensorflow lite format. the conversion  gives no error and no warning.
The option used for the conversion are as follow:
`converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]`
On phone, the interpreter instanciation fails when running on CPU: `tflite = new Interpreter(tfliteModel, tfliteOptions);` gives the following error:
`Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:111 op_context.dims <= reference_ops::PadKernelMaxDimensionCount() was not true.
    Node number 239 (PAD) failed to prepare.`
When trying to use GPU or NNAPI delegates, i have the same kind of error:
`java.lang.RuntimeException: Unable to start activity ComponentInfo{org.pytorch.helloworld/org.pytorch.helloworld.MainActivity}: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: tensorflow/lite/kernels/pad.cc:111 op_context.dims <= reference_ops::PadKernelMaxDimensionCount() was not true.
    Node number 239 (PAD) failed to prepare.`

**Describe the expected behavior**
I expect the model to be able to execute whatever target (CPU/GPU/NNAPI) is used, but most likely on NNAPI or GPU to get the best performances.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs**
I tried several things to cope with this issue. When using the following option:
`converter.target_ops=SELECT_TF_OPS`
It is working on CPU, but fails with another error on GPU: 
`ignoring failed delegate application: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.`
I guess this is because these target ops are not compatible with GPU and NNAPI delegates.

I also tried to use converter v2 using the following method:
`converter =  tf.lite.TFLiteConverter.from_concrete_functions([func])`
But the model size is very huge (624MB instead of 110MB for converter.v1) and i faced the same error when running on mobile: 
` Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:111 op_context.dims <= reference_ops::PadKernelMaxDimensionCount() was not true.
    Node number 221 (PAD) failed to prepare.`

"
42189,No gradient defined for operation RaggedTensorFromVariant,"hello , 

I having an issue with training a simple model with RaggedTensors and Tendorflow is throwing the below error :
`""No gradient defined for operation RaggedTensorFromVariant""`
**System information**
-Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
-OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
-Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
-TensorFlow installed from (source or binary): Binary
-TensorFlow version (use command below): '2.3.0'
-Python version: 3.7
-Bazel version (if compiling from source): NA
-GCC/Compiler version (if compiling from source): NA
-CUDA/cuDNN version: 10.1
-GPU model and memory: RTX 2080 TI
You can collect some of this information using our environment capture

**Describe the current behavior**
I'm unable to calculate the gradient of the dense values of a Ragged Tensor when RaggedTensors has been  used inside tf.map_fn.  below is the error that i get when running my code : 
`LookupError: No gradient defined for operation 'map_16/RaggedFromVariant/RaggedTensorFromVariant' (op type: RaggedTensorFromVariant)`

**Describe the expected behavior**
I believe that tensorflow should be able to handle such operations and be able to calculate the gradient especially that the values component of a raggedTensor is normal dense Tensor.  
**Standalone code to reproduce the issue**
```
import tensorflow.compat.v1 as tf
tf.compat.v1.disable_eager_execution()
tf.disable_v2_behavior()
import numpy as np 
myTensor = tf.ragged.placeholder(dtype=tf.float32 , ragged_rank=1)
def matmul_ragged( a) : 
    tens= a 
    con5 = tf.Variable([[0.1 , 2.11 , 11.2 ] ,[5.0 , 0.0 , 15.11 ] ])
    mat=tf.matmul(tens,con5)
    return mat
 
struct = tf.RaggedTensorSpec(shape=[None,None] , ragged_rank=0 ,dtype=tf.float32)
final_answer = tf.map_fn(matmul_ragged ,myTensor, fn_output_signature=struct)
print(final_answer)
loss = tf.reduce_mean(final_answer.values)
optimizer = tf.train.AdamOptimizer(learning_rate=.001)  # Adam Optimizer
opt_op = optimizer.minimize(loss)

with tf.Session() as sess : 
    sess.run(tf.global_variables_initializer())
    vals =tf.ragged.RaggedTensorValue(np.array([[1.0, 2.2 ]  , [4.0, 5.0]  , [6.0, 7.0] ,  [8.0, 9.0] , [10.11, 10.11]]) , np.array([0, 2, 5]))
    re    = sess.run([final_answer  ] , feed_dict={myTensor:vals} )
    print(re)
```

Below is a error stack that I get 

```
LookupError                               Traceback (most recent call last)
C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\ops\gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    606           try:
--> 607             grad_fn = ops.get_gradient_function(op)
    608           except LookupError:

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\framework\ops.py in get_gradient_function(op)
   2654     op_type = op.type
-> 2655   return _gradient_registry.lookup(op_type)
   2656 

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\framework\registry.py in lookup(self, name)
     96       raise LookupError(
---> 97           ""%s registry has no entry for: %s"" % (self._name, name))

LookupError: gradient registry has no entry for: RaggedTensorFromVariant

During handling of the above exception, another exception occurred:

LookupError                               Traceback (most recent call last)
<ipython-input-17-8c10c3f6b529> in <module>
     23 loss = tf.reduce_mean(final_answer.values)
     24 optimizer = tf.train.AdamOptimizer(learning_rate=.001)  # Adam Optimizer
---> 25 opt_op = optimizer.minimize(loss)
     26 
     27 with tf.Session() as sess :

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\training\optimizer.py in minimize(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)
    401         aggregation_method=aggregation_method,
    402         colocate_gradients_with_ops=colocate_gradients_with_ops,
--> 403         grad_loss=grad_loss)
    404 
    405     vars_with_grad = [v for g, v in grads_and_vars if g is not None]

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\training\optimizer.py in compute_gradients(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)
    510         gate_gradients=(gate_gradients == Optimizer.GATE_OP),
    511         aggregation_method=aggregation_method,
--> 512         colocate_gradients_with_ops=colocate_gradients_with_ops)
    513     if gate_gradients == Optimizer.GATE_GRAPH:
    514       grads = control_flow_ops.tuple(grads)

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\ops\gradients_impl.py in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)
    170         ys, xs, grad_ys, name, colocate_gradients_with_ops,
    171         gate_gradients, aggregation_method, stop_gradients,
--> 172         unconnected_gradients)
    173   # pylint: enable=protected-access
    174 

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\ops\gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    621               raise LookupError(
    622                   ""No gradient defined for operation '%s' (op type: %s)"" %
--> 623                   (op.name, op.type))
    624         if loop_state:
    625           loop_state.EnterGradWhileContext(op, before=False)

LookupError: No gradient defined for operation 'map_16/RaggedFromVariant/RaggedTensorFromVariant' (op type: RaggedTensorFromVariant)`

```
I would appreciate your help to fix this bug or if possible guide me on a work around. 

Thanks 
"
42188,Tflite convertor inserted additional 1x1 conv layers,"@tensorflow/micro

**System information**
- Windows 10
- pip install tensorflow==2.1.0

**Describe the problem**
I made a model with tf.keras, converted it using TensorflowLite and got strange redundant layers 4 1x1 conv layers.

**Please provide the exact sequence of commands/steps when you ran into the problem**
This is my script

`
import tensorflow as tf
from tflite_runtime.interpreter import Interpreter
import numpy as np
import os
unixToolsPaths=r'C:\ARC_2019_12\tools\make;C:\ARC_2019_12\tools\cmake\bin;C:\ARC_2019_12\tools\usr\x86_64-pc-msys\bin;C:\ARC_2019_12\tools\usr\bin;'
os.environ['PATH'] += unixToolsPaths
import subprocess

def makeModel():
    inputs = tf.keras.Input(shape=(49, 10, 1))
    x = tf.keras.layers.Conv2D( 64, (10,4), (2, 2), padding='same', activation='relu')(inputs)
    x = tf.keras.layers.SeparableConv2D( 64, (3,3), padding='same')(x)
    x = tf.keras.layers.Conv2D( 64, (1,1), padding='valid', activation='relu')(x)
    x = tf.keras.layers.SeparableConv2D( 64, (3,3), padding='same')(x)
    x = tf.keras.layers.Conv2D( 64, (1,1), padding='valid', activation='relu')(x)
    x = tf.keras.layers.SeparableConv2D( 64, (3,3), padding='same')(x)
    x = tf.keras.layers.Conv2D( 64, (1,1), padding='valid', activation='relu')(x)
    x = tf.keras.layers.SeparableConv2D( 64, (3,3), padding='same')(x)
    x = tf.keras.layers.Conv2D( 64, (1,1), padding='valid', activation='relu')(x)
    x = tf.keras.layers.AveragePooling2D((25, 5))(x)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(2)(x)
    x = tf.keras.layers.Softmax()(x)
    model = tf.keras.Model(inputs=inputs, outputs=x)
    return model


def quantizationDataGenerator():
    for i in range(10):
        yield [ np.random.rand(1, 49, 10, 1).astype(np.float32)]

def convertTFL(name, model):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = quantizationDataGenerator
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8
    quantModel = converter.convert()

    with open(""{}.tflite"".format(name), ""wb"") as f:
        f.write(quantModel)

def convertToCC(file, ccFile):
    subprocess.run(r'xxd -i {} > {}'.format(file, ccFile), shell=True, check=True)
    
    with open(ccFile, 'r') as f:
        linesOrig = f.readlines()
    lines = [
        'unsigned char modelBuffer[] DATA_ALIGN_ATTRIBUTE = {\n'
    ]
    lines.extend(linesOrig[1:-1])
                
    with open(ccFile, 'w') as f:
        f.writelines(lines)
        

if __name__ == '__main__':
    name = 'kws'
    model = makeModel()
    model.summary() 
    convertTFL(name, model)
`

"
42186,Failed to load the native TensorFlow runtime.,"**System information**
- OS Platform and Distribution windows 10
- TensorFlow installed from source
- TensorFlow 2.3
- Python 3.8
- Installed using conda




**Describe the problem**

I am just trying to a run a code that i downloaded from github if someone can help this is my first time using tensorflow.

**Any other info / logs**
[Running] python -u ""c:\Users\projects\Desktop\Machine and  Deep learning\TensorflowProjects-master\TensorflowProjects-master\MNIST\HelloTensor.py""
Traceback (most recent call last):
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\Users\projects\Desktop\Machine and  Deep learning\TensorflowProjects-master\TensorflowProjects-master\MNIST\HelloTensor.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

[Done] exited with code=1 in 145.607 seconds

[Running] python -u ""c:\Users\projects\Desktop\Machine and  Deep learning\TensorflowProjects-master\TensorflowProjects-master\EmotionDetection\EmotionDetector.py""
Traceback (most recent call last):
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\Users\projects\Desktop\Machine and  Deep learning\TensorflowProjects-master\TensorflowProjects-master\EmotionDetection\EmotionDetector.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

[Done] exited with code=1 in 366.04 seconds

[Running] python -u ""c:\Users\projects\Desktop\Machine and  Deep learning\TensorflowProjects-master\TensorflowProjects-master\EmotionDetection\EmotionDetector.py""
Traceback (most recent call last):
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\Users\projects\Desktop\Machine and  Deep learning\TensorflowProjects-master\TensorflowProjects-master\EmotionDetection\EmotionDetector.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\projects\.conda\envs\tensorflow\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

[Done] exited with code=1 in 196.316 seconds
"
42185,Node number 241 (TfLiteFlexDelegate) failed to invoke.,"**System information**
- OS Platform  : TFlite C++ API on Android Platform
- TensorFlow version : tf-nightly 2.4.0

**I have build tflite C library with Flex Op module.

But when I test it with a Tflite model which contain flex ops, I have got a error while invoke：**

 op_kernel.cc:1772 OP_REQUIRES failed at tensor_array_ops.cc:1035 : Not found: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)
Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)
    	 (while executing 'TensorArrayScatterV3' via Eager)
Node number 241 (TfLiteFlexDelegate) failed to invoke.

Has anyone encountered such a problem?
"
42184,Get error during converting ResizeNearestNeighbor to tflite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Arch Linux
- TensorFlow installed from (source or binary):  package manager
- TensorFlow version (or github SHA if from source):  2.2.0 - 1


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
tflite_model_quant = converter.convert()
```

**The output from the converter invocation**

```
# Copy and paste the output here.
2020-08-10 18:10:20.777385: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
loc(callsite(""sequential/up_sampling2d/resize/ResizeNearestNeighbor""(""/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":865:0) at callsite(""/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":959:0 at callsite(""/usr/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"":435:0 at ""test.py"":51:0)))): error: 'tf.ResizeNearestNeighbor' op is neither a custom op nor a flex op
error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): ResizeNearestNeighbor.
Traceback (most recent call last):
  File ""/usr/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/lib/python3.8/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/lib/python3.8/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/lib/python3.8/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/usr/lib/python3.8/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 50, in execute
    output_str = _pywrap_toco_api.TocoConvert(
Exception: /usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:865:9: error: 'tf.ResizeNearestNeighbor' op is neither a custom op nor a flex op
        self._initialize(args, kwargs, add_initializers_to=initializers)
        ^
/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:959:5: note: called from
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
    ^
/usr/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:435:5: note: called from
    concrete_func = func.get_concrete_function()
    ^
test.py:51:1: note: called from
converter = tf.lite.TFLiteConverter.from_keras_model(model)
^
<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): ResizeNearestNeighbor.

```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
Conversion fails.

In the attachment zip file, there is a .py file that you can run and reproduce the error. The code is originally from this tutorial:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb

The cause of the failure is that I added a UpSampling2D layer with ""nearest neighbor"" in the model and do ""Convert using integer-only quantization"".  Everything is ok if I delete UpSampling2D, or use UpSampling2D with ""bilinear"".

[test.zip](https://github.com/tensorflow/tensorflow/files/5050250/test.zip)


"
42183,Adam optimizer - ValueError: tf.function-decorated function tried to create variables on non-first call,"I am using tensorflow 2.3

The code below 



    import  tensorflow as tf
    
    y_N= tf.Variable([1., 2., 3.],name=""dd"")
    
    @tf.function
    def loss():
        return -tf.reduce_mean(input_tensor=tf.reduce_sum(input_tensor=tf.math.log(y_N), axis=0))
    
    @tf.function
    def run():
        tf.keras.optimizers.Adam(0.5).minimize(loss, var_list=[y_N])
    
    run()

gives exception

    ValueError: tf.function-decorated function tried to create variables on non-first call.

Problem looks like `tf.keras.optimizers.Adam(0.5).minimize(loss, var_list=[y_N])` creates new variable on > first call, while using `@tf.function`. If I must wrap adam_optimizer under `@tf.function`, is it possible? looks like a bug?"
42182,Not every keras.metrics.* accept from_logits=True,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Linux Ubuntu 18.04.3
- TensorFlow installed from: binary (Docker Image tensorflow:2.3.0-gpu)
- TensorFlow version: v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.6.9 
- CUDA/cuDNN version: CUDA10.2
- GPU model and memory: RTX 2080 8GB


**Describe the current behavior**
The issue is the same as described by MeghnaNatraj in ticket [37103](https://github.com/tensorflow/tensorflow/issues/37103). The mentioned ticket states the problem has been solved. I was requested to open a new ticket.

If I have a model with an output layer of one neuron and 'sigmoid' activation function and using BinaryCrossentropy(from_logits=False), then the model.fit() function accepts any metrics (e.g. Precision)
If I have the same model as before but without activation function and BinaryCrossentropy(from_logits=True), then model.fit() function will return an error.

**Describe the expected behavior**
- Having a model, which has an output layer without an activation function: keras.layers.Dense(1) # Output range is [-inf, +inf]
- Loss function of the model working with logits: BinaryCrossentropy(from_logits=True)
- Accepting metrics during fitting like keras.metrics.Precision

**Standalone code to reproduce the issue**
I have copied the same test code by MeghnaNatraj in ticket [37103](https://github.com/tensorflow/tensorflow/issues/37103) 

```
# INITIALIZE

import tensorflow as tf
import numpy as np
# define dataset
dataset = np.array([[6,148,72,35,0,33.6,0.627,50,1],
[1,85,66,29,0,26.6,0.351,31,0],
[8,183,64,0,0,23.3,0.672,32,1],
[1,89,66,23,94,28.1,0.167,21,0],
[0,137,40,35,168,43.1,2.288,33,1]])
# split into input (X) and output (y) variables
X = dataset[:,0:8]
y = dataset[:,8]
```

```
# WORKS: Model output is in range [0, 1]
# define the keras model
model = tf.keras.models.Sequential([tf.keras.layers.Dense(12, input_dim=8, activation='relu'),
                                    tf.keras.layers.Dense(1, activation='sigmoid')])
# compile the keras model
model.compile(loss=tf.keras.losses.BinaryCrossentropy(),
              optimizer=tf.keras.optimizers.RMSprop(),
              metrics=[tf.keras.metrics.Accuracy(name='accuracy'),
                       tf.keras.metrics.Precision(name='precision'),
                       tf.keras.metrics.TruePositives(name='tp')])
# fit the keras model on the dataset
model.fit(X, y, epochs=10, batch_size=10, verbose=0)
```

```
# DOES NOT WORK: Model output is in range [-inf, inf]
# define the keras model
model = tf.keras.models.Sequential([tf.keras.layers.Dense(12, input_dim=8, activation='relu'),
                                    tf.keras.layers.Dense(1)])
# compile the keras model
model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              optimizer=tf.keras.optimizers.RMSprop(),
              metrics=[tf.keras.metrics.Accuracy(name='accuracy'),
                       tf.keras.metrics.Precision(name='precision'),
                       tf.keras.metrics.TruePositives(name='tp')])
# fit the keras model on the dataset
model.fit(X, y, epochs=10, batch_size=10, verbose=0)

InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential_8/dense_17/BiasAdd:0) = ] [[22.0911655][62.7297783][35.2793274]...] [y (metrics/precision/Cast_3/x:0) = ] [1]
	 [[{{node metrics/precision/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]]
	 [[metrics/tp/assert_greater_equal/Assert/AssertGuard/pivot_f/_31/_61]]
  (1) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential_8/dense_17/BiasAdd:0) = ] [[22.0911655][62.7297783][35.2793274]...] [y (metrics/precision/Cast_3/x:0) = ] [1]
	 [[{{node metrics/precision/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_distributed_function_12253]

Function call stack:
distributed_function -> distributed_function

Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1098, in fit
    tmp_logs = train_function(iterator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 840, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 550, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential/dense_1/BiasAdd:0) = ] [[28.8497276][37.4658966][48.6209221]...] [y (Cast_5/x:0) = ] [1]
         [[{{node assert_less_equal/Assert/AssertGuard/else/_11/assert_less_equal/Assert/AssertGuard/Assert}}]]
         [[assert_less_equal_1/Assert/AssertGuard/pivot_f/_41/_81]]
  (1) Invalid argument:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (sequential/dense_1/BiasAdd:0) = ] [[28.8497276][37.4658966][48.6209221]...] [y (Cast_5/x:0) = ] [1]
         [[{{node assert_less_equal/Assert/AssertGuard/else/_11/assert_less_equal/Assert/AssertGuard/Assert}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_1165]
```
"
42181,TensorArray cannot be converted with TFLiteConverter,"I want to use a `tf.TensorArray` in a decoding-loop in order to collect predicted ids from the model (for later conversion to text. However, it seems that `tf.TensorArray` makes issues when trying to convert it with `TFLiteConverter`.

**System information**
- OS Platform and Distribution: Ubuntu 16.04
- TensorFlow installed from: binary
- TensorFlow version: 2.3.0
- Python version: 3.8 (Conda)
- CUDA/cuDNN version: 10.1

**Describe the current behavior**

Converting a function which uses `tf.TensorArray` throws an exception saying

```none
error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
```

**Describe the expected behavior**

Convert the model without errors.

**Standalone code to reproduce the issue**

```python
import tensorflow as tf


@tf.function
def tensor_array():
    outputs = tf.TensorArray(dtype=tf.int32, size=1, dynamic_size=True)
    outputs = outputs.write(0, 1)
    outputs = outputs.write(1, 2)
    outputs = outputs.write(2, 3)
    return outputs.gather(tf.range(outputs.size()))


def main():
    concrete_fn = tensor_array.get_concrete_function()
    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_fn])
    converter.experimental_new_converter = True
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
    tflite_model = converter.convert()

    with open('model.tflite', 'wb') as f:
        f.write(tflite_model)


if __name__ == '__main__':
    main()
```

**Other info / logs** 

```none
2020-08-10 10:28:45.806093: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-08-10 10:28:45.809971: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize
2020-08-10 10:28:45.809981: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.004ms.
2020-08-10 10:28:45.809988: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-10 10:28:45.822697: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-08-10 10:28:45.822721: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
loc(callsite(""TensorArrayV2""(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py"":464:0) at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py"":1071:0 at callsite(""/home/sfalk/tmp/my-speech-v2/asr/bin/tensor_array.py"":6:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"":962:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":600:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"":986:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py"":3065:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py"":3213:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py"":2855:0 at ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":696:0)))))))))): error: requires element_shape to be 1D tensor during TF Lite transformation pass
loc(callsite(""TensorArrayV2""(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py"":464:0) at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py"":1071:0 at callsite(""/home/sfalk/tmp/my-speech-v2/asr/bin/tensor_array.py"":6:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"":962:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":600:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"":986:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py"":3065:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py"":3213:0 at callsite(""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py"":2855:0 at ""/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":696:0)))))))))): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
```
"
42180,"While Tensorflow usually uses GatherV2, TFLite only supports Gather","<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): v2.3.0
- Are you willing to contribute it (Yes/No): No


**Describe the feature and the current behavior/state.**
While TensorFlow converts tf.gather to GatherV2, TFlite only supports Gather.
So we cannot directly convert tf.gather to TFlite. I think it doesn't make sense.
(Flex delegate somehow works, though)
I argue that TFLite should support GatherV2.

**Will this change the current api? How?**
Since it only requires to modify the underlying kernel, user API would not be changed.

**Who will benefit with this feature?**
The one who wants to use gather and convert their model to TFlite
**Any Other info.**
"
42178,Capability to get probabilities for each tag in crf_decode,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.15
- Are you willing to contribute it (Yes/No): Yes


**Describe the feature and the current behavior/state.**
I am talking about this specific repository.
[https://github.com/tensorflow/addons/blob/v0.10.0/tensorflow_addons/text/crf.py](url)

For now crf_decode function returns the tag indices with highest probability and a viterbi score for the whole sequence.
But the crf_decode do not returns the probabilities for every tag for each token in sequence like we get in softmax.
So I request to please add this capability because probabilities of tags help us know the confidence score and many more things.


**Will this change the current api? How?**
Yes, it will support more capabilities.

**Who will benefit with this feature?**
I believe many developers around the globe are looking for this feature.

**Any Other info.**
Please add it as soon as possible."
42177,Fused conv implementation does not support grouped convolutions for now,"
![image](https://user-images.githubusercontent.com/12997948/89756964-837d1e80-db16-11ea-98a9-262719e3bc72.png)

`Fused conv implementation does not support grouped convolutions for now`

What should i do ？"
42176,TF Lite version for examples/lite/examples/image_classification,"I tried to run image classification demo on Android based on the following link. It can work successfully.
https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/android/README.md

I have a question about the version number for this TF Lite. I want to know weather this demo is using libtflite.so in my Android OS or some other TF Lite version?

Thanks."
42175,ValueError: Data cardinality is ambiguous. No issue in version 2.0.0 but fails with 2.2.0/2.3.0,"### Functional API Multi input/output model works correctly in TF 2.0.0 but fails with TF 2.2.0 and 2.3.0

**Describe the current behavior**
Created a Multi Input/Output model using the functional api.
model.fit fails with the following error:
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-6-20532c7b88ab> in <module>()
     11 print('x',np.asarray(x).shape)
     12 print('y',y.shape)
---> 13 model.fit(x,y,epochs=1)

3 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)
    280             label, "", "".join(str(i.shape[0]) for i in nest.flatten(data)))
    281       msg += ""Please provide data which shares the same first dimension.""
--> 282       raise ValueError(msg)
    283     num_samples = num_samples.pop()
    284 

ValueError: Data cardinality is ambiguous:
  x sizes: 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224
  y sizes: 2
Please provide data which shares the same first dimension.
```
Colab Github Gist: https://colab.research.google.com/gist/sramakrishnan247/0897350c315280935b1617e325665c08/tf2-3-issue.ipynb

**Describe the expected behavior**
model.fit should work successfully (similar to tensorflow 2.0.0)
```
x (10, 2, 224, 224, 20)
y (2, 3)
Train on 2 samples
14/2 [==================================================================================================================================================================================================================] - 34s 2s/sample - loss: 1.4392
<tensorflow.python.keras.callbacks.History at 0x7f444928b048>
```
Colab Github gist: https://colab.research.google.com/gist/sramakrishnan247/08becc3e024ad21a2b90fa2ebabcfe76/tf2-0-sample.ipynb"
42174,some question about grpc+verbs and grpc+gdr,"when i use gdr, but the server_protocol can be use grpc+gdr or grpc+verbs.
i followed this script, and nv_peer_mem is loaded.
[gdr](https://github.com/tensorflow/tensorflow/tree/v1.8.0/tensorflow/contrib/gdr)
but the performance of grpc+gdr is worse, why?"
42172,`DepthwiseConv2D` is no faster than `Conv2D`,"I'm reimplementing [MobileNet](https://arxiv.org/abs/1704.04861), but I find the depthwise convolution is no faster than conv2d(I haven't included the 1 by 1 pointwise convolution yet). Here's the test code run on colab: https://colab.research.google.com/drive/1nBuYrmmH5kM0jbtIZdsuiG6uJbU6mpA7?usp=sharing

```python
import tensorflow as tf
import time
x = tf.random.normal((2, 64, 64, 3))
conv = tf.keras.layers.Conv2D(16, 3, strides=1, padding='same')
dw = tf.keras.layers.DepthwiseConv2D(3, padding='same')
start = time.time()
conv(x)
print('conv2d:', time.time() - start)    # approximate 0.0036s
start = time.time()
dw(x)
print('dw:', time.time() - start)    # approximate 0.0034s
%timeit conv(x)    # 1000 loops, best of 3: 225 µs per loop
%timeit dw(x)    # 1000 loops, best of 3: 352 µs per loop
```

I also try it on my laptop using CPUs only, similar results are spotted. Any idea of how to speed up `DepthwiseConv2D`?
"
42171, AttributeError: 'NoneType' object has no attribute 'outer_context',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
Epoch 1/3
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-28-e5e1b2f4217c> in <module>()
      1 history = model.fit([np.array(X_train), GetGazetteersFeatures(X_train)], y_train, validation_split = 0.2,
----> 2                     batch_size=batch_size, epochs=3, verbose=1)

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1096                 batch_size=batch_size):
   1097               callbacks.on_train_batch_begin(step)
-> 1098               tmp_logs = train_function(iterator)
   1099               if data_handler.should_sync:
   1100                 context.async_wait()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    821       # This is the first call of __call__, so we have to initialize.
    822       initializers = []
--> 823       self._initialize(args, kwds, add_initializers_to=initializers)
    824     finally:
    825       # At this point we know that the initialization is complete (or less

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    695     self._concrete_stateful_fn = (
    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 697             *args, **kwds))
    698 
    699     def invalid_creator_scope(*unused_args, **unused_kwds):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2853       args, kwargs = None, None
   2854     with self._lock:
-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2856     return graph_function
   2857 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3211 
   3212       self._function_cache.missed.add(call_context_key)
-> 3213       graph_function = self._create_graph_function(args, kwargs)
   3214       self._function_cache.primary[cache_key] = graph_function
   3215       return graph_function, args, kwargs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3073             arg_names=arg_names,
   3074             override_flat_arg_shapes=override_flat_arg_shapes,
-> 3075             capture_by_value=self._capture_by_value),
   3076         self._function_attributes,
   3077         function_spec=self.function_spec,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--> 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    599         # the function a weak reference to itself to avoid a reference cycle.
--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    601     weak_wrapped_fn = weakref.ref(wrapped_fn)
    602 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    971           except Exception as e:  # pylint:disable=broad-except
    972             if hasattr(e, ""ag_error_metadata""):
--> 973               raise e.ag_error_metadata.to_exception(e)
    974             else:
    975               raise

AttributeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step
        y_pred = self(x, training=True)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call
        inputs, training=training, mask=mask)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph
        outputs = node.layer(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:903 call
        result = self.function(inputs, **kwargs)
    <ipython-input-18-c52c410a00c9>:4 ElmoEmbedding
        sequence_len=tf.constant(batch_size*[max_len]))[""elmo""]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1655 __call__
        return self._call_impl(args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/wrap_function.py:247 _call_impl
        args, kwargs, cancellation_manager)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1673 _call_impl
        return self._call_with_flat_signature(args, kwargs, cancellation_manager)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1722 _call_with_flat_signature
        return self._call_flat(args, self.captured_inputs, cancellation_manager)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1929 _call_flat
        forward_function, args_with_tangents = forward_backward.forward()
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1433 forward
        self._inference_args, self._input_tangents)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1189 forward
        self._forward_and_backward_functions(inference_args, input_tangents))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1389 _forward_and_backward_functions
        outputs, inference_args, input_tangents)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:899 _build_functions_for_outputs
        src_graph=self._func_graph)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:551 _GradientsHelper
        to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs_set)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:124 _PendingCount
        between_op_list, between_ops, colocate_gradients_with_ops)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_state.py:780 MaybeCreateControlFlowState
        loop_state.AddWhileContext(op, between_op_list, between_ops)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_state.py:577 AddWhileContext
        outer_forward_ctxt = forward_ctxt.outer_context

    AttributeError: 'NoneType' object has no attribute 'outer_context'

"
42170,Error when trying to run MobileNetV2 on esp32 (abort),"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 (tensorflow), Windows 10 (microcontroller ide)
- TensorFlow installed from (source or binary): 
- Tensorflow version (commit SHA if source): 2.3.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): esp32(with external ram)

**Describe the problem**

I am trying to run MobileNetV2 on esp32, the model creation and conversion code is:

`base_model = tf.keras.applications.MobileNetV2(input_shape=(48, 48, 1), alpha=0.35, weights=None, include_top=False)
x = base_model.output
x = tf.keras.layers.Flatten()(x)
x = tf.keras.layers.Dense(2)(x) #final layer with softmax activation for N classes
preds = tf.keras.layers.Softmax()(x)
model = tf.keras.models.Model(inputs=base_model.input,outputs=preds) #specify the inputs and outputs
converter = tf.lite.TFLiteConverter.from_keras_model(model)
def representative_dataset():
  for i in range(500):
    yield([np.random.rand(1,48,48,1).astype(np.float32)])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.representative_dataset = representative_dataset
tflite_model = converter.convert()
open(""mobilenet_test.tflite"", ""wb"").write(tflite_model)`

I am loading the tflite into partition called tensorflow_model, the esp32 code:
`    // alloc the tensor data on external RAM
    tensor_arena = (uint8_t *) heap_caps_malloc(kTensorArenaSize, MALLOC_CAP_SPIRAM);

    printf(""tesnor arena at addr: %p\r\n"", tensor_arena);

    // Find the cry_model partition in the partition table
    const esp_partition_t *partition = esp_partition_find_first(ESP_PARTITION_TYPE_DATA, 
                                                                ESP_PARTITION_SUBTYPE_ANY, 
                                                                ""tensorflow_model"");

    // Map the partition to data memory
    ESP_ERROR_CHECK(esp_partition_mmap(partition, 
                                       0, 
                                       partition->size, 
                                       SPI_FLASH_MMAP_DATA, 
                                       &tensorflow_model_data,
                                       &map_handle));

    ESP_LOGI(TAG, ""Mapped tensorflow_model partition to data memory address %p"", tensorflow_model_data);

    // Set up logging. Google style is to avoid globals or statics because of
    // lifetime uncertainty, but since this has a trivial destructor it's okay.
    // NOLINTNEXTLINE(runtime-global-variables)
    static tflite::MicroErrorReporter micro_error_reporter;
    error_reporter = &micro_error_reporter;

    // Map the model into a usable data structure. This doesn't involve any
    // copying or parsing, it's a very lightweight operation.
    model = tflite::GetModel(tensorflow_model_data);
    if (model->version() != TFLITE_SCHEMA_VERSION) 
    {
        TF_LITE_REPORT_ERROR(error_reporter,
                             ""Model provided is schema version %d not equal ""
                             ""to supported version %d."",
                             model->version(), TFLITE_SCHEMA_VERSION);
        return;
    }

    static tflite::AllOpsResolver resolver;

    // Build an interpreter to run the model with.
    static tflite::MicroInterpreter static_interpreter(model,
                                                       resolver, 
                                                       tensor_arena, 
                                                       kTensorArenaSize, 
                                                       error_reporter);
    interpreter = &static_interpreter;

    // Allocate memory from the tensor_arena for the model's tensors.
    TfLiteStatus allocate_status = interpreter->AllocateTensors();
    if (allocate_status != kTfLiteOk) 
    {
        ESP_LOGI(TAG, ""AllocateTensors() failed"");
        return;
    }
    TfLiteStatus invoke_status = interpreter->Invoke();
    if (invoke_status != kTfLiteOk) {
      TF_LITE_REPORT_ERROR(error_reporter, ""Invoke failed\n"");
    }`

the code crush in invoke with :
abort() was called at PC 0x401134f7 on core 0
0x401134f7: tflite::PreprocessSoftmaxScaling(double, double, int, int*, int*) at C:\work\projects\rhino\build/../components/tfmicro/tensorflow/lite/kernels/internal/quantization_util.cc:96
 (inlined by) tflite::PreprocessSoftmaxScaling(double, double, int, int*, int*) at C:\work\projects\rhino\build/../components/tfmicro/tensorflow/lite/kernels/internal/quantization_util.cc:296


ELF file SHA256: 8bf88518f1fe95d5

Backtrace: 0x40087ca9:0x3ffb5390 0x40088061:0x3ffb53b0 0x401134f7:0x3ffb53d0 0x400ed948:0x3ffb5400 0x400d93c2:0x3ffb5480 0x400d548d:0x3ffb54a0 0x400d562f:0x3ffb54d0 0x400d0ff0:0x3ffb5610 0x4008c141:0x3ffb5630
0x40087ca9: invoke_abort at C:/work/esp-idf/components/esp32/panic.c:155

0x40088061: abort at C:/work/esp-idf/components/esp32/panic.c:172

0x401134f7: tflite::PreprocessSoftmaxScaling(double, double, int, int*, int*) at C:\work\projects\rhino\build/../components/tfmicro/tensorflow/lite/kernels/internal/quantization_util.cc:96
 (inlined by) tflite::PreprocessSoftmaxScaling(double, double, int, int*, int*) at C:\work\projects\rhino\build/../components/tfmicro/tensorflow/lite/kernels/internal/quantization_util.cc:296

0x400ed948: tflite::ops::micro::activations::SoftmaxEval(TfLiteContext*, TfLiteNode*) at C:\work\projects\rhino\build/../components/tfmicro/tensorflow/lite/micro/kernels/softmax.cc:57
 (inlined by) tflite::ops::micro::activations::SoftmaxEval(TfLiteContext*, TfLiteNode*) at C:\work\projects\rhino\build/../components/tfmicro/tensorflow/lite/micro/kernels/softmax.cc:118

0x400d93c2: tflite::MicroInterpreter::Invoke() at C:\work\projects\rhino\build/../components/tfmicro/tensorflow/lite/micro/micro_interpreter.cc:285

0x400d548d: setup_model_data() at C:\work\projects\rhino\build/../main/main.cc:145

0x400d562f: app_main at C:\work\projects\rhino\build/../main/main.cc:232

0x400d0ff0: main_task at C:/work/esp-idf/components/esp32/cpu_start.c:553

0x4008c141: vPortTaskWrapper at C:/work/esp-idf/components/freertos/port.c:143

Thanks, 
"
42169,python2.7,There is a problem come from ubuntu coding. 
42168,Update TensorFlow docs for a11y,"### Description:

Hey @lamberta @MarkDaoust @yashk2810, 

I've put together a few small commits to update the TensorFlow docs for more inclusive language. It's to do with ~~”Native”~~ -> “Built-in”. (Source: an a11y [presentation](https://docs.google.com/presentation/d/1UVHzuMo5Ef1zUCZ3qdFwDQh-aVHpkYnY73TrJ2yHt3E/edit#slide=id.g6fe49527a0_0_334) by @heyawhite—a tech writer at Google). 

[Link to diffs](https://github.com/tensorflow/docs/compare/master...8bitmp3:master).

If you're OK with these changes, I can submit a PR.

### Submit a pull request?

Yes, can do

### Affected docs:

- TF testing best practices guide
- TensorFlow (R1) C++ API guide
- TF 1.x Eager mode notebook
- TensorFlow Customization basics notebook
- Build TensorFlow on Windows guide
- TensorFlow 2 migration notebook
- tf.function notebook
- TF create an op in C++ guide
- TF (R1) Adding a new op in C++ guide"
42167, ValueError: No gradients provided for any variable,"For the code

    import  tensorflow as tf
    
    y_N= tf.Variable([1., 2., 3.],name=""dd"")
    cost = -tf.reduce_mean(input_tensor=tf.reduce_sum(input_tensor=tf.math.log(y_N), axis=0))
    
    loss=lambda:cost
    
    train_step = tf.keras.optimizers.Adam(0.5).minimize(loss, var_list=[y_N])


I got error

    ValueError: No gradients provided for any variable: ['dd:0']."
42166,libcudart.so.10.1 is not included in the cuda 10.2 package,"I'm trying to see enabled GPUs in tensorflow by the following: 
```
import tensorflow as tf
from tensorflow.python.client import device_lib
import os
os.environ[""TF_MIN_GPU_MULTIPROCESSOR_COUNT""]=""2""
os.environ[""CUDA_VISIBLE_DEVICES""]=""0,1""
print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
```
It returns 0 GPUs because it is looking for a `cuda` library called 'libcudart.so.10.1'. 
What I tried to so was rename the latest file `libcudart.so.10.2.89` to `libcudart.so.10.1` with no success.
The only way we can probably get this to work is by building from source which takes 10 hours on my machine. 
Can you make tensorflow to point to libcudart.so.10.2 in tensorflow 2.3?

Thanks,

"
42165,ES32 Hello World project crashing in the target,"Please go to Stack Overflow for help and support:

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Catalina
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: No
-   **TensorFlow installed from (source or binary)**: Source
-   **TensorFlow version (use command below)**: v2.3.0
-   **Python version**: Python 3.7
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project

cd tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/hello_world/esp-idf

idf.py build

idf.py --port /dev/ttyUSB0 flash

idf.py --port /dev/ttyUSB0 monitor

### Describe the problem
I am trying the hello world example for tensor flow lite for microcontrollers. I am using an ESP32-CAM board which uses ESP32-S module. I generate the code as mentioned here https://github.com/tensorflow/tensorflow/tree/v2.2.0/tensorflow/lite/micro/examples/hello_world

After flashing the binary the module continuously resets. Please check the idf monitor logs.

### Source code / logs
Rebooting...
ets Jun  8 2016 00:22:57

rst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)
configsip: 0, SPIWP:0xee
clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00
mode:DIO, clock div:2
load:0x3fff0030,len:4
load:0x3fff0034,len:7176
load:0x40078000,len:13696
ho 0 tail 12 room 4
load:0x40080400,len:4000
0x40080400: _init at ??:?

entry 0x40080688
I (31) boot: ESP-IDF v4.2-dev-1660-g7d7521367 2nd stage bootloader
I (31) boot: compile time 15:00:22
I (31) boot: chip revision: 1
I (35) boot_comm: chip revision: 1, min. bootloader chip revision: 0
I (42) boot.esp32: SPI Speed      : 40MHz
I (47) boot.esp32: SPI Mode       : DIO
I (51) boot.esp32: SPI Flash Size : 2MB
I (56) boot: Enabling RNG early entropy source...
I (61) boot: Partition Table:
I (65) boot: ## Label            Usage          Type ST Offset   Length
I (72) boot:  0 nvs              WiFi data        01 02 00009000 00006000
I (80) boot:  1 phy_init         RF data          01 01 0000f000 00001000
I (87) boot:  2 factory          factory app      00 00 00010000 00100000
I (95) boot: End of partition table
I (99) boot_comm: chip revision: 1, min. application chip revision: 0
I (106) esp_image: segment 0: paddr=0x00010020 vaddr=0x3f400020 size=0x09af0 ( 39664) map
I (130) esp_image: segment 1: paddr=0x00019b18 vaddr=0x3ffb0000 size=0x02854 ( 10324) load
I (135) esp_image: segment 2: paddr=0x0001c374 vaddr=0x40080000 size=0x00404 (  1028) load
0x40080000: _WindowOverflow4 at /Users/sudeep_subi/software/esp-idf/components/freertos/xtensa/xtensa_vectors.S:1730

I (137) esp_image: segment 3: paddr=0x0001c780 vaddr=0x40080404 size=0x03898 ( 14488) load
I (152) esp_image: segment 4: paddr=0x00020020 vaddr=0x400d0020 size=0x4ea20 (322080) map
0x400d0020: _stext at ??:?

I (277) esp_image: segment 5: paddr=0x0006ea48 vaddr=0x40083c9c size=0x063ec ( 25580) load
0x40083c9c: prvReceiveGeneric at /Users/sudeep_subi/software/esp-idf/components/esp_ringbuf/ringbuf.c:760

I (294) boot: Loaded app from partition at offset 0x10000
I (295) boot: Disabling RNG early entropy source...
I (295) cpu_start: Pro cpu up.
I (299) cpu_start: Application information:
I (303) cpu_start: Project name:     hello_world
I (309) cpu_start: App version:      1
I (313) cpu_start: Compile time:     Aug  9 2020 15:00:14
I (319) cpu_start: ELF file SHA256:  242d4cfeca1609d0...
I (325) cpu_start: ESP-IDF:          v4.2-dev-1660-g7d7521367
I (332) cpu_start: Starting app cpu, entry point is 0x400816d4
0x400816d4: call_start_cpu1 at /Users/sudeep_subi/software/esp-idf/components/esp32/cpu_start.c:286

I (323) cpu_start: App cpu up.
I (342) heap_init: Initializing. RAM available for dynamic allocation:
I (349) heap_init: At 3FFAE6E0 len 00001920 (6 KiB): DRAM
I (355) heap_init: At 3FFB51A0 len 0002AE60 (171 KiB): DRAM
I (361) heap_init: At 3FFE0440 len 00003AE0 (14 KiB): D/IRAM
I (368) heap_init: At 3FFE4350 len 0001BCB0 (111 KiB): D/IRAM
I (374) heap_init: At 4008A088 len 00015F78 (87 KiB): IRAM
I (380) cpu_start: Pro cpu start user code
I (399) spi_flash: detected chip: generic
I (399) spi_flash: flash io: dio
W (399) spi_flash: Detected size(4096k) larger than the size in the binary image header(2048k). Using the size in the binary image header.
I (410) cpu_start: Starting scheduler on PRO CPU.
I (0) cpu_start: Starting scheduler on APP CPU.
8 bytes lost due to alignment. To avoid this loss, please make sure the tensor_arena is 16 bytes aligned.
Guru Meditation Error: Core  0 panic'ed (StoreProhibited). Exception was unhandled.

Core  0 register dump:
PC      : 0x400d3848  PS      : 0x00060230  A0      : 0x800d3805  A1      : 0x3ffb6fd0  
0x400d3848: loop at /Users/sudeep_subi/junk/esp32_examples/esp-idf/build/../main/main_functions.cc:100

A2      : 0x00000000  A3      : 0x00000014  A4      : 0x40c90fdb  A5      : 0x383f8000  
A6      : 0x3ffb8fc8  A7      : 0x00000000  A8      : 0x00000000  A9      : 0x3ffb6fc0  
A10     : 0x00000000  A11     : 0x41a00000  A12     : 0x00000001  A13     : 0xffffffff  
A14     : 0x00000005  A15     : 0x00000004  SAR     : 0x00000001  EXCCAUSE: 0x0000001d  
EXCVADDR: 0x00000000  LBEG    : 0x400029ac  LEND    : 0x400029cb  LCOUNT  : 0x00000000  

Backtrace:0x400d3845:0x3ffb6fd0 0x400d3802:0x3ffb6ff0 0x400d21d6:0x3ffb7010 0x40084719:0x3ffb7040
0x400d3845: loop at /Users/sudeep_subi/junk/esp32_examples/esp-idf/build/../main/main_functions.cc:100

0x400d3802: app_main at /Users/sudeep_subi/junk/esp32_examples/esp-idf/build/../main/esp/main.cc:21 (discriminator 1)

0x400d21d6: main_task at /Users/sudeep_subi/software/esp-idf/components/esp32/cpu_start.c:580

0x40084719: vPortTaskWrapper at /Users/sudeep_subi/software/esp-idf/components/freertos/xtensa/port.c:143



ELF file SHA256: 242d4cfeca1609d0"
42164,Difference between TF2.3 and TF2.2[MKL],"I am working on project and we are trying to make TF use functions that we have written, these functions are there in the form of a .so file, we managed to get Tensorflow2.2 to use our MatMul function, but it stopped working for TF2.4. We achieved our aim in TF2.2 by using LD_PRELOAD, Any guesses as to why this has happened. An important detail is that both of these TF environments we built from source with MKL support (--config=mkl)
Also these are the function defined inside our .so file (nm command on the .so file, screenshot)
"
42163,Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): I don't really how to tell
- TensorFlow version: 2.1
- Python version: 3.6.10
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): Im not really sure what that means either
- GCC/Compiler version (if compiling from source): again can't tell
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: Nividia Geforce RTX 2060 4604 MB memory



**Describe the problem**
I ran then ran this code to check if the compiler can discover my gpu and to see the difference in speed between it and cpu:

```
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))
import timeit

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  print(
      '\n\nThis error most likely means that this notebook is not '
      'configured to use a GPU.  Change this in Notebook Settings via the '
      'command palette (cmd/ctrl-shift-P) or the Edit menu.\n\n')
  raise SystemError('GPU device not found')

def cpu():
  with tf.device('/cpu:0'):
    random_image_cpu = tf.random.normal((100, 100, 100, 3))
    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)
    return tf.math.reduce_sum(net_cpu)

def gpu():
  with tf.device('/device:GPU:0'):
    random_image_gpu = tf.random.normal((100, 100, 100, 3))
    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)
    return tf.math.reduce_sum(net_gpu)
  
# We run each op once to warm up; see: https://stackoverflow.com/a/45067900
cpu()
gpu()

# Run the op several times.
print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '
      '(batch x height x width x channel). Sum of ten runs.')
print('CPU (s):')
cpu_time = timeit.timeit('cpu()', number=10, setup=""from __main__ import cpu"")
print(cpu_time)
print('GPU (s):')
gpu_time = timeit.timeit('gpu()', number=10, setup=""from __main__ import gpu"")
print(gpu_time)
print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))

```

and it returned the following error:


```
Found GPU at: /device:GPU:0
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
<ipython-input-1-121519b30cf2> in <module>
     29 # We run each op once to warm up; see: https://stackoverflow.com/a/45067900
     30 cpu()
---> 31 gpu()
     32 
     33 # Run the op several times.

<ipython-input-1-121519b30cf2> in gpu()
     24   with tf.device('/device:GPU:0'):
     25     random_image_gpu = tf.random.normal((100, 100, 100, 3))
---> 26     net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)
     27     return tf.math.reduce_sum(net_gpu)
     28 

~\anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py in __call__(self, inputs, *args, **kwargs)
    820           with base_layer_utils.autocast_context_manager(
    821               self._compute_dtype):
--> 822             outputs = self.call(cast_inputs, *args, **kwargs)
    823           self._handle_activity_regularization(inputs, outputs)
    824           self._set_mask_metadata(inputs, outputs, input_masks)

~\anaconda3\lib\site-packages\tensorflow_core\python\keras\layers\convolutional.py in call(self, inputs)
    207       inputs = array_ops.pad(inputs, self._compute_causal_padding())
    208 
--> 209     outputs = self._convolution_op(inputs, self.kernel)
    210 
    211     if self.use_bias:

~\anaconda3\lib\site-packages\tensorflow_core\python\ops\nn_ops.py in __call__(self, inp, filter)
   1133           call_from_convolution=False)
   1134     else:
-> 1135       return self.conv_op(inp, filter)
   1136     # copybara:strip_end
   1137     # copybara:insert return self.conv_op(inp, filter)

~\anaconda3\lib\site-packages\tensorflow_core\python\ops\nn_ops.py in __call__(self, inp, filter)
    638 
    639   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin
--> 640     return self.call(inp, filter)
    641 
    642 

~\anaconda3\lib\site-packages\tensorflow_core\python\ops\nn_ops.py in __call__(self, inp, filter)
    237         padding=self.padding,
    238         data_format=self.data_format,
--> 239         name=self.name)
    240 
    241 

~\anaconda3\lib\site-packages\tensorflow_core\python\ops\nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)
   2009                            data_format=data_format,
   2010                            dilations=dilations,
-> 2011                            name=name)
   2012 
   2013 

~\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)
    931             input, filter, strides=strides, use_cudnn_on_gpu=use_cudnn_on_gpu,
    932             padding=padding, explicit_paddings=explicit_paddings,
--> 933             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)
    934       except _core._SymbolicException:
    935         pass  # Add nodes to the TensorFlow graph.

~\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py in conv2d_eager_fallback(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)
   1020   explicit_paddings, ""data_format"", data_format, ""dilations"", dilations)
   1021   _result = _execute.execute(b""Conv2D"", 1, inputs=_inputs_flat, attrs=_attrs,
-> 1022                              ctx=ctx, name=name)
   1023   if _execute.must_record_gradient():
   1024     _execute.record_gradient(

~\anaconda3\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~\anaconda3\lib\site-packages\six.py in raise_from(value, from_value)

UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]
```

I've tried the solutions mentioned here https://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261/2 but to no avail.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I've tried using Tensorflow GPU accelerator in google colab with local runtime on my machine, I've followed all the steps precisely on https://www.tensorflow.org/install/gpu 

**Any other info / logs**
this is the log from the jupyter terminal:

```
2020-08-09 04:37:22.168805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-08-09 04:37:24.322956: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-08-09 04:37:24.329330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-08-09 04:37:25.599803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.335GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2020-08-09 04:37:25.607874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-08-09 04:37:25.616921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-08-09 04:37:25.626584: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-08-09 04:37:25.635135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-08-09 04:37:25.650044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-08-09 04:37:25.659390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-08-09 04:37:25.681098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-08-09 04:37:25.686397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-08-09 04:37:26.217444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-09 04:37:26.222044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-08-09 04:37:26.225124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-08-09 04:37:26.228586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 4604 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-08-09 04:37:26.239786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.335GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2020-08-09 04:37:26.249100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-08-09 04:37:26.254350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-08-09 04:37:26.260971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-08-09 04:37:26.265307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-08-09 04:37:26.271569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-08-09 04:37:26.276251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-08-09 04:37:26.281798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-08-09 04:37:26.287682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-08-09 04:37:26.291846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-09 04:37:26.298235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-08-09 04:37:26.300794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-08-09 04:37:26.305262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 4604 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-08-09 04:37:26.313775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.335GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2020-08-09 04:37:26.328318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-08-09 04:37:26.339994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-08-09 04:37:26.345874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-08-09 04:37:26.352587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-08-09 04:37:26.359694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-08-09 04:37:26.365286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-08-09 04:37:26.371099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-08-09 04:37:26.375749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-08-09 04:37:26.380113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.335GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2020-08-09 04:37:26.393424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-08-09 04:37:26.403150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-08-09 04:37:26.408577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-08-09 04:37:26.423141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-08-09 04:37:26.428838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-08-09 04:37:26.434061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-08-09 04:37:26.438479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-08-09 04:37:26.443288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-08-09 04:37:26.446511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-09 04:37:26.453204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-08-09 04:37:26.458931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-08-09 04:37:26.463016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4604 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-08-09 04:37:26.823644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-08-09 04:37:27.877441: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-08-09 04:37:27.882143: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
```

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
42162,looking for libcudart.so.10 when  libcudart.so.11 installed,"

using anacoda
setting enviroment,
installing pip
using pip to install tensorflow
testrun
python
import tensorflow as tf
gives error 

2020-08-08 23:41:49.327601: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-08 23:41:49.327623: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


so I dutifully went to nvidia and installed cuda.
Trying again give same error.

using updatedb and locate I found 
the following instances.

/usr/local/cuda-11.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so
/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0
/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0.221

so it looks like Nvidia has a newer version out then whats been looked at.

I'm not sure who's error this is, if it's not yours please redirect me to whomever it is. thanks

**System information**
linux mint 20,
"
42160,ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `Nope`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Windows 10`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `No`
- TensorFlow installed from (source or binary): `pip`
- TensorFlow version (use command below): `2.3.0`
- Python version: `3.8.5`
- Bazel version (if compiling from source): `N/A`
- GCC/Compiler version (if compiling from source): `N/A`
- CUDA/cuDNN version: `10.1`
- GPU model and memory: `NVIDIA GeForce GTX 970, 4GB`

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
When I import TensorFlow from Python, a message is printed like below.

> >>> import tensorflow
> Traceback (most recent call last):
>   File ""C:\Users\y\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
>     from tensorflow.python._pywrap_tensorflow_internal import *
> ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""C:\Users\y\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\tensorflow\__init__.py"", line 41, in <module>
>     from tensorflow.python.tools import module_util as _module_util
>   File ""C:\Users\y\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
>     from tensorflow.python.eager import context
>   File ""C:\Users\y\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
>     from tensorflow.python import pywrap_tfe
>   File ""C:\Users\y\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
>     from tensorflow.python import pywrap_tensorflow
>   File ""C:\Users\y\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
>     raise ImportError(msg)
> ImportError: Traceback (most recent call last):
>   File ""C:\Users\y\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
>     from tensorflow.python._pywrap_tensorflow_internal import *
> ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.
> 
> 
> Failed to load the native TensorFlow runtime.
> 
> See https://www.tensorflow.org/install/errors
> 
> for some common reasons and solutions.  Include the entire stack trace
> above this error message when asking for help.

Hopefully, it is not that serious matter to resolve.

**Describe the expected behavior**
Import TensorFlow successfully.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

If environment is equivalent, then the problem may be reproduced.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42159,ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42157,Input shape for converted tflite model is wrong,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Android 10
- TensorFlow installed from (source or binary):binary
- TensorFlow version (or github SHA if from source):2.4.0-dev20200808


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/117z3RoXIdk-yhptaQIzjuj_WQ5mIO8wP?usp=sharing

```
converter = tf.lite.TFLiteConverter.from_saved_model('/content/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/',signature_keys=['serving_default'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)
```

**The output from the converter invocation**

TFLite file: https://drive.google.com/file/d/12lFDByC29jYNa-9V4vzm8poJfTH1zNMI/view?usp=sharing

**Failure details**
Able to produce the TFLite model, after visualizing the generated .tflite with https://lutzroeder.github.io/netron/ found the input shape of the model is [1,1,1,3] instead of [1,640,640,3].
Android Object Detection sample fails to run. I have modified TF_OD_API_SIZE, TF_OD_API_IS_QUANTIZED, TF_OD_API_MODEL_FILE accordingly.

**Any other info / logs**
```
ADB logcat: Cannot copy to a TensorFlowLite tensor (serving_default_input_tensor:0) with 3 bytes from a Java Buffer with 4915200 bytes.
```"
42156, Could not dlopen library 'libcudnn.so.7' for CUDA9.1,"I'm using CUDA9.1 and tensorflow version 1.14.0.   When I run the code it is not using the GPUs. It seems it started once I've update the Keras version. Anyway I get this error:

```
2020-08-08 19:17:16.746067: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-08-08 19:17:16.747865: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-08-08 19:17:16.749660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-08-08 19:17:16.750029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-08-08 19:17:16.752270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-08-08 19:17:16.753794: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-08-08 19:17:16.754002: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-9.0/lib64:/usr/local/cuda/lib64:/usr/local/cuda-9.1/lib64:
2020-08-08 19:17:16.754018: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...
2020-08-08 19:17:16.754071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-08 19:17:16.754089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1
2020-08-08 19:17:16.754097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y
2020-08-08 19:17:16.754103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N
2020-08-08 19:17:16.762468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e828a90720 executing computations on platform CUDA. Devices:
2020-08-08 19:17:16.762491: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-08-08 19:17:16.762499: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-08-08 19:17:16.961125: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0808 19:17:17.188626 140541490861888 deprecation_wrapper.py:119] From /home/shiftone/vsd-shiftone/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.
```"
42155,module 'tensorflow' has no attribute 'HistogramProto',
42153,Convert saved model - issue generated shapes,"**System information**
- OS: MAC
- TensorFlow version 2.4.0-dev20200805


**Command used to run the converter or code if you’re using the Python API**

```
!pip install tf-nightly

import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model('ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True

converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()

open(""m.tflite"", ""wb"").write(tflite_model)
```


**Original Model Input & Output shape**

![image](https://user-images.githubusercontent.com/68266028/89719024-c337ef00-d9cc-11ea-8858-afc169c5237c.png)


**Converted Model Input & Output shape**

![image](https://user-images.githubusercontent.com/68266028/89719032-e367ae00-d9cc-11ea-9ff2-f5700e7c36a7.png)


**Also, please include a link to the saved model {{[LINK MODEL](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz)}}**



**Please let me know if I have missed anything here, I feel that the model has something wrong! (Shapes are not matched)  As I replaced the model in the Android version of object detection, it gives me errors.**
"
42152,floating point exception in `tf.nn.atrous_conv2d` when there is 0 in filters.shape,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.6.9
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`tf.nn.atrous_conv2d` throws floating point exception when the shape of `filters` is `[0,*,*,*]`, or there is `0` in the first three dimension of the shape, e.g. `[*,0,*,*]. [*,*,0,*]`

**Describe the expected behavior**
Expect no floating point exception

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
~~~python
import tensorflow as tf
tf.nn.atrous_conv2d(filters=tf.ones((0,1,1,1)), value=tf.ones((1,1,1,1)), rate=1, padding=""SAME"")
tf.nn.atrous_conv2d(filters=tf.ones((1,0,1,1)), value=tf.ones((1,1,1,1)), rate=1, padding=""SAME"")
tf.nn.atrous_conv2d(filters=tf.ones((1,1,0,1)), value=tf.ones((1,1,1,1)), rate=1, padding=""SAME"")
~~~
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
~~~python
Floating point exception (core dumped)
~~~"
42151,tf.nn.ctc_beam_search_decoder expects output of softmax whereas documentation says it expects logits,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7

**Describe the current behavior**

Currently https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder says it expects input to be logits, whereas it acutally expects softmax already applied.

See https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_decode, which expects output of softmax, and it directly passes the input to https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder - see https://github.com/tensorflow/tensorflow/blob/7b301123019d2b4bbd9c597916ba032f05854074/tensorflow/python/keras/backend.py#L6037-L6088

**Describe the expected behavior**

The documentation of https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder should say it expects softmax output.
"
42150,Keras plot_model bug when rendering to svg,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.7


**Describe the current behavior**
The tf.keras.utils.plot_model() function (and by extension the tf.keras.utils.model_to_dot() function) when specifying the file extension as svg creates an svg with an incorrectly set 'view'. Only the view is incorrect, as the model is correctly plotted, just partly outside the visible range. 
The reason for this bug is that the dpi standard value of 96 prevents graphviz from figuring out the correct svg view window itself. If the dpi is set to 'None', graphviz figures out the correct view. I am uncertain if this bug also occurs with other vector graphic formats, I however tested it with pdfs and it seemed fine.

Graphviz is set to figure out the correct dpi by itself anyway and applies standard values as 96 to bitmap formats by default [1]. Offering a standard value in the keras plot_model function overwrites that functionality.
The problem can be solved by setting the dpi default value in the plot_model/model_to_dot function to None and letting graphviz figure out the correct dpi; or by checking for edge cases when converting to special formats such as svg. As I am unaware of the default-value policy of tensorflow did I not want to create an unnecessary pull request, though I would gladly help in the bug fix [2].

[1] https://graphviz.org/doc/info/attrs.html#d:dpi
[2] mail@paulpauls.de


**Standalone code to reproduce the issue**

The code is not reproducible within a jupyter notebook / Google colab, as IPython does not support svg display. Therefore am I attaching minimal reproducing code below:

```
import tensorflow as tf
from tensorflow.keras import models, layers

print(tf.__version__)

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

tf.keras.utils.plot_model(model, to_file='./model.png')

tf.keras.utils.plot_model(model, to_file='./model_96DPI.svg')

tf.keras.utils.plot_model(model, to_file='./model_NoneDPI.svg', dpi=None)
```
"
42149,hb,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42147,XNNPack delegate undefined reference,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Android 10
- TensorFlow installed from (source or binary): source
- TensorFlow version: master
- Python version: 3.6
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

I'm trying to use xnnpack on Android 10 (arm64-v8a). I was able to build xnnpack delegate lib 

```
bazel build -c opt --config=android_arm64 \
  //tensorflow/lite/delegates/xnnpack:xnnpack_delegate
```

And it produces static lib libs libxnnpack_delegate.a and libxnnpack_delegate.pic.a. But when linking into my Android project, we still have undefined reference errors as following
```
/proc/self/cwd/tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc:3119: undefined reference to `xnn_initialize'
```

I am wondering what we are missing in these steps?

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
42146,Dataset sharding in MultiWorker Mirrored Strategy,"Hi, I am relatively new to distributed TensorFlow. I am running a custom CIFAR10 training code from tensorflow website on 2 Azure VMs. I have made key-less ssh connections between them and have set up TF_CONFIG. My training completes successfully. I just want to know, how CIFAR10 data is getting sharded in my code. First it mentions that it is switching to DATA and then it says it cannot find a shardable source but still it proceeds to train my code. A surprising thing is that with all these errors with sharding in my cluster, my training completes more swiftly as compared to getting trained in a single VM. The logs tell that it cannot shard my code, if this is so, why am I getting a speed increase in training, despite dataset not getting sharded? Please help.

**ERROR:**

. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
 You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via.

And then :

2020-08-01 16:29:05.556918: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: ""FlatMapDataset/_9""
op: ""FlatMapDataset""
input: ""PrefetchDataset/_8""
attr {
  key: ""Targuments""
  value {
    list {
    }
  }
}
attr {
  key: ""f""
  value {
    func {
      name: ""__inference_Dataset_flat_map_slice_batch_indices_39847""
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
attr {
  key: ""output_types""
  value {
    list {
      type: DT_INT64
    }
  }
}
. 

### **System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version: 3.5.2
- Bazel version (if compiling from source):
- 2 CPU only machines : Azure D2s V3 (2 cores, 8gb ram)
-Tensorflow 2.2


**Standalone code to reproduce the issue**

```
`from` __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import os	
import json 	

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()


train_images, test_images = train_images / 255.0, test_images / 255.0

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    # The CIFAR labels happen to be arrays, 
    # which is why you need the extra index
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

with strategy.scope():

	model = models.Sequential()
	model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
	model.add(layers.MaxPooling2D((2, 2)))
	model.add(layers.Conv2D(64, (3, 3), activation='relu'))
	model.add(layers.MaxPooling2D((2, 2)))
	model.add(layers.Conv2D(64, (3, 3), activation='relu'))


#model.summary()


	model.add(layers.Flatten())
	model.add(layers.Dense(64, activation='relu'))
	model.add(layers.Dense(10))

	model.compile(optimizer='adam',
	              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
	              metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=10, 
                    validation_data=(test_images, test_labels))

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)




`print(test_acc)`
```


****### ** FULL LOGS******


2020-08-01 16:22:46.425007: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-01 16:22:46.425047: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-08-01 16:22:47.497587: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-01 16:22:47.497633: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-01 16:22:47.497673: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance1): /proc/driver/nvidia/version does not exist
2020-08-01 16:22:47.497969: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-01 16:22:47.505592: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2593905000 Hz
2020-08-01 16:22:47.505762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a13560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-01 16:22:47.505844: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-01 16:22:47.513007: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.4:12345, 1 -> 10.0.0.5:12345}
2020-08-01 16:22:47.513233: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://10.0.0.4:12345
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
2020-08-01 16:22:49.618955: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.
2020-08-01 16:22:49.916264: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.
2020-08-01 16:22:50.285604: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: ""FlatMapDataset/_9""
op: ""FlatMapDataset""
input: ""PrefetchDataset/_8""
attr {
  key: ""Targuments""
  value {
    list {
    }
  }
}
attr {
  key: ""f""
  value {
    func {
      name: ""__inference_Dataset_flat_map_slice_batch_indices_244""
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
attr {
  key: ""output_types""
  value {
    list {
      type: DT_INT64
    }
  }
}
. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
Epoch 1/10
WARNING:tensorflow:From /home/iamhassaan/venv/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Iterator.get_next_as_optional()` instead.
1561/1563 [============================>.] - ETA: 0s - loss: 1.5020 - accuracy: 0.45262020-08-01 16:23:27.691909: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: ""FlatMapDataset/_9""
op: ""FlatMapDataset""
input: ""PrefetchDataset/_8""
attr {
  key: ""Targuments""
  value {
    list {
    }
  }
}
attr {
  key: ""f""
  value {
    func {
      name: ""__inference_Dataset_flat_map_slice_batch_indices_4289""
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
attr {
  key: ""output_types""
  value {
    list {
      type: DT_INT64
    }
  }
}
. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `1563/1563 [==============================] - 38s 25ms/step - loss: 1.5017 - accuracy: 0.4527 - val_loss: 1.2870 - val_accuracy: 0.5304
Epoch 2/10
1563/1563 [==============================] - 37s 24ms/step - loss: 1.1390 - accuracy: 0.5970 - val_loss: 1.0820 - val_accuracy: 0.6155
Epoch 3/10
1563/1563 [==============================] - 37s 24ms/step - loss: 0.9962 - accuracy: 0.6510 - val_loss: 0.9849 - val_accuracy: 0.6546
Epoch 4/10
1563/1563 [==============================] - 37s 24ms/step - loss: 0.8935 - accuracy: 0.6890 - val_loss: 0.9642 - val_accuracy: 0.6618
Epoch 5/10
1563/1563 [==============================] - 37s 24ms/step - loss: 0.8244 - accuracy: 0.7117 - val_loss: 0.9134 - val_accuracy: 0.6870
Epoch 6/10
1563/1563 [==============================] - 37s 24ms/step - loss: 0.7653 - accuracy: 0.7351 - val_loss: 0.8816 - val_accuracy: 0.6953
Epoch 7/10
1563/1563 [==============================] - 37s 24ms/step - loss: 0.7151 - accuracy: 0.7497 - val_loss: 0.8829 - val_accuracy: 0.6986
Epoch 8/10
1563/1563 [==============================] - 37s 24ms/step - loss: 0.6721 - accuracy: 0.7656 - val_loss: 0.9168 - val_accuracy: 0.6910
Epoch 9/10
1563/1563 [==============================] - 37s 24ms/step - loss: 0.6250 - accuracy: 0.7830 - val_loss: 0.9076 - val_accuracy: 0.7012
Epoch 10/10
1563/1563 [==============================] - 37s 24ms/step - loss: 0.5895 - accuracy: 0.7968 - val_loss: 0.9148 - val_accuracy: 0.7039
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
2020-08-01 16:29:05.556918: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: ""FlatMapDataset/_9""
op: ""FlatMapDataset""
input: ""PrefetchDataset/_8""
attr {
  key: ""Targuments""
  value {
    list {
    }
  }
}
attr {
  key: ""f""
  value {
    func {
      name: ""__inference_Dataset_flat_map_slice_batch_indices_39847""
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
attr {
  key: ""output_types""
  value {
    list {
      type: DT_INT64
    }
  }
}
. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
313/313 - 3s - loss: 0.9148 - accuracy: 0.7039
0.7038999795913696



"
42145,how to make tensorflow2.1.0 to rpm ，or even have some git  link can also,"I want to build tensorflow to rpm is there have any tools to compile ?

Thank U very much"
42144,Docs on using TPUs with custom training loop can be misleading,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/guide/tpu#train_a_model_using_custom_training_loop

## Description of issue (what needs changing):
After reading the docs on how to use a TPU with a custom training loop, I went ahead and tried training my model on the TPU.
The training loop I implemented looked like:
```
    for step in range(steps_per_epoch):
      train_step(train_iterator)
      if step % 1000 == 0:
        print(step)
```
When I ran this with my model, I would see steps printed very quickly, but then after a while I saw an OOM error, since my model didn't fit in memory. I spent a long time trying to figure out how I could get an OOM error after successfully training for 1000s of steps. Eventually, I realized that train_step (with its internal strategy.run call) doesn't block on completion of the training step, and if I instead ran the following loop:
```
    for step in range(steps_per_epoch):
      train_step(train_iterator)
      if step % 1000 == 0:
        print(optimizer.iterations.numpy())
```
I would see the OOM before any steps completed as expected.

When initially reading the docs it was not at all clear to me this would happen, so I think it would be nice if the docs mentioned that strategy.run is non-blocking. I'm pretty new to tf 2.* so maybe I missed some docs that would've given me this understanding, and if that's the case I apologize. "
42142,saving a large kersa model through exception,"**saving checkpoint or tf.kersa.models.save_model in non eager mode throws the following exception:
I am using Ubuntu 18 and tried different versions of tensorflow (1.15,2.2,2.4, nightly built) the exceptiong ramdomly changed and complain about different variables ** 
tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta/N10tensorflow3VarE does not exist.
	 [[{{node voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta/Read/ReadVariableOp}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train.py"", line 632, in <module>
    train(cfgPath,modelPath) 
  File ""train.py"", line 566, in train
    raise e
  File ""train.py"", line 391, in train
    save_path = manager.save()
  File ""/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/checkpoint_management.py"", line 807, in save
    save_path = self._checkpoint.write(prefix)
  File ""/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py"", line 1543, in write
    output = self._saver.save(file_prefix=file_prefix, session=session)
  File ""/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py"", line 1216, in save
    return session.run(save_path, feed_dict=feed_dict)
  File ""/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 958, in run
    run_metadata_ptr)
  File ""/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1181, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta/N10tensorflow3VarE does not exist.
	 [[node voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta/Read/ReadVariableOp (defined at /home/babak/pp/tfpp/models/voxelnet.py:303) ]]

   **My code sample**
   with sess.as_default():
        with graph.as_default():     
                init = tf.global_variables_initializer()                
                sess.run(init)                                              
                
                model_dir = pathlib.Path(model_dir)  
                
                result_path = model_dir / result_name
                    
                config = pipeline_pb2.TrainEvalPipelineConfig()    
                with open(config_path, ""r"") as f:
                    proto_str = f.read()
                    text_format.Merge(proto_str, config)
            
                #nput_cfg = config.eval_input_reader
                input_cfg = config.train_input_reader
                model_cfg = config.model.second
                train_cfg = config.train_config
                class_names = list(input_cfg.class_names)
                center_limit_range = model_cfg.post_center_limit_range
                
                voxel_generator = voxel_builder.build(model_cfg.voxel_generator)
                bv_range = voxel_generator.point_cloud_range[[0, 1, 3, 4]]
                box_coder = box_coder_builder.build(model_cfg.box_coder)
                target_assigner_cfg = model_cfg.target_assigner
                target_assigner = target_assigner_builder.build(target_assigner_cfg,    
                                                               bv_range, box_coder)
                
                
                net = voxelnet_builder.build(model_cfg, voxel_generator, target_assigner,sess)
                
             
                optimizer_cfg = train_cfg.optimizer
                
                dataset = input_reader_builder.build(
                    input_cfg,
                    model_cfg,
                    training=True,
                    voxel_generator=voxel_generator,
                    target_assigner=target_assigner)    
                eval_dataset = input_reader_builder.build(
                    input_cfg,
                    model_cfg,
                    training=False,
                    voxel_generator=voxel_generator,
                    target_assigner=target_assigner)
                
                def _worker_init_fn(worker_id):
                    time_seed = np.array(time.time(), dtype=np.int32)
                    np.random.seed(time_seed + worker_id)
                    print(f""WORKER {worker_id} seed:"", np.random.get_state()[1][0])
                    
                dataloader = DataLoader(
                    dataset,
                    batch_size=input_cfg.batch_size,
                    shuffle=False, #True,
                    #num_workers= input_cfg.num_workers,
                    num_workers= 0,
                    pin_memory=False,
                    collate_fn=merge_second_batch)
                    #worker_init_fn=_worker_init_fn)
                
                eval_dataloader = DataLoader(
                    eval_dataset,
                    batch_size=input_cfg.batch_size,
                    shuffle=False,
                    #num_workers=input_cfg.num_workers,
                    num_workers=0,
                    pin_memory=False,
                    collate_fn=merge_second_batch)
                
            
                if train_cfg.enable_mixed_precision:
                    float_dtype = tf.float16
                else:
                    float_dtype = tf.float32
            
                #data_iter = iter(dataloader)
            
                ######################
                # TRAINING
                ######################
                log_path = 'log.txt'
                logf = open(log_path, 'a')
                logf.write(proto_str)
                logf.write(""\n"")
                summary_dir = model_dir / 'summary'
                summary_dir.mkdir(parents=True, exist_ok=True)
                writer = SummaryWriter(str(summary_dir))
            
                total_step_elapsed = 0
                #remain_steps = train_cfg.steps - net.get_global_step()
                t = time.time()
                ckpt_start_time = t
            
                total_loop = train_cfg.steps // train_cfg.steps_per_eval + 1
               
                clear_metrics_every_epoch = train_cfg.clear_metrics_every_epoch
            
                if train_cfg.steps % train_cfg.steps_per_eval == 0:
                    total_loop -= 1
                
                initial_learning_rate = 
                optimizer_cfg.adam_optimizer.learning_rate.exponential_decay_learning_rate.initial_learning_rate
                decay_steps = optimizer_cfg.adam_optimizer.learning_rate.exponential_decay_learning_rate.decay_steps
                decay_factor = optimizer_cfg.adam_optimizer.learning_rate.exponential_decay_learning_rate.decay_factor
                staircase = optimizer_cfg.adam_optimizer.learning_rate.exponential_decay_learning_rate.staircase
             
                loss_norm_type_dict = {
                        0: LossNormType.NormByNumExamples,
                        1: LossNormType.NormByNumPositives,
                        2: LossNormType.NormByNumPosNeg,
                    }
                
                loss_norm_type = loss_norm_type_dict[model_cfg.loss_norm_type]
                    
                losses = losses_builder.build(model_cfg.loss)
                encode_rad_error_by_sin = model_cfg.encode_rad_error_by_sin
                cls_loss_ftor, loc_loss_ftor, cls_weight, loc_weight, _ = losses
                pos_cls_weight = model_cfg.pos_class_weight
                neg_cls_weight = model_cfg.neg_class_weight
                direction_loss_weight = model_cfg.direction_loss_weight    
                box_code_size=target_assigner.box_coder.code_size
                
                ppLoss = PPLoss(
                    num_class=1,
                    cls_loss_weight=cls_weight,
                    loc_loss_weight=loc_weight,
                    pos_cls_weight=pos_cls_weight,
                    neg_cls_weight=neg_cls_weight,
                    direction_loss_weight=direction_loss_weight,
                    loss_norm_type=loss_norm_type,
                    encode_rad_error_by_sin=encode_rad_error_by_sin,
                    loc_loss_ftor=loc_loss_ftor,
                    cls_loss_ftor=cls_loss_ftor,
                    box_code_size=box_code_size,
                    use_direction_classifier=model_cfg.use_direction_classifier)
                
                         
                try:  
                    global_step = tf.Variable(0, trainable=False)                    
                    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=decay_steps, 
                   decay_rate=decay_factor,staircase=staircase)
                    optimizer = Adam(learning_rate=lr_schedule)    
                    ckpt = tf.train.Checkpoint(step=tf.Variable(1),model=net)##optimizer=optimizer)#, model=model)        
                    manager = tf.train.CheckpointManager(ckpt, ""./tf_ckpts"", max_to_keep=3)      
                    ckpt.restore(manager.latest_checkpoint)
                    if manager.latest_checkpoint:
                        print(""Restored from {}"".format(manager.latest_checkpoint))
                    else:
                        print(""Initializing from scratch."")
                    
                    initv = tf.global_variables_initializer()
                    sess.run(initv)
                    
                    for _ in range(total_loop):
                        if total_step_elapsed + train_cfg.steps_per_eval > train_cfg.steps:
                            steps = train_cfg.steps % train_cfg.steps_per_eval
                        else:
                            steps = train_cfg.steps_per_eval
                        for step in range(steps):
                     
                            example = next(iter(dataloader))
                                                      
                            example_tf = example_convert_to_tf(example, float_dtype)
            
                            batch_size = example[""anchors""].shape[0]
                            
                            with tf.GradientTape() as tape:
                                ret_dict = net(example_tf,training=True)
                                loss_value = ppLoss.call(example_tf, ret_dict)
                                
                            gradients = tape.gradient(loss_value[""loss""], net.trainable_weights)
                            
                            optimizer.apply_gradients(zip(gradients, net.trainable_weights))
                            
                            print(""step {} is done!"".format(step))
                            global_step.assign_add(1)
                            if step % 10 == 0 and step != 0:                            
                                    save_path = manager.save()
                                    print(""Saved checkpoint for step {}: {}"".format(step, save_path))
                                    #print(""Saving Model for step {}"".format(step))
                                    #print(""loss {:1.2f}"".format(loss_value[""loss""])) 
                                    #net._set_inputs(example_tf)
                                    #net.save('./PPModels/ppModel'+str(step),save_format='tf')
                   except Exception as e:
                
                    logf.close()
                    raise e        
            
    logf.close()


"
42140,blank_index in tf.nn.ctc_loss and tf.nn.ctc_beam_search_decoder has different default value,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7

**Describe the current behavior**

Currently https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss and https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder has different default blank index.

https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss sets default blank index to be 0.

Whreas https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder doesn't have an API for setting blank index, and it assumes to be `num_category - 1` (see https://github.com/tensorflow/tensorflow/blob/cd7da16dd6c17df428dc9ec105c0c8f11e5fd4f5/tensorflow/core/kernels/ctc_decoder_ops.cc#L331)

**Describe the expected behavior**

This is very unexpected - I would assume they have the same default value since they both work with CTC. Or at least both should provide API to change the blank index. 
"
42139,tf.keras.callbacks.TensorBoard does not save batch - level statistics when profiling is disabled completely,"During profile setup, _should_trace is set to false.

https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/keras/callbacks.py#L2137

However, during the batch begin, this is also used:
https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/keras/callbacks.py#L2160

Thus, disabling profiling ALSO disables batch level outputs."
42131,cannot able to train keras fashion_mnist model in tensorflow cpu,"E:\pythonProject\image cliassifir>python imageclif.py
2020-08-07 20:54:14.852315: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-08-07 20:54:14.857148: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-08-07 20:54:17.258338: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2020-08-07 20:54:17.273874: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-07 20:54:17.288006: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-7LER57Q
2020-08-07 20:54:17.293339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-7LER57Q
2020-08-07 20:54:17.296868: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-07 20:54:17.322399: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20589d863f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-07 20:54:17.327558: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Epoch 1/10
Traceback (most recent call last):
  File ""imageclif.py"", line 46, in <module>
    model.fit(train_images,train_labels,epochs=10)
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\training.py"", line 1098, in fit
    tmp_logs = train_function(iterator)
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\eager\def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\eager\def_function.py"", line 823, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\eager\def_function.py"", line 697, in _initialize
    *args, **kwds))
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\eager\function.py"", line 2855, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\eager\function.py"", line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\eager\function.py"", line 3075, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\framework\func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\eager\def_function.py"", line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\framework\func_graph.py"", line 973, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\training.py:806 train_function  *
        return step_function(self, iterator)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\distribute\distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\distribute\distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\distribute\distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\training.py:789 run_step  **
        outputs = model.train_step(data)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\training.py:749 train_step
        y, y_pred, sample_weight, regularization_losses=self.losses)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\compile_utils.py:187 __call__
        self.build(y_pred)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\compile_utils.py:140 build
        self._losses = nest.map_structure(self._get_loss_object, self._losses)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\util\nest.py:635 map_structure
        structure[0], [func(*x) for x in entries],
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\util\nest.py:635 <listcomp>
        structure[0], [func(*x) for x in entries],
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\engine\compile_utils.py:263 _get_loss_object
        loss = losses_mod.get(loss)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\losses.py:1895 get
        return deserialize(identifier)
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\losses.py:1854 deserialize
        printable_module_name='loss function')
    C:\Users\ADMIN\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\keras\utils\generic_utils.py:378 deserialize_keras_object
        'Unknown ' + printable_module_name + ': ' + object_name)

    ValueError: Unknown loss function: spare_categorical_crossentropy"
42129,segfault in `tf.image.crop_and_resize` when `boxes` contains large value,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A




**Describe the current behavior**
`tf.image.crop_and_resize` segfault when there is a very large value in `boxes`. Can also be reproduced in nightly version

**Describe the expected behavior**
Expect no segfault
**Standalone code to reproduce the issue**


~~~python
import tensorflow as tf
tf.image.crop_and_resize(image=tf.zeros((2,1,1,1)), boxes=[[1.0e+40, 0,0,0]], box_indices=[1], crop_size=[1,1])
~~~

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

~~~python
Segmentation fault (core dumped)
~~~"
42128,Add __name__ property to optimizer classes,"
**System information**
- TensorFlow version (you are using): 1.15.3
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Add __name__ property to optimizer classes (and potentially others) for easy access at runtime. 

Current behavior:
`opt = SGD()`
`opt.__name__`
AttributeError: 'Adam' object has no attribute '__name__'

Suggested behavior: 
`opt = SGD()`
`opt.__name__`
""SGD""

**Will this change the current api? How?**

Will allow quick access to class name as string.

**Who will benefit with this feature?**

Researchers compiling results from models using several different optimizers. 

**Any Other info.**
"
42127,TimeDistributed layer does not (always) propagate mask,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.2
- CUDA/cuDNN version: CUDA 10.1.243, cuDNN 7.6.5.32

**Describe the current behavior**
The TimeDistributed layer does not propagate a given mask when a custom wrapped layer is used. In the source code (https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/layers/wrappers.py#L192-L245) it shows, that if the ""_always_use_reshape"" property of the the TimeDistributed layer is false, an RNN-implementation is used, which does not seem to propagate the given mask correctly. ""_always_use_reshape"" is set to false, if the wrapped layer is a custom one. 
The following simple example shows a custom layer, which simply reduces the last dimension of the input by its sum and multiplies the result by the mask. Note that the mask argument in its call function is not optional (in order to show by a thrown exception that the mask is not propagated).

**Describe the expected behavior**
Running the example code as it is shown in the following, will result in the exception: ""_call() missing 1 required positional argument: 'mask'_"". This is not expected since a mask is provided in the call of the TimeDistributed layer. However if the ""_always_use_reshape"" property is set to True, the example works as expected without an exception.

**Standalone code to reproduce the issue**
```
import tensorflow as tf

class TestLayer(tf.keras.layers.Layer):
    def __init__(self):
        super(TestLayer, self).__init__()
        self.supports_masking = True

    def call(self, input, mask):
        # simply sum last dimension
        return tf.reduce_sum(input, axis=-1) * tf.cast(mask, tf.float32)
        
    def compute_output_shape(self, input_shape):
        return input_shape[:-2] + input_shape[-1]
    
    
layer = tf.keras.layers.TimeDistributed(TestLayer())

# By commenting in the following line, this example works properly
# layer._always_use_reshape = True 

result_ones_mask  = layer(tf.random.normal([1,8,4]), mask=tf.ones ([1,8], dtype=tf.bool))
result_zeros_mask = layer(tf.random.normal([1,8,4]), mask=tf.zeros([1,8], dtype=tf.bool))


print(result_ones_mask.numpy())  # expected 1x8-tensor with random numbers
print(result_zeros_mask.numpy()) # expected 1x8-tensor with zeros
```


"
42126,Tensorflow getting stuck when running forward pass for a tf hub module,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.6.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: using on CPU
- GPU model and memory: using on CPU

**Describe the current behavior**
Tensorflow get stuck, it hangs suddenly and intermittently

**Describe the expected behavior**
Tensorflow not getting stuck

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_text

module = hub.load(""https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3"")
for i in range(50):
    response_embeddings = module.signatures['response_encoder'](
        input=tf.constant([""I am happy"", ""I am not happy""]),
        context=tf.constant([""I am happy"", ""I am not happy""]))
    t = response_embeddings[""outputs""].numpy()
    print(t.shape)
```
If you repeat that last loop of 50 iterations like 3 times or something it will just get stuck and hang.

"
42125,using tf.compat.v1.ragged.placeholder,"Hello , 

I'm facing some issue with tf.compat.v1.ragged.placeholder. I would appreciate your help on how to fix this. I'm not sure if this is a bug or lack of documentation especially that the official website does not provide any examples on how to use such placeholders. 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): '2.3.0'
- Python version: 3.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 10.1
- GPU model and memory: RTX 2080 TI


**Describe the current behavior**
I'm trying to pass a simple ragged array to tf.compat.v1.ragged.placeholder but Tensorflow throws the below error :
                               `AttributeError: 'list' object has no attribute 'nested_row_splits'` 
a similar code works fine on ragged.constant

**Describe the expected behavior**
I have tried to run the same code using ragged.constantand it works fine. I believe that tf.compat.v1.ragged.placeholder should work exactly like ragged.constant in terms of user interface without any code modification from the user. of course the internal handling could be different but this is abstracted from the user.  IF this is not possible I would appreciate your help on how to use ragged.Placeholders 
below is a code using constants and is working fine : 
```
rt = tf.ragged.constant([[[1, 2 ] ,  [4, 5]] , [[6, 7] ,  [8, 9] , [10, 11]]] , ragged_rank=1 )
rt= tf.Print(rt.values , [rt.values] , ""This is a constat"")
with tf.Session() as sess : 
    re    = sess.run([rt  ])


output : 
    This is a constat[[1 2][4...]...] 
```



**Standalone code to reproduce the issue**

```
import tensorflow.compat.v1 as tf
tf.compat.v1.disable_eager_execution()
tf.disable_v2_behavior()
vals = [[[1, 2 ] ,  [4, 5]] , [[6, 7] ,  [8, 9] , [10, 11]]]

myTensor = tf.compat.v1.ragged.placeholder(dtype=tf.int32 , ragged_rank=1)
rt= tf.Print(myTensor.values , [myTensor.values] , ""This is a placeholder"")
with tf.Session() as sess : 
    re    = sess.run([rt  ],feed_dict={myTensor:vals})

```

this throws the below exception : 
```
<ipython-input-27-5c8fe49f6984> in <module>
      6 rt= tf.Print(myTensor.values , [myTensor.values] , ""This is a placeholder"")
      7 with tf.Session() as sess :
----> 8     re    = sess.run([rt  ],feed_dict={myTensor:vals})

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    956     try:
    957       result = self._run(None, fetches, feed_dict, options_ptr,
--> 958                          run_metadata_ptr)
    959       if run_metadata:
    960         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1116       feed_dict = nest.flatten_dict_items(feed_dict)
   1117       for feed, feed_val in feed_dict.items():
-> 1118         for subfeed, subfeed_val in _feed_fn(feed, feed_val):
   1119           try:
   1120             subfeed_t = self.graph.as_graph_element(

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\client\session.py in _feed_fn(feed, feed_val)
   1096       for tensor_type, _, feed_fn, _ in _REGISTERED_EXPANSIONS:
   1097         if isinstance(feed, tensor_type):
-> 1098           return feed_fn(feed, feed_val)
   1099       raise TypeError('Feed argument %r has invalid type %r' %
   1100                       (feed, type(feed)))

C:\ProgramData\Anaconda3\envs\AutoEncoder\lib\site-packages\tensorflow\python\ops\ragged\ragged_tensor.py in _ragged_tensor_session_feed(feed_key, feed_val)
   2366 def _ragged_tensor_session_feed(feed_key, feed_val):
   2367   key_components = feed_key.nested_row_splits + (feed_key.flat_values,)
-> 2368   val_components = feed_val.nested_row_splits + (feed_val.flat_values,)
   2369   return zip(key_components, val_components)
   2370 

AttributeError: 'list' object has no attribute 'nested_row_splits'
```"
42123,No documentation on how to profile the memory usage for TF,"Hello,

## URL(s) with the issue:

https://www.tensorflow.org/guide/profiler#memory_profile_tool

## Description of issue (what needs changing):

### Clear description

TF profiler only outputs the CPU information with the default configuration, but I was not able to find neither in the documentation nor on the StackOverflow etc. how to set it up for monitoring the memory usage.

I get only this message on the ""memory_profile"" tools page:
""There is no memory profile to display because there were no memory activity data in the captured duration. ""

TF and tensorboard versions are both 2.3.0.
Profiling is run on the machine without GPU, under the non-root user, in Jupyter Notebook.

### Usage example

No code example for the memory profiling is provided, hence it is not clear whether some setting should be provided to the profiler."
42122,tflite runtime package compatibility for Raspeberry Pi,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian GNU/Linux 10(buster)
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Raspberry Pi Model B Rev 2

**Describe the problem**
I have an old Raspberry Pi, probably one of the first model they released. It as an ARMv6-compatible processor rev 7, BCM2835. It is RPi Model B Rev 2

I get the error : **tflite_runtime-2.1.0.post1-cp37-cp37m-linux_armv7l.whl is not a supported wheel on this platform**

**Please provide the exact sequence of commands/steps when you ran into the problem**

1. Installed latest version of python, pip-20.2.1 wheel-0.34.2, Python3.7
2. Installed OpenCV
`sudo apt-get -y install libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev
sudo apt-get -y install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev
sudo apt-get -y install libxvidcore-dev libx264-dev
sudo apt-get -y install qt4-dev-tools libatlas-base-dev
pip3 install opencv-python==3.4.6.27`

3. Tried installing https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_armv7l.whl and https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_aarch64.whl (as given in https://www.tensorflow.org/lite/guide/python) gives the same error **_*.whl is not a supported wheel on this platform_**
![image](https://user-images.githubusercontent.com/64406245/89629896-d8166480-d89e-11ea-9735-53e8fa80ccf6.png)

Please let me know if TF Lite runtime package is supported on this platform.
"
42121,keras.models.load_model fails after tf.reset_default_graph OR tf.keras.backend.clear_session,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.15.0-rc3-22-g590d6eef7e 1.15.0
- Python version: Python 3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)] on win32
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1.243/6.14.11.10010
- GPU model and memory: GeForce GTX 960M 3040 MB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
The second load_model fails with error ""Cannot interpret feed_dict key as Tensor: Tensor Tensor(""Placeholder:0"", shape=(40, 80), dtype=float32) is not an element of this graph.""

**Describe the expected behavior**
I expect the model to be loaded, exactly like in the first call 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
    import tensorflow as tf
    from keras.models import load_model

    model = load_model(""model.h5"")
    model.summary()

    # tf.reset_default_graph() OR
    tf.keras.backend.clear_session()

    model = load_model(""model.h5"")
    model.summary()

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42120,Slow iteration/converting of tensors to vector<float> via Python C API,"**System information**
- Have I written custom code: **Yes**
- OS Platform and Distribution: **Windows 10 Build 19041 and Docker version 19.03.12**
- TensorFlow installed from: **binary**
- TensorFlow version: **v2.3.0-rc2-23-gb36436b087 2.3.0**
- Python version: **3.6.9**
- CUDA/cuDNN version: **No GPU**
- GPU model and memory: **No GPU**

**Describe the current behavior**

Currently iteration/converting of tensor to `vector<float>` via Python C API is extremely slow - it takes from 13 seconds to a minute to convert 100 tensors (with shape `(1792,)`) into c++ `vector<float>`.

If the tensor is converted into ndarray with `numpy()` call beforehand the operation is performed instantaneously. 

**Describe the expected behavior**

The speed of tensor conversion and the speed of ndarray conversion is the same (or similar). 

**Standalone code to reproduce the issue**

[Collab Notebook](https://colab.research.google.com/drive/1ISRM-9Vr0hcM6xrPtCMZLQpjvQ2T_OcS)

```python
from annoy import AnnoyIndex
import tensorflow as tf
from time import perf_counter

tf.compat.v1.enable_eager_execution()

dims = 1792
trees = 10000
features = []

for key in range(0, 100):
    features.append(tf.random.uniform([dims]))

t1 = perf_counter()

t = AnnoyIndex(dims, metric='angular')

for key, feature in enumerate(features):
    # t.add_item(key, feature.numpy())
    t.add_item(key, feature)

t2 = perf_counter()

print(f""Vector add: {t2 - t1:.2f}"")
```

**Other info / logs**

The issue is present in both Tensorflow 1 and 2. Tested in Docker.

- Tensorflow: 2.3.0 (`tensorflow/tensorflow:latest-jupyter`): Vector add: 28.09
- Tensorflow: 2.3.0 with `numpy()` call (`tensorflow/tensorflow:latest-jupyter`): Vector add: 0.02
- Tensorflow: 1.15.2 (`tensorflow/tensorflow:1.15.2-py3-jupyter`): Vector add: 29.82


Same issue in [annoy library](https://github.com/spotify/annoy/issues/498).
[Maybe relevant Tensorflow issue](https://github.com/tensorflow/tensorflow/issues/27692). I tested on Numpy 1.19.1 and it did not help.

Annoy library call hierarchy:
- [add_item](https://github.com/spotify/annoy/blob/master/src/annoymodule.cc#L534)
- [py_an_add_item](https://github.com/spotify/annoy/blob/master/src/annoymodule.cc#L369)
- [convert_list_to_vector](https://github.com/spotify/annoy/blob/master/src/annoymodule.cc#L295)
   - `int z` - cycle iterator
   - `int f` - tensor length
   - `PyObject* v` - tensor
   - `PyObject *pf` - one tensor value

```c
  for (int z = 0; z < f; z++) {
    PyObject *key = PyInt_FromLong(z);
    PyObject *pf = PyObject_GetItem(v, key);
    (*w)[z] = PyFloat_AsDouble(pf);
    Py_DECREF(key);
    Py_DECREF(pf);
  }
```"
42119,autograph fails inside keras model train_step including a for loop over a tensor,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linus Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary (docker image latest-gpu-py3)
- TensorFlow version (use command below): 2.3
- Python version: Python 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: V100

**Describe the current behavior**

When writing a python ""for"" loop inside a tf.keras.Model.train_step I get the following error:

OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.

The same function works correctly when outside of a keras model but still decorated with tf.function. 

**Describe the expected behavior**

autograph should support iterating over a tensor also inside a keras model

**Standalone code to reproduce the issue**

```
import tensorflow as tf
import numpy as np

t = tf.Variable(0)

@tf.function()
def foo():
    for n in tf.range(tf.constant(10)):
        t.assign_add(n)
    return t

nt = foo()
nt #  <tf.Tensor: shape=(), dtype=int32, numpy=45>

class mymodel(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.t = tf.Variable(0)
    def train_step(self, data):
        for n in tf.range(tf.constant(10)):
            t.assign_add(n)
        return {""loss"": t}

mm = mymodel()
mm.compile()
mm.fit(np.random.random((5)), steps_per_epoch=1) # this doesn't work see trace below
```

**Other info / logs** 

OperatorNotAllowedInGraphErrorTraceback (most recent call last)
<ipython-input-18-c68155fbb474> in <module>
----> 1 mm.fit(np.random.random((5)), steps_per_epoch=1)

~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1096                 batch_size=batch_size):
   1097               callbacks.on_train_batch_begin(step)
-> 1098               tmp_logs = train_function(iterator)
   1099               if data_handler.should_sync:
   1100                 context.async_wait()

~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    821       # This is the first call of __call__, so we have to initialize.
    822       initializers = []
--> 823       self._initialize(args, kwds, add_initializers_to=initializers)
    824     finally:
    825       # At this point we know that the initialization is complete (or less

~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    695     self._concrete_stateful_fn = (
    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 697             *args, **kwds))
    698 
    699     def invalid_creator_scope(*unused_args, **unused_kwds):

~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2853       args, kwargs = None, None
   2854     with self._lock:
-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2856     return graph_function
   2857 

~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3211 
   3212       self._function_cache.missed.add(call_context_key)
-> 3213       graph_function = self._create_graph_function(args, kwargs)
   3214       self._function_cache.primary[cache_key] = graph_function
   3215       return graph_function, args, kwargs

~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3073             arg_names=arg_names,
   3074             override_flat_arg_shapes=override_flat_arg_shapes,
-> 3075             capture_by_value=self._capture_by_value),
   3076         self._function_attributes,
   3077         function_spec=self.function_spec,

~usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--> 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    599         # the function a weak reference to itself to avoid a reference cycle.
--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    601     weak_wrapped_fn = weakref.ref(wrapped_fn)
    602 

~usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    971           except Exception as e:  # pylint:disable=broad-except
    972             if hasattr(e, ""ag_error_metadata""):
--> 973               raise e.ag_error_metadata.to_exception(e)
    974             else:
    975               raise

OperatorNotAllowedInGraphError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **
        outputs = model.train_step(data)
    <ipython-input-12-62f0dcb0797d>:6 train_step
        for n in tf.range(tf.constant(10)):
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:503 __iter__
        self._disallow_iteration()
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:496 _disallow_iteration
        self._disallow_when_autograph_enabled(""iterating over `tf.Tensor`"")
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:474 _disallow_when_autograph_enabled
        "" indicate you are trying to use an unsupported feature."".format(task))

    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.





"
42118,keras meet a problem with sync bn in multi worker,"```strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(communication=getattr(tf.distribute.experimental.CollectiveCommunication,'NCCL'))  #RING WORK
with strategy.scope():
    
    inputs = keras.Input(shape=(256,256,3), name='digits')
    output1=applications.ResNet50()(inputs)
    # ,normalizer=""l2"",normalize_args={'axis':1})
    outputs = layers.Dense(1, activation='relu', name='dense_1')(output1)
    model = keras.Model(inputs=inputs, outputs=outputs)
    # inputs = keras.Input(shape=(784,), name='digits')
    # num_units = 4096
    # dense1 = layers.Dense(num_units, activation='relu', name='dense_1')
    # x = dense1(inputs)
    # x=tf.keras.layers.experimental.SyncBatchNormalization()(x)
    # dense2 = layers.Dense(num_units, activation='relu', name='dense_2')
    # x = dense2(x)
    # outputs = layers.Dense(10, activation='softmax', name='predictions')(x)
    # model = keras.Model(inputs=inputs, outputs=outputs)
    model.compile(loss='sparse_categorical_crossentropy',
                optimizer=keras.optimizers.RMSprop(),
                metrics=['accuracy'])
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train=np.zeros((2048,64,64,3),dtype=np.float32)
x_test = x_train[:2048]
y_train=y_train[:2048]
y_test=y_test[:2048]
history = model.fit(x_train, y_train,
                    batch_size=1024,
                    epochs=5,
                    validation_split=0.2)
test_scores = model.evaluate(x_test, y_test, verbose=1)
print('Test loss:', test_scores[0])
print('Test accuracy:', test_scores[1])
```

the training code

here is the custom resnet:

```# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
# pylint: disable=invalid-name
""""""ResNet models for Keras.

Reference:
  - [Deep Residual Learning for Image Recognition](
      https://arxiv.org/abs/1512.03385) (CVPR 2015)
""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from tensorflow.python.keras import backend
from tensorflow.python.keras.applications import imagenet_utils
from tensorflow.python.keras.engine import training
from tensorflow.python.keras.layers import VersionAwareLayers
from tensorflow.python.keras.utils import data_utils
from tensorflow.python.keras.utils import layer_utils
from tensorflow.python.lib.io import file_io
from tensorflow.python.util.tf_export import keras_export
from tensorflow.keras.layers.experimental import SyncBatchNormalization as BatchNormalization

BASE_WEIGHTS_PATH = (
    'https://storage.googleapis.com/tensorflow/keras-applications/resnet/')
WEIGHTS_HASHES = {
    'resnet50': ('2cb95161c43110f7111970584f804107',
                 '4d473c1dd8becc155b73f8504c6f6626'),
    'resnet101': ('f1aeb4b969a6efcfb50fad2f0c20cfc5',
                  '88cf7a10940856eca736dc7b7e228a21'),
    'resnet152': ('100835be76be38e30d865e96f2aaae62',
                  'ee4c566cf9a93f14d82f913c2dc6dd0c'),
    'resnet50v2': ('3ef43a0b657b3be2300d5770ece849e0',
                   'fac2f116257151a9d068a22e544a4917'),
    'resnet101v2': ('6343647c601c52e1368623803854d971',
                    'c0ed64b8031c3730f411d2eb4eea35b5'),
    'resnet152v2': ('a49b44d1979771252814e80f8ec446f9',
                    'ed17cf2e0169df9d443503ef94b23b33'),
    'resnext50': ('67a5b30d522ed92f75a1f16eef299d1a',
                  '62527c363bdd9ec598bed41947b379fc'),
    'resnext101':
        ('34fb605428fcc7aa4d62f44404c11509', '0f678c91647380debd923963594981b3')
}

layers = None


def ResNet(stack_fn,
           preact,
           use_bias,
           model_name='resnet',
           include_top=True,
           weights='imagenet',
           input_tensor=None,
           input_shape=None,
           pooling=None,
           classes=1000,
           classifier_activation='softmax',
           **kwargs):
  """"""Instantiates the ResNet, ResNetV2, and ResNeXt architecture.

  Reference:
  - [Deep Residual Learning for Image Recognition](
      https://arxiv.org/abs/1512.03385) (CVPR 2015)

  Optionally loads weights pre-trained on ImageNet.
  Note that the data format convention used by the model is
  the one specified in your Keras config at `~/.keras/keras.json`.

  Caution: Be sure to properly pre-process your inputs to the application.
  Please see `applications.resnet.preprocess_input` for an example.

  Arguments:
    stack_fn: a function that returns output tensor for the
      stacked residual blocks.
    preact: whether to use pre-activation or not
      (True for ResNetV2, False for ResNet and ResNeXt).
    use_bias: whether to use biases for convolutional layers or not
      (True for ResNet and ResNetV2, False for ResNeXt).
    model_name: string, model name.
    include_top: whether to include the fully-connected
      layer at the top of the network.
    weights: one of `None` (random initialization),
      'imagenet' (pre-training on ImageNet),
      or the path to the weights file to be loaded.
    input_tensor: optional Keras tensor
      (i.e. output of `layers.Input()`)
      to use as image input for the model.
    input_shape: optional shape tuple, only to be specified
      if `include_top` is False (otherwise the input shape
      has to be `(224, 224, 3)` (with `channels_last` data format)
      or `(3, 224, 224)` (with `channels_first` data format).
      It should have exactly 3 inputs channels.
    pooling: optional pooling mode for feature extraction
      when `include_top` is `False`.
      - `None` means that the output of the model will be
          the 4D tensor output of the
          last convolutional layer.
      - `avg` means that global average pooling
          will be applied to the output of the
          last convolutional layer, and thus
          the output of the model will be a 2D tensor.
      - `max` means that global max pooling will
          be applied.
    classes: optional number of classes to classify images
      into, only to be specified if `include_top` is True, and
      if no `weights` argument is specified.
    classifier_activation: A `str` or callable. The activation function to use
      on the ""top"" layer. Ignored unless `include_top=True`. Set
      `classifier_activation=None` to return the logits of the ""top"" layer.
    **kwargs: For backwards compatibility only.
  Returns:
    A `keras.Model` instance.

  Raises:
    ValueError: in case of invalid argument for `weights`,
      or invalid input shape.
    ValueError: if `classifier_activation` is not `softmax` or `None` when
      using a pretrained top layer.
  """"""
  global layers
  if 'layers' in kwargs:
    layers = kwargs.pop('layers')
  else:
    layers = VersionAwareLayers()
  if kwargs:
    raise ValueError('Unknown argument(s): %s' % (kwargs,))
  if not (weights in {'imagenet', None} or file_io.file_exists(weights)):
    raise ValueError('The `weights` argument should be either '
                     '`None` (random initialization), `imagenet` '
                     '(pre-training on ImageNet), '
                     'or the path to the weights file to be loaded.')

  if weights == 'imagenet' and include_top and classes != 1000:
    raise ValueError('If using `weights` as `""imagenet""` with `include_top`'
                     ' as true, `classes` should be 1000')

  # Determine proper input shape
  input_shape = imagenet_utils.obtain_input_shape(
      input_shape,
      default_size=224,
      min_size=32,
      data_format=backend.image_data_format(),
      require_flatten=include_top,
      weights=weights)

  if input_tensor is None:
    img_input = layers.Input(shape=input_shape)
  else:
    if not backend.is_keras_tensor(input_tensor):
      img_input = layers.Input(tensor=input_tensor, shape=input_shape)
    else:
      img_input = input_tensor

  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1

  x = layers.ZeroPadding2D(
      padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)
  x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)

  if not preact:
    x = BatchNormalization(
        axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)
    x = layers.Activation('relu', name='conv1_relu')(x)

  x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)
  x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)

  x = stack_fn(x)

  if preact:
    x = BatchNormalization(
        axis=bn_axis, epsilon=1.001e-5, name='post_bn')(x)
    x = layers.Activation('relu', name='post_relu')(x)

  if include_top:
    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)
    imagenet_utils.validate_activation(classifier_activation, weights)
    x = layers.Dense(classes, activation=classifier_activation,
                     name='predictions')(x)
  else:
    if pooling == 'avg':
      x = layers.GlobalAveragePooling2D(name='avg_pool')(x)
    elif pooling == 'max':
      x = layers.GlobalMaxPooling2D(name='max_pool')(x)

  # Ensure that the model takes into account
  # any potential predecessors of `input_tensor`.
  if input_tensor is not None:
    inputs = layer_utils.get_source_inputs(input_tensor)
  else:
    inputs = img_input

  # Create model.
  model = training.Model(inputs, x, name=model_name)

  # Load weights.
  if (weights == 'imagenet') and (model_name in WEIGHTS_HASHES):
    if include_top:
      file_name = model_name + '_weights_tf_dim_ordering_tf_kernels.h5'
      file_hash = WEIGHTS_HASHES[model_name][0]
    else:
      file_name = model_name + '_weights_tf_dim_ordering_tf_kernels_notop.h5'
      file_hash = WEIGHTS_HASHES[model_name][1]
    weights_path = data_utils.get_file(
        file_name,
        BASE_WEIGHTS_PATH + file_name,
        cache_subdir='models',
        file_hash=file_hash)
    model.load_weights(weights_path)
  elif weights is not None:
    model.load_weights(weights)

  return model


def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):
  """"""A residual block.

  Arguments:
    x: input tensor.
    filters: integer, filters of the bottleneck layer.
    kernel_size: default 3, kernel size of the bottleneck layer.
    stride: default 1, stride of the first layer.
    conv_shortcut: default True, use convolution shortcut if True,
        otherwise identity shortcut.
    name: string, block label.

  Returns:
    Output tensor for the residual block.
  """"""
  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1

  if conv_shortcut:
    shortcut = layers.Conv2D(
        4 * filters, 1, strides=stride, name=name + '_0_conv')(x)
    shortcut = BatchNormalization(
        axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)
  else:
    shortcut = x

  x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)
  x = BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)
  x = layers.Activation('relu', name=name + '_1_relu')(x)

  x = layers.Conv2D(
      filters, kernel_size, padding='SAME', name=name + '_2_conv')(x)
  x = BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)
  x = layers.Activation('relu', name=name + '_2_relu')(x)

  x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)
  x = BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)

  x = layers.Add(name=name + '_add')([shortcut, x])
  x = layers.Activation('relu', name=name + '_out')(x)
  return x


def stack1(x, filters, blocks, stride1=2, name=None):
  """"""A set of stacked residual blocks.

  Arguments:
    x: input tensor.
    filters: integer, filters of the bottleneck layer in a block.
    blocks: integer, blocks in the stacked blocks.
    stride1: default 2, stride of the first layer in the first block.
    name: string, stack label.

  Returns:
    Output tensor for the stacked blocks.
  """"""
  x = block1(x, filters, stride=stride1, name=name + '_block1')
  for i in range(2, blocks + 1):
    x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))
  return x


def block2(x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None):
  """"""A residual block.

  Arguments:
      x: input tensor.
      filters: integer, filters of the bottleneck layer.
      kernel_size: default 3, kernel size of the bottleneck layer.
      stride: default 1, stride of the first layer.
      conv_shortcut: default False, use convolution shortcut if True,
        otherwise identity shortcut.
      name: string, block label.

  Returns:
    Output tensor for the residual block.
  """"""
  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1

  preact = BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_preact_bn')(x)
  preact = layers.Activation('relu', name=name + '_preact_relu')(preact)

  if conv_shortcut:
    shortcut = layers.Conv2D(
        4 * filters, 1, strides=stride, name=name + '_0_conv')(preact)
  else:
    shortcut = layers.MaxPooling2D(1, strides=stride)(x) if stride > 1 else x

  x = layers.Conv2D(
      filters, 1, strides=1, use_bias=False, name=name + '_1_conv')(preact)
  x = BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)
  x = layers.Activation('relu', name=name + '_1_relu')(x)

  x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)
  x = layers.Conv2D(
      filters,
      kernel_size,
      strides=stride,
      use_bias=False,
      name=name + '_2_conv')(x)
  x = BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)
  x = layers.Activation('relu', name=name + '_2_relu')(x)

  x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)
  x = layers.Add(name=name + '_out')([shortcut, x])
  return x


def stack2(x, filters, blocks, stride1=2, name=None):
  """"""A set of stacked residual blocks.

  Arguments:
      x: input tensor.
      filters: integer, filters of the bottleneck layer in a block.
      blocks: integer, blocks in the stacked blocks.
      stride1: default 2, stride of the first layer in the first block.
      name: string, stack label.

  Returns:
      Output tensor for the stacked blocks.
  """"""
  x = block2(x, filters, conv_shortcut=True, name=name + '_block1')
  for i in range(2, blocks):
    x = block2(x, filters, name=name + '_block' + str(i))
  x = block2(x, filters, stride=stride1, name=name + '_block' + str(blocks))
  return x


def block3(x,
           filters,
           kernel_size=3,
           stride=1,
           groups=32,
           conv_shortcut=True,
           name=None):
  """"""A residual block.

  Arguments:
    x: input tensor.
    filters: integer, filters of the bottleneck layer.
    kernel_size: default 3, kernel size of the bottleneck layer.
    stride: default 1, stride of the first layer.
    groups: default 32, group size for grouped convolution.
    conv_shortcut: default True, use convolution shortcut if True,
        otherwise identity shortcut.
    name: string, block label.

  Returns:
    Output tensor for the residual block.
  """"""
  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1

  if conv_shortcut:
    shortcut = layers.Conv2D(
        (64 // groups) * filters,
        1,
        strides=stride,
        use_bias=False,
        name=name + '_0_conv')(x)
    shortcut = BatchNormalization(
        axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)
  else:
    shortcut = x

  x = layers.Conv2D(filters, 1, use_bias=False, name=name + '_1_conv')(x)
  x = BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)
  x = layers.Activation('relu', name=name + '_1_relu')(x)

  c = filters // groups
  x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)
  x = layers.DepthwiseConv2D(
      kernel_size,
      strides=stride,
      depth_multiplier=c,
      use_bias=False,
      name=name + '_2_conv')(x)
  x_shape = backend.int_shape(x)[1:-1]
  x = layers.Reshape(x_shape + (groups, c, c))(x)
  x = layers.Lambda(
      lambda x: sum(x[:, :, :, :, i] for i in range(c)),
      name=name + '_2_reduce')(x)
  x = layers.Reshape(x_shape + (filters,))(x)
  x = BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)
  x = layers.Activation('relu', name=name + '_2_relu')(x)

  x = layers.Conv2D(
      (64 // groups) * filters, 1, use_bias=False, name=name + '_3_conv')(x)
  x = BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)

  x = layers.Add(name=name + '_add')([shortcut, x])
  x = layers.Activation('relu', name=name + '_out')(x)
  return x


def stack3(x, filters, blocks, stride1=2, groups=32, name=None):
  """"""A set of stacked residual blocks.

  Arguments:
    x: input tensor.
    filters: integer, filters of the bottleneck layer in a block.
    blocks: integer, blocks in the stacked blocks.
    stride1: default 2, stride of the first layer in the first block.
    groups: default 32, group size for grouped convolution.
    name: string, stack label.

  Returns:
    Output tensor for the stacked blocks.
  """"""
  x = block3(x, filters, stride=stride1, groups=groups, name=name + '_block1')
  for i in range(2, blocks + 1):
    x = block3(
        x,
        filters,
        groups=groups,
        conv_shortcut=False,
        name=name + '_block' + str(i))
  return x


@keras_export('keras.applications.resnet50.ResNet50',
              'keras.applications.resnet.ResNet50',
              'keras.applications.ResNet50')
def ResNet50(include_top=True,
             weights='imagenet',
             input_tensor=None,
             input_shape=None,
             pooling=None,
             classes=1000,
             **kwargs):
  """"""Instantiates the ResNet50 architecture.""""""

  def stack_fn(x):
    x = stack1(x, 64, 3, stride1=1, name='conv2')
    x = stack1(x, 128, 4, name='conv3')
    x = stack1(x, 256, 6, name='conv4')
    return stack1(x, 512, 3, name='conv5')

  return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,
                input_tensor, input_shape, pooling, classes, **kwargs)


@keras_export('keras.applications.resnet.ResNet101',
              'keras.applications.ResNet101')
def ResNet101(include_top=True,
              weights='imagenet',
              input_tensor=None,
              input_shape=None,
              pooling=None,
              classes=1000,
              **kwargs):
  """"""Instantiates the ResNet101 architecture.""""""

  def stack_fn(x):
    x = stack1(x, 64, 3, stride1=1, name='conv2')
    x = stack1(x, 128, 4, name='conv3')
    x = stack1(x, 256, 23, name='conv4')
    return stack1(x, 512, 3, name='conv5')

  return ResNet(stack_fn, False, True, 'resnet101', include_top, weights,
                input_tensor, input_shape, pooling, classes, **kwargs)


@keras_export('keras.applications.resnet.ResNet152',
              'keras.applications.ResNet152')
def ResNet152(include_top=True,
              weights='imagenet',
              input_tensor=None,
              input_shape=None,
              pooling=None,
              classes=1000,
              **kwargs):
  """"""Instantiates the ResNet152 architecture.""""""

  def stack_fn(x):
    x = stack1(x, 64, 3, stride1=1, name='conv2')
    x = stack1(x, 128, 8, name='conv3')
    x = stack1(x, 256, 36, name='conv4')
    return stack1(x, 512, 3, name='conv5')

  return ResNet(stack_fn, False, True, 'resnet152', include_top, weights,
                input_tensor, input_shape, pooling, classes, **kwargs)


@keras_export('keras.applications.resnet50.preprocess_input',
              'keras.applications.resnet.preprocess_input')
def preprocess_input(x, data_format=None):
  return imagenet_utils.preprocess_input(
      x, data_format=data_format, mode='caffe')


@keras_export('keras.applications.resnet50.decode_predictions',
              'keras.applications.resnet.decode_predictions')
def decode_predictions(preds, top=5):
  return imagenet_utils.decode_predictions(preds, top=top)


preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(
    mode='',
    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_CAFFE,
    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__

DOC = """"""

  Reference paper:
  - [Deep Residual Learning for Image Recognition]
  (https://arxiv.org/abs/1512.03385) (CVPR 2015)

  Optionally loads weights pre-trained on ImageNet.
  Note that the data format convention used by the model is
  the one specified in your Keras config at `~/.keras/keras.json`.

  Arguments:
    include_top: whether to include the fully-connected
      layer at the top of the network.
    weights: one of `None` (random initialization),
      'imagenet' (pre-training on ImageNet),
      or the path to the weights file to be loaded.
    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
      to use as image input for the model.
    input_shape: optional shape tuple, only to be specified
      if `include_top` is False (otherwise the input shape
      has to be `(224, 224, 3)` (with `'channels_last'` data format)
      or `(3, 224, 224)` (with `'channels_first'` data format).
      It should have exactly 3 inputs channels,
      and width and height should be no smaller than 32.
      E.g. `(200, 200, 3)` would be one valid value.
    pooling: Optional pooling mode for feature extraction
      when `include_top` is `False`.
      - `None` means that the output of the model will be
          the 4D tensor output of the
          last convolutional block.
      - `avg` means that global average pooling
          will be applied to the output of the
          last convolutional block, and thus
          the output of the model will be a 2D tensor.
      - `max` means that global max pooling will
          be applied.
    classes: optional number of classes to classify images
      into, only to be specified if `include_top` is True, and
      if no `weights` argument is specified.

  Returns:
    A Keras model instance.
""""""

setattr(ResNet50, '__doc__', ResNet50.__doc__ + DOC)
setattr(ResNet101, '__doc__', ResNet101.__doc__ + DOC)
setattr(ResNet152, '__doc__', ResNet152.__doc__ + DOC)
```

_Originally posted by @ImMrMa in https://github.com/tensorflow/tensorflow/issues/42051#issuecomment-670379919_"
42117,Why the performance slowly by double 1080ti than single 1080ti?,"I write a code for double 1080ti , I find the speed not reduce than single 1080ti, but I check the information by nvidia-smi the double 1080ti is working, I don't understand why the double 1080ti almost same speed than single 1080ti ?

I use the tensorboard to watch the profile:
![image](https://user-images.githubusercontent.com/10364552/89617865-8a5d2480-d8bd-11ea-8b98-e52d95f8cadc.png)
It is looks input waste lots of time , how to fix this problem?

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
The full code:
Double 1080ti:
```
#!/usr/bin/env python
# coding: utf-8

# In[1]:

import sys
import os
from datetime import datetime
#from packaging import version
os.environ[""CUDA_VISIBLE_DEVICES""]=""0,1""
batch_size = 128
epochs = 500
IMG_HEIGHT = 224
IMG_WIDTH = 224
NUM_WORKERS = 4

PATH = os.path.abspath(os.path.dirname(__file__))

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'valid')

train_close_dir = os.path.join(train_dir, 'close')  # directory with our training cat pictures
train_open_dir = os.path.join(train_dir, 'open')  # directory with our training dog pictures
validation_close_dir = os.path.join(validation_dir, 'close')  # directory with our validation cat pictures
validation_open_dir = os.path.join(validation_dir, 'open')  # directory with our validation dog pictures


import tensorflow as tf

print (tf.__version__)


# In[2]:


print(""Version: "", tf.__version__)
print(""Eager mode: "", tf.executing_eagerly())
print(""GPU is"", ""available"" if tf.config.experimental.list_physical_devices(""GPU"") else ""NOT AVAILABLE"")

gpus = tf.config.experimental.list_physical_devices('GPU')
for g in gpus:
    tf.config.experimental.set_virtual_device_configuration(g, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])


# In[3]:


from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import random

import matplotlib.pyplot as plt

# In[4]:
#mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
mirrored_strategy = tf.distribute.MirroredStrategy()

num_close_tr = len(os.listdir(train_close_dir))
num_open_tr = len(os.listdir(train_open_dir))

num_close_val = len(os.listdir(validation_close_dir))
num_open_val = len(os.listdir(validation_open_dir))

total_train = num_close_tr + num_open_tr
total_val = num_close_val + num_open_val

print('total training close images:', num_close_tr)
print('total training open images:', num_open_tr)
print('total validation close images:', num_close_val)
print('total validation open images:', num_open_val)
print(""--"")
print(""Total training images:"", total_train)
print(""Total validation images:"", total_val)


if len(sys.argv) > 1:
    batch_size = int(sys.argv[1])

if len(sys.argv) > 2:
    epochs = int(sys.argv[2])

def preprocess_image(image):
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [image_size, image_size])
    image /= 255.0
    return image

def load_and_preprocess_image(path):
    image = tf.io.read_file(path)
    return preprocess_image(image)


train_image_generator = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.1, rotation_range=45) # Generator for our training data
validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data

train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,
                                                           directory=train_dir,
                                                           shuffle=True,
                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                           class_mode='binary')

val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,
                                                              directory=validation_dir,
                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                              class_mode='binary')

sample_training_images, _ = next(train_data_gen)


# In[5]:


def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20, 20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

plotImages(sample_training_images[:5])



# In[6]:




# In[7]:


with mirrored_strategy.scope():
    tinydarknet = keras.Sequential([
        keras.layers.Conv2D(16, (3, 3), strides=[1, 1], padding=""same"", input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),
        keras.layers.Conv2D(32, (3, 3), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),
        keras.layers.Conv2D(16, (1, 1), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(128, (3, 3), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(16, (1, 1), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(128, (3, 3), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),
        keras.layers.Conv2D(32, (1, 1), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(256, (3, 3), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(32, (1, 1), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(256, (3, 3), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),
        keras.layers.Conv2D(64, (1, 1), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(512, (3, 3), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(64, (1, 1), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(512, (3, 3), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(128, (1, 1), strides=[1, 1], padding=""same""),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(1000, (1, 1)),
        keras.layers.BatchNormalization(),
        keras.layers.AveragePooling2D(),
        keras.layers.Flatten(),
        keras.layers.Dense(1)
    ])


    # In[8]:


    tinydarknet.compile(optimizer=""adam"",
                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
                 metrics=[""accuracy""])


# In[9]:
logs = ""logs/"" + datetime.now().strftime(""%Y%m%d-%H%M%S"")
tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,
                                                 histogram_freq = 1,
                                                 profile_batch = '500,520')


history = tinydarknet.fit(#_generator(
    train_data_gen,
    steps_per_epoch=total_train // batch_size,
    epochs=epochs,
    validation_data=val_data_gen,
    validation_steps=total_val // batch_size,
    workers=NUM_WORKERS,
    callbacks = [tboard_callback]
)


# In[10]:


acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss=history.history['loss']
val_loss=history.history['val_loss']

epochs_range = range(epochs)


tinydarknet.save(""keras_model"")

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open(""tinydarknet.tflite"", ""w+b"") as fp:
    fp.write(tflite_model)
    fp.flush()

```

The single 1080ti code:
```
#!/usr/bin/env python
# coding: utf-8

# In[1]:

import sys
import os

batch_size = 128
epochs = 500
IMG_HEIGHT = 224
IMG_WIDTH = 224
NUM_WORKERS = 4

PATH = os.path.abspath(os.path.dirname(__file__))

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'valid')

train_close_dir = os.path.join(train_dir, 'close')  # directory with our training cat pictures
train_open_dir = os.path.join(train_dir, 'open')  # directory with our training dog pictures
validation_close_dir = os.path.join(validation_dir, 'close')  # directory with our validation cat pictures
validation_open_dir = os.path.join(validation_dir, 'open')  # directory with our validation dog pictures


import tensorflow as tf

print (tf.__version__)


# In[2]:


print(""Version: "", tf.__version__)
print(""Eager mode: "", tf.executing_eagerly())
print(""GPU is"", ""available"" if tf.config.experimental.list_physical_devices(""GPU"") else ""NOT AVAILABLE"")

gpus = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6000)])


# In[3]:


from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import random

import matplotlib.pyplot as plt

# In[4]:


num_close_tr = len(os.listdir(train_close_dir))
num_open_tr = len(os.listdir(train_open_dir))

num_close_val = len(os.listdir(validation_close_dir))
num_open_val = len(os.listdir(validation_open_dir))

total_train = num_close_tr + num_open_tr
total_val = num_close_val + num_open_val

print('total training close images:', num_close_tr)
print('total training open images:', num_open_tr)
print('total validation close images:', num_close_val)
print('total validation open images:', num_open_val)
print(""--"")
print(""Total training images:"", total_train)
print(""Total validation images:"", total_val)


if len(sys.argv) > 1:
    batch_size = int(sys.argv[1])

if len(sys.argv) > 2:
    epochs = int(sys.argv[2])

def preprocess_image(image):
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [image_size, image_size])
    image /= 255.0
    return image

def load_and_preprocess_image(path):
    image = tf.io.read_file(path)
    return preprocess_image(image)


train_image_generator = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.1, rotation_range=45) # Generator for our training data
validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data

train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,
                                                           directory=train_dir,
                                                           shuffle=True,
                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                           class_mode='binary')

val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,
                                                              directory=validation_dir,
                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                              class_mode='binary')

sample_training_images, _ = next(train_data_gen)


# In[5]:


def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20, 20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

plotImages(sample_training_images[:5])



# In[6]:




# In[7]:



tinydarknet = keras.Sequential([
    keras.layers.Conv2D(16, (3, 3), strides=[1, 1], padding=""same"", input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),
    keras.layers.Conv2D(32, (3, 3), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),
    keras.layers.Conv2D(16, (1, 1), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(128, (3, 3), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(16, (1, 1), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(128, (3, 3), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),
    keras.layers.Conv2D(32, (1, 1), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(256, (3, 3), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(32, (1, 1), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(256, (3, 3), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),
    keras.layers.Conv2D(64, (1, 1), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(512, (3, 3), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(64, (1, 1), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(512, (3, 3), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(128, (1, 1), strides=[1, 1], padding=""same""),
    keras.layers.BatchNormalization(),
    keras.layers.LeakyReLU(alpha=0.1),
    keras.layers.Conv2D(1000, (1, 1)),
    keras.layers.BatchNormalization(),
    keras.layers.AveragePooling2D(),
    keras.layers.Flatten(),
    keras.layers.Dense(1)
])


# In[8]:


tinydarknet.compile(optimizer=""adam"",
             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
             metrics=[""accuracy""])


# In[9]:

history = tinydarknet.fit(#_generator(
    train_data_gen,
    steps_per_epoch=total_train // batch_size,
    epochs=epochs,
    validation_data=val_data_gen,
    validation_steps=total_val // batch_size,
    workers=NUM_WORKERS
)


# In[10]:


acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss=history.history['loss']
val_loss=history.history['val_loss']

epochs_range = range(epochs)


tinydarknet.save(""keras_model"")

converter = tf.lite.TFLiteConverter.from_keras_model(tinydarknet)
tflite_model = converter.convert()

with open(""tinydarknet.tflite"", ""w+b"") as fp:
    fp.write(tflite_model)
    fp.flush()


# In[ ]:


- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):binary by pip
- TensorFlow version (use command below): 2.3.0
- Python version:Python 3.7.7
- CUDA/cuDNN version:10.2
- GPU model and memory: 1080ti  



"
42116,"tf.cond  make me confused if use constant it does not work, but if convert it to tensor it works ","`
import tensorflow as tf


a = tf.constant([[[1,2,3,4],[5,6,7,8]], [[1,2,3,4],[5,6,7,8]]], name='a')
b = tf.constant([[1,0,1,1,1,1,1,1,1], [0,1,1,1,1,0,0,0,0]], name='b')

g = tf.slice(a, [0,0,0], [-1, 1, -1])
""""""
 if use  
   xax_len = 7 
   seq_length = 9
 then tensorflow raise a error
elif use
   xax_len = tf.convert_to_tensor(7) 
   seq_length = tf.convert_to_tensor(9) 
then it works
"""""" 
xax_len = tf.convert_to_tensor(7) 
seq_length = tf.convert_to_tensor(9) 
input_x = tf.cond(tf.greater(xax_len,seq_length),
                  lambda : tf.pad(tensor=b, paddings=[[0, 0], [0, xax_len-seq_length]], constant_values=0),
                  lambda : tf.slice(b, [0,0], [-1, xax_len]))
print(input_x)
`"
42115,Why does the input_layer sort the columns? ,https://github.com/tensorflow/tensorflow/blob/05ab6a2afa2959410d48aab2336cea9dc1e2c13e/tensorflow/python/feature_column/feature_column.py#L199
42114,Input size of converted lite model doesn't match the original model input size,"**System information**
- COLAB:
- TensorFlow version 2.4.0-dev20200805:


**Command used to run the converter or code if you’re using the Python API**
this [Link](https://colab.research.google.com/gist/jvishnuvardhan/23066f1a722fc566b437a5210d1b97b0/ssd_saved_model_tflite_conversion.ipynb#scrollTo=X5s5D5ufCcKb) for code I used in converting the saved model to TensorFlow lite

```
!pip install tf-nightly
model_dir=saved_model'
converter = tf.lite.TFLiteConverter.from_saved_model(model_dir,signature_keys=['serving_default'],)

converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()

#open(""saved_model/converted_model.tflite"", ""wb"").write(tflite_model)
open('tflite_model.tflite','wb').write(tflite_model)
```

**The output from the converter invocation**
- successfully generate the model.tflite
- But When I checked the input for both the original and converted model, I found the following mismatching:
- -  checked the input for the model I got it as [1,1,1,3] instead of [1,300,300,3]
-- in my config file to train the object detection model, I have the following image resize:
```
image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
```


**The original model I used is saved model,  It is the same as all models in the [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md).**


**I was training the object detection API and run it successfully with original .pb saved model ([using this backbone model](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz))**



Any recommendations here? Thanks."
42113,tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.,"**System information**
- OS Platform and Distribution :CentOS Linux release 7.7.1908
- TensorFlow version:2.1.0


**Command used to run the converter or code if you’re using the Python API**
```
converter = tf.lite.TFLiteConverter.from_concrete_functions([train_step.get_concrete_function(tf.TensorSpec(shape=(64, 64, 2048),dtype=tf.dtypes.float32),tf.TensorSpec(shape=(64, 50),dtype=tf.dtypes.int32))])
tflite_model = converter.convert()
```
# Copy and paste here the exact command
`tflite_model = converter.convert()`
**The output from the converter invocation**
```
2020-08-07 09:40:27.848678: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize
2020-08-07 09:40:27.848903: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 16782 nodes (0), 22769 edges (0), time = 401.073ms.
2020-08-07 09:40:27.848929: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 16782 nodes (0), 22769 edges (0), time = 457.052ms.
2020-08-07 09:40:27.848987: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_7_body_33225_grad_59089
2020-08-07 09:40:27.849000: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-08-07 09:40:27.849053: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849064: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_31_body_39513_rewritten
2020-08-07 09:40:27.849075: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849084: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849092: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_47_body_43705_grad_45308
2020-08-07 09:40:27.849108: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849121: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849131: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_21_cond_36892_grad_54630
2020-08-07 09:40:27.849143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849157: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849165: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_15_body_35321_rewritten
2020-08-07 09:40:27.849174: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849183: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_11_body_34273_rewritten
2020-08-07 09:40:27.849201: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849212: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849220: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_15_body_35321_grad_56441
2020-08-07 09:40:27.849230: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849239: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849250: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_38_body_41347_grad_48826
2020-08-07 09:40:27.849280: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849298: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849309: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_21_body_36893_rewritten
2020-08-07 09:40:27.849323: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849340: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849358: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_19_body_36369_grad_55116
2020-08-07 09:40:27.849422: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849432: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849442: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_12_body_34535_rewritten
2020-08-07 09:40:27.849453: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849462: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849471: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_13_cond_34796_rewritten
2020-08-07 09:40:27.849481: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849491: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849500: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_20_body_36631_grad_54785
2020-08-07 09:40:27.849509: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849517: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849526: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_23_body_37417_rewritten
2020-08-07 09:40:27.849534: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849543: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849551: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_37_body_41085_rewritten
2020-08-07 09:40:27.849560: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849570: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849580: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_18_body_36107_rewritten
2020-08-07 09:40:27.849590: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849607: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_28_body_38727_rewritten
2020-08-07 09:40:27.849616: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849624: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849636: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_2_body_31915_grad_60746
2020-08-07 09:40:27.849646: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849656: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849664: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_4_cond_32438_grad_60260
2020-08-07 09:40:27.849675: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849684: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849693: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_32_body_39775_rewritten
2020-08-07 09:40:27.849702: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849711: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849721: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_24_body_37679_grad_53461
2020-08-07 09:40:27.849732: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849742: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849751: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_8_body_33487_rewritten
2020-08-07 09:40:27.849761: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849771: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849782: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_6_body_32963_rewritten
2020-08-07 09:40:27.849790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849799: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_21_cond_36892_rewritten
2020-08-07 09:40:27.849816: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849827: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849838: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_11_cond_34272_rewritten
2020-08-07 09:40:27.849846: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849855: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849863: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_40_body_41871_grad_48164
2020-08-07 09:40:27.849872: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849881: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849890: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_17_cond_35844_grad_55954
2020-08-07 09:40:27.849901: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.849911: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849920: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_1_cond_31652_grad_61253
2020-08-07 09:40:27.849929: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849939: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849947: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_25_cond_37940_rewritten
2020-08-07 09:40:27.849957: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.849967: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.849978: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_8_cond_33486_rewritten
2020-08-07 09:40:27.849988: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850000: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850010: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_3_body_32177_grad_60415
2020-08-07 09:40:27.850020: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850030: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850041: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_11_cond_34272_grad_57941
2020-08-07 09:40:27.850049: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850058: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850068: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_10_body_34011_grad_58096
2020-08-07 09:40:27.850077: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850085: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850094: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_14_cond_35058_grad_56948
2020-08-07 09:40:27.850109: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850120: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850130: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_35_cond_40560_rewritten
2020-08-07 09:40:27.850139: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850160: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_31_cond_39512_rewritten
2020-08-07 09:40:27.850170: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_14_body_35059_rewritten
2020-08-07 09:40:27.850202: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850214: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850223: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_17_body_35845_grad_55778
2020-08-07 09:40:27.850232: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850242: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850251: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_28_cond_38726_grad_52313
2020-08-07 09:40:27.850261: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850269: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850278: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_31_cond_39512_grad_51320
2020-08-07 09:40:27.850288: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.01ms.
2020-08-07 09:40:27.850296: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850306: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_45_body_43181_grad_46509
2020-08-07 09:40:27.850315: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850326: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850335: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_15_cond_35320_grad_56617
2020-08-07 09:40:27.850345: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850353: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850362: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_36_body_40823_grad_49488
2020-08-07 09:40:27.850371: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850382: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850390: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_44_body_42919_rewritten
2020-08-07 09:40:27.850399: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850408: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850417: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_48_body_43967_grad_44362
2020-08-07 09:40:27.850430: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850439: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850449: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_42_cond_42394_rewritten
2020-08-07 09:40:27.850458: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850466: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850475: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_38_cond_41346_rewritten
2020-08-07 09:40:27.850484: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850494: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850504: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_47_body_43705_rewritten
2020-08-07 09:40:27.850512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850523: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850545: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_44_cond_42918_grad_47016
2020-08-07 09:40:27.850558: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850633: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850670: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_13_body_34797_grad_57103
2020-08-07 09:40:27.850701: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850715: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850731: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_10_cond_34010_grad_58272
2020-08-07 09:40:27.850750: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850760: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850796: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_1_body_31653_rewritten
2020-08-07 09:40:27.850812: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850833: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850850: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_27_body_38465_rewritten
2020-08-07 09:40:27.850862: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850879: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850891: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_32_cond_39774_rewritten
2020-08-07 09:40:27.850902: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850918: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.850927: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_6_body_32963_grad_59420
2020-08-07 09:40:27.850939: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850950: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.850962: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_4_cond_32438_rewritten
2020-08-07 09:40:27.850971: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.850982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851007: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_9_body_33749_rewritten
2020-08-07 09:40:27.851017: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851065: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_25_cond_37940_grad_53306
2020-08-07 09:40:27.851076: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851091: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851108: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_9_body_33749_grad_58427
2020-08-07 09:40:27.851129: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-08-07 09:40:27.851141: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_33_body_40037_grad_50481
2020-08-07 09:40:27.851171: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-08-07 09:40:27.851181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851193: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_5_body_32701_grad_59753
2020-08-07 09:40:27.851205: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851218: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851237: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_48_cond_43966_rewritten
2020-08-07 09:40:27.851248: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851270: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851280: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_30_body_39251_grad_51475
2020-08-07 09:40:27.851294: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-08-07 09:40:27.851312: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851330: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_34_cond_40298_rewritten
2020-08-07 09:40:27.851407: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851440: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851475: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_33_cond_40036_grad_50657
2020-08-07 09:40:27.851498: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851508: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851528: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_2_cond_31914_grad_60922
2020-08-07 09:40:27.851547: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851564: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851577: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_16_body_35583_rewritten
2020-08-07 09:40:27.851605: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851616: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851656: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_24_cond_37678_grad_53637
2020-08-07 09:40:27.851666: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851675: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851684: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_25_body_37941_grad_53130
2020-08-07 09:40:27.851693: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851701: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851710: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_17_cond_35844_rewritten
2020-08-07 09:40:27.851719: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851728: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851736: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_2_cond_31914_rewritten
2020-08-07 09:40:27.851745: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-08-07 09:40:27.851753: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851762: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_33_body_40037_rewritten
2020-08-07 09:40:27.851773: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851783: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851794: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_36_cond_40822_rewritten
2020-08-07 09:40:27.851805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851816: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851825: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_23_cond_37416_rewritten
2020-08-07 09:40:27.851834: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851844: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851854: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_17_body_35845_rewritten
2020-08-07 09:40:27.851864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851875: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851883: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_32_cond_39774_grad_50988
2020-08-07 09:40:27.851892: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851900: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851909: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_35_body_40561_rewritten
2020-08-07 09:40:27.851920: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851931: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851941: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_6_cond_32962_rewritten
2020-08-07 09:40:27.851951: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.851960: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.851970: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_35_cond_40560_grad_49995
2020-08-07 09:40:27.851980: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.851991: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852001: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_37_cond_41084_grad_49333
2020-08-07 09:40:27.852010: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.852018: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852027: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_7_body_33225_rewritten
2020-08-07 09:40:27.852035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.852046: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852056: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_45_body_43181_rewritten
2020-08-07 09:40:27.852066: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852076: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852086: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_24_body_37679_rewritten
2020-08-07 09:40:27.852101: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852112: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852123: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_43_body_42657_rewritten
2020-08-07 09:40:27.852133: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852144: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_48_body_43967_rewritten
2020-08-07 09:40:27.852164: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.852175: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852185: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_25_body_37941_rewritten
2020-08-07 09:40:27.852196: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852205: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852213: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_46_cond_43442_grad_46324
2020-08-07 09:40:27.852224: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852233: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852241: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_cond_31385_grad_61584
2020-08-07 09:40:27.852250: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852258: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852267: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_8_body_33487_grad_58758
2020-08-07 09:40:27.852276: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.852286: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852294: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_28_body_38727_grad_52137
2020-08-07 09:40:27.852304: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852313: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852321: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_21_body_36893_grad_54454
2020-08-07 09:40:27.852330: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.852340: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_cond_31385_rewritten
2020-08-07 09:40:27.852359: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852370: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852380: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_1_body_31653_grad_61077
2020-08-07 09:40:27.852389: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852397: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852406: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_12_cond_34534_rewritten
2020-08-07 09:40:27.852414: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852423: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852431: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_32_body_39775_grad_50812
2020-08-07 09:40:27.852440: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852450: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852459: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_46_body_43443_grad_46148
2020-08-07 09:40:27.852469: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852478: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_7_cond_33224_rewritten
2020-08-07 09:40:27.852497: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.852505: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852514: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_body_31386_grad_61408
2020-08-07 09:40:27.852523: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852531: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852541: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_29_body_38989_grad_51806
2020-08-07 09:40:27.852550: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852559: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852567: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_44_cond_42918_rewritten
2020-08-07 09:40:27.852579: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.852589: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_19_body_36369_rewritten
2020-08-07 09:40:27.852610: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.852619: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852627: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_20_cond_36630_grad_54961
2020-08-07 09:40:27.852637: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852645: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852654: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_29_cond_38988_rewritten
2020-08-07 09:40:27.852663: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852672: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852680: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_27_body_38465_grad_52468
2020-08-07 09:40:27.852689: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852701: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852710: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_26_body_38203_grad_52799
2020-08-07 09:40:27.852719: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852727: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852736: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_1_cond_31652_rewritten
2020-08-07 09:40:27.852744: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852753: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852763: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_35_body_40561_grad_49819
2020-08-07 09:40:27.852772: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852782: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852791: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_10_cond_34010_rewritten
2020-08-07 09:40:27.852801: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852811: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852819: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_16_cond_35582_grad_56285
2020-08-07 09:40:27.852828: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852837: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852847: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_22_cond_37154_grad_54299
2020-08-07 09:40:27.852856: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852866: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852876: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_14_body_35059_grad_56772
2020-08-07 09:40:27.852886: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852896: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852904: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_8_cond_33486_grad_58934
2020-08-07 09:40:27.852914: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.852922: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852932: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_2_body_31915_rewritten
2020-08-07 09:40:27.852941: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852952: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852960: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_3_cond_32176_grad_60591
2020-08-07 09:40:27.852969: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.852979: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.852988: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_23_body_37417_grad_53792
2020-08-07 09:40:27.852997: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853007: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853016: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_26_body_38203_rewritten
2020-08-07 09:40:27.853025: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853034: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853042: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_16_body_35583_grad_56109
2020-08-07 09:40:27.853053: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.853064: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853074: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_16_cond_35582_rewritten
2020-08-07 09:40:27.853083: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853091: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853106: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_18_cond_36106_grad_55623
2020-08-07 09:40:27.853116: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853127: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853137: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_10_body_34011_rewritten
2020-08-07 09:40:27.853148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853156: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853165: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_body_31386_rewritten
2020-08-07 09:40:27.853173: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.853182: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853193: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_26_cond_38202_rewritten
2020-08-07 09:40:27.853204: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853214: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853223: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_30_cond_39250_grad_51651
2020-08-07 09:40:27.853234: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853243: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853254: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_30_cond_39250_rewritten
2020-08-07 09:40:27.853265: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853274: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853283: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_12_cond_34534_grad_57610
2020-08-07 09:40:27.853292: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853301: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853310: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_44_body_42919_grad_46840
2020-08-07 09:40:27.853318: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853327: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853335: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_24_cond_37678_rewritten
2020-08-07 09:40:27.853344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853353: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853361: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_38_cond_41346_grad_49002
2020-08-07 09:40:27.853370: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853378: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853386: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_18_cond_36106_rewritten
2020-08-07 09:40:27.853395: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853404: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853412: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_27_cond_38464_grad_52644
2020-08-07 09:40:27.853421: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853429: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853438: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_4_body_32439_rewritten
2020-08-07 09:40:27.853446: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.853455: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853466: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_39_body_41609_rewritten
2020-08-07 09:40:27.853475: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853483: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853492: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_19_cond_36368_rewritten
2020-08-07 09:40:27.853500: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853509: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853519: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_42_cond_42394_grad_47678
2020-08-07 09:40:27.853528: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853536: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853546: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_38_body_41347_rewritten
2020-08-07 09:40:27.853554: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.853564: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853573: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_7_cond_33224_grad_59265
2020-08-07 09:40:27.853584: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853594: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853603: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_27_cond_38464_rewritten
2020-08-07 09:40:27.853613: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853621: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853631: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_11_body_34273_grad_57765
2020-08-07 09:40:27.853639: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853649: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853658: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_13_body_34797_rewritten
2020-08-07 09:40:27.853667: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853676: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853685: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_28_cond_38726_rewritten
2020-08-07 09:40:27.853694: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853704: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853715: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_41_body_42133_grad_47833
2020-08-07 09:40:27.853725: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853736: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853747: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_39_cond_41608_rewritten
2020-08-07 09:40:27.853755: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.853765: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853774: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_33_cond_40036_rewritten
2020-08-07 09:40:27.853786: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853796: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853807: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_46_body_43443_rewritten
2020-08-07 09:40:27.853818: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853829: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853839: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_18_body_36107_grad_55447
2020-08-07 09:40:27.853850: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853860: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853869: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_14_cond_35058_rewritten
2020-08-07 09:40:27.853878: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853887: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853896: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_29_body_38989_rewritten
2020-08-07 09:40:27.853905: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.853915: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853926: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_30_body_39251_rewritten
2020-08-07 09:40:27.853936: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.853944: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853955: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_39_cond_41608_grad_48671
2020-08-07 09:40:27.853965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.853976: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.853984: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_42_body_42395_grad_47502
2020-08-07 09:40:27.853996: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854007: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854017: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_23_cond_37416_grad_53968
2020-08-07 09:40:27.854026: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.854034: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854044: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_40_cond_41870_rewritten
2020-08-07 09:40:27.854055: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854065: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854075: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_5_cond_32700_grad_59929
2020-08-07 09:40:27.854084: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854093: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854104: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_47_cond_43704_grad_45484
2020-08-07 09:40:27.854115: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854125: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854135: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_41_cond_42132_grad_48009
2020-08-07 09:40:27.854145: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.854154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854163: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_45_cond_43180_rewritten
2020-08-07 09:40:27.854172: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854191: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_34_cond_40298_grad_50326
2020-08-07 09:40:27.854200: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854209: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854220: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_45_cond_43180_grad_46685
2020-08-07 09:40:27.854230: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854240: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854250: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_31_body_39513_grad_51144
2020-08-07 09:40:27.854259: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854269: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854277: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_6_cond_32962_grad_59596
2020-08-07 09:40:27.854287: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854296: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854307: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_9_cond_33748_grad_58603
2020-08-07 09:40:27.854315: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854331: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854342: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_12_body_34535_grad_57434
2020-08-07 09:40:27.854355: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854364: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854374: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_22_cond_37154_rewritten
2020-08-07 09:40:27.854384: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854393: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854402: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_22_body_37155_rewritten
2020-08-07 09:40:27.854411: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854420: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854430: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_13_cond_34796_grad_57279
2020-08-07 09:40:27.854438: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854448: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854457: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_26_cond_38202_grad_52975
2020-08-07 09:40:27.854467: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854476: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_3_body_32177_rewritten
2020-08-07 09:40:27.854494: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854504: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854513: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_39_body_41609_grad_48495
2020-08-07 09:40:27.854522: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854530: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854540: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_43_body_42657_grad_47171
2020-08-07 09:40:27.854549: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854559: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854568: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_37_body_41085_grad_49157
2020-08-07 09:40:27.854578: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854588: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854597: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_40_cond_41870_grad_48340
2020-08-07 09:40:27.854605: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854614: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854623: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_46_cond_43442_rewritten
2020-08-07 09:40:27.854634: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854642: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854651: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_5_body_32701_rewritten
2020-08-07 09:40:27.854660: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854679: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_34_body_40299_rewritten
2020-08-07 09:40:27.854689: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854699: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854715: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_36_body_40823_rewritten
2020-08-07 09:40:27.854725: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854734: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854742: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_4_body_32439_grad_60084
2020-08-07 09:40:27.854752: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854761: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854769: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_48_cond_43966_grad_44538
2020-08-07 09:40:27.854778: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854789: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854799: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_47_cond_43704_rewritten
2020-08-07 09:40:27.854808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854821: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854831: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_43_cond_42656_grad_47347
2020-08-07 09:40:27.854841: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854854: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_20_body_36631_rewritten
2020-08-07 09:40:27.854873: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854881: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854890: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_34_body_40299_grad_50150
2020-08-07 09:40:27.854899: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.854907: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854916: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_43_cond_42656_rewritten
2020-08-07 09:40:27.854928: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854940: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854949: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_5_cond_32700_rewritten
2020-08-07 09:40:27.854959: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.854971: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.854982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_41_body_42133_rewritten
2020-08-07 09:40:27.854992: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855000: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855009: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_19_cond_36368_grad_55292
2020-08-07 09:40:27.855018: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855026: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.855035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_37_cond_41084_rewritten
2020-08-07 09:40:27.855047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.855056: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.855083: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_40_body_41871_rewritten
2020-08-07 09:40:27.855094: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855110: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.855121: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_22_body_37155_grad_54123
2020-08-07 09:40:27.855132: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.855147: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.855159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_20_cond_36630_rewritten
2020-08-07 09:40:27.855170: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.855181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.855192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_29_cond_38988_grad_51982
2020-08-07 09:40:27.855203: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855213: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.855224: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_15_cond_35320_rewritten
2020-08-07 09:40:27.855235: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855244: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.855252: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_9_cond_33748_rewritten
2020-08-07 09:40:27.855262: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.855271: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855281: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_36_cond_40822_grad_49664
2020-08-07 09:40:27.855289: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.855298: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855307: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_41_cond_42132_rewritten
2020-08-07 09:40:27.855318: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855329: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.855340: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_42_body_42395_rewritten
2020-08-07 09:40:27.855351: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-08-07 09:40:27.855362: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-08-07 09:40:27.855371: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_3_cond_32176_rewritten
2020-08-07 09:40:27.855379: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-08-07 09:40:27.855389: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
Traceback (most recent call last):
  File ""convert2savedmodel.py"", line 280, in <module>
    tflite_model = converter.convert()
  File ""/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 1076, in convert
    return super(TFLiteConverterV2, self).convert()
  File ""/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 878, in convert
    self._funcs[0], lower_control_flow=False))
  File ""/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 1103, in convert_variables_to_constants_v2_as_graph
    aggressive_inlining=aggressive_inlining)
  File ""/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 804, in __init__
    self._build_tensor_data()
  File ""/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 823, in _build_tensor_data
    data = val_tensor.numpy()
  File ""/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1063, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1031, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.
```


**Also, please include a link to the saved model or GraphDef**
```
@tf.function
def train_step(img_tensor, target):
    loss = 0

    #初始化每个批次的隐藏状态因为图像与图像的字幕之间没有关系
    hidden = decoder.reset_states(batch_size=target.shape[0])

    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)

    with tf.GradientTape() as tape:
        features = encoder(img_tensor)

        for i in  range(1, target.shape[1]):
            #通过解码器传递特征
            predictions, hidden, _ = decoder(dec_input, features, hidden)

            loss += loss_function(target[:, i], predictions)

            # 使用 teacher forcing
            dec_input = tf.expand_dims(target[:, i], 1)

    total_loss = (loss / int(target.shape[1]))

    trainable_variables = encoder.trainable_variables + decoder.trainable_variables

    gradients = tape.gradient(loss, trainable_variables)

    optimizer.apply_gradients(zip(gradients, trainable_variables))

    return loss, total_loss
```


**full code**

```
class BahdanauAttention(tf.keras.Model):
    def __init__(self, utils):
        super(BahdanauAttention, self).__init__()
        self.W1 = tf.keras.layers.Dense(utils)
        self.W2 = tf.keras.layers.Dense(utils)
        self.V = tf.keras.layers.Dense(1)

    def call(self, features, hidden):
        # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)

        # hidden shape == (batch_size, hidden_size)
        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)
        hidden_with_time_axis_shape = tf.expand_dims(hidden, 1)

        # score shape == (batch_size, 64, hidden_size)
        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis_shape))

        # attention_weights shape == (batch_size, 64, 1)
        # you get 1 at the last axis because you are applying score to self.V
        attention_weights = tf.nn.softmax(self.V(score), axis=1)

        # context_vector shape after sum == (batch_size, hidden_size)
        context_vector = attention_weights * features
        context_vector = tf.reduce_sum(context_vector, axis=1)

        return context_vector, attention_weights

class CNN_Encoder(tf.keras.Model):
    #由于您已经提取了特征并使用pickle进行了转储
    #该编码器通过完全连接的层传递这些特征
    def __init__(self, embedding):
        super(CNN_Encoder, self).__init__()
        # shape after fc == (batch_size, 64, embedding_dim)
        self.fc = tf.keras.layers.Dense(embedding_dim)

    def call(self, x):
        x = self.fc(x)
        x = tf.nn.relu(x)
        return x

class RNN_Decoder(tf.keras.Model):
    def __init__(self, embedding_dim, units, vocab_size):
        super(RNN_Decoder, self).__init__()
        self.units = units

        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.gru = tf.keras.layers.GRU(self.units,
                                       return_sequences=True,
                                       return_state=True,
                                       recurrent_initializer='glorot_uniform')
        self.fc1 = tf.keras.layers.Dense(self.units)
        self.fc2 = tf.keras.layers.Dense(vocab_size)

        self.attention = BahdanauAttention(self.units)

    def call(self, x , features, hidden):
        #将注意力定义为一个单独的模型
        context_vector, attention_weights = self.attention(features, hidden)

        #x shape after passing through embedding == (batch_size, 1, embedding_dim)
        x = self.embedding(x)

        #x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)
        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)

        #将concated后的的向量传递给GRU
        output, state = self.gru(x)

        #shape == (batch_size, max_length, hidden_size)
        x = self.fc1(output)

        #x shape == (batch_size, max_length, hidden_size)
        x = tf.reshape(x, (-1, x.shape[2]))

        # output shape == (batch_size * max_length, vocab)
        x = self.fc2(x)

        return x, state, attention_weights

    def reset_states(self, batch_size):
        return tf.zeros((batch_size, self.units))

encoder = CNN_Encoder(embedding_dim)
decoder = RNN_Decoder(embedding_dim, units, vocab_size)

optimizer = tf.keras.optimizers.Adam()
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=True, reduction='none'
)
def loss_function(real, pred):
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    loss_ = loss_object(real, pred)

    mask = tf.cast(mask, dtype=loss_.dtype)
    loss_ *= mask

    return tf.reduce_mean(loss_)

#CheckPoint

checkpoint_path = './checkpoints/train'
ckpt = tf.train.Checkpoint(encoder=encoder,
                           decoder=decoder,
                           optimizer = optimizer)
ckpt_manage = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)

start_epoch = 0
if ckpt_manage.latest_checkpoint:
    start_epoch = int(ckpt_manage.latest_checkpoint.split('-')[-1])
    print(start_epoch)
    #恢复checkpoint_path中的最新检查点
    ckpt.restore(ckpt_manage.latest_checkpoint)
BATCH_SIZE = 128
BUFFER_SIZE = 1000
embedding_dim = 256
units = 512
vocab_size = top_k + 1
num_steps = len(img_name_train) // BATCH_SIZE
# 从InceptionV3提取的向量的形状为(64，2048)
# 这两个变量表示矢量形状
features_shape = 2048
attention_features_shape = 64

```



"
42112,tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
42111,TensorFlow hangs forever in multinode training with NCCL and certain model (with SyncBatchNorm layers),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04 running in Docker container (host is 18.04)
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.29.1-1.0
- GCC/Compiler version (if compiling from source): 4.8.5
- CUDA/cuDNN version: 10.0
- GPU model and memory: Various, e.g. Nvidia RTX 2080 Ti

**Describe the current behavior**
In certain circumstances, TensorFlow appears to hang forever before starting training:
- Multinode training using `MultiWorkerMirroredStrategy` (the bug does not appear when using one worker with multiple GPUs, or with one GPU).
- `NCCL` communication (not 100% sure on this)
- A specific model, which seems to require SyncBatchNorm layers interleaved with Conv2D layers

This seems to happen both on the Estimator and Keras frameworks - the output is slightly different but my guess is that it's the same bug.

I've tried to test with tf-nightly, but unfortunately I've had difficulty getting the correct CUDA libraries for our particular setup and haven't been able to verify whether it is reproducible on tf-nightly. However, if you e.g. are unable to reproduce and would like me to take another look, please let me know.

**Describe the expected behavior**
TensorFlow should not hang forever. This toy model in particular finishes training in seconds, but when the bug is triggered, hangs for hours with no output.

**Standalone code to reproduce the issue**
Please note that this code must be run with multiple workers to reproduce the issue, and the `TF_CONFIG` environment variable should be set correspondingly according to your specific setup.

As far as I can see, on Colab it is possible to have multiple _GPUs_ on one worker, but I'm not sure how to set it up with multiple _workers_ (with one GPU per worker). So I'm not sure if this problem can be reproduced on Colab. But if there is a way to use multiple workers, please point me at a guide and I can try to reproduce on Colab.

Estimator code:
```
import logging
import os
import shutil
import sys

import numpy as np
import tensorflow as tf

def setup_multi_node_training():
    # IMPORTANT: SET UP TF_CONFIG FOR MULTINODE TRAINING HERE
    os.environ[""TF_FORCE_GPU_ALLOW_GROWTH""] = ""true""
    tf.config.set_soft_device_placement(True)
    mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(tf.distribute.experimental.CollectiveCommunication.NCCL)
    # Constructs the configuration
    run_config = tf.estimator.RunConfig(
        train_distribute=mirrored_strategy,
    )
    return run_config

def input_fn():
    dataset = tf.data.Dataset.from_tensors([tf.random.normal(shape=[496, 496, 64])] * 3)
    dataset = dataset.repeat()
    return dataset

def batch_norm(x, is_training):
    layer = tf.keras.layers.experimental.SyncBatchNormalization(axis=-1)
    x_norm = layer(x, is_training)
    with tf.control_dependencies(layer.get_updates_for(x)):
        x_norm = tf.identity(x_norm)
    return x_norm

def inference(features, is_training):
    conv1 = tf.keras.layers.Conv2D(32, 3, padding=""SAME"")(features)
    conv1bn = batch_norm(conv1, is_training)
    deconv1bn = batch_norm(conv1bn, is_training)
    conv2 = tf.keras.layers.Conv2D(32, 3, padding=""SAME"")(conv1bn)
    conv2bn = batch_norm(conv2, is_training)
    return tf.keras.layers.Concatenate()([conv1bn, deconv1bn, conv2bn])

def compute_loss(predictions, labels, is_training):
    return tf.reduce_mean(predictions)

def model_fn(features, labels, mode):
    global_step = tf.compat.v1.train.get_global_step()
    is_training = mode == tf.estimator.ModeKeys.TRAIN

    predictions = inference(features, is_training)
    loss = compute_loss(predictions, labels, is_training)

    optimizer = tf.compat.v1.train.GradientDescentOptimizer(1e-5)
    train_op = optimizer.minimize(loss, global_step=global_step)

    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)

def main():
    model_dir = ""/tmp/output""
    run_config_params = {
        ""save_checkpoints_steps"": 100,
        ""save_summary_steps"": 100,
        ""log_step_count_steps"": 100,
        ""tf_random_seed"": 0,
        ""keep_checkpoint_max"": 1,
        ""model_dir"": model_dir,
    }
    run_config = setup_multi_node_training().replace(**run_config_params)
    estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)

    train_spec = tf.estimator.TrainSpec(input_fn=input_fn, max_steps=1000)

    eval_spec = tf.estimator.EvalSpec(
        input_fn=input_fn, steps=100, throttle_secs=0, start_delay_secs=0
    )

    print(""Training and evaluating model..."")
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)

if __name__ == ""__main__"":
    main()
```

Keras code:
```
import os

import tensorflow as tf
from tensorflow import keras

class MyModel(keras.Model):
    def __init__(self, **kwargs):
        super().__init__(name=""my_model"", **kwargs)
        self.conv1 = keras.layers.Conv2D(16, 3, padding=""SAME"")
        self.sbn1 = keras.layers.experimental.SyncBatchNormalization()
        self.sbn2 = keras.layers.experimental.SyncBatchNormalization()
        self.conv2 = keras.layers.Conv2D(32, 3, padding=""SAME"")
        self.sbn3 = keras.layers.experimental.SyncBatchNormalization()
        self.concat = keras.layers.Concatenate()

    def call(self, inputs, training=False):
        conv1 = self.conv1(inputs)
        conv1bn = self.sbn1(conv1, training)
        conv1bn2 = self.sbn2(conv1bn, training)
        conv2 = self.conv2(conv1bn)
        conv2bn = self.sbn3(conv2, training)
        return self.concat([conv1bn, conv1bn2, conv2bn])

def get_dataset():
    dataset = tf.data.Dataset.from_tensors(
        [tf.random.normal(shape=[496, 496, 64])] * 3
    )
    dataset = dataset.repeat()
    dataset = tf.data.Dataset.zip((dataset, dataset))
    return dataset

def main():
    model_dir = ""/tmp/keras_example""

    # IMPORTANT: SET UP TF_CONFIG FOR MULTINODE TRAINING HERE
    os.environ[""TF_FORCE_GPU_ALLOW_GROWTH""] = ""true""
    tf.config.set_soft_device_placement(True)
    mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(tf.distribute.experimental.CollectiveCommunication.NCCL)

    # Create dataset
    train_dataset = get_dataset()

    with strategy.scope():
        model = MyModel()

        model.compile(
            optimizer=keras.optimizers.Adam(),
            loss=keras.losses.MeanSquaredError(),
        )

    model.fit(x=train_dataset, steps_per_epoch=100, epochs=1)

if __name__ == ""__main__"":
    main()
```

**Other info / logs**
There are three log files: [Estimator log](https://github.com/tensorflow/tensorflow/files/5038681/estimator_log_1.txt), [Estimator log with more debug output](https://drive.google.com/file/d/1-4abJDs1QWlHgFkFzbW6PGjZ4hXoLbpf/view?usp=sharing) (`TF_CPP_MIN_LOG_LEVEL=0` and `TF_CPP_MIN_VLOG_LEVEL=2`) (note this is a Google Drive link as the file is >20 MB), [Keras log](https://github.com/tensorflow/tensorflow/files/5038696/keras_log_1.txt). I had trouble getting the Keras log with debug output so I haven't included that but will update if I can get it.

Note that the second Estimator log is gigantic, but most of the log is output in about a minute, and then the last hundred lines or so seem to be of the job actually hanging until it is killed after about 15 minutes, with this output repeated:
```
0: 2020-08-06 00:22:30.510236: I external/org_tensorflow/tensorflow/core/framework/model.cc:892] Starting optimization of tunable parameters with HillClimb
0: 2020-08-06 00:22:30.510355: I external/org_tensorflow/tensorflow/core/framework/model.cc:943] Number of tunable parameters: 0
0: 2020-08-06 00:22:30.510377: I external/org_tensorflow/tensorflow/core/kernels/data/model_dataset_op.cc:191] Waiting for 60000 ms.
```
It seems somewhat bizarre that if there are 0 parameters to tune, TensorFlow should still try to repeatedly optimize the nonexistent tunable parameters. I wonder if there's some issue with the `model.cc` code not properly signaling that it has finished, if there are no tunable parameters? I see that in line 1485-1487 of `core/framework/model.cc`, there is some code that seems to be doing something with the mutex and notifying, but this block would be entirely skipped if there are no tunable parameters, and that might contribute to the infinite loop here.

Thanks so much!"
42107,.,the issue has been solved
42106,"tf.keras.models.load_model unable to load model in TF 2.3.0 - ""int() argument must be a string, a bytes-like object or a number, not 'NoneType' ""","My first time posting a GitHub issue, so excuse me if I leave something out.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mac OSX 10.12.6
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version (use command below):
2.3.0
- Python version:
3.7

**Describe the current behavior**
Every time I call `tf.keras.models.load_model` on my SavedModel in version 2.3.0, the model fails to load. I had saved the model with tensorflow 2.0.0 installed, and I could load it with 2.0.0, but when I upgraded to 2.3.0, I got the following error:

```python
Traceback (most recent call last):
  File ""../python/recommender.py"", line 501, in <module>
    new_topics=args.new_topic_path)
  File ""../python/recommender.py"", line 51, in load_data
    add_to_matrix(tdf, vdf, save_matrix, corr_matrix, new_values, new_topics)
  File ""../python/recommender.py"", line 352, in add_to_matrix
    df2 = get_corrs(ntdf, vdf)
  File ""../python/recommender.py"", line 401, in get_corrs
    model = load_model(model_dir, None)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py"", line 187, in load_model
    return saved_model_load.load(filepath, compile, options)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 121, in load
    path, options=options, loader_cls=KerasObjectLoader)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 633, in load_internal
    ckpt_options)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 194, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 130, in __init__
    self._load_all()
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 215, in _load_all
    self._layer_nodes = self._load_layers()
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 315, in _load_layers
    layers[node_id] = self._load_layer(proto.user_object, node_id)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 341, in _load_layer
    obj, setter = self._revive_from_config(proto.identifier, metadata, node_id)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 359, in _revive_from_config
    self._revive_layer_from_config(metadata, node_id))
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 445, in _revive_layer_from_config
    built = self._try_build_layer(obj, node_id, build_input_shape)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 482, in _try_build_layer
    obj.build(build_input_shape)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/wrappers.py"", line 685, in build
    self.forward_layer.build(input_shape)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 581, in build
    self.cell.build(step_input_shape)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py"", line 323, in wrapper
    output_shape = fn(instance, input_shape)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 2367, in build
    caching_device=default_caching_device)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 614, in add_weight
    caching_device=caching_device)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 750, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py"", line 145, in make_variable
    shape=variable_shape if variable_shape else None)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 260, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 221, in _variable_v1_call
    shape=shape)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 199, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 2597, in default_variable_creator
    shape=shape)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1518, in __init__
    distribute_strategy=distribute_strategy)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1651, in _init_from_args
    initial_value() if init_from_fn else initial_value,
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/initializers/initializers_v2.py"", line 397, in __call__
    return super(VarianceScaling, self).__call__(shape, dtype=_get_dtype(dtype))
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py"", line 545, in __call__
    fan_in, fan_out = _compute_fans(scale_shape)
  File ""/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py"", line 1425, in _compute_fans
    return int(fan_in), int(fan_out)
TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
```

**Describe the expected behavior**
Ideally, I should be able to load up my model and just use it from there.

**Standalone code to reproduce the issue**
I could reproduce this with the model in [model.zip](https://github.com/tensorflow/tensorflow/files/5037874/model.zip) and with the following code:

```bash
python3
>>> import tensorflow as tf
>>> tf.keras.models.load_model('model/')
```"
42105,Segmentation fault in tf.quantization.quantize_and_dequantize,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
`tf.quantization.quantize_and_dequantize` produces a segfault  when `input` is a tensor in any shape of `float32` or `float64` and `axis` is specified to a large number. 

**Describe the expected behavior**
No segfault

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
tf.quantization.quantize_and_dequantize(input=[2.5, 2.5], input_min=[0,0], input_max=[1,1], axis=10)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
`Segmentation fault (core dumped)`
"
42103,ImportError: DLL load failed with error code 3221225501 while importing _pywrap_ tensorflow_internal in Python3.8,"<em>How i can solve this error while import TensorFlow</em>

**System information:**
 - Python 3.8.4.
 - Windows 7 Ultimate 64bit.
 - 2GB Ram.
 - Intel(R) Celeron(R) CPU N2840 @ 2.16GHz.
 - Intel(R) HD Graphics.


**Error Text/Logs:**
```
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""G:\Users\Abdo-Prgraming\AppData\Roaming\Python\Python38\site-packages\te
nsorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed with error code 3221225501 while importing _pywrap_
tensorflow_internal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""G:\Users\Abdo-Prgraming\AppData\Roaming\Python\Python38\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""G:\Users\Abdo-Prgraming\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""G:\Users\Abdo-Prgraming\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe
  File ""G:\Users\Abdo-Prgraming\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""G:\Users\Abdo-Prgraming\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""G:\Users\Abdo-Prgraming\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed with error code 3221225501 while importing _pywrap_tensorflow_internal


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```"
42101,plot_model not connecting layers between models correctly,"Tested in tf 2.3.0

When building models from other models, the graph generated by `plot_model` does not create arrows between the correct outputs and inputs. See e.g. 

```
inn = tf.keras.Input((1,),name=""in1"")
d1 = tf.keras.layers.Dense(1, name=""d1"")(inn)
d2 = tf.keras.layers.Dense(1, name=""d2"")(inn)
m1 = tf.keras.Model(inputs=inn, outputs=[d1,d2], name=""model1"")
in2_1 = tf.keras.Input((1,),name=""in2_1"")
in2_2 = tf.keras.Input((1,),name=""in2_2"")
m2 = tf.keras.Model(inputs=[in2_1,in2_2],outputs=[in2_1 + in2_2],name=""model2"")

# combined model
in0 = tf.keras.Input((1,),name=""in0"")
m = tf.keras.Model(inputs=in0, outputs=m2(m1(in0)))
tf.keras.utils.plot_model(m, show_shapes=True, expand_nested=True)
```
outputs:
![image](https://user-images.githubusercontent.com/18280829/89551998-7bb23700-d803-11ea-961f-127eb8e71413.png)

As you can see, the first output of the first model isn't connected to the first output of the second model
"
42099,SequenceFeatures cant get embedding with shared_embedding_columns,"```
import tensorflow as tf # tf.version==1.14.0

def test_crossed_column():
    """""" crossed column测试 """"""
    features = {
        'price': [[0,1], [1,0], [2,1]],
        'color': [[1,2], [2,2], [0,0]]
    }
    price = tf.feature_column.sequence_categorical_column_with_vocabulary_list('price', [1,2], default_value=-1)
    color = tf.feature_column.sequence_categorical_column_with_vocabulary_list('color', [1,2], default_value=-1)
    price = tf.feature_column.shared_embedding_columns([price, color], 4)
    price_layer = tf.keras.experimental.SequenceFeatures(price)
    x = price_layer(features)
    with tf.Session() as session:
        session.run(tf.global_variables_initializer())
        session.run(tf.tables_initializer())
        print(session.run([x]))
test_crossed_column()
```
with the code, tf cant get embedding value with shared_embdding_columns, for the reason
```
ValueError: Items of feature_columns must be a FeatureColumn. Given (type <class 'tensorflow.python.feature_column.feature_column._SharedEmbeddingColumn'>): _SharedEmbeddingColumn(categorical_column=_SequenceCategoricalColumn(categorical_column=VocabularyListCategoricalColumn(key='price', vocabulary_list=(1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7f8fd783a850>, shared_embedding_collection_name='color_price_shared_embedding', ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True).
```
Why _SharedEmbeddingColumn isn't a type of fc?"
42098,[Tensorflow Lite] MobileBert Inferencing Latency on mobile device significantly slower than expected,"I am trying to run the BERT Question and Answer demo outlined on [this page](https://www.tensorflow.org/lite/models/bert_qa/overview), which demonstrates inferencing MobileBert on a mobile device.

I have cloned the relevant Android repository code found [here](https://github.com/tensorflow/examples/tree/master/lite/examples/bert_qa/android), and deployed the project to my Pixel 3 device.

The demo runs, however it takes significantly longer than expected: according to this [blog post](https://blog.tensorflow.org/2020/04/whats-new-in-tensorflow-lite-from-devsummit-2020.html), model latency should be around 74ms, however I'm seeing latency on the order of 500ms.

Can someone please advise if there's some setting/configuration that I'm missing? I have noted that the supplied MobileBert model is Float32 and so hasn't been quantised which means it won't use any hardware acceleration. I've also noted that no delegate has been specified to leverage any dedicated hardware acceleration (e.g. GPU).

Note: I'm submitting this issue here, as there's no option to submit issues under the relevant [examples](https://github.com/tensorflow/examples) repository. Please do let me know if I should be raising this query elsewhere.

Thanks in advance for any assistance/advice you can provide :)

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 3
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: n/a
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**

Query inferencing time is ~500ms.

**Describe the expected behavior**

Query inference time should be closer to 74ms.

**Standalone code to reproduce the issue**
I used the code from the example project repository verbatim (without any changes/customisations)."
42096,cross-compile Inference Diff tool,"Hello guys,

is it posible to cross-compile the [Inference Diff tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks/inference_diff) - I mean with bazel ...
If so, can you please indicate how?

Thank you"
42094,Compilation and Linking errors in MSVC Debug builds,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**
- TensorFlow installed from (source or binary): **Source**
- TensorFlow version: **2.3.0**
- Python version: **3.8.5**
- Bazel version (if compiling from source): **3.3.1**
- GCC/Compiler version (if compiling from source): **Visual Studio 2019**

Also reproduced in master (4be925e3)

**Describe the problem**

Multiple compilation errors when building in Windows Debug mode due to [C4716 ('function' must return a value)](https://docs.microsoft.com/en-us/cpp/error-messages/compiler-warnings/compiler-warning-level-1-c4716?view=vs-2019)

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
bazel build --config=dbg //tensorflow:tensorflow_framework
```

**Any other info / logs**

Compilation errors due to C4716 being elevated to an error in debug mode, eg in [`device_base.cc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/device_base.cc)

```.py 
const DeviceAttributes& DeviceBase::attributes() const {
  LOG(FATAL) << ""Device does not implement attributes()"";
}
```

Since AFAIK tensorflow does not use C++ exceptions (I believe it compiles with `-fno-exceptions` on Clang/GCC so I assume this is official policy) this would have to be handled with a `pragma warning (disable: 4217)` somewhere in the code. Will submit a suitable PR when I have time if no one gets to it first.
"
42093,PIP Install incorrct hashes,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Linux Elementary OS 5.1 Hera
- Python version: 3.6
- Installed via pip in a python venv 

**Describe the problem**
Unable to install via pip due to incorrect hashes

**Provide the exact sequence of commands / steps that you executed before running into the problem**
user1@XXXX-PC:~/Desktop/Python/ChatBotAI$ python -m venv chatenv python=3.6
user1@XXXX-PC:~/Desktop/Python/ChatBotAI$ pip install tensorflow

**Any other info / logs**
Collecting tensorflow
  Using cached tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)
ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.
    tensorflow from https://files.pythonhosted.org/packages/16/89/f2d29c2eafc2eeafb17d5634340e06366af904d332341200a49d954bce85/tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl#sha256=92430b6e91f00f38a602c4f547bbbaca598a3a90376f90d5b2acd24bc18fa1d7:
        Expected sha256 92430b6e91f00f38a602c4f547bbbaca598a3a90376f90d5b2acd24bc18fa1d7
             Got        49d42fc43402a2d9fb53aaea084c07c0fdddfd31af0995da463dd31ecc38f41e



"
42092,getting input/output dtype as  float32  after converting  keras mnist model to integer quantized tflite model ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 16.04
- TensorFlow installed from (source or binary): 
- TensorFlow version (or github SHA if from source): 2.2


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```
import tensorflow as tf 
import numpy as np



# Load MNIST dataset
mnist = tf.keras.datasets.mnist


(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images.astype(np.float32) / 255.0
test_images = test_images.astype(np.float32) / 255.0

# Define the model architecture
model = tf.keras.Sequential([
  tf.keras.layers.InputLayer(input_shape=(28, 28)),
  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),
  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(10)
])

# Train the digit classification model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(
                  from_logits=True),
              metrics=['accuracy'])
model.fit(
  train_images,
  train_labels,
  epochs=5,
  validation_data=(test_images, test_labels)
)
model.save(""mnist.h5"")

model_ = tf.keras.models.load_model(""mnist.h5"")




def representative_data_gen():
  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):
    # Model has only one input so each data point has one element.
    yield [input_value]





converter = tf.lite.TFLiteConverter.from_keras_model(model_)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
# Ensure that if any ops can't be quantized, the converter throws an error
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
# Set the input and output tensors to uint8 (APIs added in r2.3)
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

tflite_model_quant = converter.convert()


interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)
input_type = interpreter.get_input_details()[0]['dtype']
print('input: ', input_type)
output_type = interpreter.get_output_details()[0]['dtype']
print('output: ', output_type)
**The output from the converter invocation**

```
# Copy and paste the output here.

<class 'numpy.float32'>
<output:  <class 'numpy.float32'>

```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Hi 
Please help me to identify this issue, After successful conversion of mnist model to integer quantized tflite model i am getting the input dtype as float32 instead  of uint8.
I followed the same post training interger quantization steps mentioned in the tensorflows official website, but getting input/output dtype  as float32
Attaching the link: https://www.tensorflow.org/lite/performance/post_training_integer_quant


I also followed the command line tflite_converter command too,  still getting quantized float model only
command used : 
tflite_convert --output_file mnist_tflite_cmd.tflite --keras_model_file mnist.h5 --input_arrays ""reshape_input"" --input_shapes ""1,28,28"" --output_arrays ""Identity"" --output_format TFLITE --inference_type QUANTIZED_UINT8 --inference_input_type QUANTIZED_UINT8 

Thanks 

"
42091,"ValueError: slice index 0 of dimension 0 out of bounds. for 'strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.","### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Code provided by TensorFlow themselves. Tutorial link: https://www.tensorflow.org/tutorials/structured_data/feature_columns 

-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Catalina v10.15.4
-   **TensorFlow installed from (source or binary)**: source
-   **TensorFlow version (use command below)**: 2.0.0
-   **Python version**: 3.7.7

### Describe the problem
Bug with Tensorflow code, which I have executed in a Anaconda Environment on Jupyter Notebooks. I have tried running the notebook provided by Tensorflow themselves (link specified above) and was confronted with the following traceback:

`Epoch 1/10
231/231 [==============================] - 4s 19ms/step - loss: 0.6898 - accuracy: 0.6893
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)
   1609   try:
-> 1610     c_op = c_api.TF_FinishOperation(op_desc)
   1611   except errors.InvalidArgumentError as e:

InvalidArgumentError: slice index 0 of dimension 0 out of bounds. for 'strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-39-9b1057f115c9> in <module>
     13 model.fit(train_ds,
     14           validation_data=val_ds,
---> 15           epochs=10)

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    368                       mode=ModeKeys.TEST,
    369                       training_context=eval_context,
--> 370                       total_epochs=1)
    371                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,
    372                                  prefix='val_')

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--> 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---> 86                               distributed_function(input_fn))
     87 
     88   return execution_function

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    501       # This is the first call of __call__, so we have to initialize.
    502       initializer_map = object_identity.ObjectIdentityDictionary()
--> 503       self._initialize(args, kwds, add_initializers_to=initializer_map)
    504     finally:
    505       # At this point we know that the initialization is complete (or less

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    406     self._concrete_stateful_fn = (
    407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 408             *args, **kwds))
    409 
    410     def invalid_creator_scope(*unused_args, **unused_kwds):

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   1846     if self.input_signature:
   1847       args, kwargs = None, None
-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)
   1849     return graph_function
   1850 

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2148         graph_function = self._function_cache.primary.get(cache_key, None)
   2149         if graph_function is None:
-> 2150           graph_function = self._create_graph_function(args, kwargs)
   2151           self._function_cache.primary[cache_key] = graph_function
   2152         return graph_function, args, kwargs

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2039             arg_names=arg_names,
   2040             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2041             capture_by_value=self._capture_by_value),
   2042         self._function_attributes,
   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    913                                           converted_func)
    914 
--> 915       func_outputs = python_func(*func_args, **func_kwargs)
    916 
    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    357         # the function a weak reference to itself to avoid a reference cycle.
--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    359     weak_wrapped_fn = weakref.ref(wrapped_fn)
    360 

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in distributed_function(input_iterator)
     71     strategy = distribution_strategy_context.get_strategy()
     72     outputs = strategy.experimental_run_v2(
---> 73         per_replica_function, args=(model, x, y, sample_weights))
     74     # Out of PerReplica outputs reduce or pick values to return.
     75     all_outputs = dist_utils.unwrap_output_dict(

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py in experimental_run_v2(self, fn, args, kwargs)
    758       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),
    759                                 convert_by_default=False)
--> 760       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    761 
    762   def reduce(self, reduce_op, value, axis):

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)
   1785       kwargs = {}
   1786     with self._container_strategy().scope():
-> 1787       return self._call_for_each_replica(fn, args, kwargs)
   1788 
   1789   def _call_for_each_replica(self, fn, args, kwargs):

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)
   2130         self._container_strategy(),
   2131         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):
-> 2132       return fn(*args, **kwargs)
   2133 
   2134   def _reduce_to(self, reduce_op, value, destinations):

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    290   def wrapper(*args, **kwargs):
    291     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
--> 292       return func(*args, **kwargs)
    293 
    294   if inspect.isfunction(func) or inspect.ismethod(func):

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in test_on_batch(model, x, y, sample_weight, reset_metrics)
    319       x, y, sample_weight=sample_weight, extract_tensors_from_dataset=True)
    320 
--> 321   batch_size = array_ops.shape(nest.flatten(x, expand_composites=True)[0])[0]
    322   outputs = training_eager.test_on_batch(
    323       model,

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py in _slice_helper(tensor, slice_spec, var)
    811         ellipsis_mask=ellipsis_mask,
    812         var=var,
--> 813         name=name)
    814 
    815 

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py in strided_slice(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)
    977       ellipsis_mask=ellipsis_mask,
    978       new_axis_mask=new_axis_mask,
--> 979       shrink_axis_mask=shrink_axis_mask)
    980 
    981   parent_name = name

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py in strided_slice(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)
  10392                         ellipsis_mask=ellipsis_mask,
  10393                         new_axis_mask=new_axis_mask,
> 10394                         shrink_axis_mask=shrink_axis_mask, name=name)
  10395   _result = _op.outputs[:]
  10396   _inputs_flat = _op.inputs

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    791         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,
    792                          input_types=input_types, attrs=attr_protos,
--> 793                          op_def=op_def)
    794       return output_structure, op_def.is_stateful, op
    795 

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in create_op(***failed resolving arguments***)
    546     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    547         op_type, inputs, dtypes, input_types, name, attrs, op_def,
--> 548         compute_device)
    549 
    550   def capture(self, tensor, name=None):

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)
   3427           input_types=input_types,
   3428           original_op=self._default_original_op,
-> 3429           op_def=op_def)
   3430       self._create_op_helper(ret, compute_device=compute_device)
   3431     return ret

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)
   1771           op_def, inputs, node_def.attr)
   1772       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,
-> 1773                                 control_input_ops)
   1774     # pylint: enable=protected-access
   1775 

~/miniconda3/envs/cogsci/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)
   1611   except errors.InvalidArgumentError as e:
   1612     # Convert to ValueError for backwards compatibility.
-> 1613     raise ValueError(str(e))
   1614 
   1615   return c_op

ValueError: slice index 0 of dimension 0 out of bounds. for 'strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.`
"
42090,"Build Failure of version 2.3.0 in macOS, MacPorts","Version 2.3.0 fails to build on macOS.

First issue, `Action failed to execute: java.io.IOException: Cannot run program… error=24, Too many open files`:
```
ERROR: /opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py37-tensorflow/work/tensorflow-tensorflow-b36436b/tensorflow/core/common_runtime/BUILD:328:11: C++ compilation of rule '//tensorflow/core/common_runtime:collective_executor_mgr' failed (Exit -1): wrapped_clang failed: error executing command 
  (cd /opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py37-tensorflow/work/e3571a779784f9da03a7824d69817047/execroot/org_tensorflow && \
  exec env - \
    APPLE_SDK_PLATFORM=MacOSX \
    APPLE_SDK_VERSION_OVERRIDE=10.15 \
    PATH=/opt/local/bin:/opt/local/sbin:/bin:/sbin:/usr/bin:/usr/sbin \
    XCODE_VERSION_OVERRIDE=11.6.0.11E708 \
  external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG '-std=c++11' -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/gif -iquote bazel-out/host/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/host/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/host/bin/external/com_google_protobuf -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib -iquote bazel-out/host/bin/external/zlib -iquote external/double_conversion -iquote bazel-out/host/bin/external/double_conversion -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/gif -isystem bazel-out/host/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/host/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/host/bin/external/zlib -isystem external/double_conversion -isystem bazel-out/host/bin/external/double_conversion -MD -MF bazel-out/host/bin/tensorflow/core/common_runtime/_objs/collective_executor_mgr/collective_executor_mgr.d -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' '-frandom-seed=bazel-out/host/bin/tensorflow/core/common_runtime/_objs/collective_executor_mgr/collective_executor_mgr.o' -isysroot __BAZEL_XCODE_SDKROOT__ -F__BAZEL_XCODE_SDKROOT__/System/Library/Frameworks -F__BAZEL_XCODE_DEVELOPER_DIR__/Platforms/MacOSX.platform/Developer/Library/Frameworks '-mmacosx-version-min=10.15' -g0 '-march=x86-64' -g0 '-std=c++14' -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions '-DTENSORFLOW_USE_XLA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/common_runtime/collective_executor_mgr.cc -o bazel-out/host/bin/tensorflow/core/common_runtime/_objs/collective_executor_mgr/collective_executor_mgr.o)
Execution platform: @local_execution_config_platform//:platform. Note: Remote connection/protocol failed with: execution failed
Action failed to execute: java.io.IOException: Cannot run program ""/opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py37-tensorflow/work/install/1eb24b6f9fb447fbef56fd6c7521f126/process-wrapper"" (in directory ""/opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py37-tensorflow/work/e3571a779784f9da03a7824d69817047/execroot/org_tensorflow""): error=24, Too many open files
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

This is with system settings:
```bash
$ ulimit -n
65536
$ launchctl limit maxfiles
	maxfiles    65536          200000   
```

Starting the build again, another issue is encountered, apparently arising from https://github.com/tensorflow/tensorflow/pull/40654.

Second issue, `error: no matching function for call to object of type '(lambda at tensorflow/python/lib/core/bfloat16.cc:637:25)`:
```
:info:build tensorflow/python/lib/core/bfloat16.cc:678:8: error: no matching function for call to object of type '(lambda at tensorflow/python/lib/core/bfloat16.cc:637:25)'
:info:build   if (!register_ufunc(""less_equal"", CompareUFunc<Bfloat16LeFunctor>,
:info:build        ^~~~~~~~~~~~~~
:info:build tensorflow/python/lib/core/bfloat16.cc:637:25: note: candidate function not viable: no overload of 'CompareUFunc' matching 'PyUFuncGenericFunction' (aka 'void (*)(char **, const long *, const long *, void *)') for 2nd argument
:info:build   auto register_ufunc = [&](const char* name, PyUFuncGenericFunction fn,
:info:build                         ^
:info:build tensorflow/python/lib/core/bfloat16.cc:682:8: error: no matching function for call to object of type '(lambda at tensorflow/python/lib/core/bfloat16.cc:637:25)'
:info:build   if (!register_ufunc(""greater_equal"", CompareUFunc<Bfloat16GeFunctor>,
:info:build        ^~~~~~~~~~~~~~
```

macOS 10.15.6 19G73
Xcode 11.6 11E708 

Related:
* https://trac.macports.org/ticket/60960
* https://github.com/macports/macports-ports/pull/7575
* https://github.com/tensorflow/tensorflow/pull/40654
"
42088,Problem with tf.train.FloatList Precision,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.10
- CUDA/cuDNN version: 10.2

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I want to convert my Pascal VOC to TFRecords.
But my bounding box values are not the same.
For example:
my xmin is:  [0.620390625]
but the value I get from example is: [0.6203906536102295]

```python
import tensorflow as tf

xmin = [0.620390625]
feature_dict = {
    'xmin':
        tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),
}
example = tf.train.Example(features=tf.train.Features(feature=feature_dict))

print(xmin) # [0.620390625]
print(example.features.feature['xmin'].float_list.value) # [0.6203906536102295]
```
And I also try other values, only the value `2.7182817459106445` show in [TFRecord tutorials](https://www.tensorflow.org/tutorials/load_data/tfrecord) would be the same, as below:

![Screenshot from 2020-08-06 16-57-53](https://user-images.githubusercontent.com/20853096/89513954-ce8ded80-d807-11ea-8c2a-d8ba7a19424a.png)

**Describe the expected behavior**

value should be the same

**Standalone code to reproduce the issue**
Colab link: https://colab.research.google.com/drive/1X_PnjlxA948OpgXaN2laNzdVRQ-1wuHl"
42087,ImportError: DLL load failed: The specified module could not be found.,"I am getting the following error when trying to import tensorflow. I have tried many solutions and non seem to work.

I have seen Issue #22794, but it does not seem to help.

Versions -- > python 3.7.4 -- > tensorflow 2.3.0

> 
> runfile('C:/Users/pshad/.spyder-py3/temp.py', wdir='C:/Users/pshad/.spyder-py3')
> Traceback (most recent call last):
> 
>   File ""<ipython-input-30-bc8fb4f78acd>"", line 1, in <module>
>     runfile('C:/Users/pshad/.spyder-py3/temp.py', wdir='C:/Users/pshad/.spyder-py3')
> 
>   File ""C:\Users\pshad\Anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 827, in runfile
>     execfile(filename, namespace)
> 
>   File ""C:\Users\pshad\Anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 110, in execfile
>     exec(compile(f.read(), filename, 'exec'), namespace)
> 
>   File ""C:/Users/pshad/.spyder-py3/temp.py"", line 9, in <module>
>     import tensorflow as tf
> 
>   File ""C:\Users\pshad\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
>     from tensorflow.python.tools import module_util as _module_util
> 
>   File ""C:\Users\pshad\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
>     from tensorflow.python.eager import context
> 
>   File ""C:\Users\pshad\Anaconda3\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
>     from tensorflow.python import pywrap_tfe
> 
>   File ""C:\Users\pshad\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
>     from tensorflow.python import pywrap_tensorflow
> 
>   File ""C:\Users\pshad\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
>     raise ImportError(msg)
> 
> ImportError: Traceback (most recent call last):
>   File ""C:\Users\pshad\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
>     from tensorflow.python._pywrap_tensorflow_internal import *
> ImportError: DLL load failed: The specified module could not be found.
> 
> 
> Failed to load the native TensorFlow runtime.
> 
> See https://www.tensorflow.org/install/errors

I tried to reinstall the tensorflow, downgrade,  and upgrade as well. Nothing seem to work, unfortunately. "
42086,Person detection training doesn't converge. Evaluation showing accuracy of 52% after 1M steps,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): Docker installation
- Tensorflow version (commit SHA if source): 1.14.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): None

**Describe the problem**
I have done the training as exactly as in the document https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection/training_a_model.md with some minor command changes which is not updated in the original document. The training was done for 1Million steps and when evaluated the accuracy was 52%. 
The minor modifications were 
1. use the script download_and_convert.py instead of build_visualwakewords_data.py. 
2. Changed arguments --input_grayscale to --use_grayscale

**Please provide the exact sequence of commands/steps when you ran into the problem**
The commands i used are as follows all from the path models/research/slim
1. python slim/download_and_convert_data.py \
    --dataset_name=visualwakewords \
    --dataset_dir=/tmp/visualwakewords

2. python slim/train_image_classifier.py     --train_dir=vww_96_grayscale     --dataset_name=visualwakewords     --dataset_split_name=train     --dataset_dir=coco_dataset/     --model_name=mobilenet_v1_025     --preprocessing_name=mobilenet_v1     --train_image_size=96     --use_grayscale=True     --save_summaries_secs=300     --learning_rate=0.045     --label_smoothing=0.1     --learning_rate_decay_factor=0.98     --num_epochs_per_decay=2.5     --moving_average_decay=0.9999     --batch_size=96     --max_number_of_steps=1000000

3. python slim/eval_image_classifier.py --alsologtostderr checkpoint_path=vww_96_grayscale/model.ckpt-1000000 --dataset_dir=coco_dataset/ --dataset_name=visualwakewords --dataset_split_name=val --model_name=mobilenet_v1_025 --preprocessing_name=mobilenet_v1 --use_grayscale=True --train_image_size=96

Can someone help me in identifying why it is not converging as stated in the paper? "
42085,[TFLite] Error: TfLiteGpuDelegate Init: MUL: 1024x131  cannot be reduced to linear.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 10.0 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel3 
- TensorFlow installed from (source or binary): binary 
- TensorFlow version (use command below): org.tensorflow:tensorflow-lite-gpu:2.2.0 / 0.0.0-nightly 
- Python version: 3.6 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: X
- GPU model and memory:  Adreno 630

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Hi. I'm trying to serve our model on Pixel3(Android 10), using TFLite's GPU backend. 
But, this error makes our app crash. (Both of tensorflow-lite-gpu:2.2.0 and 0.0.0-nightly)
```
  Process: org.tensorflow.lite.examples.posenet, PID: 30052
    java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Next operations are not supported by GPU delegate:
    SUM: Operation is not supported.
    First 141 operations will run on the GPU, and the remaining 7 on the CPU.
    TfLiteGpuDelegate Init: MUL: 1024x131  cannot be reduced to linear.
    TfLiteGpuDelegate Prepare: delegate is not initialized
    Node number 148 (TfLiteGpuDelegateV2) failed to prepare.
```
The error is ""TfLiteGpuDelegate Init: MUL: 1024x131  cannot be reduced to linear."" 
What is the matter and what can I do to utilize TfLiteGPUDelegate?    

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42084,Tensorflow is BROKE .... ,"Stuck here, tf-nightly is not compatible with CUDA 11.0 and the latest code is broke....

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): One line ?
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): Latest as of this second
- Python version: 3.8.2
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 11.00
- GPU model and memory: RTX 2070

```
Python 3.8.2 (default, Jul 16 2020, 14:00:26) 
[GCC 9.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf

2020-08-06 00:18:35.042260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/xxxxx/.virtualenvs/tensorflowgpu/lib/python3.8/site-packages/tensorflow/__init__.py"", line 433, in <module>
    _ll.load_library(_main_dir)
  File ""/home/xxxx/.virtualenvs/tensorflowgpu/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library
    py_tf.TF_LoadLibrary(lib)
tensorflow.python.framework.errors_impl.NotFoundError: /home/xxxxx/.local/lib/python3.8/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb
>>> 
```"
42083,"Wrong JPEG library version: library is 90, caller expects 80","I got this error when i call tf.image.decode_jpeg in my program which linked a libjpeg of version 90.
Tensorflow : 1.14
Opencv : 3.1.0"
42082,QAT conversion RuntimeError: Quantization not yet supported for op: 'DEQUANTIZE' issue with tf-nightly,"**UPDATE**

**You can now fully quantize QAT models trained in any TF 2.x version. However, this feature is only available from TF version `2.4.0-rc0` onwards (and will be available in the final TF 2.4 release as well).**

**You will not require any workaround, i.e, you don't have to use TF 1.x**

To verify that your TF version supports this, run the following code and check if runs successfully:

```
import tensorflow as tf
assert tf.__version__[:3] == ""2.4"", 'Your TF version ({}), does not support full quantization of QAT models. Upgrade to a TF 2.4 version (2.4.0-rc0, 2.4.0-rc1...2.4) or above'.format(tf.__version__)
```



------------------------------------------------------------------------------------------
**ISSUE**

**System information**
TensorFlow version (use command below): 2.4.0-dev20200728

**Describe the current behavior**
Error converting quantize aware trained tensorflow model to a fully integer quantized tflite model - error: `RuntimeError: Quantization not yet supported for op: 'DEQUANTIZE'`

**Describe the expected behavior**
Convert successfully

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/gist/sayakpaul/8c8a1d7c94beca26d93b67d92a90d3f0/qat-bad-accuracy.ipynb"
42081,[ROCm] Cannot find rocm library hip_hcc,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 3.4.1
- GCC/Compiler version (if compiling from source): 10.1.0
- CUDA/cuDNN version: N/A
- ROCm version: 3.5.0
- GPU model and memory:



**Describe the problem**

When building I am getting the following error:
```
Repository rule rocm_configure defined at:
  /home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl:861:33: in <toplevel>
ERROR: An error occurred during the fetch of repository 'local_config_rocm':
   Traceback (most recent call last):
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 840
		_create_local_rocm_repository(<1 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 647, in _create_local_rocm_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 449, in _find_libs
		_select_rocm_lib_paths(<3 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 418, in _select_rocm_lib_paths
		auto_configure_fail(<1 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 162, in auto_configure_fail
		fail(<1 more arguments>)

ROCm Configuration Error: Cannot find rocm library hip_hcc
INFO: Repository com_google_protobuf instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule tf_http_archive defined at:
  /home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/repo.bzl:134:34: in <toplevel>
ERROR: Skipping '//tensorflow:install_headers': no such package '@local_config_rocm//rocm': Traceback (most recent call last):
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 840
		_create_local_rocm_repository(<1 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 647, in _create_local_rocm_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 449, in _find_libs
		_select_rocm_lib_paths(<3 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 418, in _select_rocm_lib_paths
		auto_configure_fail(<1 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 162, in auto_configure_fail
		fail(<1 more arguments>)

ROCm Configuration Error: Cannot find rocm library hip_hcc
ERROR: no such package '@local_config_rocm//rocm': Traceback (most recent call last):
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 840
		_create_local_rocm_repository(<1 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 647, in _create_local_rocm_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 449, in _find_libs
		_select_rocm_lib_paths(<3 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 418, in _select_rocm_lib_paths
		auto_configure_fail(<1 more arguments>)
	File ""/home/acxz/vcs/git/github/rocm-arch/tensorflow-rocm/src/tensorflow-2.2.0-rocm/third_party/gpus/rocm_configure.bzl"", line 162, in auto_configure_fail
		fail(<1 more arguments>)

ROCm Configuration Error: Cannot find rocm library hip_hcc
INFO: Elapsed time: 5.658s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow ... (2 packages)
==> ERROR: A failure occurred in build().
    Aborting...
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. git clone
2. `export TF_NEED_ROCM=1`
3. `./configure`
4. 
```
  bazel \
        build --config=mkl --config=avx2_linux -c opt \
          //tensorflow:libtensorflow.so \
          //tensorflow:libtensorflow_cc.so \
          //tensorflow:install_headers \
          //tensorflow/tools/pip_package:build_pip_package
      bazel-bin/tensorflow/tools/pip_package/build_pip_package --gpu ""${srcdir}""/tmpoptrocm
```

To be exactly precise I am using the following build script (PKGBUILD):
https://aur.archlinux.org/cgit/aur.git/tree/PKGBUILD?h=tensorflow-rocm

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Downstream issue: https://github.com/rocm-arch/tensorflow-rocm/issues/5
"
42080,"File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorflow/python/feature_column/dense_features.py"", line 30, in <module>     class DenseFeatures(fc._BaseFeaturesLayer):  # pylint: disable=protected-access AttributeError: module 'tensorflow.python.feature_column.feature_column_v2' has no attribute '_BaseFeaturesLayer'","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.3.0
- Python version: 3.8.3
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 11.0 / cuDNN 7.6.5
- GPU model and memory: RTX 2070 super



**Describe the problem**
Can not run tensorboard
**Provide the exact sequence of commands / steps that you executed before running into the problem**
conda activate tf1 #(where I have tensor installed)
pip install -U tensorboard
tensorboard --logdir=models/my_ssd_resnet50_v1_fpn
tensorboard dev --help  #(doesn't work either, gives error narrowed down to title) 



**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

2020-08-05 18:01:41.991550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Traceback (most recent call last):
  File ""/home/ray/anaconda3/envs/tf1/bin/tensorboard"", line 5, in <module>
    from tensorboard.main import run_main
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorboard/main.py"", line 43, in <module>
    from tensorboard import default
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorboard/default.py"", line 40, in <module>
    from tensorboard.plugins.beholder import beholder_plugin_loader
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorboard/plugins/beholder/__init__.py"", line 22, in <module>
    from tensorboard.plugins.beholder.beholder import Beholder
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorboard/plugins/beholder/beholder.py"", line 225, in <module>
    class BeholderHook(tf.estimator.SessionRunHook):
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py"", line 62, in __getattr__
    module = self._load()
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py"", line 45, in _load
    module = importlib.import_module(self.__name__)
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorflow_estimator/__init__.py"", line 10, in <module>
    from tensorflow_estimator._api.v1 import estimator
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py"", line 10, in <module>
    from tensorflow_estimator._api.v1.estimator import experimental
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py"", line 10, in <module>
    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py"", line 23, in <module>
    from tensorflow.python.feature_column import dense_features
  File ""/home/ray/anaconda3/envs/tf1/lib/python3.8/site-packages/tensorflow/python/feature_column/dense_features.py"", line 30, in <module>
    class DenseFeatures(fc._BaseFeaturesLayer):  # pylint: disable=protected-access
AttributeError: module 'tensorflow.python.feature_column.feature_column_v2' has no attribute '_BaseFeaturesLayer'
"
42079,"tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- TensorFlow installed from (source or binary): Anaconda
- TensorFlow version (or github SHA if from source):  tf_nightly_gpu-2.4.0.dev20200805-cp37-cp37m-win_amd64.whl


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
model = tf.saved_model.load(saved_model_dir)
concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
concrete_func.inputs[0].set_shape([1, 300, 300, 3])
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])


# These lines are necessary for the issue fix https://github.com/tensorflow/tensorflow/issues/41877
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
```

**The output from the converter invocation**

```
(tf_gpu_tf_nightly) d:\TensorFlow\tensorflowComponentId\models\research\object_detection>python convert_saved_model_to_f
lat_buffer.py
2020-08-05 16:31:38.096415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cudart64_101.dll
2020-08-05 16:31:46.030792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library nvcuda.dll
2020-08-05 16:31:46.153774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P4000 computeCapability: 6.1
coreClock: 1.48GHz coreCount: 14 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 226.62GiB/s
2020-08-05 16:31:46.176284: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cudart64_101.dll
2020-08-05 16:31:46.371687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cublas64_10.dll
2020-08-05 16:31:46.632753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cufft64_10.dll
2020-08-05 16:31:46.734036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library curand64_10.dll
2020-08-05 16:31:47.053455: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cusolver64_10.dll
2020-08-05 16:31:47.157739: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cusparse64_10.dll
2020-08-05 16:31:47.917165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cudnn64_7.dll
2020-08-05 16:31:47.930832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 16:31:47.966000: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized wit
h oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:
 AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-05 16:31:48.030523: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x214141cae40 initialized for
platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-05 16:31:48.088275: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default
 Version
2020-08-05 16:31:48.136648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P4000 computeCapability: 6.1
coreClock: 1.48GHz coreCount: 14 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 226.62GiB/s
2020-08-05 16:31:48.156650: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cudart64_101.dll
2020-08-05 16:31:48.166699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cublas64_10.dll
2020-08-05 16:31:48.176341: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cufft64_10.dll
2020-08-05 16:31:48.187558: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library curand64_10.dll
2020-08-05 16:31:48.198596: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cusolver64_10.dll
2020-08-05 16:31:48.207628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cusparse64_10.dll
2020-08-05 16:31:48.219176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cudnn64_7.dll
2020-08-05 16:31:48.230180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 16:31:48.869564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor
with strength 1 edge matrix:
2020-08-05 16:31:48.878309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-08-05 16:31:48.883346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-08-05 16:31:48.888900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:loc
alhost/replica:0/task:0/device:GPU:0 with 6307 MB memory) -> physical GPU (device: 0, name: Quadro P4000, pci bus id: 00
00:01:00.0, compute capability: 6.1)
2020-08-05 16:31:48.914058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21455b650a0 initialized for
platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-05 16:31:48.924375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P4000,
 Compute Capability 6.1
2020-08-05 16:32:21.722971: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute
capability >= 0.0): 1
2020-08-05 16:32:21.732162: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-08-05 16:32:21.738833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P4000 computeCapability: 6.1
coreClock: 1.48GHz coreCount: 14 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 226.62GiB/s
2020-08-05 16:32:21.757141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cudart64_101.dll
2020-08-05 16:32:21.764885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cublas64_10.dll
2020-08-05 16:32:21.775482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cufft64_10.dll
2020-08-05 16:32:21.783435: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library curand64_10.dll
2020-08-05 16:32:21.791890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cusolver64_10.dll
2020-08-05 16:32:21.799672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cusparse64_10.dll
2020-08-05 16:32:21.813984: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic
library cudnn64_7.dll
2020-08-05 16:32:21.822129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 16:32:21.827773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutorwith strength 1 edge matrix:
2020-08-05 16:32:21.839959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-08-05 16:32:21.844847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-08-05 16:32:21.850558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6307 MB memory) -> physical GPU (device: 0, name: Quadro P4000, pci bus id: 00
00:01:00.0, compute capability: 6.1)
2020-08-05 16:32:23.381950: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:832] Optimization results for grappler item: graph_to_optimize
2020-08-05 16:32:23.392215: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:834]   function_optimizer: Graph size after: 9459 nodes (8971), 11780 edges (11285), time = 283.837ms.
2020-08-05 16:32:23.408641: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:834]   function_optimizer: function_optimizer did nothing. time = 6.568ms.
2020-08-05 16:32:44.552016: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:315] Ignored output_format.
2020-08-05 16:32:44.561287: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:318] Ignored drop_control_dependency.
loc(""Func/StatefulPartitionedCall/input/_0""): error: requires all operands and results to have compatible element types
Traceback (most recent call last):
  File ""C:\Users\clgilbe\Anaconda3\envs\tf_gpu_tf_nightly\lib\site-packages\tensorflow\lite\python\convert.py"", line 199, in toco_convert_protos
    enable_mlir_converter)
  File ""C:\Users\clgilbe\Anaconda3\envs\tf_gpu_tf_nightly\lib\site-packages\tensorflow\lite\python\wrap_toco.py"", line 38, in wrapped_toco_convert
    enable_mlir_converter)
Exception: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x300x300x3x!tf.quint8>) -> tensor<1x300x300x3xui8>


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""convert_saved_model_to_flat_buffer.py"", line 21, in <module>
    tflite_model = converter.convert()
  File ""C:\Users\clgilbe\Anaconda3\envs\tf_gpu_tf_nightly\lib\site-packages\tensorflow\lite\python\lite.py"", line 1118,in convert
    return super(TFLiteConverterV2, self).convert()
  File ""C:\Users\clgilbe\Anaconda3\envs\tf_gpu_tf_nightly\lib\site-packages\tensorflow\lite\python\lite.py"", line 942, in convert
    self).convert(graph_def, input_tensors, output_tensors)
  File ""C:\Users\clgilbe\Anaconda3\envs\tf_gpu_tf_nightly\lib\site-packages\tensorflow\lite\python\lite.py"", line 669, in convert
    **converter_kwargs)
  File ""C:\Users\clgilbe\Anaconda3\envs\tf_gpu_tf_nightly\lib\site-packages\tensorflow\lite\python\convert.py"", line 574, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""C:\Users\clgilbe\Anaconda3\envs\tf_gpu_tf_nightly\lib\site-packages\tensorflow\lite\python\convert.py"", line 202, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x300x300x3x!tf.quint8>) -> tensor<1x300x300x3xui8>
```

**Also, please include a link to the saved model or GraphDef**

```
Pre-trained model ssd_resnet50_v1_fpn_640x640_coco17_tpu-8 http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz
```

**Failure details**
Failure to convert using instructions for converting a saved model using concrete_functions.  https://www.tensorflow.org/lite/convert/python_api#converting_a_savedmodel_  Similar error to #41877


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title. - NOPE

**Any other info / logs**

See above
"
42076,Tensorflow BROKE... for CUDA 11.0,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): Latest
- Python version: 3.8.2
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.00
- GPU model and memory: RTX 2070


Python 3.8.2 (default, Jul 16 2020, 14:00:26) 
[GCC 9.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> **import tensorflow as tf**

2020-08-05 17:27:44.548309: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/xxxxxxx/.virtualenvs/tensorflowgpu/lib/python3.8/site-packages/tensorflow/__init__.py"", line 433, in <module>
    _ll.load_library(_main_dir)
  File ""/home/xxxxxxx/.virtualenvs/tensorflowgpu/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library
    py_tf.TF_LoadLibrary(lib)
tensorflow.python.framework.errors_impl.NotFoundError: /home/xxxxxxxx/.local/lib/python3.8/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb
"
42075,Hello World example project's generated binary is empty for Bluepill,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs Catalina version 10.15.3
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 89851a6a7725d92735e9817ee6a1f551dd7492ab
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Bluepill

**Describe the problem**
When I build the Hello World Tensorflow Lite example project for the blue pill microcontroller, the resulting binary is empty. This is demonstrated when I objdump the resulting ELF file:

```
bluepill_cortex-m3/bin/hello_world:     file format elf32-littlearm




Disassembly of section ._user_heap_stack:


20000000 <._user_heap_stack>:
    ...

```

**Please provide the exact sequence of commands/steps when you ran into the problem**
Build the Hello World binary by specifying the bluepill as target:
```
gmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill hello_world_bin
```
Then see the objdump of the ELF:
```
tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/arm-none-eabi/bin/objdump tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/hello_world -D
```
"
42070,Universal Multiple Optimizer Wrapper with Layer Assignment,"I am proposing a universal wrapper for a layer-wise set of distinct optimizers. This will allow each optimizer in a set of optimizers to apply the gradient to its layer-wise variables. This will enable discriminative layer training. It will also enable any training method that applies any combination of optimizers to any combination of layers at any combination of hyperparameters for those optimizers.

The optimizer wrapper will consume a list of instantiated optimizers and layers, referred to as an optimizer spec. For each optimizer spec, it will allocate the correct gradients and variables and then call the apply_gradients method for the optimizer. This allows the optimizer wrapper to leverage all implementations of optimizer specific operations, notably the resource apply methods. 

A prototype of the optimizer wrapper is available at this link. [link](https://colab.research.google.com/drive/1NKAsrjj1qcls6p8S5dvJT1PkdC2Ieazc?usp=sharing)

The prototype works on both TPU and CPU. 

I am willing to contribute this code. 

This will not change any existing classes. Instead, it will act as a wrapper that allows a model to use multiple optimizers. 

Discriminative layer training is most beneficial for fine tuning pretrained models. Users looking to apply existing technology will benefit in reduced training time and improved transfer learning. 

"
42068,tf.keras.utils.plot_model doesn't work,"**System information**
Google colab.

**Steps to reproduce:**
1. Click ""Run all"" at Colab of https://www.tensorflow.org/tutorials/structured_data/feature_columns
2. Add a cell with the following code:
```tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)```


**Describe the current behavior**
1. It displays only 1 block `[sequential]`.
2. If you copy all cells + plot_model and run locally in a separate py script (not Colab), you'll also get a lot of warnings that features v2 are deprecated and will be removed in next releases (tf 2.2).

**Describe the expected behavior**
1. The model would be displayed.
2. No deprecation warning would be displayed.

**Standalone code to reproduce the issue**
https://www.tensorflow.org/tutorials/structured_data/feature_columns
"
42066,[Docs] RAM usage when building from source,"## URL(s) with the issue:
https://www.tensorflow.org/install/source

## Description of issue (what needs changing):
Aproximately the RAM that used when compiling. IMO, ""Building TensorFlow from source can use **a lot of** RAM"", is not clear how ""a lot of"" is how many GB. I have VM with 6vCPU 10GB RAM and I frequently run out of memory. This run out of memory is not only slowing down the compiling, but also make system freeze/unresponsive, Every this happens, I need to increase the RAM by 500MB to unlock the system.

### Clear description
Why we need this? Because we don't want to sleep with the machine compiling overnight. And when we wakes up, it turns out the compiling failed, or the machine frozen, and it's really waste of time. This ""aproximately RAM usage"" should help anticipate this though.

### How about `--local_ram_resources`?
Well, I already tried with this flag `--local_ram_resources=HOST_RAM*.2` as described from [here](https://docs.bazel.build/versions/master/user-manual.html#flag--local_{ram,cpu}_resources). Is this mean the building process will only take 20% RAM? Is this global or for every thread? Is this flag supported on the `v2.3.0` tag on this repo? I watched `htop` and seen many tasks at once using more than 20%. I run out of memory again even with this, this is ridiculous. 😭 

### Submit a pull request?
To this [repo](https://github.com/tensorflow/docs)? Yes if I can get how aproximately the RAM usage... I think it's max around 3GB per CPU core? Correct me if I'm wrong.

### Other information
Well it seems I got a lot of RAM, but I running out of memory. The VM is live CD (not installed), and also the swap.... yeah it's zram (5GB) instead of swapfile. Because... uh..., I don't want to kill the SSD :(

### Related issue
#30047"
42065,"tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Tensorflow version: 2.3.0
- TensorFlow installed from (source or binary): Binary (Anaconda) 


**Command used to run the converter or code if you’re using the Python API**

```
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir,signature_keys=['serving_default'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
quantized_model = converter.convert()
```

**The output from the converter invocation**

```
2020-08-05 14:53:54.038060: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:53:56.073223: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-08-05 14:53:58.130905: I tensorflow/stream_executor/cuda/cuda_gpu_exec
utor.cc:982] successful NUMA node read from SysFS had negative value (-1), 
but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.131826: I tensorflow/core/common_runtime/gpu/gpu_device
.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryB
andwidth: 223.96GiB/s
2020-08-05 14:53:58.131898: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:53:58.134264: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-05 14:53:58.136456: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-05 14:53:58.136904: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-05 14:53:58.139311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-05 14:53:58.140510: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-05 14:53:58.145672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-05 14:53:58.145878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.146748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.147536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 14:53:58.147999: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-05 14:53:58.158009: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-08-05 14:53:58.158281: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558637af4d10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-05 14:53:58.158342: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-05 14:53:58.207301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.208313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558637b08a60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-05 14:53:58.208367: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2020-08-05 14:53:58.208657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.209465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-08-05 14:53:58.209534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:53:58.209670: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-05 14:53:58.209798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-05 14:53:58.209882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-05 14:53:58.209990: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-05 14:53:58.210115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-05 14:53:58.210180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-05 14:53:58.210338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.211290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.212074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 14:53:58.212147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:53:58.765400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-05 14:53:58.765463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-08-05 14:53:58.765635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-08-05 14:53:58.766139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.767126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.767958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10618 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2020-08-05 14:54:09.899095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.899586: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-08-05 14:54:09.899811: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-08-05 14:54:09.900545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.900959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-08-05 14:54:09.901027: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:54:09.901113: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-05 14:54:09.901170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-05 14:54:09.901247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-05 14:54:09.901349: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-05 14:54:09.901427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-05 14:54:09.901501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-05 14:54:09.901648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.902096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.902468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 14:54:09.902524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-05 14:54:09.902550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-08-05 14:54:09.902571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-08-05 14:54:09.902728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.903208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.903590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10618 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2020-08-05 14:54:10.067218: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize
2020-08-05 14:54:10.067284: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 2978 nodes (2644), 3263 edges (2922), time = 94.971ms.
2020-08-05 14:54:10.067309: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 1.906ms.
2020-08-05 14:54:13.144913: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-08-05 14:54:13.144989: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
loc(""Func/StatefulPartitionedCall/input/_0""): error: requires all operands and results to have compatible element types
Traceback (most recent call last):
  File ""/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 196, in toco_convert_protos
    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
  File ""/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/wrap_toco.py"", line 32, in wrapped_toco_convert
    return _pywrap_toco_api.TocoConvert(
Exception: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""scratch.py"", line 8, in <module>
    quantized_model = converter.convert()
  File ""/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 1076, in convert
    return super(TFLiteConverterV2, self).convert()
  File ""/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 899, in convert
    return super(TFLiteFrozenGraphConverterV2,
  File ""/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 629, in convert
    result = _toco_convert_impl(
  File ""/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 569, in toco_convert_impl
    data = toco_convert_protos(
  File ""/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 202, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>

```

**Also, please include a link to the saved model or GraphDef**


[model.zip](https://github.com/tensorflow/tensorflow/files/5029227/model.zip)



**Any other info / logs**
Model architecture is SSD-Mobilenet V2 with input size of 96x96, created by Object Detection API
Model exported according to [instructions](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#exporting-a-trained-model)
"
42064,Building Tensorflow Lite Locally :  Unrecoverable error while evaluating node ,"I am building on Linux Ubuntu 16.04, and following the Android quickstart guide:
https://www.tensorflow.org/lite/guide/android

I build the image with the given DockerFile:
https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/tools/dockerfiles/tflite-android.Dockerfile
docker build . -t tflite-builder -f tflite-android.Dockerfile


I run it with the following command:

docker run -it -w /tensorflow_src -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" \
    tensorflow/tensorflow:devel bash

Additional android tools in the container:
android update sdk --no-ui -a --filter tools,platform-tools,android-${ANDROID_API_LEVEL},build-tools-${ANDROID_BUILD_TOOLS_VERSION}


and finally the build command in bazel:
bazel build -c opt --fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a \
  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \
  //tensorflow/lite/java:tensorflow-lite


giving error:
FAILED: Build did NOT complete successfully (65 packages loaded, 1078 targets configured)
Internal error thrown during build. Printing stack trace: java.lang.RuntimeException: Unrecoverable error while evaluating node '@bazel_tools//src/tools/android/java/com/google/devtools/build/android/incrementaldeployment:incremental_stub_application BuildConfigurationValue.Key[291c4977886154b7d32d07c6d0dba1da3dce0bb2e69fd7a43e21c0fea58a22d0] false' (requested by nodes '@bazel_tools//tools/android:incremental_stub_application BuildConfigurationValue.Key[291c4977886154b7d32d07c6d0dba1da3dce0bb2e69fd7a43e21c0fea58a22d0] false')
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:399)
        at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
Caused by: java.lang.NullPointerException
        at com.google.devtools.build.lib.rules.android.BusyBoxActionBuilder.addAapt(BusyBoxActionBuilder.java:315)
        at com.google.devtools.build.lib.rules.android.AndroidResourcesProcessorBuilder.createAapt2ApkAction(AndroidResourcesProcessorBuilder.java:279)
        at com.google.devtools.build.lib.rules.android.AndroidResourcesProcessorBuilder.build(AndroidResourcesProcessorBuilder.java:208)
        at com.google.devtools.build.lib.rules.android.AndroidResourcesProcessorBuilder.buildWithoutLocalResources(AndroidResourcesProcessorBuilder.java:179)
        at com.google.devtools.build.lib.rules.android.ResourceApk.processFromTransitiveLibraryData(ResourceApk.java:328)
        at com.google.devtools.build.lib.rules.android.AndroidLibrary.create(AndroidLibrary.java:178)
        at com.google.devtools.build.lib.rules.android.AndroidLibrary.create(AndroidLibrary.java:42)
        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:484)
        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:190)
        at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:888)
        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:899)
        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:338)
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:438)
        ... 7 more
java.lang.RuntimeException: Unrecoverable error while evaluating node '@bazel_tools//src/tools/android/java/com/google/devtools/build/android/incrementaldeployment:incremental_stub_application BuildConfigurationValue.Key[291c4977886154b7d32d07c6d0dba1da3dce0bb2e69fd7a43e21c0fea58a22d0] false' (requested by nodes '@bazel_tools//tools/android:incremental_stub_application BuildConfigurationValue.Key[291c4977886154b7d32d07c6d0dba1da3dce0bb2e69fd7a43e21c0fea58a22d0] false')
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:399)
        at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
        at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
Caused by: java.lang.NullPointerException
        at com.google.devtools.build.lib.rules.android.BusyBoxActionBuilder.addAapt(BusyBoxActionBuilder.java:315)
        at com.google.devtools.build.lib.rules.android.AndroidResourcesProcessorBuilder.createAapt2ApkAction(AndroidResourcesProcessorBuilder.java:279)
        at com.google.devtools.build.lib.rules.android.AndroidResourcesProcessorBuilder.build(AndroidResourcesProcessorBuilder.java:208)
        at com.google.devtools.build.lib.rules.android.AndroidResourcesProcessorBuilder.buildWithoutLocalResources(AndroidResourcesProcessorBuilder.java:179)
        at com.google.devtools.build.lib.rules.android.ResourceApk.processFromTransitiveLibraryData(ResourceApk.java:328)
        at com.google.devtools.build.lib.rules.android.AndroidLibrary.create(AndroidLibrary.java:178)
        at com.google.devtools.build.lib.rules.android.AndroidLibrary.create(AndroidLibrary.java:42)
        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:484)
        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:190)
        at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:888)
        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:899)
        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:338)
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:438)
FAILED: Build did NOT complete successfully (65 packages loaded, 1078 targets configured)

"
42062,multi worker in nccl mode with something wrong,"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):N/A
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 2.3.0
Python version: 3.7.4
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: 10.1.243/N
GPU model and memory: V100 32GB

I just run a sample code with keras training api  in NCCL multi worker mode with 2*8V100gpus.
Sometimes I the training process with failed with this error. But sometimes not, and the training process is same as before.

Here is the error information:

>`2020-08-05 20:21:04.420413: E tensorflow/core/common_runtime/ring_alg.cc:274] Aborting RingReduce with Invalid argument: [_Derived_]indices[4] = 14 is not in [0, 14)
	 [[{{node GatherV2}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional_3]]
	 [[GroupCrossDeviceControlEdges_3/div_no_nan/_619]]
Additional GRPC error information from remote target /job:worker/replica:0/task:0:
:{""created"":""@1596630064.420329728"",""description"":""Error received from peer ipv4:10.128.98.77:9000"",""file"":""external/com_github_grpc_grpc/src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""[_Derived_]indices[4] = 14 is not in [0, 14)\n\t [[{{node GatherV2}}]]\n\t [[MultiDeviceIteratorGetNextFromShard]]\n\t [[RemoteCall]]\n\t [[IteratorGetNextAsOptional_3]]\n\t [[GroupCrossDeviceControlEdges_3/div_no_nan/_619]]"",""grpc_status"":3}
2020-08-05 20:21:04.420665: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at collective_ops.cc:257 : Invalid argument: [_Derived_]indices[4] = 14 is not in [0, 14)
	 [[{{node GatherV2}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional_3]]
	 [[GroupCrossDeviceControlEdges_3/div_no_nan/_619]]
Additional GRPC error information from remote target /job:worker/replica:0/task:0:
:{""created"":""@1596630064.420329728"",""description"":""Error received from peer ipv4:10.128.98.77:9000"",""file"":""external/com_github_grpc_grpc/src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""[_Derived_]indices[4] = 14 is not in [0, 14)\n\t [[{{node GatherV2}}]]\n\t [[MultiDeviceIteratorGetNextFromShard]]\n\t [[RemoteCall]]\n\t [[IteratorGetNextAsOptional_3]]\n\t [[GroupCrossDeviceControlEdges_3/div_no_nan/_619]]"",""grpc_status"":3}
Traceback (most recent call last):
  File ""/opt/tiger/mta/scripts/keras/../../scripts/keras/train_model.py"", line 115, in <module>
    main(args)
  File ""/opt/tiger/mta/scripts/keras/../../scripts/keras/train_model.py"", line 110, in main
    trainer.fit(task_index,num_devices)
  File ""/opt/tiger/mta/mta/keras/trainer.py"", line 170, in fit
    steps_per_epoch=self._config.train.steps_per_epoch,verbose=self._config.train.verbose_mode,callbacks=[CusCallBack(self._config,task_index,self._lr_scheduler,num_devices),self._ckpt_callback])
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 117, in _method_wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_coordinator.py"", line 860, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 115, in <lambda>
    lambda _: method(self, *args, **kwargs),
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1098, in fit
    tmp_logs = train_function(iterator)
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 807, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 550, in call
    ctx=ctx)
  File ""/home/tiger/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError:  [_Derived_]indices[4] = 14 is not in [0, 14)
	 [[{{node GatherV2}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional_3]]
	 [[GroupCrossDeviceControlEdges_3/div_no_nan/_619]]
Additional GRPC error information from remote target /job:worker/replica:0/task:0:
:{""created"":""@1596630064.420329728"",""description"":""Error received from peer ipv4:10.128.98.77:9000"",""file"":""external/com_github_grpc_grpc/src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""[_Derived_]indices[4] = 14 is not in [0, 14)\n\t [[{{node GatherV2}}]]\n\t [[MultiDeviceIteratorGetNextFromShard]]\n\t [[RemoteCall]]\n\t [[IteratorGetNextAsOptional_3]]\n\t [[GroupCrossDeviceControlEdges_3/div_no_nan/_619]]"",""grpc_status"":3}
	 [[allreduce/CollectiveReduce]]
	 [[replica_4/Size_3/_270]] [Op:__inference_train_function_116225]

Function call stack:`
I will be grateful if anyone who help me save the problem."
42061,Fail to export function containing tf.lookup.StaticHashTable,"**System information**
- Ubuntu 18.04
- TensorFlow installed from (source or binary): binary (`pip install tensorflow)
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.6.9

**Describe the current behavior**

Trying to save a SavedModel with `tf.saved_model.save`, `tf.Module` fails if it includes `tf.lookup.StaticHashTable`.

**Describe the expected behavior**

No failure.

**Standalone code to reproduce the issue**

The following code 

```
import tensorflow as tf
class M(tf.Module):
    @tf.function
    def __call__(self, a):       
        keys_tensor = tf.constant([1, 2])
        vals_tensor = tf.constant([3, 4])
        input_tensor = tf.constant([1, 5])
        tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), -1)

        return a

m = M()
cf = m.__call__.get_concrete_function(a=tf.TensorSpec([None], tf.float32))

tf.saved_model.save(m, ""~/output_dir"", signatures={""serving_default"": cf})
```

yields the error:

```
AssertionError: Tried to export a function which references untracked object Tensor(""178:0"", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.
```

Note that the following modification (assigning the return value of `tf.lookup.StaticHashTable` to a class attribute) fails with the same Exception

```
import tensorflow as tf
class M(tf.Module):
    def __init__(self, **kwargs):
        super(M, self).__init__()
        self.table = None
        
    @tf.function
    def __call__(self, a):       
        keys_tensor = tf.constant([1, 2])
        vals_tensor = tf.constant([3, 4])
        input_tensor = tf.constant([1, 5])
        self.table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), -1)
        
        return a
    
m = M()
concrete_fn = m.__call__.get_concrete_function(a=tf.TensorSpec([None], tf.float32))

tf.saved_model.save(m, ""~/some_output_dir"", signatures={""serving_default"": concrete_fn})
```


**Other info / logs** Include any logs or source code that would be helpful to

Full trace:

```
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-19-401fea85b3de> in <module>
     17 concrete_fn = m.__call__.get_concrete_function(a=tf.TensorSpec([None], tf.float32))
     18 
---> 19 tf.saved_model.save(m, ""~/some_output_dir"", signatures={""serving_default"": concrete_fn})

~/py3env/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    974 
    975   _, exported_graph, object_saver, asset_info = _build_meta_graph(
--> 976       obj, export_dir, signatures, options, meta_graph_def)
    977   saved_model.saved_model_schema_version = constants.SAVED_MODEL_SCHEMA_VERSION
    978 

~/py3env/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def)
   1064   asset_info, exported_graph = _fill_meta_graph_def(meta_graph_def,
   1065                                                     saveable_view, signatures,
-> 1066                                                     options.namespace_whitelist)
   1067   if options.function_aliases:
   1068     function_aliases = meta_graph_def.meta_info_def.function_aliases

~/py3env/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py in _fill_meta_graph_def(meta_graph_def, saveable_view, signature_functions, namespace_whitelist)
    651 
    652   with exported_graph.as_default():
--> 653     signatures = _generate_signatures(signature_functions, resource_map)
    654     for concrete_function in saveable_view.concrete_functions:
    655       concrete_function.add_to_graph()

~/py3env/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py in _generate_signatures(signature_functions, resource_map)
    517                                                   signature_key, function.name))
    518     outputs = _call_function_with_mapped_captures(
--> 519         function, mapped_inputs, resource_map)
    520     signatures[signature_key] = signature_def_utils.build_signature_def(
    521         _tensor_dict_to_tensorinfo(exterior_argument_placeholders),

~/py3env/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py in _call_function_with_mapped_captures(function, args, resource_map)
    469   """"""Calls `function` in the exported graph, using mapped resource captures.""""""
    470   export_captures = _map_captures_to_created_tensors(function.graph.captures,
--> 471                                                      resource_map)
    472   # Calls the function quite directly, since we have new captured resource
    473   # tensors we need to feed in which weren't part of the original function

~/py3env/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py in _map_captures_to_created_tensors(original_captures, resource_map)
    392            ""be tracked by assigning them to an attribute of a tracked object ""
    393            ""or assigned to an attribute of the main object directly.""
--> 394           ).format(interior))
    395     export_captures.append(mapped_resource)
    396   return export_captures

AssertionError: Tried to export a function which references untracked object Tensor(""836:0"", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.
```
"
42060,Fail to load model from ModelCheckpoint in java.,"Fail to load model in java.

**Python**
checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, 
                             save_best_only=True, mode='min', save_weights_only = True)
**Java**
SavedModelBundle model = SavedModelBundle.load(""C:\\workspace\\tools\\cross-360p-high2Tp1Cl100VpConc.1.09.hdf5"", ""serve"" );	

**System information**
libtensorflow-2.3.0.jar


**Other info / logs**
2020-08-05 21:17:29.484400: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: C:\workspace\tools\cross-360p-high2Tp1Cl100VpConc.1.09.hdf5
2020-08-05 21:17:29.484980: I tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: fail. Took 554 microseconds.
Exception in thread ""main"" org.tensorflow.TensorFlowException: Could not find SavedModel .pb or .pbtxt at supplied export directory path: C:\workspace\tools\cross-360p-high2Tp1Cl100VpConc.1.09.hdf5
	at org.tensorflow.SavedModelBundle.load(Native Method)
	at org.tensorflow.SavedModelBundle.access$000(SavedModelBundle.java:27)
	at org.tensorflow.SavedModelBundle$Loader.load(SavedModelBundle.java:32)
	at org.tensorflow.SavedModelBundle.load(SavedModelBundle.java:95)
	at com.TensorFlowEngine.main(TensorFlowEngine.java:9)

"
42058,Import Tensorflow giving error,"Hi,
I am trying to deploy a simple CNN on FLASK. on operating system Windows 10, 
Python 3.8.3
tensor flow version is 2.3.0  (installed using pip install)
keras version 2.4.3 (installed using pip install)

I uninstalled and reinstalled Anaconda also. 
Upgraded  Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 from https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads

My system has CPU (no GPU), 4GB RAM, i5 processor


For the statement ""import tensorflow as tf"" i am getting an error.

D:\>python -c ""import tensorflow as tf""
Traceback (most recent call last):
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

*******************************************************************************************************

### If I use TensorFlow 2.2.0, I get the following error

D:\>python -c ""import tensorflow as tf""
Traceback (most recent call last):
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\amala\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\amala\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\amala\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\amala\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\amala\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

"
42057,TensorFlow Lite causes segementation faults in C++ when creating threads if fully statically linked,"**System information**
- Linux Ubuntu 18.04
- TensorFlow Binary (via `pip`)
- Tested on 2.1.0, 2.2.0, 2.3.0 & all recent master branches of `tensorflow/tensorflow:devel` up to my last comment
  - I have a local CI script tracking this issue
- Tested on `x86_64` as well as ARM builds

**Problem**
- Segmentaion fault on `invoke()` when running any model that spawns threads 
  - Only occurs if TensorFlow Lite library has been statically linked
  - Not an issue in older versions (pre-2.0.0)

**Problem Reproduction**
- Standard Tensorflow Lite library build
  - Spin up `tensorflow/tensorflow:devel` docker container
  - `cd tensorflow_src`
  - `./tensorflow/lite/tools/make/download_dependencies.sh`
  - `./tensorflow/lite/tools/make/build_lib.sh`
  - Grab TensorFlow and Flatbuffer headers, as well as Tensorflow `.a` file
- Compile [tflite c++ minimal example](https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_c)
  - GCC 7.5
  - Static
    - `g++ minimal.cc -I../tensorflow_headers -I../flatbuffers_include -Wl,--whole-archive -lpthread -Wl,--no-whole-archive -pthread -g -static -L../tensorflow_lib -ltensorflow-lite -ldl -o tflite_min_static`
  - Dynamic
    - `g++ minimal.cc -I../tensorflow_headers -I../flatbuffers_include -Wl,--whole-archive -lpthread -Wl,--no-whole-archive -pthread -g -L../tensorflow_lib -ltensorflow-lite -ldl -o tflite_min_dynamic`
- Make some test models
  - Convolutional model creates extra threads, non-convolutional model does not
```python
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Input, Dense
from tensorflow.keras.models import Model

### With a convolution (creates threads on invoke())
inputs = Input(shape=[10, 5, 1])
x = inputs
x = Conv2D(32, (3, 3))(x)
x = Flatten()(x)
x = Dense(1)(x)

model = Model(inputs, x)
model.compile()

# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# Save the TF Lite model.
with tf.io.gfile.GFile(""min_model_with_conv.tflite"", ""wb"") as f:
    f.write(tflite_model)

### Without convolution (no extra threading)
inputs = Input(shape=[10, 5, 1])
x = inputs
# x = Conv2D(32, (3, 3))(x)
x = Flatten()(x)
x = Dense(1)(x)

model = Model(inputs, x)
model.compile()

# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# Save the TF Lite model.
with tf.io.gfile.GFile(""min_model_no_conv.tflite"", ""wb"") as f:
    f.write(tflite_model)

```
- Run minimal examples
  - `tflite_min_dynamic min_model_no_conv.tflite`: pass
  - `tflite_min_dynamic min_model_with_conv.tflite`: pass
  - `tflite_min_static min_model_no_conv.tflite`: pass
  - `tflite_min_static min_model_with_conv.tflite`: segmentation fault
- From `gdb --args tflite_min_static min_model_with_conv.tflite`
```
Node   2 Operator Builtin Code   9 FULLY_CONNECTED
  Inputs: 6 2 -1
  Outputs: 7
[New Thread 0x7fffff7b0700 (LWP 2331)]
[New Thread 0x7ffffefa0700 (LWP 2332)]

Thread 2 ""tflite_min_stat"" received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0x7fffff7b0700 (LWP 2331)]
0x0000000000000000 in ?? ()
```

**Bazel Reproduction**
Using the minimal example above, the problem can be reproduced under Bazel by adding the following build rule:
```
cc_binary(
    name = ""tflite_minimal_bazel"",
    srcs = [""minimal.cc""],
    deps = [
        "":framework"",
        ""//tensorflow/lite/kernels:builtin_ops_all_linked"", # For kernels/register.h
    ],
    features = [""fully_static_link""], # For full static link of standard library
    linkstatic=True,
)
```

**Files for Reproduction**
See [here](https://www.dropbox.com/sh/0ztotvfm5l92aaz/AAAI4-TYwyuddKnb4S2uaKBja?dl=0). 


"
42056,android use XNNPACK happen error," - android 7
 - ssd_mobilenet_v2

```
    implementation 'org.tensorflow:tensorflow-lite:2.3.0'
    implementation 'org.tensorflow:tensorflow-lite-gpu:2.3.0'
    implementation 'org.tensorflow:tensorflow-lite-support:0.1.0-rc1'
```


```java
Interpreter.Options options = new Interpreter.Options();
options.setUseXNNPACK(true);
options.setNumThreads(NUM_THREADS);
NnApiDelegate delegate = new NnApiDelegate();
options.addDelegate(delegate);
tflite = new Interpreter(file, options);
```

error log:
```
Failed to apply XNNPACK delegate: ModifyGraphWithDelegate is disallowed when graph is immutable.
```"
42055,"F .\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: a PTX JIT compilation failed","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.2.0
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda v10.0/cudnn-10.0-windows10-x64-v7.4.2.24
- GPU model and memory:



I installed tensorflow 2.2.0 in May 2020 and ran the tutorial program successfully. However, I come across this issue using the same tutorial program. I believe that I didn't change python interpreter, cuda, cudnn, and tensorflow.

```python
import tensorflow as tf
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
# print('\n\n')
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer='adam',
              loss=loss_fn,
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test,  y_test, verbose=2)
```
Out:
```
2020-08-05 13:54:52.036310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-08-05 13:55:07.270688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-08-05 13:55:07.734233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0
coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s
2020-08-05 13:55:07.797735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-08-05 13:55:07.990395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-08-05 13:55:08.045563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-08-05 13:55:08.082869: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-08-05 13:55:08.199070: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-08-05 13:55:08.241274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-08-05 13:55:08.470320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-08-05 13:55:08.554461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-08-05 13:55:08.566140: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow 
binary was not compiled to use: AVX2
2020-08-05 13:55:08.656817: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x172aaf17030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-05 13:55:08.694556: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-05 13:55:08.755347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0
coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s
2020-08-05 13:55:08.951294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-08-05 13:55:09.001277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-08-05 13:55:09.056517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-08-05 13:55:09.129672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-08-05 13:55:09.220914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-08-05 13:55:09.402285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-08-05 13:55:09.456762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-08-05 13:55:09.581936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-08-05 13:55:41.323465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-05 13:55:41.477075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-08-05 13:55:41.617702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-08-05 13:55:41.802239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1465 MB memory) -> physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-08-05 13:55:42.283031: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x172ccaf7de0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-05 13:55:42.752069: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce 940MX, Compute Capability 5.0
2020-08-05 13:55:43.501455: F .\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: a PTX JIT compilation failed
```


Can someone tell me what happened?
"
42054,How to check whether MKL is supported or not  with the installed tensorflow,"**System information**
- OS Platform and Distribution : Windows 10
- TensorFlow installed from : binary
- TensorFlow version: 2.1.0
- Python version: 3.7.0
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


I installed tensorflow with mkl support following [this guide](https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html). Now I want to check whether mkl is properly installed or not. I tried the following as suggested by Intel, but encountered no matching attribute error.
>>>import tensorflow
>>> print(tensorflow.pywrap_tensorflow.IsMklEnabled())
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'pywrap_tensorflow'

Is there any other way to do the same?

I installed tensorflow with the following cmd:
` pip install tensorflow-mkl`"
42053,All validation loss reported as 0.0000e+00 in keras / TF,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
This is running on Google Colab. I am running macOS 10.15.6. Colab is opened in Chrome 84.0.4147.105 .
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
Not installed by me as it is running in Colab. 
- TensorFlow version (use command below):
v2.3.0-0-gb36436b087 2.3.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: N/A although this also happens when using Tesla P100 on Colab

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

During training, val_loss is reported as 0.0000e+00.
When printing model.history.history['val_loss'], an array of [0.0,..., 0.0] is printed.
However, when evaluating the model on examples val_x, val_y, a non-zero loss is reported.
This happens for at least 4 different notebooks, including notebooks that worked properly earlier today.

**Describe the expected behavior**

During training, a non-zero validation loss should be reported in most cases.
These non-zero losses should be reported in the model history.
When evaluating the model against the validation examples val_x, val_y, a loss similar to that reported in the model history should be reported.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1YP_dR7O9KsqSeLyrgFTzOSna0EggL9Gs?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

"
42052,Tensorflow-gpu status: Internal: no kernel image is available for execution on the device,"**I run my code on tensorflow 2.1.0 Anaconda with CUDA Toolkit 10.1 CUDNN 7.6.0 (Windows 10) and it returns a issue**
` F .\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device`
**My GPU : GT940MX Compute Capability 5.0**

**I already run the nvcc -V and it returns :** 
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019
Cuda compilation tools, release 10.1, V10.1.105

**This is the full result :**
```
2020-08-05 10:05:48.368012: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-05 10:06:00.488544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-08-05 10:06:48.153611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0
coreClock: 0.8605GHz coreCount: 4 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s
2020-08-05 10:06:48.164731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-05 10:06:48.245826: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-05 10:06:48.296245: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-05 10:06:48.338860: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-05 10:06:48.439393: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-05 10:06:48.489830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-05 10:06:48.941872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-05 10:06:48.946651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 10:06:48.951881: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-05 10:06:48.979077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23d29b660d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-05 10:06:48.985680: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-05 10:06:48.990616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0
coreClock: 0.8605GHz coreCount: 4 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s
2020-08-05 10:06:49.003356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-05 10:06:49.009869: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-05 10:06:49.014858: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-05 10:06:49.020699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-05 10:06:49.028876: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-05 10:06:49.033607: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-05 10:06:49.039192: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-05 10:06:49.045288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 10:06:49.218497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-05 10:06:49.223536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-08-05 10:06:49.226857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-08-05 10:06:49.230413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1460 MB memory) -> physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-08-05 10:06:49.244107: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23d301b8fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-05 10:06:49.250377: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce 940MX, Compute Capability 5.0
2020-08-05 10:06:49.446601: F .\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device
```
**What are the issues and how to fix it?**"
42051,keras meet a problem with sync bn in multi worker,"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):N/A
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 2.3.0
Python version: 3.7.4
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

I just replace the keras bn layer in office resnet.py with tf.keras.layers.experimental.SyncBatchNormalization.
I find in nccl multi worker mode, the model.fit training process will be stuck without error information, and will not begin the training.
Same code work in ring mode well.
I test the code with 2/~4 hosts, each has 2/~4 gpus. didn't work for all the situations.


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42049,Binary won't build for hello world.,"**System information**

-Catalina 
-System default Python 3.8.5
-Spark edge 1
-Make version 4.3

**Describe the problem**

While trying to build for the hello world binary, I get the following error. 

```
make: tensorflow/lite/experimental/micro/tools/make/Makefile: No such file or directory

make: *** No rule to make target 'tensorflow/lite/experimental/micro/tools/make/Makefile'.
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

-My make version was lower than 3.2, so I changed my make version to 4.3.

-make -f tensorflow/lite/micro/tools/make/Makefile \
  TARGET=sparkfun_edge hello_world_bin

**Any other info / logs**

-Please help. I need to get this working. I really want to learn this. 

@dansitu"
42047,TF with CUDA 11 and cuDNN 8,"Enable TF-nightly with CUDA 11 and cuDNN 8 for Ubuntu and Windows.
"
42046,Keras custom model shape inference does not work with model.fit() for hub modules,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9.11
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Keras appears to do some things under the hood when calling `model.fit(...)` that don't work with TensorFlow Hub modules. Minimal script included below, which produces the following error:

```
ValueError: Shape must be rank 1 but is rank 2 for '{{node text_preprocessor/tokenize/StringSplit/StringSplit}} = StringSplit[skip_empty=true](text_preprocessor/StaticRegexReplace_1, text_preprocessor/tokenize/StringSplit/Const)' with input shapes: [?,1], [].
```

If I print out the `inputs` argument to `model.call` during `model.fit`, I see that it is actually a `Tensor(""ExpandDims:0"", shape=(None, 1), dtype=string)`, so if I start `model.call` with `inputs = tf.squeeze(inputs)`, everything works, but this is a bit of a hack.

I'm actually not sure if the error is specifically related to TensorFlow Hub modules, but it is at least sufficient to reproduce the issue.

**Describe the expected behavior**
`model.fit(x, y)` should work the same as as manually calling the forward pass with `model(x, y)`

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
import tensorflow_hub as hub

class MyModel(tf.keras.Model):    
    def __init__(self):
        super().__init__()
        self.embed = hub.load(""https://tfhub.dev/google/universal-sentence-encoder/4"")
        self.dense = tf.keras.layers.Dense(1)
        
    def call(self, inputs, training=False):
        x = self.embed(inputs)
        x = self.dense(x)
        return x
    
model = MyModel()
x = ['a sentence', 'b sentence']
y = [0, 1]

model(x, y)  # works fine

model.compile(loss='mse', optimizer='sgd')
model.fit(x, y)  # errors
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
42045,"TF website tutorial ""Save and load"" fails on Google Colab for entire models","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab on cloud (run in Safari browser on Mac OSX 10.14.6)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): NA
- TensorFlow version (use command below): TF 2.3.0, Git version v2.3.0-0-gb36436b087
- Python version: Appears to be 3.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: ??
- GPU model and memory: ??

**Describe the current behavior**
The TensorFlow tutorial page https://www.tensorflow.org/tutorials/keras/save_and_load fails even when run in Google Colab, your cloud environment. Where it fails exactly is towards the bottom, in the section of the tutorial describing how to save and load entire models with model.save() and load_model(). I find that the restored models (in either SavedModel or HDF5 format) fail to reproduce the original model accuracies, given exactly the provided code. Instead I get around 8-9% accuracies.

I get the same problem running the downloaded Jupyter notebook on my own laptop (Mac OSX 10.14.6, TF 2.4.0-dev20200727, Git v1.12.1-37595-g9f2e1a7246, TF from pip3, Python 3.8.5).

**Describe the expected behavior**
The expected behavior is for the saved and reloaded models to have exactly the same accuracies on the same test data.

**Standalone code to reproduce the issue**
I've attached a small notebook that replicates the problem on my laptop. 
[minimal.ipynb.txt](https://github.com/tensorflow/tensorflow/files/5024470/minimal.ipynb.txt)

This was modeled after a similar tutorial (https://machinelearningmastery.com/save-load-keras-deep-learning-models/ under ""Save Model Weights and Architecture Together""). That tutorial's code runs fine with the given example data on my laptop (the saved and reloaded model has identical accuracy to the original), yet the very similar code in the attached notebook using the MNIST data and slightly different model does not. I'm not sure what this means. Honestly I'm pretty new to Keras. I'm not sure if this is a bug in the Keras code, or just an error in the tutorial. But again, it doesn't work with the provided tutorial in the Google Colab environment, suggesting it's not an error on my part.

FWIW, I do notice that the reloaded SavedModel model and the reloaded HDF5 model, when saved from the same original model (as in my example notebook), both give the identical bad accuracy.

**Other info / logs** 
Not sure if relevant, but these warning appear the first time model.save() is used (from Google Colab):

_WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: saved_model/my_model/assets_

On my laptop, I get the same warnings (with a different path to tracking.py: /Users/lilley/Library/Python/3.8/lib/python/site-packages/tensorflow/python/training/tracking/tracking.py).

The example run given on the tutorial page suggests that this functionality was originally working in TF 2.2.0.
"
42043,"""logs"" Callback bugs with TF 2.3 on colab with TPU","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): 2.3
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:TPU 
- GPU model and memory:

I got some weird issue, it seems that when using a custom callback for computing a metric, and then save it in the logs, 
the ModelCheckpoint function does not see the metrics saved in logs, so it does not save the model at the end of an epoch. I have seen this issue today. It worked well few days ago, so it seems to be related to TF 2.3. I also see some issue about the memory, I have to lower the batch size to make the training work.


`WARNING:tensorflow:Can save best model only with roc_val available, skipping.`
`WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0288s vs `on_train_batch_end` time: 0.9656s). Check your callbacks.`


```
class RocCallback(Callback):
    def __init__(self , dataset_val):
        self.x = dataset_val
        self.y =  np.concatenate([np.array(x[1]) for x in list(dataset_val)]).reshape(-1)
    def on_train_begin(self, logs={}):
        return

    def on_train_end(self, logs={}):
        return

    def on_epoch_begin(self, epoch, logs={}):
        return

    def on_epoch_end(self, epoch, logs={}):
        pred = model.predict(self.x)
        roc_val = roc_auc_score(self.y, pred)
        logs[""roc_val""] = roc_val
        print('\n - %s average: %s' % ('roc_val', str(round(roc_val,4))),end=100*' '+'\n')
        return

    def on_batch_begin(self, batch, logs={}):
        return

    def on_batch_end(self, batch, logs={}):
        return
```

```
tf.keras.callbacks.ModelCheckpoint(""model.h5"", monitor='roc_val', verbose=0, save_best_only=True,
        save_weights_only=True, mode='max', save_freq='epoch')
```

Is there a way to choose the version of TF (2.2) on colab  ?

"
42041,comp:mkl,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Microsoft Windows 10 Pro
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: Tensorflow 2.4
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 5.3
- GPU model and memory: NVIDIA GTX 1050 v451.67, CUDADNN 11
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s


**Describe the problem**
Unable to build tensorflow 2.3 on windows. I use Anaconda. The objective was to benefit from the AVX2 instructionset available on my laptop for enhanced performance.

""This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.""

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I followed the steps here:
https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html#Anaconda_main_win
 1. Already installed:  numpy, keras-applications, keras-preprocessing, pip, six, wheel, mock

2. git clone https://github.com/tensorflow/tensorflow
git checkout r2.1

windows cmd: set PATH=%PATH%;output_dir\external\mkl_windows\lib

3. tried either of
bazel --output_base=output_dir build --config=mkl --copt=-mavx2 --config=cuda --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow/tools/pip_package:build_pip_package
and
bazel --output_base=output_dir build --config=mkl --copt=-mavx2 //tensorflow/tools/pip_package:build_pip_package


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


(base) C:\Users\agarw\tensorflow>bazel --output_base=output_dir build --config=mkl --config=opt --copt=-mavx2 --config=cuda --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow/tools/pip_package:build_pip_package
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/agarw/anaconda3/python.exe
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Found applicable config definition build:v2 in file c:\users\agarw\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:mkl in file c:\users\agarw\tensorflow\.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_mkl_dnn_v1_only=true -c opt
ERROR: Config value opt is not defined in any .rc file

(base) C:\Users\agarw\tensorflow>bazel --output_base=output_dir build --config=mkl --copt=-mavx2 --config=cuda --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow/tools/pip_package:build_pip_package
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/agarw/anaconda3/python.exe
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Found applicable config definition build:v2 in file c:\users\agarw\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:mkl in file c:\users\agarw\tensorflow\.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_mkl_dnn_v1_only=true -c opt
INFO: Found applicable config definition build:cuda in file c:\users\agarw\tensorflow\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file c:\users\agarw\tensorflow\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:windows in file c:\users\agarw\tensorflow\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file c:\users\agarw\tensorflow\.bazelrc: --define framework_shared_object=false
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at C:/users/agarw/tensorflow/output_dir/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
 - C:/users/agarw/tensorflow/output_dir/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - C:/users/agarw/tensorflow/WORKSPACE:37:1
ERROR: infinite symlink expansion detected
[start of symlink chain]
C:/users/agarw/tensorflow/output_dir/external/org_tensorflow
C:/users/agarw/tensorflow
[end of symlink chain]
INFO: Call stack for the definition of repository 'rules_cc' which is a tf_http_archive (rule definition at C:/users/agarw/tensorflow/third_party/repo.bzl:134:19):
 - C:/users/agarw/tensorflow/tensorflow/workspace.bzl:1013:5
 - C:/users/agarw/tensorflow/WORKSPACE:19:1
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': no such package '@org_tensorflow//third_party/gpus': Could not access C:/users/agarw/tensorflow/output_dir/external/org_tensorflow: Infinite symlink expansion
WARNING: Target pattern parsing failed.
ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': no such package '@org_tensorflow//third_party/gpus': Could not access C:/users/agarw/tensorflow/output_dir/external/org_tensorflow: Infinite symlink expansion
INFO: Elapsed time: 55.821s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded)
    Fetching @local_config_cuda; Restarting.

(base) C:\Users\agarw\tensorflow>bazel --output_base=output_dir build --config=mkl --config=cuda --copt=-mavx2 //tensorflow/tools/pip_package:build_pip_package
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/agarw/anaconda3/python.exe
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Found applicable config definition build:v2 in file c:\users\agarw\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:mkl in file c:\users\agarw\tensorflow\.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_mkl_dnn_v1_only=true -c opt
INFO: Found applicable config definition build:cuda in file c:\users\agarw\tensorflow\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file c:\users\agarw\tensorflow\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:windows in file c:\users\agarw\tensorflow\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file c:\users\agarw\tensorflow\.bazelrc: --define framework_shared_object=false
INFO: Call stack for the definition of repository 'rules_cc' which is a tf_http_archive (rule definition at C:/users/agarw/tensorflow/third_party/repo.bzl:134:19):
 - C:/users/agarw/tensorflow/tensorflow/workspace.bzl:1013:5
 - C:/users/agarw/tensorflow/WORKSPACE:19:1
ERROR: infinite symlink expansion detected
[start of symlink chain]
C:/users/agarw/tensorflow/output_dir/external/org_tensorflow
C:/users/agarw/tensorflow
[end of symlink chain]
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at C:/users/agarw/tensorflow/output_dir/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
 - C:/users/agarw/tensorflow/output_dir/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - C:/users/agarw/tensorflow/WORKSPACE:37:1
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': no such package '@org_tensorflow//third_party/gpus': Could not access C:/users/agarw/tensorflow/output_dir/external/org_tensorflow: Infinite symlink expansion
WARNING: Target pattern parsing failed.
ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': no such package '@org_tensorflow//third_party/gpus': Could not access C:/users/agarw/tensorflow/output_dir/external/org_tensorflow: Infinite symlink expansion
INFO: Elapsed time: 0.435s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded)
    Fetching @local_config_cuda; Restarting.

(base) C:\Users\agarw\tensorflow>bazel --output_base=output_dir build --config=mkl --config=opt --copt=-mavx2 //tensorflow/tools/pip_package:build_pip_package
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/agarw/anaconda3/python.exe
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Found applicable config definition build:v2 in file c:\users\agarw\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:mkl in file c:\users\agarw\tensorflow\.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_mkl_dnn_v1_only=true -c opt
ERROR: Config value opt is not defined in any .rc file

(base) C:\Users\agarw\tensorflow>bazel --output_base=output_dir build --config=mkl --copt=-mavx2 //tensorflow/tools/pip_package:build_pip_package
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/agarw/anaconda3/python.exe
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Found applicable config definition build:v2 in file c:\users\agarw\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:mkl in file c:\users\agarw\tensorflow\.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_mkl_dnn_v1_only=true -c opt
INFO: Found applicable config definition build:windows in file c:\users\agarw\tensorflow\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file c:\users\agarw\tensorflow\.bazelrc: --define framework_shared_object=false
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at C:/users/agarw/tensorflow/output_dir/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
 - C:/users/agarw/tensorflow/output_dir/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - C:/users/agarw/tensorflow/WORKSPACE:37:1
INFO: Call stack for the definition of repository 'com_google_protobuf' which is a tf_http_archive (rule definition at C:/users/agarw/tensorflow/third_party/repo.bzl:134:19):
 - C:/users/agarw/tensorflow/tensorflow/workspace.bzl:601:5
 - C:/users/agarw/tensorflow/WORKSPACE:19:1
ERROR: infinite symlink expansion detected
[start of symlink chain]
C:/users/agarw/tensorflow/output_dir/external/org_tensorflow
C:/users/agarw/tensorflow
[end of symlink chain]
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: invalid registered execution platform '@local_execution_config_platform//:platform': no such package '@local_execution_config_platform//': no such package '@org_tensorflow//third_party/remote_config': Could not access C:/users/agarw/tensorflow/output_dir/external/org_tensorflow: Infinite symlink expansion
INFO: Elapsed time: 5.345s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (6 packages loaded, 5 targets configured)
    currently loading: tensorflow
    Fetching @local_execution_config_platform; Restarting. 4s

(base) C:\Users\agarw\tensorflow>bazel --output_base=output_dir build --config=mkl --config=opt //tensorflow/tools/pip_package:build_pip_package
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/agarw/anaconda3/python.exe
INFO: Reading rc options for 'build' from c:\users\agarw\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Found applicable config definition build:v2 in file c:\users\agarw\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:mkl in file c:\users\agarw\tensorflow\.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_mkl_dnn_v1_only=true -c opt
ERROR: Config value opt is not defined in any .rc file

(base) C:\Users\agarw\tensorflow>

"
42039,tf.constant causes CUDA_ERROR_TOO_MANY_PEERS error with more than 10 GPUs,"### System information

-   **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device**: No
-   **TensorFlow installed from (source or binary)**: Binary
-   **TensorFlow version (use command below)**: 2.2.0
-   **Python version**: 3.8.2
-   **Bazel version (if compiling from source)**: N/A
-   **GCC/Compiler version (if compiling from source)**:  N/A
-   **CUDA/cuDNN version**: 10.2.89
-   **GPU model and memory**: Quadro 8000/48GB
-   **NCCL version:** 2.5.7

**Describe the current behavior**

When creating a `tf.constant` on a 10x Quadro RTX 8000 server, a `CUDA_ERROR_TOO_MANY_PEERS` error is thrown even after disabling NCCL P2P.

**Describe the expected behavior**

Creating a `tf.constant` should not raise a `CUDA_ERROR_TOO_MANY_PEERS` error when the `NCCL_P2P_DISABLE` environment variable is set.

**Standalone code to reproduce the issue**

```
$ NCCL_P2P_DISABLE=1 python3 -c 'import tensorflow as tf; a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])'
```

**Other info / logs**

```
$ export NCCL_DEBUG=INFO NCCL_P2P_DISABLE=1
$ python3
Python 3.8.2 (default, Apr 27 2020, 15:53:34)
[GCC 9.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
2020-07-24 06:07:34.108942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2020-07-24 06:07:34.110425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
>>> print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
2020-07-24 06:07:44.421555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-24 06:07:44.504448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:1a:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.508520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:1b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.512569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:
pciBusID: 0000:1c:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.516601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:
pciBusID: 0000:1d:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.520621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 4 with properties:
pciBusID: 0000:1e:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.524650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 5 with properties:
pciBusID: 0000:3d:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.528674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 6 with properties:
pciBusID: 0000:3e:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.532699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 7 with properties:
pciBusID: 0000:3f:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.536720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 8 with properties:
pciBusID: 0000:40:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.540750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 9 with properties:
pciBusID: 0000:41:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s
2020-07-24 06:07:44.540781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2020-07-24 06:07:44.543092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-24 06:07:44.545372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-24 06:07:44.545738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-24 06:07:44.548233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-24 06:07:44.549673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-24 06:07:44.554615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-24 06:07:44.611146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
Num GPUs Available: 10
```

```
>>>  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
2020-07-24 06:07:54.494617: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-07-24 06:07:54.545902: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2100000000 Hz
2020-07-24 06:07:54.552981: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30a6e40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-24 06:07:54.553039: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version
2020-07-24 06:07:59.775126: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2020-07-24 06:07:59.778106: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:2: failed initializing StreamExecutor for CUDA device ordinal 2: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
2020-07-24 06:07:59.778824: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x306aa30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-24 06:07:59.778851: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2020-07-24 06:07:59.778859: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2020-07-24 06:07:59.778865: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (2): Quadro RTX 8000, Compute Capability 7.5
2020-07-24 06:07:59.778871: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (3): Quadro RTX 8000, Compute Capability 7.5
2020-07-24 06:07:59.778877: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (4): Quadro RTX 8000, Compute Capability 7.5
2020-07-24 06:07:59.778883: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (5): Quadro RTX 8000, Compute Capability 7.5
2020-07-24 06:07:59.778889: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (6): Quadro RTX 8000, Compute Capability 7.5
2020-07-24 06:07:59.778895: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (7): Quadro RTX 8000, Compute Capability 7.5
2020-07-24 06:07:59.778926: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 0, reason: Invalid argument: device CUDA:0 not supported by XLA service
2020-07-24 06:07:59.779683: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 2, reason: Invalid argument: device CUDA:2 not supported by XLA service
2020-07-24 06:08:00.521575: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_TOO_MANY_PEERS: peer mapping resources exhausted
[lambda-server:648257] *** Process received signal ***
[lambda-server:648257] Signal: Aborted (6)
[lambda-server:648257] Signal code: (-6)
[lambda-server:648257] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x46210)[0x7f23210b9210]
[lambda-server:648257] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcb)[0x7f23210b918b]
[lambda-server:648257] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x12b)[0x7f2321098859]
[lambda-server:648257] [ 3] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.cpython-38-x86_64-linux-gnu.so(+0xb1da10b)[0x7f21ae9ba10b]
[lambda-server:648257] [ 4] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.cpython-38-x86_64-linux-gnu.so(_ZN15stream_executor4port17internal_statusor6Helper5CrashERKN10tensorflow6StatusE+0x61)[0x7f21a631090d]
[lambda-server:648257] [ 5] /usr/lib/python3/dist-packages/tensorflow/python/../libtensorflow_framework.so.2(_ZN10tensorflow20BaseGPUDeviceFactory16EnablePeerAccessERKSt6vectorINS_3gtl7IntTypeINS_18PlatformGpuId_tag_EiEESaIS5_EE+0x33d)[0x7f219e0b518d]
[lambda-server:648257] [ 6] /usr/lib/python3/dist-packages/tensorflow/python/../libtensorflow_framework.so.2(_ZN10tensorflow20BaseGPUDeviceFactory13CreateDevicesERKNS_14SessionOptionsERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPSt6vectorISt10unique_ptrINS_6DeviceESt14default_deleteISE_EESaISH_EE+0x1840)[0x7f219e0bb0d0]
[lambda-server:648257] [ 7] /usr/lib/python3/dist-packages/tensorflow/python/../libtensorflow_framework.so.2(_ZN10tensorflow13DeviceFactory10AddDevicesERKNS_14SessionOptionsERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPSt6vectorISt10unique_ptrINS_6DeviceESt14default_deleteISE_EESaISH_EE+0x109)[0x7f219e0fcc19]
[lambda-server:648257] [ 8] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.cpython-38-x86_64-linux-gnu.so(TFE_NewContext+0x8d)[0x7f21a6f3febd]
[lambda-server:648257] [ 9] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_tfe.cpython-38-x86_64-linux-gnu.so(+0x3c529)[0x7f219c3ff529]
[lambda-server:648257] [10] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_tfe.cpython-38-x86_64-linux-gnu.so(+0x53d3b)[0x7f219c416d3b]
[lambda-server:648257] [11] python3(PyCFunction_Call+0x55)[0x5f1625]
[lambda-server:648257] [12] python3(_PyObject_MakeTpCall+0x296)[0x5f2246]
[lambda-server:648257] [13] python3(_PyEval_EvalFrameDefault+0x5c0f)[0x56c70f]
[lambda-server:648257] [14] python3(_PyFunction_Vectorcall+0x1ab)[0x5f19cb]
[lambda-server:648257] [15] python3(_PyEval_EvalFrameDefault+0x825)[0x567325]
[lambda-server:648257] [16] python3(_PyEval_EvalCodeWithName+0x262)[0x5654d2]
[lambda-server:648257] [17] python3(_PyFunction_Vectorcall+0x3a5)[0x5f1bc5]
[lambda-server:648257] [18] python3(_PyEval_EvalFrameDefault+0x6fd)[0x5671fd]
[lambda-server:648257] [19] python3(_PyEval_EvalCodeWithName+0x262)[0x5654d2]
[lambda-server:648257] [20] python3(_PyFunction_Vectorcall+0x3a5)[0x5f1bc5]
[lambda-server:648257] [21] python3(_PyEval_EvalFrameDefault+0x1904)[0x568404]
[lambda-server:648257] [22] python3(_PyEval_EvalCodeWithName+0x262)[0x5654d2]
[lambda-server:648257] [23] python3(_PyFunction_Vectorcall+0x3a5)[0x5f1bc5]
[lambda-server:648257] [24] python3(_PyEval_EvalFrameDefault+0x5556)[0x56c056]
[lambda-server:648257] [25] python3(_PyEval_EvalCodeWithName+0x262)[0x5654d2]
[lambda-server:648257] [26] python3(PyEval_EvalCode+0x23)[0x686d53]
[lambda-server:648257] [27] python3[0x676101]
[lambda-server:648257] [28] python3[0x67617f]
[lambda-server:648257] [29] python3[0x4a032d]
[lambda-server:648257] *** End of error message ***
Aborted (core dumped)
```"
42038,"ValueError: No gradients provided for any variable (Keras 2.4, Tensorflow 2.3.0)","So I'm using [this model](https://github.com/ekohendratno/Screenshot-to-code-in-Keras/blob/master/floydhub/Bootstrap/bootstrap_generator.ipynb) to train on Google colab, it was written for Tensorflow 1.9 and Keras 2, but when I train I get the following error, has anyone seen this or how to solve it?

It was training fine before but this error started today.

Actual code:

```
from os import listdir
from numpy import array
from keras.preprocessing.text import Tokenizer, one_hot
from keras.preprocessing.sequence import pad_sequences
from keras.models import Model, Sequential, model_from_json
from keras.utils import to_categorical
from keras.layers.core import Dense, Dropout, Flatten
from keras.optimizers import RMSprop
from keras.layers.convolutional import Conv2D
from keras.callbacks import ModelCheckpoint
from keras.layers import Embedding, TimeDistributed, RepeatVector, LSTM,     concatenate , Input, Reshape, Dense
from keras.preprocessing.image import array_to_img, img_to_array, load_img
import numpy as np

dir_name = '/data/train/'

# Read a file and return a string
def load_doc(filename):
file = open(filename, 'r')
text = file.read()
file.close()
return text

def load_data(data_dir):
text = []
images = []
# Load all the files and order them
all_filenames = listdir(data_dir)
all_filenames.sort()
for filename in (all_filenames):
    if filename[-3:] == ""npz"":
        # Load the images already prepared in arrays
        image = np.load(data_dir+filename)
        images.append(image['features'])
    else:
        # Load the boostrap tokens and rap them in a start and end tag
        syntax = '<START> ' + load_doc(data_dir+filename) + ' <END>'
        # Seperate all the words with a single space
        syntax = ' '.join(syntax.split())
        # Add a space after each comma
        syntax = syntax.replace(',', ' ,')
        text.append(syntax)
images = np.array(images, dtype=float)
return images, text

train_features, texts = load_data(dir_name)

# Initialize the function to create the vocabulary 
tokenizer = Tokenizer(filters='', split="" "", lower=False)
# Create the vocabulary 
tokenizer.fit_on_texts([load_doc('bootstrap.vocab')])

# Add one spot for the empty word in the vocabulary 
vocab_size = len(tokenizer.word_index) + 1
max_length = 48

def preprocess_data(texts, features, max_sequence):
X, y, image_data = list(), list(), list()
sequences = tokenizer.texts_to_sequences(texts)
for img_no, seq in enumerate(sequences):
    for i in range(1, len(seq)):
        # Add the sentence until the current count(i) and add the current     count to the output
        in_seq, out_seq = seq[:i], seq[i]
        # Pad all the input token sentences to max_sequence
        in_seq = pad_sequences([in_seq], maxlen=max_sequence)[0]
        # Turn the output into one-hot encoding
        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]
        # Add the corresponding image to the boostrap token file
        image_data.append(features[img_no])
        # Cap the input sentence to 48 tokens and add it
        X.append(in_seq[-48:])
        y.append(out_seq)
return np.array(image_data), np.array(X), np.array(y)


# data generator, intended to be used in a call to model.fit_generator()
def data_generator(descriptions, features, n_step, max_sequence):
# loop until we finish training
while 1:
    # loop over photo identifiers in the dataset
    for i in range(0, len(descriptions), n_step):
        Ximages, XSeq, y = list(), list(),list()
        for j in range(i, min(len(descriptions), i+n_step)):
            image = features[j]
            # retrieve text input
            desc = descriptions[j]
            # generate input-output pairs
            in_img, in_seq, out_word = preprocess_data([desc], [image], max_sequence)
            for k in range(len(in_img)):
                Ximages.append(in_img[k])
                XSeq.append(in_seq[k])
                y.append(out_word[k])
        # yield this batch of samples to the model
        yield [[array(Ximages), array(XSeq)], array(y)]

#Create the encoder
image_model = Sequential()
image_model.add(Conv2D(16, (3, 3), padding='valid', activation='relu', input_shape=(256, 256, 3,)))
image_model.add(Conv2D(16, (3,3), activation='relu', padding='same', strides=2))
image_model.add(Conv2D(32, (3,3), activation='relu', padding='same'))
image_model.add(Conv2D(32, (3,3), activation='relu', padding='same', strides=2))
image_model.add(Conv2D(64, (3,3), activation='relu', padding='same'))
image_model.add(Conv2D(64, (3,3), activation='relu', padding='same', strides=2))
image_model.add(Conv2D(128, (3,3), activation='relu', padding='same'))

image_model.add(Flatten())
image_model.add(Dense(1024, activation='relu'))
image_model.add(Dropout(0.3))
image_model.add(Dense(1024, activation='relu'))
image_model.add(Dropout(0.3))

image_model.add(RepeatVector(max_length))

visual_input = Input(shape=(256, 256, 3,))
encoded_image = image_model(visual_input)

language_input = Input(shape=(max_length,))
language_model = Embedding(vocab_size, 50, input_length=max_length,    mask_zero=True)(language_input)
language_model = LSTM(128, return_sequences=True)(language_model)
language_model = LSTM(128, return_sequences=True)(language_model)

#Create the decoder
decoder = concatenate([encoded_image, language_model])
decoder = LSTM(512, return_sequences=True)(decoder)
decoder = LSTM(512, return_sequences=False)(decoder)
decoder = Dense(vocab_size, activation='softmax')(decoder)

# Compile the model
model = Model(inputs=[visual_input, language_input], outputs=decoder)
optimizer = RMSprop(lr=0.0001, clipvalue=1.0)
model.compile(loss='categorical_crossentropy', optimizer=optimizer)

#Save the model for every 2nd epoch
filepath=""org-weights-epoch-{epoch:04d}--loss-{loss:.4f}.hdf5""
checkpoint = ModelCheckpoint(filepath, verbose=1, save_weights_only=True,     period=2)
callbacks_list = [checkpoint]

# test the data generator
generator = data_generator(texts, train_features, 1, 150)
model.fit_generator(generator, steps_per_epoch=50, epochs=5, callbacks=callbacks_list, verbose=1)

```

Error I receive when training:
```
ValueError                                
Traceback (most recent call last)
<ipython-input-4-6927891f43ca> in <module>()
  1 # test the data generator
  2 generator = data_generator(texts, train_features, 1, max_sequence)
----> 3 loaded_model.fit_generator(generator, steps_per_epoch=steps, epochs=5, callbacks=callbacks_list, verbose=1)
  4 loaded_model.save(mydrive + '/output/weights.hdf5')

12 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
971           except Exception as e:  # pylint:disable=broad-except
972             if hasattr(e, ""ag_error_metadata""):
--> 973               raise e.ag_error_metadata.to_exception(e)
974             else:
975               raise

ValueError: in user code:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
    return step_function(self, iterator)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **
    outputs = model.distribute_strategy.run(run_step, args=(data,))
/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica
    return fn(*args, **kwargs)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **
    outputs = model.train_step(data)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:757 train_step
    self.trainable_variables)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2737 _minimize
    trainable_variables))
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:562 _aggregate_gradients
    filtered_grads_and_vars = _filter_grads(grads_and_vars)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1271 _filter_grads
    ([v.name for _, v in grads_and_vars],))

ValueError: No gradients provided for any variable: ['embedding_1/embeddings:0', 'lstm_1/lstm_cell/kernel:0', 'lstm_1/lstm_cell/recurrent_kernel:0', 'lstm_1/lstm_cell/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_2/lstm_cell_1/kernel:0', 'lstm_2/lstm_cell_1/recurrent_kernel:0', 'lstm_2/lstm_cell_1/bias:0', 'lstm_3/lstm_cell_2/kernel:0', 'lstm_3/lstm_cell_2/recurrent_kernel:0', 'lstm_3/lstm_cell_2/bias:0', 'lstm_4/lstm_cell_3/kernel:0', 'lstm_4/lstm_cell_3/recurrent_kernel:0', 'lstm_4/lstm_cell_3/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'].
```
I'm training it on Google Colab using the TPU. If I train it on Tensorflow 1.x it trains fine but takes 8 hours per epoch with my dataset. Tensorflow 2.x was taking 1 hour per epoch but is now giving this error

EDIT: SOLUTION 

I cannot train on TPU, but I am at least able to train on GPU, I can continue the project !
Solution by @silentkinght25 and @silentkinght25 solves it. 

""To resolve this u must modify the data generator function as: yield ([array(Ximages), array(XSeq)], array(y)) instead of yield [[array(Ximages), array(XSeq)], array(y)]"""
42037,Random addition of channel during training when input data is all 1 channel,"**System information**
Have I written custom code [posted below]:
Done on google colab using TF 2.x


Currently during training, somehow my training data gets a surprising second channel. I think this has something to do with datatype changing that happens during the fit function, but is not resolved when forcing dtype prior to entering training. This messes with the concatenation of my Dense-Net like structures. Looking at the warning below, I don't understand how its being called with a shape of  512,512, 1, 1, as the overall shape of image_list is 1540, 512,512, 1. Where each image slice is 512, 512, 1. (HWC)

Traceback is:
```
WARNING:tensorflow:Model was constructed with shape (None, 512, 512, 1) for input Tensor(""input_2:0"", shape=(None, 512, 512, 1), dtype=float32), but it was called on an input with incompatible shape (512, 512, 1, 1).
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-17-b77dae276c25> in <module>()
      1 
----> 2 model.fit(dataset, epochs=1 )

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1096                 batch_size=batch_size):
   1097               callbacks.on_train_batch_begin(step)
-> 1098               tmp_logs = train_function(iterator)
   1099               if data_handler.should_sync:
   1100                 context.async_wait()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    821       # This is the first call of __call__, so we have to initialize.
    822       initializers = []
--> 823       self._initialize(args, kwds, add_initializers_to=initializers)
    824     finally:
    825       # At this point we know that the initialization is complete (or less

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    695     self._concrete_stateful_fn = (
    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 697             *args, **kwds))
    698 
    699     def invalid_creator_scope(*unused_args, **unused_kwds):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2853       args, kwargs = None, None
   2854     with self._lock:
-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2856     return graph_function
   2857 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3211 
   3212       self._function_cache.missed.add(call_context_key)
-> 3213       graph_function = self._create_graph_function(args, kwargs)
   3214       self._function_cache.primary[cache_key] = graph_function
   3215       return graph_function, args, kwargs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3073             arg_names=arg_names,
   3074             override_flat_arg_shapes=override_flat_arg_shapes,
-> 3075             capture_by_value=self._capture_by_value),
   3076         self._function_attributes,
   3077         function_spec=self.function_spec,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--> 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    599         # the function a weak reference to itself to avoid a reference cycle.
--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    601     weak_wrapped_fn = weakref.ref(wrapped_fn)
    602 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    971           except Exception as e:  # pylint:disable=broad-except
    972             if hasattr(e, ""ag_error_metadata""):
--> 973               raise e.ag_error_metadata.to_exception(e)
    974             else:
    975               raise

ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step
        y_pred = self(x, training=True)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call
        inputs, training=training, mask=mask)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph
        outputs = node.layer(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:183 call
        return self._merge_function(inputs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:522 _merge_function
        return K.concatenate(inputs, axis=self.axis)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:2881 concatenate
        return array_ops.concat([to_dense(x) for x in tensors], axis)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1654 concat
        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:1222 concat_v2
        ""ConcatV2"", values=values, axis=axis, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal
        compute_device)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal
        op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1975 __init__
        control_input_ops, op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1815 _create_c_op
        raise ValueError(str(e))

    ValueError: Dimension 2 in both shapes must be equal, but are 2 and 1. Shapes are [512,32,2] and [512,32,1]. for '{{node functional_3/concatenate_60/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](functional_3/leaky_re_lu_84/LeakyRelu, functional_3/concatenate_55/concat, functional_3/concatenate_60/concat/axis)' with input shapes: [512,32,2,86], [512,32,1,172], [] and with computed input tensors: input[2] = <3>.
```

Link to colab: https://colab.research.google.com/drive/1FwuS2Wa589CvbiqOgAznqqnbKruez9Nj?usp=sharing

link to sample dataset: <removed>"
42035,hang in recursive call of google::protobuf::DescriptorPool::FindFileByName,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.0
- Bazel version (if compiling from source): 3.1
- GCC/Compiler version (if compiling from source): 5.4
- CUDA/cuDNN version: 10.1
- GPU model and memory: -

**Describe the current behavior**

TensorFlow hangs at import (`import tensorflow`).
The only output I see is:
```
2020-08-04 17:42:26.693993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
```

**Describe the expected behavior**

TensorFlow should not hang at import.

**Standalone code to reproduce the issue**

```
import tensorflow
```

**Other info / logs**

I attached GDB, and the stacktrace is interesting. I posted it [here](https://gist.github.com/albertz/f46a19276c95af5900833c98f47742a8).

The relevant part:
```
#0  __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135
#1  0x00007ffff7620dbd in __GI___pthread_mutex_lock (mutex=0xe6cfb0) at ../nptl/pthread_mutex_lock.c:80
#2  0x00007fffd03f5d91 in google::protobuf::DescriptorPool::FindFileByName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#3  0x00007fffd044328e in google::protobuf::(anonymous namespace)::AssignDescriptorsImpl(google::protobuf::internal::DescriptorTable const*) ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#4  0x00007ffff7625a99 in __pthread_once_slow (
    once_control=0x7fffd0ee5d74 <descriptor_table_google_2fprotobuf_2fdescriptor_2eproto_once>, 
    init_routine=0x7fffed339ac0 <std::__once_proxy()>) at pthread_once.c:116
#5  0x00007fffd0436d46 in google::protobuf::internal::AssignDescriptors(google::protobuf::internal::DescriptorTable const*)
    ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#6  0x00007fffd0405590 in google::protobuf::FileOptions::GetMetadata() const ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#7  0x00007fffd0461e98 in google::protobuf::Message::GetTypeName[abi:cxx11]() const ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#8  0x00007fffd050a178 in google::protobuf::(anonymous namespace)::ByteSizeConsistencyError(unsigned long, unsigned long, unsigned long, google::protobuf::MessageLite const&) [clone .constprop.38] ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#9  0x00007fffd050b61c in google::protobuf::MessageLite::AppendPartialToString(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*) const ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#10 0x00007fffd050b92e in google::protobuf::MessageLite::SerializeAsString[abi:cxx11]() const ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#11 0x00007fffd03ecd12 in void google::protobuf::DescriptorBuilder::AllocateOptionsImpl<google::protobuf::FileDescriptor>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::FileDescriptor::OptionsType const&, google::protobuf::FileDescriptor*, std::vector<int, std::allocator<int> > const&) ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#12 0x00007fffd03ed02c in google::protobuf::DescriptorBuilder::AllocateOptions(google::protobuf::FileOptions const&, google::protobuf::FileDescriptor*) ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#13 0x00007fffd03f495b in google::protobuf::DescriptorBuilder::BuildFileImpl(google::protobuf::FileDescriptorProto const&)
    ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#14 0x00007fffd03f57de in google::protobuf::DescriptorBuilder::BuildFile(google::protobuf::FileDescriptorProto const&) ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#15 0x00007fffd03f5be5 in google::protobuf::DescriptorPool::BuildFileFromDatabase(google::protobuf::FileDescriptorProto const&) const ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#16 0x00007fffd03f5d3b in google::protobuf::DescriptorPool::TryFindFileInFallbackDatabase(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#17 0x00007fffd03f5e34 in google::protobuf::DescriptorPool::FindFileByName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#18 0x00007fffd044328e in google::protobuf::(anonymous namespace)::AssignDescriptorsImpl(google::protobuf::internal::DescriptorTable const*) ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#19 0x00007ffff7625a99 in __pthread_once_slow (
    once_control=0x7fffd0ee9354 <descriptor_table_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto_once>, 
    init_routine=0x7fffed339ac0 <std::__once_proxy()>) at pthread_once.c:116
#20 0x00007fffd0436d46 in google::protobuf::internal::AssignDescriptors(google::protobuf::internal::DescriptorTable const*)
    ()
   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#21 0x00007fffd059ea10 in tensorflow::OpList::GetMetadata() const ()
```

I noticed that `google::protobuf::DescriptorPool::FindFileByName` occurs twice in this stacktrace.
Maybe `google::protobuf::DescriptorPool::FindFileByName` locks the same mutex twice? That would explain the hang.
This is the only thread running at this point.
"
42033,Add deterministic tf.image.crop_and_resize backprop,"Note: I am willing and able to implement this feature but I don't know when I will get to it. My intention in creating this issue is to clearly reproduce and document the current nondeterministic functionality for the community and to allow for someone else to address it, if they have available bandwidth.

**System information**
- TensorFlow version: nondeterminism reproduced using version 2.3.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
See nondeterminism repro code at the end of this comment.
- Backprop to `image` is nondeterministic on both CPU and GPU. CPU variance is much higher.
- Backprop to `boxes` is nondeterministic on GPU.

**Will this change the current api? How?**
**No**. Existing environment variable `TF_DETERMINISTIC_OPS=1` will enable deterministic operation for `tf.image.crop_and_resize`

**Who will benefit with this feature?**
Users who care about determinism in TensorFlow, which includes users running safety-critical applications or anyone who wants to save time and compute cycles spent re-running nondeterministic processes for reproing, debugging, experimentation, and regression testing. This current feature request was prompted by framework-determinism [issue 18](https://github.com/NVIDIA/framework-determinism/issues/18).

**Any Other info.**
A solution will look similar to [PR 39243](https://github.com/tensorflow/tensorflow/pull/39243), from me, in this current repo. A solution will require new CUDA kernels in `crop_and_resize_op_gpu.cu.cc`. The existing kernels utilize CUDA `atomicAdd` in such a way as to introduce nondeterminism.

**Test / Repro Code**
```
import os
import tensorflow as tf

# Force-disable GPU:
# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

# The following line is how determinism will be enabled, but is not expected
# to currently have any effect on the output.
os.environ['TF_DETERMINISTIC_OPS'] = '1'

batch_size = 16
input_height = 64
input_width = 64
depth = 1
input_shape = (batch_size, input_height, input_width, depth)
tf.random.set_seed(456)
image = tf.random.uniform(
    input_shape, minval=-1.0, maxval=1.0, dtype=tf.float32)

# Image Gradients:
#
# Upsampling of a crop, leading to three or more output pixels being derived
# from an input pixel, will contribute to nondeterminism in the gradient
# associated with that input pixel location.
#
# Note that the number of boxes can be less than, equal to, or greater than
# the batch size. Three or more crops overlapping on the same input image pixel
# can independently contribute to nondeterminism in the image gradient
# associated with that input pixel location. This is independent of
# contributions caused by the upsampling of any given crop.
#
# Boxes Gradients:
#
# If the input and output dimensions are the same, then the boxes gradients
# will be deterministically zero, otherwise they will contain nondeterminism
# weather there is upsampling or downsampling and whether or not there are
# overlapping crops.

box_count = 4 * batch_size
boxes = tf.random.uniform(
  (box_count, 4), minval=0.0, maxval=1.01, dtype=tf.float32)

box_indices = tf.random.uniform(
  (box_count, ), minval=0, maxval=batch_size, dtype=tf.int32)

crop_size = [input_height*2, input_width*2]
output_shape = (box_count, *crop_size, depth)

injected_gradients = tf.random.uniform(
    output_shape, minval=-0.001, maxval=0.001, dtype=tf.float32)

def gradients():
  with tf.GradientTape() as tape:
    tape.watch([image, boxes])
    output = tf.image.crop_and_resize(
        image, boxes, box_indices, crop_size, method='bilinear')
    upstream = output * injected_gradients
  return tape.gradient(upstream, [image, boxes])

def sum(tensor):
  return tf.reduce_sum(tensor)

for device in ['gpu', 'cpu']:
  print(""\n# Running on {}:\n"".format(device))
  print(""#         Image Gradients |  Boxes Gradients"")
  print(""#        -----------------+------------------"")
  msg = ""# Run {:d}: {:15.13f} | {:16.13f}""
  with tf.device(""/{}:0"".format(device)):
    for i in range(8):
      image_gradients, boxes_gradients = gradients()
      print(msg.format(i+1, sum(image_gradients), sum(boxes_gradients)))

print("""")

# Example output (running on TensorFlow 2.3.0):

# Running on gpu:

#         Image Gradients |  Boxes Gradients
#        -----------------+------------------
# Run 1: -1.2592203617096 | -55.5643386840820
# Run 2: -1.2592202425003 | -55.5643081665039
# Run 3: -1.2592201232910 | -55.5643692016602
# Run 4: -1.2592203617096 | -55.5644264221191
# Run 5: -1.2592200040817 | -55.5643730163574
# Run 6: -1.2592201232910 | -55.5644035339355
# Run 7: -1.2592202425003 | -55.5643386840820
# Run 8: -1.2592201232910 | -55.5643272399902

# Running on cpu:

#         Image Gradients |  Boxes Gradients
#        -----------------+------------------
# Run 1: -1.2608621120453 | -55.5644989013672
# Run 2: -1.2792857885361 | -55.5644989013672
# Run 3: -1.2577195167542 | -55.5644989013672
# Run 4: -1.2553272247314 | -55.5644989013672
# Run 5: -1.2539256811142 | -55.5644989013672
# Run 6: -1.2622516155243 | -55.5644989013672
# Run 7: -1.2515500783920 | -55.5644989013672
# Run 8: -1.2537302970886 | -55.5644989013672
```"
42030,Tensorflow 2.1 + Docker + CUDA 10.2 Issue with the recognition of the graphics card,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Developer laptop -> Win10, Docker container: ubuntu18.04, Server: Linux
- TensorFlow installed from (source or binary): Source with pip
- TensorFlow version: 2.1
- Python version: 3.6
- Installed using virtualenv? pip? conda?: docker (pip)
- CUDA/cuDNN version: Developer laptop: 10.2, Server: 10.2
- GPU model and memory: Developer laptop GTC 1660 Ti, Server=?


**Describe the problem**
I am developing a deep learning model with Tensorflow2 and this model should be trained inside a docker container on the server. If I run the code on my laptop without a docker container, the GPU of the laptop will be recognized and can be trained with it. As soon as the code is in the container, no graphics card is recognized anymore, but the output of Tensorflow2 is generated, which is located at the bottom of **Any other info / logs**.

the problem seems to be that the containers do not allow access to the graphics cards.


**Any other info / logs**
```python
2020-08-04 10:44:10.798030: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-04 10:44:10.798086: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-04 10:44:10.798117: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (12e682dbeadb): /proc/driver/nvidia/version does not exist
```
"
42027,Stale(?) references to activation histograms,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard

## Description of issue (what needs changing):

### Clear description

URL above says

> `histogram_freq`    frequency (in epochs) at which to compute activation and weight histograms ...

However,
- I do not see any activation histograms in my TensorBoard despite using `validation_data` - only biases and kernels.
- I do not see any activation-specific code in https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/keras/callbacks.py#L2227-L2238

See also https://stackoverflow.com/questions/60816678/

Therefore, I suspect that activation histograms are not logged at all."
42026,_create_keras_history_helper error ('NoneType' object has no attribute 'op') in 2.3.0 not in 2.2.0,"When using model subclassing, we have been exploiting reinitialization of the subclass as a way to define the inputs for our model at construction, allowing us to call e.g. the `summary` method of our model and have specific input shape be listed as opposed to the 'multiple' input shape present when not constructing with an input. However, moving to tf 2.3.0 from 2.2.0 this now produces an unexpected error on the 2nd time the model is constructed. Here's a minimal reproducer:

```
class MyModel(tf.keras.Model):

  def __init__(self,**kwargs):
    super(MyModel,self).__init__(**kwargs)
    # create model layers ...
    self.layer1 = tf.keras.layers.Dense(10)
    # define input shape, and reinit ...
    inputs = tf.keras.Input(shape=(5,))
    super(MyModel,self).__init__(inputs=inputs, outputs=self.call(inputs),**kwargs)
    # calling 'summary' will show specific input shapes
    self.summary()
  
  def call(self, inputs):
    return self.layer1(inputs)

m = MyModel()
m = MyModel() ## exception here!
```

Produces error:

```
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    224                        'op wrapping. Please wrap these ops in a Lambda layer: '
    225                        '\n\n```\n{example}\n```\n'.format(example=example))
--> 226     op = tensor.op  # The Op that created this Tensor.
    227     if op not in processed_ops:
    228       # Recursively set `_keras_history`.

AttributeError: 'NoneType' object has no attribute 'op'
```

In honesty we always considered the above 'reinit' a bit of a hack, and would be happy to be told the correct way to achieve what we want (a subclassed model with a defined input shape at construction time). But thought should report this anomalous behaviour none-the-less.

Thanks

"
42025,Confusion Matrix produces different results in Keras model tf==2.3.0,"Using tf==2.3.0, keras 2.4.3
Built keras with from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
With Keras Sequential Model Prediction
To get Class Labels
we can do
```
yhat_classes1 = Keras_model.predict_classes(predictors)[:, 0] #this shows deprecated warning in tf==2.3.0

WARNING:tensorflow:From <ipython-input-54-226ad21ffae4>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.
Instructions for updating:
Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(""int32"")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).

```
or
```
yhat_classes2 = np.argmax(Keras_model.predict(predictors), axis=1)
```
With the first class labels if i create confusion matrix, i get
```
matrix = confusion_matrix(actual_y, yhat_classes1)
 [[108579   8674]
 [  1205  24086]]
```
But with the second class labels with the confusion matrix, i get 0 for True Positive and False Positive
```
matrix = confusion_matrix(actual_y, yhat_classes2)
 [[117253      0]
 [ 25291      0]]
```
Final layer has
```
Keras_model.add(Dense(1, activation='sigmoid', kernel_initializer=init_mode)) 
```
May I know whats the issue please, Thanks"
42024,RESIZE_NEAREST_NEIGHBOR Operation version not supported,"def save_tflite():
  converter = tf.lite.TFLiteConverter.from_saved_model(FLAGS.weights)
  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
  converter.optimizations = [tf.lite.Optimize.DEFAULT]
  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
  converter.allow_custom_ops = True
  converter.representative_dataset = representative_dataset_gen
  tflite_model = converter.convert()
  open(FLAGS.output, 'wb').write(tflite_model)

  TF version:2.3.0  


Edge TPU Compiler version 14.1.317412892
Input: yolov3-416-int8.tflite
Output: yolov3-416-int8_edgetpu.tflite

Operator                       Count      Status

DEQUANTIZE                     3          Operation is working on an unsupported data type
QUANTIZE                       2          More than one subgraph is not supported
QUANTIZE                       1          Operation is otherwise supported, but not mapped due to some unspecified limitation
CONV_2D                        15         More than one subgraph is not supported
CONV_2D                        60         Mapped to Edge TPU
RESIZE_NEAREST_NEIGHBOR        2          Operation version not supported
PAD                            5          Mapped to Edge TPU
CONCATENATION                  2          More than one subgraph is not supported
ADD                            23         Mapped to Edge TPU

when I use Edge TPU Compiler compile tflite model, I got the error about RESIZE_NEAREST_NEIGHBOR,ths."
42022,Memory leak in keras.backend preventing graphs from being GC'ed,"In some situations (i.e. [when outside of an eager execution context](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/backend.py#L394)) a Tensor value will be inserted into [_GRAPH_LEARNING_PHASES](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/backend.py#L6389). This is a problem because the Tensor value itself references the graph which is suppose to be weakly held in memory by this dictionary. With the implementation of weakref.WeakKeyDictionary a value that strongly references its key will forever prevent the key from being reclaimed. This means the entire graph is permanently stuck in memory unless the entry is explicitly deleted.

This issue is present in tf 2.3.0

Simple repro code

```
import gc

import psutil
import tensorflow as tf

FIX_LEAK = False

def _get_rss():
    return psutil.Process().memory_info().rss

def _test_iteration():
    with tf.Graph().as_default() as graph:
        inputs = tf.keras.Input(shape=(8,), dtype=""int32"")
        embedding_layer = tf.keras.layers.Embedding(
            input_dim=128,
            output_dim=128,
            input_length=8,
        )(inputs)
        tf.keras.layers.LSTM(
            256,
            dropout=0.5,
        )(embedding_layer)
        
    if FIX_LEAK:
        import tensorflow.python.keras.backend as backend
        backend._GRAPH_LEARNING_PHASES.pop(graph, None)
    
for _ in range(128):
    _test_iteration()

    gc.collect()
    print(""RSS"", _get_rss())
```

With FIX_LEAK as False the memory usage grows forever (about 8MB or so for me each iteration). If FIX_LEAK is True the memory stays stable. I'm not super familiar with TF/keras, there may be a more bare bones example. In particular it seems that the dropout parameter was needed to trigger the learning_phrase Tensor to be created."
42021,Issue Running T5 in colab TPU - Tensorflow,"Hi Team,

I was trying to do a pre training of T5 from scratch on colab. I could see if i install t5 using (pip install t5[gcp]), and tried to connect to execute tf.tpu.experimental.initialize_tpu_system(tpu), getting below error.

InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}

If install/ upgrade tensorflow, it gets resolved, however import of t5 does not work as below.
import t5

NotFoundError: /usr/local/lib/python3.6/dist-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl11string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS8_EE

Please let me know how if there is a way to resolve this.
Thanks."
42018,Sparse input name missing in exported model,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: No
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: 2.3.0
-   **Python version**: 3.6.11
-   **Bazel version (if compiling from source)**: not used
-   **GCC/Compiler version (if compiling from source)**: not used
-   **CUDA/cuDNN version**: not used
-   **GPU model and memory**: not used
-   **Exact command to reproduce**:  please check below descriptions

### Describe the problem
When using tf.keras.Input with 'sparse=True', the input tensor info names are unreadable in serving signatures, such as args_0, args_0_1, args_0_2. As a result, it is very hard to distinguish when multiple sparse inputs are used in one model.

### Source code / logs
**[produce model]**
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

inputs =  keras.Input(shape=(10,), sparse=True, name='input')  # use a sparse input
dense = layers.Dense(64, activation=""relu"")
outputs = dense(inputs)
model = keras.Model(inputs=inputs, outputs=outputs, name=""model"")

tf.keras.models.save_model(model, ""exported_model"", overwrite=True, include_optimizer=False)

**[examine exported_model]**
$ saved_model_cli show --dir exported_model/ --tag_set serve --signature_def serving_default
output:
The given SavedModel SignatureDef contains the following input(s):
  **inputs['args_0'] tensor_info:**
      dtype: DT_INT64
      shape: (-1, 2)
      **name: serving_default_args_0:0**
  **inputs['args_0_1'] tensor_info:**
      dtype: DT_FLOAT
      shape: (-1)
      **name: serving_default_args_0_1:0**
  **inputs['args_0_2'] tensor_info:**
      dtype: DT_INT64
      shape: (2)
      **name: serving_default_args_0_2:0**
The given SavedModel SignatureDef contains the following output(s):
  outputs['dense'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 64)
      name: StatefulPartitionedCall:0
Method name is: tensorflow/serving/predict"
42017,ValueError: Graph disconnected: cannot obtain value for tensor Tensor…The following previous layers were accessed without issue:,"I want to obtain the output of intermediate sub-model layers with tf2.keras.Here is a model composed of two sub-modules:
```python
    input_shape = (100, 100, 3)

    def model1():
        input = tf.keras.layers.Input(input_shape)
        cov = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1,name='cov1')(input)
        embedding_model = tf.keras.Model(input,cov,name='model1')
        return embedding_model

    def model2(embedding_model):

        input_sequence = tf.keras.layers.Input((None,) + input_shape)

        sequence_embedding = tf.keras.layers.TimeDistributed(embedding_model,name='time_dis1')

        emb = sequence_embedding(input_sequence)
        att = tf.keras.layers.Attention()([emb,emb])
        dense1 = tf.keras.layers.Dense(64,name='dense1')(att)
        outputs = tf.keras.layers.Softmax()(dense1)

        final_model = tf.keras.Model(inputs=input_sequence, outputs=outputs,name='model2')
        return final_model

    embedding_model = model1()

    model2 = model2(embedding_model)
    print(model2.summary())
```

output:
```python
Model: ""model2""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, None, 100, 1 0                                            
__________________________________________________________________________________________________
time_dis1 (TimeDistributed)     (None, None, 98, 98, 896         input_2[0][0]                    
__________________________________________________________________________________________________
attention (Attention)           (None, None, 98, 98, 0           time_dis1[0][0]                  
                                                                 time_dis1[0][0]                  
__________________________________________________________________________________________________
dense1 (Dense)                  (None, None, 98, 98, 2112        attention[0][0]                  
__________________________________________________________________________________________________
softmax (Softmax)               (None, None, 98, 98, 0           dense1[0][0]                     
==================================================================================================
Total params: 3,008
Trainable params: 3,008
Non-trainable params: 0
```
and then,I want to get output intermediate layer of model1 and model2:

```python
    model1_output_layer = model2.get_layer('time_dis1').layer.get_layer('cov1')
    output1 = model1_output_layer.get_output_at(0)
    output2 = model2.get_layer('dense1').get_output_at(0)

    output_tensors = [output1,output2]
    model2_input = model2.input
    submodel = tf.keras.Model([model2_input],output_tensors)
    input_data2 = np.zeros((1,10,100,100,3))

    result = submodel.predict([input_data2])
    print(result)
```
Running in tf2.3 ,the error I am getting is:
```python
 File ""/Users/bouluoyu/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/functional.py"", line 115, in __init__
    self._init_graph_network(inputs, outputs)
  File ""/Users/bouluoyu/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/Users/bouluoyu/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/functional.py"", line 191, in _init_graph_network
    self.inputs, self.outputs)
  File ""/Users/bouluoyu/anaconda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/functional.py"", line 931, in _map_graph_network
    str(layers_with_complete_input))
ValueError: Graph disconnected: cannot obtain value for tensor Tensor(""input_1:0"", shape=(None, 100, 100, 3), dtype=float32) at layer ""cov1"". The following previous layers were accessed without issue: ['time_dis1', 'attention', 'dense1']
```
But the following code works:

```python
    model1_input = embedding_model.input
    model2_input = model2.input

    submodel = tf.keras.Model([model1_input,model2_input],output_tensors)

    input_data1 = np.zeros((1,100,100,3))
    input_data2 = np.zeros((1,10,100,100,3))

    result = submodel.predict([input_data1,input_data2])
    print(result
```
But not what I want.This is strange, model1 is part of model2, so why do we need to input an extra tensor ```input_data1``` ? Sometimes,it is hard to get an extra tensor,especially for complex models.What should I do? Do we need a new API to support this functionality?
"
42016,Timeseries example is not working with latest 2.4 code,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb

When it comes to Convolution model, this errors out.
===code===
history = compile_and_fit(conv_model, conv_window)

IPython.display.clear_output()
val_performance['Conv'] = conv_model.evaluate(conv_window.val)
performance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0)
==============
===error====
NotFoundError:  No algorithm worked!
	 [[node sequential_3/conv1d/conv1d (defined at <ipython-input-41-716049f06cb3>:12) ]] [Op:__inference_train_function_127129]

Function call stack:
train_function
"
42015,How to start recording video when something has been detected!,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes (I took it from someone's github)
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Raspberry pi, however, this code works with windows too
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**: Using tflite
-   **Python version**:3.7
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

This is the code. how can I start recording video when something gets detected and then store it in a output directory. If possible how would I be able to additionally give a time stamp of when the recording was taken. THIS WOULD BE A HUGE HELP IF SOMEONE CAN HELP ME! I wouldn't mind using a completely different code which is made just for the purpose of storing videos of detection!
import os
import argparse
import cv2
import numpy as np
import sys
import time
from threading import Thread
import importlib.util

# Define VideoStream class to handle streaming of video from webcam in separate processing thread
# Source - Adrian Rosebrock, PyImageSearch: https://www.pyimagesearch.com/2015/12/28/increasing-raspberry-pi-fps-with-python-and-opencv/
class VideoStream:
    """"""Camera object that controls video streaming from the Picamera""""""
    def __init__(self,resolution=(640,480),framerate=30):
        # Initialize the PiCamera and the camera image stream
        self.stream = cv2.VideoCapture(0)
        ret = self.stream.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
        ret = self.stream.set(3,resolution[0])
        ret = self.stream.set(4,resolution[1])
            
        # Read first frame from the stream
        (self.grabbed, self.frame) = self.stream.read()

	# Variable to control when the camera is stopped
        self.stopped = False

    def start(self):
	# Start the thread that reads frames from the video stream
        Thread(target=self.update,args=()).start()
        return self

    def update(self):
        # Keep looping indefinitely until the thread is stopped
        while True:
            # If the camera is stopped, stop the thread
            if self.stopped:
                # Close camera resources
                self.stream.release()
                return

            # Otherwise, grab the next frame from the stream
            (self.grabbed, self.frame) = self.stream.read()

    def read(self):
	# Return the most recent frame
        return self.frame

    def stop(self):
	# Indicate that the camera and thread should be stopped
        self.stopped = True

# Define and parse input arguments
parser = argparse.ArgumentParser()
parser.add_argument('--modeldir', help='Folder the .tflite file is located in',
                    required=True)
parser.add_argument('--graph', help='Name of the .tflite file, if different than detect.tflite',
                    default='detect.tflite')
parser.add_argument('--labels', help='Name of the labelmap file, if different than labelmap.txt',
                    default='labelmap.txt')
parser.add_argument('--threshold', help='Minimum confidence threshold for displaying detected objects',
                    default=0.5)
parser.add_argument('--resolution', help='Desired webcam resolution in WxH. If the webcam does not support the resolution entered, errors may occur.',
                    default='1280x720')
parser.add_argument('--edgetpu', help='Use Coral Edge TPU Accelerator to speed up detection',
                    action='store_true')

args = parser.parse_args()

MODEL_NAME = args.modeldir
GRAPH_NAME = args.graph
LABELMAP_NAME = args.labels
min_conf_threshold = float(args.threshold)
resW, resH = args.resolution.split('x')
imW, imH = int(resW), int(resH)
use_TPU = args.edgetpu

# Import TensorFlow libraries
# If tflite_runtime is installed, import interpreter from tflite_runtime, else import from regular tensorflow
# If using Coral Edge TPU, import the load_delegate library
pkg = importlib.util.find_spec('tflite_runtime')
if pkg:
    from tflite_runtime.interpreter import Interpreter
    if use_TPU:
        from tflite_runtime.interpreter import load_delegate
else:
    from tensorflow.lite.python.interpreter import Interpreter
    if use_TPU:
        from tensorflow.lite.python.interpreter import load_delegate

# If using Edge TPU, assign filename for Edge TPU model
if use_TPU:
    # If user has specified the name of the .tflite file, use that name, otherwise use default 'edgetpu.tflite'
    if (GRAPH_NAME == 'detect.tflite'):
        GRAPH_NAME = 'edgetpu.tflite'       

# Get path to current working directory
CWD_PATH = os.getcwd()

# Path to .tflite file, which contains the model that is used for object detection
PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,GRAPH_NAME)

# Path to label map file
PATH_TO_LABELS = os.path.join(CWD_PATH,MODEL_NAME,LABELMAP_NAME)

# Load the label map
with open(PATH_TO_LABELS, 'r') as f:
    labels = [line.strip() for line in f.readlines()]

# Have to do a weird fix for label map if using the COCO ""starter model"" from
# https://www.tensorflow.org/lite/models/object_detection/overview
# First label is '???', which has to be removed.
if labels[0] == '???':
    del(labels[0])

# Load the Tensorflow Lite model.
# If using Edge TPU, use special load_delegate argument
if use_TPU:
    interpreter = Interpreter(model_path=PATH_TO_CKPT,
                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])
    print(PATH_TO_CKPT)
else:
    interpreter = Interpreter(model_path=PATH_TO_CKPT)

interpreter.allocate_tensors()

# Get model details
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]

floating_model = (input_details[0]['dtype'] == np.float32)

input_mean = 127.5
input_std = 127.5

# Initialize frame rate calculation
frame_rate_calc = 1
freq = cv2.getTickFrequency()

# Initialize video stream
videostream = VideoStream(resolution=(imW,imH),framerate=30).start()
time.sleep(1)

#for frame1 in camera.capture_continuous(rawCapture, format=""bgr"",use_video_port=True):
while True:

    # Start timer (for calculating frame rate)
    t1 = cv2.getTickCount()

    # Grab frame from video stream
    frame1 = videostream.read()

    # Acquire frame and resize to expected shape [1xHxWx3]
    frame = frame1.copy()
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_resized = cv2.resize(frame_rgb, (width, height))
    input_data = np.expand_dims(frame_resized, axis=0)

    # Normalize pixel values if using a floating model (i.e. if model is non-quantized)
    if floating_model:
        input_data = (np.float32(input_data) - input_mean) / input_std

    # Perform the actual detection by running the model with the image as input
    interpreter.set_tensor(input_details[0]['index'],input_data)
    interpreter.invoke()

    # Retrieve detection results
    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects
    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects
    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects
    #num = interpreter.get_tensor(output_details[3]['index'])[0]  # Total number of detected objects (inaccurate and not needed)

    # Loop over all detections and draw detection box if confidence is above minimum threshold
    for i in range(len(scores)):
        if ((scores[i] > min_conf_threshold) and (scores[i] <= 1.0)):

            # Get bounding box coordinates and draw box
            # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()
            ymin = int(max(1,(boxes[i][0] * imH)))
            xmin = int(max(1,(boxes[i][1] * imW)))
            ymax = int(min(imH,(boxes[i][2] * imH)))
            xmax = int(min(imW,(boxes[i][3] * imW)))
            
            cv2.rectangle(frame, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)

            # Draw label
            object_name = labels[int(classes[i])] # Look up object name from ""labels"" array using class index
            label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'
            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size
            label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window
            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in
            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text

    # Draw framerate in corner of frame
    cv2.putText(frame,'FPS: {0:.2f}'.format(frame_rate_calc),(30,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,0),2,cv2.LINE_AA)

    # All the results have been drawn on the frame, so it's time to display it.
    cv2.imshow('Object detector', frame)

    # Calculate framerate
    t2 = cv2.getTickCount()
    time1 = (t2-t1)/freq
    frame_rate_calc= 1/time1

    # Press 'q' to quit
    if cv2.waitKey(1) == ord('q'):
        break

# Clean up
cv2.destroyAllWindows()
videostream.stop()
"
42014,ValueError: Input tensors to a Functional must come from `tf.keras.Input` (TF 2.3),"Example below works in 2.2; `K.function` [now builds](https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/python/keras/backend.py#L3911) a `Model` in Eager execution, so we're passing `Model(inputs=[learning_phase,...])`.

I do have a workaround in mind, but it's hackish, and lot more complex than `K.function`; is there an analog to below in 2.3?

<hr>

```python
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.python.keras import backend as K
import numpy as np

ipt = Input((16,))
x   = Dense(16)(ipt)
out = Dense(16)(x)
model = Model(ipt, out)
model.compile('sgd', 'mse')

outs_fn = K.function([model.input, K.symbolic_learning_phase()],
                     [model.layers[1].output])  # error
x = np.random.randn(32, 16)
print(outs_fn([x, True]))
```
```
>>> ValueError: Input tensors to a Functional must come from `tf.keras.Input`. 
Received: Tensor(""keras_learning_phase:0"", shape=(), dtype=bool) 
(missing previous layer metadata).
```"
42010,tf.keras.preprocessing.image_dataset_from_directory doesn't work on TPU,"**System information**
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.6
- TPU model and memory: TPU v3-8 (Kaggle default)

**Describe the current behavior**
`tf.keras.preprocessing.image_dataset_from_directory` doesn't work on TPU.

Error message:
`InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=TensorSliceDataset; signature=components: -> handle:variant; attr=Toutput_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>; NodeDef: {{node TensorSliceDataset}} [Op:MapDataset]`

"
42009,Tensorflow lite model always gives same output no matter the input,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Using Google Collab platform for model development 
- TensorFlow installed from (source or binary): Installed from source 
- Tensorflow version (commit SHA if source): v2.1.1
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32 

My goal is to run a Keras model I have made in my ESP32 microcontroller. I have the libraries all working correctly.

I have created a Keras model using google Collab that looks to be working fine when I give it random test data within google Collab. The model has two input features and 4 different outputs.(a multiple-output regression model)

However, when I export and load the model into my c++ application in the ESP32 it does not matter what the inputs are, it always predicts the same output.

I have based myself in this code in order to load and run the model in c++ : https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/magic_wand/main_functions.cc

And this is my version of the code
```
namespace {
    tflite::ErrorReporter* error_reporter = nullptr;
    const tflite::Model* model = nullptr;
    tflite::MicroInterpreter* interpreter = nullptr;
    TfLiteTensor* input = nullptr;
    TfLiteTensor* output = nullptr;
    int inference_count = 0;

    // Create an area of memory to use for input, output, and intermediate arrays.
    // Finding the minimum value for your model may require some trial and error.
    constexpr int kTensorArenaSize = 2 * 2048;
    uint8_t tensor_arena[kTensorArenaSize];
}  // namespace 

```
```
static void setup(){
    static tflite::MicroErrorReporter micro_error_reporter;
    error_reporter = &micro_error_reporter;

    model = tflite::GetModel(venti_model);
    if (model->version() != TFLITE_SCHEMA_VERSION) {
        error_reporter->Report(
            ""Model provided is schema version %d not equal ""
            ""to supported version %d."",
            model->version(), TFLITE_SCHEMA_VERSION);
        return;
    }

    // This pulls in all the operation implementations we need.
    // NOLINTNEXTLINE(runtime-global-variables)
    static tflite::ops::micro::AllOpsResolver resolver;

    // Build an interpreter to run the model with.
    static tflite::MicroInterpreter static_interpreter(
            model, resolver, tensor_arena, kTensorArenaSize, error_reporter);
    interpreter = &static_interpreter;

    // Allocate memory from the tensor_arena for the model's tensors.
    TfLiteStatus allocate_status = interpreter->AllocateTensors();
    if (allocate_status != kTfLiteOk) {
        error_reporter->Report(""AllocateTensors() failed"");
        return;
    }

    // Obtain pointers to the model's input and output tensors.
    input = interpreter->input(0);

    ESP_LOGI(""TENSOR SETUP"", ""input size = %d"", input->dims->size);
    ESP_LOGI(""TENSOR SETUP"", ""input size in bytes = %d"", input->bytes);
    ESP_LOGI(""TENSOR SETUP"", ""Is input float32? = %s"", (input->type == kTfLiteFloat32) ? ""true"" : ""false"");
    ESP_LOGI(""TENSOR SETUP"", ""Input data dimentions = %d"",input->dims->data[1]);

    output = interpreter->output(0);

    ESP_LOGI(""TENSOR SETUP"", ""output size = %d"", output->dims->size);
    ESP_LOGI(""TENSOR SETUP"", ""output size in bytes = %d"", output->bytes);
    ESP_LOGI(""TENSOR SETUP"", ""Is input float32? = %s"", (output->type == kTfLiteFloat32) ? ""true"" : ""false"");
    ESP_LOGI(""TENSOR SETUP"", ""Output data dimentions = %d"",output->dims->data[1]);

}
```
```
static bool setupDone = true;

static void the_ai_algorithm_task(){

    /* First time task is init setup the ai model */
    if(setupDone == false){
        setup();
        setupDone = true;
    }

    /* Load the input data i.e deltaT1 and deltaT2 */
    //int i = 0;
    input->data.f[0] = 2.0;   /* Different values dont change the output */
    input->data.f[1] = 3.2;   


    // Run inference, and report any error
    TfLiteStatus invoke_status = interpreter->Invoke();
    if (invoke_status != kTfLiteOk) {
        error_reporter->Report(""Invoke failed"");
        // return;
    }

    /* Retrieve outputs Fan , AC , Vent 1 , Vent 2 */
    double fan = output->data.f[0];
    double ac = output->data.f[1];
    double vent1 = output->data.f[2];
    double vent2 = output->data.f[3];


    ESP_LOGI(""TENSOR SETUP"", ""fan = %lf"", fan);
    ESP_LOGI(""TENSOR SETUP"", ""ac = %lf"", ac);
    ESP_LOGI(""TENSOR SETUP"", ""vent1 = %lf"", vent1);
    ESP_LOGI(""TENSOR SETUP"", ""vent2 = %lf"", vent2);
    
}
```
The model seems to load ok as the dimensions and sizes are correct. But the output is always the same 4 values. The input are float32

```
fan = 0.0087
ac = 0.54
vent1 = 0.73
vent2 = 0.32
```
Any idea on what can be going wrong? Is it something about my model or am I just not using the model correctly in my c++ application?"
42008,assertion error on tf.random.normal() and tf.keras.layers.conv2D(),"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: NO
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 64 bit
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: NO
-   **TensorFlow installed from (source or binary)**: Source
-   **TensorFlow version (use command below)**: 2.1.0
-   **Python version**: 3.7.4
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**: 10.1
-   **GPU model and memory**: NVIDIA GeForce MX 250, 2GB
-   **Exact command to reproduce**:
** Following is the code I took from the official documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) after getting the exact here at tf.keras.layers.Conv2D traceback. 
![Capture](https://user-images.githubusercontent.com/53314831/89201564-50df9d00-d5cf-11ea-8f70-a0dd89fd182d.PNG)

input_shape = (4, 28, 28, 3)
x = tf.random.normal(input_shape)
y = tf.keras.layers.Conv2D(2, 3, activation='relu', input_shape=input_shape[1:])(x)
print(y.shape)

---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-403-88a6eef2a73d> in <module>
----> 1 tf.random.normal((2, 2))

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\ops\random_ops.py in random_normal(shape, mean, stddev, dtype, seed, name)
     67   """"""
     68   with ops.name_scope(name, ""random_normal"", [shape, mean, stddev]) as name:
---> 69     shape_tensor = tensor_util.shape_tensor(shape)
     70     mean_tensor = ops.convert_to_tensor(mean, dtype=dtype, name=""mean"")
     71     stddev_tensor = ops.convert_to_tensor(stddev, dtype=dtype, name=""stddev"")

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\tensor_util.py in shape_tensor(shape)
    992       # not convertible to Tensors becasue of mixed content.
    993       shape = tuple(map(tensor_shape.dimension_value, shape))
--> 994   return ops.convert_to_tensor(shape, dtype=dtype, name=""shape"")
    995 
    996 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1312 
   1313     if ret is None:
-> 1314       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1315 
   1316     if ret is NotImplemented:

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    315                                          as_ref=False):
    316   _ = as_ref
--> 317   return constant(v, dtype=dtype, name=name)
    318 
    319 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\constant_op.py in constant(value, dtype, shape, name)
    256   """"""
    257   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 258                         allow_broadcast=True)
    259 
    260 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    264   ctx = context.context()
    265   if ctx.executing_eagerly():
--> 266     t = convert_to_eager_tensor(value, ctx, dtype)
    267     if shape is None:
    268       return t

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
     93     except AttributeError:
     94       dtype = dtypes.as_dtype(dtype).as_datatype_enum
---> 95   ctx.ensure_initialized()
     96   return ops.EagerTensor(value, ctx.device_name, dtype)
     97 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\context.py in ensure_initialized(self)
    491       if self._initialized:
    492         return
--> 493       assert self._context_devices is None
    494       opts = pywrap_tensorflow.TFE_NewContextOptions()
    495       try:

AssertionError: 

"
42007,There are some repeated calls in the data_augmentation.ipynb！,"The location of the problem：/docs/site/en/tutorials/images/data_augmentation.ipynb
You can find it according to the mark of the picture：
![9371596469059_ pic_hd](https://user-images.githubusercontent.com/61530230/89200299-627e7000-d5e2-11ea-910e-50ee98f30cb8.jpg)
---
`image,label = convert(image, label)`  AND `image = tf.image.convert_image_dtype(image, tf.float32)`  are the same."
42006,error: 'std.constant' op requires attribute's type ('tensor<500x2450xf32>') to match op's return type ('tensor<*xf32>'),"Hello,
We are currently using TFlite to quantize our trained models with FP16 and INT8. When running the experiments the unquantized baseline and FP16 quantization seem to work, but with INT8 the logfile created gives us the following error and output: 
error: 'std.constant' op requires attribute's type ('tensor<500x2450xf32>') to match op's return type ('tensor<*xf32>')
00000000C1C040BD00000000000000000000000000000000C1C040BDC1C0403D00000000C1C0403D000000000000000000000000C1C0403D00000000000000000000000000000000C1C040BDC1C0403D00000000C1C0403D000000000000000000000000C1C0403DC1C0403D00000000C1C0403D00000000C1C040BDC1C0403DC1C0403D00000000000000000000000000000000…
We are running our experiments on the CPUs of a DGX1 and are using TF 2.3, is there anything we are missing?
Thank you!
"
42005,Tensorflow 2.0.0 error,"---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\anaconda3\envs\iNeuron\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\anaconda3\envs\iNeuron\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-5-d6579f534729> in <module>
----> 1 import tensorflow

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\karti\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\karti\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\karti\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\karti\anaconda3\envs\iNeuron\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\karti\anaconda3\envs\iNeuron\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime."
42004,KeyError on concrete_functions while loading a model,"**System information**
- Have I written custom code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b
- Python version: 3.7.7
- CUDA/cuDNN version: 10.0 / 7.6
- GPU model and memory: Nvidia Quadro P1000, 4GB

**Describe the current behavior**
When loading a SavedModel object, function_deserialization.py#265 (`concrete_function_objects.append(concrete_functions[concrete_function_name])`) throws a `KeyError` exception caused from looking for a concrete function which is not in the SavedModel (was not serialised). In my case the missing functions are called
1. `__inference_my_model_layer_call_fn_37929`
2. `__inference_my_model_layer_call_fn_38165`
All other concrete functions are successfully located and recovered.

The call traces back to `saved_model/load.py` at line 604. Yet when I debug the values in `object_graph_proto` I can't see these missing keys, meaning they're added at a later phase.
I also tried changing the original code line to
```python
        try:
            concrete_function_objects.append(concrete_functions[concrete_function_name])
        except KeyError:
            print(
                f'from saved_model/function_deserialization.py: couldnt find concrete function {concrete_function_name}'
            )
            continue
        print(
            f'from saved_model/function_deserialization.py: found concrete function {concrete_function_name}'
        )
```
It indeed shows that only these two functions are not found while all other ones are there. Also by doing that I can use the model for testing and inference, i.e. I see no limited functionality at the moment.
Notice there are two similarly-named functions in `concrete_functions` called
1. `__inference_my_model_layer_call_and_return_conditional_losses_35962`
2. `__inference_my_model_layer_call_and_return_conditional_losses_37693`

I guess there are two functions there as one originates from the training function and the other is related to the cross validation function.

My `MyModel` object extends Keras' Model class and contains a series of Models and Layers which are called in the `call` function. `MyModel` doesn't have any paramters or variables of its own. The last object in the series (an object extending `Layer`) also uses `self.add_loss` in its `call` function.

**Describe the expected behavior**
Model should load and work properly.

**Standalone code to reproduce the issue**
Not easy to do since the model structure is rather complicated.

**Other info / logs** Include any logs or source code that would be helpful to
The output without my workaround:
```
Traceback (most recent call last):
  File ""test.py"", line 148, in <module>
    main()
  File ""test.py"", line 107, in main
    model = tf.keras.models.load_model(model_path)
  File ""tensorflow\python\keras\saving\save.py"", line 190, in load_model
    return saved_model_load.load(filepath, compile)
  File ""tensorflow\python\keras\saving\saved_model\load.py"", line 116, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""tensorflow\python\saved_model\load.py"", line 604, in load_internal
    export_dir)
  File ""tensorflow\python\keras\saving\saved_model\load.py"", line 188, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File ""tensorflow\python\saved_model\load.py"", line 123, in __init__
    self._load_all()
  File ""tensorflow\python\keras\saving\saved_model\load.py"", line 212, in _load_all
    super(KerasObjectLoader, self)._load_all()
  File ""tensorflow\python\saved_model\load.py"", line 134, in _load_all
    self._load_nodes()
  File ""tensorflow\python\saved_model\load.py"", line 264, in _load_nodes
    node, setter = self._recreate(proto, node_id)
  File ""tensorflow\python\keras\saving\saved_model\load.py"", line 233, in _recreate
    obj, setter = super(KerasObjectLoader, self)._recreate(proto, node_id)
  File ""tensorflow\python\saved_model\load.py"", line 370, in _recreate
    return factory[kind]()
  File ""tensorflow\python\saved_model\load.py"", line 359, in <lambda>
    ""function"": lambda: self._recreate_function(proto.function),
  File ""tensorflow\python\saved_model\load.py"", line 398, in _recreate_function
    proto, self._concrete_functions), setattr
  File ""tensorflow\python\saved_model\function_deserialization.py"", line 265, in recreate_function
    concrete_function_objects.append(concrete_functions[concrete_function_name])
KeyError: '__inference_my_model_layer_call_fn_37929'
```
"
42003,Please add Tensorflow 2.3 GPU and all subsequent versions to Conda package manager for Windows and Linux,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): No because I do not think I can



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**
This will change the current API. It will add the latest version of TensorFlow to Conda. 
**Who will benefit with this feature?**
Anyone who wants to get started with TensorFlow GPU fast or wants to have multiple versions of TensorFlow GPU across multiple environments because when you install TensorFlow-GPU from Conda, it automatically installs CUDA and cuDNN for that specific virtual environment. 
**Any Other info.**
As of right now, only version 2.1 is there for windows and 2.2 for Linux as seen [https://anaconda.org/anaconda/tensorflow-gpu](here)"
42002,tf.nn.conv2d_transpose name is overwritten,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): TF 2.2
- TensorFlow version: v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.7
- CUDA/cuDNN version: 10.2 .76
- GPU model and memory:

**Describe the current behavior**
conv2d_transpose output tensor name is Conv2DBackpropInput:0

**Describe the expected behavior**
conv2d_transpose output tensor name should be ct:0

**Standalone code to reproduce the issue**
import numpy as np
import tensorflow as tf
from tensorflow.keras import Input, Model


inputs = Input(shape=(32, 32, 3), name='net_input')
w0 = tf.Variable(np.ones((4, 4, 3, 6)).astype(np.float32)/16/16, name='w0')
c0 = tf.nn.conv2d(inputs, w0, 2, ""SAME"", name='conv0')
r0 = tf.nn.relu(c0, name='relu0')

wt = tf.Variable(np.ones((3, 3, 6, 6)).astype(np.float32)/16/16, name='wt')
ct = tf.nn.conv2d_transpose(r0, wt, (1, 16, 16, 6), strides=1, name='ct')
rt = tf.nn.relu(ct, name='relut')

wt2 = tf.Variable(np.ones((3, 3, 6, 6)).astype(np.float32)/16/16, name='wt2')
ct2 = tf.nn.conv2d_transpose(rt, wt2, (1, 16, 16, 6), strides=1, name='ct2')
rt2 = tf.nn.relu(ct2, name='relut2')

w1 = tf.Variable(np.ones((16, 16, 6, 4)).astype(np.float32)/16/16, name='w1')
c1 = tf.nn.conv2d(rt2, w1, 1, ""VALID"", name='conv1')
out = tf.nn.relu(c1, name='relu1')

m = Model(inputs=inputs, outputs=out, name='test')
print(ct.name)"
42001,tf.string.format is not returning Unicode characters,"As also described in [this Stackoverflow post](https://stackoverflow.com/questions/59795552/tf-string-format-is-not-returning-unicode-characters), when a string passes through `tf.strings.format` unicode characters are not represented correctly.

```python
import tensorflow as tf

print(tf.constant('😊:😊').numpy().decode('utf-8')) # output: 😊:😊
print(tf.strings.format(""😊:{}"", tf.constant('😊')).numpy().decode('utf-8')) # output: 😊:""\\360\\237\\230\\212"" 
```

Error observed in tensorflow 2.2 and 2.3"
42000,Report error 'non-first' call when repeate experiment,"Question: The code can successfully run when using autograph for acceleration, whereas it reports 'optimizer non-first call'  error when I repeat the experiment multiple times(10 in the sample code), which confused me.
 The code logic is as follows：
--------------------------------------------
```
 for i in np.arange(10):
       run_flow(random_seed=i)

def run_flow(random_seed=0):
      optimizer = tf.keras.optimizers.Adam()
      for i in num_epoch:
           train_epoch(optimizer)

def train_epoch(optimzier):
      for i in num_batchs:
            train_step(optimizer)

@tf.function
def train_step(optimizer)
      # .....
      optimizer.apply_gradients(...)
```
----------------------------------------------
Clearly, the definition-optimizer  is outside the function-train_step."
41999,tf.GradientTape() doesn't work on sliced outputs,"Here is a piece of code which I tried to run:
```
import tensorflow as tf

a = tf.constant([[1, 2], [2, 3]], dtype=tf.float32)
b = tf.constant([[1, 2], [2, 3]], dtype=tf.float32)

with tf.GradientTape() as tape1, tf.GradientTape() as tape2:
    tape1.watch(a)
    tape2.watch(a)
    
    c = a * b

grad1 = tape1.gradient(c, a)
grad2 = tape2.gradient(c[:, 0], a)
print(grad1)
print(grad2)
```
And this is the output:
```
tf.Tensor(
[[1. 2.]
 [2. 3.]], shape=(2, 2), dtype=float32)
None
```
As you can see that tf.GradientTape() is not working with sliced outputs. Is there any way around to this?"
41998,tf.nn.conv2d_transpose name is overridden,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
If you use this conv2d_transpose with a name, it chooses another name, with BackProp as substring
**Describe the expected behavior**
I want the supplied name to be the name of the convolution.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41997,Need to build tensorflow version 2.1.0 from source on Windows,"
**System information**
- OS Platform and Distribution : Windows 10
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.1
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source):

**Describe the problem**
I want to build tensorflow 2.1.0 from source. Github Branch r2.1 builts tensorflow version 2.1.1 by default. May I know how to explicitly give the tensorflow version for compilation ?

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
41996,Tensorflow Build Failure with Bazel,"**Apologies in advance for the text dump**

I am attempting to compile Tensorflow in OSX 10.13.4 using Bazel based on these instructions:
https://medium.com/xplore-ai/nvidia-egpu-macos-tensorflow-gpu-the-definitive-setup-guide-to-avoid-headaches-f40e831f26ea

I attempted the build using the following command: 
`bazel build --config=cuda --config=opt --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env PATH --action_env LD_LIBRARY_PATH --action_env DYLD_LIBRARY_PATH //tensorflow/tools/pip_package:build_pip_package`

Here are the versions of all relevant programs:
Python: 3.6
CUDA: 10.0
cuDNN: 7.4
Tensorflow: https://github.com/zylo117/tensorflow-gpu-macosx
GPU: NVIDIA GTX 980
Bazel Version: 0.16.1

Here is the verbose error information along with some run info:

5 warnings generated.

```
ERROR: /Users/brianmoser/tensorflow-gpu-macosx/tensorflow/core/kernels/BUILD:3423:1: error while parsing .d file: /private/var/tmp/_bazel_brianmoser/9608e82147ff56f68b42fd19bee93cb0/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/core/kernels/_objs/bincount_op_gpu/bincount_op_gpu.cu.d (No such file or directory)

nvcc fatal : The version ('10.0') of the host compiler ('Apple clang') is not supported

Target //tensorflow/tools/pip_package:build_pip_package failed to build

Use --verbose_failures to see the command lines of failed build steps.

INFO: Elapsed time: 1407.017s, Critical Path: 63.10s

INFO: 2389 processes: 2389 local.

FAILED: Build did NOT complete successfully
```

Additionally, here is the final step the build conducted:

`tensorflow/stream_executor/cuda/cuda_dnn.cc:1506:19: warning: private field 'data_type_' is not used [-Wunused-private-field]
  cudnnDataType_t data_type_;
`

Finally, here is the final relevant information:

```
git rev-parse HEAD

795d7c36152a1f96adca0c48f4537e500f5ad36b
```
```

bazel version

Build label: 0.16.1

```
Build target: 
`bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar`

Does anybody have any idea what could be the reason for this error?"
41993,E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_EXECUTION_FAILED,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04
- TensorFlow installed from (source or binary): Latest
- TensorFlow version (use command below): Latest
- Python version: 3.8.1
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: 11.0
- GPU model and memory: RTX 2070

https://www.tensorflow.org/tutorials/structured_data/time_series

E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_EXECUTION_FAILED
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1831): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
2020-08-02 22:58:40.548649: W tensorflow/core/framework/op_kernel.cc:1772] OP_REQUIRES failed at cudnn_rnn_ops.cc:1517 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 19, 32, 1, 24, 32, 32] 


"
41992,CNN convolution neural network problem,Why do we define the weights of CNN convolutions neural networks with normal distribution，is it because of the central limit theorem？
41991,ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed. Failed to load the native TensorFlow runtime. ,"I'm receiving this error message when importing keras: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow'

When I downgrade to keras 2.3.1, I receive the following error ""ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.""  

Stackoverflow link: https://stackoverflow.com/questions/63209972/error-while-loading-keras-2-4-3-for-tensorflow-2-2?noredirect=1#comment111793997_63209972

###update as of 8/2/2020###
I've narrowed the problem down to the c:\windows\system32\msvcp140_1.dll file.  The file is not read-only and everyone has full permissions on the file.  I've tried condas install and reinstalling C++ redistrib packages and still receive the same error message that the DLL can't initialize. 

import struct
print(""Python version: "" + str(8 * struct.calcsize(""P"")))  # outputs 64
print(""loading keras.layers..."")
from keras.layers import Input, LSTM, Dense
print(""loading keras.models..."")
from keras.models import Model
print(""loading nltk.corpus..."")
from nltk.corpus import stopwords
------------------------

### System information

Windows Server 2012 R12 x64 (VM)
python 3.8.3 x64
Keras 3.4.1 or 3.2.1
tensorflow 2.2
C++ redistribution
No GPU

##### Error Message When Laucnhing the above Test Script ####

Traceback (most recent call last):
  File ""C:\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", lin
e 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dyna
mic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Python\lib\site-packages\tensorflow\__init__.py"", line 41, in <module
>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Python\lib\site-packages\tensorflow\python\__init__.py"", line 40, in
<module>
    from tensorflow.python.eager import context
  File ""C:\Python\lib\site-packages\tensorflow\python\eager\context.py"", line 35
, in <module>
    from tensorflow.python import pywrap_tfe
  File ""C:\Python\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, i
n <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", lin
e 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Python\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", lin
e 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dyna
mic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
41990,CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid?,"

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: v2.3.0-rc2-23-gb36436b087 2.3.0
-   **Python version**: 3.8.2
-   **CUDA/cuDNN version**: Cuda 10.1/ cuDNN 7.6.5
-   **GPU model and memory**: Nvidia GTX 750Ti
-   **Exact command to reproduce**: 

```
# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
train_images = train_images / 255.0
test_images = test_images / 255.0

# At this step I was getting the error which I've posted below in the terminal.

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10)
])
```


### Describe the problem
I've recently installed ubuntu 20.04 LTS and it comes with python-3.8, so I'll installed **nvidia-cuda-toolkit** and **nvidia drivers** and I can confirm they are working fine.

```
$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
```
```
$ nvidia-smi
Mon Aug  3 02:56:11 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 750 Ti  Off  | 00000000:01:00.0  On |                  N/A |
| 27%   38C    P0     1W /  38W |    245MiB /  1997MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0       979      G   /usr/lib/xorg/Xorg                            20MiB |
+-----------------------------------------------------------------------------+

```

Now, I tried to build a small sequential model I am getting an error which says `InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid`

I don't know what causing the issue. My linux ubuntu is a new installation. I have installed everything correctly.

### Source code / logs
```
2020-08-03 02:48:40.720575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-08-03 02:48:40.750630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 750 Ti computeCapability: 5.0
coreClock: 1.137GHz coreCount: 5 deviceMemorySize: 1.95GiB deviceMemoryBandwidth: 80.47GiB/s
2020-08-03 02:48:40.750735: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-03 02:48:40.791690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-03 02:48:40.815993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-03 02:48:40.821924: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-03 02:48:40.863910: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-03 02:48:40.870559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-03 02:48:40.945916: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-03 02:48:40.947130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-03 02:48:40.979471: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3311130000 Hz
2020-08-03 02:48:40.980123: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4aa6700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-03 02:48:40.980190: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-03 02:48:41.121266: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49375f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-03 02:48:41.121357: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 750 Ti, Compute Capability 5.0
2020-08-03 02:48:41.122574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 750 Ti computeCapability: 5.0
coreClock: 1.137GHz coreCount: 5 deviceMemorySize: 1.95GiB deviceMemoryBandwidth: 80.47GiB/s
2020-08-03 02:48:41.122676: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-03 02:48:41.122762: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-03 02:48:41.122830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-03 02:48:41.122898: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-03 02:48:41.122963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-03 02:48:41.123029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-03 02:48:41.123145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-03 02:48:41.124618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-03 02:48:41.124716: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1

---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
<ipython-input-4-ac4dc71cdd20> in <module>
----> 1 model = keras.Sequential([
      2     keras.layers.Flatten(input_shape=(28, 28)),
      3     keras.layers.Dense(128, activation='relu'),
      4     keras.layers.Dense(10)
      5 ])

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in __init__(self, layers, name)
    114     """"""
    115     # Skip the init in FunctionalModel since model doesn't have input/output yet
--> 116     super(functional.Functional, self).__init__(  # pylint: disable=bad-super-call
    117         name=name, autocast=False)
    118     self.supports_masking = True

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in __init__(self, *args, **kwargs)
    306     self._steps_per_execution = None
    307 
--> 308     self._init_batch_counters()
    309     self._base_model_initialized = True
    310     _keras_api_gauge.get_cell('model').set(True)

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _init_batch_counters(self)
    315     # `evaluate`, and `predict`.
    316     agg = variables.VariableAggregationV2.ONLY_FIRST_REPLICA
--> 317     self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
    318     self._test_counter = variables.Variable(0, dtype='int64', aggregation=agg)
    319     self._predict_counter = variables.Variable(

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    260       return cls._variable_v1_call(*args, **kwargs)
    261     elif cls is Variable:
--> 262       return cls._variable_v2_call(*args, **kwargs)
    263     else:
    264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)
    242     if aggregation is None:
    243       aggregation = VariableAggregation.NONE
--> 244     return previous_getter(
    245         initial_value=initial_value,
    246         trainable=trainable,

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)
    235                         shape=None):
    236     """"""Call on Variable class. Useful to force the signature.""""""
--> 237     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
    238     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access
    239       previous_getter = _make_getter(getter, previous_getter)

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)
   2631   shape = kwargs.get(""shape"", None)
   2632 
-> 2633   return resource_variable_ops.ResourceVariable(
   2634       initial_value=initial_value,
   2635       trainable=trainable,

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    262       return cls._variable_v2_call(*args, **kwargs)
    263     else:
--> 264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)
    265 
    266 

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)
   1505       self._init_from_proto(variable_def, import_scope=import_scope)
   1506     else:
-> 1507       self._init_from_args(
   1508           initial_value=initial_value,
   1509           trainable=trainable,

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)
   1648         with ops.get_default_graph()._attr_scope({""_class"": attr}):
   1649           with ops.name_scope(""Initializer""), device_context_manager(None):
-> 1650             initial_value = ops.convert_to_tensor(
   1651                 initial_value() if init_from_fn else initial_value,
   1652                 name=""initial_value"", dtype=dtype)

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1497 
   1498     if ret is None:
-> 1499       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1500 
   1501     if ret is NotImplemented:

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py in _default_conversion_function(***failed resolving arguments***)
     50 def _default_conversion_function(value, dtype, name, as_ref):
     51   del as_ref  # Unused.
---> 52   return constant_op.constant(value, dtype, name=name)
     53 
     54 

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)
    261     ValueError: if called on a symbolic tensor.
    262   """"""
--> 263   return _constant_impl(value, dtype, shape, name, verify_shape=False,
    264                         allow_broadcast=True)
    265 

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    273       with trace.Trace(""tf.constant""):
    274         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
--> 275     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    276 
    277   g = ops.get_default_graph()

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    298 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):
    299   """"""Implementation of eager constant.""""""
--> 300   t = convert_to_eager_tensor(value, ctx, dtype)
    301   if shape is None:
    302     return t

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
     95     except AttributeError:
     96       dtype = dtypes.as_dtype(dtype).as_datatype_enum
---> 97   ctx.ensure_initialized()
     98   return ops.EagerTensor(value, ctx.device_name, dtype)
     99 

/mnt/Work/work_env/lib/python3.8/site-packages/tensorflow/python/eager/context.py in ensure_initialized(self)
    537         if self._use_tfrt is not None:
    538           pywrap_tfe.TFE_ContextOptionsSetTfrt(opts, self._use_tfrt)
--> 539         context_handle = pywrap_tfe.TFE_NewContext(opts)
    540       finally:
    541         pywrap_tfe.TFE_DeleteContextOptions(opts)

InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid
```
"
41989,Weird dash lines on ImageProjectiveTransformV2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 (Google Colab)
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3
- Python version: 3.6.9

**Describe the current behavior**
I used these transform values
```
transform = [
             [1, 0.027, -4.905, -0.025, 1.096, 4.518, 0, 0],
             [1.041, 0.01, -10.256, -0.01, 1, -0.67, 0, 0],
             [1, 0, 0, 0, 1.06, -2.536, 0, 0]
]
```
but the resulting images got.... weird dash lines. To view the images, you can open my notebook from link on the standalone code section.

**Describe the expected behavior**
It should be seamless without weird lines?

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1z6zDhE6ikQr-aYHluxvlrpOhriztOmB0?usp=sharing

**Other question**
https://github.com/tensorflow/tensorflow/blob/4910e8e8ed56af3779eaa88449631a7855d4815e/tensorflow/core/kernels/image_ops.cc#L61-L83
Also is this is only logging? It's not stopping me entering random string into `fill_mode` and `interpolation` parameters?

**Speculation**
My speculation is, it seems like the code responsible for map the coordinate miss by 1 pixel? I tried to understand `image_ops` code but I don't get which one it is."
41988,Facing issues while importing 'network' from 'tensorflow.python.keras.engine',"
On Tensorflow 2.3.0
Anaconda Environment.
```
from tf_agents.environments import suite_gym



ImportError                               Traceback (most recent call last)
<ipython-input-8-b9cd8ac2787f> in <module>
----> 1 from tf_agents.environments import suite_gym
      2 
      3 # env = suite_gym.load(""Breakout-v4"")
      4 # env

~\AppData\Roaming\Python\Python38\site-packages\tf_agents\environments\__init__.py in <module>
     24 from tf_agents.environments import tf_py_environment
     25 from tf_agents.environments import trajectory_replay
---> 26 from tf_agents.environments import utils
     27 from tf_agents.environments import wrappers

~\AppData\Roaming\Python\Python38\site-packages\tf_agents\environments\utils.py in <module>
     23 from tf_agents.environments import tf_environment
     24 from tf_agents.environments import tf_py_environment
---> 25 from tf_agents.policies import random_py_policy
     26 from tf_agents.specs import array_spec
     27 

~\AppData\Roaming\Python\Python38\site-packages\tf_agents\policies\__init__.py in <module>
     16 """"""Policies Module.""""""
     17 
---> 18 from tf_agents.policies import actor_policy
     19 from tf_agents.policies import boltzmann_policy
     20 from tf_agents.policies import epsilon_greedy_policy

~\AppData\Roaming\Python\Python38\site-packages\tf_agents\policies\actor_policy.py in <module>
     27 import tensorflow_probability as tfp
     28 
---> 29 from tf_agents.networks import network
     30 from tf_agents.policies import tf_policy
     31 from tf_agents.specs import tensor_spec

~\AppData\Roaming\Python\Python38\site-packages\tf_agents\networks\__init__.py in <module>
     16 """"""Networks Module.""""""
     17 
---> 18 from tf_agents.networks import actor_distribution_network
     19 from tf_agents.networks import actor_distribution_rnn_network
     20 from tf_agents.networks import bias_layer

~\AppData\Roaming\Python\Python38\site-packages\tf_agents\networks\actor_distribution_network.py in <module>
     24 import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import
     25 
---> 26 from tf_agents.networks import categorical_projection_network
     27 from tf_agents.networks import encoding_network
     28 from tf_agents.networks import network

~\AppData\Roaming\Python\Python38\site-packages\tf_agents\networks\categorical_projection_network.py in <module>
     24 import tensorflow_probability as tfp
     25 
---> 26 from tf_agents.networks import network
     27 from tf_agents.networks import utils
     28 from tf_agents.specs import distribution_spec

~\AppData\Roaming\Python\Python38\site-packages\tf_agents\networks\network.py in <module>
     31 
     32 # pylint:disable=g-direct-tensorflow-import
---> 33 from tensorflow.python.keras.engine import network as keras_network  # TF internal
     34 from tensorflow.python.training.tracking import base  # TF internal
     35 from tensorflow.python.util import tf_decorator  # TF internal

ImportError: cannot import name 'network' from 'tensorflow.python.keras.engine' (C:\Users\asus\anaconda3\envs\tf2\lib\site-packages\tensorflow\python\keras\engine\__init__.py)
```

Tried Reinstalling TF. The issue still persists.
Tried running on TF 2.2, it asks me to upgrade.
"
41987,NotFoundError:  No algorithm worked! .... convolutional model,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04
- TensorFlow installed from (source or binary): Latest as of today
- TensorFlow version (use command below): 2.4.0
- Python version: 3.8.0
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0
- GPU model and memory: RTX 2070

The sample code to debug this issue is at,
https://www.tensorflow.org/tutorials/structured_data/time_series

NotFoundError:  No algorithm worked!
	 [[node sequential_3/conv1d/conv1d (defined at <ipython-input-42-716049f06cb3>:12) ]] [Op:__inference_train_function_127130]

Function call stack:
train_function

"
41986,"Typo on the order number for title on guide ""Automatic Differentiation""","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://tensorflow.google.cn/guide/autodiff

## Description of issue (what needs changing):

When listing the reason of the ""None"" gradient (Chapter of ""Getting a gradient of None""), the text  ""**3. Took gradients through an integer or string**"" is followed by order number ""5"", which is ""**5. Took gradients through a stateful object**"". Suggest to correct it to  ""**4. Took gradients through a stateful object**""

"
41985,Posenet when change to front facing camera displays the camera preview upside down. ,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Microsoft Windows 10 64-bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: all


**Describe the current behavior**

As in the current behaviour the app displays the camera preview with upside down orientation from the front facing camera.
( According to the example code provided for posenet sample app. )

**Describe the expected behavior**

It should displays the camera preview as perfect and well oriented as it shows from the back facing camera.

Please help as i have working on something important."
41983,Bug in Saved Tensorflow model,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Model training has unexplainable impact on older models saved on disk. I saved 1 tensorflow model(let's say 'best_model.h5') onto the disk which when loaded and evaluated gave me correct results. However, we I retrained my model which I didn't save to disk and then loaded my older model (i.e. the saved model 'best_model.h5'); the model evaluation results of saved model differed from the earlier load.
E.g with steps.
Step 1. Took UCI data for binary sentiment classification.
Step 2. Data Preparation -> Tokenize and Padded sequences of text.
Step 3. Simple NN architecture with Embedding, GlobalAveragePooling1D() and output Dense layer.
Step 4. Evaluated the model on Test data. Accuracy 83%
Step 5. Saved the model as 'best_model.h5'
Step 6. Loaded the 'best_model.h5' model and evaluated in Test Data. Accuracy 83%.
Step 7. Repeated all above steps except Step 5. Step 4 gave accuracy 81% and Step 6 gave accuracy 92%.
**Describe the expected behavior**
In the rerun as explained in Step 7 above, Step 6 should have maintained the accuracy of 83% instead it gave a different accuracy.
**Standalone code to reproduce the issue**
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

df=pd.read_csv('imdb_labelled.txt', sep='\t', header=None)
df.columns=['text', 'sentiment']

text=df.text.values
labels=df.sentiment.values

num_tokens=2000
max_len=20

tokenize=Tokenizer(num_words=num_tokens, oov_token='<OOV>')
tokenize.fit_on_texts(text)
sentences=tokenize.texts_to_sequences(text)

text_padded = pad_sequences(sentences, maxlen=max_len, padding='post', truncating='post')

X_train, X_test, y_train, y_test = train_test_split(text_padded, labels, test_size = 0.25)

initializer1 = tf.keras.initializers.GlorotUniform(seed=37)
initializer2 = tf.keras.initializers.GlorotNormal(seed=41)
model=tf.keras.Sequential([
                           tf.keras.layers.Embedding(num_tokens, 16, input_length=max_len, embeddings_initializer=initializer1),
                           tf.keras.layers.GlobalAveragePooling1D(),
                           tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=initializer2)
])

model.summary()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, batch_size=16, epochs=30, verbose=0)

y_pred=np.round(model.predict(X_test))

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))

Model: ""sequential_90""
Layer (type)                 Output Shape              Param 
embedding_91 (Embedding)     (None, 20, 16)            32000     
global_average_pooling1d_91  (None, 16)                0         
dense_90 (Dense)             (None, 1)                 17        
Total params: 32,017
Trainable params: 32,017
Non-trainable params: 0

Confusion matrix when trained again.
========================
[[65 20]
 [25 77]]
              precision    recall  f1-score   support

           0       0.72      0.76      0.74        85
           1       0.79      0.75      0.77       102

    accuracy                           0.76       187
   macro avg       0.76      0.76      0.76       187
weighted avg       0.76      0.76      0.76       187

0.7593582887700535

### Commented the model.save below to avoid overwrite of earlier saved model of 75.93%.
'# model.save('best_model.h5')
saved_model=tf.keras.models.load_model('best_model.h5')
saved_model.summary()
sm_y_pred=np.round(saved_model.predict(X_test))

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(confusion_matrix(y_test,sm_y_pred))
print(classification_report(y_test,sm_y_pred))
print(accuracy_score(y_test, sm_y_pred))

loss, acc = saved_model.evaluate(X_test,  y_test, verbose=2)
print('Restored model, accuracy: {:5.2f}%'.format(100*acc))

Model: ""sequential""
Layer (type)                 Output Shape              Param #   
embedding (Embedding)        (None, 20, 16)            32000     
global_average_pooling1d (Gl (None, 16)                0         
dense (Dense)                (None, 1)                 17        

Total params: 32,017
Trainable params: 32,017
Non-trainable params: 0

Confusion matrix of saved model.  Earlier the accuracy of saved model was 75.93% when initially saved.
==================================================================
[[89  7]
 [ 9 82]]
              precision    recall  f1-score   support

           0       0.91      0.93      0.92        96
           1       0.92      0.90      0.91        91

    accuracy                           0.91       187
   macro avg       0.91      0.91      0.91       187
weighted avg       0.91      0.91      0.91       187

0.9144385026737968
187/187 - 0s - loss: 0.3531 - accuracy: 0.9144
Restored model, accuracy: 91.44%

## The saved model predictions improved magically to 91.44%.

Attaching the dataset used by the code.
==========================
[imdb_labelled.txt](https://github.com/tensorflow/tensorflow/files/5012013/imdb_labelled.txt)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41982,"I could do import tensorflow as tf with no problem, but the library keeps returning errors when used","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.1.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: installed using pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA (10.1), cuDNN(7.6.4)
- GPU model and memory:
NVIDIA GeForce GTX 1050 with Max-Q Design


**Describe the problem**
I could import tensorflow with no problem, but when I used the library, it returns errors.
These are my tf library versions
tensorboard                        2.1.1
tensorboard-plugin-wit             1.7.0
tensorflow                         2.1.0
tensorflow-estimator               2.1.0
tensorflow-gpu                     2.1.0
tensorflow-gpu-estimator           2.1.0

**Provide the exact sequence of commands / steps that you executed before running into the problem**

import tensorflow as tf
tf. __version__ (it is bolded because of the double underscore)

**Any other info / logs**

ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-8-a0ebd646edc3>"", line 7, in <module>
    tf.__version__
AttributeError: module 'tensorflow' has no attribute '__version__'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'AttributeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\user\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\user\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1101, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\Users\user\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\Users\user\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\Users\user\Anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\user\Anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\user\Anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\user\Anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\user\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\user\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-8-a0ebd646edc3>"", line 7, in <module>
    tf.__version__
AttributeError: module 'tensorflow' has no attribute '__version__'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'AttributeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\user\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\user\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
---------------------------------------------------------------------------"
41980,Large batch size with dense layers will fail all_reduce occasionally,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
  os: Linux
  os kernel version: #1 SMP Debian 4.9.210-1 (2020-01-20)
  os release version: 4.9.0-12-amd64
  os platform: Linux-4.9.0-12-amd64-x86_64-with-debian-9.12
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla P100-PCIE-16GB (on Google Cloud Platform)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I tried to use the SyncBatchnormalization (tf.keras.layers.experimental.SyncBatchNormalization) in my models but I found it will result in NaN in the model sometimes. Thus I decided to take a closer look. In the below code I implemented a simple SyncBatchnormalization. And I found when the batch size is very large (e.g. 262144) for dense layers (which is the case for the sub-module in my model), the `all_reduce` will occasionally result in wrong results.

**Describe the expected behavior**
`all_reduce` results in correct results at all times.

**Standalone code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf
from tensorflow.python.distribute import distribution_strategy_context as ds
from tensorflow.python.distribute import reduce_util
from tensorflow.python.keras.layers import normalization


class SyncBatchNormalization(normalization.BatchNormalizationBase):
    """"""The SyncBatchNormalization in TF 2.2 seems causing NaN issue.
    We implement this one to avoid the issue.
    See https://github.com/google-research/simclr/blob/bfe07eed7f101ab51f3360100a28690e1bfbf6ec/resnet.py#L37-L85
    """"""

    def __init__(self,
                 axis=-1,
                 momentum=0.99,
                 epsilon=1e-3,
                 center=True,
                 scale=True,
                 beta_initializer='zeros',
                 gamma_initializer='ones',
                 moving_mean_initializer='zeros',
                 moving_variance_initializer='ones',
                 beta_regularizer=None,
                 gamma_regularizer=None,
                 beta_constraint=None,
                 gamma_constraint=None,
                 renorm=False,
                 renorm_clipping=None,
                 renorm_momentum=0.99,
                 trainable=True,
                 adjustment=None,
                 name=None,
                 **kwargs):
        # Currently we only support aggregating over the global batch size.
        super(SyncBatchNormalization, self).__init__(
            axis=axis,
            momentum=momentum,
            epsilon=epsilon,
            center=center,
            scale=scale,
            beta_initializer=beta_initializer,
            gamma_initializer=gamma_initializer,
            moving_mean_initializer=moving_mean_initializer,
            moving_variance_initializer=moving_variance_initializer,
            beta_regularizer=beta_regularizer,
            gamma_regularizer=gamma_regularizer,
            beta_constraint=beta_constraint,
            gamma_constraint=gamma_constraint,
            renorm=renorm,
            renorm_clipping=renorm_clipping,
            renorm_momentum=renorm_momentum,
            fused=False,
            trainable=trainable,
            virtual_batch_size=None,
            name=name,
            **kwargs)

    def _calculate_mean_and_var(self, inputs, reduction_axes, keep_dims):
        shard_mean, shard_variance = super(SyncBatchNormalization, self)._calculate_mean_and_var(
            inputs, reduction_axes, keep_dims=keep_dims)
        replica_ctx = ds.get_replica_context()
        if replica_ctx:
            group_mean, group_variance = replica_ctx.all_reduce(reduce_util.ReduceOp.MEAN, [shard_mean, shard_variance])
            mean_distance = tf.math.squared_difference(tf.stop_gradient(group_mean), shard_mean)
            group_variance += replica_ctx.all_reduce(reduce_util.ReduceOp.MEAN, mean_distance)
            tf.cond(tf.reduce_mean(group_variance) > 50,
                    lambda: tf.print(
                        f""\n{self.name} id"", replica_ctx.replica_id_in_sync_group, ""/"",
                        replica_ctx.num_replicas_in_sync, ""\n"",
                        ""local mean distance:"", mean_distance, ""mean local mean distance"",
                        tf.reduce_mean(mean_distance), ""\n"",
                        ""group var:"", group_variance, ""mean group var:"", tf.reduce_mean(group_variance), ""\n"",
                        ""local var:"", shard_variance, ""mean local var:"", tf.reduce_mean(shard_variance), ""\n"",
                        ""group mean:"", group_mean, ""mean group mean"", tf.reduce_mean(group_mean), ""\n"",
                        ""local mean:"", shard_mean, ""mean local mean"", tf.reduce_mean(shard_mean), ""\n"",
                        ""size:"", tf.shape(shard_mean)),
                    lambda: tf.no_op()
                    )
            return group_mean, group_variance
        else:
            return shard_mean, shard_variance


class Test(tf.keras.models.Model):
    def __init__(self):
        super(Test, self).__init__()
        self.mlps = []
        for i in range(10):
            self.mlps.append(tf.keras.Sequential([
                tf.keras.layers.Dense(512),
                SyncBatchNormalization(),
                tf.keras.layers.ReLU(),
                tf.keras.layers.Dense(256),
                SyncBatchNormalization(),
                tf.keras.layers.ReLU(),
                tf.keras.layers.Dense(128),
            ]))
        self.head = tf.keras.layers.Dense(10)

    def call(self, inputs, training=None, mask=None):
        out = []
        for mlp in self.mlps:
            out.append(mlp(inputs))
        return self.head(tf.concat(out, axis=-1))


dummy_data = np.random.random((2621440, 3)).astype(np.float32) * 6 - 3
dummy_label = np.random.randint(0, 10, 2621440).astype(np.int32)
# print(dummy_label.shape)
dataset = tf.data.Dataset.from_tensor_slices((dummy_data, dummy_label)).batch(262144)

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    model = Test()
    model.compile(
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        optimizer=tf.keras.optimizers.Adam(learning_rate=0)
    )
    model.fit(dataset, epochs=10000)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Here I paste the outputs when the code runs on a machine with 4 P100 GPUs:
```
$ python test_syncbn.py
2020-08-02 00:12:57.236317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-02 00:12:58.708082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.712891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-08-02 00:12:58.713072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.714765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:00:05.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-08-02 00:12:58.714901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.801883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:
pciBusID: 0000:00:06.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-08-02 00:12:58.802048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.803362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:
pciBusID: 0000:00:07.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-08-02 00:12:58.803698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-02 00:12:58.805523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-02 00:12:58.807244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-08-02 00:12:58.807614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-08-02 00:12:58.809516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-08-02 00:12:58.810620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-08-02 00:12:58.814611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-02 00:12:58.814734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.815664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.816579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.817486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.818413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.819344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.820235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.821133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:58.821967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3
2020-08-02 00:12:58.822388: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-08-02 00:12:58.830470: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2000185000 Hz
2020-08-02 00:12:58.831013: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c4178b0db0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-02 00:12:58.831039: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-02 00:12:59.256430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.329113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.360236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.367112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.368223: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c4145a2150 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-02 00:12:59.368249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-08-02 00:12:59.368256: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-08-02 00:12:59.368267: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-08-02 00:12:59.368293: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-08-02 00:12:59.371553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.372373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-08-02 00:12:59.372472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.373300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:00:05.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-08-02 00:12:59.373389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.374198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:
pciBusID: 0000:00:06.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-08-02 00:12:59.374265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.375094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:
pciBusID: 0000:00:07.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-08-02 00:12:59.375161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-02 00:12:59.375183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-02 00:12:59.375204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-08-02 00:12:59.375223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-08-02 00:12:59.375242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-08-02 00:12:59.375260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-08-02 00:12:59.375280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-02 00:12:59.375341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.376284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.377135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.378016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.378845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.379650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.380503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.381341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.382160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3
2020-08-02 00:12:59.382205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-02 00:12:59.386308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-02 00:12:59.386333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3
2020-08-02 00:12:59.386341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y N N
2020-08-02 00:12:59.386350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N N N
2020-08-02 00:12:59.386355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   N N N Y
2020-08-02 00:12:59.386363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   N N Y N
2020-08-02 00:12:59.386614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.387475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.388358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.389240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.390107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.390967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15056 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
2020-08-02 00:12:59.391525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.392374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15056 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0)
2020-08-02 00:12:59.392906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.393843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 15056 MB memory) -> physical GPU (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:06.0, compute capability: 6.0)
2020-08-02 00:12:59.394386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 00:12:59.395303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 15056 MB memory) -> physical GPU (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:07.0, compute capability: 6.0)
Epoch 1/10000
2020-08-02 00:13:52.468511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
10/10 [==============================] - 3s 335ms/step - loss: 2.7836
Epoch 2/10000
10/10 [==============================] - 3s 335ms/step - loss: 2.7742
Epoch 3/10000
10/10 [==============================] - 3s 339ms/step - loss: 2.7742
Epoch 4/10000
10/10 [==============================] - 3s 341ms/step - loss: 2.7742
Epoch 5/10000
 1/10 [==>...........................] - ETA: 0s - loss: 2.7735
sync_batch_normalization_9 id 0 / 4
 local mean distance: [372190.406 373072.062 361857.031 ... 11281.4863 14100.6201 13597.5859] mean local mean distance 71088.7109
 group var: [278891.656 279530 271112.156 ... 8756.89258 10855.8447 10485.8672] mean group var: 53282.5
 local var: [0.216322735 0.351680636 0.654191434 ... 0.101593301 0.440946668 0.21738404] mean local var: 0.440011531
 group mean: [611.271729 611.215698 601.546692 ... 105.587341 118.7118 115.605087] mean group mean 91.9500732
 local mean: [1.1976552 0.419436097 0.00116307894 ... -0.626998782 -0.0342339203 -1.00359774] mean local mean -0.01634828
 size: [256]

sync_batch_normalization_9 id 1 / 4
 local mean distance: [0.806274891 0.0985621 1.88196e-05 ... 0.223046422 0.000869709416 0.567140639] mean local mean distance 0.132760748
 group var: [279142.844 279803.875 271389.75 ... 8461.29 10575.9697 10198.2939] mean group var: 53316.6094
 local var: [0.217430741 0.351392329 0.65093118 ... 0.102492645 0.439819723 0.220061317] mean local var: 0.439691663
 group mean: [0.299309373 0.104648665 0.00144605222 ... -0.15742597 -0.00983027834 -0.251029134] mean group mean -0.00408996362
 local mean: [1.19723749 0.418594658 0.00578420889 ... -0.629703879 -0.0393211134 -1.00411654] mean local mean -0.0163598545
 size: [256]

sync_batch_normalization_9 id 2 / 4
 local mean distance: [372190.406 373070.594 361849.094 ... 11281.6875 14101.8311 13597.8037] mean local mean distance 71088.5547
 group var: [278891.656 279530 271112.156 ... 8756.89258 10855.8447 10485.8672] mean group var: 53282.5
 local var: [0.214262575 0.350284219 0.650416493 ... 0.101662345 0.442076713 0.21601209] mean local var: 0.439108968
 group mean: [611.271729 611.215698 601.546692 ... 105.587341 118.7118 115.605087] mean group mean 91.9500732
 local mean: [1.19765222 0.420656025 0.00775553659 ... -0.627944 -0.0393257216 -1.00453138] mean local mean -0.0164480079
 size: [256]

sync_batch_normalization_9 id 3 / 4
 local mean distance: [372189.5 373072.375 361852.312 ... 11281.6631 14100.9863 13597.001] mean local mean distance 71088.6406
 group var: [278891.656 279530 271112.156 ... 8756.89258 10855.8447 10485.8672] mean group var: 53282.5
 local var: [0.218500063 0.352682829 0.651915729 ... 0.102855965 0.440146983 0.216531143] mean local var: 0.439344555
 group mean: [611.271729 611.215698 601.546692 ... 105.587341 118.7118 115.605087] mean group mean 91.9500732
 local mean: [1.19834054 0.419162512 0.00508273114 ... -0.627833903 -0.0357722044 -1.00109076] mean local mean -0.0162223056
 size: [256]
10/10 [==============================] - 3s 343ms/step - loss: 2.6909
Epoch 6/10000
10/10 [==============================] - 3s 337ms/step - loss: 2.6679
Epoch 7/10000
10/10 [==============================] - 3s 336ms/step - loss: 2.6742
```

As you can see, the `group_mean` readouts from different replicas are different."
41979,"BatchNorm with Momentum=0.0 Should Return the Same Output with training=True, and then with Training=False","Python 3.6
Ubuntu 18.04
Tensorflow from Binary
v2.3.0-rc2-23-gb36436b087 2.3.0

```
import tensorflow as tf

seq1 = tf.keras.Sequential([tf.keras.layers.Conv2D(32, 3), tf.keras.layers.BatchNormalization(axis=3, momentum=0.0), tf.keras.layers.LeakyReLU(0.01)])

import numpy as np
x = np.random.randn(128,32,32,1)

res1 = seq1(x, training=True)
res2 = seq1(x, training=False)

print(np.linalg.norm(res1 - res2))
```

When using BatchNormalization with momentum=0.0 with training=True, the moving average of mean and variance should update to the statistics of the batch exactly. Therefore when running the model again on the same data with training=False one should expect to get the same output. 
But the print shows a difference between the two of 0.005684062
Help will be appreciated.
Thank you



"
41978,TensorFlow UnboundLocalError: local variable 'batch_outputs' referenced before assignment,"I am trying to run some python3 code on databricks GPU cluster for image understanding by CNN.
The env:

       TensorFlow: 2.2
       python 3.7.6
       keras: 2.3.0-tf
       Unbuntu: 4.4

The code: 

```
import os
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

base_dir = '/Users/Downloads/cats_and_dogs_small'

train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

datagen = ImageDataGenerator(rescale=1./255)
batch_size = 20

def extract_features(directory, sample_count):
    features = np.zeros(shape=(sample_count, 4, 4, 512))
    labels = np.zeros(shape=(sample_count))
    generator = datagen.flow_from_directory(
        directory,
        target_size=(150, 150),
        batch_size=batch_size,
        class_mode='binary')
    i = 0
    for inputs_batch, labels_batch in generator:
        features_batch = conv_base.predict(inputs_batch) # error !
        features[i * batch_size : (i + 1) * batch_size] = features_batch
        labels[i * batch_size : (i + 1) * batch_size] = labels_batch
        i += 1
        if i * batch_size >= sample_count:
            # Note that since generators yield data indefinitely in a loop,
            # we must `break` after every image has been seen once.
            break
    return features, labels

train_features, train_labels = extract_features(train_dir, 2000). # error here !
validation_features, validation_labels = extract_features(validation_dir, 1000)
test_features, test_labels = extract_features(test_dir, 1000)

```

the call stack:

```
Found 0 images belonging to 0 classes.
UnboundLocalError: local variable 'batch_outputs' referenced before assignment
---------------------------------------------------------------------------
UnboundLocalError                         Traceback (most recent call last)
<command-2528158> in <module>
     33     return features, labels
     34 
---> 35 train_features, train_labels = extract_features(train_dir, 2000)
     36 validation_features, validation_labels = extract_features(validation_dir, 1000)
     37 test_features, test_labels = extract_features(test_dir, 1000)

<command-2528158> in extract_features(directory, sample_count)
     23     i = 0
     24     for inputs_batch, labels_batch in generator:
---> 25         features_batch = conv_base.predict(inputs_batch)
     26         features[i * batch_size : (i + 1) * batch_size] = features_batch
     27         labels[i * batch_size : (i + 1) * batch_size] = labels_batch

/databricks/python/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     86       raise ValueError('{} is not supported in multi-worker mode.'.format(
     87           method.__name__))
---> 88     return method(self, *args, **kwargs)
     89 
     90   return tf_decorator.make_decorator(

/databricks/python/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1283             callbacks.on_predict_batch_end(step, {'outputs': batch_outputs})
   1284       callbacks.on_predict_end()
-> 1285     all_outputs = nest.map_structure_up_to(batch_outputs, concat, outputs)
   1286     return tf_utils.to_numpy_or_python_type(all_outputs)
   1287 

UnboundLocalError: local variable 'batch_outputs' referenced before assignment

```"
41977,Benchmark application with `use_xnnpack=true`: ModifyGraphWithDelegate is disallowed when graph is immutable.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): v2.3.0
- Python version: N/A
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

I've built the benchmarking application with XNNPack enabled for my host machine (Linux, Ubuntu 18.04) using the `tensorflow/tensorflow:2.3.0` Docker image. I built the application with the following bazel command

`bazel build -c opt --define tflite_with_xnnpack=true tensorflow/lite/tools/benchmark:benchmark_model`

When running `benchmark_application` with a non-quantized test model I have, TFLite spits out the following error: 

`ERROR: ModifyGraphWithDelegate is disallowed when graph is immutable.`

The benchmarking application still runs to completion, although I am not sure whether the XNNPack delegate is being used because of the above error. I noticed no difference in performance when running without `--use_xnnpack`, so don't think the delegate is being used.

I've run `benchmark_application` with the following command:

`./benchmark_model --graph=model.tflite --use_xnnpack=true`

**Describe the expected behavior**

Would expect with v2.3.0 for the XNNPack delegate to work with non-quantized tflite models. The model was generated with the TFLite model conversion tools, specifically the Keras to TFLite tools.

**Standalone code to reproduce the issue**

This may not be able to be reproduced across all platforms, however, invoking `benchmark_model` as above would be the best attempt to reproduce the issue.

The model can be found here: https://www.dropbox.com/s/dyed8ch0erghb1v/yolov4-416.tflite?dl=0

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

`uname -a` output: Linux ubuntu 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux 
"
41976,TF 2.4.0 build from source gets InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid.,"Nvidia-SMI command issued from inside the container 
NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: ERR!     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 107...  Off  | 00000000:01:00.0 Off |                  N/A |
|  0%   33C    P8     6W / 180W |    193MiB /  8117MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|============================================================================

I am running Ubuntu 20.04. I followed the instructions to Build from source:

After I compiled TF inside the container, I committed and saved it. 

I run the following commands to load the image and execute jupyter notebook:
docker run --gpus all --ipc=""host"" -it -w /tensorflow -v $PWD:/mnt -p 8888:8888 -e HOST_PERMS=""$(id -u):$(id -g)"" tensorflow/tensorflow:from-src2 bash 
export LD_LIBRARY_PATH=“/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/include/x64_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64”
pip install jupyter
pip install jupyter_http_over_ws
jupyter serverextension enable --py jupyter_http_over_ws
jupyter notebook --no-browser --notebook-dir=/mnt/notebooks --ip=0.0.0.0  --debug --NotebookApp.allow_origin='https://www.example.com' --NotebookApp.allow_remote_access=True --allow-root

This gets me a running notebook server.
I try to run the tensorflow-tutorials/text_classification.ipynb file

When I ran the: 

raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(
    'aclImdb/train', 
    batch_size=batch_size, 
    validation_split=0.2, 
    subset='training', 
    seed=seed)

In the jupyter notebook, I get: 
**TypeError: Could not build a TypeSpec for ['aclImdb/train/neg/4932_4.txt', 
 [there follows many pages of text similar to the above]...**

Then I get the following 

**with type list

During handling of the above exception, another exception occurred:**

InternalError                             Traceback (most recent call last)
<ipython-input-10-09c13e5c92d7> in <module>
      7     validation_split=0.2,
      8     subset='training',
----> 9     seed=seed)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/text_dataset.py in text_dataset_from_directory(directory, labels, label_mode, class_names, batch_size, max_length, shuffle, seed, validation_split, subset, follow_links)
    159       label_mode=label_mode,
    160       num_classes=len(class_names),
--> 161       max_length=max_length)
    162   if shuffle:

163     # Shuffle locally at each iteration

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/text_dataset.py in paths_and_labels_to_dataset(file_paths, labels, label_mode, num_classes, max_length)
    175                                 max_length):
    176   """"""Constructs a dataset of text strings and labels.""""""
--> 177   path_ds = dataset_ops.Dataset.from_tensor_slices(file_paths)
    178   string_ds = path_ds.map(
    179       lambda x: path_to_string_content(x, max_length))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py in from_tensor_slices(tensors)
    680       Dataset: A `Dataset`.
    681     """"""
--> 682     return TensorSliceDataset(tensors)
    683 
    684   class _GeneratorState(object):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, element)
   2999   def __init__(self, element):
   3000     """"""See `Dataset.from_tensor_slices()` for details.""""""
-> 3001     element = structure.normalize_element(element)
   3002     batched_spec = structure.type_spec_from_value(element)
   3003     self._tensors = structure.to_batched_tensor_list(batched_spec, element)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py in normalize_element(element)
     96         # the value. As a fallback try converting the value to a tensor.
     97         normalized_components.append(
---> 98             ops.convert_to_tensor(t, name=""component_%d"" % i))
     99       else:
    100         if isinstance(spec, sparse_tensor.SparseTensorSpec):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1524 
   1525     if ret is None:
-> 1526       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1527 
   1528     if ret is NotImplemented:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    337                                          as_ref=False):
    338   _ = as_ref
--> 339   return constant(v, dtype=dtype, name=name)
    340 
    341 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)
    263   """"""
    264   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 265                         allow_broadcast=True)
    266 
    267 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    274       with trace.Trace(""tf.constant""):
    275         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
--> 276     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    277 
    278   g = ops.get_default_graph()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    299 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):
    300   """"""Implementation of eager constant.""""""
--> 301   t = convert_to_eager_tensor(value, ctx, dtype)
    302   if shape is None:
    303     return t

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
     95     except AttributeError:
     96       dtype = dtypes.as_dtype(dtype).as_datatype_enum
---> 97   ctx.ensure_initialized()
     98   return ops.EagerTensor(value, ctx.device_name, dtype)
     99 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py in ensure_initialized(self)
    547         if self._use_tfrt is not None:
    548           pywrap_tfe.TFE_ContextOptionsSetTfrt(opts, self._use_tfrt)
--> 549         context_handle = pywrap_tfe.TFE_NewContext(opts)
    550       finally:
    551         pywrap_tfe.TFE_DeleteContextOptions(opts)

**InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid.**

This from /tensorflow_src/.bazelrc : release_gpu_common --action_env=TF_CUDA_COMPUTE_CAPABILITIES=""sm_35,sm_37,sm_52,sm_60,sm_61,compute_70

I believe the GeForce 1070 is sm_61 compute level.

Some software versions
gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Python 3.6.9
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243



<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I will attach the full .bazelrc file and a piped output of the build from source when I can figure out how to do that. I’m on an iPad now and can copy and paste but can’t seem to figure out how to copy a file to the ipad and then upload to github issue..."
41974,"Hi, I am trying to load a saved model using load_model('path') but i am getting the following error :","  File ""F:\anaconda\envs\facerecog\lib\site-packages\tensorflow\python\keras\saving\save.py"", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File ""F:\anaconda\envs\facerecog\lib\site-packages\tensorflow\python\saved_model\loader_impl.py"", line 113, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: ferlatest.h5/{saved_model.pbtxt|saved_model.pb}
"
41973,Memory Leak with latest Tensorflow,"
**System information**
- Have I written custom code: Yes, but minimal
- OS Platform and Distribution: Windows 10
- TensorFlow installed from: conda
- TensorFlow version: `2.3.0`
- Python version: 3.7.4

**Current behavior**
Memory leaks.
**Expected behavior**
Memory does not leak.
**Code to reproduce the issue**
```Python
import numpy as np
import tensorflow
from tensorflow import keras
from tensorflow.keras import layers
import gc
import tracemalloc    
if __name__ == ""__main__"":
    tracemalloc.start()
    while True:
        inputs = keras.Input(shape=(10,))
        out = layers.Dense(1)(inputs)
        model = keras.Model(inputs=inputs, outputs=out)
        model.compile(optimizer=""adam"", loss=""mse"")
        train = np.random.rand(1000,10)
        label = np.random.rand(1000)
        model.fit(train, label)
        gc.collect()
        current, peak = tracemalloc.get_traced_memory()
        print(f""Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB"")
```
"
41972,tensorflow.python.framework.errors_impl.NotFoundError: 'DummySeedGenerator',"On Google Colab using TPU

2020-08-01 18:34:58.551171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Using TensorFlow backend.
TENSORFLOW version: 2.3.0
Tensorflow device List:
2020-08-01 18:35:01.566174: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-01 18:35:01.575940: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
2020-08-01 18:35:01.576357: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc4a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-01 18:35:01.576430: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-01 18:35:01.581369: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-08-01 18:35:01.585626: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-08-01 18:35:01.585692: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cbed57a08e06): /proc/driver/nvidia/version does not exist
Running on TPU  ['10.102.83.42:8470']
2020-08-01 18:35:01.604749: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.102.83.42:8470}
2020-08-01 18:35:01.604991: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34406}
2020-08-01 18:35:01.624392: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.102.83.42:8470}
2020-08-01 18:35:01.624476: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34406}
2020-08-01 18:35:01.625695: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://localhost:34406
REPLICAS:  8
train dataset:  665 , validation dataset:  36
2020-08-01 18:35:40.190966: E tensorflow/core/common_runtime/eager/context.cc:678] Failed to register function remotely due to 'DummySeedGenerator' is neither a type of a primitive operation nor a name of a function registered in binary running on n-a43c3c58-w-0. Make sure the operation or function is registered in the binary running in this process.
_**This shouldn't happen, please file a bug to tensorflow team.**_
Traceback (most recent call last):
  File ""scripts/tf_imgseg_train.py"", line 196, in <module>
    callbacks=callbacks)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1063, in fit
    steps_per_execution=self._steps_per_execution)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py"", line 1102, in __init__
    self._steps_per_execution_value = steps_per_execution.numpy().item()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/values.py"", line 662, in numpy
    return self.read_value().numpy()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1063, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1031, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.NotFoundError: 'DummySeedGenerator' is neither a type of a primitive operation nor a name of a function registered in binary running on n-a43c3c58-w-0. Make sure the operation or function is registered in the binary running in this process.
2020-08-01 18:35:40.194364: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:76] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: 'DummySeedGenerator' is neither a type of a primitive operation nor a name of a function registered in binary running on n-a43c3c58-w-0. Make sure the operation or function is registered in the binary running in this process.
2020-08-01 18:35:40.195337: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 6815, Output num: 0
Additional GRPC error information from remote target /job:worker/replica:0/task:0:
:{""created"":""@1596306940.195137527"",""description"":""Error received from peer ipv4:10.102.83.42:8470"",""file"":""external/com_github_grpc_grpc/src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""Unable to find the relevant tensor remote_handle: Op ID: 6815, Output num: 0"",""grpc_status"":3}
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py"", line 540, in async_wait
    context.async_wait()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py"", line 2319, in async_wait
    context().sync_executors()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py"", line 658, in sync_executors
    pywrap_tfe.TFE_ContextSyncExecutors(self._context_handle)
tensorflow.python.framework.errors_impl.NotFoundError: 'DummySeedGenerator' is neither a type of a primitive operation nor a name of a function registered in binary running on n-a43c3c58-w-0. Make sure the operation or function is registered in the binary running in this process."
41971,Error in nce_loss using intermediate layer output,"**Standalone code to reproduce the issue**
[colab notebook](https://colab.research.google.com/drive/1JTQzXF_Gu4WHzwCg_EWbjAU2gc-8VAOx?usp=sharing)

**System information**
tensorflow version on my machine v2.2.0-rc4-8-g2b96f3662b 2.2.

I am trying to use the nce_loss by passing the second to last layer's ouput to this loss function, then I got error

>OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.

"
41968,Looking for Post-training Quantization for int 16 in TF2/TF Lite,"**System information**
- TensorFlow version (you are using): TF 2.2.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Dear TF developers, I'm looking for a 16-bits integer Post-training Quantization (PQ) solution. I noticed that we have 16-bit Quantization Aware Training (QAT) APIs for TF2 (which is great!), while for PQ, INT16 is not supported in TF Lite. 

Or do you know any framework that can achieve int16 PQ currently?

**Will this change the current api? How?**
Yes or No. For the tf.lite.TFLiteConverter.from_keras_mode, we need to import another parameter in order to indicate the quantization bits. Or we can create a new api to fit this method. 

**Who will benefit with this feature?**
Platforms that have a nice 16 bits calculation support. This will save more calculation 

**Any Other info.**
"
41967,UserWarning: Tensorflow optimizers do not mkae it possible to access optimizer attributes or optimizer state after instantiation.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  
- TensorFlow version: 2.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: Quadro GV100, 32GB



**Describe the problem**

Hello, I just make some model from keras, and got some problems like below:
```UserWarning: Tensorflow optimizers do not mkae it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers)```

In my codes,
```
model = Sequential()
model.add(Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), data_format=""channels_last"", activation='relu', input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])))
model.add(Flatten())
model.add(Dense(len(label), activation='softmax'))
model.summary()

initial_learning_rate = args.lr
    
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
initial_learning_rate,
decay_steps=4000,
decay_rate=0.96,
staircase=True)

optimizer = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.9, beta_2=0.98, epsilon=1e-9)

model.compile(loss=tf.keras.losses.KLDivergence(), optimizer=optimizer, metrics=['accuracy'])

model_path='./'
file_path = os.path.join(model_path, 'saved-model-{epoch:02d}-{val_loss:.2f}.hdf5') # 
checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=False, mode='max') # 
callback_list = [checkpoint]

hist = model.fit(train_datagen.flow(x_train, y_train, batch_size=args.batch_size), epochs=args.epochs, steps_per_epoch=train_steps, validation_data = (valid_datagen.flow(x_valid, y_valid, batch_size=args.batch_size)), callbacks = callback_list, shuffle=True)
```
As shown in my code, I used the optimizers from ```tf.keras.optimizers``` but I got some errors.

When I do evaluate, I got this warning message:
```UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually```

Here the summary of my ```eval.py``` code:
```
model = keras.models.load_model(model_dir)
model.summary()

y_pred = model.predict(x_test)
```

Is it possible to use that saved model directly? or how should I use this model? May I ignore that Warning message?


**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam
"
41966,Unable to use libtensorflowlite.so ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0
- Python version: 3.8.3
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 10.1, cuDNN  
- GPU model and memory: Nvidia Geforce 940MX 2GB



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

 I want to use tensorflowlite C++ API to run inference. I used bazel build and installed it using "" bazel build -c opt --config=android_x86_64 //tensorflow/lite:libtensorflowlite.so"" this command. I copied the header files of flatbuffer and abseil and created a new folder 

I used the code provided in Android Quickstart:

```c++
#include ""tensorflow/lite/model.h""
#include ""tensorflow/lite/kernels/register.h""
#include <iostream>
#include <memory>

using namespace std;

int main()
{
    const char* filename = ""models/inception_v4.tflite"";
    // Load the model
    std::unique_ptr<tflite::FlatBufferModel> model =
        tflite::FlatBufferModel::BuildFromFile(filename);

    // Build the interpreter
    tflite::ops::builtin::BuiltinOpResolver resolver;
    std::unique_ptr<tflite::Interpreter> interpreter;
    tflite::InterpreterBuilder(*model.get(), resolver)(&interpreter);

    // Resize input tensors, if desired.
    interpreter->AllocateTensors();

    float* input = interpreter->typed_input_tensor<float>(0);
    // Fill `input`.

    interpreter->Invoke();

    float* output = interpreter->typed_output_tensor<float>(0);

}
```

I ran this command to compile

```g++ hello.cpp  -I/<working_directory>/include -ltensorflowlite```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


```
usr/bin/ld: warning: libm.so, needed by //usr/local/lib/libtensorflowlite.so, not found (try using -rpath or -rpath-link)
/usr/bin/ld: warning: liblog.so, needed by //usr/local/lib/libtensorflowlite.so, not found (try using -rpath or -rpath-link)
/usr/bin/ld: warning: libc.so, needed by //usr/local/lib/libtensorflowlite.so, not found (try using -rpath or -rpath-link)
/tmp/ccWPry2X.o: In function `main':
model.cpp:(.text+0xa4): undefined reference to `tflite::impl::InterpreterBuilder::operator()(std::unique_ptr<tflite::impl::Interpreter, std::default_delete<tflite::impl::Interpreter> >*)'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtod@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `towlower@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_self@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_key_create@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswcntrl@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fseeko@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcsnrtombs@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `vsnprintf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `roundf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtoll_l@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `atan@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_mutexattr_destroy@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_detach@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `munmap@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_mutex_destroy@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `mbsnrtowcs@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wmemmove@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strerror_r@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswdigit@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__strlen_chk@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `sysconf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `dlopen@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `vsscanf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strlen@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fwrite@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `sched_yield@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `ldexp@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `puts@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtol@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `localeconv@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtold@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `btowc@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `openlog@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fclose@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `ftello@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_mutex_trylock@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `realloc@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `log@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `vfprintf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `close@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `qsort@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strxfrm@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fopen@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `sinf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `mmap@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtoull@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `abort@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `isupper@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtoll@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `exit@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `putchar@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `memset@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_cond_signal@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `calloc@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `syscall@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_cond_destroy@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `vasprintf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `acos@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_getspecific@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `getenv@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `clock_gettime@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `sin@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `isspace@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcrtomb@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `bsearch@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `sincos@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `memcmp@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__system_property_get@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswpunct@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__cxa_finalize@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_create@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strcoll@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__android_log_vprint'
//usr/local/lib/libtensorflowlite.so: undefined reference to `tan@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__cxa_atexit@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `asin@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `mbrtowc@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcstof@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fputs@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `realpath@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtoul@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strpbrk@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `snprintf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wmemchr@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `round@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `sscanf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_cond_timedwait@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pow@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strcmp@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fseek@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `mbtowc@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcstoull@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `setlocale@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `tanhf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswupper@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__vsnprintf_chk@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `towupper@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wctob@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fflush@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcsxfrm@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `exp@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fprintf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strncpy@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `closelog@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `expf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `open@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fmodf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `cos@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__ctype_get_mb_cur_max@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `freelocale@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `mbsrtowcs@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wmemcmp@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `ldexpf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `tolower@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswblank@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcstod@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `powf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `uselocale@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `atoi@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `frexp@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_mutexattr_settype@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_cond_wait@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `mkdir@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_setspecific@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_cond_init@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__stack_chk_fail@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `nanosleep@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `dlsym@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strftime@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcstoll@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `memmove@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_mutex_init@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `toupper@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `mbrlen@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__memmove_chk@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcstold@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__errno@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `syslog@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswlower@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `newlocale@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `android_set_abort_message@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcstol@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_join@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `swprintf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `memchr@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `__sF@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `isxdigit@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `memcpy@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `dl_iterate_phdr@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswspace@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `read@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `malloc@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strncmp@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_mutexattr_init@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtoull_l@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_equal@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `posix_memalign@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `logf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_mutex_unlock@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtold_l@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswalpha@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `stat@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strtof@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_once@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fread@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_mutex_lock@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswprint@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fputc@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcscoll@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fileno@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `pthread_cond_broadcast@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `strerror@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `free@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `fstat@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcslen@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `cosf@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `log1p@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wmemcpy@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wcstoul@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `iswxdigit@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `wmemset@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `islower@LIBC'
//usr/local/lib/libtensorflowlite.so: undefined reference to `printf@LIBC'
```
"
41965,Tensor into numpy,"How do I turn a tensor such as `Tensor(""lstm_42/Identity:0"", shape=(1, 100, 13), dtype=float32)` into a numpy array in keras? Tried .numpy() and .eval() but nothing seems to work."
41964,"ImportError: DLL load failed: The specified module could not be found.  During handling of the above exception, another exception occurred:","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
I have python 3.7.4 and tensorflow 2.2 installed along with keras 2.2.4



**Describe the problem**
Here's the traceback for the error I'm getting: 

C:\Users\Edan\AppData\Local\Programs\Python\Python37\python.exe C:/Users/Edan/Desktop/Studies/AI/Project/final_project_ai/engine/game_engine.py
Traceback (most recent call last):
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from tensorflow.keras.layers.experimental.preprocessing import RandomRotation
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/Edan/Desktop/Studies/AI/Project/final_project_ai/engine/game_engine.py"", line 12, in <module>
    from agents.simpleAgents import GreedyAgent, RandomAgent
  File ""C:\Users\Edan\Desktop\Studies\AI\Project\final_project_ai\agents\simpleAgents.py"", line 1, in <module>
    from agents.Agents import Agent
  File ""C:\Users\Edan\Desktop\Studies\AI\Project\final_project_ai\agents\Agents.py"", line 5, in <module>
    from keras.models import Sequential, Model
  File ""C:\Users\Edan\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\__init__.py"", line 6, in <module>
    'Keras requires TensorFlow 2.2 or higher. '
ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`

Process finished with exit code 1


**Provide the exact sequence of commands / steps that you executed before running into the problem**
Just trying to import tensorflow into some python files:

import random
import numpy as np
# import tensorflow as tf
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Input, InputLayer, Flatten
from keras.layers.merge import Add, Multiply
from keras.optimizers import Adam
from random import choices
from collections import deque


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
41963,TFLite flex delegate build failed on Windows: fatal error C1001: An internal error has occurred in the compiler.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro Version 1903
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: `r2.3` branch
- Python version: 3.6.0
- Installed using virtualenv? pip? conda?: None, but have pip.
- Bazel version (if compiling from source): 3.1.0 (as it recommends [here](https://www.tensorflow.org/install/source))
- GCC/Compiler version (if compiling from source): MSVC 2017 (v141-14.16.27023) x64
- CUDA/cuDNN version: None
- GPU model and memory: RX 470 4GB

**Describe the problem**
`tensorflow\compiler\xla\literal.cc(1166) : fatal error C1001: An internal error has occurred in the compiler.`

I previously built the Tensorflow Lite C++ DLL successfully via the command `bazel build -c opt //tensorflow/lite:tensorflowlite`, but when trying to build with the Flex delegate (either by adding to BUILD dependencies and doing monolithic like it says [here](https://www.tensorflow.org/lite/guide/ops_select?hl=es-419#c)) or trying to straight out build the delegate itself I get this error after some time. I'm building without CUDA nor ROCm support

I tried, according to other issues I found: (none worked)
1. Turning off strong inline.
2. Running cmd as administrator.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Attempt 1: `bazel build --config monolithic //tensorflow/lite:tensorflowlite` after adding flex delegate to BUILD dependencies for lite.
Attempt 2: `bazel build -c opt //tensorflow/lite/delegates/flex:delegate`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
ERROR: C:/users/zdisket/documents/edit/tflitecompile/tensorflow/tensorflow/compiler/xla/BUILD:432:1: C++ compilation of rule '//tensorflow/compiler/xla:literal' failed (Exit 3): cl.exe failed: error executing command
  cd C:/users/zdisket/_bazel_zdisket/jc7gu5by/execroot/org_tensorflow
  SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.16.27023\ATLMFC\include;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.16.27023\include;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\cppwinrt
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.16.27023\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft SDKs\TypeScript\3.1;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\MSBuild\15.0\bin\Roslyn;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.6.1 Tools\x64\;C:\Program Files (x86)\HTML Help Workshop;C:\Program Files (x86)\Windows Kits\10\bin\10.0.17763.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\\MSBuild\15.0\bin;C:\WINDOWS\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\Tools\;;C:\WINDOWS\system32;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/ZDisket/AppData/Local/Programs/Python/Python36/python.exe
    SET PYTHON_LIB_PATH=C:/Users/ZDisket/AppData/Local/Programs/Python/Python36/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\ZDisket\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_ENABLE_XLA=1
    SET TMP=C:\Users\ZDisket\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/HostX64/x64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/libjpeg_turbo /Ibazel-out/x64_windows-opt/bin/external/libjpeg_turbo /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/gif/windows /Ibazel-out/x64_windows-opt/bin/external/gif/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /DTF_USE_SNAPPY /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw /w /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /std:c++14 /Fobazel-out/x64_windows-opt/bin/tensorflow/compiler/xla/_objs/literal/literal.obj /c tensorflow/compiler/xla/literal.cc
Execution platform: @local_execution_config_platform//:platform
c:\users\zdisket\_bazel_zdisket\jc7gu5by\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1166) : fatal error C1001: An internal error has occurred in the compiler.
(compiler file 'd:\agent\_work\3\s\src\vctools\compiler\utc\src\p2\main.c', line 187)
 To work around this problem, try simplifying or changing the program near the locations listed above.
Please choose the Technical Support command on the Visual C++
 Help menu, or open the Technical Support help file for more information
  cl!CloseTypeServerPDB()+0x132a74
  cl!CloseTypeServerPDB()+0x1499b
  cl!CloseTypeServerPDB()+0x14b47
  cl!CloseTypeServerPDB()+0x14df0
  cl!CloseTypeServerPDB()+0x79992
  cl!CloseTypeServerPDB()+0xb4aff
  cl!CloseTypeServerPDB()+0xb415e
  cl!InvokeCompilerPassW()+0x67d7b
  cl!beginthreadex()+0x142
  cl!BaseThreadInitThunk()+0x14
  cl!RtlUserThreadStart()+0x21

c:\users\zdisket\_bazel_zdisket\jc7gu5by\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1166) : fatal error C1001: An internal error has occurred in the compiler.
(compiler file 'd:\agent\_work\3\s\src\vctools\compiler\utc\src\common\error.c', line 835)
 To work around this problem, try simplifying or changing the program near the locations listed above.
Please choose the Technical Support command on the Visual C++
 Help menu, or open the Technical Support help file for more information
Target //tensorflow/lite/delegates/flex:delegate failed to build
INFO: Elapsed time: 14977.319s, Critical Path: 371.66s
INFO: 1335 processes: 1335 local.
FAILED: Build did NOT complete successfully
```
"
41962,Pycharm:TensorFlow-Attribute error issue ,"Hi,

While trying to run the below code I encountered an Attribute error, description for which is given below.

Code

import tensorflow as tf

node1 = tf.constant (3.0,tf.float32)

node2 = tf.constant (4.0)

print(node1,node2)

Error Message encountered-AttributeError: module 'os' has no attribute 'add_dll_directory'

System Configurations are as mentioned below

OS-Windows 7
Python version-3.8.0
Pycharm version-Community 2019.1
Tensorflow-2.3.0

PFA the screenshots of Pycharm packages
![pycharm_packages_1](https://user-images.githubusercontent.com/64397079/89103662-09bba580-d431-11ea-86ec-29bbd93c066a.jpg)
![pycharm_packages_2](https://user-images.githubusercontent.com/64397079/89103664-0b856900-d431-11ea-8003-395027d06fef.jpg)

"
41960,cross compilation for tflite delegate testing tools,"Hi,

I'm implementing my custom delegates for tflite to use RiscV-based accelerators.
While following the guides in **https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/utils/dummy_delegate**
I found that kernel tests are not convenient for cross-compilation.

Is there a recommended way to test my delegate functions for other architectures?

Thanks!

"
41959,tf.math.l2_normalize - gradients seem to be wrong,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.16.16, Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): docker container, versions `tensorflow/tensorflow:2.2.0-gpu` and `tensorflow/tensorflow:2.3.0`
- TensorFlow version (use command below): `v2.2.0-rc4-8-g2b96f3662b 2.2.0` and `v2.3.0-rc2-23-gb36436b087 2.3.0`
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0.130 on Linux, no CUDA on OSX
- GPU model and memory: GTX 1080 Ti 12GB on Linux, no GPU on OSX

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Gradients of `tf.math.l2_normalize` seem to be wrong. I confirmed both analytically and with numerical computations that values computed by tensorflow are off. There is always a chance my math is wrong, but I'm quite confident in it + numerical computations indicate same results as my workings.

Here's a unit test that compares gradients computed by tensorflow to expected values.
Since they differ, test fails:
```python
def test_l2_gradients_with_tensorflow():

    x = tf.constant([3, 4], tf.float32)

    with tf.GradientTape() as gradient_tape:

        gradient_tape.watch(x)
        y = tf.math.l2_normalize(x)

    expected_y = np.array([0.6, 0.8])

    assert np.all(np.isclose(expected_y, y))

    gradients = gradient_tape.gradient(y, x)

    expected_gradients = np.array([0.128, 0.072])

    # This line fails, tensorflow computes gradients to be [0.032 -0.024]
    assert np.all(np.isclose(expected_gradients, gradients))
```

**Describe the expected behavior**
Below are my workings for what the correct `dy/dx1` derivative should be for values in unit test above. `dy/dx2` follows the same logic.

![IMG_20200801_205810](https://user-images.githubusercontent.com/13689310/89102189-b0a83d80-d441-11ea-8b52-0e9a05e7d2e3.jpg)

I also double checked with numerical computations in numpy, and they agree with my numbers:

```python
def test_l2_gradients_with_numpy():

    # Specify x1 only
    x1 = np.arange(2.998, 3.003, 0.001)

    # index for x1 = 3
    test_index = 2

    # x2 is set to constant 4
    y = x1 / np.sqrt(x1*x1 + 16)
    expected_y = 0.6

    assert np.isclose(expected_y, y[test_index])

    gradients = np.gradient(y, x1)
    expected_gradient = 0.128

    assert np.isclose(expected_gradient, gradients[test_index])
```


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Please refer to unit tests above

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41958,Keras evaluate method returns wrong value after loading a model,"**System information**
- OS Platform : Windows10
- TensorFlow installed from : source(pip in anaconda)
- TensorFlow version : 2.3.0
- Python version : 3.8.3

**Describe the current behavior**
Keras Sequential method:`evaluate()` returns wrong value after loading a model. value of loss is equal but metrics differs before and after the model is saved and loaded.
I calculated the accuracy manually using sklearn.metrics and got the same value. Therefore, the problem seems to be in this method.
In the below code, the `acc1`, `acc2` are the same. However `acc1=0.863` and `acc2=0.086` in my environment.

~~When I ran the code in colab, this issue was not occurred.~~

**Describe the expected behavior**
Keras Sequential method:`evaluate()` returns same value before and after the model is saved and loaded.

**Standalone code to reproduce the issue**
This code is a modified version of this [tutorial](https://www.tensorflow.org/tutorials/keras/save_and_load) code to reproduce the issue.
If you run the code in the above tutorial on Windows10, I think you are able to reproduce the issue.
For your information, I comment on the results in my environment.

```
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import accuracy_score

(train_images, train_labels),(test_images, test_labels) = tf.keras.datasets.mnist.load_data()
train_labels = train_labels[:1000]
test_labels = test_labels[:1000]
train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0
test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0

def create_model():
    model = tf.keras.models.Sequential([
        keras.layers.Dense(512, activation='relu', input_shape=(784,)),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(10)
    ])
    model.compile(optimizer='adam',
                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])
    return model

# Create first model
model = create_model()
model.fit(train_images, train_labels, epochs=5)

model.save('saved_model/my_model')

# Create second model (load the saved model)
new_model = tf.keras.models.load_model('saved_model/my_model')

# First model's results
loss1, acc1 = model.evaluate(test_images, test_labels)
accuracy_score1 = accuracy_score(test_labels, np.argmax(model.predict(test_images), axis=1))
# loss1, acc1 = [0.4392167329788208, 0.8629999756813049]
# accuracy_score1 = 0.863

# Second model's results
loss2, acc2 = new_model.evaluate(test_images, test_labels)                           
accuracy_score2 = accuracy_score(test_labels, np.argmax(new_model.predict(test_images), axis=1))
# loss2, acc2 = [0.4392167329788208, 0.0860000029206276] <- THIS!!!
# accuracy_score2 = 0.863
```

Why is this happening?
Can you help me?
"
41957,Model performs differently for model.fit and custom training loop,"**System information**

- Os platform Linux Ubuntu 16.04
- TensorFlow version used - 2.2.0
- Python version: 3.6.9

**Custom Training Loop vs Model.fit code**

```
model=model()
optimizer=tf.keras.optimizers.Adam()
batch_size=opt.b_size
n_batches = int(len(train_set) / opt.b_size)

for i in range(opt.epochs):
    loss_t=0
    loss_vt=0
    it=0
    for j in range(n_batches):
        with tf.GradientTape() as tape:
            tape.watch(model.trainable_variables)
            curr=train_set[it:it+batch_size]
            forward=model(curr,True)
            loss=tf.keras.losses.MeanAbsoluteError()(y_train[it:it+batch_size],forward)
            loss_t += loss

        grads=tape.gradient(loss,model.trainable_variables)
        optimizer.apply_gradients(zip(grads,model.trainable_variables))
        it+=batch_size

    # shuffling the test set 
    index = np.arange(0, len(test_set))
    np.random.shuffle(index)
    test_set = test_set[index]
    y_test = y_test[index]
    loss_t=loss_t.numpy()
    
    # calculating the validation loss
    forward_v = model(test_set[:batch_size], False)
    loss_v = tf.keras.losses.MeanAbsoluteError()(y_test[:batch_size], forward_v)
    loss_v=loss_v.numpy()
    loss_t /= n_batches
    print(""Loss: {} Validation loss: {} "".format( round(loss_t,4) , round(loss_v,4) ) )
```
The above mentioned code is the custom training loop of a model.
```
model=model()
model.compile(tf.keras.optimizers.Adam(),tf.keras.losses.MeanAbsoluteError(),metrics=['accuracy'])
model.fit(train_set,y_train,batch_size=opt.b_size,epochs=opt.epochs,validation_data=(test_set,y_test))
```
The above code uses model.fit method for training.


**Behaviour and code  to replicate the Results**
But when I run the same code on the same train dataset and validation dataset with all the same parameters, the validation loss obtained is very different in the two cases.
- Here is the [google colab gist](https://colab.research.google.com/drive/1AuvfArBWjowMT-2Eydw6FBDpo1mspPn1?usp=sharing) to replicate the results.
- Alternatively, to replicate results locally, please run  **train.py** and **train2.py** on [my github](https://github.com/arshagarwal/outlier-experiment) using the following code after cloning the repository to reproduce the results:
1.  `bash import_weights.sh`
2. `python train.py --n_samples 1000 --epochs 100  --b_size 50` for model.fit
3. `python train2.py --n_samples 1000 --epochs 100  --b_size 50` for custom training

"
41956,"not sure but should it not be ""ZerosLike"" rather than ""OnesLike"" over here?",https://github.com/tensorflow/tensorflow/blob/05632ed9bad5bf9eee3edd57ade3d8250d580019/tensorflow/c/eager/gradients.cc#L104
41954,"tensorflow-io 0.14.0 requires tensorflow<2.3.0,>=2.2.0, but you'll have tensorflow 2.3.0 which is incompatible","
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
 - TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version:3.8.2
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: 10.1
- GPU model and memory: 1650 4GB



**Describe the problem**
Cant use tensorflow-io , if I try to install tensorflow-io with pip  tensorflow downgrades  please fix this dependency issue.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
pip install tensorflow 

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
pip install tensorflow 
Defaulting to user installation because normal site-packages is not writeable
Collecting tensorflow

Using cached tensorflow-2.3.0-cp38-cp38-manylinux2010_x86_64.whl (320.5 MB)
Requirement already satisfied: wrapt>=1.11.1 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.12.1)
Requirement already satisfied: gast==0.3.3 in ./.local/lib/python3.8/site-packages (from tensorflow) (0.3.3)
Requirement already satisfied: numpy<1.19.0,>=1.16.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.18.4)
Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.3.0)
Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)
Requirement already satisfied: astunparse==1.6.3 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)
Requirement already satisfied: google-pasta>=0.1.8 in ./.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)
Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)
Requirement already satisfied: protobuf>=3.9.2 in ./.local/lib/python3.8/site-packages (from tensorflow) (3.12.2)
Requirement already satisfied: h5py<2.11.0,>=2.10.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)
Requirement already satisfied: tensorboard<3,>=2.3.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.3.0)
Requirement already satisfied: scipy==1.4.1 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.4.1)
Requirement already satisfied: grpcio>=1.8.6 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.29.0)
Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)
Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow) (0.34.2)
Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.8/site-packages (from tensorflow) (3.2.1)
Requirement already satisfied: absl-py>=0.7.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (0.9.0)
Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.9.2->tensorflow) (45.2.0)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)
Requirement already satisfied: google-auth<2,>=1.6.3 in ./.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.16.0)
Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)
Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.6.0.post3)
Requirement already satisfied: werkzeug>=0.11.15 in ./.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)
Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)
Requirement already satisfied: rsa<4.1,>=3.1.4 in ./.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.0)
Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)
Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.0)
Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)
Requirement already satisfied: pyasn1>=0.1.3 in ./.local/lib/python3.8/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)
Installing collected packages: tensorflow
ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.

We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.

tensorflow-io 0.14.0 requires tensorflow<2.3.0,>=2.2.0, but you'll have tensorflow 2.3.0 which is incompatible"
41953,tensorflow 2.3.0: target 'grpc++_public_hdrs' not declared in package when build from source,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Gentoo linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: -
- Bazel version (if compiling from source): 3.2.0
- GCC/Compiler version (if compiling from source): 8.4.0
- CUDA/cuDNN version: 10.2
- GPU model and memory: -


**Describe the problem**
tf 2.3.0 introduces experimental tf.data service and uses undefined `grpc++_public_hdrs` dependency. Thus building tf 2.3.0 from source on Gentoo linux gives the following error:
`tensorflow/python/data/experimental/service/BUILD:11:27: no such target '@com_github_grpc_grpc//:grpc++_public_hdrs': target 'grpc++_public_hdrs' not declared in package '' defined by /var/tmp/portage/sci-libs/tensorflow-2.3.0/work/tensorflow-2.3.0-python3_7-bazel-base/external/com_github_grpc_grpc/BUILD.bazel and referenced by '//tensorflow/python/data/experimental/service:_pywrap_server_lib.so'`

The installation was done by the portage system (ebuild file) of Gentoo linux, please see [here](https://github.com/naturomics/gentoo-overlays) for the commands I used.

not sure if this problem affects other system, but [here](https://github.com/naturomics/gentoo-overlays/blob/master/sci-libs/tensorflow/files/tensorflow-2.3.0-0002-systemlibs-grpc-Fix-deps.patch) is a patch I wrote to fix it for gentoo linux.
"
41952,Model predicts only one class In Binary Classification,"Model : 

base_model=tf.keras.applications.EfficientNetB7(input_shape=input_shape,include_top=False, weights='imagenet')

global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
prediction_layer = tf.keras.layers.Dense(1,activation='sigmoid')

model = tf.keras.Sequential([base_model,
  global_average_layer,
  prediction_layer
])

model.compile(optimizer=tf.optimizers.Adam(lr=0.00001),loss='BinaryCrossentropy',metrics=[tf.keras.metrics.AUC()])

history=model.fit(train_data_gen,epochs=1,validation_data=validation_data_gen,callbacks=[lr_scheduler])

sub['Test_Classes']=model.predict_classes(test_data_gen)

Expected Output : 0 1 0 0 0 1 0 1 

Actual Output      : 0 0 0 0 0 0 0 0 
"
41951,use tf.image.ssim to calculate ssim is differen from paper(matlab?),"I use the following code to calculate the ssim of set5 dataset, but the results is differen from paper. When use 'Bicubic' method and set scale to 4, papers are usually PSNR(28.42)/ SSIM(0.810) .
```python
import tensorflow as tf
ssims = 0
psnrs = 0

for i in range(5):
    path1 = 'Set5\\Set5\\image_SRF_4\\img_00'+str(i+1)+'_SRF_4_bicubic.png'#bicubic
    path2 = 'Set5\\Set5\\image_SRF_4\\img_00'+str(i+1)+'_SRF_4_HR.png'
    img1 = tf.io.read_file(path1)
    img1 = tf.io.decode_image(img1,3,expand_animations=False)

    img2 = tf.io.read_file(path2)
    img2 = tf.io.decode_image(img2,3,expand_animations=False)

    ssims = ssims + tf.image.ssim(img1, img2, max_val=255)
    psnrs = psnrs + tf.image.psnr(img1, img2, max_val=255)
    
ssims/5,psnrs/5
```
```
(<tf.Tensor: shape=(), dtype=float32, numpy=0.7731458>,
 <tf.Tensor: shape=(), dtype=float32, numpy=26.69437>)
```
**Why is there a big gap between my results and the paper? Is my calculation wrong?**"
41950,Keras 2.4.3 test missing cases,"**System information**
- OS Platform and Distribution :Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.2.0 
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version:  Cuda10.0, cudnn 7.6.5.32
- GPU model and memory: GTX1070 , 8G

Keras version 2.4.3

I have a mnist script to test my tensorflow installation

```
'''Trains a simple convnet on the MNIST dataset.
Gets to 99.25% test accuracy after 12 epochs
(there is still a lot of margin for parameter tuning).
16 seconds per epoch on a GRID K520 GPU.
'''

import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K

batch_size = 128
num_classes = 10
epochs = 12

# input image dimensions
img_rows, img_cols = 28, 28

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

```
**Describe the current behavior**

A lot of samples are lost, here is the output of running the script with keras 2.4.3 with tensoflow backend [in my setup python=python3] Comparing to expected behaviour below (with kereas 2.3.1), there are only 496 samples in an epoch instead of 6000

```
python /home/bernard/python-dev/test/mnist_cnn_demo.py
2020-07-31 21:34:53.674307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
2020-07-31 21:34:55.075415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-31 21:34:55.104800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:34:55.105872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.695GHz coreCount: 16 deviceMemorySize: 7.92GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-31 21:34:55.105894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-31 21:34:55.107057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-31 21:34:55.107952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-07-31 21:34:55.108219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-07-31 21:34:55.109467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-07-31 21:34:55.110373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-07-31 21:34:55.113179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-31 21:34:55.113334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:34:55.113952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:34:55.114509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-31 21:34:55.121289: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2904000000 Hz
2020-07-31 21:34:55.121631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x42e2280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-31 21:34:55.121650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-31 21:34:55.182191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:34:55.182711: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x436c5e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-31 21:34:55.182743: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-07-31 21:34:55.182917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:34:55.183371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.695GHz coreCount: 16 deviceMemorySize: 7.92GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-31 21:34:55.183411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-31 21:34:55.183441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-31 21:34:55.183470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-07-31 21:34:55.183482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-07-31 21:34:55.183493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-07-31 21:34:55.183516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-07-31 21:34:55.183545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-31 21:34:55.183616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:34:55.184210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:34:55.184688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-31 21:34:55.184751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-31 21:34:55.665812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-31 21:34:55.665860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-31 21:34:55.665888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-31 21:34:55.666241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:34:55.666841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:34:55.667435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6988 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Epoch 1/12
2020-07-31 21:34:56.279338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-31 21:34:56.477766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
469/469 [==============================] - 4s 8ms/step - loss: 2.2858 - accuracy: 0.1543 - val_loss: 2.2619 - val_accuracy: 0.2190
Epoch 2/12
469/469 [==============================] - 3s 7ms/step - loss: 2.2462 - accuracy: 0.2411 - val_loss: 2.2135 - val_accuracy: 0.3888
Epoch 3/12
469/469 [==============================] - 3s 7ms/step - loss: 2.1951 - accuracy: 0.3359 - val_loss: 2.1482 - val_accuracy: 0.5546
Epoch 4/12
469/469 [==============================] - 3s 7ms/step - loss: 2.1254 - accuracy: 0.4195 - val_loss: 2.0573 - val_accuracy: 0.6437
Epoch 5/12
469/469 [==============================] - 3s 7ms/step - loss: 2.0294 - accuracy: 0.4904 - val_loss: 1.9342 - val_accuracy: 0.6910
Epoch 6/12
469/469 [==============================] - 3s 7ms/step - loss: 1.9057 - accuracy: 0.5410 - val_loss: 1.7749 - val_accuracy: 0.7224
Epoch 7/12
469/469 [==============================] - 3s 7ms/step - loss: 1.7500 - accuracy: 0.5860 - val_loss: 1.5826 - val_accuracy: 0.7497
Epoch 8/12
469/469 [==============================] - 3s 7ms/step - loss: 1.5807 - accuracy: 0.6156 - val_loss: 1.3772 - val_accuracy: 0.7735
Epoch 9/12
469/469 [==============================] - 3s 7ms/step - loss: 1.4153 - accuracy: 0.6406 - val_loss: 1.1840 - val_accuracy: 0.7954
Epoch 10/12
469/469 [==============================] - 3s 7ms/step - loss: 1.2699 - accuracy: 0.6618 - val_loss: 1.0213 - val_accuracy: 0.8093
Epoch 11/12
469/469 [==============================] - 3s 7ms/step - loss: 1.1508 - accuracy: 0.6834 - val_loss: 0.8939 - val_accuracy: 0.8220
Epoch 12/12
469/469 [==============================] - 3s 7ms/step - loss: 1.0579 - accuracy: 0.7003 - val_loss: 0.7974 - val_accuracy: 0.8316
Test loss: 0.7974222898483276
Test accuracy: 0.83160001039505
```

**Describe the expected behavior**

Downgraded keras to version 2.3.1 and run the script again, the outcome is consistent with older versions of keras before

Note that **Train on 60000 samples, validate on 10000 samples** is missing from the output above using keras 2.4.3.

```
python /home/bernard/python-dev/test/mnist_cnn_demo.py
Using TensorFlow backend.
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
2020-07-31 21:17:44.616490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-31 21:17:44.641796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:17:44.643804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.695GHz coreCount: 16 deviceMemorySize: 7.92GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-31 21:17:44.644032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-31 21:17:44.645151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-31 21:17:44.646009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-07-31 21:17:44.646247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-07-31 21:17:44.647392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-07-31 21:17:44.648247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-07-31 21:17:44.650968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-31 21:17:44.651097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:17:44.651925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:17:44.652674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-31 21:17:44.658691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2904000000 Hz
2020-07-31 21:17:44.659154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cb4a20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-31 21:17:44.659167: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-31 21:17:44.718817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:17:44.719399: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d43f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-31 21:17:44.719434: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-07-31 21:17:44.719622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:17:44.720238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.695GHz coreCount: 16 deviceMemorySize: 7.92GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-31 21:17:44.720286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-31 21:17:44.720299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-31 21:17:44.720330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-07-31 21:17:44.720343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-07-31 21:17:44.720354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-07-31 21:17:44.720379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-07-31 21:17:44.720390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-31 21:17:44.720463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:17:44.721061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:17:44.721531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-31 21:17:44.721574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-31 21:17:44.722447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-31 21:17:44.722457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-31 21:17:44.722479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-31 21:17:44.722716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:17:44.723177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-31 21:17:44.724393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7088 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
**Train on 60000 samples, validate on 10000 samples**
Epoch 1/12
2020-07-31 21:17:45.945316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-31 21:17:46.131405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Epoch 1/12
2020-07-31 21:24:25.101205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-31 21:24:25.295790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
60000/60000 [==============================] - 5s 91us/step - loss: 0.2614 - accuracy: 0.9188 - val_loss: 0.0578 - val_accuracy: 0.9811
Epoch 2/12
60000/60000 [==============================] - 4s 67us/step - loss: 0.0910 - accuracy: 0.9730 - val_loss: 0.0411 - val_accuracy: 0.9857
Epoch 3/12
60000/60000 [==============================] - 4s 67us/step - loss: 0.0656 - accuracy: 0.9805 - val_loss: 0.0407 - val_accuracy: 0.9862
Epoch 4/12
60000/60000 [==============================] - 4s 67us/step - loss: 0.0538 - accuracy: 0.9837 - val_loss: 0.0311 - val_accuracy: 0.9898
Epoch 5/12
60000/60000 [==============================] - 4s 67us/step - loss: 0.0483 - accuracy: 0.9850 - val_loss: 0.0288 - val_accuracy: 0.9904
Epoch 6/12
60000/60000 [==============================] - 4s 67us/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 0.0291 - val_accuracy: 0.9905
Epoch 7/12
60000/60000 [==============================] - 4s 67us/step - loss: 0.0381 - accuracy: 0.9888 - val_loss: 0.0283 - val_accuracy: 0.9902
Epoch 8/12
60000/60000 [==============================] - 4s 67us/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0286 - val_accuracy: 0.9914
Epoch 9/12
60000/60000 [==============================] - 4s 68us/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 0.0275 - val_accuracy: 0.9916
Epoch 10/12
60000/60000 [==============================] - 4s 74us/step - loss: 0.0314 - accuracy: 0.9909 - val_loss: 0.0276 - val_accuracy: 0.9916
Epoch 11/12
60000/60000 [==============================] - 5s 77us/step - loss: 0.0300 - accuracy: 0.9907 - val_loss: 0.0248 - val_accuracy: 0.9917
Epoch 12/12
60000/60000 [==============================] - 5s 77us/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0292 - val_accuracy: 0.9907
Test loss: 0.02923813719809523
Test accuracy: 0.9907000064849854
```

"
41949,E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] layout failed: Invalid argument: Size of values 0 does not match size of permutation 4 @ fanin shape ingradient_tape /replica_1/SelectV2_4-2-TransposeNHWCToNCHW-LayoutOptimizer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0 and tf-nightly
- Python version: 2.7
- CUDA/cuDNN version: 10.1
- GPU model and memory: v100

**Describe the current behavior**
Running a tf.keras fit method triggers this error in the logs. I am working with a really large codebase, hence providing a standlone code example is not feasible. Also finding what block of code is causing this isn't straightforwad for the same reason. Interestingly the fit method runs successfully even with this error popping up in the logs.


**Other info / logs** 
```
2020-08-01 11:02:39.503101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3
2020-08-01 11:02:39.503161: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-01 11:02:43.832731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-01 11:02:43.832785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 2 3
2020-08-01 11:02:43.832795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N Y Y Y
2020-08-01 11:02:43.832800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   Y N Y Y
2020-08-01 11:02:43.832805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   Y Y N Y
2020-08-01 11:02:43.832810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   Y Y Y N
2020-08-01 11:02:43.848539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14755 MB memory) -> p
hysical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:0a:00.0, compute capability: 7.0)
2020-08-01 11:02:43.854140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14755 MB memory) -> p
hysical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:0b:00.0, compute capability: 7.0)
2020-08-01 11:02:43.858886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 14755 MB memory) -> p
hysical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
2020-08-01 11:02:44.130409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 14755 MB memory) -> p
hysical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:10:00.0, compute capability: 7.0)
2020-08-01 11:03:44.659136: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] layout failed: Invalid argument: Size of values 0 does not match size of permutation 4 @ fanin
 shape ingradient_tape/replica_1/SelectV2_4-2-TransposeNHWCToNCHW-LayoutOptimizer
2020-08-01 11:03:57.040696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-01 11:04:01.069013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library 
```"
41948,Undefined symbols for architecture arm64 when loading TensorFlowLiteSelectTfOps on iOS device,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): iOS 13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone 11
- TensorFlow installed from (source or binary): binary
- TensorFlow version: TensorFlowLiteSwift (same issue with both 2.2.0 and 0.0.1-nightly), TensorFlowLiteSelectTfOps (0.0.1-nightly)
- Python version:
- Installed using virtualenv? pip? conda?: CocoaPods
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the problem**
I'm trying to integrate a tflite model that requires select TF ops with an iOS project, following the steps given here: https://www.tensorflow.org/lite/guide/ops_select#ios 
I created an empty Xcode project just to test out the setup, I installed the dependencies using CocoaPods, and then linked the TF ops, but when I build the project on a device I encountered the following error: Undefined symbol: _uprv_getICUData_conversion (see screenshot below):
![error-device](https://user-images.githubusercontent.com/23728605/89082882-4fa73980-d35d-11ea-8bba-b57de28c97c3.png)

And just to confirm, does select TF ops currently support simulator for iOS? I get a warning during build and the app crashes when the interpreter is invoked (see screenshot below):
![error-simulator](https://user-images.githubusercontent.com/23728605/89083018-b88eb180-d35d-11ea-9563-a36bb3a2d6ba.png)


**Provide the exact sequence of commands / steps that you executed before running into the problem**
1. Create a new project
2. Create a Podfile with TensorFlowLiteSwift and TensorFlowLiteSelectTfOps dependencies
3. Install dependencies and add linker flag
4. Build project


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
41945,Can't use tensorflow,"I'm trying to use keras, but the output says that keras requires tensorflow 2.2 or higher, which I already have installed. And when I try this command 
`import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello))`
Returns: 
`Traceback (most recent call last):

  File ""C:\Users\luiz_\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: Não foi possível encontrar o módulo especificado.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File ""<ipython-input-4-9d5f9c01b035>"", line 1, in <module>
    import tensorflow as tf

  File ""C:\Users\luiz_\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util

  File ""C:\Users\luiz_\anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context

  File ""C:\Users\luiz_\anaconda3\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe

  File ""C:\Users\luiz_\anaconda3\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow

  File ""C:\Users\luiz_\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)

ImportError: Traceback (most recent call last):
  File ""C:\Users\luiz_\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: Não foi possível encontrar o módulo especificado.


Failed to load the native TensorFlow runtime.`

Please help! I installed both tensorflow and keras with pip install"
41943,tflite on Android: Didn't find op for builtin opcode 'CONV_2D' version '5',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android emulator (Android 10.0+ (Google APIs))
- TensorFlow installed from (source or binary): Model was generated with TF from binary
- TensorFlow version (or github SHA if from source): Model was generated with `tf-2.2.0` and converted to tflite with `tf-nightly-2.4.0.dev20200730`. Using [`tflite` v1.1.1](https://pub.dev/packages/tflite) flutter bindings.

**Provide the text output from tflite_convert**

No issues with `tflite_convert` (thanks to @amahendrakar in #41877). My issue is with using my model on the mobile side, using the [`tflite`](https://pub.dev/packages/tflite) flutter bindings.

I'm getting the following error when I try to load my custom model:

```
Unsupported value: java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find op for builtin opcode 'CONV_2D' version '5'

Registration failed.
```

**Standalone code to reproduce the issue** 

See [this gist](https://gist.github.com/mgalgs/f92d78e6c7ee09b8298cd325bf4f3ed6). The error is happening when I try to [load the model](https://gist.github.com/mgalgs/f92d78e6c7ee09b8298cd325bf4f3ed6#file-home-dart-L31-L35).

If I swap out my custom generated tflite model (see #41877 for how the model was generated) for an off-the-shelf SSD model detection works just fine.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.

Stack trace:

**Dart**
```
StandardMethodCodec.decodeEnvelope (message_codecs.dart:569)
MethodChannel.invokeMethod (platform_channel.dart:321)
<asynchronous gap>
Tflite.loadModel (tflite.dart:15)
_HomePageState.loadModel (home.dart:30)
_HomePageState.initState (home.dart:26)
StatefulElement._firstBuild (framework.dart:4355)
ComponentElement.mount (framework.dart:4201)
Element.inflateWidget (framework.dart:3194)
Element.updateChild (framework.dart:2988)
... snipped a bunch of framework stuff ...
```

**Native (Android)**
```
java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find op for builtin opcode 'CONV_2D' version '5'

Registration failed.

	at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)
	at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:72)
	at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)
	at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:266)
	at sq.flutter.tflite.TflitePlugin.loadModel(TflitePlugin.java:232)
	at sq.flutter.tflite.TflitePlugin.onMethodCall(TflitePlugin.java:98)
	at io.flutter.plugin.common.MethodChannel$IncomingMethodCallHandler.onMessage(MethodChannel.java:230)
	at io.flutter.embedding.engine.dart.DartMessenger.handleMessageFromDart(DartMessenger.java:85)
	at io.flutter.embedding.engine.FlutterJNI.handlePlatformMessage(FlutterJNI.java:692)
	at android.os.MessageQueue.nativePollOnce(Native Method)
	at android.os.MessageQueue.next(MessageQueue.java:335)
	at android.os.Looper.loop(Looper.java:183)
	at android.app.ActivityThread.main(ActivityThread.java:7476)
	at java.lang.reflect.Method.invoke(Native Method)
	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:549)
	at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:939)
```"
42239,[TF 2.2] tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null,"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): pip install tensorflow==2.0.0
Python version:3.7.5
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Describe the current behavior
I am able to export the model with tf.saved_model.save but when I try to run the exported model with tf-serving, it runs to seg fault and running the saved_model_cli throws the error attached

Describe the expected behavior

The exported model from tf.saved_model.save should work correctly with tf-serving

Standalone code to reproduce the issue

```
class NGramTF(tf.Module):
    def __init__(self):
        self.oov_score = 0
        self.pseudo_count = 5.0
        pass

    def fit_tf_lookup_table(self, dist):
        keys_tensor = tf.constant(list(dist.keys()))
        vals_tensor = tf.constant(list(dist.values()))
        initializer = tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor)
        table = tf.lookup.StaticHashTable(initializer, self.oov_score)
        return table

    def fit_word_casing(self, wordCasingLookup):
        indices = []
        values = []
        tokens = []
        for idx, (token, items) in enumerate(wordCasingLookup.items()):
            tokens.append(token)
            for j, item in enumerate(items):
                indices.append([idx, j])
                values.append(item)
        word_casing_lookup_shape = [len(tokens), max([len(item) for item in wordCasingLookup.values()])]
        word_casing_lookup_tf = tf.SparseTensor(indices=indices, values=values, dense_shape=word_casing_lookup_shape)
        word_casing_indices = tf.range(0, len(tokens))
        dense_word_casing_lookup_tf = tf.sparse.to_dense(word_casing_lookup_tf, default_value='')

        initializer = tf.lookup.KeyValueTensorInitializer(tf.constant(tokens), word_casing_indices)

        # TODO: this does ot work
        table = tf.lookup.StaticHashTable(initializer, -1)
        return table, dense_word_casing_lookup_tf

    def fit(self, wordCasingLookup, uniDist, backwardBiDist, forwardBiDist, trigramDist):
        self.word_casing, self.word_casing_lookup = self.fit_word_casing(wordCasingLookup)
        self.tf_uni_dist = self.fit_tf_lookup_table(uniDist)
        self.backwardBiDist = self.fit_tf_lookup_table(backwardBiDist)
        self.forwardBiDist = self.fit_tf_lookup_table(forwardBiDist)
        self.trigramDist = self.fit_tf_lookup_table(trigramDist)
```

Code to export the model:

```
def load_truecasing_model(model_filename):
    with open(model_filename, 'rb') as bin_file:  # from s3://workfit-models/auto-punc/
        uni_dist = pickle.load(bin_file)
        backward_bi_dist = pickle.load(bin_file)
        forward_bi_dist = pickle.load(bin_file)
        trigram_dist = pickle.load(bin_file)
        word_casing_lookup = pickle.load(bin_file)
        return word_casing_lookup, uni_dist, backward_bi_dist, forward_bi_dist, trigram_dist

truecaser_weights = 'en/en_truecasing_model.obj'
export_path = './truecaser_serving/1/'
wordCasingLookup, uniDist, backwardBiDist, forwardBiDist, trigramDist = load_truecasing_model(truecaser_weights)
tf_model = truecaser_tf.NGramTF()
tf_model.fit(wordCasingLookup, uniDist, backwardBiDist, forwardBiDist, trigramDist)
signature_def = tf_model.get_true_case.get_concrete_function(
        tf.TensorSpec(shape=(None), dtype=tf.string, name=""input_text""))
tf.saved_model.save(tf_model,export_path,signatures={'serving_default': signature_def})

```

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['__saved_model_init_op']:
  The given SavedModel SignatureDef contains the following input(s):
  The given SavedModel SignatureDef contains the following output(s):
    outputs['__saved_model_init_op'] tensor_info:
        dtype: DT_INVALID
        shape: unknown_rank
        name: NoOp
  Method name is: 

signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['input_text'] tensor_info:
        dtype: DT_STRING
        shape: unknown_rank
        name: serving_default_input_text:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['output_0'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: StatefulPartitionedCall_5:0
  Method name is: tensorflow/serving/predict
2020-07-31 10:32:36.828182: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-31 10:32:36.864779: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffd54e04ae0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-31 10:32:36.864800: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version

Defined Functions:
  Function Name: 'get_true_case'
    Option tensorflow/serving#1
      Callable with:
        Argument tensorflow/serving#1
          input_text: TensorSpec(shape=<unknown>, dtype=tf.string, name='input_text')
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x12f849050>
Traceback (most recent call last):
tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x12f849050>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py"", line 191, in __del__
    self._destroy_resource()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 241, in restored_function_body
    return _call_concrete_function(function, inputs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 72, in _call_concrete_function
    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 101, in _call_flat
    cancellation_manager)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1760, in _call_flat
    flat_outputs = forward_function.call(ctx, args_with_tangents)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 627, in call
    executor_type=executor_type)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/functional_ops.py"", line 1165, in partitioned_call
    f.add_to_graph(graph)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 543, in add_to_graph
    g._add_function(self)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3187, in _add_function
    gradient)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null
WARNING:tensorflow:Unresolved object in checkpoint: (root).word_casing._initializer
WARNING:tensorflow:Unresolved object in checkpoint: (root).tf_uni_dist._initializer
WARNING:tensorflow:Unresolved object in checkpoint: (root).backwardBiDist._initializer
WARNING:tensorflow:Unresolved object in checkpoint: (root).forwardBiDist._initializer
WARNING:tensorflow:Unresolved object in checkpoint: (root).trigramDist._initializer
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
```

The code can be accessed here to look at the entire source code:
https://github.com/ayushch3/truecaser_tf

The weights file can be accessed here: https://drive.google.com/file/d/1DpmsDYm-gzcwXCJT4sMCUXmtHGSxKiIR/view?usp=sharing"
41941,Tensorflow 2.2.0 require scipy-1.4.1??,"**System information**
- OS Platform and Distribution :Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.2.0
- Python version: 3.8.5
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version:  Cuda10.0, cudnn 7.6.5.32
- GPU model and memory: GTX1070 , 8G

**Describe the problem**
installing tensorflow removes existing scipy 1.5.2 and installs 1.4.1

**Provide the exact sequence of commands / steps that you executed before running into the problem**

After building tensorflow2.2.0 successfully, I installed it with
```
pip install --no-cache-dir tensorflow-2.2.0-cp38-cp38-linux_x86_64.whl
```
(pip = pip3 in my set up)

It was installed successfully and I checked the installation with some tests, all passed. But it uninstalls my already exist scipy 1.5.2 and installed 1.4.1

```
Attempting uninstall: scipy
    Found existing installation: scipy 1.5.2
    Uninstalling scipy-1.5.2:
      Successfully uninstalled scipy-1.5.2
```
"
41940,AOT compiled graph is 2-7x slower than Python,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2
- Python version: 3.6.8
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**

For `tf.matmul` and `tf.linalg.triangular_solve` AOT is much slower (2-7x) than the equivalent TF-Python version. For `triangular_solve`, which is easy to hand-code, this also applies wrt bespoke C implementation.

**Describe the expected behavior**

I expect that the computation time of the AOT compiled graph is better than the Python counterpart.

**Standalone code to reproduce the issue**

The graph is the following:

```python
def trisolve(A, b):
    """""" Builds a graph. A is a lower-triangular MxM matrix, b is a Mx1 column vector """"""    
    res = tf.linalg.triangular_solve(A, b, lower=True)    
    return res

M = 2048
predict_fn = tf.function(trisolve,
        input_signature=[tf.TensorSpec(shape=[M,M], dtype=tf.float64, name='A'),
        tf.TensorSpec(shape=[M,1], dtype=tf.float64, name='b')], experimental_compile=False)
    
module_to_save = tf.Module()
module_to_save.predict = predict_fn
tf.saved_model.save(module_to_save, 'saved_model', signatures={'serving_default': module_to_save.predict})
```

The graph is then compiled with:
```bash
$ cd saved_model
$ saved_model_cli aot_compile_cpu --checkpoint_path .\variables\variables --dir . --signature_def_key serving_default --target_triple x86_64-none-windows --cpp_class trisolve --output_prefix libs64/libtrisolve --tag_set serve
```

and is linked to a simple cpp file that just runs the model for benchmark.

```cpp
#include <iostream>
#include ""third_party/eigen3/unsupported/Eigen/CXX11/Tensor""
#include ""libtrisolve.h"" // generated
#include <chrono>
#include <fstream>

using namespace std::chrono;

#define M 2048

int main(int argc, char** argv) {  
  trisolve model;  

  int i, j, idx;
  double *test_A;   // Initialize with a MxM lower triangular matrix
  double *test_b;   // Initialize with a Mx1 vector

  std::copy(test_A, test_A+M*M, model.arg0_data());
  std::copy(test_b, test_b+M, model.arg1_data());
  
  int N = 1000;
  auto tStart = high_resolution_clock::now(); 
  for (int i = 0; i < N; i++)
    model.Run();
  auto tEnd = high_resolution_clock::now();
  auto duration = duration_cast<microseconds>((tEnd - tStart)/N); 
  std::cout << ""Time TF Compiled: "" << duration.count() << ""us"" << std::endl;

  return 0;
}
```

**Performance Issue:**

Triangular Solve (as above):
- A very simple single-threaded C++ implementation takes just 2ms;
- Running the triangular solve from the Python code, takes ~3ms;
- Running the compiled executable, instead, takes 17ms.

MatMul (multiplication of two square matrices 2048x2048):
- Python version takes ~150ms
- Compiled version takes ~370ms
"
41938,Unresolved symbol EigenMatMulF64 when linking a compiled graph with XLA AOT runtime,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2
- Python version: 3.6.8
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**

When compiling a Tensorflow graph compiled using `saved_model_cli aot_compile_cpu`, the following linking error occurs:

```
libcholesky.o : error LNK2019: unresolved external symbol __xla_cpu_runtime_EigenMatMulF64 referenced in function entry_34875272679f13979ced813466bdebb0 [C:\Projects\aot\aot\tests\mve\build\main.vcxproj]
C:\Projects\aot\aot\tests\mve\build\Release\main.exe : fatal error LNK1120: 1 unresolved externals [C:\Projects\aot\aot\tests\mve\build\main.vcxproj]
```

I think this is because the AOT compile references ""tensorflow/include/tensorflow/compiler/xla/service/cpu/runtime_matmul.h"" instead of ""tensorflow/include/tensorflow/compiler/xla/service/cpu/runtime_single_threaded_matmul.h"".

**Describe the expected behavior**

I expect that the exported model can be compiled by referencing only the files in ""tensorflow/xla_aot_runtime_src"", as stated [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/BUILD#L193).

**Standalone code to reproduce the issue**

I used and saved the following graph:

```python
def cholesky(A, b):
    """""" Builds a graph """"""    
    A = tf.linalg.cholesky(A) 
    res = tf.linalg.triangular_solve(A, b)     
    return res

M = 4
predict_fn = tf.function(cholesky,
        input_signature=[tf.TensorSpec(shape=[M,M], dtype=tf.float64, name='A'), tf.TensorSpec(shape=[M,1], dtype=tf.float64, name='b')], experimental_compile=False)

module_to_save = tf.Module()
module_to_save.predict = predict_fn
tf.saved_model.save(module_to_save, 'saved_model', signatures={'serving_default': module_to_save.predict})
```

Then I compiled the graph using the `saved_model_cli` script:

```bash
$ cd saved_model
$ saved_model_cli aot_compile_cpu --checkpoint_path .\variables\variables --dir . --signature_def_key serving_default --target_triple x86_64-none-windows --cpp_class cholesky --output_prefix libs64/libcholesky --tag_set serve
```

Compiling this sample `main.cpp` and linking it against the generated library above and the [XLA AOT CPU runtime that ships with the pip package](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/BUILD#L193) produces the linking error above.

```cpp
#include <iostream>
#include ""third_party/eigen3/unsupported/Eigen/CXX11/Tensor""
#include ""libcholesky.h"" // generated

#define M 4

int main(int argc, char** argv) {  
  cholesky model;  

  int i, j, idx;
  double test_A[] = {1.0583131 , 0.8570645 , 0.77131426, 0.9754439, 0.8570645 , 0.8788354 , 0.6582537 , 0.88981044,0.77131426, 0.6582537 , 0.6411602 , 0.7668645,
       0.9754439 , 0.88981044, 0.7668645 , 1.3106735 };

  double test_b[] = {1, 2, 3, 4};

  std::copy(test_A, test_A+M*M, model.arg0_data());
  std::copy(test_b, test_b+M, model.arg1_data());
  model.Run();
 
  std::cout << model.result0_data()[0] << std::endl;

  return 0;
}
```

**Other info / logs** 
"
41937,tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error,"I am trying to build an image with Centos and tensorflow 1.14 GPU, I have installed in the host the Cuda 10 and tried also 11, in the image i tried 10 and also 11 , different versions and I keep getting below error

tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error

Full Error:
>>> import tensorflow as tf
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
>>> print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
2020-07-31 16:03:16.558174: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-07-31 16:03:16.562049: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error
2020-07-31 16:03:16.562109: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: c15680640844
2020-07-31 16:03:16.562130: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: c15680640844
2020-07-31 16:03:16.562276: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 418.152.0
2020-07-31 16:03:16.562335: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.152.0
2020-07-31 16:03:16.562359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 418.152.0
Num GPUs Available:  0

I tried nvidia-modprobe, check /dev/nvidia script, install different cudn, nvidia-smi working fine...etc

System Info:

Python 3.6.9
tensorflow-estimator (1.14.0)
tensorflow-gpu (1.14.0)

kmod-nvidia-latest-dkms-418.152.00-1.el7.x86_64
nvidia-modprobe-latest-418.152.00-1.el7.x86_64
nvidia-driver-latest-NvFBCOpenGL-418.152.00-1.el7.x86_64
nvidia-driver-latest-devel-418.152.00-1.el7.x86_64
nvidia-driver-latest-418.152.00-1.el7.x86_64
nvidia-driver-local-repo-rhel7-418.152.00-1.0-1.x86_64
nvidia-driver-latest-cuda-libs-418.152.00-1.el7.x86_64
nvidia-xconfig-latest-418.152.00-1.el7.x86_64

Fri Jul 31 16:02:21 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.152.00   Driver Version: 418.152.00   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla M60           Off  | 00000000:00:1B.0 Off |                    0 |
| N/A   39C    P0    42W / 150W |      0MiB /  7618MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla M60           Off  | 00000000:00:1C.0 Off |                    0 |
| N/A   35C    P0    41W / 150W |      0MiB /  7618MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla M60           Off  | 00000000:00:1D.0 Off |                    0 |
| N/A   36C    P0    47W / 150W |      0MiB /  7618MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla M60           Off  | 00000000:00:1E.0 Off |                    0 |
| N/A   35C    P0    47W / 150W |      0MiB /  7618MiB |     53%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+




This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
41934,tf.image.resize with bilinear breaks mixed precision,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
- TensorFlow installed from (source or binary):conda
- TensorFlow version (use command below):2.1/2.2/2.3
- Python version:3.7
- CUDA/cuDNN version:10.1
- GPU model and memory:v100 32GB

Use tf.image.resize with BILINEAR upsampling breaks mixed precision and makes the speed much slower than fp32. Change to NEAREST_NEIGHBOR works
"
41933,"Documentation fix of ""Text Classification with Movie Reviews""","This is the same issue mentioned [here](https://github.com/tensorflow/tensorflow/issues/41413).

Currently [here](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_text_classification.ipynb#scrollTo=zXXx5Oc3pOmN) under 'Loss function and optimizer' it says:

```
model.compile(optimizer='adam',
              loss=tf.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

This needs to be corrected to:


`model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])`
"
41932,Only 1 subgraph is currently supported - CMSIS-NN,"@tensorflow/micro

System information

Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): make with Linux Ubuntu 20.04, complied on Atmel Studio on Windows 10, Python 3.7.7
TensorFlow installed from (source or binary): downloaded from master
Tensorflow version (commit SHA if source): 2.3.0, e544dce
Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Atmel SAMD51 - Atmel Studio

**Describe the problem**
After some issue to link correctly the TFLite with cmsis-nn kernels files into my Atmel Studio project I have built a static library with Atmel Studio and linked the .a file. To do that I make the project with TAGS=cmsis-nn, copy the the files from a Keil project (I used the image recognition example) from the make directory and compile with Atmel Studio to get the .a file.

When I run inference compiling the C files (obtained without the cmsis-tag in the Tensorflow-Lite subdirectory of the image recognition example in the make folder) within the project everything works fine. When I run inference with the static library obtained from making with the cmsis-nn tag I get the following error: ""Only 1 subgraph is currently supported. Exiting with status 1"". The flatbuffer file is the same.

**Please provide the exact sequence of commands/steps when you ran into the problem**
Please refere to this Colab to see the python code: https://drive.google.com/file/d/1k-9Id6ljpf4EjlcYIy6D4-fAHwOg1hI-/view?usp=sharing
Please refere there to see the trained models: https://drive.google.com/drive/folders/1hQgInGGy3A7EEOB0xZHw5CgheXp8nl_9?usp=sharing
Please refere there for the project (in the cmsis-nn brench): https://github.com/Sixaxis9/TFLite-SAMD51
Replicating the issue: copying and pasting the flatbuffer inside a working project with the cmsis-nn version of TFLite, loading the model and running inference."
41931,Error with TFlite hello world example on ESP-EYE,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 2.4.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP-EYE

**Describe the problem**

I am trying to setup the ESP-EYE for TFlite. I have been able to set up the ESP-EYE for basic setup as per: https://docs.espressif.com/projects/esp-idf/en/stable/get-started/index.html. I am also able to use the AWS IoT example https://github.com/espressif/esp-aws-iot/tree/master/examples.

For TFlite, I am trying out the example for ESP-EYE at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/README.md

When I try to compile this per the instructions above for ESP-EYE, I am getting a compiler error:

cc1plus: error: command line option '-std=c11' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: error: command line option '-std=c11' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: all warnings being treated as errors

**Please provide the exact sequence of commands/steps when you ran into the problem**

Per the steps at the TFlite link above:

Generate the examples The example project can be generated with the following command:
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project

Building the example Go the the example project directory
cd tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/hello_world/esp-idf

Then build with idf.py

idf.py build
I get this error repeatedly:

cc1plus: error: command line option '-std=c11' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: error: command line option '-std=c11' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: all warnings being treated as errors

The error does go away if I remove -Werror in the below line in components/tfmicro/CMakeLists.txt:

target_compile_options(${COMPONENT_LIB} PRIVATE $<$<COMPILE_LANGUAGE:CXX>: -std=c++11 -DTF_LITE_STATIC_MEMORY -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -DNDEBUG -O3 -Wno-return-type -Wno-strict-aliasing -Wno-ignored-qualifiers -Wno-return-type -Wno-strict-aliasing -Wno-ignored-qualifiers -Wno-return-type -Wno-strict-aliasing -Wno-return-type -Wno-strict-aliasing >)

But the image when flashed, does not work. It keeps crashing with a register dump.

Any suggestions for this issue?"
41930,Unusable code in the Overfit and Underfit tutotial for beginners,"## URL(s) with the issue:

https://www.tensorflow.org/tutorials/keras/overfit_and_underfit

## Description of issue (what needs changing):

### Clear description

The unbatch() method is apparently deprecated, hence TF v. 1.14.0 (used in Jupyter Notebook) complains about the following line
`packed_ds = ds.batch(10000).map(pack_row).unbatch()`

The error:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-37-58db46f67dc2> in <module>
----> 1 packed_ds = ds.batch(10000).map(pack_row).unbatch()

AttributeError: 'DatasetV1Adapter' object has no attribute 'unbatch'
```
I hope this helps to improve the tutorial!"
41929,TF 2.3 broken hierarchical functional model loading (e.g. HAN) [ValueError: Unknown layer: Functional],"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.3
Python version: 3.6.9
CUDA/cuDNN version: v10.2
GPU model and memory: GeForce GTX 1070 - 8117MiB

Describe the current behavior:
I cannot load a model trained with TF 2.3 in TF 2.2 -> **breaking change**
In TF 2.3 the release notes mention the following: 
`Functional models now get constructed if any tensor in a layer call's arguments/keyword arguments comes from a keras input. Previously the functional api would only work if all of the elements in the first argument to the layer came from a keras input.`

I have a hierarchical attention model, trained either with TF2.2 with the following underlying config: 
```
{'name': 'HAN_DocSent', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 150, None), 'dtype': 'int32', 'sparse': False, 'ragged': False, 'name': 'input_1'}, 'name': 'input_1', 'inbound_nodes': []}, {'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed', 'trainable': True, 'dtype': 'float32', 'layer': {'class_name': 'Model', 'config': {'name': 'HAN_SentWord', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, None), 'dtype': 'int32', 'sparse': False, 'ragged': False, 'name': 'word/sentence_input'}, 'name': 'word/sentence_input', 'inbound_nodes': []}, {'class_name': 'Embedding', 'config': {'name': 'word_embedding', 'trainable': True, 'batch_input_shape': (None, None), 'dtype': 'float32', 'input_dim': 20002, 'output_dim': 300, 'embeddings_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': True, 'input_length': None}, 'name': 'word_embedding', 'inbound_nodes': [[['word/sentence_input', 0, 0, {}]]]}, {'class_name': 'Bidirectional', 'config': {'name': 'bidirectional', 'trainable': True, 'dtype': 'float32', 'layer': {'class_name': 'GRU', 'config': {'name': 'gru', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 100, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.25, 'recurrent_dropout': 0.25, 'implementation': 1, 'reset_after': True}}, 'merge_mode': 'concat'}, 'name': 'bidirectional', 'inbound_nodes': [[['word_embedding', 0, 0, {}]]]}, {'class_name': 'HierarchicalAttention', 'config': {'name': 'word_attention', 'trainable': True, 'dtype': 'float32'}, 'name': 'word_attention', 'inbound_nodes': [[['bidirectional', 0, 0, {}]]]}], 'input_layers': [['word/sentence_input', 0, 0]], 'output_layers': [['word_attention', 0, 0]]}}}, 'name': 'time_distributed', 'inbound_nodes': [[['input_1', 0, 0, {}]]]}, {'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_1', 'trainable': True, 'dtype': 'float32', 'layer': {'class_name': 'GRU', 'config': {'name': 'gru_1', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 100, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.25, 'recurrent_dropout': 0.25, 'implementation': 1, 'reset_after': True}}, 'merge_mode': 'concat'}, 'name': 'bidirectional_1', 'inbound_nodes': [[['time_distributed', 0, 0, {}]]]}, {'class_name': 'HierarchicalAttention', 'config': {'name': 'sentence_attention', 'trainable': True, 'dtype': 'float32'}, 'name': 'sentence_attention', 'inbound_nodes': [[['bidirectional_1', 0, 0, {}]]]}, {'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 31, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'name': 'dense_2', 'inbound_nodes': [[['sentence_attention', 0, 0, {}]]]}], 'input_layers': [['input_1', 0, 0]], 'output_layers': [['dense_2', 0, 0]]}
```
Yet in TF 2.3 the saved config is differently wrapped with ""Functional"": 
```
{""class_name"": ""Functional"", ""config"": {""name"": ""HAN_DocSent"", ""layers"": [{""class_name"": ""InputLayer"", ""config"": {""batch_input_shape"": [null, 30, null], ""dtype"": ""int32"", ""sparse"": false, ""ragged"": false, ""name"": ""input_1""}, ""name"": ""input_1"", ""inbound_nodes"": []}, {""class_name"": ""TimeDistributed"", ""config"": {""name"": ""time_distributed"", ""trainable"": true, ""dtype"": ""float32"", ""layer"": {""class_name"": ""Functional"", ""config"": {""name"": ""HAN_SentWord"", ""layers"": [{""class_name"": ""InputLayer"", ""config"": {""batch_input_shape"": [null, null], ""dtype"": ""int32"", ""sparse"": false, ""ragged"": false, ""name"": ""word/sentence_input""}, ""name"": ""word/sentence_input"", ""inbound_nodes"": []}, {""class_name"": ""Embedding"", ""config"": {""name"": ""word_embedding"", ""trainable"": true, ""batch_input_shape"": [null, null], ""dtype"": ""float32"", ""input_dim"": 20000, ""output_dim"": 50, ""embeddings_initializer"": {""class_name"": ""RandomUniform"", ""config"": {""minval"": -0.05, ""maxval"": 0.05, ""seed"": null}}, ""embeddings_regularizer"": null, ""activity_regularizer"": null, ""embeddings_constraint"": null, ""mask_zero"": true, ""input_length"": null}, ""name"": ""word_embedding"", ""inbound_nodes"": [[[""word/sentence_input"", 0, 0, {}]]]}, {""class_name"": ""Bidirectional"", ""config"": {""name"": ""bidirectional"", ""trainable"": true, ""dtype"": ""float32"", ""layer"": {""class_name"": ""GRU"", ""config"": {""name"": ""gru"", ""trainable"": true, ""dtype"": ""float32"", ""return_sequences"": true, ""return_state"": false, ""go_backwards"": false, ""stateful"": false, ""unroll"": false, ""time_major"": false, ""units"": 100, ""activation"": ""tanh"", ""recurrent_activation"": ""sigmoid"", ""use_bias"": true, ""kernel_initializer"": {""class_name"": ""GlorotUniform"", ""config"": {""seed"": null}}, ""recurrent_initializer"": {""class_name"": ""Orthogonal"", ""config"": {""gain"": 1.0, ""seed"": null}}, ""bias_initializer"": {""class_name"": ""Zeros"", ""config"": {}}, ""kernel_regularizer"": null, ""recurrent_regularizer"": null, ""bias_regularizer"": null, ""activity_regularizer"": null, ""kernel_constraint"": null, ""recurrent_constraint"": null, ""bias_constraint"": null, ""dropout"": 0.5, ""recurrent_dropout"": 0.25, ""implementation"": 1, ""reset_after"": true}}, ""merge_mode"": ""concat""}, ""name"": ""bidirectional"", ""inbound_nodes"": [[[""word_embedding"", 0, 0, {}]]]}, {""class_name"": ""HierarchicalAttention"", ""config"": {""name"": ""word_attention"", ""trainable"": true, ""dtype"": ""float32""}, ""name"": ""word_attention"", ""inbound_nodes"": [[[""bidirectional"", 0, 0, {}]]]}], ""input_layers"": [[""word/sentence_input"", 0, 0]], ""output_layers"": [[""word_attention"", 0, 0]]}}}, ""name"": ""time_distributed"", ""inbound_nodes"": [[[""input_1"", 0, 0, {}]]]}, {""class_name"": ""Bidirectional"", ""config"": {""name"": ""bidirectional_1"", ""trainable"": true, ""dtype"": ""float32"", ""layer"": {""class_name"": ""GRU"", ""config"": {""name"": ""gru_1"", ""trainable"": true, ""dtype"": ""float32"", ""return_sequences"": true, ""return_state"": false, ""go_backwards"": false, ""stateful"": false, ""unroll"": false, ""time_major"": false, ""units"": 100, ""activation"": ""tanh"", ""recurrent_activation"": ""sigmoid"", ""use_bias"": true, ""kernel_initializer"": {""class_name"": ""GlorotUniform"", ""config"": {""seed"": null}}, ""recurrent_initializer"": {""class_name"": ""Orthogonal"", ""config"": {""gain"": 1.0, ""seed"": null}}, ""bias_initializer"": {""class_name"": ""Zeros"", ""config"": {}}, ""kernel_regularizer"": null, ""recurrent_regularizer"": null, ""bias_regularizer"": null, ""activity_regularizer"": null, ""kernel_constraint"": null, ""recurrent_constraint"": null, ""bias_constraint"": null, ""dropout"": 0.5, ""recurrent_dropout"": 0.25, ""implementation"": 1, ""reset_after"": true}}, ""merge_mode"": ""concat""}, ""name"": ""bidirectional_1"", ""inbound_nodes"": [[[""time_distributed"", 0, 0, {}]]]}, {""class_name"": ""HierarchicalAttention"", ""config"": {""name"": ""sentence_attention"", ""trainable"": true, ""dtype"": ""float32""}, ""name"": ""sentence_attention"", ""inbound_nodes"": [[[""bidirectional_1"", 0, 0, {}]]]}, {""class_name"": ""Dense"", ""config"": {""name"": ""dense_2"", ""trainable"": true, ""dtype"": ""float32"", ""units"": 5, ""activation"": ""softmax"", ""use_bias"": true, ""kernel_initializer"": {""class_name"": ""GlorotUniform"", ""config"": {""seed"": null}}, ""bias_initializer"": {""class_name"": ""Zeros"", ""config"": {}}, ""kernel_regularizer"": null, ""bias_regularizer"": null, ""activity_regularizer"": null, ""kernel_constraint"": null, ""bias_constraint"": null}, ""name"": ""dense_2"", ""inbound_nodes"": [[[""sentence_attention"", 0, 0, {}]]]}], ""input_layers"": [[""input_1"", 0, 0]], ""output_layers"": [[""dense_2"", 0, 0]]}}'
```
The error, of course, relates to the internal model which now compiles to a ""Functional"" model: 
`ValueError: Unknown layer: Functional`
The errors occurs in this line: 
```/media/hdd/.virtualenvs/arkham/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py(177)load_model_from_hdf5()
-> model = model_config_lib.model_from_config(model_config, ...)
```

Describe the expected behavior:
Model loading stays stable between releases...

Standalone code to reproduce the issue
I cannot share the code due to proprietary rights... yet since it is reported in the release, it should be straightforward to find a solution.
E.g. should I change the way I load my model? 
"
41926,Tensorflow-2.3.0 build failed,"**System information**
- OS Platform and Distribution :Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.3.0
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version:  Cuda10.0, cudnn 7.6.5.32
- GPU model and memory: GTX1070 , 8G

**Describe the problem**
Cannot build tensorflow

Tensorflow configured with cuda and tensorrt enabled

build with

```
bazel build --config=opt --config=cuda --copt=-mavx --copt=-mavx2 --copt=-msse4.1 --copt=-msse4.2 --copt=-mfma --copt=-mfpmath=both //tensorflow/tools/pip_package:build_pip_package 
```

build failed with these output

```
INFO: From ProtoCompile tensorflow/lite/toco/toco_flags.pb.h:
bazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.
ERROR: /home/bernard/opt/python38/tensorflow-2.3.0/tensorflow/core/kernels/BUILD:5123:1: C++ compilation of rule '//tensorflow/core/kernels:dilation_ops_gpu' failed (Exit 1)
external/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.h: In function ‘constexpr absl::lts_2020_02_25::time_internal::cctz::detail::civil_day absl::lts_2020_02_25::time_internal::cctz::detail::next_weekday(absl::lts_2020_02_25::time_internal::cctz::detail::civil_day, absl::lts_2020_02_25::time_internal::cctz::detail::weekday)’:
external/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.h:567:20: error: call to non-constexpr function ‘absl::lts_2020_02_25::time_internal::cctz::detail::civil_time<absl::lts_2020_02_25::time_internal::cctz::detail::day_tag> absl::lts_2020_02_25::time_internal::cctz::detail::operator+(absl::lts_2020_02_25::time_internal::cctz::detail::civil_time<absl::lts_2020_02_25::time_internal::cctz::detail::day_tag>, absl::lts_2020_02_25::time_internal::cctz::diff_t)’
           return cd + (j - i);
                    ^
external/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.h: In function ‘constexpr absl::lts_2020_02_25::time_internal::cctz::detail::civil_day absl::lts_2020_02_25::time_internal::cctz::detail::prev_weekday(absl::lts_2020_02_25::time_internal::cctz::detail::civil_day, absl::lts_2020_02_25::time_internal::cctz::detail::weekday)’:
external/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.h:587:20: error: call to non-constexpr function ‘absl::lts_2020_02_25::time_internal::cctz::detail::civil_time<absl::lts_2020_02_25::time_internal::cctz::detail::day_tag> absl::lts_2020_02_25::time_internal::cctz::detail::operator-(absl::lts_2020_02_25::time_internal::cctz::detail::civil_time<absl::lts_2020_02_25::time_internal::cctz::detail::day_tag>, absl::lts_2020_02_25::time_internal::cctz::diff_t)’
           return cd - (j - i);
                    ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1001.142s, Critical Path: 93.36s
INFO: 4993 processes: 4993 local.
FAILED: Build did NOT complete successfully
```


"
41924,Building From Source on Ubuntu TMP directory defaults to 'C:\Windows\Temp,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version:2.3.0
- Python version:3.8.0
- Bazel version (if compiling from source):3.1.0

**Describe the problem**

$ bazel build -c opt //tensorflow/tools/lib_package:libtensorflow

Warning shows 

`Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default`

Full output

```
bazel build -c opt //tensorflow/tools/lib_package:libtensorflow
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=179
INFO: Reading rc options for 'build' from /home/russell/git/go/src/github.com/tensorflow/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/russell/git/go/src/github.com/tensorflow/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /home/russell/git/go/src/github.com/tensorflow/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/russell/anaconda3/bin/python3 --action_env PYTHON_LIB_PATH=/home/russell/anaconda3/lib/python3.8/site-packages --python_path=/home/russell/anaconda3/bin/python3 --config=xla --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-10.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=7.5 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-9 --config=cuda --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /home/russell/git/go/src/github.com/tensorflow/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/russell/git/go/src/github.com/tensorflow/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/russell/git/go/src/github.com/tensorflow/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:cuda in file /home/russell/git/go/src/github.com/tensorflow/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/russell/git/go/src/github.com/tensorflow/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1
INFO: Found applicable config definition build:linux in file /home/russell/git/go/src/github.com/tensorflow/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/russell/git/go/src/github.com/tensorflow/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
DEBUG: /home/russell/.cache/bazel/_bazel_russell/8890081aadea2dff92679e25965ee39c/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:5: 
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default

```"
41918,pbfile output different result with checkpoint when using slim model,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
41917,ragged.boolean_mask() gives a different result when executed in a model,"```
mask = tf.ones((1, 100, 300), dtype=bool)

data = tf.ragged.boolean_mask(
    data=tf.ones((1,100,300,12)),
    mask=mask
).to_tensor()

print(data)
```

This gives me `tf.Tensor(......, shape=(1, 100, 300, 12), dtype=float32)` when executed normally, but when it is executed in a model it gives me `Tensor(""model/attention/RaggedToTensor/RaggedTensorToTensor:0"", shape=(None, None, None, 12), dtype=float32)`.

Why is this? How do I get it to return the correctly masked tensor in a model?"
41915,tf.math.reduce_euclidean_norm can not be in tf.function with experimental_compile=True,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0-dev20200730
- Python version: colab
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: no

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

```
EuclideanNorm: unsupported op: No registered 'EuclideanNorm' OpKernel for XLA_CPU_JIT devices compatible with node {{node EuclideanNorm}}
```

**Describe the expected behavior**

The op can run as usual.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python3
import tensorflow as tf

x = tf.complex(tf.random.uniform(shape=(5, 5)), tf.random.uniform(shape=(5, 5)))

@tf.function(experimental_compile=True)
def reduce_euclidean_norm(x):
  return tf.math.reduce_euclidean_norm(x)

print(reduce_euclidean_norm(x))
```

https://colab.research.google.com/drive/1YENmpGDLU6kCupseizWTO1wBiDDj8v9x?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41914,"Keras reports “ValueError: initial_value must have a shape specified:Tensor(”dense_4/MatMul:0“,shape=(?, 1),dtype=float32)” when customizing random AF","I am implementing a feed-forward neural network model with random activation function at the out layer which has only one neuron. The random activation function works as if the output of the last hidden layer is greater than a threshold, the output of the model will be 1, otherwise, the model output is zero.

I used the following code using ""get_custom_objects"" to customize the activation function, but it gives me an error that ""ValueError: initial_value must have a shape specified: Tensor(""dense_4/MatMul:0"", shape=(?, 1), dtype=float32)""
```
class Rand(Activation):                
     def __init__(self, activation, **kwargs):
        super(Rand, self).__init__(activation, **kwargs)
        self.__name__ = 'rand'

 
def rand(x):
    result = tf.Variable(tf.cond(tf.random.uniform(shape=[1])[0] > tf.Variable(x), 1, 0))
    return result
```"
41913,Support outputting tree leaves in BoostedTreesClassifier,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.14 and would like to migrate to 2.3
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Currently the `BoostedTreesClassifier` canner estimator does not support outputting the activated leaves of the tree on output, instead only supporting outputting the natural output of the classifier. The feature request I am making is to also support outputting the leaves, such as what the `CoreGradientBoostedDecisionTreeEstimator` in TF 1.14 supported via the flag `output_leaf_index=True`. With this flag the estimator would also provide an output on which leaves were output on an evaluation.

**Will this change the current api? How?**
The estimator will gain an initialization argument of `output_leaf_index`. When set to true, the estimator would add leaf indices as one of its predict keys which will be output to the user on evaluation.

**Who will benefit with this feature?**
One common use case of boosted trees models is in stacked architectures where the output of the tree model is fed into a deep neural network. For this use case the leaf indices are oftentimes more useful as an input to the DNN than the raw prediction of the tree model. This use case is supported in TF 1 but not in TF 2 so it prevents migrating code for this use case to TF 2."
41912,"Should this be ""ZerosLike"" ?",https://github.com/tensorflow/tensorflow/blob/05632ed9bad5bf9eee3edd57ade3d8250d580019/tensorflow/c/eager/gradients.cc#L104
41910,"Only support ksizes across space, when using tf.image.extract_patches","System info:
Os: MacOs catalina (10.15.5 )
Tensorflow: 2.0.0 installed over anaconda navigator (1.9.12 python 2.7) enviroment

I was **trying to split my image through 4 patches** when I came through the following error: 

```UnimplementedError: Only support ksizes across space``` 

```python
iterator = tf.compat.v1.data.make_one_shot_iterator(parsed_dataset) 
image,label = iterator.get_next()
image_height = image.shape[0]
image_width = image.shape[1]
# Since the expected type is (batch,height,width,channels), i have tryied to expand my image that have
# dimensions: (800,344,3) to (1,800,344,3) but didn't solved the error.
#image = tf.expand_dims(image ,0)
images = list(image)
extracted_patches = tf.image.extract_patches(images=images,
                                             sizes=[1,int(0.25*image_height),int(0.25*image_width),3],
                                             strides=[1,int(0.25*image_height),int(0.25*image_width),3],
                                             rates=[1,1,1,1],
                                             padding=""SAME"")
```

### Traceback:
```
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
<ipython-input-64-23c2aff4c306> in <module>()
     17                                              strides=[1,int(0.25*image_height),int(0.25*image_width),3],
     18                                              rates=[1,1,1,1],
---> 19                                              padding=""SAME"")
     20 
     21 

/Users/lucianoaraujo/anaconda2/lib/python2.7/site-packages/tensorflow_core/python/ops/array_ops.pyc in extract_image_patches_v2(images, sizes, strides, rates, padding, name)
   4657   """"""
   4658   return gen_array_ops.extract_image_patches(images, sizes, strides, rates,
-> 4659                                              padding, name)
   4660 
   4661 

/Users/lucianoaraujo/anaconda2/lib/python2.7/site-packages/tensorflow_core/python/ops/gen_array_ops.pyc in extract_image_patches(images, ksizes, strides, rates, padding, name)
   2542       else:
   2543         message = e.message
-> 2544       _six.raise_from(_core._status_to_exception(e.code, message), None)
   2545   # Add nodes to the TensorFlow graph.
   2546   if not isinstance(ksizes, (list, tuple)):

/Users/lucianoaraujo/anaconda2/lib/python2.7/site-packages/six.pyc in raise_from(value, from_value)
    735 else:
    736     def raise_from(value, from_value):
--> 737         raise value
    738 
    739 

UnimplementedError: Only support ksizes across space. [Op:ExtractImagePatches]
```"
41909,Tensor Flow 2.2/CUDA 10.1 Could not load dynamic library,"I believe my PATH is set up correctly and these files are present in the bin

2020-07-30 16:17:56.453813: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-07-30 16:17:56.453948: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-07-30 16:17:58.729263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-07-30 16:17:58.751682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-07-30 16:17:58.752751: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-07-30 16:17:58.753611: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found
2020-07-30 16:17:58.756415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-07-30 16:17:58.757327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-07-30 16:17:58.763641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-07-30 16:17:58.764657: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found
2020-07-30 16:17:58.765503: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found
2020-07-30 16:17:58.765627: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-07-30 16:17:58.766078: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-07-30 16:17:58.772467: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18e96ef2a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-30 16:17:58.772617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-30 16:17:58.772770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-30 16:17:58.772873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]

[code.txt](https://github.com/tensorflow/tensorflow/files/5003637/code.txt)


![path](https://user-images.githubusercontent.com/54596770/88971045-59f40580-d281-11ea-9c06-b094b10a3f31.PNG)
![bin](https://user-images.githubusercontent.com/54596770/88971048-5a8c9c00-d281-11ea-8ba3-a271f86e23b6.PNG)




"
41906,How to disable Cudnn for reproducible results,"I use the setting in [https://github.com/NVIDIA/framework-determinism](https://github.com/NVIDIA/framework-determinism), But I found my model still get random result each time (1% mIOU different)

Is there any way in Tensorflow provides the feature like Pytorch:
```
torch.backends.cudnn.enabled = False
```
I also found there is an enviroment variable ""TF_USE_CUDNN"" but it does not work."
41904,Windows import library is missing sufficient symbols to use C++ API,"**System information**
- OS Platform and Distribution **Windows 10**
- TensorFlow installed from (source or binary): **Source**
- TensorFlow version: **2.3.0**
- Python version: **3.8.5**
- Bazel version (if compiling from source): **3.3.1**
- GCC/Compiler version (if compiling from source): **Visual Studio 2019**

**Expected Result**

The generated Windows Binaries should export sufficient symbols to compile and link a basic program using the C++ API

**Actual Result**

Compiling and linking a basic Tensorflow C++ program with the Windows Binaries results in undefined symbols.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Example from [Tensorflow 2.3.0 API Reference](https://www.tensorflow.org/api_docs/cc/class/tensorflow/client-session)

`main.cpp`

```.cpp

#include <tensorflow/cc/framework/scope.h>
#include <tensorflow/cc/client/client_session.h>
#include <tensorflow/cc/ops/array_ops.h>
#include <tensorflow/cc/ops/math_ops.h>

#include <vector>

namespace tf = tensorflow;
using namespace tf::ops;

int main() {
    tf::Scope root = tf::Scope::NewRootScope();
    auto a = Placeholder(root, tf::DT_INT32);
    auto c = Add(root, a, {41});

    tf::ClientSession session(root);
    std::vector<tf::Tensor> outputs;

    auto status = session.Run({{a, {1}}}, {c}, &outputs);

    return 0;
}
```

`CMakeLists.txt`

```
cmake_minimum_required(VERSION 2.8)
project(tensorflow_example)

set(CMAKE_VERBOSE_MAKEFILE TRUE)
add_executable(example main.cpp)

target_link_libraries(example PRIVATE ""${TENSORFLOW_ROOT}/tensorflow_cc.lib"")
target_compile_definitions(example PRIVATE NOMINMAX)
target_include_directories(example PRIVATE
    ""${TENSORFLOW_ROOT}/include""
    ""${TENSORFLOW_ROOT}/include/src""
)
```

```
python configure.py
<Accept defaults>
bazel build --config=opt //tensorflow:tensorflow_cc
bazel build --config=opt //tensorflow:tensorflow_cc_dll_import_lib
bazel build --config=opt //tensorflow:install_headers
```

```
mkdir build
cd build
cmake .. -DTENSORFLOW_ROOT=<path to bazel-bin/tensorflow>
cmake --build .
```

The compilation succeeds but linking fails with the following missing externals: 
```
Microsoft (R) Build Engine version 16.6.0+5ff7b0c9e for .NET Framework
Copyright (C) Microsoft Corporation. All rights reserved.

main.obj : error LNK2019: unresolved external symbol ""public: __cdecl tensorflow::Operation::Operation(class tensorflow::Node *)"" (??0Operation@tensorflow@@QEAA@PEAVNode@1@@Z) referenced in function ""public: __cdecl tensorflow::Input::Input(class std::initializer_list<struct tensorflow::Input::Initializer> const &)"" (??0Input@tensorflow@@QEAA@AEBV?$initializer_list@UInitializer@Input@tensorflow@@@std@@@Z) [C:\Users\plane\projects\tf_test\build\example.vcxproj]
main.obj : error LNK2019: unresolved external symbol ""public: __cdecl tensorflow::Input::Initializer::Initializer(class std::initializer_list<struct tensorflow::Input::Initializer> const &)"" (??0Initializer@Input@tensorflow@@QEAA@AEBV?$initializer_list@UInitializer@Input@tensorflow@@@std@@@Z) referenced in function ""public: __cdecl tensorflow::Input::Input(class std::initializer_list<struct tensorflow::Input::Initializer> const &)"" (??0Input@tensorflow@@QEAA@AEBV?$initializer_list@UInitializer@Input@tensorflow@@@std@@@Z) [C:\Users\plane\projects\tf_test\build\example.vcxproj]
main.obj : error LNK2019: unresolved external symbol ""public: __cdecl tensorflow::Scope::~Scope(void)"" (??1Scope@tensorflow@@QEAA@XZ) referenced in function main [C:\Users\plane\projects\tf_test\build\example.vcxproj]
main.obj : error LNK2019: unresolved external symbol ""public: static class tensorflow::Scope __cdecl tensorflow::Scope::NewRootScope(void)"" (?NewRootScope@Scope@tensorflow@@SA?AV12@XZ) referenced in function main [C:\Users\plane\projects\tf_test\build\example.vcxproj]
main.obj : error LNK2019: unresolved external symbol ""public: __cdecl tensorflow::ClientSession::ClientSession(class tensorflow::Scope const &)"" (??0ClientSession@tensorflow@@QEAA@AEBVScope@1@@Z) referenced in function main [C:\Users\plane\projects\tf_test\build\example.vcxproj]
main.obj : error LNK2019: unresolved external symbol ""public: __cdecl tensorflow::ClientSession::~ClientSession(void)"" (??1ClientSession@tensorflow@@QEAA@XZ) referenced in function main [C:\Users\plane\projects\tf_test\build\example.vcxproj]
main.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::Status __cdecl tensorflow::ClientSession::Run(class std::unordered_map<class tensorflow::Output,struct tensorflow::Input::Initializer,struct tensorflow::OutputHash,struct std::equal_to<class tensorflow::Output>,class std::allocator<struct std::pair<class tensorflow::Output const ,struct tensorflow::Input::Initializer> > > const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > const &,class std::vector<class tensorflow::Tensor,class std::allocator<class tensorflow::Tensor> > *)const "" (?Run@ClientSession@tensorflow@@QEBA?AVStatus@2@AEBV?$unordered_map@VOutput@tensorflow@@UInitializer@Input@2@UOutputHash@2@U?$equal_to@VOutput@tensorflow@@@std@@V?$allocator@U?$pair@$$CBVOutput@tensorflow@@UInitializer@Input@2@@std@@@7@@std@@AEBV?$vector@VOutput@tensorflow@@V?$allocator@VOutput@tensorflow@@@std@@@5@PEAV?$vector@VTensor@tensorflow@@V?$allocator@VTensor@tensorflow@@@std@@@5@@Z) referenced in function main [C:\Users\plane\projects\tf_test\build\example.vcxproj]
main.obj : error LNK2019: unresolved external symbol ""public: __cdecl tensorflow::ops::Placeholder::Placeholder(class tensorflow::Scope const &,enum tensorflow::DataType)"" (??0Placeholder@ops@tensorflow@@QEAA@AEBVScope@2@W4DataType@2@@Z) referenced in function main [C:\Users\plane\projects\tf_test\build\example.vcxproj]
main.obj : error LNK2019: unresolved external symbol ""public: __cdecl tensorflow::ops::Add::Add(class tensorflow::Scope const &,class tensorflow::Input,class tensorflow::Input)"" (??0Add@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@1@Z) referenced in function main [C:\Users\plane\projects\tf_test\build\example.vcxproj]
C:\Users\plane\projects\tf_test\build\Debug\example.exe : fatal error LNK1120: 9 unresolved externals [C:\Users\plane\projects\tf_test\build\example.vcxproj]
```

"
41902,Relax constraint on `numpy` dependency,"In https://github.com/tensorflow/tensorflow/commit/79518facb4b857af9d9d5df2da463fdbf7eb0e3e the constraint of the `numpy` dependency was bounded to `numpy < 1.19.0` from `numpy < 2.0` due to breaking ABI changes from https://github.com/numpy/numpy/pull/15355.

The next quarterly release of pip, 20.3, in October 2020 will change the default dependency resolution behavior to ensure that this constraint is more strictly followed. Specifically, it means that installing the latest version of TensorFlow will have the effect of asking the user to downgrade to `numpy < 1.19.0` if they have `numpy >= 1.19.0` installed.

It's likely that there are currently many TensorFlow users who are also using `numpy >= 1.19.0` without issue, who will start to experience this behavior when the new version of pip is released. This is already being reported by users who have opted-in to the new version of the resolver (https://github.com/pypa/pip/issues/8076#issuecomment-664161421).

I couldn't find an issue about resetting this constraint to `numpy < 2.0` and migrating to the new ABI (sorry if I missed it) so I wanted to create this to capture that, and also give you some early warning about how the change pip's behavior will affect users of this project. Thanks!
"
41901,Could not import PIL.Image. The use of `array_to_img` requires PIL,"**System information**
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution : ubuntu 18.04 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Jetson Nano
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): tensorflow==1.15.2+nv20.6
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: CUDA 10.2 / cuDNN 8.00
GPU model and memory: NVIDIA Tegra X1 (nvgpu)/integrated and 4GB memory
Keras: 2.0.5



**Describe the problem**

While executing an application, i got following exception


![image](https://user-images.githubusercontent.com/2168986/88942166-83c02300-d2a7-11ea-8948-551074acb48d.png)


After that, I installed pillow-7.2.0. But i am getting same error message **ImportError: Could not import PIL.Image. The use of array_to_img requires PIL**.

Could you please help me to resolve the issue?
"
41900,TFLu r2.3: Broken memory allocation for micro interpreter object with TF_LITE_STATIC_MEMORY enabled,"Compiling TFLu r2.3 with TF_LITE_STATIC_MEMORY gives an incorrect memory allocation for the micro interpreter object. 

**System information**
- TFLu r2.3
- OS Platform: Linux Ubuntu 16.04 or Windows 10 64 bit
- Target: Cortex M4F

**Current behavior**
In my case the size of the network input data is
interpreter->input(0)->bytes = 1920

After calling for memory allocation
TfLiteStatus allocate_status = interpreter->AllocateTensors();

the memory address of the input data is
interpreter->input(0)->data = 0x8012174
and memory address of the input tensor structure is
interpreter->input(0) = 0x8012570

This gives only 1020 bytes memory space for the data which is 1920 btes. As a consequence, the input tensor structure is overwritten when copying the input data.

**Expected behavior**
After removing TF_LITE_STATIC_MEMORY from the CCFLAGS/CXXFLAGS the memory allocation leaves enough space between the data and the input tensor structure:
interpreter->input(0) = 0x80124d0
interpreter->input(0)->data = 0x80103c0

**Other info**
Using TFLu r2.2 with TF_LITE_STATIC_MEMORY does not show the problem. It gives correct memory layout. Starting with commit fbf407383c93774d10bd7c45cd66788a070b0e07 (mid of June '20) the memory layout is broken.

I'm not sure if this is a bug or if it is intended behavior and I better compile without TF_LITE_STATIC_MEMORY.
"
41899,Compilation Failure when using tf.keras.layers.UpSampling2D() with colab TPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS, Mojave 10.14.6 (Running in Colab)
- TensorFlow version (use command below):2.2.0
- Python version: Python 3.6.9



**Describe the current behavior**
While using tf.keras.layers.Upsampling2D() in Colab TPU, The following error occurs:

```UnimplementedError                        Traceback (most recent call last)
<ipython-input-34-7125d086c152> in <module>()
     10   model.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])
     11 model.summary()
---> 12 history = model.fit(training_dataset, epochs=10, validation_data=validation_dataset, steps_per_epoch=steps_per_epoch)

10 frames
/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnimplementedError: {{function_node __inference_train_function_66860}} Compilation failure: CustomCall is not supported to have a dynamic dimension
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_7048177641045036345/_5}}]]
```

**Describe the expected behavior**
If I use tf.keras.UpSampling2D((2,2)), I should expect the tensor to be resized by a factor of 2.

**Standalone code to reproduce the issue**
```
def create_model():
    
    pretrained_model = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3], include_top=False)
    pretrained_model.trainable = True

    model = tf.keras.Sequential([
        pretrained_model,
        tf.keras.layers.MaxPooling2D((2,2)),
        tf.keras.layers.UpSampling2D((2,2)),
        tf.keras.layers.GlobalAveragePooling2D(),
        #tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(5, activation='softmax', dtype=tf.float32) # the float32 is needed on softmax layer when using mixed precision
    ])

    model.compile(
        optimizer='adam',
        loss = 'categorical_crossentropy',
        metrics=['accuracy']
    )

    return model
with strategy.scope():
  model = create_model()
model.summary()
start_time = time.time()
history = model.fit(training_dataset, validation_data=validation_dataset,
                    steps_per_epoch=TRAIN_STEPS, epochs=EPOCHS, callbacks=[lr_callback])

final_accuracy = history.history[""val_accuracy""][-5:]
print(""FINAL ACCURACY MEAN-5: "", np.mean(final_accuracy))
print(""TRAINING TIME: "", time.time() - start_time, "" sec"")
```

This is the [link](https://colab.research.google.com/drive/1yABsMbLguooJutACqH3splUq3lMkc38N?usp=sharing) to the Colab Notebook

**Other info / logs** 
The training dataset is a publicly available TFRecord Dataset"
41898,"Keras Model, Functional API, Multi-input, Efficient allreduce is not supported for n IndexedSlices","<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: Python 3.6.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: CUDA Version 10.1.243
- GPU model and memory: (8x) Tesla K80 - 11441MiB - Driver Version: 410.72


**Describe the current behavior**
Same issue using TF v2.2.0.
I am using Keras functional API to train a model with more than one input. As a simplified example geting the same problem,

```
import sys
import tensorflow as tf
import numpy as np

def build_model_():

	input_a_size = 20
	input_b_size = 4
	num_classes = 2
	len_embedding = 256

	input_a = tf.keras.layers.Input(shape=(input_a_size,), name='input_a', dtype=np.uint8)
	input_b = tf.keras.layers.Input(shape=(input_b_size,), name='input_b', dtype=np.float32)

	x = tf.keras.layers.Embedding(len_embedding, 100)(input_a)
	x = tf.keras.layers.Conv1D(128, 4, activation='relu')(x)
	x = tf.keras.layers.MaxPooling1D(4)(x)
	x = tf.keras.layers.Flatten()(x)
	branch_a = tf.keras.layers.Dense(64, activation='relu')(x)

	x = tf.keras.layers.Dense(32, activation='relu')(input_b)
	branch_b = tf.keras.layers.Dense(32, activation='relu')(x)

	concat = tf.keras.layers.Concatenate()([
				                            branch_a,
				                            branch_b,
				                           ])

	x = tf.keras.layers.Dense(512, activation = 'relu')(concat)
	output = tf.keras.layers.Dense(num_classes, name='output', activation='softmax')(x)

	model = tf.keras.models.Model(inputs=[
				                          input_a,
				                          input_b,
				                         ],
				                  outputs=[output])

	return model

strategy = tf.distribute.MirroredStrategy(['/gpu:0', '/gpu:1'])
with strategy.scope():
    model = build_model_()
    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

y_train = True
y_train = tf.keras.utils.to_categorical(y_train, 2)

dataset = tf.data.Dataset.from_tensors(
    (
        {""input_a"": [[1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.]], 
         ""input_b"": [[1.], [1.], [1.], [1.]],}, 
        {""output"": y_train},
    )
).repeat(1000000).batch(256)

history = model.fit(
    x = dataset,
    epochs=10,
    verbose = 1,
)
```

When starting training I get this warning,
`WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices`
When training a model with 3 inputs I get, ...not supported for 2 IndexedSlices, so, I'm getting 
`WARNING:tensorflow:Efficient allreduce is not supported for n-1 IndexedSlices`, being `n` the number of inputs to the net.

The performance is not scaling using multiple GPUs. It gets slower with 2 GPUs vs 1 GPUs, and worst case using 8 GPUs.
"
41897,Allow black box ops (with custom_gradient) in @tf.function,"**System information**
- TensorFlow version (you are using): 2.3
- Are you willing to contribute it (Yes/No): No (don't know how)

**Describe the feature and the current behavior/state.**
When decorating a function with `@tf.function` it would be great to be able to include untraceable ops (e.g., because they contain compiled numba code), as long as they are decorated with  `@tf.custom_gradient` and somehow their signature and dtype is well specified.

Unless I'm missing something major, once a function is decorated with `@custom_gradient`, it shouldn't be necessary for AutoGraph to trace it. It should be ""pluggable"" in the computational graph as a block.

**Will this change the current api? How?**
Possibly (perhaps optional flags in `tf.function`).

**Who will benefit with this feature?**
Users who want to use custom/compiled code compatibly with `tf.function`/autograph (which sometimes happens by default, e.g. when using `Model.fit()` in keras).

"
41896,"Get deadlock after Restoring SavedModelBundle(cuda10.1, cudnn7.6.3, trt6.0, Tesla T4 GPU)","- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux centos 7
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): r2.1
- Python version: 2.7
- Bazel version (if compiling from source): 1.2.1
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: cuda 10.1.168 / cudnn 7.6.3
- GPU model and memory: Tesla T4

I have build my own Service  (TFServing Like) to run tensorflow for model inferencing, but get stucked after load first saved model bundle.  it's fine in cpu mode, so i tracked the stack, and got some information below.

obviously, it's in async execute, and waiting for something

```
Thread 33 (Thread 0x7fefe47b5700 (LWP 68)):
#0  0x00007feff6106ba9 in syscall () from /usr/lib64/libc.so.6
#1  0x00007ff018372402 in nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec) () from ./lib/libtensorflow_framework.so.2
#2  0x00007ff018371a49 in nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*) () from ./lib/libtensorflow_framework.so.2
#3  0x00007ff01836f06b in nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*) () from ./lib/libtensorflow_framework.so.2
#4  0x00007ff01836f543 in nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*) () from ./lib/libtensorflow_framework.so.2
#5  0x00007ff002a7c49c in tensorflow::DirectSession::WaitForNotification(tensorflow::Notification*, long long) () from ./lib/libtensorflow_cc.so.2
#6  0x00007ff002a7c56d in tensorflow::DirectSession::WaitForNotification(tensorflow::Notification*, tensorflow::DirectSession::RunState*, tensorflow::CancellationManager*, long long) () from ./lib/libtensorflow_cc.so.2
#7  0x00007ff002a8ccee in tensorflow::DirectSession::RunInternal(long long, tensorflow::RunOptions const&, tensorflow::CallFrameInterface*, tensorflow::DirectSession::ExecutorsAndKeys*, tensorflow::RunMetadata*, tensorflow::thread::ThreadPoolOptions const&) () from ./lib/libtensorflow_cc.so.2
#8  0x00007ff002a8fb97 in tensorflow::DirectSession::RunCallable(long long, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*, tensorflow::thread::ThreadPoolOptions const&) () from ./lib/libtensorflow_cc.so.2
#9  0x00007ff002a7a760 in tensorflow::DirectSession::RunCallable(long long, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from ./lib/libtensorflow_cc.so.2
#10 0x00007ff017746302 in tensorflow::(anonymous namespace)::RunOnce(tensorflow::RunOptions const&, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*, tensorflow::Session*) [clone .constprop.473] () from ./lib/libtensorflow_framework.so.2
#11 0x00007ff017746b7c in tensorflow::(anonymous namespace)::RunRestore(tensorflow::RunOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, absl::string_view, absl::string_view, std::vector<tensorflow::AssetFileDef, std::allocator<tensorflow::AssetFileDef> > const&, tensorflow::Session*) () from ./lib/libtensorflow_framework.so.2
#12 0x00007ff0177472e0 in tensorflow::LoadSavedModel(tensorflow::SessionOptions const&, tensorflow::RunOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_set<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, tensorflow::SavedModelBundle*) () from ./lib/libtensorflow_framework.so.2

```

what does it exactly waiting for...

```
Thread 95 (Thread 0x7fef50d2b700 (LWP 170)):
#0  0x00007feff6106ba9 in syscall () from /usr/lib64/libc.so.6
#1  0x000000000101a1a1 in absl::lts_2020_02_25::synchronization_internal::Futex::WaitUntil (t=..., val=0, v=0x7fefac0bb150) at external/com_google_absl/absl/synchronization/internal/waiter.cc:107
#2  absl::lts_2020_02_25::synchronization_internal::Waiter::Wait (this=this@entry=0x7fefac0bb150, t=t@entry=...) at external/com_google_absl/absl/synchronization/internal/waiter.cc:151
#3  0x000000000101a0e2 in AbslInternalPerThreadSemWait (t=...) at external/com_google_absl/absl/synchronization/internal/waiter.h:99
#4  0x00007ff018536fbd in absl::Mutex::Block(absl::base_internal::PerThreadSynch*) () from ./lib/libtensorflow_framework.so.2
#5  0x00007ff01772e04a in absl::Mutex::LockSlowWithDeadline(absl::MuHowS const*, absl::Condition const*, absl::synchronization_internal::KernelTimeout, int) [clone .cold.36] () from ./lib/libtensorflow_framework.so.2
#6  0x00007ff01772e05e in absl::Mutex::LockSlow(absl::MuHowS const*, absl::Condition const*, int) () from ./lib/libtensorflow_framework.so.2
#7  0x00007ff018535e03 in absl::Notification::WaitForNotification() const () from ./lib/libtensorflow_framework.so.2
#8  0x00007ff018365f90 in stream_executor::(anonymous namespace)::BlockOnThreadExecutor(tensorflow::thread::ThreadPool*) () from ./lib/libtensorflow_framework.so.2
#9  0x00007ff01836b2b9 in stream_executor::StreamExecutor::SynchronizeAllActivity() () from ./lib/libtensorflow_framework.so.2
#10 0x00007ff017e3e5da in tensorflow::GPUUtil::SyncAll(tensorflow::Device*) () from ./lib/libtensorflow_framework.so.2
#11 0x00007ff017e29121 in tensorflow::BaseGPUDevice::Sync() () from ./lib/libtensorflow_framework.so.2
#12 0x00007ff017e75ab1 in tensorflow::Device::Sync(std::function<void (tensorflow::Status const&)> const&) () from ./lib/libtensorflow_framework.so.2
#13 0x00007ff017e88bcc in tensorflow::(anonymous namespace)::ExecutorState::Finish() () from ./lib/libtensorflow_framework.so.2
#14 0x00007ff017e912f4 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) () from ./lib/libtensorflow_framework.so.2
#15 0x00007ff017e91daf in std::_Function_handler<void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(absl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8ul, std::allocator<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode> >*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#2}>::_M_invoke(std::_Any_data const&) () from ./lib/libtensorflow_framework.so.2
#16 0x00007ff017f62463 in Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) () from ./lib/libtensorflow_framework.so.2
#17 0x00007ff017f5fbb3 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from ./lib/libtensorflow_framework.so.2
#18 0x00007feff66aed9f in std::execute_native_thread_routine (__p=0xacf3cb0) at ../../../.././libstdc++-v3/src/c++11/thread.cc:80
#19 0x00007feff7269e65 in start_thread () from /usr/lib64/libpthread.so.0
#20 0x00007feff610c88d in clone () from /usr/lib64/libc.so.6
```

```
Thread 80 (Thread 0x7fefb66d7700 (LWP 154)):
#0  0x00007feff6106ba9 in syscall () from /usr/lib64/libc.so.6
#1  0x00007ff003165e31 in absl::synchronization_internal::Waiter::Wait(absl::synchronization_internal::KernelTimeout) () from ./lib/libtensorflow_cc.so.2
#2  0x00007ff003165cc2 in AbslInternalPerThreadSemWait () from ./lib/libtensorflow_cc.so.2
#3  0x00007ff00316718d in absl::Mutex::Block(absl::base_internal::PerThreadSynch*) () from ./lib/libtensorflow_cc.so.2
#4  0x00007ff00316810d in absl::Mutex::AwaitCommon(absl::Condition const&, absl::synchronization_internal::KernelTimeout) () from ./lib/libtensorflow_cc.so.2
#5  0x00007ff00316816d in absl::Mutex::Await(absl::Condition const&) () from ./lib/libtensorflow_cc.so.2
#6  0x00007ff00278fbfb in stream_executor::host::HostStream::WorkLoop() () from ./lib/libtensorflow_cc.so.2
#7  0x00007feff66aed9f in std::execute_native_thread_routine (__p=0x9ede390) at ../../../.././libstdc++-v3/src/c++11/thread.cc:80
#8  0x00007feff7269e65 in start_thread () from /usr/lib64/libpthread.so.0
#9  0x00007feff610c88d in clone () from /usr/lib64/libc.so.6

Thread 85 (Thread 0x7fefadaf1700 (LWP 160)):
#0  0x00007feff6106ba9 in syscall () from /usr/lib64/libc.so.6
#1  0x00007ff018372402 in nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec) () from ./lib/libtensorflow_framework.so.2
#2  0x00007ff018371a49 in nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*) () from ./lib/libtensorflow_framework.so.2
#3  0x00007ff01836f06b in nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*) () from ./lib/libtensorflow_framework.so.2
#4  0x00007ff01836f543 in nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*) () from ./lib/libtensorflow_framework.so.2
#5  0x00007ff017f2e153 in tensorflow::EventMgr::PollLoop() () from ./lib/libtensorflow_framework.so.2
#6  0x00007ff017f62463 in Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) () from ./lib/libtensorflow_framework.so.2
#7  0x00007ff017f5fbb3 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from ./lib/libtensorflow_framework.so.2
#8  0x00007feff66aed9f in std::execute_native_thread_routine (__p=0xacf3410) at ../../../.././libstdc++-v3/src/c++11/thread.cc:80
#9  0x00007feff7269e65 in start_thread () from /usr/lib64/libpthread.so.0
#10 0x00007feff610c88d in clone () from /usr/lib64/libc.so.6
```

```
GPU Info
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:08.0 Off |                    0 |
| N/A   56C    P0    28W /  70W |  14333MiB / 15079MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+
```


tf logs

```
2020-07-30 20:07:18.210474: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-07-30 20:07:18.225309: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2494140000 Hz
2020-07-30 20:07:18.226300: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc1180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-30 20:07:18.226319: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-30 20:07:18.228940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-30 20:07:18.374126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 20:07:18.375556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc0700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-30 20:07:18.375588: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-07-30 20:07:18.375783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 20:07:18.377080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties:
pciBusID: 0000:00:08.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-07-30 20:07:18.377634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 20:07:18.379342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-30 20:07:18.380984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-30 20:07:18.381417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-30 20:07:18.383041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-30 20:07:18.383863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-30 20:07:18.387237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-30 20:07:18.387324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 20:07:18.388741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 20:07:18.389989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-07-30 20:07:18.390018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 20:07:18.391498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-30 20:07:18.391514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0
2020-07-30 20:07:18.391524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N
2020-07-30 20:07:18.391652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 20:07:18.392929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 20:07:18.394207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:08.0, compute capability: 7.5)
2020-07-30 20:07:18.402115: I tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.
```

cuda threads bt
```
Thread 81 (Thread 0x7fefaeaf3700 (LWP 155)):
#0  0x00007feff610dd1f in accept4 () from /usr/lib64/libc.so.6
#1  0x00007fefb4f6b38a in ?? () from /usr/lib64/libcuda.so.1
#2  0x00007fefb4f5d68d in ?? () from /usr/lib64/libcuda.so.1
#3  0x00007fefb4f6ca58 in ?? () from /usr/lib64/libcuda.so.1
#4  0x00007feff7269e65 in start_thread () from /usr/lib64/libpthread.so.0
#5  0x00007feff610c88d in clone () from /usr/lib64/libc.so.6

Thread 84 (Thread 0x7fefacaef700 (LWP 159)):
#0  0x00007feff6101bed in poll () from /usr/lib64/libc.so.6
#1  0x00007fefb4f6a3e3 in ?? () from /usr/lib64/libcuda.so.1
#2  0x00007fefb4ff830d in ?? () from /usr/lib64/libcuda.so.1
#3  0x00007fefb4f6ca58 in ?? () from /usr/lib64/libcuda.so.1
#4  0x00007feff7269e65 in start_thread () from /usr/lib64/libpthread.so.0
#5  0x00007feff610c88d in clone () from /usr/lib64/libc.so.6

```

other eigen threads are just in pthread_cond_wait, 3ks"
41895,ImportError: DLL load failed: The specified module could not be found,"
**System information**
- OS Platform and Distribution : Windows 10
- TensorFlow installed from (source or binary): Source (branch r2.1)
- Python version: 3.6
- Bazel version :0.29.1
- GCC/Compiler version :
- Memory: 8GB

**Describe the problem**
 Compiling Tensorflow with mkl on Windows ends up in 
""ERROR: C:/users/dm212/documents/devi/tensorflow/tensorflow/python/keras/api/BUILD:115:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)"". 
I followed the steps from **https://www.tensorflow.org/install/source_windows**. Also checked few solutions in similar issues, but didn't help.

 **Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel --output_base=""C:/Users/dm212/Documents/TF""  build --config=mkl --config=opt  --config=v2                            --define=no_tensorflow_py_deps=true   //tensorflow/tools/pip_package:build_pip_package 

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
ERROR: C:/users/dm212/documents/devi/tensorflow/tensorflow/python/keras/api/BUILD:115:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)
Traceback (most recent call last):
  File ""\\?\C:\Users\dm212\AppData\Local\Temp\Bazel.runfiles_8o1_a1ke\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""\\?\C:\Users\dm212\AppData\Local\Temp\Bazel.runfiles_8o1_a1ke\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""\\?\C:\Users\dm212\AppData\Local\Temp\Bazel.runfiles_8o1_a1ke\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\dm212\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\dm212\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""\\?\C:\Users\dm212\AppData\Local\Temp\Bazel.runfiles_8o1_a1ke\runfiles\org_tensorflow\tensorflow\python\tools\api\generator\create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""\\?\C:\Users\dm212\AppData\Local\Temp\Bazel.runfiles_8o1_a1ke\runfiles\org_tensorflow\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""\\?\C:\Users\dm212\AppData\Local\Temp\Bazel.runfiles_8o1_a1ke\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""\\?\C:\Users\dm212\AppData\Local\Temp\Bazel.runfiles_8o1_a1ke\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""\\?\C:\Users\dm212\AppData\Local\Temp\Bazel.runfiles_8o1_a1ke\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""\\?\C:\Users\dm212\AppData\Local\Temp\Bazel.runfiles_8o1_a1ke\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\dm212\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\dm212\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: C:/users/dm212/documents/devi/tensorflow/tensorflow/tools/pip_package/BUILD:114:1 Executing genrule //tensorflow:tf_python_api_gen_v2 failed (Exit 1)
INFO: Elapsed time: 24724.095s, Critical Path: 20460.98s
INFO: 5794 processes: 5794 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully

```"
41894,"Add ""CIRCULAR"" mode padding to tensorflow.pad()","<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.2.0-rc3
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
The requested feature would enable tensorflow.pad() to perform circular padding, which is of importance in several signal processing applications.
Following the example in the [documentation for tf.pad()](https://www.tensorflow.org/api_docs/python/tf/pad) for other modes (""CONSTANT"", ""SYMMETRIC"", ""REFLECT""), the circular padding should result in a tensor like this:
```python
t = tf.constant([[1, 2, 3], [4, 5, 6]])
paddings = tf.constant([[1, 1,], [2, 2]])

tf.pad(t, paddings, ""CIRCULAR"")  # [[5, 6, 4, 5, 6, 4, 5],
                                 #  [2, 3, 1, 2, 3, 1, 2],
                                 #  [5, 6, 4, 5, 6, 4, 5],
                                 #  [2, 3, 1, 2, 3, 1, 2]]
```
**Will this change the current api? How?**
I think it should not, as this will simply be another option for the mode argument. Of course, the backend must be modified to provide the functionality.

**Who will benefit with this feature?**
As stated before, circular padding often occurs in signal processing applications. Another example would be images that stem from e.g. a cylindric or circular domain. 
IMHO this feature would enable higher-level APIs, e.g. the convolutional layers in Keras to add an option for ""circular"" padding, which in turn should enable easier use for the specific tasks mentioned above. Making the feature available to the higher-level API will benefit the mentioned signal processing applications.

**Any Other info.**
The functionality is implemented in Pytorch, where the [padding mode for Convolutional layers](https://pytorch.org/docs/master/generated/torch.nn.Conv1d.html#torch.nn.Conv1d) can be set to `circular`.
> padding_mode (string, optional) – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'"
41892,Tensorflow 2.3 doesn't recognize GeForce MX130 GPU,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04.4
- TensorFlow installed from: binary as per instructions on [tf website](https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101)
- TensorFlow version: 2.3
- Python version: 3.6
- Installed using : pip
- CUDA/cuDNN version:  CUDA 10.1, cuDNN 7
- GPU model and memory: GeForce MX130, 2GB


**Problem Description:**
Tensorflow 2.3 doesn't recognize my GPU.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
After installation I run the following:
```
python3 -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
```
I get this error message:
```
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid
```

On Tensorflow 2.2, I don't get the error.
"
41891,CUDA_ERROR_ILLEGAL_ADDRESS in toy training example,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Inside virtual container:
uname -a
Linux 3558c7dc300b 4.15.0-74-generic #84-Ubuntu SMP Thu Dec 19 08:06:28 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux

- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: Python 3.6.8
- CUDA/cuDNN version: 
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243

- GPU model and memory:

NVIDIA DGX-2
16x NVIDIA Tesla V100 (32GB)
2x Intel Xeon Platinum 8168 2.7GHz 24C/48T
1.5TB RAM
30TB Internal NVME SSD

**Describe the current behavior**

Crashes. Same happens in [Colab](https://colab.research.google.com/drive/1akS92A3mbh_L-c978OsTHvTFAxnv22vV?usp=sharing) and in tf-nightly. 

See crash report in colab:

2020-07-30 08:06:02.330777: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered

**Describe the expected behavior**

It should work, as it does for other values of the batch and repeat parameters.

**Standalone code to reproduce the issue**

```python

# This is a simplified version of https://www.tensorflow.org/guide/distributed_training

m_training_data = tf.constant([[1.1,1.]], dtype=tf.double)
dataset = tf.data.Dataset.from_tensor_slices((m_training_data,)).repeat(8*1024).batch(1024)

mirrored_strategy = tf.distribute.MirroredStrategy()
dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)

def train_step(input):
    A = tf.matmul(input[0], tf.linalg.matrix_transpose(input[0]))
    return tf.linalg.det(A)

@tf.function
def distributed_train_step(dist_inputs):
    loss = mirrored_strategy.run(train_step, args=(dist_inputs,))
    return mirrored_strategy.reduce(tf.distribute.ReduceOp.SUM, loss,
                         axis=None)

for dist_inputs in dist_dataset:
    print(distributed_train_step(dist_inputs))

```

**Other info / logs** 
[crash_1002.txt](https://github.com/tensorflow/tensorflow/files/5000057/crash_1002.txt)
"
41890,the info need me to tell you,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution win10 18363:
- TensorFlow installed from conda:
- TensorFlow version 2.3.0-rc0:
- Python 3.7:
- CUDA/cuDNN 10.2:
- 1080  16G:




**Describe the current behavior**
Epoch 1/5
WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000013933B3A798> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000013933B3A798> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
235/235 [==============================] - 0s 1ms/step - loss: 0.7901 - accuracy: 0.7434
Epoch 2/5
235/235 [==============================] - 0s 1ms/step - loss: 0.5730 - accuracy: 0.8110
Epoch 3/5
235/235 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.8239
Epoch 4/5
235/235 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.8309
Epoch 5/5
235/235 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.8352
**Describe the expected behavior**

**Standalone code to reproduce the issue**
import tensorflow as tf
from tensorflow import keras
fashion_mnist = keras.datasets.fashion_mnist
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
x_train = x_train / 255.0
x_test = x_test / 255.0

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])
model.compile(optimizer=tf.keras.optimizers.SGD(0.1),
              loss = 'sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x_train,y_train,epochs=5,batch_size=256)

and now it`s happen


"
41888,Resource exhausted: OOM when allocating tensor with shape[256] ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution : ubuntu 18.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  Jetson Nano
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tensorflow==1.15.2+nv20.6
- Python version: 3.6
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.2 / cuDNN 8.00
- GPU model and memory: NVIDIA Tegra X1 (nvgpu)/integrated and 4GB memory
Keras: 2.0.5

**Describe the current behavior**
**Error :**

**tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at assign_op.h:117 : Resource exhausted: OOM when allocating tensor with shape[256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc**

![image](https://user-images.githubusercontent.com/2168986/88894424-7b46f880-d265-11ea-98bb-55ea40271009.png)


**Source code**

![image](https://user-images.githubusercontent.com/2168986/88894492-9154b900-d265-11ea-8799-58202d7338b0.png)

**Refer the Logs, generated while start executing**

**“adding visible gpu devices: 0”**

**is GPU not allocated for the job?**
![image](https://user-images.githubusercontent.com/2168986/88894707-ee506f00-d265-11ea-9cac-b9d1d29c13bc.png)


"
41887,module 'tensorflow.python.framework.ops' has no attribute 'register_tensor_conversion_function',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41886,"Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.","With: 

#### load MNIST dataset
mnist = tf.keras.datasets.mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()

print(X_train.shape, y_train.shape)
print(X_train.min(), X_train.max(), y_train.min(), y_train.max())

X_train, X_test = X_train/255., X_test/255.


model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(100, activation='relu'),
    tf.keras.layers.Dense(10),
    ])

predictions = model(X_train.astype('float32')[:1]).numpy()
print(predictions)

y_pred = tf.nn.softmax(predictions).numpy()
print(y_pred)
print(y_pred.sum())

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(X_train, y_train, epochs=15)

model.evaluate(X_test, y_test, verbose=2)

model = tf.keras.models.Sequential()

model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(tf.keras.layers.MaxPool2D((2, 2)))
model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D((2, 2)))
model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))

model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(64, activation='relu'))
model.add(tf.keras.layers.Dense(10))

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
             metrics=['accuracy'])
             
history = model.fit(X_train[:, :, :, np.newaxis], y_train, epochs=10,
                    validation_data=(X_test[:, :, :, np.newaxis], y_test))

###################
**I get:**
###################

Epoch 1/10

---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
<ipython-input-20-0e520e098f8a> in <module>
      4 
      5              # fit
----> 6 history = model.fit(X_train[:, :, :, np.newaxis], y_train, epochs=10,
      7                     validation_data=(X_test[:, :, :, np.newaxis], y_test))
      8 

~/miniconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

~/miniconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    846                 batch_size=batch_size):
    847               callbacks.on_train_batch_begin(step)
--> 848               tmp_logs = train_function(iterator)
    849               # Catch OutOfRangeError for Datasets of unknown size.
    850               # This blocks until the batch has finished executing.

~/miniconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--> 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

~/miniconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    642         # Lifting succeeded, so variables are initialized and we can run the
    643         # stateless function.
--> 644         return self._stateless_fn(*args, **kwds)
    645     else:
    646       canon_args, canon_kwds = \

~/miniconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2418     with self._lock:
   2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2421 
   2422   @property

~/miniconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs)
   1659       `args` and `kwargs`.
   1660     """"""
-> 1661     return self._call_flat(
   1662         (t for t in nest.flatten((args, kwargs), expand_composites=True)
   1663          if isinstance(t, (ops.Tensor,

~/miniconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1743         and executing_eagerly):
   1744       # No tape is watching; skip to running the function.
-> 1745       return self._build_call_outputs(self._inference_function.call(
   1746           ctx, args, cancellation_manager=cancellation_manager))
   1747     forward_backward = self._select_forward_and_backward_functions(

~/miniconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    591       with _InterpolateFunctionError(self):
    592         if cancellation_manager is None:
--> 593           outputs = execute.execute(
    594               str(self.signature.name),
    595               num_outputs=self._num_outputs,

~/miniconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     57   try:
     58     ctx.ensure_initialized()
---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:

UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node sequential_1/conv2d/Conv2D (defined at <ipython-input-20-0e520e098f8a>:6) ]] [Op:__inference_train_function_59155]

Function call stack:
train_function`

####################
**My specs:**
####################

NAME=""elementary OS""
VERSION=""5.1.6 Hera""
ID=elementary
ID_LIKE=ubuntu
PRETTY_NAME=""elementary OS 5.1.6 Hera""
LOGO=distributor-logo
VERSION_ID=""5.1.6""
HOME_URL=""https://elementary.io/""
SUPPORT_URL=""https://elementary.io/support""
BUG_REPORT_URL=""https://github.com/elementary/os/issues/new""
PRIVACY_POLICY_URL=""https://elementary.io/privacy-policy""
VERSION_CODENAME=hera
UBUNTU_CODENAME=bionic

Distributor ID:	Ubuntu
Description:	Ubuntu 18.04.4 LTS
Release:	18.04
Codename:	bionic

GPU drivers (nvidia-smi)
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 207...  Off  | 00000000:09:00.0  On |                  N/A |
|  0%   51C    P8    25W / 215W |   7915MiB /  7979MiB |      2%      Default |
+-------------------------------+----------------------+----------------------+
 

(All installed with conda install)
**Tensorflow-gpu version 2.2.0**
cudnn                     7.6.5                cuda10.1_0  
cudatoolkit               10.1.243             h6bb024c_0  
                                                                             
I tried installing driver version 435 and it worked but my screen stops being recognized, therefore I cannot readjust the resolution



"
41885,Peraid131-White,"
![prs-p-1](https://user-images.githubusercontent.com/68693282/88882575-8559fe80-d247-11ea-95a6-e46664fcf92d.jpg)
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
41884,K-fold Cross Validation error in Tensorflow sklearn,"I am using following code for semantic segmentation (image, and mask), this code was working fine with simple training and testing, but when i tried to implement k-fold cross validation. this code has shown error, please check my code and let me know what is wrong, and how i can fix this!

````
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.losses import sparse_categorical_crossentropy
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import KFold
import numpy as np

def tf_dataset(x, y, batch=8):
    dataset = tf.data.Dataset.from_tensor_slices((x, y))
    dataset = dataset.map(tf_parse)
    dataset = dataset.batch(batch)
    dataset = dataset.repeat()
    return dataset

train_dataset = tf_dataset(train_x, train_y, batch=batch_size)
valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)

num_folds = 10

# Define per-fold score containers
acc_per_fold = []
loss_per_fold = []

# Define the K-fold Cross Validator
kfold = KFold(n_splits=num_folds, shuffle=True)

# K-fold Cross Validation model evaluation
fold_no = 1

for train, valid in kfold.split(train_dataset, valid_dataset):
  
  optimizer = tf.keras.optimizers.Adam(lr)
  metrics = ['accuracy']
  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=metrics)

  callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),
              EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False)]

  train_steps = len(train_x) // batch_size
  valid_steps = len(valid_x) // batch_size

  if len(train_x) % batch_size != 0:
    train_steps += 1
  if len(valid_x) % batch_size != 0:
    valid_steps += 1


  # Generate a print
  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  model.fit(train_dataset[train], valid_dataset[train],
            epochs=epochs,
            steps_per_epoch=train_steps,
            validation_steps=valid_steps,
            callbacks=callbacks)

  # Generate generalization metrics
  scores = model.evaluate(train_dataset[valid], valid_dataset[valid], verbose=0)
  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')
  acc_per_fold.append(scores[1] * 100)
  loss_per_fold.append(scores[0])

  # Increase fold number
  fold_no = fold_no + 1

# == Provide average scores ==
print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print('------------------------------------------------------------------------')
```

**Error:**

> 
> --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () 12 # K-fold Cross Validation model evaluation 13 fold_no = 1 ---> 14 for train, valid in kfold.split(train_dataset, valid_dataset): 15 16 optimizer = tf.keras.optimizers.Adam(lr)
> 
> 4 frames /usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py in _num_samples(x) 150 if len(x.shape) == 0: 151 raise TypeError(""Singleton array %r cannot be considered"" --> 152 "" a valid collection."" % x) 153 # Check that shape is returning an integer or default to len 154 # Dask dataframes may not return numeric shape[0] value
> 
> TypeError: Singleton array array(<RepeatDataset shapes: ((None, 224, 224, 3), (None, 224, 224, 1)), types: (tf.float64, tf.float64)>, dtype=object) cannot be considered a valid collection."
41883,Import TensorFlow Failed,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10 x64
- TensorFlow installed from (source or binary): anaconda prompt
- TensorFlow version: tensorflow2.3.0 only cpu
- Python version: 3.7
- Installed using virtualenv? pip? conda?: from anaconda prompt- [pip install tensorflow]
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: I dont have a GPU



**Describe the problem**
I'm new to tensorflow. Sorry if it's a dummy question.
I downloaded the tensorflow from anaconda prompt as I listed above. Then I only run ""import tensorflow as tf"" as the turtorial said but it goes wrong as below. I check the path and there's no such a dll file. Can anyone help me?



**Any other info / logs**

runfile('C:/Users/13926/zzz/untitled1.py', wdir='C:/Users/13926/zzz')
Traceback (most recent call last):

  File ""C:\Users\13926\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *

ImportError: DLL load failed: The specified module could not be found


During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File ""C:\Users\13926\zzz\untitled1.py"", line 8, in <module>
    import tensorflow as tf

  File ""C:\Users\13926\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util

  File ""C:\Users\13926\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context

  File ""C:\Users\13926\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe

  File ""C:\Users\13926\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow

  File ""C:\Users\13926\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)

ImportError: Traceback (most recent call last):
  File ""C:\Users\13926\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
41882,When i run code by python2 but it read python3 library files erro. What should i do?,"When i run code by python2 but it read python3 library files all time.
As shown below.
![image](https://user-images.githubusercontent.com/31792429/88876372-bb9e7a80-d255-11ea-8ad3-ffb226e50c26.png)


"
41881,tf doesn't use gpu to train ```tf.estimator``` model when I use ```tf.distribute.MirroredStrategy```,"**System information**
CentOS 7 
pip install tensorflow
- TensorFlow version (use command below):
2.2
- Python version:
3.7
- CUDA/cuDNN version:
10.1
- GPU model and memory:
gtx 1070 * 2

You can collect some of this information using our environment capture
v2.2.0-rc4-8-g2b96f3662b 2.2.0


**Describe the current behavior**
When I use ```tf.distribute.MirroredStrategy``` , tf doesn't use gpu to train ```tf.estimator``` model . 
 
**Describe the expected behavior**
When I use ```tf.distribute.MirroredStrategy``` , tf should use all gpu to train ```tf.estimator``` model . 

**code0**
```
import tensorflow as tf

def build_lr_estimator(feature_column_list:list,model_dir:str,config:dict):
    """"""
    """"""
    estimator = tf.estimator.LinearClassifier(
        feature_columns=feature_column_list,
        optimizer=lambda: tf.keras.optimizers.Ftrl(
            learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(
                initial_learning_rate=0.1, decay_steps=10000, decay_rate=0.96, staircase=False, name=None
            ),
            #learning_rate = 0.001,
            l1_regularization_strength=0.001,
        ),
        model_dir = model_dir,
        config=config,
        warm_start_from=None,
    )
    return estimator
```


**code1**
```
tf.get_logger().setLevel('INFO')
mirrored_strategy = tf.distribute.MirroredStrategy(devices=None)
mirrored_strategy_config = tf.estimator.RunConfig(
    train_distribute=mirrored_strategy, eval_distribute=mirrored_strategy
)
train_input_fn = make_input_fn(_type=""train"")
valid_input_fn = make_input_fn(_type=""valid"")
feature_column_list_path = FEATURE_COLUMN_LIST_PATH
with open(feature_column_list_path,""rb"") as f:
    feature_column_list = dill.load(f)
lr_model = build_lr_estimator(
    feature_column_list,
    model_dir=os.path.join(_DIR,""data"",""model_callback"",""train""),
    config=mirrored_strategy_config,
    #config=None,
)
lr_model.train(train_input_fn)
```
**logs1**
```
2020-07-30 09:49:59.880322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-30 09:50:00.348416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.348838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 09:50:00.348913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.349283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 09:50:00.349457: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 09:50:00.351300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-30 09:50:00.352937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-30 09:50:00.353153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-30 09:50:00.354902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-30 09:50:00.355745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-30 09:50:00.359075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-30 09:50:00.359186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.359604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.359985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.360355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.360690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-07-30 09:50:00.360993: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-30 09:50:00.366483: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 4008000000 Hz
2020-07-30 09:50:00.366764: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cb9dfa9590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-30 09:50:00.366787: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-30 09:50:00.439573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.441319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.441813: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cb9e033be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-30 09:50:00.441836: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-07-30 09:50:00.441846: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1070, Compute Capability 6.1
2020-07-30 09:50:00.442648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.443005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 09:50:00.443066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.443404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 09:50:00.443436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 09:50:00.443451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-30 09:50:00.443465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-30 09:50:00.443479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-30 09:50:00.443492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-30 09:50:00.443509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-30 09:50:00.443524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-30 09:50:00.443575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.443950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.444319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.444688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.445025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-07-30 09:50:00.445065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 09:50:00.446166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-30 09:50:00.446193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1
2020-07-30 09:50:00.446205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y
2020-07-30 09:50:00.446213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N
2020-07-30 09:50:00.446311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.446747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.447139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.447499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7553 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-07-30 09:50:00.447824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:00.452857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7554 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070, pci bus id: 0000:02:00.0, compute capability: 6.1)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Initializing RunConfig with distribution strategies.
INFO:tensorflow:Not using Distribute Coordinator.
INFO:tensorflow:Using config: {'_model_dir': '/home/zhaodachuan/data/lr_model_data/data/model_callback/train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f7f69aafd90>, '_device_fn': None, '_protocol': None, '_eval_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f7f69aafd90>, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}
WARNING:tensorflow:From /home/zhaodachuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Calling model_fn.
WARNING:tensorflow:From /home/zhaodachuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:540: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
WARNING:tensorflow:From /home/zhaodachuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:batch_all_reduce: 25 all-reduces with algorithm = nccl, num_packs = 1
WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).
WARNING:tensorflow:AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7f802c34c830> and will run it as-is.
Cause: could not parse the source code:

      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))

This error may be avoided by creating the lambda in a standalone statement.

To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
INFO:tensorflow:Create CheckpointSaverHook.
WARNING:tensorflow:From /home/zhaodachuan/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.
Instructions for updating:
Use the iterator's `initializer` property instead.
INFO:tensorflow:Graph was finalized.
2020-07-30 09:50:53.797698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.798125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 09:50:53.798249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.798835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 09:50:53.798882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 09:50:53.798898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-30 09:50:53.798914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-30 09:50:53.798929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-30 09:50:53.798943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-30 09:50:53.798959: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-30 09:50:53.798974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-30 09:50:53.799025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.799470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.800099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.800500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.801124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-07-30 09:50:53.801166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-30 09:50:53.801177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1
2020-07-30 09:50:53.801187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y
2020-07-30 09:50:53.801194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N
2020-07-30 09:50:53.801307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.801728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.802388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.802789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7553 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-07-30 09:50:53.802864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 09:50:53.803485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7554 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070, pci bus id: 0000:02:00.0, compute capability: 6.1)
2020-07-30 09:50:55.361690: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
Identity: GPU CPU XLA_CPU XLA_GPU
Switch: GPU CPU XLA_CPU XLA_GPU
ResourceSparseApplyFtrl: CPU
Cast: GPU CPU XLA_CPU XLA_GPU
VarHandleOp: GPU CPU XLA_CPU XLA_GPU
Const: GPU CPU XLA_CPU XLA_GPU
VarIsInitializedOp: GPU CPU XLA_CPU XLA_GPU
AssignVariableOp: GPU CPU XLA_CPU XLA_GPU
ReadVariableOp: GPU CPU XLA_CPU XLA_GPU
GatherV2: GPU CPU XLA_CPU XLA_GPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/single_visit_duration_bucketized/weights/Initializer/zeros (Const)
  linear/linear_model/single_visit_duration_bucketized/weights (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/single_visit_duration_bucketized/weights/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/single_visit_duration_bucketized/weights/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/single_visit_duration_bucketized/weights/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/ReadVariableOp (ReadVariableOp)
  linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/weighted_sum/embedding_lookup_sparse/embedding_lookup/axis (Const)
  linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/weighted_sum/embedding_lookup_sparse/embedding_lookup (GatherV2)
  zero_fraction/total_size/Size_18/ReadVariableOp (ReadVariableOp)
  training/Ftrl/gradients/gradients/linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/weighted_sum/embedding_lookup_sparse/embedding_lookup_grad/Shape (Const)
  training/Ftrl/gradients/gradients/linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/weighted_sum/embedding_lookup_sparse/embedding_lookup_grad/Cast (Cast)
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator/Initializer/Const (Const)
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear/Initializer/zeros (Const)
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/Ftrl/update_linear/linear_model/single_visit_duration_bucketized/weights/update_0/ResourceSparseApplyFtrl (ResourceSparseApplyFtrl) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_38 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_208 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_210 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_212 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_214 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables_1/VarIsInitializedOp_38 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_208 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_210 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_212 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_214 (VarIsInitializedOp)
  save/Read_20/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/Read_70/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/Read_71/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/AssignVariableOp_40 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/ReadVariableOp_40 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/AssignVariableOp_140 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/ReadVariableOp_140 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/AssignVariableOp_142 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/ReadVariableOp_142 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  zero_fraction/total_zero/zero_count_18/linear/linear_model/single_visit_duration_bucketized/weights/_351 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/zero_fraction/total_zero/zero_count_18/then/_346/input/_1207 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  zero_fraction/total_zero/zero_count_18/else/_347/zero_fraction/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  Func/zero_fraction/total_zero/zero_count_18/else/_347/input/_1212 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.362210: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
Switch: GPU CPU XLA_CPU XLA_GPU
ResourceSparseApplyFtrl: CPU
Cast: GPU CPU XLA_CPU XLA_GPU
GatherV2: GPU CPU XLA_CPU XLA_GPU
VarHandleOp: GPU CPU XLA_CPU XLA_GPU
Identity: GPU CPU XLA_CPU XLA_GPU
Const: GPU CPU XLA_CPU XLA_GPU
VarIsInitializedOp: GPU CPU XLA_CPU XLA_GPU
AssignVariableOp: GPU CPU XLA_CPU XLA_GPU
ReadVariableOp: GPU CPU XLA_CPU XLA_GPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/single_visit_duration_bucketized/weights/replica_1/Initializer/Identity (Identity) /job:localhost/replica:0/task:0/device:GPU:1
  linear/linear_model/single_visit_duration_bucketized/weights/replica_1 (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:1
  linear/linear_model/single_visit_duration_bucketized/weights/replica_1/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:1
  linear/linear_model/single_visit_duration_bucketized/weights/replica_1/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  linear/linear_model/single_visit_duration_bucketized/weights/replica_1/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator/replica_1/Initializer/Identity (Identity) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator/replica_1 (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator/replica_1/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator/replica_1/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/accumulator/replica_1/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear/replica_1/Initializer/Identity (Identity) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear/replica_1 (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear/replica_1/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear/replica_1/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/single_visit_duration_bucketized/weights/linear/replica_1/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/ReadVariableOp (ReadVariableOp)
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/weighted_sum/embedding_lookup_sparse/embedding_lookup/axis (Const)
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/weighted_sum/embedding_lookup_sparse/embedding_lookup (GatherV2)
  replica_1/zero_fraction/total_size/Size_18/ReadVariableOp (ReadVariableOp)
  training_1/Ftrl/gradients/gradients/replica_1/linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/weighted_sum/embedding_lookup_sparse/embedding_lookup_grad/Shape (Const)
  training_1/Ftrl/gradients/gradients/replica_1/linear/linear_model/linear/linear_model/linear/linear_model/single_visit_duration_bucketized/weighted_sum/embedding_lookup_sparse/embedding_lookup_grad/Cast (Cast)
  training/Ftrl/Ftrl/update_linear/linear_model/single_visit_duration_bucketized/weights/update_1/ResourceSparseApplyFtrl (ResourceSparseApplyFtrl) /job:localhost/replica:0/task:0/device:GPU:1
  report_uninitialized_variables/VarIsInitializedOp_39 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_209 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_211 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_213 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_215 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables_1/VarIsInitializedOp_39 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_209 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_211 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_213 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_215 (VarIsInitializedOp)
  save/AssignVariableOp_41 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/ReadVariableOp_41 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/AssignVariableOp_141 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/ReadVariableOp_141 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/AssignVariableOp_143 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/ReadVariableOp_143 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/AssignVariableOp_210 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/AssignVariableOp_211 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/zero_fraction/total_zero/zero_count_18/linear/linear_model/single_visit_duration_bucketized/weights/replica_1/_604 (Switch) /job:localhost/replica:0/task:0/device:GPU:1
  Func/replica_1/zero_fraction/total_zero/zero_count_18/then/_599/input/_1489 (Identity) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/zero_fraction/total_zero/zero_count_18/else/_600/zero_fraction/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  Func/replica_1/zero_fraction/total_zero/zero_count_18/else/_600/input/_1494 (Identity) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.362707: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
Identity: GPU CPU XLA_CPU XLA_GPU
Switch: GPU CPU XLA_CPU XLA_GPU
ResourceSparseApplyFtrl: CPU
Cast: GPU CPU XLA_CPU XLA_GPU
GatherV2: GPU CPU XLA_CPU XLA_GPU
ReadVariableOp: GPU CPU XLA_CPU XLA_GPU
AssignVariableOp: GPU CPU XLA_CPU XLA_GPU
Mul: GPU CPU XLA_CPU XLA_GPU
TruncatedNormal: GPU CPU XLA_CPU XLA_GPU
Add: GPU CPU XLA_CPU XLA_GPU
VarHandleOp: GPU CPU XLA_CPU XLA_GPU
Fill: GPU CPU XLA_CPU XLA_GPU
Const: GPU CPU XLA_CPU XLA_GPU
VarIsInitializedOp: GPU CPU XLA_CPU XLA_GPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/uuid_embedding/embedding_weights/Initializer/truncated_normal/shape (Const)
  linear/linear_model/uuid_embedding/embedding_weights/Initializer/truncated_normal/mean (Const)
  linear/linear_model/uuid_embedding/embedding_weights/Initializer/truncated_normal/stddev (Const)
  linear/linear_model/uuid_embedding/embedding_weights/Initializer/truncated_normal/TruncatedNormal (TruncatedNormal)
  linear/linear_model/uuid_embedding/embedding_weights/Initializer/truncated_normal/mul (Mul)
  linear/linear_model/uuid_embedding/embedding_weights/Initializer/truncated_normal (Add)
  linear/linear_model/uuid_embedding/embedding_weights (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/uuid_embedding/embedding_weights/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/uuid_embedding/embedding_weights/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/uuid_embedding/embedding_weights/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/ReadVariableOp (ReadVariableOp)
  linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_embedding_weights/embedding_lookup_sparse/embedding_lookup/axis (Const)
  linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_embedding_weights/embedding_lookup_sparse/embedding_lookup (GatherV2)
  zero_fraction/total_size/Size_22/ReadVariableOp (ReadVariableOp)
  training/Ftrl/gradients/gradients/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_embedding_weights/embedding_lookup_sparse/embedding_lookup_grad/Shape (Const)
  training/Ftrl/gradients/gradients/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_embedding_weights/embedding_lookup_sparse/embedding_lookup_grad/Cast (Cast)
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator/Initializer/Const (Const)
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/Initializer/zeros/shape_as_tensor (Const)
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/Initializer/zeros/Const (Const)
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/Initializer/zeros (Fill)
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  training/Ftrl/Ftrl/update_linear/linear_model/uuid_embedding/embedding_weights/update_0/ResourceSparseApplyFtrl (ResourceSparseApplyFtrl) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_46 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_240 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_242 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_244 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_246 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables_1/VarIsInitializedOp_46 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_240 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_242 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_244 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_246 (VarIsInitializedOp)
  save/Read_24/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/Read_78/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/Read_79/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/AssignVariableOp_48 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/ReadVariableOp_48 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/AssignVariableOp_156 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/ReadVariableOp_156 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/AssignVariableOp_158 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  save/ReadVariableOp_158 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  zero_fraction/total_zero/zero_count_22/linear/linear_model/uuid_embedding/embedding_weights/_387 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/zero_fraction/total_zero/zero_count_22/then/_382/input/_1247 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  zero_fraction/total_zero/zero_count_22/else/_383/zero_fraction/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  Func/zero_fraction/total_zero/zero_count_22/else/_383/input/_1252 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.363172: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
Switch: GPU CPU XLA_CPU XLA_GPU
ResourceSparseApplyFtrl: CPU
Cast: GPU CPU XLA_CPU XLA_GPU
GatherV2: GPU CPU XLA_CPU XLA_GPU
VarHandleOp: GPU CPU XLA_CPU XLA_GPU
Identity: GPU CPU XLA_CPU XLA_GPU
Const: GPU CPU XLA_CPU XLA_GPU
VarIsInitializedOp: GPU CPU XLA_CPU XLA_GPU
AssignVariableOp: GPU CPU XLA_CPU XLA_GPU
ReadVariableOp: GPU CPU XLA_CPU XLA_GPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/uuid_embedding/embedding_weights/replica_1/Initializer/Identity (Identity) /job:localhost/replica:0/task:0/device:GPU:1
  linear/linear_model/uuid_embedding/embedding_weights/replica_1 (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:1
  linear/linear_model/uuid_embedding/embedding_weights/replica_1/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:1
  linear/linear_model/uuid_embedding/embedding_weights/replica_1/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  linear/linear_model/uuid_embedding/embedding_weights/replica_1/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator/replica_1/Initializer/Identity (Identity) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator/replica_1 (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator/replica_1/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator/replica_1/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/accumulator/replica_1/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/replica_1/Initializer/Identity (Identity) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/replica_1 (VarHandleOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/replica_1/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/replica_1/Assign (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  training/Ftrl/linear/linear_model/uuid_embedding/embedding_weights/linear/replica_1/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/ReadVariableOp (ReadVariableOp)
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_embedding_weights/embedding_lookup_sparse/embedding_lookup/axis (Const)
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_embedding_weights/embedding_lookup_sparse/embedding_lookup (GatherV2)
  replica_1/zero_fraction/total_size/Size_22/ReadVariableOp (ReadVariableOp)
  training_1/Ftrl/gradients/gradients/replica_1/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_embedding_weights/embedding_lookup_sparse/embedding_lookup_grad/Shape (Const)
  training_1/Ftrl/gradients/gradients/replica_1/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_embedding_weights/embedding_lookup_sparse/embedding_lookup_grad/Cast (Cast)
  training/Ftrl/Ftrl/update_linear/linear_model/uuid_embedding/embedding_weights/update_1/ResourceSparseApplyFtrl (ResourceSparseApplyFtrl) /job:localhost/replica:0/task:0/device:GPU:1
  report_uninitialized_variables/VarIsInitializedOp_47 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_241 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_243 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_245 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables/VarIsInitializedOp_247 (VarIsInitializedOp) /job:localhost/replica:0/task:0/device:GPU:0
  report_uninitialized_variables_1/VarIsInitializedOp_47 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_241 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_243 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_245 (VarIsInitializedOp)
  report_uninitialized_variables_1/VarIsInitializedOp_247 (VarIsInitializedOp)
  save/AssignVariableOp_49 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/ReadVariableOp_49 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/AssignVariableOp_157 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/ReadVariableOp_157 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/AssignVariableOp_159 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/ReadVariableOp_159 (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/AssignVariableOp_218 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  save/AssignVariableOp_219 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/zero_fraction/total_zero/zero_count_22/linear/linear_model/uuid_embedding/embedding_weights/replica_1/_640 (Switch) /job:localhost/replica:0/task:0/device:GPU:1
  Func/replica_1/zero_fraction/total_zero/zero_count_22/then/_635/input/_1529 (Identity) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/zero_fraction/total_zero/zero_count_22/else/_636/zero_fraction/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:1
  Func/replica_1/zero_fraction/total_zero/zero_count_22/else/_636/input/_1534 (Identity) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.363474: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/active_reading_period_indicator/active_reading_period_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/active_reading_period_indicator/active_reading_period_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/active_reading_period_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.363632: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/article_type_name_indicator/article_type_name_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/article_type_name_indicator/article_type_name_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/article_type_name_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.363780: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/channel_names_indicator/channel_names_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/channel_names_indicator/channel_names_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/channel_names_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.363947: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/isopen_push_indicator/isopen_push_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/isopen_push_indicator/isopen_push_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/isopen_push_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.364102: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/latest_area_indicator/latest_area_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/latest_area_indicator/latest_area_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/latest_area_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.364259: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/permanent_land_indicator/permanent_land_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/permanent_land_indicator/permanent_land_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/permanent_land_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.364404: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/phone_brand_newest_indicator/phone_brand_newest_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/phone_brand_newest_indicator/phone_brand_newest_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/phone_brand_newest_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.364625: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/source_name_indicator/source_name_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/source_name_indicator/source_name_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/source_name_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.364784: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.364952: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  linear/linear_model/linear/linear_model/linear/linear_model/visit_page_class_indicator/visit_page_class_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/visit_page_class_indicator/visit_page_class_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:0
  linear/linear_model/linear/linear_model/linear/linear_model/visit_page_class_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:0

2020-07-30 09:50:55.365386: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/active_reading_period_indicator/active_reading_period_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/active_reading_period_indicator/active_reading_period_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/active_reading_period_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.365537: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/article_type_name_indicator/article_type_name_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/article_type_name_indicator/article_type_name_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/article_type_name_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.365682: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/channel_names_indicator/channel_names_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/channel_names_indicator/channel_names_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/channel_names_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.365845: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/isopen_push_indicator/isopen_push_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/isopen_push_indicator/isopen_push_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/isopen_push_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.365990: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/latest_area_indicator/latest_area_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/latest_area_indicator/latest_area_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/latest_area_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.366147: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/permanent_land_indicator/permanent_land_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/permanent_land_indicator/permanent_land_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/permanent_land_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.366291: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/phone_brand_newest_indicator/phone_brand_newest_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/phone_brand_newest_indicator/phone_brand_newest_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/phone_brand_newest_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.366512: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/source_name_indicator/source_name_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/source_name_indicator/source_name_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/source_name_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.366668: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/uuid_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/uuid_embedding/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

2020-07-30 09:50:55.366840: W tensorflow/core/common_runtime/colocation_graph.cc:1017] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:1' supported_device_types_=[CPU] possible_devices_=[]
LookupTableFindV2: CPU
HashTableV2: CPU
LookupTableImportV2: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/visit_page_class_indicator/visit_page_class_lookup/hash_table/hash_table (HashTableV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/visit_page_class_indicator/visit_page_class_lookup/hash_table/table_init/LookupTableImportV2 (LookupTableImportV2) /job:localhost/replica:0/task:0/device:GPU:1
  replica_1/linear/linear_model/linear/linear_model/linear/linear_model/visit_page_class_indicator/hash_table_Lookup/LookupTableFindV2 (LookupTableFindV2) /job:localhost/replica:0/task:0/device:GPU:1

INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...
INFO:tensorflow:Saving checkpoints for 0 into /home/zhaodachuan/data/lr_model_data/data/model_callback/train/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...
2020-07-30 09:52:51.082541: W tensorflow/core/grappler/utils/graph_view.cc:832] No registered 'MultiDeviceIteratorFromStringHandle' OpKernel for GPU devices compatible with node {{node MultiDeviceIteratorFromStringHandle}}
        .  Registered:  device='CPU'

2020-07-30 09:52:51.083215: W tensorflow/core/grappler/utils/graph_view.cc:832] No registered 'MultiDeviceIteratorGetNextFromShard' OpKernel for GPU devices compatible with node {{node MultiDeviceIteratorGetNextFromShard}}
        .  Registered:  device='CPU'

2020-07-30 09:52:51.089263: W tensorflow/core/grappler/utils/graph_view.cc:832] No registered 'MultiDeviceIteratorFromStringHandle' OpKernel for GPU devices compatible with node {{node MultiDeviceIteratorFromStringHandle}}
        .  Registered:  device='CPU'

2020-07-30 09:52:51.089670: W tensorflow/core/grappler/utils/graph_view.cc:832] No registered 'MultiDeviceIteratorGetNextFromShard' OpKernel for GPU devices compatible with node {{node MultiDeviceIteratorGetNextFromShard}}
        .  Registered:  device='CPU'

2020-07-30 09:52:54.569784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 1.3862944, step = 0
INFO:tensorflow:global_step/sec: 16.243
INFO:tensorflow:loss = 0.0002972064, step = 100 (6.157 sec)
INFO:tensorflow:global_step/sec: 28.2076
```
**code2**
```
tf.get_logger().setLevel('INFO')
mirrored_strategy = tf.distribute.MirroredStrategy(devices=None)
mirrored_strategy_config = tf.estimator.RunConfig(
    train_distribute=mirrored_strategy, eval_distribute=mirrored_strategy
)
train_input_fn = make_input_fn(_type=""train"")
valid_input_fn = make_input_fn(_type=""valid"")
feature_column_list_path = FEATURE_COLUMN_LIST_PATH
with open(feature_column_list_path,""rb"") as f:
    feature_column_list = dill.load(f)
lr_model = build_lr_estimator(
    feature_column_list,
    model_dir=os.path.join(_DIR,""data"",""model_callback"",""train""),
    #config=mirrored_strategy_config,
    config=None,
)
lr_model.train(train_input_fn)
```
**logs2**
```
2020-07-30 10:03:36.371458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-30 10:03:36.850104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.850514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 10:03:36.850589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.851184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 10:03:36.851363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 10:03:36.852982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-30 10:03:36.854618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-30 10:03:36.854820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-30 10:03:36.856409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-30 10:03:36.857170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-30 10:03:36.860369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-30 10:03:36.860521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.861002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.861626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.862052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.862639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-07-30 10:03:36.862990: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-30 10:03:36.868372: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 4008000000 Hz
2020-07-30 10:03:36.868708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558ebdee35d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-30 10:03:36.868726: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-30 10:03:36.942375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.944161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.944639: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558ebdf6dc30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-30 10:03:36.944661: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-07-30 10:03:36.944670: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1070, Compute Capability 6.1
2020-07-30 10:03:36.945471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.945825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 10:03:36.945886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.946224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 10:03:36.946255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 10:03:36.946270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-30 10:03:36.946283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-30 10:03:36.946296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-30 10:03:36.946313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-30 10:03:36.946327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-30 10:03:36.946341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-30 10:03:36.946390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.946760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.947164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.947604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.947981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-07-30 10:03:36.948020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 10:03:36.951940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-30 10:03:36.951972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1
2020-07-30 10:03:36.951983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y
2020-07-30 10:03:36.951991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N
2020-07-30 10:03:36.952104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.952533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.953239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.953644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7553 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-07-30 10:03:36.954039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:03:36.954639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7554 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070, pci bus id: 0000:02:00.0, compute capability: 6.1)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Initializing RunConfig with distribution strategies.
INFO:tensorflow:Not using Distribute Coordinator.
INFO:tensorflow:Using default config.
INFO:tensorflow:Using config: {'_model_dir': '/home/zhaodachuan/data/lr_model_data/data/model_callback/train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:From /home/zhaodachuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /home/zhaodachuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
INFO:tensorflow:Calling model_fn.
WARNING:tensorflow:From /home/zhaodachuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:540: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
WARNING:tensorflow:From /home/zhaodachuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
2020-07-30 10:04:01.288559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.288991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 10:04:01.289118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.289702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-30 10:04:01.289749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-30 10:04:01.289769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-30 10:04:01.289786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-30 10:04:01.289803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-30 10:04:01.289832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-30 10:04:01.289852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-30 10:04:01.289868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-30 10:04:01.289925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.290325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.290944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.291342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.291952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-07-30 10:04:01.291995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-30 10:04:01.292006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1
2020-07-30 10:04:01.292014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y
2020-07-30 10:04:01.292022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N
2020-07-30 10:04:01.292118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.292544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.293155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.293526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7553 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-07-30 10:04:01.293599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-30 10:04:01.294158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7554 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070, pci bus id: 0000:02:00.0, compute capability: 6.1)
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...
INFO:tensorflow:Saving checkpoints for 0 into /home/zhaodachuan/data/lr_model_data/data/model_callback/train/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...
2020-07-30 10:05:04.494990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.6931472, step = 0
INFO:tensorflow:global_step/sec: 55.9369
INFO:tensorflow:loss = 3.0821118e-06, step = 100 (1.788 sec)
INFO:tensorflow:global_step/sec: 215.479
INFO:tensorflow:loss = 2.562792e-05, step = 200 (0.464 sec)
```"
41879,Model was stuck when build model with inputs and outputs based on transformer.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MACOS 10.15.5 Catalina
- TensorFlow version: 2.2 and 2.3
- Python version: 3.6

**Describe the problem**
I want to build a transformer (according to this [notebook](https://www.tensorflow.org/tutorials/text/transformer)) model in non-eager execution, and everything runs smoothly only when building model with the tf.keras.layers.Input and its corresponding outputs, the whole program is stuck. By the way, when executing the for loop in block 10, it consumes extremely much time.

There are no error messages about this phenomenon, totally have no idea about what leads to this.

I have replicated this issue [here](https://colab.research.google.com/drive/1sGkTwMUgOUSlfbYmyuEOaQK7inECuCp9?usp=sharing) in google colab.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I initialized an Input `tf.keras.layers.Input` and generate outputs with transformer model, then use the input and outputs to build a model but the whole program is stuck.
"
41878,tf.keras.losses.binary_crossentropy gives worse result than calling 'binary_crossentropy',"**QUESTION 1:** Why does calling binary_crossentropy by its name with a string 'binary_crossentropy' gives different (better) results than calling, the same(?), tf.keras.losses.binary_crossentropy function inside a custom loss function?

**QUESTION 2:** What am I doing wrong?

**PROBLEM:** I'm trying to solve a mystery of different results I get when I use:
```python
def bc_custom(y_true, y_pred): return tf.keras.losses.binary_crossentropy(y_true, y_pred)
model1.compile(optimizer=tf.compat.v2.optimizers.Adam(learning_rate=LEARNING_RATE, loss = bc_custom, metrics=['binary_accuracy'])
```
and 
```python
model2.compile(optimizer=tf.compat.v2.optimizers.Adam(learning_rate=LEARNING_RATE, loss = 'binary_crossentropy', metrics=['binary_accuracy'])
```
Basically: 

 - the difference is in calling binary_crossentropy inside a custom function (model1) and the same function by its name with a string (model2),
 - following https://stackoverflow.com/a/57331394/5536388 advice, I set metrics to binary_accuracy,
 - both models use the same dataset which may only differ after being shuffled in the training process,
 - the models solve a multilabel classification problem. The final layer uses the sigmoid activation function.

**RESULTS:**
I made several tests and each time model1:

 - is being taught much slower:

 epoch, accuracy, loss, accuracy_val, loss_val
    
    0,0.01571397,0.08330947177696847,0.08565965,0.06395021689980937
    1,0.14730678,0.04977951637815227,0.24956022,0.039584608338986936 
    2,0.2366954,0.98736,0.2366954,0.03144164173531004,0.27801147,0.99116695,0.27801147,0.022898457557974424

vs model2

    0,0.98126763,0.08199372373072011,0.9798808,0.061917345579108135
    1,0.98271894,0.0477434622772295,0.98628557,0.03482157470263099
    2,0.9884866,0.9884866,0.24891642,0.028994456771504733,0.9914624,0.9914624,0.27778202,0.022188534344907987

 - model1 gives worse results, at least in the beginning (haven't waited till the final results):
[![model1 results after epoch 0][1]][1]
results of model1 after epoch 0
[![model2 results after epoch 0][2]][2]
results of model2 after epoch 0

 - what's even more interesting, when a smaller dataset, 'binary_crossentropy' still gives some prediction results while the custom function returns 0 probability across all labels :|. 

The expected results are one-point-wide straight-to-top lines in several positions (10, 30, 50, 110, 140, 210, 230) as the model2 is clearly going to and, in the end, reaches the correct answer in 98% of cases. 


  [1]: https://i.stack.imgur.com/llgpH.png
  [2]: https://i.stack.imgur.com/eFg5l.png"
41877,"TFLiteConverter: ConvertError: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types","**System information**
- OS Platform and Distribution: Manjaro running Ubuntu 18.04 under Docker (using the `tensorflow/tensorflow:2.2.0-gpu-jupyter` image)
- TensorFlow installed from (source or binary): Using official docker image, actually not sure if it's source or binary.
- TensorFlow version (or github SHA if from source): 2.2.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```python
import sys
import os

import tensorflow as tf


def usage():
    proggie = os.path.basename(sys.argv[0])
    print(f""""""\
Usage: {proggie} <input_saved_model_dir> <output>

Example: {proggie} output_inference_graph_v1.pb/saved_model converted_model.tflite"""""")


if __name__ == ""__main__"":
    if len(sys.argv) != 3 or '-h' in sys.argv or '--help' in sys.argv:
        usage()
        sys.exit(1)

    saved_model_dir, outfile = sys.argv[1:]
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
    tflite_model = converter.convert()
    with tf.io.gfile.GFile('model.tflite', 'wb') as f:
        f.write(tflite_model)
    print(f""{outfile} written"")
```

**The output from the converter invocation**

```
docker exec -ti tf2 \
        bash -c \
        ""cd /tf/routespotter/training/routesv3/ && python /tf/routespotter/scripts/convert_to_tflite.py trained-inference-graphs/output/saved_model trained-inference-graphs/output/converted_model.tflite""
2020-07-29 21:30:35.933784: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-07-29 21:30:37.541131: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-07-29 21:30:37.554309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:65:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.835GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-29 21:30:37.554340: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-07-29 21:30:37.555786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-07-29 21:30:37.557191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-07-29 21:30:37.557467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-07-29 21:30:37.558961: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-07-29 21:30:37.559781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-07-29 21:30:37.562688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-07-29 21:30:37.563390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-07-29 21:30:37.563659: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-07-29 21:30:37.569752: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3301490000 Hz
2020-07-29 21:30:37.571232: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaf61e40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-29 21:30:37.571276: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-29 21:30:37.718561: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xafcdab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-29 21:30:37.718596: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-07-29 21:30:37.719275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:65:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.835GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-29 21:30:37.719308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-07-29 21:30:37.719337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-07-29 21:30:37.719357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-07-29 21:30:37.719375: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-07-29 21:30:37.719394: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-07-29 21:30:37.719406: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-07-29 21:30:37.719422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-07-29 21:30:37.720408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-07-29 21:30:37.720450: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-07-29 21:30:38.075379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-29 21:30:38.075416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-07-29 21:30:38.075422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-07-29 21:30:38.076193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7091 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:65:00.0, compute capability: 6.1)
2020-07-29 21:30:47.046860: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-07-29 21:30:47.046987: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-07-29 21:30:47.047691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:65:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.835GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-07-29 21:30:47.047721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-07-29 21:30:47.047745: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-07-29 21:30:47.047755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-07-29 21:30:47.047765: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-07-29 21:30:47.047775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-07-29 21:30:47.047788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-07-29 21:30:47.047798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-07-29 21:30:47.048149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-07-29 21:30:47.048174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-29 21:30:47.048181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-07-29 21:30:47.048188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-07-29 21:30:47.048560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7091 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:65:00.0, compute capability: 6.1)
2020-07-29 21:30:47.229748: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize
2020-07-29 21:30:47.229790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 4275 nodes (3787), 4874 edges (4379), time = 107.259ms.
2020-07-29 21:30:47.229795: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 3.916ms.
2020-07-29 21:30:51.658251: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-07-29 21:30:51.658289: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
loc(""Func/StatefulPartitionedCall/input/_0""): error: requires all operands and results to have compatible element types
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py"", line 199, in toco_convert_protos
    enable_mlir_converter)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/wrap_toco.py"", line 38, in wrapped_toco_convert
    enable_mlir_converter)
Exception: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/tf/routespotter/scripts/convert_to_tflite.py"", line 22, in <module>
    tflite_model = converter.convert()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py"", line 1076, in convert
    return super(TFLiteConverterV2, self).convert()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py"", line 900, in convert
    self).convert(graph_def, input_tensors, output_tensors)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py"", line 633, in convert
    **converter_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py"", line 574, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py"", line 202, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>
```

**Also, please include a link to the saved model or GraphDef**

Custom trained model based on [ssd_resnet50_v1_fpn_640x640_coco17_tpu-8](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz) by following the [tensorflow-object-detection-api-tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io). I know my custom trained model works because I've run it through the [object_detection_tutorial](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb) using test images from my dataset and I get successful detections. Not sure if I'm just using an unsupported operand for tflite? Having a hard time deciphering the error message...

```
https://drive.google.com/file/d/1O_c12RAALroTomEvDaH8gwukYzNZDegq/view?usp=sharing
```

**Failure details**
- Conversion process fails


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title. :x:  

**Any other info / logs**

See traceback above."
41876,TensorFlowLiteC and TensorFlowLiteSelectTfOps expose duplicate symbols on iOS,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone 11 Pro Max
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.3.0

**Describe the problem**

When attempting to use TensorFlow Lite on iOS [with `TensorFlowLiteSelectTfOps` as per the documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/ios/TensorFlowLiteSelectTfOps.md), the linker raises an error that it found `17 duplicate symbols for architecture arm64`:

```
duplicate symbol '_TfLiteDelegateCreate' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteFloatArrayCreate' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteFloatArrayFree' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteFloatArrayGetSizeInBytes' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteIntArrayCopy' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteIntArrayCreate' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteIntArrayEqual' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteIntArrayEqualsArray' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteIntArrayFree' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteIntArrayGetSizeInBytes' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteQuantizationFree' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteSparsityFree' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteTensorDataFree' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteTensorFree' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteTensorRealloc' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteTensorReset' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteTypeGetName' in:
    [...snip...]/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(common_1fe599348340cdd31b92895a3a36b237.o)
    [...snip...]/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
ld: 17 duplicate symbols for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Ran `pod install` with the following lines in my `Podfile`, as per documentation:
```
pod 'TensorFlowLiteObjC'
pod 'TensorFlowLiteSelectTfOps', '~> 0.0.1-nightly.20200729'
use_frameworks!
```

Attempted to build the app in Xcode.

`grep Tensor Podfile.lock` returns:
```
  - TensorFlowLiteC (2.3.0):
    - TensorFlowLiteC/Core (= 2.3.0)
  - TensorFlowLiteC/Core (2.3.0)
  - TensorFlowLiteObjC (2.3.0):
    - TensorFlowLiteC (= 2.3.0)
  - TensorFlowLiteSelectTfOps (0.0.1-nightly.20200729)
  - TensorFlowLiteObjC
  - TensorFlowLiteSelectTfOps (~> 0.0.1-nightly.20200729)
    - TensorFlowLiteC
    - TensorFlowLiteObjC
    - TensorFlowLiteSelectTfOps
  TensorFlowLiteC: 51f50caf5777f740a70e2c1a5dbdc149e7aeb50b
  TensorFlowLiteObjC: 5b358503636cffcbbafd8b0ac9badb577fd72800
  TensorFlowLiteSelectTfOps: eb44f3855f87b50470c70a379777c98aaf13a943
```

Friendly ping to @yyoon - I see you've been active in this code recently and may have some insight. 🙂"
41874,Keras ModelCheckpoint callback not raising exception when h5 save fails,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3
- Python version:3.6

**Describe the current behavior**
The callback conceals the exception thrown by `save_model`. The checkpoints are not saved but no error is reported. 

**Describe the expected behavior**
The callback should re-throw the error after catching it. 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/1Nq5ARA3BHTxUyguiFFBBH74tXC54MABB?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41873,Pylint E1121 caused by arguments to reshape method.,"When I run pylint (with provided rc file) on Tensorflow, lot of E1121 popped up. Looking over the code I found lines like this to be the cause:
https://github.com/tensorflow/tensorflow/blob/206ed7a37f0e5e80b1f62e2172f96a9a2f7041c8/tensorflow/python/kernel_tests/parsing_ops_test.py#L449-L454

Specifically the reshape method. Now tests run just fine as they are and it's just a style issue. 
It's completely possible that this was a conscious choice on part of people involved, but if so it might be good idea to adjust relevant parts of projects style definition.

Especially because most of the numpy docs seem to show tuple as a way to pass new shape to the method:
https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy.reshape

If this is an oversight I can open a PR with fix for at least several files. Alternatively I can take a look at the style definition adjustment. "
41871,Unable to install tensorflow even after upgrading pip,"
![error](https://user-images.githubusercontent.com/42766576/88843049-199f7380-d1fe-11ea-9477-2bac3760a634.png)
<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Windows 10.0.18363
- TensorFlow installed from (source or binary): Tried to install using `pip install tensorFlow`
- TensorFlow version: 
- Python version: Tried on both 3.6.0 and 3.8.5
- Installed using pip


**Describe the problem**
I tried to install tensorflow but encountered an error as there is no matching distribution. By going through the previous issues I upgrade my pip version to 20.2. Tried it on both python 3.6 and python 3.8.5 "
41869,Returning tf.data.UNKNOWN_CARDINALITY when the cardinality can be easily computed,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): *yes*
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): *dockerhub tensorflow/tensorflow:latest*
- TensorFlow installed from (source or binary): *dockerhub image*
- TensorFlow version (use command below): *v2.3.0-rc2-23-gb36436b087 2.3.0*

**Describe the current behavior**

*tf.data.Dataset.cardinality returns tf.data.UNKNOWN_CARDINALITY when the cardinality can be easily computed*

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python

import tensorflow as tf

print(tf.__version__)
# prints 2.3.0

nx = 2

t = tf.data.Dataset.from_tensor_slices(tf.constant([[0],[1]]))
t2 = t.flat_map(lambda ti: tf.data.Dataset.from_tensors(ti).repeat(nx))

#########################
for ti in t2:
    print(ti)

# correctly prints:
#tf.Tensor([0], shape=(1,), dtype=int32)
#tf.Tensor([0], shape=(1,), dtype=int32)
#tf.Tensor([1], shape=(1,), dtype=int32)
#tf.Tensor([1], shape=(1,), dtype=int32)

#############################3

print((t2.cardinality() == tf.data.UNKNOWN_CARDINALITY).numpy())
# prints True


```
"
41864,Building of the PIP package (as described in docs) is broken,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?: neither
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 10.2.89/7.6.5
- GPU model and memory: GeForce RTX 2080 Ti



**Describe the problem**

The documentation [says](https://www.tensorflow.org/install/source) that in order to build the PIP package from source you have to:

`./bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag /tmp/tensorflow_pkg
`

This doesn't work, since there is no more `bazel-bin` in the TF source tree, and running the same command with `bazel-tensorlflow` instead of `bazel-bin` doesn't work either.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`./bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag /tmp/tensorflow_pkg`

"
41863,Cuda Error when training RNN,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): Binary (python wheel using pip)
- TensorFlow version: 2.2 AND 2.3
- Python version: 3.8.2
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: GTX 1070 8GB with the current driver 451.67



**Describe the problem**
I wanted to test my tensorflow-gpu installation. It works for CNNs but when I try to run the text classification tutorial where Bidirectional layers with LSTM are used(https://www.tensorflow.org/tutorials/text/text_classification_rnn) the training process crashes during early epochs with this error (I left out part of the repeating part of the stacktrace):
```
E tensorflow/stream_executor/dnn.cc:613] CUDNN_STATUS_INTERNAL_ERROR
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1986): ""cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())""

W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at cudnn_rnn_ops.cc:1922 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1449, 32, 64] 
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I installed cuda 10.1 and cuDNN 7.6.5 and edited my PATH variable accordingly + restarted, because sometimes windows is weird about changing environment variables.
Afterwards I ran `pip install tensorflow-gpu` inside a conda environment.

I then executed a python file containing all the code of the tutorial.

**Any other info / logs**
The error occurs within the first epoch. Not directly after the start, but in early steps during the epoch, which makes me wonder where the problem originates.
When I use a model without the `tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),` layer it works just fine.

When I run `tf.config.list_physical_devices('GPU')` it seems to load all dll's correctly.
I was also considering that this error is due to insufficient GPU memory. Even though the model is 'relatively' small, tensorflow allocated between 6 and 7GB memory. It does that also for small CNN models."
41862,"WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details","
![Capture](https://user-images.githubusercontent.com/62254038/88812450-a242f300-d1af-11ea-8d2f-e461a0e2c00e.JPG)


Hi All,

i'm trying to train train my own models with the tensorflow 2.2, by using predefined models used this link but i'm facing the above error. Can anyone please let me know anyone was able to run the pretrained models on tensorflow 2.2??

thanks in advance."
41861,Function tracing fails after upgrading to 2.3.0,"**System information**
- Windows 7
- TensorFlow 2.3.0 from PyPI
- Python version: 3.7.7
- CPU only

After upgrading to 2.3.0 function tracing fails
```

WARNING:tensorflow:AutoGraph could not transform <function _convert_function_call.<locals>.f at 0x0000000015156E58> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Converted call: <function pfor.<locals>.f at 0x00000000138BBD38>
    args: ()
    kwargs: {}

<function pfor.<locals>.f at 0x00000000138BBD38> is not cached for subkey ConversionOptions[{}]
Source code of <function pfor.<locals>.f at 0x00000000138BBD38>:

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
def f():
  return _pfor_impl(loop_fn,
  iters,
  fallback_to_while_loop=fallback_to_while_loop,
  parallel_iterations=parallel_iterations)


Error transforming entity <function pfor.<locals>.f at 0x00000000138BBD38>
WARNING: AutoGraph could not transform <function pfor.<locals>.f at 0x00000000138BBD38> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

Traceback (most recent call last):
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 584, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 119, in convert
    entity, program_ctx.options, program_ctx, custom_vars)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transpiler.py"", line 412, in transform_function
    extra_locals)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transpiler.py"", line 373, in _transformed_factory
    nodes, ctx = self._transform_function(fn, user_context)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transpiler.py"", line 339, in _transform_function
    node = self.transform_ast(node, context)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 70, in transform_ast
    node = activity.resolve(node, ctx, None)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 705, in resolve
    return ActivityAnalyzer(context, parent_scope).visit(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transformer.py"", line 445, in visit
    result = super(Base, self).visit(node)
  File ""C:\ProgramData\Miniconda3.7\lib\ast.py"", line 271, in visit
    return visitor(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 575, in visit_FunctionDef
    node = self._visit_arg_annotations(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 551, in _visit_arg_annotations
    node = self._visit_arg_declarations(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 556, in _visit_arg_declarations
    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)
AttributeError: 'arguments' object has no attribute 'posonlyargs'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 584, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 119, in convert
    entity, program_ctx.options, program_ctx, custom_vars)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transpiler.py"", line 412, in transform_function
    extra_locals)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transpiler.py"", line 373, in _transformed_factory
    nodes, ctx = self._transform_function(fn, user_context)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transpiler.py"", line 339, in _transform_function
    node = self.transform_ast(node, context)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 70, in transform_ast
    node = activity.resolve(node, ctx, None)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 705, in resolve
    return ActivityAnalyzer(context, parent_scope).visit(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transformer.py"", line 445, in visit
    result = super(Base, self).visit(node)
  File ""C:\ProgramData\Miniconda3.7\lib\ast.py"", line 271, in visit
    return visitor(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 575, in visit_FunctionDef
    node = self._visit_arg_annotations(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 551, in _visit_arg_annotations
    node = self._visit_arg_declarations(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 556, in _visit_arg_declarations
    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)
AttributeError: 'arguments' object has no attribute 'posonlyargs'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 584, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 119, in convert
    entity, program_ctx.options, program_ctx, custom_vars)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transpiler.py"", line 412, in transform_function
    extra_locals)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transpiler.py"", line 373, in _transformed_factory
    nodes, ctx = self._transform_function(fn, user_context)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transpiler.py"", line 339, in _transform_function
    node = self.transform_ast(node, context)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 70, in transform_ast
    node = activity.resolve(node, ctx, None)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 705, in resolve
    return ActivityAnalyzer(context, parent_scope).visit(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\transformer.py"", line 445, in visit
    result = super(Base, self).visit(node)
  File ""C:\ProgramData\Miniconda3.7\lib\ast.py"", line 271, in visit
    return visitor(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 575, in visit_FunctionDef
    node = self._visit_arg_annotations(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 551, in _visit_arg_annotations
    node = self._visit_arg_declarations(node)
  File ""C:\ProgramData\Miniconda3.7\lib\site-packages\tensorflow\python\autograph\pyct\static_analysis\activity.py"", line 556, in _visit_arg_declarations
    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)
AttributeError: 'arguments' object has no attribute 'posonlyargs'

```"
41858,ImportError : cannot import name 'cloud” from  ' tensorflow.contrib' (/usr/1ocal/lib/ python3.7/dist-packages/tensorflow/ contrib/_ init Py),"I am using TensorFlow 1.14.0 and python3.7.
When  i run code, this erro will display.
![image](https://user-images.githubusercontent.com/31792429/88808693-c7eaef00-d1e5-11ea-9df3-afd3706d4806.png)



"
41857,protoc fails to execute due to missing environment (LD_LIBRARY_PATH),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0

**Describe the problem**

Build fails during execution of `protoc` due to unset `LD_LIBRARY_PATH

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Setup custom GCC + binutils and export PATH/LD_LIBRARY_PATH

**Any other info / logs**

This is the same problem as fixed in https://github.com/bazelbuild/bazel/pull/11860 which copied a file from grpc, fixed in https://github.com/grpc/grpc/pull/23664"
41856,TensorFlow 2.3.0 installation fails as protoc could not be found,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.4
- Bazel version (if compiling from source): 3.4.1

**Describe the current behavior**

Building TensorFlow fails with:

```
ERROR: /tmp/easybuild-tmp/eb-Lae15c/tmpdO084_-bazel-build/external/com_google_protobuf/BUILD:412:10: Linking of rule '@com_google_protobuf//:protoc' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed
: error executing command 
  (cd /tmp/easybuild-tmp/eb-Lae15c/tmpdO084_-bazel-build/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/software/generic/CUDA/10.1.243 \
    CUDNN_INSTALL_PATH=/sw/installed/cuDNN/7.6.4.38-gcccuda-2019b \
    GCC_HOST_COMPILER_PATH=/sw/installed/GCCcore/8.3.0/bin/gcc \
    LD_LIBRARY_PATH=<...> \
    NCCL_INSTALL_PATH=/sw/installed/NCCL/2.4.8-gcccuda-2019b \
    PATH=<...> \
    PWD=/proc/self/cwd \
    PYTHONNOUSERSITE=1 \
    PYTHONPATH=<...> \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
    TF_CUBLAS_VERSION=10.2.1 \
    TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.1,7.0 \
    TF_CUDA_PATHS=/sw/installed/CUDA/10.1.243 \
    TF_CUDA_VERSION=10.1 \
    TF_CUDNN_VERSION=7.6.4 \
    TF_NCCL_VERSION=2.4.8 \
    TF_NEED_CUDA=1 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-opt/bin/external/com_google_protobuf/protoc-2.params)
Execution platform: @local_execution_config_platform//:platform
gcc: error: bazel-out/k8-opt/bin/external/com_google_protobuf/protoc: No such file or directory
```

**Describe the expected behavior**

TF compiles

**Standalone code to reproduce the issue**

```
export TF_MKL_DOWNLOAD=1 &&   bazel --output_base=/tmp/easybuild-tmp/eb-Lae15c/tmpdO084_-bazel-build --install_base=/tmp/easybuild-tmp/eb-Lae15c/tmpdO084_-bazel-build/inst_base --output_user_root=/tmp/easybuild-tmp/eb-Lae15c/tmp6IGZ5P-user_root build --compilation_mode=opt --config=opt --subcommands --verbose_failures --config=noaws --jobs=24 --copt=""-fPIC"" --action_env=PYTHONPATH --action_env=PYTHONNOUSERSITE=1 --distinct_host_configuration=false  --config=mkl //tensorflow/tools/pip_package:build_pip_package
```"
41855,tf.keras.Sequential() fails,"**System information**
- Running the most basic instruction fails, for example from the documentation page [https://www.tensorflow.org/api_docs/python/tf/keras/Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)
- OS Platform and Distribution: Arch Linux kernel 5.7.10-arch1-1 (linux@archlinux) (gcc version 10.1.0 (GCC), GNU ld (GNU Binutils) 2.34.0)
- TensorFlow installed from (source or binary): binary package (official Arch package)
- TensorFlow version (use command below): tensorflow-cuda 2.3.0
- Python version: Python 3.8.4
- CUDA/cuDNN version: cuda 11.0
- GPU model and memory: GeForce GTX 950M,  Driver Version: 450.57 - 2004MiB

**Describe the current behavior**
Start python then run:

```

import tensorflow as tf

m = tf.keras.Sequential()
```
The last line fails with the following error messages:
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py"", line 116, in __init__
    super(functional.Functional, self).__init__(  # pylint: disable=bad-super-call
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 308, in __init__
    self._init_batch_counters()
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 317, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py"", line 262, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py"", line 244, in _variable_v2_call
    return previous_getter(
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py"", line 237, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py"", line 2633, in default_variable_creator_v2
    return resource_variable_ops.ResourceVariable(
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1507, in __init__
    self._init_from_args(
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1661, in _init_from_args
    handle = eager_safe_variable_handle(
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 242, in eager_safe_variable_handle
    return _variable_handle_from_shape_and_dtype(
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 174, in _variable_handle_from_shape_and_dtype
    gen_logging_ops._assert(  # pylint: disable=protected-access
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/ops/gen_logging_ops.py"", line 49, in _assert
    _ops.raise_from_not_ok_status(e, name)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 6843, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse
```

**Describe the expected behavior**

An empty sequential model is created, no error.

**Standalone code to reproduce the issue**
```
import tensorflow as tf

m = tf.keras.Sequential()
```


"
41854,Raspberry pi running tensorflow lite at 0.69 -0.73 fps.,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspberry pi 4 8gb ram
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): using TensorFlow 1.14
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: no
- GPU model and memory: no

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
It is giving incredibly low fps. 0.69 for tflite. This is the same when I am running with normal TensorFlow as well.
**Describe the expected behavior**
at 2 fps or above
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://github.com/Dasinator21/Replicate-Error
Github link above to my tflite model as well as the code I am running the model with.
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41853,Using tf.keras.Model.test_on_batch inside tf.function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7

**Describe the current behavior**
Given a tf.keras.Model and a tf.data.Dataset, I'd like to be able to iterate a batched dataset and perform mode.test_on_batch and collect the results.
Note: eager execution is disabled due to other reported bugs 

```python
import tensorflow as tf
import numpy as np

tf.compt.v1.disable_eager_execution()

x = tf.keras.Input(shape=(3,))
y = tf.keras.layers.Dense(2)(x)
model = tf.keras.Model([x], [y])
compile_kwargs = {'optimizer': 'sgd', 'loss': tf.keras.losses.mean_squared_error}
model.compile(**compile_kwargs)

data = [np.full(shape=(3,), fill_value=i) for i in range(10)]
data = np.asarray(data)
labels = [np.full(shape=(2,), fill_value=i)*3 for i in range(10)]
labels = np.asarray(labels)

ds = tf.data.Dataset.from_tensor_slices((data, labels)).batch(2)

# Option 1 - doesn't work when eager execution is disabled
# Throws - RuntimeError: __iter__() is only supported inside of tf.function or when eager execution is enabled.
# ins = ds.map(lambda x, y: x)
# for batch in ins:
   # r = model.test_on_batch(batch)
   # print(r)

# Option 2
@tf.function
def test_on_batch_example(model, ins):
  for batch in ins:
    r = model.test_on_batch(batch)
    print(r)
  
ins = ds.map(lambda x, y: x)
test_on_batch_example(model, ins)
```

Option 2 throws:
    <ipython-input-7-e1744a238c31>:5 test_on_batch_example  *
        r = model.test_on_batch(batch)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:1163 test_on_batch  **
        self._make_test_function()
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:2054 _make_test_function
        **self._function_kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:3943 function
        model = models.Model(inputs=inputs, outputs=outputs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:242 __new__
        return functional.Functional(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:464 _method_wrapper
        result = method(self, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:111 __init__
        self._init_graph_network(inputs, outputs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:464 _method_wrapper
        result = method(self, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:138 _init_graph_network
        base_layer_utils.create_keras_history(self._nested_outputs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:189 create_keras_history
        _, created_layers = _create_keras_history_helper(tensors, set(), [])
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:249 _create_keras_history_helper
        constants[i] = backend.eval_in_eager_or_function(op_input)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:3880 eval_in_eager_or_function
        raise ValueError('Unknown graph. Aborting.')

    ValueError: Unknown graph. Aborting.

**Standalone code to reproduce the issue**

https://colab.research.google.com/drive/1exTEugyIZCoc4j0rGyexj1CTf58weuaO?usp=sharing

"
41852,ERROR HINDERING MY ABILITY TO USE TENSOR FLOW,"
[TF Error.docx](https://github.com/tensorflow/tensorflow/files/4993986/TF.Error.docx)
Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
41851,Keras Callbacks logs / numpy_logs not in sync,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.8


**Describe the current behavior**
Some callbacks (e.g. ProgbarLogger, ModelCheckpoint, ...) have the flag `self._supports_tf_logs = True`. If other callbacks (especially custom Callback) don't have this property, then those callbacks do not have acces to the same logs. 
In the code example below, `ModelCheckpoint` can not use the `'val_log_loss'` as a monitor value from the `CustomMetric` callback.
This results from the commit https://github.com/tensorflow/tensorflow/commit/50480faea75f56def464b84f251b4aee388dfce9 where a new `numpy_logs` property has been introduced, without making sure to sync it with the pre-existing `logs` property.

**Describe the expected behavior**
The two propertys `numpy_logs` and `logs` should contain the same information OR it should be made clear in the docs (https://www.tensorflow.org/guide/keras/custom_callback#keras_callbacks_overview) what `_supports_tf_logs` does and that there could be compatibility issues.

**Standalone code to reproduce the issue**
```
...
from tensorflow.keras.callbacks import Callback, ModelCheckpoint
...

class CustomMetric(Callback):
    def __init__(self, x_valid, y_valid):
        super().__init__()
        self.x_valid = x_valid
        self.y_valid = y_valid

    def on_epoch_end(self, epoch, logs=None):
        y_pred = self.model.predict(self.x_valid, batch_size=BATCHSIZE)

        logs['val_log_loss'] = metrics.log_loss(self.y_valid, y_pred)

...

model.fit(
        x_train,
        y_train,
        validation_data=(x_valid, y_valid),
        shuffle=True,
        batch_size=BATCHSIZE,
        epochs=EPOCHS,
        verbose=1,
        callbacks=[CustomMetric(x_valid, y_valid), ModelCheckpoint('test.h5', 'val_log_loss', verbose=1, save_best_only=True, mode='min')]
    )

...
```

**Other info / logs** 
See commit https://github.com/tensorflow/tensorflow/commit/50480faea75f56def464b84f251b4aee388dfce9"
41850,TF r2.3 Bad Address build issue on windows,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows Server 2019 Standard
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: - 
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.3
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: - 
- Bazel version (if compiling from source): 3.3.1
- GCC/Compiler version (if compiling from source): MSVC 2019 v16.6.5 Microsoft (R) C/C++ Optimizing Compiler Version 19.26.28806 for x64
- CUDA/cuDNN version: CUDA v10.2, cudnn-10.2-windows10-x64-v7.6.5.32
- GPU model and memory: - 



**Describe the problem**

I have created a docker image for TF build on Windows Server 2019 host with `mcr.microsoft.com/windows/servercore:ltsc2019` base image. I have a problem with building when I would like to build a version with CUDA support. When I configure the build for CPU without CUDA everything build fine. With the CUDA support turned on I got `Bad address` error for bash commands like this.

> ERROR: C:/tensorflow/tensorflow/core/framework/BUILD:1107:31: Executing genrule //tensorflow/core/framework:attr_value_proto_text_srcs failed (Exit 126): bash.exe failed: error executing command
  cd C:/users/containeradministrator/_bazel_containeradministrator/xv6zejqw/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/cuda/v10.2
    SET PATH=C:\tools\msys64\usr\bin;C:\tools\msys64\bin;C:\Windows;C:\Windows\System32;C:\Windows\System32\WindowsPowerShell\v1.0
    SET PYTHON_BIN_PATH=C:/Python36/python.exe
    SET PYTHON_LIB_PATH=C:/Python36/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0
    SET TF_CUDA_PATHS=C:/cuda/v10.2,C:/cudnn/cuda
    SET TF_CUDA_VERSION=10
    SET TF_CUDNN_VERSION=7
    SET TF_ENABLE_XLA=1
    SET TF_NEED_CUDA=1
  C:/tools/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt-exec-50AE0418/bin/tensorflow/tools/proto_text/gen_proto_text_functions bazel-out/x64_wi
ndows-opt/bin/tensorflow/core/framework tensorflow/core/framework/ tensorflow/core/framework/attr_value.proto tensorflow/core/framework/resource_handle.proto tensorflow/core/framework/tensor.proto tensorflow/cor
e/framework/tensor_shape.proto tensorflow/core/framework/types.proto tensorflow/tools/proto_text/placeholder.txt
Execution platform: @local_execution_config_platform//:platform
/usr/bin/bash: bazel-out/x64_windows-opt-exec-50AE0418/bin/tensorflow/tools/proto_text/gen_proto_text_functions: Bad address
Target //tensorflow:libtensorflow_cc.so failed to build
ERROR: C:/tensorflow/tensorflow/core/framework/BUILD:1107:31 Executing genrule //tensorflow/core/framework:attr_value_proto_text_srcs failed (Exit 126): bash.exe failed: error executing command
  cd C:/users/containeradministrator/_bazel_containeradministrator/xv6zejqw/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/cuda/v10.2
    SET PATH=C:\tools\msys64\usr\bin;C:\tools\msys64\bin;C:\Windows;C:\Windows\System32;C:\Windows\System32\WindowsPowerShell\v1.0
    SET PYTHON_BIN_PATH=C:/Python36/python.exe
    SET PYTHON_LIB_PATH=C:/Python36/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0
    SET TF_CUDA_PATHS=C:/cuda/v10.2,C:/cudnn/cuda
    SET TF_CUDA_VERSION=10
    SET TF_CUDNN_VERSION=7
    SET TF_ENABLE_XLA=1
    SET TF_NEED_CUDA=1
  C:/tools/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt-exec-50AE0418/bin/tensorflow/tools/proto_text/gen_proto_text_functions bazel-out/x64_wi
ndows-opt/bin/tensorflow/core/framework tensorflow/core/framework/ tensorflow/core/framework/attr_value.proto tensorflow/core/framework/resource_handle.proto tensorflow/core/framework/tensor.proto tensorflow/cor
e/framework/tensor_shape.proto tensorflow/core/framework/types.proto tensorflow/tools/proto_text/placeholder.txt
Execution platform: @local_execution_config_platform//:platform
INFO: Elapsed time: 8.666s, Critical Path: 5.56s
INFO: 96 processes: 96 local.
FAILED: Build did NOT complete successfully

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Commands executed on host:
`docker run -it -v ""C:\Users\Administrator\Downloads\cudnn-10.2-windows10-x64-v7.6.5.32"":C:\cudnn -v ""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA"":C:\cuda  tf-build`

Commands executed inside the container:
`git clone -b r2.3 https://github.com/tensorflow/tensorflow.git`
`cd tensorflow`
`C:\Python36\python.exe configure.py`
`bazel build --config=opt --define=no_tensorflow_py_deps=true //tensorflow:libtensorflow_cc.so`

**Any other info / logs**
Content of .tf_configure.bazelrc file
```
build --action_env PYTHON_BIN_PATH=""C:/Python36/python.exe""
build --action_env PYTHON_LIB_PATH=""C:/Python36/lib/site-packages""
build --python_path=""C:/Python36/python.exe""
build --config=xla
build --action_env TF_CUDA_VERSION=""10""
build --action_env TF_CUDNN_VERSION=""7""
build --action_env TF_CUDA_PATHS=""C:/cuda/v10.2,C:/cudnn/cuda""
build --action_env CUDA_TOOLKIT_PATH=""C:/cuda/v10.2""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""3.5,7.0""
build --config=cuda
build:opt --copt=/arch:AVX
build:opt --define with_default_optimizations=true
build --define=override_eigen_strong_inline=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_windows,-no_windows_gpu,-no_gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_windows,-no_windows_gpu,-no_gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_windows,-no_windows_gpu,-no_gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_windows,-no_windows_gpu,-no_gpu,-v1only
build --action_env TF_CONFIGURE_IOS=""0""
```

Dockerfile:
```
FROM mcr.microsoft.com/windows/servercore:ltsc2019

LABEL description=""Tensorflow build""

USER ContainerAdministrator

# Install choco
ENV chocolateyUseWindowsCompression=false

RUN powershell -Command \
    iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1')); \
    choco feature disable --name showDownloadProgress


# Download the Visual Studio 2019 Build Tools bootstrapper.
RUN powershell -Command Invoke-WebRequest ""https://aka.ms/vs/16/release/vs_buildtools.exe"" -OutFile C:\vs_buildtools.exe

# Use the latest release channel.
RUN powershell -Command Invoke-WebRequest ""https://aka.ms/vs/16/release/channel"" -OutFile C:\VisualStudio.chman

# For help on command-line syntax:
# https://docs.microsoft.com/en-us/visualstudio/install/use-command-line-parameters-to-install-visual-studio
# Install MSVC C++ compiler, CMake, and MSBuild.
RUN C:\vs_buildtools.exe \
    --quiet --wait --norestart --nocache \
    --channelUri C:\VisualStudio.chman \
    --installChannelUri C:\VisualStudio.chman \ 
    --add Microsoft.VisualStudio.Workload.VCTools;includeRecommended \
    --add Microsoft.Component.MSBuild \
    || IF ""%ERRORLEVEL%""==""3010"" EXIT 0

# Install Git
RUN choco install git -y

# Install pacakages for Tensorflow build
RUN choco install python --version=3.6.8 -y
RUN choco install msys2 --params ""/NoUpdate"" -y
RUN setx /M PATH ""%PATH%;C:/tools/msys64/usr/bin""
RUN choco install bazel -y
RUN setx /M PATH ""%PATH%;C:/ProgramData/chocolatey/lib/bazel""
RUN pip3 install six numpy wheel
RUN pip3 install keras_applications==1.0.6 --no-deps
RUN pip3 install keras_preprocessing==1.0.5 --no-deps

RUN pacman -S git patch unzip nano --noconfirm
```
"
41849,"Exception: TensorFlow Lite currently doesn't support control flow ops: Merge, Switch.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):1.14


**Provide the text output from tflite_convert**

```
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
2020-07-29 15:27:21.979509: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1402 operators, 2593 arrays (0 quantized)
2020-07-29 15:27:22.011911: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1290 operators, 2425 arrays (0 quantized)
2020-07-29 15:27:22.054821: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1290 operators, 2425 arrays (0 quantized)
2020-07-29 15:27:22.098145: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 1062 operators, 2194 arrays (0 quantized)
2020-07-29 15:27:22.139738: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 1062 operators, 2194 arrays (0 quantized)
2020-07-29 15:27:22.172354: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 1062 operators, 2194 arrays (0 quantized)
2020-07-29 15:27:22.219537: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 1228800 bytes, theoretical optimal value: 921600 bytes.
2020-07-29 15:27:22.231094: E tensorflow/lite/toco/toco_tooling.cc:456] TensorFlow Lite currently doesn't support control flow ops: Merge, Switch.
Traceback (most recent call last):
  File ""/home/ps/anaconda3/envs/rknn/bin/toco_from_protos"", line 11, in <module>
    sys.exit(main())
  File ""/home/ps/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/ps/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ps/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ps/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/ps/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: TensorFlow Lite currently doesn't support control flow ops: Merge, Switch.
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
41848,GPU Installation instructions may need to be updated,"I'm following the [GPU install instructions](https://www.tensorflow.org/install/gpu) for Ubuntu 18.04 and getting the following after running this:
```
sudo apt-get install --no-install-recommends \
    cuda-10-1 \
    libcudnn7=7.6.5.32+cuda10.1  \
    libcudnn7-dev=7.6.5.32-1+cuda10.1
```
I'm getting this:
```
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Version '7.6.5.32+cuda10.1' for 'libcudnn7' was not found
```
 `7.6.5.32+cuda10.1` may need to be changed to  `7.6.5.32-1+cuda10.1`  since the latter works.
"
41847,"Timeseries example is a Misnomer. It is NOT a ""timeseries"" it is rather a simple series.","https://www.tensorflow.org/tutorials/structured_data/time_series#part_2_forecast_a_multivariate_time_series

I do not understand how this can be time series ? The data is ""equidistant"" with each other. And the time itself is not considered in predicting the values, but rather just as a series. When you include TIME AS A VECTOR, i would accept that it is a Timeseries.

The title is MISLEADING and also we need an example for vectorizing Time... for an actual Timeseries."
41846,"Missing ""model"" in visualize.py script: tflite model AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model' ","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.0
- Python version: 3.8.1
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""` v1.12.1-37714-gac84c5eb81 2.4.0


**I followed the [instructions](https://www.tensorflow.org/lite/guide/faq#how_do_i_inspect_a_tflite_file) in order to inspect a tflite file. Compilation and installation of the python whl was successful. pip freeze shows 
tensorflow @ file:///tmp/tensorflow_pkg/tensorflow-2.4.0-cp38-cp38-linux_x86_64.whl. Starting the python consul and importing tensorflow works as expected. 

However, running 

python visualize.py foo.tflite foo.html

results in a an error

Traceback (most recent call last):
  File ""visualize.py"", line 517, in <module>
    main(sys.argv)
  File ""visualize.py"", line 513, in main
    CreateHtmlFile(tflite_input, html_output)
  File ""visualize.py"", line 429, in CreateHtmlFile
    data = CreateDictFromFlatbuffer(file_data)
  File ""visualize.py"", line 414, in CreateDictFromFlatbuffer
    model_obj = schema_fb.Model.GetRootAsModel(buffer_data, 0)
AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'


In addition, 

bazel run //tensorflow/lite/tools:visualize model.tflite visualized_model.html

results in a similar error

INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=153
INFO: Reading rc options for 'run' from /home/omri/src/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'run' from /home/omri/src/tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'run' from /home/omri/src/tensorflow/.tf_configure.bazelrc:
  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/home/omri/.pyenv/versions/tf_src/bin/python3 --action_env PYTHON_LIB_PATH=/home/omri/.pyenv/versions/tf_src/lib/python3.8/site-packages --python_path=/home/omri/.pyenv/versions/tf_src/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /home/omri/src/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/omri/src/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/omri/src/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:linux in file /home/omri/src/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/omri/src/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/lite/tools:visualize (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
Target //tensorflow/lite/tools:visualize up-to-date:
  bazel-bin/tensorflow/lite/tools/visualize
INFO: Elapsed time: 0.132s, Critical Path: 0.01s
INFO: 0 processes.
INFO: Build completed successfully, 1 total action
INFO: Running command line: bazel-bin/tensorflow/lite/tools/visualize /home/omri/Downloads/mobilenet_thin_openpose_opt_fullint_tf1.tflite /home/omri/DownINFO: Build completed successfully, 1 total action
Traceback (most recent call last):
  File ""/home/omri/.cache/bazel/_bazel_omri/a9e9b87cb64d67149db4f28645a2ba4b/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/visualize.runfiles/org_tensorflow/tensorflow/lite/tools/visualize.py"", line 517, in <module>
    main(sys.argv)
  File ""/home/omri/.cache/bazel/_bazel_omri/a9e9b87cb64d67149db4f28645a2ba4b/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/visualize.runfiles/org_tensorflow/tensorflow/lite/tools/visualize.py"", line 513, in main
    CreateHtmlFile(tflite_input, html_output)
  File ""/home/omri/.cache/bazel/_bazel_omri/a9e9b87cb64d67149db4f28645a2ba4b/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/visualize.runfiles/org_tensorflow/tensorflow/lite/tools/visualize.py"", line 429, in CreateHtmlFile
    data = CreateDictFromFlatbuffer(file_data)
  File ""/home/omri/.cache/bazel/_bazel_omri/a9e9b87cb64d67149db4f28645a2ba4b/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/visualize.runfiles/org_tensorflow/tensorflow/lite/tools/visualize.py"", line 414, in CreateDictFromFlatbuffer
    model_obj = schema_fb.Model.GetRootAsModel(buffer_data, 0)
AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'


Finally, starting the python consul and trying to import `Model` from  'tensorflow.lite.python.schema_py_generated' results in the same error

~/src/tensorflow/tensorflow/lite/tools$ python
Python 3.8.1 (default, Mar  5 2020, 13:14:49) 
[GCC 7.4.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from tensorflow.lite.python import schema_py_generated
>>> schema_py_generated.Model
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'

**

**The script should generate an HTML file**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41845,"Tensorflow raises exception in eager mode but works in graph mode ""AttributeError: 'float' object has no attribute '_id'""","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): `v2.1.0-rc2-17-ge5bf8de410 2.1.0`
- Python version: 3.7.6
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: V10.1.243
- GPU model and memory: RTX2070 MaxQ, 8GB

**Describe the current behavior**

Running the following code in Eager mode, the line `tf.print(tape.gradient(y, x))` throws with exception  `AttributeError: 'float' object has no attribute '_id'`. In Graph mode it returns `None` gradient as expected.

```python
# @tf.function
def sign(x):
    tf.debugging.assert_rank(x, 0)
    
    if x > 0:
        return 1.0
    else:
        return -1.0
    
x = tf.constant(3.0, dtype=tf.float32)

with tf.GradientTape() as tape:
    tape.watch(x)
    y = sign(x)
    
tf.print(y)
tf.print(tape.gradient(y, x))
```

However, wrapping the return values in `tf.constant` does not throw an exception

```python
def sign(x):
    tf.debugging.assert_rank(x, 0)
    
    if x > 0:
        return tf.constant(1.0)
    else:
        return tf.constant(-1.0)
    
x = tf.constant(3.0, dtype=tf.float32)

with tf.GradientTape() as tape:
    tape.watch(x)
    y = sign(x)
    
tf.print(y)
tf.print(tape.gradient(y, x))
```

**Describe the expected behavior**

It should either not throw an error in Eager mode or give a more verbose error message

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-8-f537fe9b7f6f> in <module>
     15 
     16 tf.print(y)
---> 17 tf.print(tape.gradient(y, x))

c:\users\windows\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\eager\backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)
   1027         output_gradients=output_gradients,
   1028         sources_raw=flat_sources_raw,
-> 1029         unconnected_gradients=unconnected_gradients)
   1030 
   1031     if not self._persistent:

c:\users\windows\appdata\local\programs\python\python37\lib\site-packages\tensorflow_core\python\eager\imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)
     75       output_gradients,
     76       sources_raw,
---> 77       compat.as_str(unconnected_gradients.value))

AttributeError: 'float' object has no attribute '_id'
```
"
41844,"""inputs"" method of tflite::Interpreter causes crash.","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: MatePad Pro
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): Android NDK 21.3.6528147
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

Using TensorFlow Lite C++ API, when you call ""inputs"" method of tflite::Interpreter, you get the error `terminating with uncaught exception of type std::length_error: vector` and the program crashes.

Until the source code with the tag 2.3.0-rc2, it works and the source code with the tag 2.3.0 and later, it crashes.

**Describe the expected behavior**

No crashes and get the result of inputs.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41843,tf.data.Dataset API with ImageGenerator => ValueError: as_list() is not defined on an unknown TensorShape.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): See the colab link below
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.2.0
- TensorFlow version (use command below): 2.2.0
- Python version: sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: colab: CPU/GPU/TPU

**Describe the current behavior**
When using tf.data.Dataset API fit throws an exception:
INFO:tensorflow:Error reported to Coordinator: as_list() is not defined on an unknown TensorShape.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py"", line 297, in stop_on_exception
    yield
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py"", line 998, in run
    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 262, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 418, in converted_call
    return _call_unconverted(f, args, kwargs, options, False)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 346, in _call_unconverted
    return f(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 543, in train_step
    self.compiled_metrics.update_state(y, y_pred, sample_weight)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py"", line 391, in update_state
    self._build(y_pred, y_true)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py"", line 322, in _build
    self._metrics, y_true, y_pred)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py"", line 1118, in map_structure_up_to
    **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py"", line 1214, in map_structure_with_tuple_paths_up_to
    *flat_value_lists)]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py"", line 1213, in <listcomp>
    results = [func(*args, **kwargs) for args in zip(flat_path_list,
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py"", line 1116, in <lambda>
    lambda _, *values: func(*values),  # Discards the path arg.
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py"", line 421, in _get_metric_objects
    return [self._get_metric_object(m, y_t, y_p) for m in metrics]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py"", line 421, in <listcomp>
    return [self._get_metric_object(m, y_t, y_p) for m in metrics]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py"", line 442, in _get_metric_object
    y_t_rank = len(y_t.shape.as_list())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 1173, in as_list
    raise ValueError(""as_list() is not defined on an unknown TensorShape."")
ValueError: as_list() is not defined on an unknown TensorShape.

**Describe the expected behavior**
No exception.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1TnU5zWWyLeDnk2K-6aVeur0W9zEscWuX?usp=sharing

Provide a reproducible test case that is the bare minimum necessary to generate
the problem.https://colab.research.google.com/drive/1TnU5zWWyLeDnk2K-6aVeur0W9zEscWuX?usp=sharing

**Other info / logs** 
Please use **use_dataset_api** flag to toggle using dataset API vs ImageGenerator, which works"
41840,Issue with a specific dataset with tf lite full integer quantisation uint8,"TensorFlow version: tf-nightly 2.4.0-dev20200728
Keras: 2.4.3
Python: 3.6.9

Issue: I trained DenseNet-169 with my dataset, validation accuracy 67.8%. My dataset (10k training images, 2k test images) is made in this way: each picture is 3 different pictures 200x200 pixels int8 piled up together. In the google colab file training_densenet169 is it possible to find a tool to visualise the images. 
After training I convert the model with tf converter (see colab file tf_to_tf_lite converter) to tf lite full integer uint8 quantisation. The tf lite model is subsequently tested with the google colab file test_tf_lite_cpu. The test shows that the tf lite model doesn't work, it predicts always the same value.

I made the following tests. 
1) I changed my dataset so to have only one channel (therefore not the three pictures pile up). I trainined it with accuracy 67.8%, converted to tf lite, and tested it. The test failed. 
2) I then took the cifar10 dataset,  multiply by 7 the size in order to have 224x224 pixels images with 3 channels, and trained densenet169, conerted to tf lite, and tested. It worked.

My ideas: 
1) cifar10 is similar to my dataset, and it works. Is it possible that maybe there is a bug so that my images size 200x200 don't work but cifar10 size 224x224 does?
2) If you can, have a look to my dataset. Is there anything specific that could trigger a failure mode in the converter? I couldn't see anything specific.

Additional information: All of the other tf lite quantisations work perfectly, only the full integer quantisation doesn't work.

Everything can be found in this google folder: https://drive.google.com/drive/u/0/folders/11XruNeJzdIm9DTn7FnuIWYaSalqg2F0B
"
